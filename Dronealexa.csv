Title,URL,Publication Year,Abstract
AERIAL DRONE COMPANION DEVICE AND A METHOD OF OPERATING AN AERIAL DRONE COMPANION DEVICE,https://lens.org/059-472-052-640-920,2018,"A method of operating an aerial drone companion device includes detecting a first voice command spoken by a first user. The aerial drone companion device is autonomously oriented such that an image capture device faces the first user in response to detecting the first voice command. A second voice command spoken by the first user is detected while the image capture device faces the first user. The second voice command is transmitted from the aerial drone companion device to a computer located remotely from the aerial drone companion device. A task signal is received indicating a task to be performed. The task signal is generated by the computer based on the second voice command, and the task signal is transmitted by the computer and received by the aerial drone companion device. The method includes autonomously executing the task by the aerial drone companion device."
Aerial drone companion device and a method of operating an aerial drone companion device,https://lens.org/059-612-079-304-443,2018,"A method of operating an aerial drone companion device includes detecting a first voice command spoken by a first user. The aerial drone companion device is autonomously oriented such that an image capture device faces the first user in response to detecting the first voice command. A second voice command spoken by the first user is detected while the image capture device faces the first user. The second voice command is transmitted from the aerial drone companion device to a computer located remotely from the aerial drone companion device. A task signal is received indicating a task to be performed. The task signal is generated by the computer based on the second voice command, and the task signal is transmitted by the computer and received by the aerial drone companion device. The method includes autonomously executing the task by the aerial drone companion device."
Onboard drone human-machine interface for autonomous operation,https://lens.org/033-727-794-808-209,2021,"An autonomous drone system uses an onboard command and control system for controlling operations of a drone without the need for a radio frequency controller or an external electronic device programming unit. The system uses a control unit that interacts with the drone's unmanned aerial system flight controller. The control unit is programmed via an HMI button that is resident onboard the drone. Various sequences of HMI button depressions program the drone for its missions as well as command the drone to perform the missions. A microphone can be substituted for or can augment the HMI button. Various devices, such as a speaker, lights, a visual display screen, etc., can be resident on the drone for giving a user feedback during command and programming of the drone."
AUTONOMOUS NAVIGATION OF AN UNMANNED AERIAL VEHICLE,https://lens.org/129-513-967-300-276,2018,A system for autonomous navigation of an unmanned aerial vehicle.
"User equipment, system, and control method for controlling drone",https://lens.org/148-532-206-320-814,2023,"Provided is a user equipment for controlling a drone. The user equipment analyzes an original video to control the drone to photograph a reproduction video giving a feeling identical to or similar to the original video. An electronic device may be connected to an artificial intelligence module, a robot, an augmented reality (AR) device, a virtual reality (VR) device, a device related to 5G service, and the like."
"User equipment, system, and control method for controlling drone",https://lens.org/148-532-206-320-814,2023,"Provided is a user equipment for controlling a drone. The user equipment analyzes an original video to control the drone to photograph a reproduction video giving a feeling identical to or similar to the original video. An electronic device may be connected to an artificial intelligence module, a robot, an augmented reality (AR) device, a virtual reality (VR) device, a device related to 5G service, and the like."
"USER EQUIPMENT, SYSTEM, AND CONTROL METHOD FOR CONTROLLING DRONE",https://lens.org/046-703-121-297-868,2021,"Provided is a user equipment for controlling a drone. The user equipment analyzes an original video to control the drone to photograph a reproduction video giving a feeling identical to or similar to the original video. An electronic device may be connected to an artificial intelligence module, a robot, an augmented reality (AR) device, a virtual reality (VR) device, a device related to 5G service, and the like."
AUTONOMOUS DRONE,https://lens.org/190-048-859-515-65X,2023,"An autonomous drone is provided. When a remote control circuit of a remote controller is triggered to output a remote control signal, a main controller of a drone records the remote control signal and a flight control panel of the drone controls the drone to fly according to the remote control signal. When the remote controller is triggered to output an automatic flight signal, a signal receiver of the drone receives and transmits the automatic flight signal to the main controller. At this time, the main controller instructs the flight control panel to control the drone to fly according to movement instruction messages of the remote control signal previously recorded."
DRONE PAYLOAD SYSTEM,https://lens.org/198-691-574-445-436,2019,"A drone payload device includes a remote drone arm and a control module. The remote drone are is coupleable to a drone. The remote drone arm includes a base, an arm, and a gripper. The base includes mounting hardware to couple to the drone. The arm extends from the base. The griper is coupled to the arm at an end of the arm distal from the base. The control module is coupleable to a drone controller. The control module is to provide a control signal to the remote drone arm to control a movement of at least one of the arm and the gripper."
Drone payload system,https://lens.org/178-369-448-015-194,2020,"A drone payload device includes a remote drone arm and a control module. The remote drone are is coupleable to a drone. The remote drone arm includes a base, an arm, and a gripper. The base includes mounting hardware to couple to the drone. The arm extends from the base. The griper is coupled to the arm at an end of the arm distal from the base. The control module is coupleable to a drone controller. The control module is to provide a control signal to the remote drone arm to control a movement of at least one of the arm and the gripper."
"Drone, method for controlling flight of the same, and non-transitory computer-readable recording medium storing program",https://lens.org/084-847-945-186-950,2018,"A drone, a method for controlling the flight of a drone, and a program for controlling the flight of a drone capable of preventing the drone from flying into a place where it is difficult for an operator to visually observe the drone and flying the drone within an area in which the operator can visually observe the drone are provided. A control unit of the drone determines whether an illuminance detected by an illuminance sensor satisfies a required illuminance for the drone to fly, and if the detected illuminance does not satisfy the required illuminance, inhibits the drone from flying in the flight direction."
"DRONE, METHOD FOR CONTROLLING FLIGHT OF THE SAME, AND NON-TRANSITORY COMPUTER-READABLE RECORDING MEDIUM STORING PROGRAM",https://lens.org/153-773-754-310-48X,2017,"A drone, a method for controlling the flight of a drone, and a program for controlling the flight of a drone capable of preventing the drone from flying into a place where it is difficult for an operator to visually observe the drone and flying the drone within an area in which the operator can visually observe the drone are provided. A control unit of the drone determines whether an illuminance detected by an illuminance sensor satisfies a required illuminance for the drone to fly, and if the detected illuminance does not satisfy the required illuminance, inhibits the drone from flying in the flight direction."
ACCIDENT IDENTIFICATION AND COMMUNICATION IN VEHICLES,https://lens.org/044-541-296-643-927,2017,"A drone control method includes commanding a drone launched from a vehicle to execute a predefined schedule of flight commands such that the drone occupies a series of locations within a predefined radius from a buoy, which is also launched from the vehicle, to identify a drone position relative to the buoy associated with a maximum signal strength of the communication signal. The execution of the predefined schedule may be in response to receipt of a communication signal from an emergency responder."
"Apparatus, method and software for assisting human operator in flying drone using remote controller",https://lens.org/118-417-369-552-204,2022,"Apparatus, method, and software for assisting human operator in flying drone using remote controller. The apparatus includes an internal data communication interface configured to receive data from the remote controller, an augmented reality display configured to display the data, one or more memories including computer program code, and one or more processors to cause the apparatus to: superimpose, on the augmented reality display, a target symbol indicating a position of the drone while the human operator is looking towards the drone; superimpose, on the augmented reality display, an orientation symbol indicating an orientation of the drone while the human operator is looking towards the drone; obtain a geographic location related to the drone; and set a world marker on the obtained geographic location."
SECURITY DRONE WITH NON-LETHAL DETERRENT,https://lens.org/086-828-097-425-259,2020,"A drone for deterring intruders within a monitored area includes a multirotor aerial vehicle with an electric drive apparatus and a power supply configured to provide electrical energy. A controller is configured to control the multirotor aerial vehicle. A first sensor is in electrical communication with the controller, the sensor configured to provide navigation information to the controller. A wireless communication circuit is in electrical communication with the controller, and in wireless communication with an external wireless transceiver. A deterrence effector bay is in electrical communication with the controller. The deterrence effector bay includes a non-lethal deterrence effector and an actuator. Activation of the actuator causes the delivery of the non-lethal deterrence effector to a target. The drone may be used in conjunction with an alarm system as a deterrent against intrusion."
Remoteless control of drone behavior,https://lens.org/148-478-781-466-882,2022,"A drone system is configured to capture an audio stream that includes voice commands from an operator, to process the audio stream for identification of the voice commands, and to perform operations based on the identified voice commands. The drone system can identify a particular voice stream in the audio stream as an operator voice, and perform the command recognition with respect to the operator voice to the exclusion of other voice streams present in the audio stream. The drone can include a directional camera that is automatically and continuously focused on the operator to capture a video stream usable in disambiguation of different voice streams captured by the drone."
REMOTELESS CONTROL OF DRONE BEHAVIOR,https://lens.org/166-750-838-711-387,2023,"A drone system is configured to capture an audio stream that includes voice commands from an operator, to process the audio stream for identification of the voice commands, and to perform operations based on the identified voice commands. The drone system can identify a particular voice stream in the audio stream as an operator voice, and perform the command recognition with respect to the operator voice to the exclusion of other voice streams present in the audio stream. The drone can include a directional camera that is automatically and continuously focused on the operator to capture a video stream usable in disambiguation of different voice streams captured by the drone."
REMOTELESS CONTROL OF DRONE BEHAVIOR,https://lens.org/166-750-838-711-387,2023,"A drone system is configured to capture an audio stream that includes voice commands from an operator, to process the audio stream for identification of the voice commands, and to perform operations based on the identified voice commands. The drone system can identify a particular voice stream in the audio stream as an operator voice, and perform the command recognition with respect to the operator voice to the exclusion of other voice streams present in the audio stream. The drone can include a directional camera that is automatically and continuously focused on the operator to capture a video stream usable in disambiguation of different voice streams captured by the drone."
Remoteless control of drone behavior,https://lens.org/148-478-781-466-882,2022,"A drone system is configured to capture an audio stream that includes voice commands from an operator, to process the audio stream for identification of the voice commands, and to perform operations based on the identified voice commands. The drone system can identify a particular voice stream in the audio stream as an operator voice, and perform the command recognition with respect to the operator voice to the exclusion of other voice streams present in the audio stream. The drone can include a directional camera that is automatically and continuously focused on the operator to capture a video stream usable in disambiguation of different voice streams captured by the drone."
CONTROL OF AN AERIAL DRONE USING RECOGNIZED GESTURES,https://lens.org/062-529-651-002-659,2017,"A method, system, and/or computer program product controls movement and adjusts operations of an aerial drone. A drone camera observes an aerial maneuver physical gesture by a user. The aerial drone then performs an aerial maneuver that correlates to the aerial maneuver physical gesture. The drone camera observes the user performing a physical action. One or more processors associate the physical action with a particular type of activity. A drone on-board computer adjusts an operation of an aerial drone based on the particular type of activity."
Control of an aerial drone using recognized gestures,https://lens.org/136-114-218-406-626,2019,"A method, system, and/or computer program product controls movement and adjusts operations of an aerial drone. A drone camera observes an aerial maneuver physical gesture by a user. The aerial drone then performs an aerial maneuver that correlates to the aerial maneuver physical gesture. The drone camera observes the user performing a physical action. One or more processors associate the physical action with a particular type of activity. A drone on-board computer adjusts an operation of an aerial drone based on the particular type of activity."
"METHOD FOR NAVIGATING AN AERIAL DRONE IN THE PRESENCE OF AN INTRUDING AIRCRAFT, AND DRONE FOR IMPLEMENTING SAID METHOD",https://lens.org/091-249-805-810-065,2017,Aerial drone designed for implementation of this method.
LONG DISTANCE TRANS-CONTINENTAL REMOTE DRONE PILOTING SYSTEM,https://lens.org/051-074-426-307-811,2023,"A remote drone control system includes a pilot endpoint system comprising a pilot endpoint and a controller connected to the pilot endpoint. The remote drone control system includes a control endpoint system including a control endpoint, a signal adaptor connected to the control endpoint, and a transmitter connected to the signal adaptor. A drone is arranged to communicate with the transmitter to receive and send drone operating data to the control endpoint system. The drone is also arranged to communicate drone video data to the control endpoint system. A remote bridge including a server is arranged to connect the pilot endpoint and the control endpoint such that data is communicated amongst the pilot endpoint, control endpoint, and drone in real-time."
LONG DISTANCE TRANS-CONTINENTAL REMOTE DRONE PILOTING SYSTEM,https://lens.org/152-848-405-344-355,2021,"A remote drone control system includes a pilot endpoint system comprising a pilot endpoint and a controller connected to the pilot endpoint. The remote drone control system includes a control endpoint system including a control endpoint, a signal adaptor connected to the control endpoint, and a transmitter connected to the signal adaptor. A drone is arranged to communicate with the transmitter to receive and send drone operating data to the control endpoint system. The drone is also arranged to communicate drone video data to the control endpoint system. A remote bridge including a server is arranged to connect the pilot endpoint and the control endpoint such that data is communicated amongst the pilot endpoint, control endpoint, and drone in real-time."
UNMANNED AERIAL VEHICLES,https://lens.org/084-077-201-122-307,2022,"A drone comprising a camera and a controller. The camera is configured to output data representing an object within a field of view of the camera. The controller is configured to attempt to maintain a visual line of sight with the object. The controller is also configured to cause control equipment of an operator of the drone to notify the operator of the drone, visually, audibly and/or haptically, as to whether or not the object is being tracked by the drone."
UNMANNED AERIAL VEHICLES,https://lens.org/084-077-201-122-307,2022,"A drone comprising a camera and a controller. The camera is configured to output data representing an object within a field of view of the camera. The controller is configured to attempt to maintain a visual line of sight with the object. The controller is also configured to cause control equipment of an operator of the drone to notify the operator of the drone, visually, audibly and/or haptically, as to whether or not the object is being tracked by the drone."
"APPARATUS, METHOD AND SOFTWARE FOR ASSISTING HUMAN OPERATOR IN FLYING DRONE USING REMOTE CONTROLLER",https://lens.org/186-917-932-518-708,2022,"Apparatus, method, and software for assisting human operator in flying drone using remote controller. The apparatus includes an internal data communication interface configured to receive data from the remote controller, an augmented reality display configured to display the data, one or more memories including computer program code, and one or more processors to cause the apparatus to: superimpose, on the augmented reality display, a target symbol indicating a position of the drone while the human operator is looking towards the drone; and superimpose, on the augmented reality display, an orientation symbol indicating an orientation of the drone while the human operator is looking towards the drone."
"APPARATUS, METHOD AND SOFTWARE FOR ASSISTING HUMAN OPERATOR IN FLYING DRONE USING REMOTE CONTROLLER",https://lens.org/186-917-932-518-708,2022,"Apparatus, method, and software for assisting human operator in flying drone using remote controller. The apparatus includes an internal data communication interface configured to receive data from the remote controller, an augmented reality display configured to display the data, one or more memories including computer program code, and one or more processors to cause the apparatus to: superimpose, on the augmented reality display, a target symbol indicating a position of the drone while the human operator is looking towards the drone; and superimpose, on the augmented reality display, an orientation symbol indicating an orientation of the drone while the human operator is looking towards the drone."
"Apparatus, method and software for assisting human operator in flying drone using remote controller",https://lens.org/049-350-915-169-217,2023,"Apparatus, method, and software for assisting human operator in flying drone using remote controller. The apparatus includes an internal data communication interface configured to receive data from the remote controller, an augmented reality display configured to display the data, one or more memories including computer program code, and one or more processors to cause the apparatus to: superimpose, on the augmented reality display, a target symbol indicating a position of the drone while the human operator is looking towards the drone; and superimpose, on the augmented reality display, an orientation symbol indicating an orientation of the drone while the human operator is looking towards the drone."
Situational command and control of drones,https://lens.org/075-823-093-593-579,2019,"Disclosed herein is a drone. The drone may comprise a flight mechanism, a receiver, and a navigation transmitter. The flight mechanism may execute a flight maneuver provided by a user. The receiver may receive, from an authority, an interruption signal. The interruption signal may include a command to interrupt the flight maneuver provided by the user. The navigation transmitter may transmit, to the flight mechanism, the command to interrupt the flight maneuver to the flight mechanism."
SITUATIONAL COMMAND AND CONTROL OF DRONES,https://lens.org/115-189-598-949-247,2018,"Disclosed herein is a drone. The drone may comprise a flight mechanism, a receiver, and a navigation transmitter. The flight mechanism may execute a flight maneuver provided by a user. The receiver may receive, from an authority, an interruption signal. The interruption signal may include a command to interrupt the flight maneuver provided by the user. The navigation transmitter may transmit, to the flight mechanism, the command to interrupt the flight maneuver to the flight mechanism."
METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE USING SMART DEVICE,https://lens.org/110-761-089-176-779,2017,"A method for controlling unmanned aerial vehicle using a smart device. The unmanned aerial vehicle includes a smart device and an unmanned plane, the smart device operating to control the flight of the unmanned plane via wireless communication signal, the smart device comprising in-built central processing unit, touch screen, wireless communication system, battery, and volume key, and an application for controlling the unmanned plane being installed in the smart device. The unmanned plane includes a power system, a flight control system, and a sensor. The method includes: 1) allowing the wireless communication system of the smart device to communicate with the unmanned plane; 2) allowing the application installed in the smart device to manipulate the unmanned plane; 3) allowing the wireless communication system to control the transmission of the commands of the unmanned plane, and to send the flight parameters of the unmanned plane back to the smart device; and 4) defining the volume key of the smart device to synchronously adjust the flight height of the unmanned plane. The volume key of the smart device is defined to synchronously adjust the flight height of the unmanned plane, so that the height of the unmanned plane is controlled conveniently."
"DRONE SYSTEM, DRONE, MOVABLE BODY, DRONE SYSTEM CONTROL METHOD, AND DRONE SYSTEM CONTROL PROGRAM",https://lens.org/010-500-468-935-180,2022,"A drone system that includes a drone and a movable body which is movable with loading the drone and where the drone can take off and land, cooperate to operate and that is able to maintain a high level of safety even during autonomous flight, is provided. The drone has a flight controller controlling a flight of the drone, and a drone transmitter transmitting an information possible to distinguish whether the drone is in flight. The movable body has a take-off and landing area where the drone is loaded, takes off and lands, a movement controller loading the drone on the take-off and landing area and moving the movable body with the drone, a movable body receiver receiving an information from the drone, and a display unit."
HUMAN INDICATION OF TARGET DRONE FOR INTERCEPTION,https://lens.org/040-098-793-546-598,2018,A system for tracking a drone includes a device where a human designates a drone as a target drone and a second autonomous intercept drone having an on-board sensor to track the target drone and self pilots to the location of the target drone
DRONE CONTROLLING DEVICE AND A DRONE,https://lens.org/133-952-207-213-945,2022,"A drone controlling device is provided that is connectable to an electrical system (102) of a drone (104, 302, 402, 502). The drone controlling device comprises a transponder (110) arranged to monitor surrounding airspace and a positioning module (112) configured to identify a location of the drone. The drone controlling device further comprises a cellular communication module (114) being configured to control the drone by communicating with a remote device and to communicate a location to the remote device. One or more data exchange modules (116) in the drone controlling device are arranged to store at least a unique identification code of the drone and exchange the unique identification code with the remote device. The drone controlling device further comprises a power switching unit (118) arranged to control a power unit of the drone remotely to reduce the power consumption of the drone."
DRONE CONTROLLING DEVICE AND A DRONE,https://lens.org/133-952-207-213-945,2022,"A drone controlling device is provided that is connectable to an electrical system (102) of a drone (104, 302, 402, 502). The drone controlling device comprises a transponder (110) arranged to monitor surrounding airspace and a positioning module (112) configured to identify a location of the drone. The drone controlling device further comprises a cellular communication module (114) being configured to control the drone by communicating with a remote device and to communicate a location to the remote device. One or more data exchange modules (116) in the drone controlling device are arranged to store at least a unique identification code of the drone and exchange the unique identification code with the remote device. The drone controlling device further comprises a power switching unit (118) arranged to control a power unit of the drone remotely to reduce the power consumption of the drone."
Drone,https://lens.org/139-131-972-054-70X,2016,"A drone 3 is associated with a work machine 1 (e.g. a digger, backhoe, bulldozer, earth mover, fork-lift, agricultural tractor, forestry vehicle, truck or other heavy or construction vehicle). Control data (e.g. a navigation path or 3D coordinates) is determined for controlling the drone with respect to the work machine 1. The work machine may have a docking station 9 comprising a housing and cover; a latch for securing the drone; a quick-release spring-loaded thrust device for launching the drone; and data-link and charging ports. The drone may comprise sensors which capture image or audio data of an area near the work vehicle and present them via a user interface in the work machine. Thus the drone may transmit an image of an obscured area 21 near the bucket 7 of an excavator"
Drone,https://lens.org/139-131-972-054-70X,2016,"A drone 3 is associated with a work machine 1 (e.g. a digger, backhoe, bulldozer, earth mover, fork-lift, agricultural tractor, forestry vehicle, truck or other heavy or construction vehicle). Control data (e.g. a navigation path or 3D coordinates) is determined for controlling the drone with respect to the work machine 1. The work machine may have a docking station 9 comprising a housing and cover; a latch for securing the drone; a quick-release spring-loaded thrust device for launching the drone; and data-link and charging ports. The drone may comprise sensors which capture image or audio data of an area near the work vehicle and present them via a user interface in the work machine. Thus the drone may transmit an image of an obscured area 21 near the bucket 7 of an excavator"
DRONE AND METHOD FOR CONTROLLING THE SAME,https://lens.org/119-033-078-591-75X,2017,"A drone including a flying unit configured to generate a lift force for flying; a communication unit configured to receive sensing data obtained in a mobile terminal from the mobile terminal; a camera configured to capture a specific object; and a controller configured to recognize at least one of a movement change of the specific object and a status change of the specific object based on the received sensing data, change a capturing composition of the specific object based on the recognized at least one of the movement change and the status change, and capture the specific object via the camera based on the changed capturing composition."
Drone and method for controlling the same,https://lens.org/055-015-122-689-342,2019,"A drone including a flying unit configured to generate a lift force for flying; a communication unit configured to receive sensing data obtained in a mobile terminal from the mobile terminal; a camera configured to capture a specific object; and a controller configured to recognize at least one of a movement change of the specific object and a status change of the specific object based on the received sensing data, change a capturing composition of the specific object based on the recognized at least one of the movement change and the status change, and capture the specific object via the camera based on the changed capturing composition."
System and method to operate a drone,https://lens.org/034-412-306-973-492,2016,"A method for controlling a drone includes receiving a natural language request for information about a spatial location, parsing the natural language request into data requests, configuring a flight plan and controlling one or more drones to fly over the spatial location to obtain data types based on the data requests, and extracting and analyzing data to answer the request. The method can include extracting data points from the data types, obtaining labels from a user for one or more of the data points, predicting labels for unlabeled data points from a learning algorithm using the labels obtained from the user, determining the predicted labels are true labels for the unlabeled data points and combining the extracted data, the user labeled data points and the true labeled data points to answer the request for information. The learning algorithm may be active learning using a support vector machine."
System and method to operate a drone,https://lens.org/164-387-753-282-142,2018,"A method for controlling a drone includes receiving a natural language request for information about a spatial location, parsing the natural language request into data requests, configuring a flight plan and controlling one or more drones to fly over the spatial location to obtain data types based on the data requests, and extracting and analyzing data to answer the request. The method can include extracting data points from the data types, obtaining labels from a user for one or more of the data points, predicting labels for unlabeled data points from a learning algorithm using the labels obtained from the user, determining the predicted labels are true labels for the unlabeled data points and combining the extracted data, the user labeled data points and the true labeled data points to answer the request for information. The learning algorithm may be active learning using a support vector machine."
SYSTEM AND METHOD TO OPERATE A DRONE,https://lens.org/020-046-066-659-174,2017,"A method for controlling a drone includes receiving a natural language request for information about a spatial location, parsing the natural language request into data requests, configuring a flight plan and controlling one or more drones to fly over the spatial location to obtain data types based on the data requests, and extracting and analyzing data to answer the request. The method can include extracting data points from the data types, obtaining labels from a user for one or more of the data points, predicting labels for unlabeled data points from a learning algorithm using the labels obtained from the user, determining the predicted labels are true labels for the unlabeled data points and combining the extracted data, the user labeled data points and the true labeled data points to answer the request for information. The learning algorithm may be active learning using a support vector machine."
"APPLICATION, SMART DEVICE, DRONE, SERVER, SYSTEM METHOD, AND PROGRAM FOR AUTOMATICALLY CONTROL DRONE FLIGHT",https://lens.org/050-704-035-959-692,2019,"The present invention is to provide an application, a smart device, a drone, a server, a method, and a program for automatically control drone flight that improve safety and convenience. The application for automatically controlling drone flight that runs on a smart device 100 connected with a drone 200 drives a camera provided in the smart device 100, acquires an image taken by the camera, analyzes the acquired image, and controls the drone flight based on a result of the image analysis."
"DRONE SYSTEM, DRONE, MOVABLE BODY, DRONE SYSTEM CONTROL METHOD, AND DRONE SYSTEM CONTROL PROGRAM",https://lens.org/121-591-640-527-543,2022,"There is provided a drone system in which a drone and a movable body operate in coordination with each other, the movable body being capable of moving with the drone aboard and allowing the drone to make a takeoff and a landing, the movable body including: a takeoff-landing area on which the drone can be placed and that serves as a takeoff-landing point from and on which the drone takes off and lands; a movement control section capable of moving the movable body together with the drone aboard; and a movable body transmission section that sends information on the movable body, the drone including: a flight control section that causes the drone to fly; and a drone reception section that receives information on the movable body, wherein the drone sends, to the movable body, a position of a takeoff-landing point at a time when the drone takes off."
"Application, smart device, drone, server, system method, and program for automatically control drone flight",https://lens.org/016-168-420-107-104,2019,"The present invention is to provide an application, a smart device, a drone, a server, a method, and a program for automatically controlling drone flight that improves safety and convenience. The application for automatically controlling drone flight that runs on a smart device 100 connected with a drone 200 drives a camera provided in the smart device 100, acquires an image taken by the camera, analyzes the acquired image, and controls the drone flight based on a result of the image analysis."
"System and method for threat monitoring, detection, and response",https://lens.org/120-033-852-508-309,2020,"A drone receives an activation command indicating a user's need for monitoring, and is deployed based on the activation command and a set of initial operational parameters. The drone autonomously navigates to a first position with respect to the user and performs a first configured action. A plurality of monitoring data signals corresponding to the user and surrounding environment is captured using sensors on the drone, and is wirelessly transmitted by the drone to a remote monitoring system. The monitoring data signals are continuously analyzed to generate updated operational parameters causing the drone to autonomously navigate to a second position and perform a second configured action. A third configured action is received by the drone from the remote monitoring system, wherein the third configured action is generated based on a threat analysis performed by the remote monitoring system on the monitoring data signals."
"SYSTEM AND METHOD FOR THREAT MONITORING, DETECTION, AND RESPONSE",https://lens.org/034-554-448-783-997,2018,"A drone receives an activation command indicating a user's need for monitoring, and is deployed based on the activation command and a set of initial operational parameters. The drone autonomously navigates to a first position with respect to the user and performs a first configured action. A plurality of monitoring data signals corresponding to the user and surrounding environment is captured using sensors on the drone, and is wirelessly transmitted by the drone to a remote monitoring system. The monitoring data signals are continuously analyzed to generate updated operational parameters causing the drone to autonomously navigate to a second position and perform a second configured action. A third configured action is received by the drone from the remote monitoring system, wherein the third configured action is generated based on a threat analysis performed by the remote monitoring system on the monitoring data signals."
"DRONE SYSTEM, DRONE, STEERING DEVICE, DRONE SYSTEM CONTROL METHOD, AND DRONE SYSTEM CONTROL PROGRAM",https://lens.org/192-750-420-836-345,2021,"A highly safe drone is provided. A remote controller and a drone are connected to each other through a network and cooperate to operate. The drone includes a flight control unit, a flight start command reception unit receiving a flight start command from a user, a drone determination unit determining a configuration of the drone itself, an external environment determination unit determining an external environment of the drone. The drone system has a plurality of states including a takeoff diagnosis state and satisfies a condition transitioning to another state. The takeoff diagnosis state includes a drone determination state where the drone determination unit determines the configuration of the drone itself and an external environment determination state where the external environment determination unit determines the external environment. The drone system makes the drone to takeoff after transitioning to the takeoff diagnosis state upon receiving the flight start command."
DRONE FLIGHT CONTROL,https://lens.org/122-984-805-905-703,2017,A drone system and method. Audio signals are received via one or more microphones positioned relative to a location on a drone and one or more of the audio signals are identified as of interest. Flight characteristics of the drone are then controlled based on the audio signals that are of interest.
Drone flight control,https://lens.org/157-448-112-053-844,2019,A drone system and method. Audio signals are received via one or more microphones positioned relative to a location on a drone and one or more of the audio signals are identified as of interest. Flight characteristics of the drone are then controlled based on the audio signals that are of interest.
Autonomous Multifunctional Aerial Drone,https://lens.org/086-222-977-153-451,2022,"An apparatus and methods are provided for an unmanned aerial vehicle that uses artificial intelligence for performing desired tasks without operator intervention. The unmanned aerial vehicle comprises a multi-rotor UAV for aerial navigation and includes internal circuitry that supports an artificial intelligence for using collected data to autonomously perform multiple functions. Cameras, sensors, and speakers coupled with the multi-rotor UAV are configured to provide collected data to the artificial intelligence. The artificial intelligence uses the cameras and sensors to avoid colliding with objects in front of the UAV, route flight paths of the UAV to destination locations based on GPS and GLONASS technology, and change flight paths of the UAV in real-time based on detected obstacles. The artificial intelligence is configured to communicate with other UAVs so as to cooperate and coordinate tasks with the other UAVs."
"Drone control system, method, and program",https://lens.org/148-679-634-771-933,2020,"A drone control system in which a drone can move to a position where a purpose can be achieved and performs an action according to the purpose is provided. The drone control system 1 controls a drone 10 capable of performing a predetermined action on a predetermined object, and includes a state data acquiring module 201 that acquires state data indicating a state of the object, a purpose data acquiring module 202 that acquires purpose data which is a purpose of moving the drone, and a detecting module 203 that detects an action point, which is position information at which an action for the purpose is executed, based on the acquired state data and purpose data."
"DRONE CONTROL SYSTEM, METHOD, AND PROGRAM",https://lens.org/042-433-404-676-910,2019,"A drone control system in which a drone can move to a position where a purpose can be achieved and performs an action according to the purpose is provided. The drone control system 1 controls a drone 10 capable of performing a predetermined action on a predetermined object, and includes a state data acquiring module 201 that acquires state data indicating a state of the object, a purpose data acquiring module 202 that acquires purpose data which is a purpose of moving the drone, and a detecting module 203 that detects an action point, which is position information at which an action for the purpose is executed, based on the acquired state data and purpose data."
MULTIFUNCTION DISINFECTION DRONE APPARATUS AND METHOD,https://lens.org/196-075-301-170-164,2021,"An autonomous drone operated remotely via wireless networks is instructed by its owner flying about in an unoccupied room to activate a system of selectable air and surface disinfection modules. An air purifier captures particles in ambient air and switches on an oscillating motion tubular shaped cage mounted with a plurality of Ultraviolet C spectrum, long range zoom and focusable lens LED projectors to disinfect virus and bacteria. A fan assisted forced air Ozone generator module speeds up disinfecting inconspicuous spots to destroy hidden viruses. Disinfection is completed after the half-life time of dispensed Ozone and an oxygen recovery module rapidly converts residual ozone still in air back to normal oxygen molecules enabling a shortened waiting time for occupants to return to the treated room. A negative ions module subsequently switches on to refresh the air."
ROTORCRAFT LANDING DEVICE,https://lens.org/094-529-271-777-197,2018,"A drone loaded with a package takes off from a takeoff device and uses a GPS system to fly to a user house that is a delivery destination of the package as the destination. Further, when the drone approaches the user house that is the destination, the flight of the drones is switched from autonomous navigation using the GPS system to remote control performed by a landing device and an in-house control device installed in the user house. The drone lands on the landing device by remote control from the landing device and the in-house control device, separates the package, and then returns to the warehouse using the GPS system and lands on the takeoff device."
Rotorcraft landing device,https://lens.org/068-518-289-560-491,2020,"A drone loaded with a package takes off from a takeoff device and uses a GPS system to fly to a user house that is a delivery destination of the package as the destination. Further, when the drone approaches the user house that is the destination, the flight of the drones is switched from autonomous navigation using the GPS system to remote control performed by a landing device and an in-house control device installed in the user house. The drone lands on the landing device by remote control from the landing device and the in-house control device, separates the package, and then returns to the warehouse using the GPS system and lands on the takeoff device."
ROTORCRAFT LANDING DEVICE,https://lens.org/111-630-009-507-942,2021,"A drone loaded with a package takes off from a takeoff device and uses a GPS system to fly to a user house that is a delivery destination of the package as the destination. Further, when the drone approaches the user house that is the destination, the flight of the drones is switched from autonomous navigation using the GPS system to remote control performed by a landing device and an in-house control device installed in the user house. The drone lands on the landing device by remote control from the landing device and the in-house control device, separates the package, and then returns to the warehouse using the GPS system and lands on the takeoff device."
Rotorcraft landing device,https://lens.org/095-294-459-912-461,2023,"A drone loaded with a package takes off from a takeoff device and uses a GPS system to fly to a user house that is a delivery destination of the package as the destination. Further, when the drone approaches the user house that is the destination, the flight of the drones is switched from autonomous navigation using the GPS system to remote control performed by a landing device and an in-house control device installed in the user house. The drone lands on the landing device by remote control from the landing device and the in-house control device, separates the package, and then returns to the warehouse using the GPS system and lands on the takeoff device."
SYSTEMS AND METHODS FOR CHANNEL BASED DRONE OPERATION,https://lens.org/179-025-478-245-369,2023,"A method for operating one or more drones including providing at least one user with one or more drone options for viewing corresponding drone video and receiving a drone selection from the at least one user. Video from the selected drone can be streamed to a display device associated with the at least one user. The method can include indicating to the at least one user that the selected drone is available for user control and providing the at least one user with one or more control options including one or more predefined flight path options available for the selected drone. The method can include receiving a control option selection from the one or more control options and upon receiving a flight path option selection, directing the drone to follow the selected flight path."
AUTONOMOUS MULTIFUNCTIONAL AERIAL DRONE,https://lens.org/088-274-523-290-539,2022,"An apparatus and methods are provided for an unmanned aerial vehicle that uses artificial intelligence for performing desired tasks without operator intervention, The unmanned aerial vehicle comprises a multi-rotor UAV for aerial navigation and includes internal circuitry that supports an artificial intelligence for using collected data to autonomously perform multiple functions. Cameras, sensors, and speakers coupled with the multi-rotor UAV are configured to provide collected data to the artificial intelligence. The artificial intelligence uses the cameras and sensors to avoid colliding with objects in front of the UAV, route flight paths of the UAV to destination locations based on GPS and GLONASS technology, and change flight paths of the UAV in real-time based on detected obstacles. The artificial intelligence is configured to communicate with other UAVs so as to cooperate and coordinate tasks with the other UAVs."
SYSTEMS AND METHODS FOR TRANSFERRING CONTROL OF AN UNMANNED AERIAL VEHICLE,https://lens.org/062-687-454-604-494,2020,"Systems and methods for transferring control of drones from one computing device to another during flight are disclosed. An example method may include accepting, by a drone control module of a computing device, a destination associated with a user. The method may further include establishing, by the drone control module, a channel of communication with a user device of the user. Thereafter, the drone control module may launch the drone from a first location. The method may further include transmitting, by the drone control module, control data for the drone to the user device via the channel of communication. The method may continue with transferring, by the drone control module, an operational control of the drone to the user device."
Systems and methods for transferring control of an unmanned aerial vehicle,https://lens.org/126-545-160-903-532,2020,"Systems and methods for transferring control of drones from one computing device to another during flight are disclosed. An example method may include accepting, by a drone control module of a computing device, a destination associated with a user. The method may further include establishing, by the drone control module, a channel of communication with a user device of the user. Thereafter, the drone control module may launch the drone from a first location. The method may further include transmitting, by the drone control module, control data for the drone to the user device via the channel of communication. The method may continue with transferring, by the drone control module, an operational control of the drone to the user device."
Apparatus and method for network based operation of an unmanned aerial vehicle,https://lens.org/082-653-423-597-295,2020,"Embodiment includes of a method and a system of network based operation of an unmanned aerial vehicle is disclosed. One system includes a drone user machine, a drone control machine, and a drone control console. The drone control machine is interfaced with the drone user machine through a network, and the drone control machine is interfaced with a drone through the drone control console. The drone control machine operates to receive user commands from the drone user machine through the network, generate drone control commands which are provided to the drone control console for controlling the drone, wherein the drone control commands are generated based on the user commands, receive video from the drone control console that was generated by a camera located on the drone, and communicate the video to the drone user machine over the network, wherein the video is displayed on a display associated with the drone user machine."
APPARATUS AND METHOD FOR NETWORK BASED OPERATION OF AN UNMANNED AERIAL VEHICLE,https://lens.org/039-875-988-141-433,2019,"Embodiment includes of a method and a system of network based operation of an unmanned aerial vehicle is disclosed. One system includes a drone user machine, a drone control machine, and a drone control console. The drone control machine is interfaced with the drone user machine through a network, and the drone control machine is interfaced with a drone through the drone control console. The drone control machine operates to receive user commands from the drone user machine through the network, generate drone control commands which are provided to the drone control console for controlling the drone, wherein the drone control commands are generated based on the user commands, receive video from the drone control console that was generated by a camera located on the drone, and communicate the video to the drone user machine over the network, wherein the video is displayed on a display associated with the drone user machine."
Apparatus and method for network based operation of an unmanned aerial vehicle,https://lens.org/082-653-423-597-295,2020,"Embodiment includes of a method and a system of network based operation of an unmanned aerial vehicle is disclosed. One system includes a drone user machine, a drone control machine, and a drone control console. The drone control machine is interfaced with the drone user machine through a network, and the drone control machine is interfaced with a drone through the drone control console. The drone control machine operates to receive user commands from the drone user machine through the network, generate drone control commands which are provided to the drone control console for controlling the drone, wherein the drone control commands are generated based on the user commands, receive video from the drone control console that was generated by a camera located on the drone, and communicate the video to the drone user machine over the network, wherein the video is displayed on a display associated with the drone user machine."
Apparatus and method for network based operation of an unmanned aerial vehicle,https://lens.org/054-049-926-171-046,2021,"Embodiment includes of a method and a system of network based operation of an unmanned aerial vehicle is disclosed. One system includes a drone user machine, a drone control machine, and a drone control console. The drone control machine is interfaced with the drone user machine through a network, and the drone control machine is interfaced with a drone through the drone control console. The drone control machine operates to receive user commands from the drone user machine through the network, generate drone control commands which are provided to the drone control console for controlling the drone, wherein the drone control commands are generated based on the user commands, receive video from the drone control console that was generated by a camera located on the drone, and communicate the video to the drone user machine over the network, wherein the video is displayed on a display associated with the drone user machine."
APPARATUS AND METHOD FOR NETWORK BASED OPERATION OF AN UNMANNED AERIAL VEHICLE,https://lens.org/142-323-522-952-814,2020,"Embodiment includes of a method and a system of network based operation of an unmanned aerial vehicle is disclosed. One system includes a drone user machine, a drone control machine, and a drone control console. The drone control machine is interfaced with the drone user machine through a network, and the drone control machine is interfaced with a drone through the drone control console. The drone control machine operates to receive user commands from the drone user machine through the network, generate drone control commands which are provided to the drone control console for controlling the drone, wherein the drone control commands are generated based on the user commands, receive video from the drone control console that was generated by a camera located on the drone, and communicate the video to the drone user machine over the network, wherein the video is displayed on a display associated with the drone user machine."
Unmanned aerial vehicles,https://lens.org/019-149-188-677-617,2018,"A UAV 100 has a camera 105 in an upward facing direction, a controller 120 and an actuator 125. The UAV 100 operates in an autonomous mode, where the controller 120 receives data from the upwards facing camera 105, receives data from an object within the field of view of the camera 105 via a communication channel between the UAV 100 and the object, and controls the actuator 125 during the autonomous procedure based on this. The field of view of the camera 105 includes airspace 115 directly above the UAV 100 during the autonomous procedure. The control may involve avoiding collision with the object, or approach or make contact with the object. The control may be an alert."
MOBILE PREMISES AUTOMATION PLATFORM,https://lens.org/048-611-322-900-031,2017,"A system including a drone or unmanned vehicle configured to perform surveillance of a premises. The drone surveillance includes autonomous navigation and/or remote or optional piloting around the premises. The drone includes a controller coupled to a plurality of sensors configured to collect drone data and security data at the premises, wherein the controller is configured to generate control data for the drone and the premises using the drone data and the security data. A remote device coupled to the drone includes a user interface configured to present the drone data, the security data, and/or the control data."
MOBILE PREMISES AUTOMATION PLATFORM,https://lens.org/186-758-164-585-020,2022,"A system including a drone or unmanned vehicle configured to perform surveillance of a premises. The drone surveillance includes autonomous navigation and/or remote or optional piloting around the premises. The drone includes a controller coupled to a plurality of sensors configured to collect drone data and security data at the premises, wherein the controller is configured to generate control data for the drone and the premises using the drone data and the security data. A remote device coupled to the drone includes a user interface configured to present the drone data, the security data, and/or the control data."
MOBILE PREMISES AUTOMATION PLATFORM,https://lens.org/186-758-164-585-020,2022,"A system including a drone or unmanned vehicle configured to perform surveillance of a premises. The drone surveillance includes autonomous navigation and/or remote or optional piloting around the premises. The drone includes a controller coupled to a plurality of sensors configured to collect drone data and security data at the premises, wherein the controller is configured to generate control data for the drone and the premises using the drone data and the security data. A remote device coupled to the drone includes a user interface configured to present the drone data, the security data, and/or the control data."
Lighting apparatus for remote controlled device,https://lens.org/042-444-950-523-739,2022,"There is a remote control device or drone, which has software and a combination of lights or LED on an lighting ring or apparatus that can move independently of the drone; the drone can be programmed or be reactive to sound or other stimulus to create the effect of writing shapes or words in the air and typically at nighttime against a dark sky."
LIGHTING APPARATUS FOR REMOTE CONTROLLED DEVICE,https://lens.org/094-269-699-410-558,2023,"There is a remote control device or drone, which has software and a combination of lights or LED on an lighting ring or apparatus that can move independently of the drone; the drone can be programmed or be reactive to sound or other stimulus to create the effect of writing shapes or words in the air and typically at nighttime against a dark sky."
Lighting apparatus for remote controlled device,https://lens.org/042-444-950-523-739,2022,"There is a remote control device or drone, which has software and a combination of lights or LED on an lighting ring or apparatus that can move independently of the drone; the drone can be programmed or be reactive to sound or other stimulus to create the effect of writing shapes or words in the air and typically at nighttime against a dark sky."
LIGHTING APPARATUS FOR REMOTE CONTROLLED DEVICE,https://lens.org/094-269-699-410-558,2023,"There is a remote control device or drone, which has software and a combination of lights or LED on an lighting ring or apparatus that can move independently of the drone; the drone can be programmed or be reactive to sound or other stimulus to create the effect of writing shapes or words in the air and typically at nighttime against a dark sky."
Lighting apparatus for remote controlled device,https://lens.org/160-233-840-229-65X,2019,"There is a remote control device or drone, which has software and a combination of lights or LED on an lighting ring or apparatus that can move independently of the drone; the drone can be programmed or be reactive to sound or other stimulus to create the effect of writing shapes or words in the air and typically at nighttime against a dark sky."
Speech interaction for unmanned aerial vehicles,https://lens.org/138-014-754-235-896,2017,"An unmanned aerial vehicle (UAV) may be used for delivering products or other articles. The UAV is configured to detect the presence of nearby people, animals, or other interactive objects. Upon detecting a nearby object, the UAV may produce speech in order to warn or instruct the object. The UAV may also have speech input capabilities in order to capture and respond to speech from the object. The UAV may conduct a speech dialog with a nearby person in order to request information and/or answer questions from the object. In certain situations, the UAV may detect whether an object is in the way of a desired landing area and may communicate with the object through speech to ask the object to move or to ask the object to specify an alternative landing area."
UNMANNED AERIAL VEHICLE INTEGRATION WITH HOME AUTOMATION SYSTEMS,https://lens.org/124-995-826-753-944,2017,"Various arrangements are provided for using an unmanned aerial vehicle with a home automation system. The home automation host system may determine that a home automation event has occurred. The system may determine to perform unmanned aerial vehicle (UAV) surveillance of the home in response to the home automation event. Deployment of a UAV may be triggered in response to determining to perform the UAV surveillance of the home. Video may then captured by the UAV of a portion of the home, possibly corresponding to the location of the home automation event. The video captured by the UAV of the portion of the home in association with an indication of the home automation event that triggered deployment of the UAV may be recorded."
UNMANNED AERIAL VEHICLE INTEGRATION WITH HOME AUTOMATION SYSTEMS,https://lens.org/145-379-455-485-532,2017,"Various arrangements are provided for using an unmanned aerial vehicle with a home automation system. The home automation host system may determine that a home automation event has occurred. The system may determine to perform unmanned aerial vehicle (UAV) surveillance of the home in response to the home automation event. Deployment of a UAV may be triggered in response to determining to perform the UAV surveillance of the home. Video may then captured by the UAV of a portion of the home, possibly corresponding to the location of the home automation event. The video captured by the UAV of the portion of the home in association with an indication of the home automation event that triggered deployment of the UAV may be recorded."
LAW ENFORCEMENT DRONE,https://lens.org/003-442-422-038-306,2018,"A law enforcement drone system is provided. The system features an unmanned aerial vehicle, having a wireless transceiver, an airframe, a propulsion system, a navigation mechanism, a processor, a memory, a power source, and at least one fuel tank. The system also features a control system having a wireless transceiver, an input device, capable of receiving a user's input and converting the user's input to electrical signals, a processor, and a memory. The control system is in wireless communication with the vehicle such that the control system is capable of utilizing the propulsion system in substantially real-time."
"Drone piloted in a spherical coordinate system by a gestural with multi-segment members, control method and associated computer program",https://lens.org/024-777-962-037-677,2018,"An electronic device for piloting a drone comprises an acquisition module to acquire a series of images of a scene including a user, taken by an image sensor equipping the drone, an electronic detection module for detecting, in the series of acquired images, a gesture by the user, and a control module for controlling a movement of the drone based on the detected gesture. The detection module is configured to detect a gesture with at least two separate limb segments of the user, and the electronic control module is configured to control the movement of the drone in a spherical coordinate system associated with the user, by calculating piloting instructions in the spherical coordinate system based on the detected gesture with several limb segments."
Electronic device and method for controlling unmanned aerial vehicle using the same,https://lens.org/137-851-914-132-872,2013,"A method for controlling an unmanned aerial vehicle (UAV) using an electronic device obtains movement data of an object on a display screen of the electronic device, and converts the movement data of the object into control signals. The method further sends the control signals to the UAV, and changes a flight status of the UAV according to the control signals."
ELECTRONIC DEVICE AND METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE USING THE SAME,https://lens.org/054-744-996-229-834,2012,"A method for controlling an unmanned aerial vehicle (UAV) using an electronic device obtains movement data of an object on a display screen of the electronic device, and converts the movement data of the object into control signals. The method further sends the control signals to the UAV, and changes a flight status of the UAV according to the control signals."
Controlling a drone through user movement,https://lens.org/009-740-144-913-062,2020,"A computer system for mapping the movement of a user to the controls of a drone generates, with a mixed-reality device, a simultaneous localization and mapping coordinate system of a user environment. The system then receives, from sensors within the mixed-reality device, a movement variable that comprises an indication that the user has moved a first distance in a particular direction with respect to the simultaneous localization and mapping coordinate system. The system communicates, to the drone, a movement command to move a second distance and particular direction based upon information within the movement variable."
CONTROLLING A DRONE THROUGH USER MOVEMENT,https://lens.org/018-174-033-971-975,2019,"A computer system for mapping the movement of a user to the controls of a drone generates, with a mixed-reality device, a simultaneous localization and mapping coordinate system of a user environment. The system then receives, from sensors within the mixed-reality device, a movement variable that comprises an indication that the user has moved a first distance in a particular direction with respect to the simultaneous localization and mapping coordinate system. The system communicates, to the drone, a movement command to move a second distance and particular direction based upon information within the movement variable."
UNMANNED HELICOPTER,https://lens.org/024-242-880-629-723,2009,"GPS devices (GPS receivers and corresponding GPS antennas) for detecting a location of an airframe are provided. An autonomous control section (e.g., an autonomous control box) including a data communication device for communicating with the ground and a control board having a built-in control program is provided. An unmanned helicopter flies depending on airframe data such as an attitude and a speed of the airframe, engine speed, and a throttle angle and flight data such as a location and a direction of the airframe. The autonomous control section is provided with a plurality of different type of GPS devices."
BIG DATA-BASED AUTONOMOUS FLIGHT DRONE SYSTEM AND AUTONOMOUS FLIGHT METHOD THEREFOR,https://lens.org/143-769-625-160-02X,2021,"There is provided is a big data-based autonomous flight drone system according to an exemplary embodiment of the present invention, which includes: a smart drone; a ground control system generating a remote control command for flight control of the smart drone; a drone IoT server which operates as a relay server for a communication connection between the smart drone and the ground control system, receives the remote control command from the ground control system so as to transfer the remote control command to the smart drone, and receives drone flight information and a camera image from the smart drone so as to transfer the drone flight information and the camera image to the ground control system; and an AI big data server which receives destination information and the drone flight information inputted in the ground control system, and generates a plurality of flight routes according to a preset criterion by interlocking with a database storing spatial information big data based on the destination information and the drone flight information, and provides the plurality of flight routes to the ground control system."
"Light emission control apparatus, drone, and method for controlling emission of light",https://lens.org/172-759-941-150-766,2020,"A drone includes a light emitter that emits light and circuitry which, in operation, obtains flight state information regarding a flight state of the drone, determines, on the basis of the flight state information, a direction in which the light emitter is to emit light, and controls the light emitter such that the light emitter emits light in the determined direction."
"Light emission control apparatus, drone, and method for controlling emission of light",https://lens.org/043-574-916-928-902,2022,"A drone includes a light emitter that emits light and circuitry which, in operation, obtains flight state information regarding a flight state of the drone, determines, on the basis of the flight state information, a direction in which the light emitter is to emit light, and controls the light emitter such that the light emitter emits light in the determined direction."
"LIGHT EMISSION CONTROL APPARATUS, DRONE, AND METHOD FOR CONTROLLING EMISSION OF LIGHT",https://lens.org/199-988-806-388-463,2017,"A drone includes a light emitter that emits light and circuitry which, in operation, obtains flight state information regarding a flight state of the drone, determines, on the basis of the flight state information, a direction in which the light emitter is to emit light, and controls the light emitter such that the light emitter emits light in the determined direction."
"CONTROL METHOD, CONTROL SYSTEM, AND SMART GLASSES FOR FIRST PERSON VIEW UNMANNED AERIAL VEHICLE FLIGHT",https://lens.org/044-348-011-140-281,2019,"A system for controlling an unmanned aerial vehicle (UAV) includes smart glasses and a remote controller. The smart glasses are configured to establish a first channel directly with the UAV, receive first person view (FPV) image data directly from the UAV through the first channel, and display the FPV image data. The remote controller is configured to establish a second channel directly with the UAV, and send a flight control instruction directly to the UAV through the second channel."
"Control method, control system, and smart glasses for first person view unmanned aerial vehicle flight",https://lens.org/155-725-626-443-639,2022,"A system for controlling an unmanned aerial vehicle (UAV) includes smart glasses and a remote controller. The smart glasses are configured to establish a first channel directly with the UAV, receive first person view (FPV) image data directly from the UAV through the first channel, and display the FPV image data. The remote controller is configured to establish a second channel directly with the UAV, and send a flight control instruction directly to the UAV through the second channel."
System and method to operate a drone,https://lens.org/073-391-109-628-299,2019,"A method for controlling a drone includes receiving a request for information about a spatial location, generating data requests, configuring a flight plan and controlling one or more drones to fly over the spatial location to obtain data types based on the data requests, and extracting and analyzing data to answer the request. The method can include extracting data points from the data types, obtaining labels from a user for one or more of the data points, predicting labels for unlabeled data points from a learning algorithm using the labels obtained from the user, determining the predicted labels are true labels for the unlabeled data points and combining the extracted data, the user labeled data points and the true labeled data points to answer the request for information. The learning algorithm may be active learning using a support vector machine."
SYSTEM AND METHOD TO OPERATE A DRONE,https://lens.org/057-644-193-040-57X,2019,"A method for controlling a drone includes receiving a request for information about a spatial location, generating data requests, configuring a flight plan and controlling one or more drones to fly over the spatial location to obtain data types based on the data requests, and extracting and analyzing data to answer the request. The method can include extracting data points from the data types, obtaining labels from a user for one or more of the data points, predicting labels for unlabeled data points from a learning algorithm using the labels obtained from the user, determining the predicted labels are true labels for the unlabeled data points and combining the extracted data, the user labeled data points and the true labeled data points to answer the request for information. The learning algorithm may be active learning using a support vector machine."
SYSTEM AND METHOD TO OPERATE A DRONE,https://lens.org/120-462-692-199-142,2019,"A method for controlling a drone includes receiving a request for information about a spatial location, generating data requests, configuring a flight plan and controlling one or more drones to fly over the spatial location to obtain data types based on the data requests, and extracting and analyzing data to answer the request. The method can include extracting data points from the data types, obtaining labels from a user for one or more of the data points, predicting labels for unlabeled data points from a learning algorithm using the labels obtained from the user, determining the predicted labels are true labels for the unlabeled data points and combining the extracted data, the user labeled data points and the true labeled data points to answer the request for information. The learning algorithm may be active learning using a support vector machine."
System and method to operate a drone,https://lens.org/030-836-777-170-569,2020,"A method for controlling a drone includes receiving a request for information about a spatial location, generating data requests, configuring a flight plan and controlling one or more drones to fly over the spatial location to obtain data types based on the data requests, and extracting and analyzing data to answer the request. The method can include extracting data points from the data types, obtaining labels from a user for one or more of the data points, predicting labels for unlabeled data points from a learning algorithm using the labels obtained from the user, determining the predicted labels are true labels for the unlabeled data points and combining the extracted data, the user labeled data points and the true labeled data points to answer the request for information. The learning algorithm may be active learning using a support vector machine."
HANDICAP ACCESSIBILITY ASSISTANCE DEVICE,https://lens.org/084-029-283-742-940,2023,"A handicap accessibility assistance device includes a drone. The drone has a wedge mechanism at a first end. A controller is configured to cause the drone to approach a door, wedge the wedge mechanism under the door, shift the drone to an opening end of the door, and push the door open."
DEVICE AND METHOD FOR AUTONOMOUS MANAGEMENT OF A DRONE,https://lens.org/178-206-129-952-459,2022,"An intelligent device for autonomous navigation of a drone comprising a control unit arranged to communicate with a remote-control station by a wireless connection, acquire a mission route  that the drone is arranged to follow to reach a desired destination, the mission route  being defined by means of coordinates xm(t), ym(t), zm(t) with respect to a reference system S(x, y, z), periodically acquire values xa, ya, za corresponding to the components of the spatial position, values vx, vy, vz corresponding to the components of the speed and values ax, ay, az corresponding to the components of the acceleration. Furthermore, in the event that at least one predetermined kinematic condition occurs, the control unit is arranged to check the status of the wireless connection with the remote-control station and, in the event that the wireless connection is active, send an alarm signal to the remote- control station and wait a response time tr . in the event that the wireless connection is not active or that there is no response by the remote- control station within the response time tr, the control unit is arranged to activate an emergency navigation mode."
DEVICE AND METHOD FOR AUTONOMOUS MANAGEMENT OF A DRONE,https://lens.org/178-206-129-952-459,2022,"An intelligent device for autonomous navigation of a drone comprising a control unit arranged to communicate with a remote-control station by a wireless connection, acquire a mission route  that the drone is arranged to follow to reach a desired destination, the mission route  being defined by means of coordinates xm(t), ym(t), zm(t) with respect to a reference system S(x, y, z), periodically acquire values xa, ya, za corresponding to the components of the spatial position, values vx, vy, vz corresponding to the components of the speed and values ax, ay, az corresponding to the components of the acceleration. Furthermore, in the event that at least one predetermined kinematic condition occurs, the control unit is arranged to check the status of the wireless connection with the remote-control station and, in the event that the wireless connection is active, send an alarm signal to the remote- control station and wait a response time tr . in the event that the wireless connection is not active or that there is no response by the remote- control station within the response time tr, the control unit is arranged to activate an emergency navigation mode."
"DRONE SYSTEM, DRONE, MOVABLE BODY, DEMARCATING MEMBER, CONTROL METHOD FOR DRONE SYSTEM, AND DRONE SYSTEM CONTROL PROGRAM",https://lens.org/015-899-779-006-038,2022,"There is provided a drone system in which a drone and a movable body operate in coordination with each other, the movable body being capable of moving with the drone aboard and allowing the drone to make a takeoff and a landing, the drone system includes a demarcating member that demarcates an operation area and detects an intruder into the operation area, the operation area being an area where at least one of the drone and the movable body performs an operation, the movable body includes a movement control section that stops movement of the movable body based on the detection of the intruder by the demarcating member, and the drone includes a landing position determining section that determines a landing position based on a stop position of the movable body."
Personal drone assistant,https://lens.org/166-416-003-584-769,2022,"An aerial drone system configured to serve as personal drone assistance is disclosed. The drone assistant is configured to follow the user and provide (1) audiovisual output including video, audio, and navigation, (2) environmental comfort including shade, light, misters for the benefit of the user, as well as (3) privacy and security. To provide audiovisual output, the drone is configured to track the user and maintain a constant height and distance relative to the user, preferably a few feet away in front of the user. To provide environmental comfort including shade, for example, the drone is configured to automatically maintain a position between the user and the sun, thus causing a shadow to be continually cast on the user. This shading is enhanced by specialized louvres and screens configured to prevent any direct sunlight from directly impinging on the user."
Personal drone assistant,https://lens.org/166-416-003-584-769,2022,"An aerial drone system configured to serve as personal drone assistance is disclosed. The drone assistant is configured to follow the user and provide (1) audiovisual output including video, audio, and navigation, (2) environmental comfort including shade, light, misters for the benefit of the user, as well as (3) privacy and security. To provide audiovisual output, the drone is configured to track the user and maintain a constant height and distance relative to the user, preferably a few feet away in front of the user. To provide environmental comfort including shade, for example, the drone is configured to automatically maintain a position between the user and the sun, thus causing a shadow to be continually cast on the user. This shading is enhanced by specialized louvres and screens configured to prevent any direct sunlight from directly impinging on the user."
Unmanned aerial vehicle guidance and communication device with system and method,https://lens.org/113-251-046-910-24X,2019,A communication device of a communication system to guide unmanned aerial vehicles.
UNMANNED AERIAL VEHICLE GUIDANCE AND COMMUNICATION DEVICE WITH SYSTEM AND METHOD,https://lens.org/003-639-881-945-369,2016,A communication device of a communication system to guide unmanned aerial vehicles.
Unmanned aerial vehicles,https://lens.org/102-804-743-963-759,2018,"A UAV 100 comprises a camera 105, a controller 120 and an actuator 125. The UAV 100 is operable in an autonomous mode in which the controller 120 is arranged to receive data based on image data captured by the camera 105 and to control the actuator 125 during an autonomous procedure to cause physical interaction between the UAV 100 and an object in a field of view of the camera 105 based on the received data. The camera 105 is configurable in an upwards-facing configuration 110 during the autonomous procedure such that the field of view of the camera 105 includes airspace 115 directly above the UAV 100 during the autonomous procedure."
ELECTRONIC DEVICE AND METHOD FOR CONTROLLING MULTIPLE DRONES,https://lens.org/023-872-787-918-061,2019,"Various embodiments of the present invention provide a drone comprising a communication module for wirelessly communicating with an external drone, and a processor configured to: when the distance from the external drone is greater than or equal to a first distance and is less than a second distance, control the position of the drone by using GPS information of the external drone, received through the communication module, and a sensor included in the drone; and when the distance from the external drone is greater than or equal to the second distance, control the position of the drone by using the GPS information."
Electronic device and method for controlling unmanned aerial vehicle using the same,https://lens.org/164-479-603-289-814,2014,"A method for controlling an unmanned aerial vehicle (UAV) using an electronic device obtains movement data of the electronic device detected by an accelerometer of the electronic device, and converts the movement data of the electronic device to control signals. The method further sends the control signals to the UAV, and changes a flight status of the UAV according to the control signals."
ELECTRONIC DEVICE AND METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE USING THE SAME,https://lens.org/069-765-381-752-300,2012,"A method for controlling an unmanned aerial vehicle (UAV) using an electronic device obtains movement data of the electronic device detected by an accelerometer of the electronic device, and converts the movement data of the electronic device to control signals. The method further sends the control signals to the UAV, and changes a flight status of the UAV according to the control signals."
DRONE SECURITY AND ENTERTAINMENT SYSTEM,https://lens.org/027-959-136-895-545,2018,"A method of operating a drone security and entertainment system includes: engaging a drone with a base; receiving signals from at least one sensor remote from the drone vehicle and base; detecting activity; disengaging the drone vehicle from the base; traveling by the drone vehicle; collecting, by the drone vehicle, data including at least one of video, audio, and sensor data; and transmitting, by the drone, the collected data. A security system includes: a base configured to house and charge a drone vehicle; a drone vehicle configured to engage with the base; and at least one sensor in electrical communication with the drone vehicle, wherein the drone is configured for: receiving signals from the at least one sensor; detecting activity; disengaging from the base; traveling; collecting data including at least one of video, audio, and sensor data; and transmitting the collected data."
MOBILE DEVICE ENABLED ROBOTIC SYSTEM,https://lens.org/187-578-012-168-314,2017,"An unmanned aerial vehicle (UAV) equipped with sensor modules and mobile devices (including smartphone, tablet) running intelligent software for autonomous navigation, onboard computer vision, communication, and robotic social networks, is disclosed herein."
MOBILE DEVICE ENABLED ROBOTIC SYSTEM,https://lens.org/102-971-974-125-072,2020,"An unmanned aerial vehicle (UAV) equipped with sensor modules and mobile devices (including smartphone, tablet) running intelligent software for autonomous navigation, onboard computer vision, communication, and robotic social networks, is disclosed herein."
Mobile device enabled robotic system,https://lens.org/073-187-590-399-593,2018,"An unmanned aerial vehicle (UAV) equipped with sensor modules and mobile devices (including smartphone, tablet) running intelligent software for autonomous navigation, onboard computer vision, communication, and robotic social networks, is disclosed herein."
MOBILE DEVICE ENABLED ROBOTIC SYSTEM,https://lens.org/092-162-569-525-194,2018,"An unmanned aerial vehicle (UAV) equipped with sensor modules and mobile devices (including smartphone, tablet) running intelligent software for autonomous navigation, onboard computer vision, communication, and robotic social networks, is disclosed herein."
"Data processing device, drone, and control device, method, and processing program therefor",https://lens.org/004-963-056-829-027,2022,"Provided is a technique for controlling an unmanned aerial vehicle in flight according to a battery level. A drone control device controls a drone according to a battery level, including: a flight distance calculation unit, calculating a flight distance according to an airframe position at any time point and a landing place of the drone; a battery status acquisition unit, acquiring the battery level of the drone; an estimated battery consumption calculation unit, calculating an estimated battery consumption when the drone flies over the flight distance calculated by the flight distance calculation unit; and a return decision unit, deciding, on the basis of the battery level of the drone and the estimated battery consumption, whether the drone is capable of flying over the flight distance and return."
"DATA PROCESSING DEVICE, DRONE, AND CONTROL DEVICE, METHOD, AND PROCESSING PROGRAM THEREFOR",https://lens.org/162-024-920-135-073,2019,"Provided is a technique for controlling an unmanned aerial vehicle in flight according to a battery level. A drone control device controls a drone according to a battery level, including: a flight distance calculation unit, calculating a flight distance according to an airframe position at any time point and a landing place of the drone; a battery status acquisition unit, acquiring the battery level of the drone; an estimated battery consumption calculation unit, calculating an estimated battery consumption when the drone flies over the flight distance calculated by the flight distance calculation unit; and a return decision unit, deciding, on the basis of the battery level of the drone and the estimated battery consumption, whether the drone is capable of flying over the flight distance and return."
DIRECTION ADJUSTABLE DRONE ACCESSORY,https://lens.org/007-249-998-264-032,2022,"The invention relates to a drone accessory and a method of controlling the drone accessory. The drone accessory comprising at least one camera being configured to capturing images of a directional-adjustable camera of a drone and transmitting the images to the processor, determining a viewing direction of the directional-adjustable camera of the drone, and directing a directional-adjustable device in the determined viewing direction."
DIRECTION ADJUSTABLE DRONE ACCESSORY,https://lens.org/007-249-998-264-032,2022,"The invention relates to a drone accessory and a method of controlling the drone accessory. The drone accessory comprising at least one camera being configured to capturing images of a directional-adjustable camera of a drone and transmitting the images to the processor, determining a viewing direction of the directional-adjustable camera of the drone, and directing a directional-adjustable device in the determined viewing direction."
DIRECTION ADJUSTABLE DRONE ACCESSORY,https://lens.org/007-249-998-264-032,2022,"The invention relates to a drone accessory and a method of controlling the drone accessory. The drone accessory comprising at least one camera being configured to capturing images of a directional-adjustable camera of a drone and transmitting the images to the processor, determining a viewing direction of the directional-adjustable camera of the drone, and directing a directional-adjustable device in the determined viewing direction."
Drone for inspection of enclosed space and method thereof,https://lens.org/188-631-221-876-946,2014,Embodiments of a drone for inspection and a method of use are depicted wherein the drone is utilized in an enclosed space and is capable of being controlled with or without line of sight to the aircraft. The drone may land on generally horizontal or vertical surfaces. A method of use is taught as well.
Drone for inspection of enclosed space and method thereof,https://lens.org/192-269-924-338-891,2016,Embodiments of a drone for inspection and a method of use are depicted wherein the drone is utilized in an enclosed space and is capable of being controlled with or without line of sight to the aircraft. The drone may hover or land on surfaces within the enclosed space for the inspection.
METHOD FOR FLIGHT CONTROL BY HOW A DEVICE IS THROWN,https://lens.org/071-971-581-366-163,2018,"An autonomous or semi-autonomous device or vehicle, such as a drone, and method for controlling the same, the method including sensing a physical manipulation or an aspect of a physical manipulation of the autonomous or semi-autonomous device or vehicle, selecting an action and/or modifying an aspect of the action according to the sensed physical manipulation or physical manipulation aspect, and instructing the autonomous or semi-autonomous device or vehicle to perform the action."
METHOD FOR FLIGHT CONTROL BY HOW A DEVICE IS THROWN,https://lens.org/005-437-088-110-638,2018,"An autonomous or semi-autonomous device or vehicle, such as a drone, and method for controlling the same, the method including sensing a physical manipulation or an aspect of a physical manipulation of the autonomous or semi-autonomous device or vehicle, selecting an action and/or modifying an aspect of the action according to the sensed physical manipulation or physical manipulation aspect, and instructing the autonomous or semi-autonomous device or vehicle to perform the action."
USER ASSISTANCE DRONE DEVICE,https://lens.org/062-398-192-536-32X,2021,"The user assistance drone device is an unmanned aerial vehicle used as a communication device. The user assistance drone device tracks the client while the user assistance drone device is in the air. The user assistance drone device follows the client and forms an audio communication link between the client and an appropriate authority. The audio communication link allows the client to speak with an appropriate authority. The user assistance drone device comprises the unmanned aerial vehicle and a master circuit. The unmanned aerial vehicle is a device capable of travel through the atmosphere. The master circuit: a) tracks the location and the movement of the client; b) transmits flight instructions to the unmanned aerial vehicle that allows the unmanned aerial vehicle to follow the client; and, c) establishes the audio communication link between the client and the appropriate authority."
SECURITY DRONE SYSTEM,https://lens.org/036-735-534-316-848,2019,"A security drone includes a drone housing defining a cavity and an actuator coupled to the drone housing and designed to move the drone housing through the predetermined area. The security drone further includes a camera designed to detect image data corresponding to the predetermined area and a network access device designed to transmit and receive data via a network. The security drone further includes a drone processor positioned within the cavity and coupled to the actuator, the camera, and the network access device. The drone processor is designed to control the actuator to move the drone housing through the predetermined area, identify a potential threat in the predetermined area based on the image data as the drone housing is moved through the predetermined area, and transmit potential threat data corresponding to the potential threat to a remote device when the potential threat is identified."
Waypoint navigation,https://lens.org/172-846-205-601-253,2006,"The invention relates to remote control of an unmanned aerial vehicle, UAV, (100) from a control station (110) by means of a wireless command link (115). The UAV (100) may be controlled in an autonomous mode wherein it flies according to a primary route (R1, R1') defined by a first set of predefined waypoints (WP1-WP8, IP). The UAV (100) may also be controlled in a manual mode wherein it flies according to an alternative primary route (R1') defined in real-time by control commands received via the wireless command link (115). Flight control parameters are monitored in both modes, and in case a major alarm condition occurs, the UAV (100) is controlled to follow an emergency route (R2') defined by a second set of predefined waypoints (HP1-HP7, TP1-TP9, IP). Particularly, a major alarm condition is activated if an engine failure is detected. Then, the emergency route (R2') involves flying the UAV (100) to an air space above a termination waypoint (TP9) on the ground at which it is estimated that the vehicle's (100) flight may be ended without injuring any personnel or causing uncontrolled material damages.
"
Waypoint navigation,https://lens.org/009-978-167-207-507,2004,"The invention relates to remote control of an unmanned aerial vehicle, UAV, (100) from a control station (110) by means of a wireless command link (115). The UAV (100) may be controlled in an autonomous mode wherein it flies according to a primary route (R1, R1') defined by a first set of predefined waypoints (WP1-WP8, IP). The UAV (100) may also be controlled in a manual mode wherein it flies according to an alternative primary route (R1') defined in real-time by control commands received via the wireless command link (115). Flight control parameters are monitored in both modes, and in case a major alarm condition occurs, the UAV (100) is controlled to follow an emergency route (R2') defined by a second set of predefined waypoints (HP1-HP7, TP1-TP9, IP). Particularly, a major alarm condition is activated if an engine failure is detected. Then, the emergency route (R2') involves flying the UAV (100) to an air space above a termination waypoint (TP9) on the ground at which it is estimated that the vehicle's (100) flight may be ended without injuring any personnel or causing uncontrolled material damages."
Direction adjustable drone accessory,https://lens.org/001-016-953-199-681,2022,"The invention relates to a drone accessory and a method of controlling the drone accessory. The drone accessory comprising at least one camera being configured to capturing images of a directional-adjustable camera of a drone and transmitting the images to the processor, determining a viewing direction of the directional- adjustable camera of the drone, and directing a directional-adjustable device in the determined viewing direction."
DIRECTION ADJUSTABLE DRONE ACCESSORY,https://lens.org/065-901-330-990-323,2021,"The invention relates to a drone accessory and a method of controlling the drone accessory. The drone accessory comprising at least one camera being configured to capturing images of a directional-adjustable camera of a drone and transmitting the images to the processor, determining a viewing direction of the directional- adjustable camera of the drone, and directing a directional-adjustable device in the determined viewing direction."
Direction adjustable drone accessory,https://lens.org/001-016-953-199-681,2022,"The invention relates to a drone accessory and a method of controlling the drone accessory. The drone accessory comprising at least one camera being configured to capturing images of a directional-adjustable camera of a drone and transmitting the images to the processor, determining a viewing direction of the directional- adjustable camera of the drone, and directing a directional-adjustable device in the determined viewing direction."
Apparatus and methods for tethered aerial platform and system,https://lens.org/173-242-244-220-014,2016,"A drone system includes a drone that includes a propulsion system, a flight stabilizer system, and an air payload interface unit, and a camera system, wherein the camera system includes a camera stabilizing unit, and a ground support system to which the drone is detachably coupled through a tether unit, and for providing electrical power to the propulsion system. The drone system further includes a ground payload interface unit for receiving and transmitting command and telemetry information to the air payload interface unit through the tether unit, and a controlling device for controlling the propulsion system and the camera system through the tether unit."
APPARATUS AND METHODS FOR TETHERED AERIAL PLATFORM AND SYSTEM,https://lens.org/048-404-089-542-36X,2016,"A drone system includes a drone that includes a propulsion system, a flight stabilizer system, and an air payload interface unit, and a camera system, wherein the camera system includes a camera stabilizing unit, and a ground support system to which the drone is detachably coupled through a tether unit, and for providing electrical power to the propulsion system. The drone system further includes a ground payload interface unit for receiving and transmitting command and telemetry information to the air payload interface unit through the tether unit, and a controlling device for controlling the propulsion system and the camera system through the tether unit."
AN AUTONOMOUS VEHICLE CONTROL SYSTEM,https://lens.org/072-274-622-645-082,2017,"A drone control system for controlling a drone which includes an onboard-flight-system previously configured to receive navigational-data in a format compliant with a standard navigational data transmission protocol. The system includes a remote-sensor and an interface. The remote sensor is located remotely from the drone and determines the position of the drone relative to the remote-sensor. The interface, coupled with the remote-sensor, produces a pseudo GPS signal indicating the position of the drone and to provide the pseudo GPS signal to an onboard-flight-system of the drone. The format of the pseudo GPS signal is fully compliant with the standard navigational data transmission protocol employed by the onboard-flight-system. The onboard-flight-system is receives inertial tracking data from an onboard inertial-measuring-unit and the pseudo GPS signal, and tracks the position of the drone by merging the inertial tracking data and the pseudo GPS signal and navigates the drone accordingly."
AN AUTONOMOUS VEHICLE CONTROL SYSTEM,https://lens.org/092-815-087-095-836,2018,"A drone control system for controlling a drone which includes an onboard-flight-system previously configured to receive navigational-data in a format compliant with a standard navigational data transmission protocol. The system includes a remote-sensor and an interface. The remote sensor is located remotely from the drone and determines the position of the drone relative to the remote-sensor. The interface, coupled with the remote-sensor, produces a pseudo GPS signal indicating the position of the drone and to provide the pseudo GPS signal to an onboard-flight-system of the drone. The format of the pseudo GPS signal is fully compliant with the standard navigational data transmission protocol employed by the onboard-flight-system. The onboard-flight-system is receives inertial tracking data from an onboard inertial-measuring-unit and the pseudo GPS signal, and tracks the position of the drone by merging the inertial tracking data and the pseudo GPS signal and navigates the drone accordingly."
Autonomous vehicle control system,https://lens.org/022-570-969-368-371,2019,"A drone control system for controlling a drone which includes an onboard-flight-system previously configured to receive navigational-data in a format compliant with a standard navigational data transmission protocol. The system includes a remote-sensor and an interface. The remote sensor is located remotely from the drone and determines the position of the drone relative to the remote-sensor. The interface, coupled with the remote-sensor, produces a pseudo GPS signal indicating the position of the drone and to provide the pseudo GPS signal to an onboard-flight-system of the drone. The format of the pseudo GPS signal is fully compliant with the standard navigational data transmission protocol employed by the onboard-flight-system. The onboard-flight-system is receives inertial tracking data from an onboard inertial-measuring-unit and the pseudo GPS signal, and tracks the position of the drone by merging the inertial tracking data and the pseudo GPS signal and navigates the drone accordingly."
SYSTEM AND METHOD FOR IMAGE CONTENT RECORDING OF A MOVING USER,https://lens.org/192-606-502-967-14X,2021,"A system for recording image content of a moving user. The system includes a control system, a drone carrying an imaging device, and a user interface for communication with the control system. The control system is configured to: obtain identification data of a user via the user interface; capture an identification image of a predetermined starting area; output said identification image for display on the user interface; obtain identification confirmation of the image; and control the drone, responsive to the obtained confirmation, to monitor movement of the user using the imaging device."
Personal Submersible Drone for Aquatic Exploration,https://lens.org/043-906-073-344-033,2015,"The invention is directed toward an autonomous submersible aquatic drone, a system utilizing an autonomous submersible aquatic drone and a control unit, a control unit for controlling an autonomous submersible aquatic drone, and a method for using the same. The autonomous submersible aquatic drone comprises a shaped housing, a propulsion system, one or more electromotors, a camera, a sonar unit, a wireless transponder, a battery, a microcontroller unit, and a control hardware unit. The control hardware unit is configured with artificial intelligence logic. The submersible drone surveys a predetermined area around a person engaged in a water sport for the presence of an underwater threat. When the aquatic drone detects the presence of an underwater threat the submersible drone sends a warning signal to a control unit worn by the person. The aquatic drone may also have a threat response unit to deter an attack on the person."
DRONE,https://lens.org/068-467-000-592-023,2022,"A drone (100) used for different applications for example, personal transportation or emergency services is disclosed. The drone (100) comprises a body frame (102) or circular a shell structure having a compartment (104) includes a control system and seats or stretchers, and/or a cargo hold, etc. (106) for persons or cargo. Ballasts (108 and 110) include cargo/batteries are positioned underneath the seats (106), configured to slide on rails (122) for attaining the center of gravity. At least two rotors (112 and 114) are rotatably positioned within a rotor guide ring (124) at a middle section of the drone (100). The rotors (112 and 114) are rotatably connected to respective motors (118 and 120) via gearboxes (126), configured to rotate and tilt up and down, thereby obtaining propulsion and flying to desired altitudes via an optimal flight path based on a control input given by the person using the control system."
Improvements in and relating to drone control,https://lens.org/021-438-080-415-845,2022,"A system 100 for controlling the operation of a drone 110 comprises: a drone 110; a receiver unit 120 mounted on the drone 110, the receiver unit 120 configured to receive a 5 signal from an animal; a processor 130 operable to process the received signal to determine the kinematics of the animal and provide an output based on the kinematics such as position or velocity of travel; and a controller 140 operable to control operation of the drone 110 based on the output from the processor 130. The signal may be an radio signal from transmitter attached to the animal, a reflected signal from a reflective object on the animal and/or a sound signal from the animal. The processor preferably being operable to determine angle of arrival and received signal strength to determine the kinematics."
METHOD FOR AUTONOMOUS CONTROLLING OF A REMOTE CONTROLLED AERIAL VEHICLE AND CORRESPONDING SYSTEM,https://lens.org/103-528-252-262-470,2016,"A method for autonomous controlling of a remote controlled aerial vehicle, wherein a flight operator commands the aerial vehicle, comprising the steps of: initializing a data link between the aerial vehicle and a ground segment; determining an operation condition of the data link during use of the data link; and issuing at least one autonomous controlling command, if, as a result of the determining, a loss of the data link is determined."
Drone and control device and communication port device thereof,https://lens.org/182-987-226-930-648,2020,"This invention comprises a control device and a communication port device applied to drone, and a drone using such devices. The control device comprises a carrier board and a main control board that is detachably configured on the carrier board, said main control board is electrically connected with the carrier board, and the carrier board is configured with an interface device in which connections between a plurality of kinds of external devices with said carrier board are established. The carrier board is mainly used for connection with other external electronic devices and power distribution, and the main control board is responsible for processing sensor data and delivering control information. The main control board and the carrier board are connected through a single interface to enable a data transmission. The communication port device is configured on the drone flight controller."
DRONE AND CONTROL DEVICE AND COMMUNICATION PORT DEVICE THEREOF,https://lens.org/128-558-656-846-493,2018,"This invention comprises a control device and a communication port device applied to drone, and a drone using such devices. The control device comprises a carrier board and a main control board that is detachably configured on the carrier board, said main control board is electrically connected with the carrier board, and the carrier board is configured with an interface device in which connections between a plurality of kinds of external devices with said carrier board are established. The carrier board is mainly used for connection with other external electronic devices and power distribution, and the main control board is responsible for processing sensor data and delivering control information. The main control board and the carrier board are connected through a single interface to enable a data transmission. The communication port device is configured on the drone flight controller."
Methods and apparatus for regulating a position of a drone,https://lens.org/187-668-750-609-993,2022,"A drone autonomously operates to track an object, track an object while being stealthy and/or observe the details of an object while maintaining communication at a rate equal to or greater than a threshold. A drone may operate to maintain the image of an object at or above a predetermined resolution in an image captured by a camera mounted on the drone and to maintain a wireless communication rate equal to or greater than a threshold rate. A drone may operate so that the sound intensity level caused by the operation of the drone is less than or equal to a sound intensity level threshold as perceived by an object (e.g., person, target, suspect) being tracked."
Methods and Apparatus for Regulating a Position of a Drone,https://lens.org/032-182-221-879-743,2020,"A drone autonomously operates to track an object, track an object while being stealthy and/or observe the details of an object while maintaining communication at a rate equal to or greater than a threshold. A drone may operate to maintain the image of an object at or above a predetermined resolution in an image captured by a camera mounted on the drone and to maintain a wireless communication rate equal to or greater than a threshold rate. A drone may operate so that the sound intensity level caused by the operation of the drone is less than or equal to a sound intensity level threshold as perceived by an object (e.g., person, target, suspect) being tracked."
Methods and Apparatus for Regulating a Position of a Drone,https://lens.org/032-182-221-879-743,2020,"A drone autonomously operates to track an object, track an object while being stealthy and/or observe the details of an object while maintaining communication at a rate equal to or greater than a threshold. A drone may operate to maintain the image of an object at or above a predetermined resolution in an image captured by a camera mounted on the drone and to maintain a wireless communication rate equal to or greater than a threshold rate. A drone may operate so that the sound intensity level caused by the operation of the drone is less than or equal to a sound intensity level threshold as perceived by an object (e.g., person, target, suspect) being tracked."
Methods and apparatus for regulating a position of a drone,https://lens.org/187-668-750-609-993,2022,"A drone autonomously operates to track an object, track an object while being stealthy and/or observe the details of an object while maintaining communication at a rate equal to or greater than a threshold. A drone may operate to maintain the image of an object at or above a predetermined resolution in an image captured by a camera mounted on the drone and to maintain a wireless communication rate equal to or greater than a threshold rate. A drone may operate so that the sound intensity level caused by the operation of the drone is less than or equal to a sound intensity level threshold as perceived by an object (e.g., person, target, suspect) being tracked."
Automatic flight control system and method for unmanned drone,https://lens.org/132-324-244-233-714,2019,"Disclosed herein are an automatic flight control system and method for an unmanned drone, in which a guidance system installed on a moving object transmits a guide signal, and the unmanned drone automatically flies based on the guide signal, thus allowing the unmanned drone to maintain a uniform distance from the moving object. The presented automatic flight control system for an unmanned drone is configured such that a guidance system transmits a guide signal based on a guidance request signal received from the unmanned drone, and the unmanned drone automatically flies depending on an automatic flight control value that is set based on an automatic flight guide signal when the guide signal is the automatic flight guide signal, and flies to the automatic control location set in response to an automatic location guide signal when the guide signal is the automatic location guide signal."
AUTOMATIC FLIGHT CONTROL SYSTEM AND METHOD FOR UNMANNED DRONE,https://lens.org/038-641-921-635-043,2017,"Disclosed herein are an automatic flight control system and method for an unmanned drone, in which a guidance system installed on a moving object transmits a guide signal, and the unmanned drone automatically flies based on the guide signal, thus allowing the unmanned drone to maintain a uniform distance from the moving object. The presented automatic flight control system for an unmanned drone is configured such that a guidance system transmits a guide signal based on a guidance request signal received from the unmanned drone, and the unmanned drone automatically flies depending on an automatic flight control value that is set based on an automatic flight guide signal when the guide signal is the automatic flight guide signal, and flies to the automatic control location set in response to an automatic location guide signal when the guide signal is the automatic location guide signal."
Supervisory Control of an Unmanned Aerial Vehicle,https://lens.org/136-621-840-418-471,2018,"An unmanned aerial vehicle (UAV) is disclosed that may allow for supervisory control interaction by a remote operator to assist with navigation to a target location. The UAV may navigate to a target area and capture and send an image of the target area to the remote operator. The remote operator can then provide a user input that indicates a target location within the target area. Upon receiving an indication of the target area, the UAV can then autonomously navigate to the target location. In some examples, after reaching the target location, the UAV may initiate delivery of a payload at the target location using a retractable delivery system while the UAV hovers above."
Supervisory control of an unmanned aerial vehicle,https://lens.org/161-253-800-917-356,2017,"An unmanned aerial vehicle (UAV) is disclosed that may allow for supervisory control interaction by a remote operator to assist with navigation to a target location. The UAV may navigate to a target area and capture and send an image of the target area to the remote operator. The remote operator can then provide a user input that indicates a target location within the target area. Upon receiving an indication of the target area, the UAV can then autonomously navigate to the target location. In some examples, after reaching the target location, the UAV may initiate delivery of a payload at the target location using a retractable delivery system while the UAV hovers above."
Method for virtual testing of real environments with pedestrian interaction and drones,https://lens.org/186-134-455-450-614,2019,"A method for testing of self-driving or autonomous vehicles A and their algorithms in situations with pedestrian interactions comprises providing a drone B controlled by a test person C. The control of the drone B comprises applying motion capture techniques and providing a walking platform to the test person C. The drone B comprises a camera, the images being wirelessly transmitted to the test person C, and the movement of the test person in response to the images tracked and used to control the drone B. There may be traffic between the drone and the vehicle. The method may be carried out in real time."
ELECTRONIC DEVICE AND METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE,https://lens.org/092-050-505-646-759,2018,"A method of an electronic device for controlling an unmanned aerial vehicle (UAV) is provided, The method includes receiving, from the UAV related to the electronic device, a signal including information regarding at least one parameter for determining an area where the UAV is capable of flying, determining the area where the UAV is capable of flying based on the information regarding the at least one parameter, and displaying information indicating the determined area where the UAV is capable of flying by superimposing the same on information indicating a region where the UAV is located. Other embodiments may be possible."
DRONE CONTROL,https://lens.org/070-934-090-810-46X,2019,A system includes a disabling device with a circuit configured to disrupt communication of a drone.
"DRONE COMPRISING A DEVICE FOR DETERMINING A REPRESENTATION OF A TARGET VIA A NEURAL NETWORK, RELATED DETERMINATION METHOD AND COMPUTER",https://lens.org/139-719-165-794-987,2018,"This drone includes an image sensor configured to take an image of a scene including a plurality of objects, and an electronic determination device including an electronic detection module configured to detect, via a neural network, in the image taken by the image sensor, a representation of a potential target from among the plurality of objects represented, an input variable of the neural network being an image depending on the image taken, at least one output variable of the neural network being an indication relative to the representation of the potential target. A first output variable of the neural network is a set of coordinates defining a contour of a zone surrounding the representation of the potential target."
VTOL fixed-wing aerial drone with interchangeable cabins,https://lens.org/102-563-724-589-39X,2019,An aerial drone having a flying platform with a canard configuration and has detachable and interchangeable cabins.
VTOL FIXED-WING AERIAL DRONE WITH INTERCHANGEABLE CABINS,https://lens.org/074-588-938-079-616,2019,An aerial drone having a flying platform with a canard configuration and has detachable and interchangeable cabins.
"METHOD AND AN APPARATUS FOR CONTROLLING A UAV, AND A UAV TAKE-OFF SYSTEM",https://lens.org/039-797-398-193-152,2017,"A method for controlling an unmanned aerial vehicle (UAV) is provided. The UAV comprises at least one rotor. The method includes receiving a take-off signal; initiating the at least one rotor to operate with a first preset rotation acceleration in response to the take-off signal; detecting a take-off status information of the UAV, the take-off status information at least comprising a current height of the UAV; determining whether the detected current height of the UAV is equal to or greater than a threshold; and sending a hover signal to the at least one rotor to enable the UAV to hover in the current height in response to the determination that the detected current height of the UAV is equal to or greater than the threshold."
"CONTROL METHOD, CONTROL SYSTEM, AND SMART GLASSES FOR FIRST PERSON VIEW UNMANNED AERIAL VEHICLE FLIGHT",https://lens.org/101-107-482-865-404,2022,"A system for controlling an unmanned aerial vehicle (UAV) includes smart glasses configured to establish a first channel directly with the UAV, receive first person view (FPV) image data directly from the UAV through the first channel, and display the FPV image data, a remote control configured to establish a second channel directly with the UAV and send a first flight control instruction corresponding to the FPV image data directly to the UAV through the second channel, and establish a fourth channel directly with the mobile terminal, and a mobile terminal configured to display the FPV image data received from the UAV and forwarded by the remote control."
CONVERSION OF A WATERCRAFT TO A WATER SKIER CONTROLLED DRONE,https://lens.org/144-429-967-098-487,1992,Method and apparatus for converting a watercraft having on-board engine and guidance controls into a drone remotely controlled through towing apparatus by the skier riding on skis behind it. A control unit is secured to the watercraft. The control unit engages the on-board engine and guidance controls of the watercraft. The engine and guidance controls are operated by the control unit through a remotely located tow handle. The tow handle is physically and electronically connected to the control unit.
DRONE WITH CRIMPING DEVICE AND METHOD OF OPERATION,https://lens.org/074-826-063-728-767,2018,A drone for performing a remote operation on a utility line includes a body member and a first rotor arm extending from the body member. A first rotor is attached to the rotor arm. A first mount extends from the body member and a camera is connected to the first mount. A second mount extends from the body member and a positioning arm is connected to the second mount. A third mount extends from the body member and a crimping device is connected to the third mount.
DRONE APPARATUS AND METHOD FOR DEPLOYING DRONE WORKING ZONE,https://lens.org/036-524-230-733-941,2022,"A drone apparatus and a method for deploying a drone working zone are provided. The drone apparatus includes an aircraft body, a communication device, a positioning device and a flight controller. The flight controller is configured to: set edge rules of a working zone unit used to construct a working zone for the drone apparatus to work around a bridge; control the aircraft body to fly along a target section selected in the bridge according to a control signal received by the communication device, and calculate positions of multiple points of interest (POIs) passed by during the flight using the positioning device; generate one working zone unit with positions of adjacent two of the POIs according to the edge rules of the working zone unit; and combine multiple working zone units generated by using positions of all the POIs to construct and deploy the working zone of the target section."
Drone apparatus and method for deploying drone working zone,https://lens.org/039-949-147-871-967,2023,"A drone apparatus and a method for deploying a drone working zone are provided. The drone apparatus includes an aircraft body, a communication device, a positioning device and a flight controller. The flight controller is configured to: set edge rules of a working zone unit used to construct a working zone for the drone apparatus to work around a bridge; control the aircraft body to fly along a target section selected in the bridge according to a control signal received by the communication device, and calculate positions of multiple points of interest (POIs) passed by during the flight using the positioning device; generate one working zone unit with positions of adjacent two of the POIs according to the edge rules of the working zone unit; and combine multiple working zone units generated by using positions of all the POIs to construct and deploy the working zone of the target section."
Waypoint navigation,https://lens.org/067-530-841-061-561,2007,"The invention relates to remote control of an unmanned aerial vehicle, UAV, ( 100 ) from a control station ( 110 ) by means of a wireless command link ( 115 ). The UAV ( 100 ) may be controlled in an autonomous mode wherein it flies according to a primary route (R 1 , R 1 ') defined by a first set of predefined waypoints (WP 1 -WP 8 , IP). The UAV ( 100 ) may also be controlled in a manual mode wherein it flies according to an alternative primary route (R 1 ') defined in real-time by control commands received via the wireless command link ( 115 ). Flight control parameters are monitored in both modes, and in case a major alarm condition occurs, the UAV ( 100 ) is controlled to follow an emergency route (R 2 ') defined by a second set of predefined waypoints (HP 1 -HP 7 , TP 1 -TP 9 , IP). Particularly, a major alarm condition is activated if an engine failure is detected. Then, the emergency route (R 2 ') involves flying the UAV ( 100 ) to an air space above a termination waypoint (TP 9 ) on the ground at which it is estimated that the vehicle's ( 100 ) flight may be ended without injuring any personnel or causing uncontrolled material damages."
METHOD FOR CONTROLLING EXTERNAL DEVICE BASED ON VOICE AND ELECTRONIC DEVICE THEREOF,https://lens.org/105-691-889-874-717,2021,"A method for an electronic device to control at least one external electronic device is provided. The method includes receiving an input for calling a voice-based assistant of the electronic device from a user, broadcasting, in response to the input, a request signal for requesting transmission of a response signal, receiving the response signal including location information about at least one external electronic device from the at least one external electronic device, obtaining a location of the electronic device based on the response signal, receiving a control utterance from the user, and transmitting the control utterance and location information about the electronic device to a server device."
Method for controlling external device based on voice and electronic device thereof,https://lens.org/025-836-322-154-801,2023,"A method for an electronic device to control at least one external electronic device is provided. The method includes receiving an input for calling a voice-based assistant of the electronic device from a user, broadcasting, in response to the input, a request signal for requesting transmission of a response signal, receiving the response signal including location information about at least one external electronic device from the at least one external electronic device, obtaining a location of the electronic device based on the response signal, receiving a control utterance from the user, and transmitting the control utterance and location information about the electronic device to a server device."
Systems and methods to control an autonomous mobile robot,https://lens.org/095-306-678-794-106,2022,"A method for controlling one or more operations of an autonomous mobile robot maneuverable within a home includes establishing wireless communication between an autonomous mobile robot and a remote computing system and, in response to receiving a wireless command signal from the remote computing system, initiating one or more operations of the autonomous mobile robot. The autonomous mobile robot is remote from an audio media device stationed within the home. The audio media device is capable of receiving and emitting audio. The remote computing system is configured to associate identification data of the autonomous mobile robot with identification data of the audio media device. The wireless command signal corresponds to an audible user command received by the audio media device."
SYSTEMS AND METHODS TO CONTROL AN AUTONOMOUS MOBILE ROBOT,https://lens.org/035-008-442-557-444,2017,"A method for controlling one or more operations of an autonomous mobile robot maneuverable within a home includes establishing wireless communication between an autonomous mobile robot and a remote computing system and, in response to receiving a wireless command signal from the remote computing system, initiating one or more operations of the autonomous mobile robot. The autonomous mobile robot is remote from an audio media device stationed within the home. The audio media device is capable of receiving and emitting audio. The remote computing system is configured to associate identification data of the autonomous mobile robot with identification data of the audio media device. The wireless command signal corresponds to an audible user command received by the audio media device."
SYSTEMS AND METHODS TO CONTROL AN AUTONOMOUS MOBILE ROBOT,https://lens.org/169-265-828-766-819,2021,"A method for controlling one or more operations of an autonomous mobile robot maneuverable within a home includes establishing wireless communication between an autonomous mobile robot and a remote computing system and, in response to receiving a wireless command signal from the remote computing system, initiating one or more operations of the autonomous mobile robot. The autonomous mobile robot is remote from an audio media device stationed within the home. The audio media device is capable of receiving and emitting audio. The remote computing system is configured to associate identification data of the autonomous mobile robot with identification data of the audio media device. The wireless command signal corresponds to an audible user command received by the audio media device."
Systems and methods to control an autonomous mobile robot,https://lens.org/083-045-697-579-593,2021,"A method for controlling one or more operations of an autonomous mobile robot maneuverable within a home includes establishing wireless communication between an autonomous mobile robot and a remote computing system and, in response to receiving a wireless command signal from the remote computing system, initiating one or more operations of the autonomous mobile robot. The autonomous mobile robot is remote from an audio media device stationed within the home. The audio media device is capable of receiving and emitting audio. The remote computing system is configured to associate identification data of the autonomous mobile robot with identification data of the audio media device. The wireless command signal corresponds to an audible user command received by the audio media device."
Systems and methods to control an autonomous mobile robot,https://lens.org/095-306-678-794-106,2022,"A method for controlling one or more operations of an autonomous mobile robot maneuverable within a home includes establishing wireless communication between an autonomous mobile robot and a remote computing system and, in response to receiving a wireless command signal from the remote computing system, initiating one or more operations of the autonomous mobile robot. The autonomous mobile robot is remote from an audio media device stationed within the home. The audio media device is capable of receiving and emitting audio. The remote computing system is configured to associate identification data of the autonomous mobile robot with identification data of the audio media device. The wireless command signal corresponds to an audible user command received by the audio media device."
Systems and methods to control an autonomous mobile robot,https://lens.org/153-694-309-803-942,2018,"A method for controlling one or more operations of an autonomous mobile robot maneuverable within a home includes establishing wireless communication between an autonomous mobile robot and a remote computing system and, in response to receiving a wireless command signal from the remote computing system, initiating one or more operations of the autonomous mobile robot. The autonomous mobile robot is remote from an audio media device stationed within the home. The audio media device is capable of receiving and emitting audio. The remote computing system is configured to associate identification data of the autonomous mobile robot with identification data of the audio media device. The wireless command signal corresponds to an audible user command received by the audio media device."
TEACHING METHOD FOR UNMANNED AERIAL VEHICLE AND REMOTE CONTROLLER FOR UNMANNED AERIAL VEHICLE,https://lens.org/089-199-390-195-229,2020,"A remote controller for an unmanned aerial vehicle (UAV) includes a stick, a driving device with one end connected to the stick, and a processor coupled to the driving device and configured to obtain teaching data including a standard trajectory of the stick and control the driving device to drive the stick to move according to the standard trajectory."
METHOD FOR CONTROLLING UAV,https://lens.org/115-599-155-798-496,2019,"A method for controlling an unmanned aerial vehicle (UAV) includes obtaining identity information of a user, determining a user permission according to the identity information and a preset database, and controlling the UAV according a control command generated based on the user permission."
Coordinated cinematic drone,https://lens.org/145-695-113-206-622,2019,"A camera is mounted on a drone, which is programmed to follow a flight path that is specified by trajectory parameters. The position of the drone is coordinated with a subject to be filmed by the camera, and may be coordinated with the position of one or more objects, including other automatically controlled drones, a manually controlled drone and virtual assets. The drone can also be coordinated with the behavior of a subject."
Coordinated cinematic drone,https://lens.org/040-862-837-149-473,2021,"A camera is mounted on a drone, which is programmed to follow a flight path that is specified by trajectory parameters. The position of the drone is coordinated with a subject to be filmed by the camera, and may be coordinated with the position of one or more objects, including other automatically controlled drones, a manually controlled drone and virtual assets. The drone can also be coordinated with the behavior of a subject."
AERIAL DRONE AIR TREATING DEVICE AND METHOD OF TREATING AIR THEREWITH,https://lens.org/138-040-175-769-235,2018,"A drone which can be piloted autonomously or by a user. The drone has an air treatment dispenser for spraying, or otherwise treating, a target area with one or more desired air treatments. The drone may operate as deemed desirable by a user, upon a predetermined schedule or in response to a demand signal from one or more target areas. By delivering the air treatments from an elevated position, the target area can be more uniformly and efficiently treated."
AERIAL DRONE AIR TREATING DEVICE AND METHOD OF TREATING AIR THEREWITH,https://lens.org/038-646-191-681-752,2021,"A drone which can be piloted autonomously or by a user. The drone has an air treatment dispenser for spraying, or otherwise treating, a target area with one or more desired air treatments. The drone may operate as deemed desirable by a user, upon a predetermined schedule or in response to a demand signal from one or more target areas. By delivering the air treatments from an elevated position, the target area can be more uniformly and efficiently treated."
Unmanned aerial vehicles,https://lens.org/064-286-724-436-431,2019,"A UAV 100 has an upward facing sensor 105, a controller 120 and an actuator 125. The UAY 100 is operable in an autonomous mode in which the controller 120 controls the actuator 125 based on data captured by the upward facing sensor 105 and data received from an object via a communication channel between the UAV 100 and the object. The sensor may be an upward facing camera."
System and methods for drone-based vehicle status determination,https://lens.org/032-778-292-161-744,2019,"Exemplary embodiments relate to a drone system including a drone configured for navigation of an outdoor facility and equipped with an RFID reader, an optical code reader, and at least one of powertrain control module data receiver and an electronic control module data receiver. The system includes a computing system in communication with the drone."
SYSTEM AND METHODS FOR DRONE-BASED VEHICLE STATUS DETERMINATION,https://lens.org/185-576-053-716-514,2018,"Exemplary embodiments relate to a drone system including a drone configured for navigation of an outdoor facility and equipped with an RFID reader, an optical code reader, and at least one of powertrain control module data receiver and an electronic control module data receiver. The system includes a computing system in communication with the drone."
Drone based systems and methodologies for capturing images,https://lens.org/034-969-970-987-567,2023,"A system is provided for sending a drone to a target on request. The system includes a server provided in communication with a plurality of mobile technology platforms, each of which having an instance of a particular software installed therein. The software contains programming instructions configured to transmit a request from a user for a drone. The system, upon receiving a transmitted request for a drone from one of the plurality of mobile technology platforms, dispatches a drone to fly to a specified target and provides the user with at least partial control of the drone's flight or of media capture by the drone based on the location of the drone relative to a geofence associated with the target."
Drone based systems and methodologies for capturing images,https://lens.org/003-755-253-858-887,2021,"A system is provided for sending a drone to a target on request. The system includes a server provided in communication with a plurality of mobile technology platforms, each of which having an instance of a particular software installed therein. The software contains programming instructions configured to transmit a request from a user for a drone. The system, upon receiving a transmitted request for a drone from one of the plurality of mobile technology platforms, dispatches a drone to fly to a specified target and provides the user with at least partial control of the drone's flight or of media capture by the drone based on the location of the drone relative to a geofence associated with the target."
DRONE BASED SYSTEMS AND METHODOLOGIES FOR CAPTURING IMAGES,https://lens.org/052-027-495-541-286,2021,"A system is provided for sending a drone to a target on request. The system includes a server provided in communication with a plurality of mobile technology platforms, each of which having an instance of a particular software installed therein. The software contains programming instructions configured to transmit a request from a user for a drone. The system, upon receiving a transmitted request for a drone from one of the plurality of mobile technology platforms, dispatches a drone to fly to a specified target and provides the user with at least partial control of the drone's flight or of media capture by the drone based on the location of the drone relative to a geofence associated with the target."
Drone based systems and methodologies for capturing images,https://lens.org/034-969-970-987-567,2023,"A system is provided for sending a drone to a target on request. The system includes a server provided in communication with a plurality of mobile technology platforms, each of which having an instance of a particular software installed therein. The software contains programming instructions configured to transmit a request from a user for a drone. The system, upon receiving a transmitted request for a drone from one of the plurality of mobile technology platforms, dispatches a drone to fly to a specified target and provides the user with at least partial control of the drone's flight or of media capture by the drone based on the location of the drone relative to a geofence associated with the target."
"Drone, method for controlling flight, and recording medium storing program",https://lens.org/136-420-994-884-319,2023,"A drone is provided that includes a controller, a time measurer that measures a present time, a position measurer that obtains a current position of the drone, and a storage that stores a time period for which the flight of the drone is permitted. The controller performs operations including determining a possible flight area of the drone in accordance with a difference between an end of the time period for which flight of the drone is permitted and the present time, and determining whether the drone is located within the possible flight area on the basis of the current position of the drone."
"Drone, method for controlling flight, and recording medium storing program",https://lens.org/136-420-994-884-319,2023,"A drone is provided that includes a controller, a time measurer that measures a present time, a position measurer that obtains a current position of the drone, and a storage that stores a time period for which the flight of the drone is permitted. The controller performs operations including determining a possible flight area of the drone in accordance with a difference between an end of the time period for which flight of the drone is permitted and the present time, and determining whether the drone is located within the possible flight area on the basis of the current position of the drone."
"DRONE, METHOD FOR CONTROLLING FLIGHT, AND RECORDING MEDIUM STORING PROGRAM",https://lens.org/030-326-183-991-351,2019,"A drone is provided that includes a controller, a time measurer that measures a present time, a position measurer that obtains a current position of the drone, and a storage that stores a time period for which the flight of the drone is permitted. The controller performs operations including determining a possible flight area of the drone in accordance with a difference between an end of the time period for which flight of the drone is permitted and the present time, and determining whether the drone is located within the possible flight area on the basis of the current position of the drone."
Search track acquire react system (STARS) drone integrated acquisition tracker (DIAT),https://lens.org/020-952-175-965-175,2021,"Exemplary drone detection, tracking, and control systems as well as related methods are provided. An exemplary system can include directional antennas and a movement system that moves the directional antennas in various azimuth and elevation orientations. A control system includes a video signal processor, a transceiver, an input/output system, a user interface, a wireless system, a machine instruction storage medium, and a plurality of machine readable instructions that operate the antenna assembly to detect, orient on, and record at least a video signal from a moveable platform as well as generate a graphical user interface (GUI) that shows a map with a user location, the antenna system location, and orientation of the antenna assembly with line of bearing. The GUI also displaying a plurality of radio channel and detected signal information. A display is provided that displays the GUI and enables user interaction with the GUI and system."
Search Track Acquire React System (STARS) Drone Integrated Acquisition Tracker (DIAT),https://lens.org/121-626-825-227-958,2019,"Exemplary drone detection, tracking, and control systems as well as related methods are provided. An exemplary system can include directional antennas and a movement system that moves the directional antennas in various azimuth and elevation orientations. A control system includes a video signal processor, a transceiver, an input/output system, a user interface, a wireless system, a machine instruction storage medium, and a plurality of machine readable instructions that operate the antenna assembly to detect, orient on, and record at least a video signal from a moveable platform as well as generate a graphical user interface (GUI) that shows a map with a user location, the antenna system location, and orientation of the antenna assembly with line of bearing. The GUI also displaying a plurality of radio channel and detected signal information. A display is provided that displays the GUI and enables user interaction with the GUI and system."
Unmanned aerial vehicles,https://lens.org/098-335-307-287-991,2021,"An unmanned aerial vehicle, UAV, is operable in an autonomous mode. The UAV comprises an upwards-configurable sensor an actuator and a controller. The upwards-configurable sensor is configurable in an upwards-facing configuration during an autonomous procedure such that a field of view of the upwards-configurable sensor includes airspace directly above the UAV during the autonomous procedure. The controller is operable to control the actuator during the autonomous procedure based on data captured by the upwards-configurable sensor to cause the UAV to make physical contact with an object in the airspace directly above the UAV during the autonomous procedure."
UNMANNED AERIAL VEHICLES,https://lens.org/122-171-234-331-970,2018,"An unmanned aerial vehicle, UAV, is operable in an autonomous mode. The UAV comprises an upwards-configurable sensor an actuator and a controller. The upwards-configurable sensor is configurable in an upwards-facing configuration during an autonomous procedure such that a field of view of the upwards-configurable sensor includes airspace directly above the UAV during the autonomous procedure. The controller is operable to control the actuator during the autonomous procedure based on data captured by the upwards-configurable sensor to cause the UAV to make physical contact with an object in the airspace directly above the UAV during the autonomous procedure."
SYSTEMS AND METHODS FOR AUTONOMOUS DRONE NAVIGATION,https://lens.org/112-713-413-080-346,2018,"Exemplary embodiments relate to an indoor drone system including an autonomous drone configured for autonomous navigation, and a computing system in communication with the autonomous drone. The autonomous drone includes an optical code reader and at least one navigational sensor. The computing system includes a verification module."
Systems and methods for autonomous drone navigation,https://lens.org/076-207-351-990-153,2019,"Exemplary embodiments relate to an indoor drone system including an autonomous drone configured for autonomous navigation, and a computing system in communication with the autonomous drone. The autonomous drone includes an optical code reader and at least one navigational sensor. The computing system includes a verification module."
SYSTEMS AND METHODS FOR AUTONOMOUS DRONE NAVIGATION,https://lens.org/034-858-902-359-612,2018,"Exemplary embodiments relate to an indoor drone system including an autonomous drone configured for autonomous navigation, and a computing system in communication with the autonomous drone. The autonomous drone includes an optical code reader and at least one navigational sensor. The computing system includes a verification module."
SYSTEMS AND METHODS FOR AUTONOMOUS DRONE NAVIGATION,https://lens.org/105-379-224-649-092,2019,"Exemplary embodiments relate to an indoor drone system including an autonomous drone configured for autonomous navigation, and a computing system in communication with the autonomous drone. The autonomous drone includes an optical code reader and at least one navigational sensor. The computing system includes a verification module."
SYSTEM AND METHOD FOR RECHARGING BATTERY IN AUGMENTED REALITY GAME SYSTEM,https://lens.org/178-832-280-884-59X,2017,"In an aspect, an augmented reality game system is provided including a mobile smart device such as a smart phone and a remotely controlled drone. The mobile smart phone device is programmed to display an augmented environment, being the real environment viewed by the camera and a virtual environment superimposed over images of the real environment. The drone is controlled via commands transmitted wirelessly by the mobile smart device. The mobile smart device is programmed to execute a video game, which includes activities requiring a player to control the drone in relation to the augmented environment displayed on the mobile smart device video screen. The drone is powered by a rechargeable battery, and the video game includes activities that keep the player occupied with the game whilst the drone's rechargeable battery recharges."
Systems And Methods For Operating Drones In Proximity To Objects,https://lens.org/045-887-500-187-397,2023,"Systems and methods for operating drones in proximity to objects are disclosed herein. An example method includes determining a change in drone, flight status that involves a rotor of the drone being active, determining presence of a mobile device within a designated clearance area established around the drone, preventing the drone from landing, providing a warning message to a user of the mobile device to clear away from the designated clearance area, detecting that the mobile device and the user are not within the designated clearance area, and causing the drone to land."
Systems And Methods For Operating Drones In Proximity To Objects,https://lens.org/045-887-500-187-397,2023,"Systems and methods for operating drones in proximity to objects are disclosed herein. An example method includes determining a change in drone, flight status that involves a rotor of the drone being active, determining presence of a mobile device within a designated clearance area established around the drone, preventing the drone from landing, providing a warning message to a user of the mobile device to clear away from the designated clearance area, detecting that the mobile device and the user are not within the designated clearance area, and causing the drone to land."
DRONE-RELATIVE GEOFENCE,https://lens.org/047-738-851-216-966,2018,"A drone receives an initiation signal which indicates that flight and/or navigation components of the drone are to be activated. Once activated, the drone then determines its initial position using a position-identifying radio signal. The drone then retrieves, from storage, dimensions of a drone-relative geofence. The drone can then calculate, using a processor, the drone-relative geofence having the dimensions with at least a specified floor and a specified radius. The drone adjusts the motor controller inputs to prevent the drone from exiting the calculated drone-relative geofence."
Drone-relative geofence,https://lens.org/092-139-282-901-468,2020,"A drone receives an initiation signal which indicates that flight and/or navigation components of the drone are to be activated. Once activated, the drone then determines its initial position using a position-identifying radio signal. The drone then retrieves, from storage, dimensions of a drone-relative geofence. The drone can then calculate, using a processor, the drone-relative geofence having the dimensions with at least a specified floor and a specified radius. The drone adjusts the motor controller inputs to prevent the drone from exiting the calculated drone-relative geofence."
"Electronic Control Device for Controlling a Drone, Related Drone, Controlling Method and Computer Program",https://lens.org/015-689-305-901-502,2018,"An electronic device for controlling a drone that comprises: a first acquisition module configured for acquiring a succession of images of a terrain overflown by the drone and taken by an image sensor equipping the drone;a second acquisition module configured for acquiring a measured ground speed via a measuring device equipping the drone, and for acquiring a measured altitude of the drone with respect to a reference level;a calculation module configured for calculating an altitude of the drone with respect to the terrain, based on the acquired measured ground speed and an optical flow algorithm applied to the acquired images; anda recalibration module configured for correlating the altitude calculated with respect to the terrain with the altitude measured with respect to the reference level."
Virtual Wall Mapping for Aerial Vehicle Navigation,https://lens.org/196-081-614-960-31X,2023,"An unmanned aerial vehicle (UAV), the UAV including an electronic speed controller and a flight controller. The electric speed controller is interfaced with thrust motors of the UAV. The flight controller is configured to: determine a geographic location and a velocity of the UAV. The flight controller configured to: determine a distance between the geographic location of the UAV and a closest segment of a no-fly-zone. The flight controller in response to the distance being less than a threshold distance, control a speed and thrust applied by the thrust motors through the electric speed controller to reduce both the first component and the second component of the velocity of the UAV based on the distance. The flight controller configured to: override a user input received via a user interface so that the UAV is moved relative to the closest segment of a no-fly-zone according to instructions from the flight controller."
Virtual Wall Mapping for Aerial Vehicle Navigation,https://lens.org/196-081-614-960-31X,2023,"An unmanned aerial vehicle (UAV), the UAV including an electronic speed controller and a flight controller. The electric speed controller is interfaced with thrust motors of the UAV. The flight controller is configured to: determine a geographic location and a velocity of the UAV. The flight controller configured to: determine a distance between the geographic location of the UAV and a closest segment of a no-fly-zone. The flight controller in response to the distance being less than a threshold distance, control a speed and thrust applied by the thrust motors through the electric speed controller to reduce both the first component and the second component of the velocity of the UAV based on the distance. The flight controller configured to: override a user input received via a user interface so that the UAV is moved relative to the closest segment of a no-fly-zone according to instructions from the flight controller."
Virtual wall mapping for aerial vehicle navigation,https://lens.org/020-397-037-643-098,2023,"An unmanned aerial vehicle (UAV), the UAV including an electronic speed controller and a flight controller. The electric speed controller is interfaced with thrust motors of the UAV. The flight controller is configured to: determine a geographic location and a velocity of the UAV. The flight controller configured to: determine a distance between the geographic location of the UAV and a closest segment of a no-fly-zone. The flight controller in response to the distance being less than a threshold distance, control a speed and thrust applied by the thrust motors through the electric speed controller to reduce both the first component and the second component of the velocity of the UAV based on the distance. The flight controller configured to: override a user input received via a user interface so that the UAV is moved relative to the closest segment of a no-fly-zone according to instructions from the flight controller."
Systems and methods for operating drones in response to an incident,https://lens.org/074-578-447-071-389,2018,"A response drone for detecting incidents within a coverage area including multiple zones is provided. With customer permission or affirmative consent, the drone may be programmed to (1) detect (or receive an indication of) triggering activity associated with one of the zones; (2) determine or receive a navigation path to that zone; (3) travel to that zone based upon the determined navigation path; (4) collect sensor data using drone-mounted sensors; and (5) transmit the collected sensor data to a user computing device associated with the coverage area for review. The response drone may be an autonomous drone in wireless communication with a smart home controller that detects triggering activity associated with an insurance-related event (e.g., fire). The autonomous drone may automatically deploy to mitigate damage to insured assets (e.g., a home or personal belongings). The autonomous drone data may be used for subsequent insurance claim handling and/or damage estimation."
Systems and methods for operating drones in response to an incident,https://lens.org/161-395-107-871-648,2021,"A response drone for detecting incidents within a coverage area including multiple zones is provided. With customer permission or affirmative consent, the drone may be programmed to (1) detect (or receive an indication of) triggering activity associated with one of the zones; (2) determine or receive a navigation path to that zone; (3) travel to that zone based upon the determined navigation path; (4) collect sensor data using drone-mounted sensors; and (5) transmit the collected sensor data to a user computing device associated with the coverage area for review. The response drone may be an autonomous drone in wireless communication with a smart home controller that detects triggering activity associated with an insurance-related event (e.g., fire). The autonomous drone may automatically deploy to mitigate damage to insured assets (e.g., a home or personal belongings). The autonomous drone data may be used for subsequent insurance claim handling and/or damage estimation."
Systems and methods for operating drones in response to an incident,https://lens.org/155-420-286-435-546,2020,"A response drone for detecting incidents within a coverage area including multiple zones is provided. With customer permission or affirmative consent, the drone may be programmed to (1) detect (or receive an indication of) triggering activity associated with one of the zones; (2) determine or receive a navigation path to that zone; (3) travel to that zone based upon the determined navigation path; (4) collect sensor data using drone-mounted sensors; and (5) transmit the collected sensor data to a user computing device associated with the coverage area for review. The response drone may be an autonomous drone in wireless communication with a smart home controller that detects triggering activity associated with an insurance-related event (e.g., fire). The autonomous drone may automatically deploy to mitigate damage to insured assets (e.g., a home or personal belongings). The autonomous drone data may be used for subsequent insurance claim handling and/or damage estimation."
REMOTE CONTROL HOLDER,https://lens.org/094-893-055-736-842,2020,"A remote control holder comprising: a body configured for releasably receiving a remote control for controlling a drone; and a stand via which an electronic display device can be mounted to the holder such that, in use, visual information captured by a drone can be displayed to the user via the display device."
Self charging lightweight drone apparatus,https://lens.org/093-759-065-466-547,2019,"A drone apparatus or arrangement is provided. The drone apparatus or arrangement includes a plurality of drone devices, each drone device including an unmanned vehicle configured to be controlled to hover in air at a desired height and move to a desired location, and a surface apparatus connected to the plurality of drone devices such that the plurality of drone devices are collectively controllable to reposition the surface apparatus to a desired location."
SELF CHARGING LIGHTWEIGHT DRONE APPARATUS,https://lens.org/131-656-698-315-09X,2016,"A drone apparatus or arrangement is provided. The drone apparatus or arrangement includes a plurality of drone devices, each drone device including an unmanned vehicle configured to be controlled to hover in air at a desired height and move to a desired location, and a surface apparatus connected to the plurality of drone devices such that the plurality of drone devices are collectively controllable to reposition the surface apparatus to a desired location."
REMOTE CONTROL DEVICE AND METHOD FOR UAV AND MOTION CONTROL DEVICE ATTACHED TO UAV,https://lens.org/007-987-355-453-360,2019,"A remote control device and method for a UAV, and a motion control device attached to the UAV. The remote control device is carried by a user, allowing the user to remotely control motions of the UAV. A sensor unit generates sensing data by sensing a motion of the remote control device using a sensor. A control unit determines at least one among a direction of inclination of the remote control device, an angle of the direction of inclination, and a period of time for which the direction of inclination is maintained, based on the sensing data, and generating a control command for controlling a motion of the UAV using at least one among the direction of inclination, the angle of the direction of inclination, and the period of time for which the direction of inclination is maintained. A communication unit transmits the control command to the UAV."
REMOTE CONTROL DEVICE AND METHOD FOR UAV AND MOTION CONTROL DEVICE ATTACHED TO UAV,https://lens.org/108-230-987-377-527,2019,"A remote control device and method for a UAV, and a motion control device attached to the UAV. The remote control device is carried by a user, allowing the user to remotely control motions of the UAV. A sensor unit generates sensing data by sensing a motion of the remote control device using a sensor. A control unit determines at least one among a direction of inclination of the remote control device, an angle of the direction of inclination, and a period of time for which the direction of inclination is maintained, based on the sensing data, and generating a control command for controlling a motion of the UAV using at least one among the direction of inclination, the angle of the direction of inclination, and the period of time for which the direction of inclination is maintained. A communication unit transmits the control command to the UAV."
Remote control device and method for UAV and motion control device attached to UAV,https://lens.org/050-723-380-606-031,2020,"A remote control device and method for a UAV, and a motion control device attached to the UAV. The remote control device is carried by a user, allowing the user to remotely control motions of the UAV. A sensor unit generates sensing data by sensing a motion of the remote control device using a sensor. A control unit determines at least one among a direction of inclination of the remote control device, an angle of the direction of inclination, and a period of time for which the direction of inclination is maintained, based on the sensing data, and generating a control command for controlling a motion of the UAV using at least one among the direction of inclination, the angle of the direction of inclination, and the period of time for which the direction of inclination is maintained. A communication unit transmits the control command to the UAV."
INFORMATION PROCESSING SYSTEM,https://lens.org/019-425-541-951-25X,2021,"Provided are a device for communicating with and controlling a small unmanned airplane, and a method therefor. In an information processing system to which the present invention is applied, a drone is provided with: a converter module that operates on a storage battery; an onboard communication means; an FDR module; a drive unit or the like, not illustrated; a leg section that contacts or approaches a landing port; and a charging terminal for supplying power for charging to the storage battery, the charging terminal being disposed in the proximal area. The landing port is the landing port where the drone lands, and has a projection for guiding the leg section onto a planar section."
Information processing system,https://lens.org/023-882-471-713-202,2023,"Provided are a device for communicating with and controlling a small unmanned airplane, and a method therefor. In an information processing system to which the present invention is applied, a drone is provided with: a converter module that operates on a storage battery; an onboard communication means; an FDR module; a drive unit or the like, not illustrated; a leg section that contacts or approaches a landing port; and a charging terminal for supplying power for charging to the storage battery, the charging terminal being disposed in the proximal area. The landing port is the landing port where the drone lands, and has a projection for guiding the leg section onto a planar section."
MICRO UNMANNED AERIAL VEHICLE AND METHOD OF CONTROL THEREFOR,https://lens.org/080-937-406-565-429,2014,"A micro unmanned aerial vehicle or drone (""UAV"") 10 is remotely controlled through an HMI (309), although this remote control is supplemented by and selectively suppressed by an on-board controller (302). The controller operates to control the generation of a sonar bubble that generally encapsulates the UAV. The sonar bubble, which may be ultrasonic in nature, is produced by a multiplicity of sonar lobes generated by specific sonar emitters associated with each axis of movement for the UAV. The emitters produce individual and beamformed sonar lobes (80-102) that partially overlap to provide stereo or bioptic data in the form of individual echo responses detected by axis- specific sonar detectors (40-68). In this way, the on-board controller is able to interpret and then generate 3-D spatial imaging of the physical environment in which the UAV is currently moving or positioned. The controller is therefore able to plot relative and absolute movement of the UAV through the 3-D space by recording measurements from on-board gyroscopes (342), magnetometers (344) and accelerometers (346). Data from the sonar bubble can therefore both proactively prevent collisions with objects by imposing a corrective instruction to rotors (12-18) and other flight control system and can also assess and compensate for sensor drift."
MICRO UNMANNED AERIAL VEHICLE AND METHOD OF CONTROL THEREFOR,https://lens.org/004-078-002-274-861,2014,"A micro unmanned aerial vehicle or drone (""UAV"") 10 is remotely controlled through an HMI (309), although this remote control is supplemented by and selectively suppressed by an on-board controller (302). The controller operates to control the generation of a sonar bubble that generally encapsulates the UAV. The sonar bubble, which may be ultrasonic in nature, is produced by a multiplicity of sonar lobes generated by specific sonar emitters associated with each axis of movement for the UAV. The emitters produce individual and beamformed sonar lobes (80-102) that partially overlap to provide stereo or bioptic data in the form of individual echo responses detected by axis- specific sonar detectors (40-68). In this way, the on-board controller is able to interpret and then generate 3-D spatial imaging of the physical environment in which the UAV is currently moving or positioned. The controller is therefore able to plot relative and absolute movement of the UAV through the 3-D space by recording measurements from on-board gyroscopes (342), magnetometers (344) and accelerometers (346). Data from the sonar bubble can therefore both proactively prevent collisions with objects by imposing a corrective instruction to rotors (12-18) and other flight control system and can also assess and compensate for sensor drift."
Delivery Drone Apparatus,https://lens.org/144-577-656-754-939,2021,"A delivery drone apparatus for automatically delivering packages includes a drone body having a body cavity. A pair of landing skids is coupled to the drone body. A battery, a CPU, and a GPS are coupled within the body cavity. A transceiver is coupled within the body cavity and is in operational communication with the battery, the CPU, and the GPS. The transceiver is configured to communicate with a smartphone. At least one camera is coupled to the drone body. The camera is in operational communication with the battery, the CPU, the GPS, and the transceiver. A plurality of motors are coupled to the drone body. Each motor has a propeller and is in operational communication with the battery and the CPU. An electromagnet is coupled to the drone body. A package magnet is selectively engageable with the electromagnet and is configured to be coupled to a package."
Delivery drone apparatus,https://lens.org/096-646-920-075-562,2022,"A delivery drone apparatus for automatically delivering packages includes a drone body having a body cavity. A pair of landing skids is coupled to the drone body. A battery, a CPU, and a GPS are coupled within the body cavity. A transceiver is coupled within the body cavity and is in operational communication with the battery, the CPU, and the GPS. The transceiver is configured to communicate with a smartphone. At least one camera is coupled to the drone body. The camera is in operational communication with the battery, the CPU, the GPS, and the transceiver. A plurality of motors are coupled to the drone body. Each motor has a propeller and is in operational communication with the battery and the CPU. An electromagnet is coupled to the drone body. A package magnet is selectively engageable with the electromagnet and is configured to be coupled to a package."
Delivery drone apparatus,https://lens.org/096-646-920-075-562,2022,"A delivery drone apparatus for automatically delivering packages includes a drone body having a body cavity. A pair of landing skids is coupled to the drone body. A battery, a CPU, and a GPS are coupled within the body cavity. A transceiver is coupled within the body cavity and is in operational communication with the battery, the CPU, and the GPS. The transceiver is configured to communicate with a smartphone. At least one camera is coupled to the drone body. The camera is in operational communication with the battery, the CPU, the GPS, and the transceiver. A plurality of motors are coupled to the drone body. Each motor has a propeller and is in operational communication with the battery and the CPU. An electromagnet is coupled to the drone body. A package magnet is selectively engageable with the electromagnet and is configured to be coupled to a package."
SYSTEMS AND METHODS FOR CONTROLLING AN UNMANNED AERIAL VEHICLE USING A BODY-ATTACHED REMOTE CONTROL,https://lens.org/138-019-687-219-628,2022,"An electronic device is communicatively connected with an unmanned aerial vehicle (UAV). The device includes an input interface, a first sensor, a second sensor, one or more processors, and memory. The device detects a first user movement from the first sensor attached to a first body portion of a user. It also detects a second user movement from the second sensor attached to a second body portion of the user. The first user movement represents a user instruction to control a flight of the UAV. The device determines one or more parameters associated with the user instruction to control the flight of the UAV based on an interaction between the first user movement and the second user movement. The device transmits to the UAV a wireless signal that is based on the parameters. The UAV adjusts the flight of the UAV in accordance with the parameters."
SYSTEMS AND METHODS FOR CONTROLLING AN UNMANNED AERIAL VEHICLE USING A BODY-ATTACHED REMOTE CONTROL,https://lens.org/138-019-687-219-628,2022,"An electronic device is communicatively connected with an unmanned aerial vehicle (UAV). The device includes an input interface, a first sensor, a second sensor, one or more processors, and memory. The device detects a first user movement from the first sensor attached to a first body portion of a user. It also detects a second user movement from the second sensor attached to a second body portion of the user. The first user movement represents a user instruction to control a flight of the UAV. The device determines one or more parameters associated with the user instruction to control the flight of the UAV based on an interaction between the first user movement and the second user movement. The device transmits to the UAV a wireless signal that is based on the parameters. The UAV adjusts the flight of the UAV in accordance with the parameters."
System and method for recharging battery in augmented reality game system,https://lens.org/097-003-775-401-575,2019,"In an aspect, an augmented reality game system is provided including a mobile smart device such as a smart phone and a remotely controlled drone. The mobile smart phone device is programmed to display an augmented environment, being the real environment viewed by the camera and a virtual environment superimposed over images of the real environment. The drone is controlled via commands transmitted wirelessly by the mobile smart device. The mobile smart device is programmed to execute a video game, which includes activities requiring a player to control the drone in relation to the augmented environment displayed on the mobile smart device video screen. The drone is powered by a rechargeable battery, and the video game includes activities that keep the player occupied with the game while the drone's rechargeable battery recharges."
One-handed remote-control device for aerial system,https://lens.org/008-782-129-517-693,2023,An unmanned aerial system includes a remote controller device and an unmanned aerial vehicle. A user input on the remote controller device indicates a flight command requested by a user. The remote controller device determines a current position and/or orientation of the remote controller device in response to the flight command from the user. The current position and/or orientation is sent to the vehicle. The vehicle responsively determines a desired orientation of the unmanned aerial vehicle as a function of the current position and/or orientation of the remote controller device and operates a lift mechanism to execute a flight operation based on the desired orientation of the unmanned aerial vehicle and the current position of the remote controller device.
ONE-HANDED REMOTE-CONTROL DEVICE FOR AERIAL SYSTEM,https://lens.org/040-214-533-808-323,2020,An unmanned aerial system includes a remote controller device and an unmanned aerial vehicle. A user input on the remote controller device indicates a flight command requested by a user. The remote controller device determines a current position and/or orientation of the remote controller device in response to the flight command from the user. The current position and/or orientation is sent to the vehicle. The vehicle responsively determines a desired orientation of the unmanned aerial vehicle as a function of the current position and/or orientation of the remote controller device and operates a lift mechanism to execute a flight operation based on the desired orientation of the unmanned aerial vehicle and the current position of the remote controller device.
One-handed remote-control device for aerial system,https://lens.org/008-782-129-517-693,2023,An unmanned aerial system includes a remote controller device and an unmanned aerial vehicle. A user input on the remote controller device indicates a flight command requested by a user. The remote controller device determines a current position and/or orientation of the remote controller device in response to the flight command from the user. The current position and/or orientation is sent to the vehicle. The vehicle responsively determines a desired orientation of the unmanned aerial vehicle as a function of the current position and/or orientation of the remote controller device and operates a lift mechanism to execute a flight operation based on the desired orientation of the unmanned aerial vehicle and the current position of the remote controller device.
MICRO UNMANNED AERIAL VEHICLE AND METHOD OF CONTROL THEREFOR,https://lens.org/104-332-990-391-508,2015,A micro unmanned aerial vehicle or drone ('UAV') 10 is remotely controlled through an HMI (309) although this remote control is supplemented by and selectively suppressed by an on board controller (302). The controller operates to control the generation of a sonar bubble that generally encapsulates the UAV. The sonar bubble which may be ultrasonic in nature is produced by a multiplicity of sonar lobes generated by specific sonar emitters associated with each axis of movement for the UAV. The emitters produce individual and beamformed sonar lobes (80 102) that partially overlap to provide stereo or bioptic data in the form of individual echo responses detected by axis specific sonar detectors (40 68). In this way the on board controller is able to interpret and then generate 3 D spatial imaging of the physical environment in which the UAV is currently moving or positioned. The controller is therefore able to plot relative and absolute movement of the UAV through the 3 D space by recording measurements from on board gyroscopes (342) magnetometers (344) and accelerometers (346). Data from the sonar bubble can therefore both proactively prevent collisions with objects by imposing a corrective instruction to rotors (12 18) and other flight control system and can also assess and compensate for sensor drift.
UAV-based smart home system and method,https://lens.org/001-573-467-044-205,2015,"The invention discloses an UAV (unmanned aerial vehicle)-based smart home system and method, belonging to the UAV application technical field. The system comprises an UAV, an intelligent hub device and a smart home device. The UAV is in connection with the intelligent hub device and can perform duplex communication; the intelligent hub device is in connection with the smart home device and can perform duplex communication; the UAV is suitable for collecting object information and sending the object information to the intelligent hub device; the intelligent hub device is suitable for receiving and processing the object information, generating reactive signals, and sending the reactive signals to the smart home device; the smart home device is suitable for receiving the reactive signals, and performing corresponding operations. The UAV-based smart home system and method utilize the UAV to collect user information in real time, actively select an intelligent control mode most suitable for a user, and realize the intelligent control of a plurality of small smart home devices configured at home."
TELEPRESENCE DRONES AND TELEPRESENCE DRONE SYSTEMS,https://lens.org/134-756-413-330-809,2020,"A telepresence drone that is configured to navigate through an environment includes a frame, a propulsion system comprising propellers and motors coupled to the frame, an electronic control unit in communication with the propulsion system, and a hull positioned outside of the frame and the propulsion system. The hull includes a plurality of openings through which the propulsion system acts on air to navigate through the environment."
Telepresence drones and telepresence drone systems,https://lens.org/047-647-600-512-249,2020,"A telepresence drone that is configured to navigate through an environment includes a frame, a propulsion system comprising propellers and motors coupled to the frame, an electronic control unit in communication with the propulsion system, and a hull positioned outside of the frame and the propulsion system. The hull includes a plurality of openings through which the propulsion system acts on air to navigate through the environment."
METHOD FOR PILOTING A ROTARY WING DRONE FOR TAKING AN EXPOSURE THROUGH AN ONBOARD CAMERA WITH MINIMIZATION OF THE DISTURBING MOVEMENTS,https://lens.org/020-512-756-237-142,2013,"The drone (10) comprises an onboard video camera (14) picking up a sequence of images to be transmitted to a remote control. The user selects an exposure mode such as forward or sideways, panoramic or boom plane, tracking, defining a trajectory to be transmitted to the drone. Corresponding setpoint values are generated and applied to a processing subsystem controlling the motors of the drone. Once the drone is stabilized on the prescribed trajectory (38), the exposure by the video camera (14) is activated and the trajectory is stabilized by an open loop control avoiding the oscillations inherent in a servocontrol with feedback loop."
Method for piloting a rotary wing drone for taking an exposure through an onboard camera with minimization of the disturbing movements,https://lens.org/030-856-060-602-334,2017,"The drone (10) comprises an onboard video camera (14) picking up a sequence of images to be transmitted to a remote control. The user selects an exposure mode such as forward or sideways, panoramic or boom plane, tracking, defining a trajectory to be transmitted to the drone. Corresponding setpoint values are generated and applied to a processing subsystem controlling the motors of the drone. Once the drone is stabilized on the prescribed trajectory (38), the exposure by the video camera (14) is activated and the trajectory is stabilized by an open loop control avoiding the oscillations inherent in a servocontrol with feedback loop."
METHOD AND DEVICE OF AUTONOMOUS NAVIGATION,https://lens.org/116-058-163-801-813,2020,"A drone (1) and method of autonomous navigation for tracking objects, wherein computer vision and LiDAR sensors of the drone (1) are used and comprising: detecting by both calibrated computer vision and LiDAR sensors at least an object to be tracked by the drone (1), measuring by the LiDAR sensor a set of features of the detected object, estimating a relative position of the drone (1) and the detected object; commanding the drone (1) to reach a target waypoint which belongs to a set of waypoints determining a trajectory, the set of waypoints being defined based on the measured features of the detected object and the estimated relative position; once the target waypoint is reached by the drone (1), adjusting the trajectory by redefining a next target waypoint from the set of waypoints to keep the detected object centered on the computer vision sensor."
Drone communication system and communication system of drone server,https://lens.org/107-812-630-983-19X,2022,"A drone communication system and method. The system includes a first communication module; a second communication module; and a drone processor electrically connected to the first communication module and the second communication module respectively; and configured to receive and send a heartbeat packet and communication data through a first communication module and a first communication network, so as to communicate with a first communication port of a server; receive and send communication data through a second communication module and a second communication network, so as to communicate with a second communication port of a server. A receiving condition of the heartbeat packet is used to determine whether to use the communication data received by the first communication network or the second communication network."
Drone communication system and communication system of drone server,https://lens.org/107-812-630-983-19X,2022,"A drone communication system and method. The system includes a first communication module; a second communication module; and a drone processor electrically connected to the first communication module and the second communication module respectively; and configured to receive and send a heartbeat packet and communication data through a first communication module and a first communication network, so as to communicate with a first communication port of a server; receive and send communication data through a second communication module and a second communication network, so as to communicate with a second communication port of a server. A receiving condition of the heartbeat packet is used to determine whether to use the communication data received by the first communication network or the second communication network."
DRONE COMMUNICATION SYSTEM AND COMMUNICATION SYSTEM OF DRONE SERVER,https://lens.org/119-096-828-253-281,2020,"A drone communication system and method. The system includes a first communication module; a second communication module; and a drone processor electrically connected to the first communication module and the second communication module respectively; and configured to receive and send a heartbeat packet and communication data through a first communication module and a first communication network, so as to communicate with a first communication port of a server; receive and send communication data through a second communication module and a second communication network, so as to communicate with a second communication port of a server. A receiving condition of the heartbeat packet is used to determine whether to use the communication data received by the first communication network or the second communication network."
"Home, office security, surveillance system using micro mobile drones and IP cameras",https://lens.org/028-737-024-603-539,2017,"A system is provided that includes a security system that protects a secured geographic area including at least a building, a wireless helicopter drone, a camera carried by the drone and a processor of the security system that controls a geographic location of the drone based upon threats detected within the secured area and that records video via the camera from the controlled location."
ARTIFICIAL DEVICE AND METHOD FOR CONTROLLING THE SAME,https://lens.org/099-449-057-851-79X,2020,"Provided are an intelligent device and a method of controlling the same. The intelligent device includes an input unit for obtaining sound information from a photographed image; a processor for controlling to learn the obtained sound information, to recognize a sound based on the result of the learned sound information, and to classify the image based on the recognized sound; and a display for displaying the image. The intelligent device may be connected to an Artificial Intelligence (AI) module, a drone (Unmanned Aerial Vehicle (UAV)), a robot, an augmented reality (AR) device, a virtual reality (VR) device, and a device related to a 5G service."
AUTONOMOUS CONTROL OF UNMANNED AIRCRAFT,https://lens.org/198-285-124-169-864,2018,"A method and apparatus for autonomous control of unmanned aircraft. A method includes, in a memory of a flight controller associated with an unmanned aircraft, identifying a target to be captured, the identifying comprising a plurality of target variables, identifying a type of the unmanned aircraft, selecting one or more capture routines, defining desired data parameters, and storing the plurality of target variables, the one or more capture routines and the desired data parameters in the memory as a flight path. A system includes a computing device having at least a processor, a memory and a display, the display including a graphical user interface (GUI), and an unmanned aircraft including at least a flight controller, a power supply, a propeller system, a landing gear system, a Global Positioning System (GPS) device, a camera system and a one or more sensors, the flight controller wirelessly linked to the computing device which provides flight path control information to the flight controller through the GUI."
REMOTE CONTROLLERS AND STRUCTURES AND SYSTEMS THEREOF,https://lens.org/132-157-482-276-896,2022,A remote controller for controlling a movable device is provided. The remote controller (100) includes a handheld portion (150). A top portion (170) of the handheld portion (150) extends from the handheld portion (150) at an angle. The top portion (170) extends further forward than a remainder of the handheld portion (150).The remote controller (100) further includes a first control component (112) on a first side (110) of the top portion (170) and a second control component (121) on a rear side (120) of the top portion (170). The first control component (112) is configured to control a gimbal of the drone or a payload of the drone (190). The rear side (120) is adjacent to the first side (110). The second control component (121) is configured to control movement of the drone (190).
REMOTE CONTROLLERS AND STRUCTURES AND SYSTEMS THEREOF,https://lens.org/132-157-482-276-896,2022,A remote controller for controlling a movable device is provided. The remote controller (100) includes a handheld portion (150). A top portion (170) of the handheld portion (150) extends from the handheld portion (150) at an angle. The top portion (170) extends further forward than a remainder of the handheld portion (150).The remote controller (100) further includes a first control component (112) on a first side (110) of the top portion (170) and a second control component (121) on a rear side (120) of the top portion (170). The first control component (112) is configured to control a gimbal of the drone or a payload of the drone (190). The rear side (120) is adjacent to the first side (110). The second control component (121) is configured to control movement of the drone (190).
ELECTRONIC DEVICE AND METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE USING THE SAME,https://lens.org/025-209-071-536-65X,2011,"A method for controlling an unmanned aerial vehicle (UAV) using an electronic device determines a designated relay station of the UAV using the electronic device, and creates a new flight path for the UAV according to the designated relay station. The method further directs the UAV to fly to the designated relay station upon the condition that the UAV can arrive at the designated relay station, and directs the UAV to fly to a subsequent relay station along the new flight path upon the condition that the UAV has not arrived at an endpoint of the new flight path."
Electronic device and method for controlling unmanned aerial vehicle using the same,https://lens.org/048-167-242-857-936,2013,"A method for controlling an unmanned aerial vehicle (UAV) using an electronic device determines a designated relay station of the UAV using the electronic device, and creates a new flight path for the UAV according to the designated relay station. The method further directs the UAV to fly to the designated relay station upon the condition that the UAV can arrive at the designated relay station, and directs the UAV to fly to a subsequent relay station along the new flight path upon the condition that the UAV has not arrived at an endpoint of the new flight path."
ROTORCRAFT LANDING DEVICE,https://lens.org/021-341-261-888-341,2018,"A drone 1 loaded with a package takes off from a takeoff device 11 and uses a GPS system to fly to a user house 20 that is a delivery destination of the package as the destination. Further, when the drone 1 approaches the user house that is the destination, the flight of the drones 1 is switched from autonomous navigation using the GPS system to remote control performed by a landing device 21 and an in-house control device 22 installed in the user house 20. The drone 1 lands on the landing device 21 by remote control from the landing device 21 and the in-house control device 22, separates the package 50, and then returns to the warehouse 10 using the GPS system and lands on the takeoff device 11."
TRANSPORT TOOL SYSTEM FOR DRONE WITH SEPARATE CONTROL,https://lens.org/037-374-264-551-914,2018,"A transport tool system having a tool attached to a drone. The drone has a first control system that operates the tool. Preferably the tool is detachable from the drone and is adapted to capture, transport, and release an object to a desired location."
DRONE CONFIGURED FOR MULTIPLE USES,https://lens.org/021-825-645-022-214,2020,"Disclosed is a drone configured for multiple uses. The drone may include a body and a sensor configured to be attached to the body. Further, the drone may include a plurality of arms configured to be attached to the body. Further, a first end of an arm of the plurality of arms may be attached to the body at a first movable joint. Further, the arm may include a first part connected to the first movable joint. Further, the arm may include a second part attached to the first part at a second movable joint. Further, the arm may include a powered rotor including a shaft configured to provide rotatory motion. Further, the powered rotor may be attached to one or more of the first part and the second part. Further, the drone may include a plurality of propeller blades attached to the shaft."
Drone configured for multiple uses,https://lens.org/079-550-146-121-220,2021,"Disclosed is a drone configured for multiple uses. The drone may include a body and a sensor configured to be attached to the body. Further, the drone may include a plurality of arms configured to be attached to the body. Further, a first end of an arm of the plurality of arms may be attached to the body at a first movable joint. Further, the arm may include a first part connected to the first movable joint. Further, the arm may include a second part attached to the first part at a second movable joint. Further, the arm may include a powered rotor including a shaft configured to provide rotatory motion. Further, the powered rotor may be attached to one or more of the first part and the second part. Further, the drone may include a plurality of propeller blades attached to the shaft."
APPLICATION AND METHOD FOR CONTROLLING FLIGHT OF UNINHABITED AIRBORNE VEHICLE,https://lens.org/024-192-434-069-129,2019,"The present invention is to provide an application for controlling the flight of an uninhabited airborne vehicle that detects a person at low cost and high efficiency and controls a drone to keep from hitting against the detected person. The application for controlling the flight of an uninhabited airborne vehicle runs on a smart device 200 connected with an uninhabited airborne vehicle 100, acquires and analyzes the image taken by a camera unit 20 of the smart device, and controls the flight of the uninhabited airborne vehicle to keep the uninhabited airborne vehicle 100 from hitting against the detected person through the uninhabited airborne vehicle flight control module 224."
Application and method for controlling flight of uninhabited airborne vehicle,https://lens.org/051-181-640-553-769,2019,"The present invention is to provide an application for controlling the flight of an uninhabited airborne vehicle that detects a person at low cost and high efficiency and controls a drone to keep from hitting against the detected person. The application for controlling the flight of an uninhabited airborne vehicle runs on a smart device 200 connected with an uninhabited airborne vehicle 100, acquires and analyzes the image taken by a camera unit 20 of the smart device, and controls the flight of the uninhabited airborne vehicle to keep the uninhabited airborne vehicle 100 from hitting against the detected person through the uninhabited airborne vehicle flight control module 224."
Managing dynamic obstructions in air traffic control systems for passenger drones and unmanned aerial vehicles,https://lens.org/122-379-731-491-994,2020,"A passenger drone includes a processing device communicatively coupled to the flight components, cameras, radar, and wireless interfaces; and memory storing instructions that, when executed, cause the processing device to receive notifications from an air traffic control system via the one or more wireless interfaces, the notifications related to previously detected obstructions in a flight path associated with a flight plan of the passenger drone, wherein the previously detected obstructions include objects at or near ground level; monitor proximate airspace with at least one of the one or more cameras and radar; detect an obstruction based on monitoring the proximate airspace, wherein the detected obstruction includes one or more objects at or near ground level in the flight path; alter the flight plan, to be carried out by the flight components, if required, based on the detected obstruction."
FLIGHT CONTROL METHOD AND ELECTRONIC DEVICE FOR SUPPORTING THE SAME,https://lens.org/081-364-544-239-665,2018,"An electronic device includes a communication circuit configured to communicate with an unmanned aerial vehicle (UAV) including a camera, a memory configured to store first flight information including a first flight pattern for a first location and first driving information of the camera, the first driving information corresponding to the first flight pattern, and a processor configured to be operatively connected with the communication circuit and the memory. The processor is configured to determine a flight reference location of the UAV, and control the UAV via the communication circuit such that the UAV flies based on the determined flight reference location and the first flight information."
Flight control method and electronic device for supporting the same,https://lens.org/081-623-174-419-821,2020,"An electronic device includes a communication circuit configured to communicate with an unmanned aerial vehicle (UAV) including a camera, a memory configured to store first flight information including a first flight pattern for a first location and first driving information of the camera, the first driving information corresponding to the first flight pattern, and a processor configured to be operatively connected with the communication circuit and the memory. The processor is configured to determine a flight reference location of the UAV, and control the UAV via the communication circuit such that the UAV flies based on the determined flight reference location and the first flight information."
SYSTEM AND METHOD FOR CONTROLLING SWARM OF REMOTE UNMANNED VEHICLES THROUGH HUMAN GESTURES,https://lens.org/078-464-863-606-08X,2009,A method is disclosed for controlling at least one remotely operated unmanned object. The method may involve defining a plurality of body movements of an operator that correspond to a plurality of operating commands for the unmanned object. Body movements of the operator may be sensed to generate the operating commands. Wireless signals may be transmitted to the unmanned object that correspond to the operating commands that control operation of the unmanned object.
System and method for controlling swarm of remote unmanned vehicles through human gestures,https://lens.org/071-874-833-028-677,2012,A method is disclosed for controlling at least one remotely operated unmanned object. The method may involve defining a plurality of body movements of an operator that correspond to a plurality of operating commands for the unmanned object. Body movements of the operator may be sensed to generate the operating commands. Wireless signals may be transmitted to the unmanned object that correspond to the operating commands that control operation of the unmanned object.
"CONTROL SYSTEM, A METHOD FOR CONTROLLING AN UAV, AND A UAV-KIT",https://lens.org/139-131-077-662-952,2016,"A control system, a method for controlling an unmanned aerial vehicle (UAV), and a UAV-kit are provided. The control system includes an UAV configured to capture an image and transmit the captured image signal. The control system further includes a mobile terminal, wirelessly connected to the UAV, configured to receive the transmitted image signal and send a control signal to the UAV. The mobile terminal includes a pattern recognition data processing module for processing image captured by the UAV."
System for Unassisted Sky Diving,https://lens.org/169-180-820-406-453,2020,"A drone is operated by a sky diver. The drone is interfaced to a parachute pack worn by the sky diver. The sky diver has a device (e.g. smartphone, smartwatch) that communicates with the drone to initiate launch/lift and to release the sky diver. In some embodiments, after the sky diver is released, the drone maneuvers around the sky diver to capture pictures/video of the sky diver. In some embodiments, safety features are included to assure the drone has sufficient battery power to achieve a safe jump altitude above ground level and to assure the release is not made until the drone achieves that safe jump altitude."
SYSTEM FOR UNASSISTED SKY DIVING,https://lens.org/177-967-592-444-974,2020,"A drone is operated by a sky diver. The drone is interfaced to a parachute pack worn by the sky diver. The sky diver has a device (e.g. smartphone, smartwatch) that communicates with the drone to initiate launch/lift and to release the sky diver. In some embodiments, after the sky diver is released, the drone maneuvers around the sky diver to capture pictures/video of the sky diver. In some embodiments, safety features are included to assure the drone has sufficient battery power to achieve a safe jump altitude above ground level and to assure the release is not made until the drone achieves that safe jump altitude."
System for Unassisted Sky Diving,https://lens.org/169-180-820-406-453,2020,"A drone is operated by a sky diver. The drone is interfaced to a parachute pack worn by the sky diver. The sky diver has a device (e.g. smartphone, smartwatch) that communicates with the drone to initiate launch/lift and to release the sky diver. In some embodiments, after the sky diver is released, the drone maneuvers around the sky diver to capture pictures/video of the sky diver. In some embodiments, safety features are included to assure the drone has sufficient battery power to achieve a safe jump altitude above ground level and to assure the release is not made until the drone achieves that safe jump altitude."
System for unassisted sky diving,https://lens.org/195-595-780-649-430,2020,"A drone is operated by a sky diver. The drone is interfaced to a parachute pack worn by the sky diver. The sky diver has a device (e.g. smartphone, smartwatch) that communicates with the drone to initiate launch/lift and to release the sky diver. In some embodiments, after the sky diver is released, the drone maneuvers around the sky diver to capture pictures/video of the sky diver. In some embodiments, safety features are included to assure the drone has sufficient battery power to achieve a safe jump altitude above ground level and to assure the release is not made until the drone achieves that safe jump altitude."
"DRONE MANEUVERING SYSTEM, MANEUVERING SIGNAL TRANSMITTER SET, AND DRONE MANEUVERING METHOD",https://lens.org/069-329-019-051-279,2019,"A drone maneuvering system includes a drone and a maneuvering signal transmitter set. The maneuvering signal transmitter set includes a first transmitter that controls at least forward, reverse, left, and right movement of the drone, and a second transmitter that controls vertical movement and rotational movement of the drone. The first transmitter includes a first auxiliary tool and transmits to the drone a maneuvering signal including tilt information of the first auxiliary tool that accompanies the actions of a pilot, in which the forward, reverse, left, and right movements of the drone are imaged. The second transmitter includes a second auxiliary tool and transmits to the drone a maneuvering signal including rotation information of the second auxiliary tool that accompanies the actions of the pilot, in which the vertical movements and rotational movements of the drone are imaged. The drone operates in accordance with the received maneuvering signals."
"Drone maneuvering system, maneuvering signal transmitter set, and drone maneuvering method",https://lens.org/005-776-705-776-758,2021,"A drone maneuvering system includes a drone and a maneuvering signal transmitter set. The maneuvering signal transmitter set includes a first transmitter that controls at least forward, reverse, left, and right movement of the drone, and a second transmitter that controls vertical movement and rotational movement of the drone. The first transmitter includes a first auxiliary tool and transmits to the drone a maneuvering signal including tilt information of the first auxiliary tool that accompanies the actions of a pilot, in which the forward, reverse, left, and right movements of the drone are imaged. The second transmitter includes a second auxiliary tool and transmits to the drone a maneuvering signal including rotation information of the second auxiliary tool that accompanies the actions of the pilot, in which the vertical movements and rotational movements of the drone are imaged. The drone operates in accordance with the received maneuvering signals."
"UNMANNED AERIAL VEHICLE CONTROL METHOD AND APPARATUS, REMOTE CONTROL DEVICE, AND UNMANNED AERIAL VEHICLE SYSTEM",https://lens.org/156-442-087-814-256,2020,"Embodiments of the present invention disclose an unmanned aerial vehicle (UAV) control method and apparatus, a remote control device, and a UAV system. The UAV control method is applied to a remote control device, the method including: obtaining voice information; determining target flight information of a UAV according to the voice information; obtaining a current flight parameter of the UAV, and generating a control instruction according to the current flight parameter and the target flight information; and sending the control instruction to the UAV, so that the UAV executes a corresponding flight mission according to the control instruction. Through the foregoing manner, according to the embodiments of the present invention, convenience and flexibility of operating a UAV can be improved by simplifying a control operation for the UAV, thereby improving user experience."
Device for the automated charging and discharging of a free-flying autonomously controlled drone,https://lens.org/132-183-514-039-211,2022,"A device for the automated charging and discharging of an object on a free-flying autonomously controlled drone includes a landing platform for the drone, a storage device for storing objects, a robot where the robot is configured to remove an object from the storage apparatus in an automated manner and to provide the object on the landing platform to be picked up by the drone and is configured to pick up in an automated manner an object that is provided on the landing platform by the drone and to deposit the object in the storage apparatus, and a controller where the robot is controllable by the controller."
Device for the automated charging and discharging of a free-flying autonomously controlled drone,https://lens.org/132-183-514-039-211,2022,"A device for the automated charging and discharging of an object on a free-flying autonomously controlled drone includes a landing platform for the drone, a storage device for storing objects, a robot where the robot is configured to remove an object from the storage apparatus in an automated manner and to provide the object on the landing platform to be picked up by the drone and is configured to pick up in an automated manner an object that is provided on the landing platform by the drone and to deposit the object in the storage apparatus, and a controller where the robot is controllable by the controller."
Device for the Automated Charging and Discharging of a Free-Flying Autonomously Controlled Drone,https://lens.org/080-491-442-369-376,2022,"A device for the automated charging and discharging of an object on a free-flying autonomously controlled drone includes a landing platform for the drone, a storage device for storing objects, a robot where the robot is configured to remove an object from the storage apparatus in an automated manner and to provide the object on the landing platform to be picked up by the drone and is configured to pick up in an automated manner an object that is provided on the landing platform by the drone and to deposit the object in the storage apparatus, and a controller where the robot is controllable by the controller."
Rescue device for distressed swimmer,https://lens.org/165-109-063-715-226,2018,"A pilotless drone is equipped with a life preserver or other buoyant device for delivery to a distressed swimmer. The drone includes a vacuum pump and a vacuum release mechanism to remotely release the life preserver once the drone is positioned over the swimmer. A camera on the drone can be used to locate the swimmer, and a remote control operates the release mechanism so that the operation can be performed from a remote location (such as a life guard station, vessel, etc.)."
"System, method, and apparatus for drone positioning control",https://lens.org/040-364-095-733-889,2022,"A system, method, and apparatus for remotely controlled or even autonomous drone positioning control includes a drone, positioning control subsystem, subcontroller, positional or inertial sensor, processor, image sensor, and ground control device, and is configured to i) ascertain a geographical area having a geofence, ii) track at least one subject and an associated physical or digital marker within the geographical area, iii) recognize and process at least one marker geofence, iv) execute at least one positioning plan data set having at least one positioning path, and v) fly the drone per the data sets and paths without crossing a geofence or colliding with any obstacle. The present invention may also be configured to execute one or more commands that cause the drone to switch its position or path relative to priority or sequence-oriented commands, or to move the drone within a certain distance from the marker."
"System, Method, and Apparatus for Drone Positioning Control",https://lens.org/195-804-554-805-835,2021,"A system, method, and apparatus for remotely controlled or even autonomous drone positioning control includes a drone, positioning control subsystem, subcontroller, positional or inertial sensor, processor, image sensor, and ground control device, and is configured to i) ascertain a geographical area having a geofence, ii) track at least one subject and an associated physical or digital marker within the geographical area, iii) recognize and process at least one marker geofence, iv) execute at least one positioning plan data set having at least one positioning path, and v) fly the drone per the data sets and paths without crossing a geofence or colliding with any obstacle. The present invention may also be configured to execute one or more commands that cause the drone to switch its position or path relative to priority or sequence-oriented commands, or to move the drone within a certain distance from the marker."
METHODS AND SYSTEMS FOR DRONE BASED ASSISTANCE,https://lens.org/117-384-128-661-587,2023,"A technique is directed to methods and systems for providing drone-based assistance to a user. Drones may be utilized to aid users in performing tasks, such as assisting a user during an activity. The assistance can include providing a cooling flow of air, spraying a cooling mist of liquid, playing music, providing guidance, providing instructions, communicating with a device(s) to seek medical aid, retrieving sporting equipment, collecting performance metrics, collecting health metrics, or any assistance action. A user can connect to the drone via a device or using a set of built-in algorithms that employ biometric recognition to identify the user. Once activated and linked to the user, the drone can take flight. The drone can fly above, in front, or behind the user at a predetermined or adjustable height and provide airflow or mist from the drone blades to cool the user."
INFORMATION PROCESSING SYSTEM,https://lens.org/080-950-797-109-346,2019,"Provided are a device for communicating with and controlling a small unmanned airplane, and a method therefor. In an information processing system to which the present invention is applied, a drone 2 is provided with: a converter module 10 that operates on a storage battery; an onboard communication means 15; an FDR module; a drive unit or the like, not illustrated; a leg section L that contacts or approaches a landing port P; and a charging terminal T2 for supplying power for charging to the storage battery, the charging terminal T2 being disposed in the proximal area. The landing port P is the landing port where the drone 2 lands, and has a projection B for guiding the leg section L onto a planar section F."
Information processing system,https://lens.org/091-089-054-938-964,2021,"Provided are a device for communicating with and controlling a small unmanned airplane, and a method therefor. In an information processing system to which the present invention is applied, a drone 2 is provided with: a converter module 10 that operates on a storage battery; an onboard communication means 15; an FDR module; a drive unit or the like, not illustrated; a leg section L that contacts or approaches a landing port P; and a charging terminal T2 for supplying power for charging to the storage battery, the charging terminal T2 being disposed in the proximal area. The landing port P is the landing port where the drone 2 lands, and has a projection B for guiding the leg section L onto a planar section F."
SYSTEM AND METHOD FOR SEISMIC DATA ACQUISITION USING SEISMIC DRONES,https://lens.org/020-834-371-127-964,2023,"A seismic drone, a system including a plurality of seismic drones and a base station, and a method of use of the system is disclosed. The seismic drone includes a positioning device, surveillance system, telecommunications transceiver, electronic control system (including a microprocessor), adaptable landing gear, a seismic receiver deployment system, and a seismic data recording system. The seismic drone is capable of take-off, flight to a target location (or locations), landing at the target location, deploying a seismic receiver, and sending data back to a base station or master drone."
AUTONOMOUS DRONE SERVICE SYSTEM,https://lens.org/126-703-671-533-933,2016,"An autonomous drone service system controls at least one drone vehicle configured to autonomously navigate along a flight path to provide one or more services requested by a user. The system includes an electronic service provider device to receive at least one service request signal generated by a user device. The request signal indicates at least one requested service provided by the drone service system and location or locations associated with the requested services. The electronic service provider device that automatically maps the at least one requested service to the at least one drone vehicle, and commands the at least one drone vehicle to perform the service request at the one or more locations."
AUTONOMOUS DRONE SERVICE SYSTEM,https://lens.org/127-872-004-673-004,2018,"An autonomous drone service system controls at least one drone vehicle configured to autonomously navigate along a flight path to provide one or more services requested by a user. The system includes an electronic service provider device to receive at least one service request signal generated by a user device. The request signal indicates at least one requested service provided by the drone service system and location or locations associated with the requested services. The electronic service provider device that automatically maps the at least one requested service to the at least one drone vehicle, and commands the at least one drone vehicle to perform the service request at the one or more locations."
"UNMANNED AERIAL VEHICLE WITH LIGHTS, AUDIO AND VIDEO",https://lens.org/058-175-650-547-219,2016,"An unmanned aerial vehicle (i.e., drone) has a main body having top and bottom halves shaped to resemble beverage bottle caps, and hinged to one another in a clamshell arrangement to surround an interior compartment. The main body is mounted on a landing gear structure having at least two support legs. For propulsion, multiple rotors (e.g., 4 to 6) are each mounted on collapsible booms that are hingedly mounted to the frame structure of the landing gear assembly. The unmanned aerial vehicle is equipped with spotlights, LEDs that change color, laser lights, strobe lights, multiple speakers, a video display screen, a video camera, a video projector, a satellite/GPS antennae, a digital music storage and playing device, a voice recording and playback device connected to the multiple speakers, at least one battery power source and a computer control module (CPU) for wireless communication with a remote control device."
Situation-aware robot,https://lens.org/003-626-727-341-281,2021,"A robot in a location interacts with a user. The robot includes a camera, an image recognition processor, a microphone and a loudspeaker, a voice assistant, and a wireless transceiver. The robot moves around and creates a model of the location, and recognizes changes. It recognizes objects of interest, beings, and situations. The robot monitors the user and recognizes body language and gesture commands, as well as voice commands. The robot communicates with the user, the TV, and other devices. It may move around to monitor for regular and non-regular situations. It anticipates user commands based on a situation. It determines if a situation is desired, and mitigates the situation if undesired. It can seek immediate help for the user in an emergency. It can capture, record, categorize and document events as they happen. It can categorize and document objects in the location."
SITUATION-AWARE ROBOT,https://lens.org/089-681-940-694-045,2020,"A robot in a location interacts with a user. The robot includes a camera, an image recognition processor, a microphone and a loudspeaker, a voice assistant, and a wireless transceiver. The robot moves around and creates a model of the location, and recognizes changes. It recognizes objects of interest, beings, and situations. The robot monitors the user and recognizes body language and gesture commands, as well as voice commands. The robot communicates with the user, the TV, and other devices. It may move around to monitor for regular and non-regular situations. It anticipates user commands based on a situation. It determines if a situation is desired, and mitigates the situation if undesired. It can seek immediate help for the user in an emergency. It can capture, record, categorize and document events as they happen. It can categorize and document objects in the location."
Methods and devices for controlling unmanned aerial vehicle,https://lens.org/187-709-275-047-132,2019,"Methods and devices are provided for controlling an unmanned aerial vehicle. The method includes: obtaining meteorological data in a current location of the UAV when the UAV is in a first flight state, where the first flight state may represent a steady flight state or a take-off preparing state of the UAV; determining a flight hazard level of the UAV based on the meteorological data, where the flight hazard level may represent a hazard level caused to a flight of the UAV by weather; and controlling the UAV to switch to a second flight state when the flight hazard level is a first preset level, where the first preset level may represent a level where the UAV cannot fly safely and the second flight state being used to represent an emergency flight state or a take-off suspended state of the UAV."
Methods and Devices for Controlling Unmanned Aerial Vehicle,https://lens.org/116-945-860-346-028,2017,"Methods and devices are provided for controlling an unmanned aerial vehicle. The method includes: obtaining meteorological data in a current location of the UAV when the UAV is in a first flight state, where the first flight state may represent a steady flight state or a take-off preparing state of the UAV; determining a flight hazard level of the UAV based on the meteorological data, where the flight hazard level may represent a hazard level caused to a flight of the UAV by weather; and controlling the UAV to switch to a second flight state when the flight hazard level is a first preset level, where the first preset level may represent a level where the UAV cannot fly safely and the second flight state being used to represent an emergency flight state or a take-off suspended state of the UAV."
"Cellular command, control and application platform for unmanned aerial vehicles",https://lens.org/156-563-255-707-734,2020,"A device can be configured to detect a physical connection with an unmanned aerial vehicle (UAV) flight controller through an interface. The device can identify a UAV identifier associated with the UAV flight controller and determine, based on the UAV identifier, an application programming interface (API) for communicating with the UAV flight controller. Using the API, the device can establish a communications link with the UAV flight controller and perform an action based on the communications link."
"CELLULAR COMMAND, CONTROL AND APPLICATION PLATFORM FOR UNMANNED AERIAL VEHICLES",https://lens.org/134-936-877-241-183,2018,"A device can be configured to detect a physical connection with an unmanned aerial vehicle (UAV) flight controller through an interface. The device can identify a UAV identifier associated with the UAV flight controller and determine, based on the UAV identifier, an application programming interface (API) for communicating with the UAV flight controller. Using the API, the device can establish a communications link with the UAV flight controller and perform an action based on the communications link."
EMERGENCY RESPONSE DRONE,https://lens.org/035-735-155-959-564,2022,An emergency response drone having a multidirectional propulsion system and data capturing equipment and operatively associated computer system for providing information and situational awareness for emergency areas and related targets.
EMERGENCY RESPONSE DRONE,https://lens.org/035-735-155-959-564,2022,An emergency response drone having a multidirectional propulsion system and data capturing equipment and operatively associated computer system for providing information and situational awareness for emergency areas and related targets.
"Method and apparatus for controlling UAV, and UAV take-off system",https://lens.org/166-730-335-143-092,2017,A method for controlling an unmanned aerial vehicle (UAV) is provided. The UAV comprises at least one rotor. The method includes receiving a take-off preparatory signal; controlling a rotation speed of the at least one rotor with an idle speed rotation in response to the take-off preparatory signal; increasing the rotation speed of the at least one rotor up to a rated speed rotation under predetermined conditions.
CONVERSION OF A WATERCRAFT TO A WATER SKIER CONTROLLED DRONE,https://lens.org/070-135-829-561-027,1992,"Method and apparatus for converting a watercraft (10) having on-board engine (22, 24, 26) and guidance controls (18, 148) into a drone remotely controlled through towing apparatus by the skier riding on skis behind it. A control unit (60) is secured to the watercraft (10). The control unit (60) engages the on-board engine (22, 24, 26) and guidance (18, 148) controls of the watercraft. The engine (22, 24, 26) and guidance (18, 148) controls are operated by the control unit (60) through a remotely located tow handle (170). The tow handle (170) is physically and electronically connected to the control unit (60)."
Drone interacting with a stranger having a cellphone,https://lens.org/076-556-346-148-063,2020,"A pedestrian with a cellphone is in a public area. He sees a drone airborne nearby. He rents the drone to control its actions. His phone shows a signal encoding his electronic address, like a phone number. The drone decodes and sends a message with an URL, deep link or linket. The latter is a brand of the drone owner that maps to a deep link. The deep link designates an app in an app store. He installs the app and interacts with the owner, taking control of the drone for a specified time. The app shows images from the drone camera. The drone can crowdsource public safety. And check the presence of players at locations in Augmented Reality games. It can distribute electronic prizes to players. It can distribute keys for cryptosystems. The drone can pick up data from users at different places. Drone-drone interactions can optimise drone routes. Drones can be used with a blimp and electronic billboards to increase crowd use of an app."
Drone interacting with a stranger having a cellphone,https://lens.org/074-898-385-770-610,2019,"A pedestrian with a cellphone is in a public area. He sees a drone airborne nearby. He rents the drone to control its actions. His phone shows a signal encoding his electronic address, like a phone number. The drone decodes and sends a message with an URL, deep link or linket. The latter is a brand of the drone owner that maps to a deep link. The deep link designates an app in an app store. He installs the app and interacts with the owner, taking control of the drone for a specified time. The app shows images from the drone camera. The drone can crowdsource public safety. And check the presence of players at locations in Augmented Reality games. It can distribute electronic prizes to players. It can distribute keys for cryptosystems. The drone can pick up data from users at different places. Drone-drone interactions can optimise drone routes. Drones can be used with a blimp and electronic billboards to increase crowd use of an app."
MANAGEMENT APP FOR DRONE WITH REMOTE ID,https://lens.org/004-754-102-271-01X,2022,"A global positioning satellite (GPS) receiver (300) and a transmitter (314) are at a base remote from a drone (204), and the transmitter sends GPS packets along with control packets to the drone. In turn, the drone also has a GPS receiver (328) and a transmitter (322) that transmits both the controller and drone GPS coordinates to the remote base. A management app for law enforcement is provided."
MANAGEMENT APP FOR DRONE WITH REMOTE ID,https://lens.org/004-754-102-271-01X,2022,"A global positioning satellite (GPS) receiver (300) and a transmitter (314) are at a base remote from a drone (204), and the transmitter sends GPS packets along with control packets to the drone. In turn, the drone also has a GPS receiver (328) and a transmitter (322) that transmits both the controller and drone GPS coordinates to the remote base. A management app for law enforcement is provided."
DRONE HAVING COLLISION PREVENTION AND RECOVERY FUNCTION,https://lens.org/106-927-487-476-614,2021,"The present invention relates to a drone. The drone includes a main body, a plurality of blades, a plurality of driving motors, a power supply unit, a control unit, a plurality of sensors, and a plurality of switch units, and the switch units are connected to turn on and off power supplied to the driving motor that drives a blade corresponding to the sensor so that the main body does not collide with the obstacle. The blades are mounted on the main body. The driving motors correspond to the respective blades. The power supply unit supplies power. The control unit controls power. The sensors are installed to correspond to the respective blades. The switch units receive a signal detected by one of the sensors and turn on and off the direct supply of power to a corresponding one of the driving motors."
SYSTEMS AND METHODS FOR UNMANNED AERIAL VEHICLES,https://lens.org/185-408-094-375-063,2017,"An unmanned aerial system (UAS) may comprise an unmanned aerial vehicle (UAV), a portable power source, and a tether connecting a UAV to a portable power source. The tether may transmit power from the portable power source to the UAV. The UAS may be controlled by a remote control, which may command the UAV to surveil a location and transmit images back to the controller. The UAV may further include one or more components attached to the UAV, such as a camera, surveillance equipment, a Taser, a LED strobe light, laser, or a claw. A remote control may control the flight of the UAV as well as the functionality of the one or more components. The UAS may be configured to, for example, surveil a location, intercept an intruder, inspect a building, and/or perform crowd control."
Rotary-wing drone comprising autonomous means for determining a position in an absolute coordinate system linked to the ground,https://lens.org/130-705-295-954-737,2016,"The drone comprises: a vertical-view camera (132) pointing downward to pick up images of a scene of the ground overflown by the drone; gyrometer, magnetometer and accelerometer sensors (176); and an altimeter (174). Navigation means determine position coordinates (X, Y, Z) of the drone in an absolute coordinate system linked to the ground. These means are autonomous, operating without reception of external signals. They include image analysis means, adapted to derive a position signal from an analysis of known predetermined patterns (210), present in the scene picked up by the camera, and they implement a predictive-filter estimator (172) incorporating a representation of a dynamic model of the drone, with as an input the position signal, a horizontal speed signal, linear and rotational acceleration signals, and an altitude signal."
Unkown,https://lens.org/145-865-637-559-313,2015,"The drone comprises: a vertical-view camera (132) pointing downward to pick up images of a scene of the ground overflown by the drone; gyrometer, magnetometer and accelerometer sensors (176); and an altimeter (174). Navigation means determine position coordinates (X, Y, Z) of the drone in an absolute coordinate system linked to the ground. These means are autonomous, operating without reception of external signals. They include image analysis means, adapted to derive a position signal from an analysis of known predetermined patterns (210), present in the scene picked up by the camera, and they implement a predictive-filter estimator (172) incorporating a representation of a dynamic model of the drone, with as an input the position signal, a horizontal speed signal, linear and rotational acceleration signals, and an altitude signal."
METHOD AND APPARATUS FOR CONTROLLING UNMANNED AERIAL VEHICLE,https://lens.org/024-067-150-060-023,2017,"A method (300, 500, 600) and an apparatus for controlling an unmanned aerial vehicle (UAV) (110) are provided. The UAV (110) comprises at least one rotor. The method (300, 500, 600) includes: receiving a take-off preparatory signal instructing the UAV (110) to enter into a take-off preparatory state; controlling the at least one rotor of the UAV (110) to rotate at a preset rotation speed in response to the take-off preparatory signal, wherein the preset rotation speed is smaller than a rotation speed that enables the UAV (110) to hover in the air; and controlling the UAV (110) to enter into a hovering mode under a predetermined condition, wherein the UAV (110) is controlled to hover at a predetermined height in the hovering mode."
Remote controller for controlling an external device using voice recognition and method thereof,https://lens.org/079-348-072-139-41X,2022,"A remote controller for controlling an external device by using voice recognition. The remote controller includes a microphone, at least one sensor, a communication interface, and a processor for controlling the microphone, the at least one sensor, and the communication interface. The controller identifies a user utterance intention based on utterance intention information of the remote controller and utterance intention information of the external device. The controller controls whether to supply power to the microphone according to a result of an identification of the user utterance intention, and controls the communication interface to transmit an electrical signal corresponding to a voice of user received through the microphone to a display device."
Remote controller for controlling an external device using voice recognition and method thereof,https://lens.org/079-348-072-139-41X,2022,"A remote controller for controlling an external device by using voice recognition. The remote controller includes a microphone, at least one sensor, a communication interface, and a processor for controlling the microphone, the at least one sensor, and the communication interface. The controller identifies a user utterance intention based on utterance intention information of the remote controller and utterance intention information of the external device. The controller controls whether to supply power to the microphone according to a result of an identification of the user utterance intention, and controls the communication interface to transmit an electrical signal corresponding to a voice of user received through the microphone to a display device."
A Pilotless drone system,https://lens.org/181-067-956-652-370,2018,"A pilotless drone system for capturing images of an area beneath the drone comprises a drone having a body 12, at least four propulsion means (20, fig 8), a battery power source (34, fig 9), a downwardly pointing camera (24, Fig 9) and data storage means on the drone. The drone also has a control system constraining the drone to a substantially vertical predetermined flight path from a departure point. A portable container 10 for housing the drone includes a connector means for connecting to a power supply system for recharging the battery power source on the drone, a calibration means 16 associated with the container for calibrating linear distance on images captured by camera means mounted on the drone. The container also includes an anemometer 14."
System comprising a drone and an entity for controlling this drone,https://lens.org/194-380-875-567-951,2020,"A system includes a drone including an onboard entity; and a control entity for controlling the drone and situated remotely from the drone. The control entity enables an operator to select data for sending to the onboard entity, the onboard entity being adapted to execute actions as a function of the received data. The onboard entity is arranged to generate a message on the basis of the data as produced by the control entity and as received by the onboard entity, and to transmit the message to the control entity. The control entity acts via warning means to generate an information signal representative of said message. The operator can then act via validation means to cause an intention message to be transmitted that authorizes or does not authorize execution of said actions by the drone."
System comprising a drone and an entity for controlling this drone,https://lens.org/194-380-875-567-951,2020,"A system includes a drone including an onboard entity; and a control entity for controlling the drone and situated remotely from the drone. The control entity enables an operator to select data for sending to the onboard entity, the onboard entity being adapted to execute actions as a function of the received data. The onboard entity is arranged to generate a message on the basis of the data as produced by the control entity and as received by the onboard entity, and to transmit the message to the control entity. The control entity acts via warning means to generate an information signal representative of said message. The operator can then act via validation means to cause an intention message to be transmitted that authorizes or does not authorize execution of said actions by the drone."
SYSTEM COMPRISING A DRONE AND AN ENTITY FOR CONTROLLING THIS DRONE,https://lens.org/116-107-840-162-931,2019,"A system includes a drone including an onboard entity; and a control entity for controlling the drone and situated remotely from the drone. The control entity enables an operator to select data for sending to the onboard entity, the onboard entity being adapted to execute actions as a function of the received data. The onboard entity is arranged to generate a message on the basis of the data as produced by the control entity and as received by the onboard entity, and to transmit the message to the control entity. The control entity acts via warning means to generate an information signal representative of said message. The operator can then act via validation means to cause an intention message to be transmitted that authorizes or does not authorize execution of said actions by the drone."
METHOD AND DEVICE OF AUTONOMOUS NAVIGATION,https://lens.org/106-942-201-985-356,2019,"A drone (1) and method of autonomous navigation for tracking objects, wherein computer vision and LiDAR sensors of the drone (1) are used and comprising: - detecting by both calibrated computer vision and LiDAR sensors at least an object to be tracked by the drone (1), - measuring by the LiDAR sensor a set of features of the detected object, - estimating a relative position of the drone (1) and the detected object; - commanding the drone (1) to reach a target waypoint which belongs to a set of waypoints determining a trajectory, the set of waypoints being defined based on the measured features of the detected object and the estimated relative position; - once the target waypoint is reached by the drone (1), adjusting the trajectory by redefining a next target waypoint from the set of waypoints to keep the detected object centered on the computer vision sensor."
Sensor-based controllable LED lighting system with repositionable components and method,https://lens.org/163-692-411-683-506,2017,"A lighting system is provided having a movement system, a light source repositionable via the movement system, a sensor, a controller, and a communication system. The controller may control characteristics of the light emitted by the light source, rotation of the panel by the movement system, and receiving signal information from the sensor. The communication system exchange data between the controller and an external device, the light source and the movement system being remotely controllable by logic received using the controller via the communication system. The light source, the movement system, the controller, the sensor, and the communication system are installable in a drone. Wearable apparatus may be used with the system. Objects may be tracked and illuminated."
LED LIGHTING SYSTEM,https://lens.org/191-580-759-728-372,2015,"A lighting system is provided having a movement system, a light source repositionable via the movement system, a sensor, a controller, and a communication system. The controller may control characteristics of the light emitted by the light source, rotation of the panel by the movement system, and receiving signal information from the sensor. The communication system exchange data between the controller and an external device, the light source and the movement system being remotely controllable by logic received using the controller via the communication system. The light source, the movement system, the controller, the sensor, and the communication system are installable in a drone. Wearable apparatus may be used with the system. Objects may be tracked and illuminated."
Methods and apparatus for data control and transfer with an unmanned aerial vehicle,https://lens.org/110-436-267-653-744,2019,A system has a drone session server to collect drone session information. A drone user machine is in a client relationship with the drone session server. A drone control machine is in a client relationship with the drone session server and a peer-to-peer relationship with the drone user machine. The drone control machine is configured to relay video data from a drone to the drone user machine via a peer-to-peer connection. The drone control machine evaluates user commands collected by the drone user machine that are relayed to the drone control machine via the peer-to-peer connection to produce enforced limits commands to maintain the drone within a three-dimensional geographical fence. The drone control machine sends autopilot commands to the drone to transport the drone from the three-dimensional geographical fence to a land site to complete a drone session.
DRONE ROUTING COMBINING AUTONOMOUS FLIGHT AND ASSIST VEHICLE TRAVEL,https://lens.org/047-412-322-124-871,2023,"A system comprises a drone having autonomous drive capability and an assist vehicle (AV) for transporting the drone in an assisted drive mode in which the drone is held at, and transported by, the assist vehicle. Control hardware and software are programmed to determine drone travel over a route having a first route section in which the drone travels autonomously and a second route section in which the drone travels in the assisted drive mode."
DRONE ROUTING COMBINING AUTONOMOUS FLIGHT AND ASSIST VEHICLE TRAVEL,https://lens.org/153-749-915-092-429,2023,"A system comprises a drone having autonomous drive capability and an assist vehicle (AV) for transporting the drone in an assisted drive mode in which the drone is held at, and transported by, the assist vehicle. Control hardware and software are programmed to determine drone travel over a route having a first route section in which the drone travels autonomously and a second route section in which the drone travels in the assisted drive mode."
DRONE ROUTING COMBINING AUTONOMOUS FLIGHT AND ASSIST VEHICLE TRAVEL,https://lens.org/153-749-915-092-429,2023,"A system comprises a drone having autonomous drive capability and an assist vehicle (AV) for transporting the drone in an assisted drive mode in which the drone is held at, and transported by, the assist vehicle. Control hardware and software are programmed to determine drone travel over a route having a first route section in which the drone travels autonomously and a second route section in which the drone travels in the assisted drive mode."
DRONE ROUTING COMBINING AUTONOMOUS FLIGHT AND ASSIST VEHICLE TRAVEL,https://lens.org/047-412-322-124-871,2023,"A system comprises a drone having autonomous drive capability and an assist vehicle (AV) for transporting the drone in an assisted drive mode in which the drone is held at, and transported by, the assist vehicle. Control hardware and software are programmed to determine drone travel over a route having a first route section in which the drone travels autonomously and a second route section in which the drone travels in the assisted drive mode."
Drone routing combining autonomous flight and assist vehicle travel,https://lens.org/102-419-012-886-998,2023,"A system comprises a drone having autonomous drive capability and an assist vehicle (AV) for transporting the drone in an assisted drive mode in which the drone is held at, and transported by, the assist vehicle. Control hardware and software are programmed to determine drone travel over a route having a first route section in which the drone travels autonomously and a second route section in which the drone travels in the assisted drive mode."
METHOD FOR AUTONOMOUS CONTROLLING OF A REMOTE CONTROLLED AERIAL VEHICLE AND CORRESPONDING SYSTEM,https://lens.org/171-298-426-870-94X,2015,"The invention relates to a method for autonomous controlling of a remote controlled aerial vehicle (50), wherein a flight operator commands the aerial vehicle (50), comprising the steps of: initializing (S1) a data link (30) between the aerial vehicle (50) and a ground segment (40); determining (S2) an operation condition of the data link (30) during use of the data link (30); and issuing (S3) at least one autonomous controlling command, if, as a result of the determining, a loss of the data link (30) is determined."
METHODS AND APPARATUS FOR VEHICLE CONTROL,https://lens.org/029-179-867-972-538,2021,"A drone is deployed from a vehicle, e.g., an autonomous or semi-autonomous vehicle, to assist in vehicle control, e.g. in situations in which the vehicle's embedded sensors may not provide sufficient information to perform a desired operation safely, e.g. backing up, parking in a tight environment, traversing a very narrow road, navigating a sharp corner, or bypassing an obstruction, etc. The deployed drone includes sensors, e.g. cameras, radars, LIDARs, etc, which capture sensor data from a position offset from the vehicle. Captured sensor data is communicated from the drone to a vehicle control system in the vehicle and/or to a remote control system, e.g., including an operator who can make decisions. Based on the captured sensor data, which supplements sensor data collected by the vehicle's embedded sensors, vehicle movement is controlled."
METHOD FOR PHOTOGRAPHING AN UNMANNED AERIAL ROBOT AND A DEVICE FOR SUPPORTING THE SAME IN AN UNMANNED AERIAL VEHICLE SYSTEM,https://lens.org/153-291-569-641-074,2020,"A method of controlling an unmanned aerial robot can include receiving a control message including zone information related to photographing one or more security zones; calculating a photographing zone of a camera of the unmanned aerial robot based on at least one of global positioning system (GPS) information of the unmanned aerial robot, angle information related to a photographing angle of the camera, or operation information related to a zoom operation of the camera; in response to a security zone among the one or more security zones being located on a photographing path of the unmanned aerial robot, comparing the photographing zone with the security zone; and photographing the photographing zone using the camera according to a comparison result of the comparing, in which a portion or an entirety the security zone is included or excluded from the photographing zone based on a specific operation."
Lighter-Than-Air Hovering Drone,https://lens.org/192-222-498-474-621,2022,"A remote controlled lighter-than-air drone assembly that is capable of prolonged flight. The drone assembly utilizes a balloon structure. Separately, a reservoir is provided for holding a smaller second volume of gas. A propulsion system and a control unit are carried by the balloon structure. The control unit selectively transfers the gas from the reservoir to the balloon structure, and selectively vents the gas as needed. A receiver is used to receive command signals from an external source. The command signals are utilized to operate the propulsion system. An electronics suite is provided that can be altered depending upon duties. The electronics suite is used to scan or otherwise monitor an area below the drone assembly. In flight, the balloon structure is translucent and internally illuminated. A projector can be provided for projecting images onto the interior of the balloon structure."
Lighter-Than-Air Hovering Drone,https://lens.org/192-222-498-474-621,2022,"A remote controlled lighter-than-air drone assembly that is capable of prolonged flight. The drone assembly utilizes a balloon structure. Separately, a reservoir is provided for holding a smaller second volume of gas. A propulsion system and a control unit are carried by the balloon structure. The control unit selectively transfers the gas from the reservoir to the balloon structure, and selectively vents the gas as needed. A receiver is used to receive command signals from an external source. The command signals are utilized to operate the propulsion system. An electronics suite is provided that can be altered depending upon duties. The electronics suite is used to scan or otherwise monitor an area below the drone assembly. In flight, the balloon structure is translucent and internally illuminated. A projector can be provided for projecting images onto the interior of the balloon structure."
Method for associating an AI device with a device based on a behavior pattern of a user and an apparatus therefor,https://lens.org/083-419-375-838-082,2022,"Provided are a method of associating an AI device with a device based on a behavior pattern of a user and a device therefor. The method of associating the AI device with the device according to an embodiment of the invention receives a preset behavior pattern of the user sensed by a first camera from the first camera, receives a voice command for controlling an operation of the device from the user, and transmits the voice command to the device, thus allowing devices having no AI function to be used in conjunction with the AI device. The AI device and the dive of the invention may be associated with artificial intelligence modules, drones (unmanned aerial vehicles (UAVs)), robots, augmented reality (AR) devices, virtual reality (VR) devices, devices related to 5G service, etc."
A METHOD FOR ASSOCIATING AN AI DEVICE WITH A DEVICE BASED ON A BEHAVIOR PATTERN OF A USER AND AN APPARATUS THEREFOR,https://lens.org/086-178-913-907-925,2019,"Provided are a method of associating an AI device with a device based on a behavior pattern of a user and a device therefor. The method of associating the AI device with the device according to an embodiment of the invention receives a preset behavior pattern of the user sensed by a first camera from the first camera, receives a voice command for controlling an operation of the device from the user, and transmits the voice command to the device, thus allowing devices having no AI function to be used in conjunction with the AI device. The AI device and the dive of the invention may be associated with artificial intelligence modules, drones (unmanned aerial vehicles (UAVs)), robots, augmented reality (AR) devices, virtual reality (VR) devices, devices related to 5G service, etc."
Method for controlling unmanned aerial vehicle using remote terminal,https://lens.org/061-081-537-714-776,2017,"A method for controlling a UAV using a remote terminal. The remote terminal is capable of wirelessly communicating with the UAV. The method comprises detecting, via a physical input device of the remote terminal, at least one user's action applied to the physical input device; generating a control instruction in response to the detected at least one user's action; and transmitting the control instruction to the UAV."
METHOD AND APPARATUS FOR VEHICLE TO DRONE INTERACTION,https://lens.org/000-867-356-675-925,2019,"A vehicle includes a controller that may be configured to, responsive to receiving a delivery request associated with a drone, periodically transmit a current location, trip route information, and acceleration data of the vehicle to guide the drone to a rendezvous location, and responsive to receiving a proximity notification associated with the drone, open a delivery opening of the vehicle."
METHOD AND APPARATUS FOR VEHICLE TO DRONE INTERACTION,https://lens.org/159-835-326-867-731,2020,"A vehicle includes a controller that may be configured to, responsive to receiving a delivery request associated with a drone, periodically transmit a current location, trip route information, and acceleration data of the vehicle to guide the drone to a rendezvous location, and responsive to receiving a proximity notification associated with the drone, open a delivery opening of the vehicle."
Method and apparatus for vehicle to drone interaction,https://lens.org/055-888-941-188-851,2022,"A vehicle includes a controller that may be configured to, responsive to receiving a delivery request associated with a drone, periodically transmit a current location, trip route information, and acceleration data of the vehicle to guide the drone to a rendezvous location, and responsive to receiving a proximity notification associated with the drone, open a delivery opening of the vehicle."
Method and apparatus for vehicle to drone interaction,https://lens.org/055-888-941-188-851,2022,"A vehicle includes a controller that may be configured to, responsive to receiving a delivery request associated with a drone, periodically transmit a current location, trip route information, and acceleration data of the vehicle to guide the drone to a rendezvous location, and responsive to receiving a proximity notification associated with the drone, open a delivery opening of the vehicle."
Programmable autopilot system for autonomous flight of unmanned aerial vehicles,https://lens.org/112-922-374-217-821,2007,"A system and method for providing autonomous control of unmanned aerial vehicles (UAVs) is disclosed. The system includes a ground station in communication with an unmanned aerial vehicle. The method for providing autonomous control of a UAV includes methods for processing communications between the ground station and UAV. The method also includes procedures for processing commands from the ground station. Also included in the method is a process for estimating the attitude of the UAV and autonomously maintaining its altitude within a desired threshold. The method also includes a process for autonomously orbiting about a specified point in space. Combined with these processes, the method also includes a process for an autonomous takeoff and landing of the UAV."
Programmable autopilot system for autonomous flight of unmanned aerial vehicles,https://lens.org/161-893-500-022-61X,2006,"A system and method for providing autonomous control of unmanned aerial vehicles (UAVs) is disclosed. The system includes a ground station in communication with an unmanned aerial vehicle. The method for providing autonomous control of a UAV includes methods for processing communications between the ground station and UAV. The method also includes procedures for processing commands from the ground station. Also included in the method is a process for estimating the attitude of the UAV and autonomously maintaining its altitude within a desired threshold. The method also includes a process for autonomously orbiting about a specified point in space. Combined with these processes, the method also includes a process for an autonomous takeoff and landing of the UAV."
CONTROLLING HOME AUTOMATION DEVICES THROUGH SECURITY PANEL USING VOICE ASSISTANT,https://lens.org/163-356-113-532-512,2019,"A security panel for controlling home automation devices via a voice assistant device is provided, in which the security panel includes a processor, a memory, a microphone, and a speaker. In one example implementation, the security panel is configured to receive a text input from a user, convert the text input into an audio format via a text-to-speech engine to generate a first voice command for controlling one or more home automation devices via a voice assistant device, and to output the first voice command via the speaker of the security panel, in which the first voice command is received by the voice assistant device via a microphone of the voice assistant device, in which the voice assistant device is configured to control the one or more home automation devices based on the first voice command."
CONTROLLING HOME AUTOMATION DEVICES THROUGH SECURITY PANEL USING VOICE ASSISTANT,https://lens.org/102-155-858-835-696,2021,"A security panel for controlling home automation devices via a voice assistant device is provided, in which the security panel includes a processor, a memory, a microphone, and a speaker. In one example implementation, the security panel is configured to receive a text input from a user, convert the text input into an audio format via a text-to-speech engine to generate a first voice command for controlling one or more home automation devices via a voice assistant device, and to output the first voice command via the speaker of the security panel, in which the first voice command is received by the voice assistant device via a microphone of the voice assistant device, in which the voice assistant device is configured to control the one or more home automation devices based on the first voice command."
DRONE FOR TAKING PICTURES OR VIDEOS,https://lens.org/031-035-370-348-691,2016,"The invention relates to drone (14) configured to communicate with a portable electronic device, such as a smartphone, and being further adapted to take pictures or videos of a user, the drone (14) being an accessory of the electronic device, the drone (14) being movable between a first configuration secured to the electronic device and a second configuration detached from the electronic device, the drone (14) being equipped with a camera (50)."
DRONE CONTROL SYSTEM,https://lens.org/070-334-067-310-353,2018,"A drone control system is communicatively coupled to a plurality of drones. A drone from the plurality drones is selected to travel to a destination site. Predefined rules associated with airspace over public and private areas may be generated and stored. A route is generated for the drone to travel based on an airspace map. Based on one or more constraints over the route specified in the predefined rules, path height is determined. The route is loaded onto drone and the drone is controlled to fly via the route according to the path height to the destination site. The drone's flight is monitored and a signal is received from the drone that the drone completed its travel to the destination site."
"VEHICLE MOUNTED DRONE PORT, DRONE, AND INTEGRATED COMMUNICATION SYSTEM",https://lens.org/139-340-347-124-718,2020,A method for deploying a drone including transporting a drone from a first location to a second location with a vehicle and supplying electricity from the vehicle to the drone while the drone is being transported. A launch command can be initiated from within the vehicle to direct the drone to ascend and hover above the vehicle. The drone can be transported in a drone port mounted to the vehicle.
SELECTIVE VIDEO ANALYTICS BASED ON CAPTURE LOCATION OF VIDEO,https://lens.org/124-379-547-289-772,2023,"A mobile security device such as a drone includes a video camera, a memory that is configured to store a plurality of video analytics algorithms, a position sensor, a transceiver and a controller. The controller is configured to determine a position of the mobile security device based on information provided by the position sensor and to select one or more video analytics algorithms of the plurality of video analytics algorithms based at least in part upon the determined position of the mobile security device. The controller is configured to instruct the video camera to capture video and to perform the selected one or more video analytics algorithms on the captured video, resulting in one or more video analytics results. The controller is configured to transmit one or more of the video analytics results to a remote device via the transceiver."
SELECTIVE VIDEO ANALYTICS BASED ON CAPTURE LOCATION OF VIDEO,https://lens.org/124-379-547-289-772,2023,"A mobile security device such as a drone includes a video camera, a memory that is configured to store a plurality of video analytics algorithms, a position sensor, a transceiver and a controller. The controller is configured to determine a position of the mobile security device based on information provided by the position sensor and to select one or more video analytics algorithms of the plurality of video analytics algorithms based at least in part upon the determined position of the mobile security device. The controller is configured to instruct the video camera to capture video and to perform the selected one or more video analytics algorithms on the captured video, resulting in one or more video analytics results. The controller is configured to transmit one or more of the video analytics results to a remote device via the transceiver."
SELECTIVE VIDEO ANALYTICS BASED ON CAPTURE LOCATION OF VIDEO,https://lens.org/141-676-992-995-357,2023,"A mobile security device such as a drone includes a video camera, a memory that is configured to store a plurality of video analytics algorithms, a position sensor, a transceiver and a controller. The controller is configured to determine a position of the mobile security device based on information provided by the position sensor and to select one or more video analytics algorithms of the plurality of video analytics algorithms based at least in part upon the determined position of the mobile security device. The controller is configured to instruct the video camera to capture video and to perform the selected one or more video analytics algorithms on the captured video, resulting in one or more video analytics results. The controller is configured to transmit one or more of the video analytics results to a remote device via the transceiver."
SELECTIVE VIDEO ANALYTICS BASED ON CAPTURE LOCATION OF VIDEO,https://lens.org/141-676-992-995-357,2023,"A mobile security device such as a drone includes a video camera, a memory that is configured to store a plurality of video analytics algorithms, a position sensor, a transceiver and a controller. The controller is configured to determine a position of the mobile security device based on information provided by the position sensor and to select one or more video analytics algorithms of the plurality of video analytics algorithms based at least in part upon the determined position of the mobile security device. The controller is configured to instruct the video camera to capture video and to perform the selected one or more video analytics algorithms on the captured video, resulting in one or more video analytics results. The controller is configured to transmit one or more of the video analytics results to a remote device via the transceiver."
"Unmanned aerial vehicle, remote controller, and control method thereof",https://lens.org/051-540-821-393-479,2020,The present disclosure provides a control method for an UAV (Unmanned Aerial Vehicle) and a remote controller. The method includes transmitting a signal to the remote controller through a first communication network; receiving a first signal switching command; and switching from the first communication network to a second communication network to transmit the signal to the remote controller.
"UNMANNED AERIAL VEHICLE, REMOTE CONTROLLER, AND CONTROL METHOD THEREOF",https://lens.org/018-053-679-041-071,2019,The present disclosure provides a control method for an UAV (Unmanned Aerial Vehicle) and a remote controller. The method includes transmitting a signal to the remote controller through a first communication network; receiving a first signal switching command; and switching from the first communication network to a second communication network to transmit the signal to the remote controller.
"Method, apparatus and electronic device for controlling smart home device",https://lens.org/066-551-558-647-723,2017,"A method, an apparatus, and an electronic device are provided for controlling a smart home device. In the method, the device detects a user trigger operation from a user, where the user trigger operation indicates a request for a control permission to control the smart home device. The device determines whether a wearable device associated with the user is located within a preset distance range. When determining that the wearable device is located within the preset distance range, the device grants the user the control permission."
"METHOD, APPARATUS AND ELECTRONIC DEVICE FOR CONTROLLING SMART HOME DEVICE",https://lens.org/092-365-641-682-582,2016,"A method, an apparatus, and an electronic device are provided for controlling a smart home device. In the method, the device detects a user trigger operation from a user, where the user trigger operation indicates a request for a control permission to control the smart home device. The device determines whether a wearable device associated with the user is located within a preset distance range. When determining that the wearable device is located within the preset distance range, the device grants the user the control permission."
Drone assistance apparatus with charging system and method,https://lens.org/163-198-205-871-801,2019,"A drone receiving apparatus is provided including a landing area including a platform, a lighting system, and/or a surface on which a drone is receivable, a charging plate for providing electrical power to charge the drone received by the landing area, and a communication system by which a signal is communicable to exchange data with the drone that is within a communicable proximity to the communication system. A method to receive a drone is also provided."
DRONE ASSISTANCE APPARATUS WITH CHARGING SYSTEM AND METHOD,https://lens.org/156-589-826-862-224,2017,"A drone receiving apparatus is provided including a landing area including a platform, a lighting system, and/or a surface on which a drone is receivable, a charging plate for providing electrical power to charge the drone received by the landing area, and a communication system by which a signal is communicable to exchange data with the drone that is within a communicable proximity to the communication system. A method to receive a drone is also provided."
DRONE ASSISTANCE APPARATUS WITH CHARGING SYSTEM AND METHOD,https://lens.org/156-589-826-862-224,2017,"A drone receiving apparatus is provided including a landing area including a platform, a lighting system, and/or a surface on which a drone is receivable, a charging plate for providing electrical power to charge the drone received by the landing area, and a communication system by which a signal is communicable to exchange data with the drone that is within a communicable proximity to the communication system. A method to receive a drone is also provided."
UNMANNED AERIAL VEHICLES,https://lens.org/076-107-568-431-020,2021,An unmanned aerial vehicle (UAV) comprises a controller. The controller of the UAV causes the UAV to access an interior of an object. The controller of the UAV causes the UAV to clean at least part of the interior of the object.
Motion and image-based control system,https://lens.org/199-801-460-464-285,2021,"Systems, devices, media, and methods are presented for detecting and interpreting motion of a device and a remote object to control operations of the device. The systems and methods identify a sensor input within a drone. The sensor input indicates movement of the drone within a three dimensional space. The systems and methods determine one or more movement attributes from the sensor input and, in response to the one or more movement attributes, selects one or more maneuvers corresponding to at least one movement attribute. The system and methods then execute the one or more maneuvers by controlling one or more drone control components to move the drone within the three dimensional space."
Motion and image-based control system,https://lens.org/054-647-628-779-379,2020,"Systems, devices, media, and methods are presented for detecting and interpreting motion of a device and a remote object to control operations of the device. The systems and methods identify a sensor input within a drone. The sensor input indicates movement of the drone within a three dimensional space. The systems and methods determine one or more movement attributes from the sensor input and, in response to the one or more movement attributes, selects one or more maneuvers corresponding to at least one movement attribute. The system and methods then execute the one or more maneuvers by controlling one or more drone control components to move the drone within the three dimensional space."
Motion and image-based control system,https://lens.org/054-647-628-779-379,2020,"Systems, devices, media, and methods are presented for detecting and interpreting motion of a device and a remote object to control operations of the device. The systems and methods identify a sensor input within a drone. The sensor input indicates movement of the drone within a three dimensional space. The systems and methods determine one or more movement attributes from the sensor input and, in response to the one or more movement attributes, selects one or more maneuvers corresponding to at least one movement attribute. The system and methods then execute the one or more maneuvers by controlling one or more drone control components to move the drone within the three dimensional space."
Automated drone systems,https://lens.org/146-371-814-799-649,2018,"An automated drone security system for surveilling a location includes one or more drones with onboard sensors and an imaging device for measuring surveillance data. The surveillance data may include images, telemetry data, infrared data, or other detectable information of the location. Drones may be capable of executing one or multiple flight operations as well as storing and transmitting the surveillance data to a server assembly operable for coordinating the drone and receiving the surveillance data. A drone dock may be included for drone launching, landing, and/or storing the drones. A user computing device may be in communication with the server assembly and the drone(s), the user computing device being capable of receiving user input and displaying surveillance data from the drone. Flight operations associated with surveilling the location may be automatically and/or manually controlled by the user computing device and/or or the server assembly in connection with the location."
AUTOMATED DRONE SYSTEMS,https://lens.org/184-453-240-851-942,2019,"An automated drone security system for surveilling a location includes one or more drones with onboard sensors and an imaging device for measuring surveillance data. The surveillance data may include images, telemetry data, infrared data, or other detectable information of the location. Drones may be capable of executing one or multiple flight operations as well as storing and transmitting the surveillance data to a server assembly operable for coordinating the drone and receiving the surveillance data. A drone dock may be included for drone launching, landing, and/or storing the drones. A user computing device may be in communication with the server assembly and the drone(s), the user computing device being capable of receiving user input and displaying surveillance data from the drone. Flight operations associated with surveilling the location may be automatically and/or manually controlled by the user computing device and/or or the server assembly in connection with the location."
Automated drone systems,https://lens.org/143-903-392-408-366,2022,"An automated drone security system for surveilling a location includes one or more drones with onboard sensors and an imaging device for measuring surveillance data. The surveillance data may include images, telemetry data, infrared data, or other detectable information of the location. Drones may be capable of executing one or multiple flight operations as well as storing and transmitting the surveillance data to a server assembly operable for coordinating the drone and receiving the surveillance data. A drone dock may be included for drone launching, landing, and/or storing the drones. A user computing device may be in communication with the server assembly and the drone(s), the user computing device being capable of receiving user input and displaying surveillance data from the drone. Flight operations associated with surveilling the location may be automatically and/or manually controlled by the user computing device and/or or the server assembly in connection with the location."
AUTOMATED DRONE SYSTEMS,https://lens.org/118-447-744-733-873,2018,"An automated drone security system for surveilling a location includes one or more drones with onboard sensors and an imaging device for measuring surveillance data. The surveillance data may include images, telemetry data, infrared data, or other detectable information of the location. Drones may be capable of executing one or multiple flight operations as well as storing and transmitting the surveillance data to a server assembly operable for coordinating the drone and receiving the surveillance data. A drone dock may be included for drone launching, landing, and/or storing the drones. A user computing device may be in communication with the server assembly and the drone(s), the user computing device being capable of receiving user input and displaying surveillance data from the drone. Flight operations associated with surveilling the location may be automatically and/or manually controlled by the user computing device and/or or the server assembly in connection with the location."
AUTOMATED DRONE SYSTEMS,https://lens.org/113-562-078-277-205,2016,"An automated drone security system for surveilling a location includes one or more drones with onboard sensors and an imaging device for measuring surveillance data. The surveillance data may include images, telemetry data, infrared data, or other detectable information of the location. Drones may be capable of executing one or multiple flight operations as well as storing and transmitting the surveillance data to a server assembly operable for coordinating the drone and receiving the surveillance data. A drone dock may be included for drone launching, landing, and/or storing the drones. A user computing device may be in communication with the server assembly and the drone(s), the user computing device being capable of receiving user input and displaying surveillance data from the drone. Flight operations associated with surveilling the location may be automatically and/or manually controlled by the user computing device and/or or the server assembly in connection with the location."
Automated drone systems,https://lens.org/050-129-823-743-368,2019,"An automated drone security system for surveilling a location includes one or more drones with onboard sensors and an imaging device for measuring surveillance data. The surveillance data may include images, telemetry data, infrared data, or other detectable information of the location. Drones may be capable of executing one or multiple flight operations as well as storing and transmitting the surveillance data to a server assembly operable for coordinating the drone and receiving the surveillance data. A drone dock may be included for drone launching, landing, and/or storing the drones. A user computing device may be in communication with the server assembly and the drone(s), the user computing device being capable of receiving user input and displaying surveillance data from the drone. Flight operations associated with surveilling the location may be automatically and/or manually controlled by the user computing device and/or or the server assembly in connection with the location."
Method for Assigning a System for Controlling a Remotely-Controlled Vehicle,https://lens.org/066-038-686-074-010,2022,"A method for assigning a control system for controlling a remotely controlled vehicle, called a drone, the system being able to transmit data relating to at least one communication service and including a drone and a control entity for controlling the drone. The assignment method makes it possible to associate a set of services that a system supports with the system, and thus to correlate quality of service or security requirements with types of mission and profiles of drones."
Method for Assigning a System for Controlling a Remotely-Controlled Vehicle,https://lens.org/066-038-686-074-010,2022,"A method for assigning a control system for controlling a remotely controlled vehicle, called a drone, the system being able to transmit data relating to at least one communication service and including a drone and a control entity for controlling the drone. The assignment method makes it possible to associate a set of services that a system supports with the system, and thus to correlate quality of service or security requirements with types of mission and profiles of drones."
UNMANNED AERIAL VEHICLE FOR INTERACTING WITH A PET,https://lens.org/162-925-846-161-705,2017,"An unmanned aerial vehicle for interacting with a pet. The unmanned aerial vehicle includes a processor-based monitoring device to provide a behavioral assessment of the pet, an activity recommender to select an activity program dependent on the behavioral assessment, a motor mounted on the unmanned aerial vehicle to provide aerial movement based on the activity program, and an activity coordinator to perform a function based on the activity program. The function includes activating feedback outputs upon completion of the activity program."
Unmanned aerial vehicle for interacting with a pet,https://lens.org/175-281-113-075-886,2017,"An unmanned aerial vehicle for interacting with a pet. The unmanned aerial vehicle includes a processor-based monitoring device to provide a behavioral assessment of the pet, an activity recommender to select an activity program dependent on the behavioral assessment, a motor mounted on the unmanned aerial vehicle to provide aerial movement based on the activity program, and an activity coordinator to perform a function based on the activity program. The function includes activating feedback outputs upon completion of the activity program."
UNMANNED AERIAL VEHICLE FOR INTERACTING WITH A PET,https://lens.org/068-108-147-975-729,2017,"An unmanned aerial vehicle for interacting with a pet. The unmanned aerial vehicle includes a processor-based monitoring device to provide a behavioral assessment of the pet, an activity recommender to select an activity program dependent on the behavioral assessment, a motor mounted on the unmanned aerial vehicle to provide aerial movement based on the activity program, and an activity coordinator to perform a function based on the activity program. The function includes activating feedback outputs upon completion of the activity program."
"DRONE, METHOD FOR CONTROLLING FLIGHT, AND RECORDING MEDIUM STORING PROGRAM",https://lens.org/152-652-447-764-337,2018,"A drone includes a time measuring unit that obtains a present time, a flight possible area changing unit that determines a flight possible area thereof in accordance with a difference between an end of a time period for which the flight thereof is permitted and the present time, and a flight control unit that controls the drone such that the drone flies within the flight possible area."
"Drone, method for controlling flight, and recording medium storing program",https://lens.org/003-658-304-429-739,2019,"A drone includes a time measuring unit that obtains a present time, a flight possible area changing unit that determines a flight possible area thereof in accordance with a difference between an end of a time period for which the flight thereof is permitted and the present time, and a flight control unit that controls the drone such that the drone flies within the flight possible area."
Remote Control Device,https://lens.org/112-486-503-284-847,2009,"A remote control device for wirelessly controlling a second device is disclosed that allows the user to remotely control the second device using spoken commands. The remote control device is preferably dimensioned to be useful as a handheld device. The remote control device includes one or more microphones into which the user can speak a command. The remote control device also includes a transmitter, for example a radio frequency transmitter and/or an optical transmitter, for transmitting a signal to the second device based on the user's spoken command."
PERSONALITY SHARING AMONG DRONE SWARM,https://lens.org/043-426-508-300-134,2019,"A drone identifies situational context (based on signals from at least one sensor) and selects an action in response to the situational context, based on a personality of the drone. The drone then communicates its personality to other drones within a swarm of drones, the drone being a member of the swarm of drones."
Personality sharing among drone swarm,https://lens.org/140-314-940-053-080,2019,"A drone identifies situational context (based on signals from at least one sensor) and selects an action in response to the situational context, based on a personality of the drone. The drone then communicates its personality to other drones within a swarm of drones, the drone being a member of the swarm of drones."
PERSONALITY SHARING AMONG DRONE SWARM,https://lens.org/038-164-458-397-194,2018,"A drone identifies situational context (based on signals from at least one sensor) and selects an action in response to the situational context, based on a personality of the drone. The drone then communicates its personality to other drones within a swarm of drones, the drone being a member of the swarm of drones."
Personality sharing among drone swarm,https://lens.org/024-466-292-526-819,2020,"A drone identifies situational context (based on signals from at least one sensor) and selects an action in response to the situational context, based on a personality of the drone. The drone then communicates its personality to other drones within a swarm of drones, the drone being a member of the swarm of drones."
Drone for autonomously completing a task,https://lens.org/002-129-745-521-178,2019,"In some embodiments, apparatuses and methods are provided herein useful to autonomously completing a task. In some embodiments, a drone comprises a propulsion mechanism, an attachment point configured to releasably receive and secure at least one tool to the drone, a plurality of sensors configured to detect information regarding a performance of the task by the drone when a particular tool is secured to the attachment point, and a control circuit configured to receive the information regarding the performance of the task by the drone, determine that the performance of the task is inadequate, and in response to a determination that the performance of the task is inadequate, at least one of (a) select a new tool with which to perform the task to replace the particular tool and (b) transmit a notification indicating that a new drone is needed to perform the task using the particular tool."
DRONE FOR AUTONOMOUSLY COMPLETING A TASK,https://lens.org/181-913-568-731-595,2018,"In some embodiments, apparatuses and methods are provided herein useful to autonomously completing a task. In some embodiments, a drone comprises a propulsion mechanism, an attachment point configured to releasably receive and secure at least one tool to the drone, a plurality of sensors configured to detect information regarding a performance of the task by the drone when a particular tool is secured to the attachment point, and a control circuit configured to receive the information regarding the performance of the task by the drone, determine that the performance of the task is inadequate, and in response to a determination that the performance of the task is inadequate, at least one of (a) select a new tool with which to perform the task to replace the particular tool and (b) transmit a notification indicating that a new drone is needed to perform the task using the particular tool."
"HOME, OFFICE SECURITY, SURVEILLANCE SYSTEM USING MICRO MOBILE DRONES AND IP CAMERAS",https://lens.org/172-502-338-337-119,2017,"A system including a security system that protects a secured geographic area including at least a building, a wireless helicopter drone, a camera carried by the drone and a processor of the security system that controls a geographic location of the drone based upon threats detected within the secured area and that records video via the camera from the controlled location."
"HOME, OFFICE SECURITY, SURVEILLANCE SYSTEM USING MICRO MOBILE DRONES AND IP CAMERAS",https://lens.org/144-090-230-136-717,2017,"A system including a security system that protects a secured geographic area including at least a building, a wireless helicopter drone, a camera carried by the drone and a processor of the security system that controls a geographic location of the drone based upon threats detected within the secured area and that records video via the camera from the controlled location."
UNMANNED AERIAL VEHICLE AND CONTROL METHOD THEREOF,https://lens.org/166-068-996-687-907,2012,"A method for controlling an unmanned aerial vehicle (UAV) using a control device receives a first direction of the control device and a control command of the UAV, obtains a second direction of the UAV, and calculates an angle deviation between the first direction and the second direction. The method further adjusts the second direction of the UAV according to the angle deviation, and controls a flight direction of the UAV according to the received control command."
REMOTE SENSOR DATA ACQUISITION USING AUTONOMOUS DRONES,https://lens.org/116-085-573-673-723,2020,"An autonomous drone is programed with the geo-location of one or more remote sensors, and the autonomous drone then flies to each of the remote sensors to acquire a most recent sensing data record, and then return to a base where the most recent data record for each remote sensor can be transferred to a computing system. Upon arriving at the location of each remote sensor, the drone causes the remote sensor to activate a local area radio transceiver so that a communication link can be established between the drone and the remote sensor."
Remote sensor data acquisition using autonomous drones,https://lens.org/155-881-290-201-20X,2022,"An autonomous drone is programed with the geo-location of one or more remote sensors, and the autonomous drone then flies to each of the remote sensors to acquire a most recent sensing data record, and then return to a base where the most recent data record for each remote sensor can be transferred to a computing system. Upon arriving at the location of each remote sensor, the drone causes the remote sensor to activate a local area radio transceiver so that a communication link can be established between the drone and the remote sensor."
Remote sensor data acquisition using autonomous drones,https://lens.org/155-881-290-201-20X,2022,"An autonomous drone is programed with the geo-location of one or more remote sensors, and the autonomous drone then flies to each of the remote sensors to acquire a most recent sensing data record, and then return to a base where the most recent data record for each remote sensor can be transferred to a computing system. Upon arriving at the location of each remote sensor, the drone causes the remote sensor to activate a local area radio transceiver so that a communication link can be established between the drone and the remote sensor."
SYSTEMS AND METHODS FOR DRONES AS A SERVICE,https://lens.org/179-297-139-425-612,2022,"A technique is described for implementing drones as a service. As an example, a drone may receive instructions from one or more network elements, coordinate operations with the one or more network elements, and perform at least one task associated with the instructions. The drone may deliver a container to a first location and perform object recognition to validate an object of a subscriber being delivered to a second location. The drone may measure the weight and dimensions of the object to confirm the object is within operating guidelines. After verifying the object is within operating guidelines, the drone may transport the container containing the object to the second location."
UNMANNED AERIAL VEHICLE,https://lens.org/153-721-505-388-994,2019,"A method for controlling an unmanned aerial vehicle (UAV) comprises receiving a position of a target in an image, obtaining a flight height of the UAV relative to a ground, and controlling a flight of the UAV according at least to the position of the target in the image and the flight height."
DRONE-HOSTED CONSTRUCTION DEFECT REMEDIATION,https://lens.org/014-681-314-053-661,2022,"A system includes processing circuitry and a drone. The drone includes a dispenser subassembly that includes a housing comprising an aerosol dispensing system and configured to receive a syringe such that an applicator of the syringe is positioned distally from the housing; a trigger that is positioned in contact with a nozzle of the aerosol dispensing system; an actuator arm; and an actuator motor configured to move the actuator arm in a reciprocating motion. Control logic of the drone is configured to navigate, based on navigation instructions received from the processing circuitry, the drone to an area associated with an object of potential survey interest (OoPSI) such that the applicator of the syringe or the nozzle of the aerosol dispensing system is proximate to the area associated with the OoPSI."
DRONE-HOSTED CONSTRUCTION DEFECT REMEDIATION,https://lens.org/014-681-314-053-661,2022,"A system includes processing circuitry and a drone. The drone includes a dispenser subassembly that includes a housing comprising an aerosol dispensing system and configured to receive a syringe such that an applicator of the syringe is positioned distally from the housing; a trigger that is positioned in contact with a nozzle of the aerosol dispensing system; an actuator arm; and an actuator motor configured to move the actuator arm in a reciprocating motion. Control logic of the drone is configured to navigate, based on navigation instructions received from the processing circuitry, the drone to an area associated with an object of potential survey interest (OoPSI) such that the applicator of the syringe or the nozzle of the aerosol dispensing system is proximate to the area associated with the OoPSI."
AERIAL DRONE,https://lens.org/024-760-959-568-724,2022,"An aerial drone is configured to capture aerial objects. The aerial drone has an airframe, a propulsion system mounted to the airframe, and a capturing device mounted to the airframe. The propulsion system is configured to control the movement of the aerial drone. The capturing device is configured to receive and capture an aerial object located above the aerial drone. A method of capturing an aerial object using the aerial drone is also contemplated."
SYSTEM AND METHOD OF LAST MILE DELIVERY,https://lens.org/156-714-995-147-619,2023,A vehicle to transport a first drone and a second drone includes a controller. The controller is configured to release the first drone from the vehicle with instructions for the first drone to move a package container to a package container reception point. The controller is configured to release the second drone from the vehicle. The second drone is configured to provide data to the first drone. The data is related to a route from the vehicle to the package container reception point.
DEVICE AND METHOD FOR BLASTING AVALANCHES,https://lens.org/171-962-638-545-105,2022,"A device and a method for blasting avalanches. The device comprises a drone, and an explosive charge attached to the drone in a freely suspended manner by means of a cord. An ignition mechanism is provided for igniting the explosive charge. The ignition mechanism can be triggered by remote control or automatically. Any desired destinations can be approached using this device in order to trigger avalanches. In this manner, the explosive charge can be positioned above the snow cover to be blasted."
DEVICE AND METHOD FOR BLASTING AVALANCHES,https://lens.org/171-962-638-545-105,2022,"A device and a method for blasting avalanches. The device comprises a drone, and an explosive charge attached to the drone in a freely suspended manner by means of a cord. An ignition mechanism is provided for igniting the explosive charge. The ignition mechanism can be triggered by remote control or automatically. Any desired destinations can be approached using this device in order to trigger avalanches. In this manner, the explosive charge can be positioned above the snow cover to be blasted."
Unmanned Aerial Vehicle Having an Insect Trap,https://lens.org/120-063-247-316-998,2019,"Embodiments of unmanned, rotary wing drones are described herein that include an insect trap for luring and capturing mosquitoes or other insects. The drone can include a set of propulsion units, each having a motor and propeller, and that collectively provide sufficient lift when operating to allow the drone to fly. A flight controller can be used to send and receive information and control a flight of the drone according to a flight plan stored on the drone. The insect trap includes a funnel or other mechanism to allow only for one-way movement of an insect into a container. To lure the insect into the trap, ultraviolet light can be shone on high-surface titanium dioxide powder that is stored within a mesh bag. A battery or other power source can be used to power the various components, and solar panels can be used to charge the battery when the drone has landed."
Method and Apparatus for Harvesting Produce,https://lens.org/138-179-644-112-436,2020,"A system for harvesting produce from a tree has a drone capable of hovering, a video camera gathering visual data of movement, a cutting implement, a remote control station with a display screen, wireless circuitry, and input mechanisms to control movement of the drone and operation of the cutting implement, and circuitry in the body of the drone enabling two-way communication with the remote control station, transmission of video data from the video camera, and response to commands from the remote control station. The video data from the camera on the drone is displayed on the display screen of the remote control station, and an operator viewing the display screen operates the input mechanisms, maneuvering the drone to position the cutting implement relative to produce in the tree, and triggers the cutting implement by command, severing a stem to separate the produce, causing the produce to fall from the tree."
Method and Apparatus for Harvesting Produce,https://lens.org/064-791-880-091-962,2017,"A system for harvesting produce from a tree has a drone capable of hovering, a video camera gathering visual data of movement, a cutting implement, a remote control station with a display screen, wireless circuitry, and input mechanisms to control movement of the drone and operation of the cutting implement, and circuitry in the body of the drone enabling two-way communication with the remote control station, transmission of video data from the video camera, and response to commands from the remote control station. The video data from the camera on the drone is displayed on the display screen of the remote control station, and an operator viewing the display screen operates the input mechanisms, maneuvering the drone to position the cutting implement relative to produce in the tree, and triggers the cutting implement by command, severing a stem to separate the produce, causing the produce to fall from the tree."
Method of controlling an automated drone for harvesting produce,https://lens.org/009-576-303-960-252,2022,"A system for harvesting produce from a tree has a drone capable of hovering, a video camera gathering visual data of movement, a cutting implement, a remote control station with a display screen, wireless circuitry, and input mechanisms to control movement of the drone and operation of the cutting implement, and circuitry in the body of the drone enabling two-way communication with the remote control station, transmission of video data from the video camera, and response to commands from the remote control station. The video data from the camera on the drone is displayed on the display screen of the remote control station, and an operator viewing the display screen operates the input mechanisms, maneuvering the drone to position the cutting implement relative to produce in the tree, and triggers the cutting implement by command, severing a stem to separate the produce, causing the produce to fall from the tree."
Automated drone for harvesting produce,https://lens.org/096-650-301-510-811,2020,"A system for harvesting produce from a tree has a drone capable of hovering, a video camera gathering visual data of movement, a cutting implement, a remote control station with a display screen, wireless circuitry, and input mechanisms to control movement of the drone and operation of the cutting implement, and circuitry in the body of the drone enabling two-way communication with the remote control station, transmission of video data from the video camera, and response to commands from the remote control station. The video data from the camera on the drone is displayed on the display screen of the remote control station, and an operator viewing the display screen operates the input mechanisms, maneuvering the drone to position the cutting implement relative to produce in the tree, and triggers the cutting implement by command, severing a stem to separate the produce, causing the produce to fall from the tree."
DRONE-BASED VEHICLE ILLUMINATION,https://lens.org/143-204-172-882-16X,2018,A computer is programmed to deploy an aerial drone to fly within a specified distance of a first vehicle. The computer is programmed to detect a second vehicle and then activate an aerial drone light.
Drone-based vehicle illumination,https://lens.org/027-727-392-613-612,2022,A computer is programmed to deploy an aerial drone to fly within a specified distance of a first vehicle. The computer is programmed to detect a second vehicle and then activate an aerial drone light.
DRONE-BASED VEHICLE ILLUMINATION,https://lens.org/166-226-983-719-982,2020,A computer is programmed to deploy an aerial drone to fly within a specified distance of a first vehicle. The computer is programmed to detect a second vehicle and then activate an aerial drone light.
UNMANNED AERIAL VEHICLE AND METHOD FOR PHOTOGRAPHING OPERATOR USING SAME,https://lens.org/088-329-968-917-731,2018,"An unmanned aerial vehicle is provided, which includes an aerial vehicle body; a camera mounted on the body; a sensor module installed in the body to sense surrounding environment information; a radio communication module installed in the body to perform radio communication with another communication device; at least one processor installed in the body and electrically connected to the camera, the sensor module, and the radio communication module; and a memory electrically connected to the processor, wherein the memory, during flying of the unmanned aerial vehicle, stores instructions to cause the processor : - to recognize a user's throwing gesture using the unmanned aerial vehicle, - to determine a user direction based on a first motion vector generated by the throwing gesture, - to predict a camera direction in a standstill location that is a target point of the unmanned aerial vehicle based on the throwing gesture, and - to control a photographing direction of the camera"
Unmaned aerial vehicles,https://lens.org/048-799-337-739-794,2021,"A UAV 100 comprising a controller controlling at least one upwards-facing light source to emit visible light when the drone is taking off and/or the drone is in a predetermined location; and an ambient light level is below a threshold ambient light level. The drone may have a downward-facing light source. The drone may have upward-facing, downwards-facing, backward-facing, and sideways-facing cameras. The controller may control the upwards-facing light source(s) only when a battery level is above a threshold battery level value. The light source may be a light-emitting diode, LED. The light source may illuminate an object above the UAV, e.g. for a clearer view in low-light and/or poor weather conditions. Objects presenting a potential collision risk may be illumined so that more accurate image data representing them may be captured. The UAV may better survey its environment prior to vertical take-off."
Method of automatically piloting a rotary-wing drone for performing camera movements with an onboard camera,https://lens.org/160-286-547-320-517,2016,"The object of the invention is an autonomous piloting method, by means of a base station, for a rotary-wing drone with multiple rotors, for controlling the drone in attitude and in velocity following a selected camera movement and a position of the subject to be filmed. The method comprises the following steps: 1. Selection by the user of a camera movement (6) defined by a set of parameters comprising: image shooting mode in a fixed or moving point (7); type of a movement in attitudes relative to the subject to be filmed (8); displacement velocity; displacement directions or axes; direction of the displacement (10); image shooting altitudes (9); 2. Generation of commands for positions (15) through which the drone will have to pass, from the said set of parameters (12) and from the instantaneous position of the subject to be filmed (13) as well as from its recent trajectory (14); 3. Activation of the image shooting by the video camera once the drone is launched on the positions sent by the onboard base station on the subject. The device according to the invention is particularly intended for the taking of aerial views."
UNMANNED AERIAL VEHICLE FLEET MANAGEMENT,https://lens.org/045-482-215-306-996,2020,"An unmanned aerial vehicle (UAV) includes one or more sources of propulsion, a power source, and communication system. The UAV also includes a controller coupled to the communication system, the power source, and the one or more sources of propulsion. The controller includes logic that when executed by the controller causes the UAV to perform operations, including measuring a power source charge level of the UAV; sending a signal including the power source charge level of the UAV to an external device; receiving movement instructions from the external device; and engaging the one or more sources of propulsion to move the UAV from a first location on a storage rack to a second location within a storage facility."
Unmanned aerial vehicle fleet management,https://lens.org/088-868-697-213-400,2022,"An unmanned aerial vehicle (UAV) includes one or more sources of propulsion, a power source, and communication system. The UAV also includes a controller coupled to the communication system, the power source, and the one or more sources of propulsion. The controller includes logic that when executed by the controller causes the UAV to perform operations, including measuring a power source charge level of the UAV; sending a signal including the power source charge level of the UAV to an external device; receiving movement instructions from the external device; and engaging the one or more sources of propulsion to move the UAV from a first location on a storage rack to a second location within a storage facility."
Unmanned aerial vehicle fleet management,https://lens.org/153-294-485-639-587,2020,"An unmanned aerial vehicle (UAV) includes one or more sources of propulsion, a power source, and communication system. The UAV also includes a controller coupled to the communication system, the power source, and the one or more sources of propulsion. The controller includes logic that when executed by the controller causes the UAV to perform operations, including measuring a power source charge level of the UAV; sending a signal including the power source charge level of the UAV to an external device; receiving movement instructions from the external device; and engaging the one or more sources of propulsion to move the UAV from a first location on a storage rack to a second location within a storage facility."
Unmanned aerial vehicle fleet management,https://lens.org/020-569-400-097-465,2021,"An unmanned aerial vehicle (UAV) includes one or more sources of propulsion, a power source, and communication system. The UAV also includes a controller coupled to the communication system, the power source, and the one or more sources of propulsion. The controller includes logic that when executed by the controller causes the UAV to perform operations, including measuring a power source charge level of the UAV; sending a signal including the power source charge level of the UAV to an external device; receiving movement instructions from the external device; and engaging the one or more sources of propulsion to move the UAV from a first location on a storage rack to a second location within a storage facility."
Unmanned aerial vehicle fleet management,https://lens.org/088-868-697-213-400,2022,"An unmanned aerial vehicle (UAV) includes one or more sources of propulsion, a power source, and communication system. The UAV also includes a controller coupled to the communication system, the power source, and the one or more sources of propulsion. The controller includes logic that when executed by the controller causes the UAV to perform operations, including measuring a power source charge level of the UAV; sending a signal including the power source charge level of the UAV to an external device; receiving movement instructions from the external device; and engaging the one or more sources of propulsion to move the UAV from a first location on a storage rack to a second location within a storage facility."
Unmanned aerial vehicle fleet management,https://lens.org/088-868-697-213-400,2022,"An unmanned aerial vehicle (UAV) includes one or more sources of propulsion, a power source, and communication system. The UAV also includes a controller coupled to the communication system, the power source, and the one or more sources of propulsion. The controller includes logic that when executed by the controller causes the UAV to perform operations, including measuring a power source charge level of the UAV; sending a signal including the power source charge level of the UAV to an external device; receiving movement instructions from the external device; and engaging the one or more sources of propulsion to move the UAV from a first location on a storage rack to a second location within a storage facility."
"FIXED-WING DRONE, IN PARTICULAR OF THE FLYING-WING TYPE, WITH ASSISTED MANUAL PILOTING AND AUTOMATIC PILOTING",https://lens.org/022-526-067-011-914,2018,"A drone that includes an automatic piloting system that receives internal and/or external piloting instructions, as well as data of instantaneous attitude (*, *), altitude (z*) and speed (V*) delivered by sensors. Set point calculation circuits calculate, as a function of a model of the aerodynamic behaviour of the drone in flight, roll () and/or pitch () set points and/or speed set points (V) and/or altitude set points (z) corresponding to the internal and/or external piloting instructions received. Correction and control circuits control the propulsion system and the drone control surface servomechanisms. A system further allows generating internally piloting instructions for autonomous flight modes such as automatic take-off or automatic landing."
"Systems, aircrafts and methods for drone detection and collision avoidance",https://lens.org/125-001-006-719-41X,2020,"A system and a method for drone detection and collision avoidance, particularly for use in an aircraft, is provided. The system includes, but is not limited to a sensor, a processor, and an avoidance unit comprising a control unit. The sensor is configured to detect a drone signal in a predetermined space and to transmit the drone signal to the processor. The processor is configured to determine the presence of a drone in the predetermined space based on the drone signal. The processor is configured to transmit a command to the avoidance unit when the processor determines the presence of a drone. The control unit is configured to receive the command and to generate a warning signal in response to receiving the command."
"SYSTEMS, AIRCRAFTS AND METHODS FOR DRONE DETECTION AND COLLISION AVOIDANCE",https://lens.org/054-643-468-725-866,2019,"A system and a method for drone detection and collision avoidance, particularly for use in an aircraft, is provided. The system includes, but is not limited to a sensor, a processor, and an avoidance unit comprising a control unit. The sensor is configured to detect a drone signal in a predetermined space and to transmit the drone signal to the processor. The processor is configured to determine the presence of a drone in the predetermined space based on the drone signal. The processor is configured to transmit a command to the avoidance unit when the processor determines the presence of a drone. The control unit is configured to receive the command and to generate a warning signal in response to receiving the command."
MICRO UNMANNED AERIAL VEHICLE AND METHOD OF CONTROL THEREFOR,https://lens.org/137-826-656-551-761,2015,"A micro unmanned aerial vehicle or drone (UAV) 10 is remotely controlled through an HMI, although this remote control is supplemented by and selectively suppressed by an on-board controller. The controller operates to control the generation of a sonar bubble that generally encapsulates the UAV. The sonar bubble, which may be ultrasonic in nature, is produced by a multiplicity of sonar lobes generated by specific sonar emitters associated with each axis of movement for the UAV. The emitters produce individual and beamformed sonar lobes that partially overlap to provide stereo or bioptic data in the form of individual echo responses detected by axis-specific sonar detectors. In this way, the on-board controller is able to interpret and then generate 3-D spatial imaging of the physical environment in which the UAV is currently moving or positioned. The controller is therefore able to plot relative and absolute movement of the UAV through the 3-D space by recording measurements from on-board gyroscopes, magnetometers and accelerometers. Data from the sonar bubble can therefore both proactively prevent collisions with objects by imposing a corrective instruction to rotors and other flight control system and can also assess and compensate for sensor drift."
MICRO UNMANNED AERIAL VEHICLE AND METHOD OF CONTROL THEREFOR,https://lens.org/192-628-555-897-883,2015,"A micro unmanned aerial vehicle or drone (UAV) 10 is remotely controlled through an HMI, although this remote control is supplemented by and selectively suppressed by an on-board controller. The controller operates to control the generation of a sonar bubble that generally encapsulates the UAV. The sonar bubble, which may be ultrasonic in nature, is produced by a multiplicity of sonar lobes generated by specific sonar emitters associated with each axis of movement for the UAV. The emitters produce individual and beamformed sonar lobes that partially overlap to provide stereo or bioptic data in the form of individual echo responses detected by axis-specific sonar detectors. In this way, the on-board controller is able to interpret and then generate 3-D spatial imaging of the physical environment in which the UAV is currently moving or positioned. The controller is therefore able to plot relative and absolute movement of the UAV through the 3-D space by recording measurements from on-board gyroscopes, magnetometers and accelerometers. Data from the sonar bubble can therefore both proactively prevent collisions with objects by imposing a corrective instruction to rotors and other flight control system and can also assess and compensate for sensor drift."
Micro unmanned aerial vehicle and method of control therefor,https://lens.org/186-332-651-573-66X,2016,"A micro unmanned aerial vehicle or drone (UAV) 10 is remotely controlled through an HMI, although this remote control is supplemented by and selectively suppressed by an on-board controller. The controller operates to control the generation of a sonar bubble that generally encapsulates the UAV. The sonar bubble, which may be ultrasonic in nature, is produced by a multiplicity of sonar lobes generated by specific sonar emitters associated with each axis of movement for the UAV. The emitters produce individual and beamformed sonar lobes that partially overlap to provide stereo or bioptic data in the form of individual echo responses detected by axis-specific sonar detectors. In this way, the on-board controller is able to interpret and then generate 3-D spatial imaging of the physical environment in which the UAV is currently moving or positioned. The controller is therefore able to plot relative and absolute movement of the UAV through the 3-D space by recording measurements from on-board gyroscopes, magnetometers and accelerometers. Data from the sonar bubble can therefore both proactively prevent collisions with objects by imposing a corrective instruction to rotors and other flight control system and can also assess and compensate for sensor drift."
Method for recording flight path and controlling automatic flight of unmanned aerial vehicle,https://lens.org/070-806-768-871-244,2018,"The invention provides a method for recording a flight path and controlling automatic flight of an unmanned aerial vehicle. The method includes: controlling, by a remote control or a smart mobile terminal device, the unmanned aerial vehicle to fly following a certain flight path according to user's requirement, triggering the unmanned aerial vehicle to record the flight path, storing tracking data, and selecting a learning track to fly automatically, where a flight mode comprises at least GPS learning mode, GPS automatic mode, and manual mode. The unmanned aerial vehicle having the control mode can be triggered to fly automatically following the tracking data stored in the flight control device according to different application scenarios, thus increasing the user experience and entertainment. In the process of recording track, the unmanned aerial vehicle can fly at a low speed and meanwhile avoid obstacles, when flying automatically, the unmanned aerial vehicle can fly fast in a racing mode, further increasing the user experience. Meanwhile, in the automatic flight at a low speed, the unmanned aerial vehicle can take photographs, and the shot images are stable and clear. In certain application scenarios requiring a terrain recorder to record the track, through learning the actual flight track, it is unnecessary to employ other devices, thus saving the user's costs."
METHOD FOR RECORDING FLIGHT PATH AND CONTROLLING AUTOMATIC FLIGHT OF UNMANNED AERIAL VEHICLE,https://lens.org/025-985-643-156-292,2017,"The invention provides a method for recording a flight path and controlling automatic flight of an unmanned aerial vehicle. The method includes: controlling, by a remote control or a smart mobile terminal device, the unmanned aerial vehicle to fly following a certain flight path according to user's requirement, triggering the unmanned aerial vehicle to record the flight path, storing tracking data, and selecting a learning track to fly automatically, where a flight mode comprises at least GPS learning mode, GPS automatic mode, and manual mode. The unmanned aerial vehicle having the control mode can be triggered to fly automatically following the tracking data stored in the flight control device according to different application scenarios, thus increasing the user experience and entertainment. In the process of recording track, the unmanned aerial vehicle can fly at a low speed and meanwhile avoid obstacles, when flying automatically, the unmanned aerial vehicle can fly fast in a racing mode, further increasing the user experience. Meanwhile, in the automatic flight at a low speed, the unmanned aerial vehicle can take photographs, and the shot images are stable and clear. In certain application scenarios requiring a terrain recorder to record the track, through learning the actual flight track, it is unnecessary to employ other devices, thus saving the user's costs."
UNMANNED AERIAL VEHICLE CONTROL METHOD AND APPARATUS,https://lens.org/136-080-803-634-328,2023,"A method and apparatus for controlling an Unmanned Aerial Vehicle (UAV) are provided. The method is applied to the UAV, and includes: receiving flight path information transmitted by a UAV controller, wherein the flight path information represents a flight path set by the UAV controller for the UAV controlled by the UAV controller; and transmitting the flight path information to a base station that provides a network service for the UAV, such that the base station determines the flight path based on the flight path information."
UNMANNED AERIAL VEHICLE CONTROL METHOD AND APPARATUS,https://lens.org/136-080-803-634-328,2023,"A method and apparatus for controlling an Unmanned Aerial Vehicle (UAV) are provided. The method is applied to the UAV, and includes: receiving flight path information transmitted by a UAV controller, wherein the flight path information represents a flight path set by the UAV controller for the UAV controlled by the UAV controller; and transmitting the flight path information to a base station that provides a network service for the UAV, such that the base station determines the flight path based on the flight path information."
Method for destination approach control of unmanned aerial vehicles,https://lens.org/041-958-960-695-552,2017,"The invention relates to a method for destination approach control of unmanned aerial vehicles, in particular delivery drones, to an arbitrary location defined by the recipient."
Method for destination approach control of unmanned aerial vehicles,https://lens.org/073-525-039-294-748,2020,"The invention relates to a method for destination approach control of unmanned aerial vehicles, in particular delivery drones, to an arbitrary location defined by the recipient."
Ground drone-based sports training aid,https://lens.org/054-794-643-477-803,2022,"A ground traversing, electrically driven drone travels along a preprogrammed path that corresponds to pass catcher's travel path during a play, matching the pass catcher's speed and run cuts. The play is wirelessly communicated to the drone by a handheld electronic device located remote of the drone. A target is located on the drone so that a quarterback can throw a football at the target in order to refine the quarterback's timing and accuracy for the play. Sensors onboard the drone track both the football's and quarterback's speed and travel trajectories so that such data can be collected, along with the drone's travel path, and stored onboard the drone's control unit and eventually fed into 3-D reconstruction software for analysis by the quarterback and coaching staff. The target rotates so that the target either faces in a fixed direction or constantly faces the quarterback during execution of drone's maneuvers."
Ground drone-based sports training aid,https://lens.org/054-794-643-477-803,2022,"A ground traversing, electrically driven drone travels along a preprogrammed path that corresponds to pass catcher's travel path during a play, matching the pass catcher's speed and run cuts. The play is wirelessly communicated to the drone by a handheld electronic device located remote of the drone. A target is located on the drone so that a quarterback can throw a football at the target in order to refine the quarterback's timing and accuracy for the play. Sensors onboard the drone track both the football's and quarterback's speed and travel trajectories so that such data can be collected, along with the drone's travel path, and stored onboard the drone's control unit and eventually fed into 3-D reconstruction software for analysis by the quarterback and coaching staff. The target rotates so that the target either faces in a fixed direction or constantly faces the quarterback during execution of drone's maneuvers."
SURROUND VIEW BY DRONES,https://lens.org/044-150-385-949-751,2020,An apparatus includes a visual display to be viewed by a vehicle occupant. At least one drone includes a camera. A controller is configured to receive images from the camera on the at least one drone and generate an overhead view of the vehicle based on the images received from the at least one drone and display the overhead view on the visual display.
Surround view by drones,https://lens.org/012-491-702-457-537,2023,An apparatus includes a visual display to be viewed by a vehicle occupant. At least one drone includes a camera. A controller is configured to receive images from the camera on the at least one drone and generate an overhead view of the vehicle based on the images received from the at least one drone and display the overhead view on the visual display.
Surround view by drones,https://lens.org/012-491-702-457-537,2023,An apparatus includes a visual display to be viewed by a vehicle occupant. At least one drone includes a camera. A controller is configured to receive images from the camera on the at least one drone and generate an overhead view of the vehicle based on the images received from the at least one drone and display the overhead view on the visual display.
Ground drone-based sports training aid,https://lens.org/034-435-446-150-457,2023,"A ground traversing, electrically driven drone travels along a programmed path that corresponds to pass catcher's travel path during a play, matching the pass catcher's speed and run cuts. The play is wirelessly communicated to the drone by a handheld electronic device located remote of the drone. A target is located on the drone so that a quarterback can throw a football at the target in order to refine the quarterback's timing and accuracy for the play. Sensors located remote of the drone track both the football's and quarterback's speed and travel trajectories so that such data can be collected, along with the drone's travel path, and transmitted to the computer and eventually fed into 3-D reconstruction software for analysis by the quarterback and coaching staff. The target rotates so that the target either faces in a fixed direction or constantly faces the quarterback during execution of drone's maneuvers."
Ground drone-based sports training aid,https://lens.org/034-435-446-150-457,2023,"A ground traversing, electrically driven drone travels along a programmed path that corresponds to pass catcher's travel path during a play, matching the pass catcher's speed and run cuts. The play is wirelessly communicated to the drone by a handheld electronic device located remote of the drone. A target is located on the drone so that a quarterback can throw a football at the target in order to refine the quarterback's timing and accuracy for the play. Sensors located remote of the drone track both the football's and quarterback's speed and travel trajectories so that such data can be collected, along with the drone's travel path, and transmitted to the computer and eventually fed into 3-D reconstruction software for analysis by the quarterback and coaching staff. The target rotates so that the target either faces in a fixed direction or constantly faces the quarterback during execution of drone's maneuvers."
DRONE CONTROL DEVICE USING MODEL PREDICTION CONTROL,https://lens.org/062-173-317-794-81X,2021,"Provided is a device for controlling flight of a drone, the device including: a rotor on which a motor is mounted; and an inertial navigation control unit that controls a rotation speed of the motor mounted on the rotor, in which in order for a drone to perform a hovering operation, the inertial navigation unit computes the rotation speed of the motor using an x-axis inertia moment, a y-axis inertia moment, and a z-axis inertia moment, which are computed using equations, and a propeller rotation inertia moment (J r ) that is an intrinsic constant for the drone, the equation being: where I xx =x-axis inertia moment, I yy =y-axis moment, I zz =z-axis inertia moment, l denotes a distance from the center axis of the drone to the motor, m denotes a weight of the drone, r denotes a radius of the drone, and m r is a weight of one rotor."
Systems and methods for controlling an unmanned aerial vehicle,https://lens.org/086-325-428-727-67X,2019,"Systems and methods for controlling an unmanned aerial vehicle recognize and interpret gestures by a user. The gestures are interpreted to adjust the operation of the unmanned aerial vehicle, a sensor carried by the unmanned aerial vehicle, or both."
Systems and methods for controlling an unmanned aerial vehicle,https://lens.org/024-525-047-343-178,2017,"Systems and methods for controlling an unmanned aerial vehicle recognize and interpret gestures by a user. The gestures are interpreted to adjust the operation of the unmanned aerial vehicle, a sensor carried by the unmanned aerial vehicle, or both."
SYSTEMS AND METHODS FOR CONTROLLING AN UNMANNED AERIAL VEHICLE,https://lens.org/134-700-212-862-427,2017,"Systems and methods for controlling an unmanned aerial vehicle recognize and interpret gestures by a user. The gestures are interpreted to adjust the operation of the unmanned aerial vehicle, a sensor carried by the unmanned aerial vehicle, or both."
SYSTEMS AND METHODS FOR CONTROLLING AN UNMANNED AERIAL VEHICLE,https://lens.org/164-487-062-577-716,2017,"Systems and methods for controlling an unmanned aerial vehicle recognize and interpret gestures by a user. The gestures are interpreted to adjust the operation of the unmanned aerial vehicle, a sensor carried by the unmanned aerial vehicle, or both."
SYSTEM AND METHOD FOR UTILIZING DRONES FOR INTERMITTENT FLIGHTS,https://lens.org/127-256-111-662-31X,2019,"A method for utilizing a drone for intermittent flights can include: receiving instructions of a flight mission with a flight route from an original location to a mission destination of the drone, wherein a plurality of stand-by locations are configured for the drone to land on along the flight route; obtaining data of the stand-by locations; scanning a first area between the original location of the drone and a first stand-by location to determine whether the first area is clear; controlling the drone to navigate over the first area along the flight route if the first area is clear; updating a drone position in real time; scanning a second area between an updated drone position and a second stand-by location to determine whether the second area is clear; and controlling the drone to land on the first stand-by location if the second area is not clear."
System and method for utilizing drones for intermittent flights,https://lens.org/098-757-229-654-847,2020,"A method for utilizing a drone for intermittent flights can include: receiving instructions of a flight mission with a flight route from an original location to a mission destination of the drone, wherein a plurality of stand-by locations are configured for the drone to land on along the flight route; obtaining data of the stand-by locations; scanning a first area between the original location of the drone and a first stand-by location to determine whether the first area is clear; controlling the drone to navigate over the first area along the flight route if the first area is clear; updating a drone position in real time; scanning a second area between an updated drone position and a second stand-by location to determine whether the second area is clear; and controlling the drone to land on the first stand-by location if the second area is not clear."
SYSTEM AND METHOD FOR UTILIZING DRONES FOR INTERMITTENT FLIGHTS,https://lens.org/161-274-459-427-275,2019,"A method for utilizing a drone for intermittent flights can include: receiving instructions of a flight mission with a flight route from an original location to a mission destination of the drone, wherein a plurality of stand-by locations are configured for the drone to land on along the flight route; obtaining data of the stand-by locations; scanning a first area between the original location of the drone and a first stand-by location to determine whether the first area is clear; controlling the drone to navigate over the first area along the flight route if the first area is clear; updating a drone position in real time; scanning a second area between an updated drone position and a second stand-by location to determine whether the second area is clear; and controlling the drone to land on the first stand-by location if the second area is not clear."
Minimizing uplink and downlink interference in mobile network connected drones,https://lens.org/191-019-724-246-740,2021,"A drone capable of bidirectional communication and control over a cellular network is provided with a signal interference minimization controller configured to periodically scan for neighboring serving cells and determine if beamforming adjustments and/or gain adjustments can be made to an antenna assembly to minimize interference experienced by the drone, in particular interference experienced during travel above the sightlines of base stations defining the network."
Unmanned aerial vehicle system and method for use,https://lens.org/095-275-789-210-637,2018,"A system includes an unmanned aerial vehicle having a body with a hollow cavity, a plurality of rotary assemblies secured to the body and configured to provide lift, a control system disposed within the hollow cavity, a deterrent device secured to the body, a remote communication device operably associated with the control system. The method includes providing tracking location of a user upon activation of the remote control device, autonomously flying the unmanned aerial vehicle to a location of the remote communication device, and delivering a payload."
DRONE,https://lens.org/176-341-741-100-104,2023,"The drone according to the embodiment has a propeller, a first direct current motor, a power source, a second direct current motor, and a control unit. The first direct current motor drives the propellers. The power source supplies power to the first direct current motor. The second direct current motor has a rotating shaft that rotates in conjunction with the rotation of a rotating shaft of the first direct current motor. The control unit controls the first direct current motor. The second direct current motor charges the power source using the current output from the second direct current motor along with the rotation of a rotating shaft of the second direct current motor."
DRONE,https://lens.org/176-341-741-100-104,2023,"The drone according to the embodiment has a propeller, a first direct current motor, a power source, a second direct current motor, and a control unit. The first direct current motor drives the propellers. The power source supplies power to the first direct current motor. The second direct current motor has a rotating shaft that rotates in conjunction with the rotation of a rotating shaft of the first direct current motor. The control unit controls the first direct current motor. The second direct current motor charges the power source using the current output from the second direct current motor along with the rotation of a rotating shaft of the second direct current motor."
MANAGING UNMANNED AERIAL VEHICLE FLIGHT DATA,https://lens.org/164-845-126-506-536,2020,"A device can be configured to receive flight data associated with an unmanned aerial vehicle (UAV), at least some of the flight data being received from the UAV; store the flight data; receive, from a requesting device, a flight data request, the flight data request including information identifying the UAV or a flight of the UAV; determine response data based on the flight data request and based on an entity associated with the requesting device, the response data including a subset of the flight data, which is available to be accessed by the entity; and perform an action associated with the response data."
Managing unmanned aerial vehicle flight data,https://lens.org/046-555-353-958-731,2022,"A device can be configured to receive flight data associated with an unmanned aerial vehicle (UAV), at least some of the flight data being received from the UAV; store the flight data; receive, from a requesting device, a flight data request, the flight data request including information identifying the UAV or a flight of the UAV; determine response data based on the flight data request and based on an entity associated with the requesting device, the response data including a subset of the flight data, which is available to be accessed by the entity; and perform an action associated with the response data."
Managing unmanned aerial vehicle flight data,https://lens.org/046-555-353-958-731,2022,"A device can be configured to receive flight data associated with an unmanned aerial vehicle (UAV), at least some of the flight data being received from the UAV; store the flight data; receive, from a requesting device, a flight data request, the flight data request including information identifying the UAV or a flight of the UAV; determine response data based on the flight data request and based on an entity associated with the requesting device, the response data including a subset of the flight data, which is available to be accessed by the entity; and perform an action associated with the response data."
MANAGING UNMANNED AERIAL VEHICLE FLIGHT DATA,https://lens.org/025-380-461-766-012,2019,"A device can be configured to receive flight data associated with an unmanned aerial vehicle (UAV), at least some of the flight data being received from the UAV; store the flight data; receive, from a requesting device, a flight data request, the flight data request including information identifying the UAV or a flight of the UAV; determine response data based on the flight data request and based on an entity associated with the requesting device, the response data including a subset of the flight data, which is available to be accessed by the entity; and perform an action associated with the response data."
UNMANNED AERIAL VEHICLE AND METHOD FOR PHOTOGRAPHING SUBJECT USING THE SAME,https://lens.org/010-996-479-042-38X,2018,"An unmanned aerial vehicle is provided, which includes an aerial vehicle body; a camera mounted on the body; a sensor module installed in the body to sense surrounding environment information; a radio communication module installed in the body to perform radio communication with another communication device; at least one processor installed in the body and electrically connected to the camera, the sensor module, and the radio communication module; and a memory electrically connected to the processor, wherein the memory, during flying of the unmanned aerial vehicle, stores instructions to cause the processor to recognize a user's throwing gesture using the unmanned aerial vehicle, to determine a user direction based on a first motion vector generated by the throwing gesture, to predict a camera direction in a standstill location that is a target point of the unmanned aerial vehicle based on the throwing gesture, and to control a photographing direction of the camera."
AERIAL IMAGERY SYSTEMS AND METHODS,https://lens.org/154-553-859-203-586,2018,"A drone system has a camera mounted to a frame of a drone, the camera configured to acquire image data upon receipt of a signal from a flight controller and a precision location device configured for continuously obtaining location data. Additionally, the drone system has a computing device configured for receiving a signal indicating that an image has been acquired, the computing device configured for transmitting a signal to a precision location device indicating that an image has been acquired, and the precision location device is further configured to record event data associated with a time indicating when the image was acquired."
Aerial imagery systems and methods,https://lens.org/025-402-847-567-328,2021,"A drone system has a camera mounted to a frame of a drone, the camera configured to acquire image data upon receipt of a signal from a flight controller and a precision location device configured for continuously obtaining location data. Additionally, the drone system has a computing device configured for receiving a signal indicating that an image has been acquired, the computing device configured for transmitting a signal to a precision location device indicating that an image has been acquired, and the precision location device is further configured to record event data associated with a time indicating when the image was acquired."
DRONE TAKEOVER AND REDIRECTING SYSTEM AND METHOD EMPLOYING LANDING OF DRONES,https://lens.org/103-510-956-463-902,2021,"A system, method and computer program product for controlled drone descent, and deactivation, including a drone deactivation system; and a location system. The drone deactivation system calculates positioning, signal reception, signal strength, and signal identification parameters of a target drone from the location system, and determines an attack method based on the calculated parameters. The drone deactivation system employs the determined attack method against the target drone for forcing at least one of controlled drone descent, and deactivation of the target drone."
"UNMANNED AERIAL VEHICLE, REMOTE CONTROLLER, AND CONTROL METHOD THEREOF",https://lens.org/170-031-825-281-238,2021,"A control method for communicating with an unmanned aerial vehicle (UAV) includes: transmitting a signal from a remote controller to the UAV through a first communication network; monitoring a state of the first communication network; and in response to the state of the first communication network not meeting a state condition: prompting, on an interface of the remote controller, a user to perform a user selection for selecting a cooperative method of the first communication network and a second communication network; receiving the user selection; and performing a network switching according to the selected corporation method to transmit at least a portion of the signal from the remote controller to the UAV through the second communication network."
"Unmanned aerial vehicle, remote controller, and control method thereof",https://lens.org/176-362-969-234-849,2021,"A control method for communicating with an unmanned aerial vehicle (UAV) includes: transmitting a signal from a remote controller to the UAV through a first communication network; monitoring a state of the first communication network; and in response to the state of the first communication network not meeting a state condition: prompting, on an interface of the remote controller, a user to perform a user selection for selecting a cooperative method of the first communication network and a second communication network; receiving the user selection; and performing a network switching according to the selected corporation method to transmit at least a portion of the signal from the remote controller to the UAV through the second communication network."
Autonomous robot,https://lens.org/050-172-238-204-260,2023,"A robot in a location interacts with a user. The robot includes a camera, an image recognition processor, a microphone and a loudspeaker, a voice assistant, and a wireless transceiver. The robot moves around and creates a model of the location, and recognizes changes. It recognizes objects of interest, beings, and situations. The robot monitors the user and recognizes body language and gesture commands, as well as voice commands. The robot communicates with the user, the TV, and other devices. It may include environment sensors and health status sensors. It acts as a user companion by answering queries, executing commands, and issuing reminders. It may monitor to determine if the user is well. The robot may monitor objects of interest, their placement and their status. When necessary, it communicates with the user."
Autonomous robot,https://lens.org/050-172-238-204-260,2023,"A robot in a location interacts with a user. The robot includes a camera, an image recognition processor, a microphone and a loudspeaker, a voice assistant, and a wireless transceiver. The robot moves around and creates a model of the location, and recognizes changes. It recognizes objects of interest, beings, and situations. The robot monitors the user and recognizes body language and gesture commands, as well as voice commands. The robot communicates with the user, the TV, and other devices. It may include environment sensors and health status sensors. It acts as a user companion by answering queries, executing commands, and issuing reminders. It may monitor to determine if the user is well. The robot may monitor objects of interest, their placement and their status. When necessary, it communicates with the user."
AUTONOMOUS ROBOT,https://lens.org/006-090-438-750-392,2020,"A robot in a location interacts with a user. The robot includes a camera, an image recognition processor, a microphone and a loudspeaker, a voice assistant, and a wireless transceiver. The robot moves around and creates a model of the location, and recognizes changes. It recognizes objects of interest, beings, and situations. The robot monitors the user and recognizes body language and gesture commands, as well as voice commands. The robot communicates with the user, the TV, and other devices. It may include environment sensors and health status sensors. It acts as a user companion by answering queries, executing commands, and issuing reminders. It may monitor to determine if the user is well. The robot may monitor objects of interest, their placement and their status. When necessary, it communicates with the user."
Local network for the simultaneous exchange of data between a drone and a plurality of user terminals,https://lens.org/157-758-478-608-764,2018,"A primary user terminal is interfaced with the drone so as to constitute a local network of the infrastructure type, where the drone is configured as an access point (AP) and the primary user terminal is configured as a mobile station. The primary user terminal comprises an adaptive software program able i) to generate piloting and control instructions to be transmitted to the drone, and ii) to establish a connection to the local network and to register the primary user terminal into a registration table of the drone. The network further comprises at least one secondary user terminal with an applicative software program adapted to establish a connection to the local network and to register the secondary user terminal into the registration table of the drone with a hierarchized management of the rights with respect to the primary terminal."
LOCAL NETWORK FOR THE SIMULTANEOUS EXCHANGE OF DATA BETWEEN A DRONE AND A PLURALITY OF USER TERMINALS,https://lens.org/011-850-613-117-640,2017,"A primary user terminal is interfaced with the drone so as to constitute a local network of the infrastructure type, where the drone is configured as an access point (AP) and the primary user terminal is configured as a mobile station. The primary user terminal comprises an adaptive software program able i) to generate piloting and control instructions to be transmitted to the drone, and ii) to establish a connection to the local network and to register the primary user terminal into a registration table of the drone. The network further comprises at least one secondary user terminal with an applicative software program adapted to establish a connection to the local network and to register the secondary user terminal into the registration table of the drone with a hierarchized management of the rights with respect to the primary terminal."
METHOD AND SYSTEM FROM CONTROLLING AN UNMANNED AERIAL VEHICLE,https://lens.org/183-338-649-708-711,2019,"A method is provided. An unmanned aerial vehicle (UAV) can be operated in an autonomous mode, performing course corrections from sensor data using an object detection processor and a decision processor. The UAV can then enter a hover mode if an override condition is present and enter a remote-control mode once the UAV is in the hover mode. In the remote-control mode, flight control commands can be received via the cellular module so as to position the UAV in response to the flight control command."
Method and system from controlling an unmanned aerial vehicle,https://lens.org/049-973-046-901-330,2020,"A method is provided. An unmanned aerial vehicle (UAV) can be operated in an autonomous mode, performing course corrections from sensor data using an object detection processor and a decision processor. The UAV can then enter a hover mode if an override condition is present and enter a remote-control mode once the UAV is in the hover mode. In the remote-control mode, flight control commands can be received via the cellular module so as to position the UAV in response to the flight control command."
Apparatus for controlling unmanned aerial vehicles and passenger drones via an air traffic control system,https://lens.org/197-786-357-238-719,2020,"A flying vehicle that is one of a passenger drone and an Unmanned Aerial Vehicle (UAV) includes a plurality of rotors disposed to a body and configured for flight; a processing device any of integrated with, disposed on, and associated with the body; wireless interfaces including hardware and antennas any of integrated with, disposed on, and associated with the body; and a control apparatus communicatively coupled to the processing device, wherein the control apparatus is configured to provide an interface between the wireless interfaces and an air traffic control system for control and/or monitoring of the flying vehicle by the air traffic control system."
Unmanned aerial vehicle voice control system,https://lens.org/190-300-774-824-009,2016,"The invention provides an unmanned aerial vehicle voice control system, including a ground control device and an airborne control device. The ground control device is used for receiving a voice instruction of a commander, converting the voice instruction into a flight control signal, and collecting current position information of the ground control device when receiving an unmanned aerial vehicle return signal sent by the airborne control device; the airborne control device is located on the unmanned aerial vehicle and used for analyzing and processing the received flight control signal, obtaining a flight motion instruction, and sending the flight motion instruction to a flight control system of the unmanned aerial vehicle, the flight control system sends a rotating speed control instruction to a rotating speed regulator of the unmanned aerial vehicle according to the flight motion instruction, and the rotating speed regulator controls motor speed of the unmanned aerial vehicle to complete flight action corresponding to the flight motion instruction. The stability of a voice control unmanned aerial vehicle system is increased, and safe, stable and efficient control of flight of the unmanned aerial vehicle through voice is realized."
"UAV (unmanned aerial vehicle), and UAV control system and method",https://lens.org/023-418-171-672-585,2015,"The invention discloses an UAV (unmanned aerial vehicle), and UAV control system and method. The UAV comprises a main control module, a flight driving module, a GPS module, a camera module and a wireless communication module; the UAV is in wireless connection with a cloud sever through the wireless communication module and communicates with an intelligent terminal device through the cloud server; the flight driving module of the UAV drives the UAV to flight; the GPS module navigates and acquires the location information of the UAV; the camera module acquires an environmental image and acquires corresponding image information; the main control module sends the location position and the image information to the cloud server so that the intelligent terminal device can gain the location information and the image information from the cloud server. The UAV can be monitored and operated on real time and can communicate with the intelligent terminal device on real time, and therefore, the user experience can be effectively increased."
Map including data for routing aerial vehicles during GNSS failure,https://lens.org/024-531-830-024-057,2022,"An unmanned aerial vehicle (UAV) includes a propulsion system, a global navigation satellite system (GNSS) sensor, a camera and a controller. The controller includes logic that, in response to execution by the controller, causes the UAV to in response to detecting a loss of tracking by the GNSS sensor determine an estimated location of the UAV on a map based on a location image captured by the camera, determine a route to a destination using tracking parameters embedded in the map, wherein the map is divided into a plurality of sections and the tracking parameters indicate an ease of determining a location of the UAV using images captured by the camera with respect to each section, and control the propulsion system to cause the UAV to follow the route to the destination."
Map including data for routing aerial vehicles during GNSS failure,https://lens.org/079-904-135-383-087,2023,"An unmanned aerial vehicle (UAV) includes a propulsion system, a global navigation satellite system (GNSS) sensor, a camera and a controller. The controller includes logic that, in response to execution by the controller, causes the UAV to in response to detecting a loss of tracking by the GNSS sensor determine an estimated location of the UAV on a map based on a location image captured by the camera, determine a route to a destination using tracking parameters embedded in the map, wherein the map is divided into a plurality of sections and the tracking parameters indicate an ease of determining a location of the UAV using images captured by the camera with respect to each section, and control the propulsion system to cause the UAV to follow the route to the destination."
MAP INCLUDING DATA FOR ROUTING AERIAL VEHICLES DURING GNSS FAILURE,https://lens.org/062-681-504-125-006,2021,"An unmanned aerial vehicle (UAV) includes a propulsion system, a global navigation satellite system (GNSS) sensor, a camera and a controller. The controller includes logic that, in response to execution by the controller, causes the UAV to in response to detecting a loss of tracking by the GNSS sensor determine an estimated location of the UAV on a map based on a location image captured by the camera, determine a route to a destination using tracking parameters embedded in the map, wherein the map is divided into a plurality of sections and the tracking parameters indicate an ease of determining a location of the UAV using images captured by the camera with respect to each section, and control the propulsion system to cause the UAV to follow the route to the destination."
Map including data for routing aerial vehicles during GNSS failure,https://lens.org/024-531-830-024-057,2022,"An unmanned aerial vehicle (UAV) includes a propulsion system, a global navigation satellite system (GNSS) sensor, a camera and a controller. The controller includes logic that, in response to execution by the controller, causes the UAV to in response to detecting a loss of tracking by the GNSS sensor determine an estimated location of the UAV on a map based on a location image captured by the camera, determine a route to a destination using tracking parameters embedded in the map, wherein the map is divided into a plurality of sections and the tracking parameters indicate an ease of determining a location of the UAV using images captured by the camera with respect to each section, and control the propulsion system to cause the UAV to follow the route to the destination."
Signal drone for an automobile,https://lens.org/048-568-000-966-918,2018,"An emergency alert system for a vehicle includes a drone system including a warning sign disposed within a body defining cavity of the vehicle and a controller. The controller is configured to, in response to a user request during a stop, launch the drone system from the cavity and specify drone position relative to the vehicle based on traffic flow around the vehicle to alert other vehicles in a vicinity of the vehicle via the warning sign regarding occurrence of the stop."
SIGNAL DRONE FOR AN AUTOMOBILE,https://lens.org/096-137-661-808-358,2018,"An emergency alert system for a vehicle includes a drone system including a warning sign disposed within a body defining cavity of the vehicle and a controller. The controller is configured to, in response to a user request during a stop, launch the drone system from the cavity and specify drone position relative to the vehicle based on traffic flow around the vehicle to alert other vehicles in a vicinity of the vehicle via the warning sign regarding occurrence of the stop."
SIGNAL DRONE FOR AN AUTOMOBILE,https://lens.org/107-773-310-831-024,2017,"An emergency alert system for a vehicle includes a drone system including a warning sign disposed within a body defining cavity of the vehicle and a controller. The controller is configured to, in response to a user request during a stop, launch the drone system from the cavity and specify drone position relative to the vehicle based on traffic flow around the vehicle to alert other vehicles in a vicinity of the vehicle via the warning sign regarding occurrence of the stop."
Signal drone for an automobile,https://lens.org/047-847-052-953-903,2020,"An emergency alert system for a vehicle includes a drone system including a warning sign disposed within a body defining cavity of the vehicle and a controller. The controller is configured to, in response to a user request during a stop, launch the drone system from the cavity and specify drone position relative to the vehicle based on traffic flow around the vehicle to alert other vehicles in a vicinity of the vehicle via the warning sign regarding occurrence of the stop."
Systems and methods for surveillance with a visual marker,https://lens.org/096-734-120-468-181,2022,"A method of controlling an unmanned aerial vehicle (UAV) in an environment includes detecting, with aid of a sensor coupled to the UAV and while the UAV is in flight, a signal that is emitted from and uniquely identifying a locating marker; determining, with aid of a processor, a sequence of actions to control the UAV in response to a plurality of instructions encoded in the locating marker and communicated by the signal; and controlling, with aid of the processor, the UAV to effect the sequence of actions according to a specified time interval included in the plurality of instructions. The specified time interval indicates a wait time before the UAV effects the sequence of actions."
Systems and methods for surveillance with a visual marker,https://lens.org/096-734-120-468-181,2022,"A method of controlling an unmanned aerial vehicle (UAV) in an environment includes detecting, with aid of a sensor coupled to the UAV and while the UAV is in flight, a signal that is emitted from and uniquely identifying a locating marker; determining, with aid of a processor, a sequence of actions to control the UAV in response to a plurality of instructions encoded in the locating marker and communicated by the signal; and controlling, with aid of the processor, the UAV to effect the sequence of actions according to a specified time interval included in the plurality of instructions. The specified time interval indicates a wait time before the UAV effects the sequence of actions."
SYSTEMS AND METHODS FOR SURVEILLANCE WITH A VISUAL MARKER,https://lens.org/164-659-014-762-325,2020,"A method of controlling an unmanned aerial vehicle (UAV) in an environment includes detecting, with aid of a sensor coupled to the UAV and while the UAV is in flight, a signal that is emitted from and uniquely identifying a locating marker; determining, with aid of a processor, a sequence of actions to control the UAV in response to a plurality of instructions encoded in the locating marker and communicated by the signal; and controlling, with aid of the processor, the UAV to effect the sequence of actions according to a specified time interval included in the plurality of instructions. The specified time interval indicates a wait time before the UAV effects the sequence of actions."
SYSTEM AND METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE IN FLIGHT SPACE,https://lens.org/108-867-220-766-787,2012,"In a method for controlling an unmanned aerial vehicle (UAV) in a flight space using a computing device, at least one camera is installed in the flight space. The method sets a flight area of the UAV in the flight space, and stores geographic information of the flight area into a storage device. The method further controls each of the camera to capture a series of 3D images from the flight space, analyzes a current location of the UAV in the flight space according to the 3D images, and compares the current location with the geographic information of the flight area to determine whether the UAV flies out of the flight area. In addition, the method sends a warning message to a remote controller when the UAV flies out of the flight area, and controls the UAV to fly within the flight area using the remote controller."
"A system and a method for activating a duress alarm by voice command. When activated the duress, alarm sends its spatial location to a computer server. The server sends commands to Unmanned Aerial Vehicles to fly and manoeuvre to the location specified by the duress alarm and turn on the UAV cameras to provide live visual coverage to a third party. The location of the duress alarm can be sent to other users of the system in the immediate location.",https://lens.org/042-032-243-751-512,2018,"A system and a method for activating a duress alarm by voice command. When activated the duress, alarm sends its spatial location to a computer server. The server sends commands to Unmanned Aerial Vehicles to fly and manoeuvre to the location specified by the duress alarm and turn on the UAV cameras to provide live visual coverage to a third party. The location of the duress alarm can be sent to other users of the system in the immediate location *1wi _ S (D * I * t-r) * '0* 0 * I 0"
A REMOTE-CONTROLLED DEVICE,https://lens.org/001-073-460-960-752,2022,"A remote-controlled device (100), the device comprising a voice interface (120), a remote controller interface (130) and a controller (110); wherein the device is configured to: receive (301), via the voice interface (120), an activation phrase; check (302) whether the application phrase is received from within an allowable activation angle; if so, receive (306), via the remote controller interface (130), a command from the remote controller (51), wherein the command includes a remote controller identifier; store (307) the remote controller identifier as an identifier of a paired remote controller."
A REMOTE-CONTROLLED DEVICE,https://lens.org/001-073-460-960-752,2022,"A remote-controlled device (100), the device comprising a voice interface (120), a remote controller interface (130) and a controller (110); wherein the device is configured to: receive (301), via the voice interface (120), an activation phrase; check (302) whether the application phrase is received from within an allowable activation angle; if so, receive (306), via the remote controller interface (130), a command from the remote controller (51), wherein the command includes a remote controller identifier; store (307) the remote controller identifier as an identifier of a paired remote controller."
REMOTE ANIMAL TREATMENT AND PROTECTION DEVICE,https://lens.org/121-504-221-113-823,2022,"The invention relates to a device for treating animals remotely. The device is an accessory to any drone, which then becomes a means of tracking and firing arrows for animals. Using a remote control or mobile phone, the user is able to control the device, track the animal, target and activate the compressed gas-based system that fires an arrow. Using 4G technology, satellite internet and Wi-Fi, the user is enabled unlimited range, i.e. management from any location."
"MONITORING SYSTEM, BASE STATION AND CONTROL METHOD THEREOF",https://lens.org/174-937-625-844-979,2020,"A monitoring system, a base station, and a control method thereof are provided. The monitoring system includes a drone and a base station. The drone includes a main body and at least two leg holders extending from the main body. The base station includes a platform and a positioning mechanism. The platform has a horizontal plate, and the drone is placed on the platform. The positioning mechanism includes at least two movement members. The movement members are movably disposed on the platform and movable between a first position and a second position. When the movement members are located at the second position, the movement members hold and fix the leg holders of the drone, each of the leg holders forms an inclined angle with respect to the horizontal plate, and the inclined angle is less than 90 degrees."
FLYING DRONE TRAJECTORY SYNCHRONIZATION,https://lens.org/197-233-473-800-65X,2015,"A flying drone (10) comprises a memory (16) for storing a forecasted flying trajectory, said trajectory being defined by a list (26) of 3D coordinates points, and a control and command computer (18) for driving drone directional and motorization means, said control and command computer (18) being connected to the memory (16) for reading the forecasted trajectory so that the flying drone (10) is able to move along said forecasted trajectory. The flying drone (10) further comprises:  a wireless receptor (20) able to receive a synchronization signal (28) emitted from a timecode (38);  the 3D coordinates points are associated to a timeline; and  the control and command computer (18) is adapted for synchronizing the flying drone timeline with the synchronization signal (28)."
Drone assisted adaptive robot control,https://lens.org/114-314-689-866-520,2018,"A method, a drone device, and an adaptive robot control system (ARCS) for adaptively controlling a programmable robot are provided. The ARCS receives environmental parameters of a work environment where the drone device operates and geometrical information of a target object to be operated on by the programmable robot. The ARCS dynamically receives a calibrated spatial location of the target object in the work environment based on the environmental parameters and a discernment of the target object from the drone device. The ARCS determines control information including parts geometry of the target object, a task trajectory of a task to be performed on the target object, and a collision-free robotic motion trajectory for the programmable robot, and dynamically transmits the control information to the programmable robot via a communication network to adaptively control the programmable robot while accounting for misalignments of the target object in the work environment."
Drone Assisted Adaptive Robot Control,https://lens.org/096-296-383-498-246,2016,"A method, a drone device, and an adaptive robot control system (ARCS) for adaptively controlling a programmable robot are provided. The ARCS receives environmental parameters of a work environment where the drone device operates and geometrical information of a target object to be operated on by the programmable robot. The ARCS dynamically receives a calibrated spatial location of the target object in the work environment based on the environmental parameters and a discernment of the target object from the drone device. The ARCS determines control information including parts geometry of the target object, a task trajectory of a task to be performed on the target object, and a collision-free robotic motion trajectory for the programmable robot, and dynamically transmits the control information to the programmable robot via a communication network to adaptively control the programmable robot while accounting for misalignments of the target object in the work environment."
Voice-controllable unmanned aerial vehicle for object retrieval and delivery,https://lens.org/003-990-728-300-597,2021,"Described herein are systems, devices, methods, computer-readable media, techniques, and methodologies for object retrieval and delivery using an unmanned aerial vehicle (UAV) such as a drone. The UAV receives user input from a user such as audial input and processes the input to determine a user command. The user command can be a command to retrieve an object that is out of reach of the user. The UAV scans the environment capturing image data using on-board sensors. The image data can be fed to a neural network trained in object detection to identify the object in the environment. Once identified, the UAV can then navigate to the object, retrieve the object, and deliver the object to a target individual or location such as a location adjacent to the user."
VOICE-CONTROLLABLE UNMANNED AERIAL VEHICLE FOR OBJECT RETRIEVAL AND DELIVERY,https://lens.org/152-747-976-654-100,2020,"Described herein are systems, devices, methods, computer-readable media, techniques, and methodologies for object retrieval and delivery using an unmanned aerial vehicle (UAV) such as a drone. The UAV receives user input from a user such as audial input and processes the input to determine a user command. The user command can be a command to retrieve an object that is out of reach of the user. The UAV scans the environment capturing image data using on-board sensors. The image data can be fed to a neural network trained in object detection to identify the object in the environment. Once identified, the UAV can then navigate to the object, retrieve the object, and deliver the object to a target individual or location such as a location adjacent to the user."
External microphone for an unmanned aerial vehicle,https://lens.org/064-996-646-428-220,2017,"A videography drone can communicate with a microphone device. The videography drone can receive spatial information and audio data from a remote microphone device (e.g., a remote tracker, a mobile device running a drone control application, and/or a standalone audio recording device separate from the videography drone without drone control functionalities). The videography drone can utilize the spatial information to navigate the videography drone to follow the remote microphone device. The videography drone can stitch a video segment captured by its camera with an audio segment from the received audio data to generate an audio/video (A/V) segment. The stitching can be performed by matching spatial or temporal information (e.g., from the received spatial information) associated with the audio segment against spatial or temporal information associated with the video segment."
EXTERNAL MICROPHONE FOR AN UNMANNED AERIAL VEHICLE,https://lens.org/051-597-582-773-147,2016,"A videography drone can communicate with a microphone device. The videography drone can receive spatial information and audio data from a remote microphone device (e.g., a remote tracker, a mobile device running a drone control application, and/or a standalone audio recording device separate from the videography drone without drone control functionalities). The videography drone can utilize the spatial information to navigate the videography drone to follow the remote microphone device. The videography drone can stitch a video segment captured by its camera with an audio segment from the received audio data to generate an audio/video (A/V) segment. The stitching can be performed by matching spatial or temporal information (e.g., from the received spatial information) associated with the audio segment against spatial or temporal information associated with the video segment."
USING HANDHELD DEVICE TO CONTROL FLYING OBJECT,https://lens.org/154-298-468-954-045,2014,"Method and system for remote control of a drone helicopter and RC plane using a handheld device is disclosed. Piloting commands and actions are performed using the handheld device, which includes a motion sensor module, with gyro-sensor and g-sensor for controlling roll, yaw and pitch of flying object under relative or absolute coordinate system. The gyro-sensor controls both heading and rotation of flying object in place around its yaw by rotating handheld device around its yaw axis; g-sensor controls pitch and roll by rotating handheld device around its pitch axis and roll axes. Upon determining free falling of flying object, throttle is thereby adjusted so as to land it safely. Flying object further has a camera, and video images are transferred wireless to be displayed on touch screen, and image zoom-in and zoom-out are provided via multi-touch of touch screen. RF and IR capability is included for wireless communication."
WEARABLE UAV CONTROL DEVICE AND UAV SYSTEM,https://lens.org/087-211-252-669-795,2019,"A wearable device for controlling an unmanned aerial vehicle (UAV) includes one or more sensors configured to detect first status information of the wearable device, a communication circuit configured to transmit the first status information to the UAV and receive second status information of the UAV from the UAV, and a processor configured to generate a control instruction according to at least one of the first status information or the second status information, and control the communication circuit to transmit the control instruction to the UAV to control the UAV."
ELECTRONIC DEVICE AND METHOD FOR SIMULATING FLIGHT OF UNMANNED AERIAL VEHICLE,https://lens.org/031-171-857-432-824,2013,"A method for simulating flight operations of an unmanned aerial vehicle (UAV) using an electronic device obtains movement data of the electronic device detected by an accelerator sensor of the electronic device, and converts the movement data of the electronic device into control signals. The method further adjusts the control signals using a physics engine of the electronic device, and simulates flight operations of the UAV by controlling flight statuses of a three dimensional (3D) virtual UAV in a 3D virtual scene on a display screen of the electronic device according to the adjusted control signals."
ENHANCED DRONE VEHICLE INTEGRATION AND CONTROLS,https://lens.org/162-959-242-020-560,2021,"Systems, methods, and computer-readable media are disclosed for drone vehicle integration and controls. A vehicle device for controlling an unmanned aerial vehicle (UAV) may receive an input indicating a request to deploy the UAV from a vehicle. The vehicle device may determine that one or more deployment conditions are satisfied. The vehicle device may cause deployment of the UAV. The vehicle device may determine a control command for the UAV and a vehicle instruction associated with operating the UAV. The vehicle device may determine that the vehicle instruction has been satisfied, and may send the control command once the vehicle instruction is satisfied."
Enhanced drone vehicle integration and controls,https://lens.org/115-263-957-351-89X,2023,"Systems, methods, and computer-readable media are disclosed for drone vehicle integration and controls. A vehicle device for controlling an unmanned aerial vehicle (UAV) may receive an input indicating a request to deploy the UAV from a vehicle. The vehicle device may determine that one or more deployment conditions are satisfied. The vehicle device may cause deployment of the UAV. The vehicle device may determine a control command for the UAV and a vehicle instruction associated with operating the UAV. The vehicle device may determine that the vehicle instruction has been satisfied, and may send the control command once the vehicle instruction is satisfied."
Systems and methods for performing remote maintenance,https://lens.org/113-171-581-972-370,2022,"Various embodiments provide systems and/or methods for automated maintenance, delivery, retrieval, and/or communications using drones."
SYSTEMS AND METHODS FOR PERFORMING REMOTE MAINTENANCE,https://lens.org/098-105-868-252-621,2022,"Various embodiments provide systems and/or methods for automated maintenance, delivery, retrieval, and/or communications using drones."
Systems and methods for performing remote maintenance,https://lens.org/097-696-618-317-411,2023,"Various embodiments provide systems and/or methods for automated maintenance, delivery, retrieval, and/or communications using drones."
Systems and methods for performing remote maintenance,https://lens.org/113-171-581-972-370,2022,"Various embodiments provide systems and/or methods for automated maintenance, delivery, retrieval, and/or communications using drones."
SYSTEMS AND METHODS FOR PERFORMING REMOTE MAINTENANCE,https://lens.org/098-105-868-252-621,2022,"Various embodiments provide systems and/or methods for automated maintenance, delivery, retrieval, and/or communications using drones."
Systems and methods for performing remote maintenance,https://lens.org/097-696-618-317-411,2023,"Various embodiments provide systems and/or methods for automated maintenance, delivery, retrieval, and/or communications using drones."
Automation system and method for operating an automation system,https://lens.org/100-133-290-075-654,2022,"An automation system, comprising a control device for controlling at least one machine, and at least one unmanned aircraft. The control device is designed to control the unmanned aircraft to support an operation of the machine."
AUTOMATION SYSTEM AND METHOD FOR OPERATING AN AUTOMATION SYSTEM,https://lens.org/132-662-789-957-458,2020,"An automation system, comprising a control device for controlling at least one machine, and at least one unmanned aircraft. The control device is designed to control the unmanned aircraft to support an operation of the machine."
ELECTRONIC DEVICE AND METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE,https://lens.org/040-457-911-922-999,2012,"An electronic device for controlling an unmanned aerial vehicle (UAV) displays a portion of a 3D virtual scene of a monitored area of the UAV on a screen, and displays a representation icon of the UAV on a preset position of the screen. The electronic device further converts an operation signal to a control signal, and sends the control signal to control movements of the UAV. After receiving flight data from the UAV, the electronic device recognizes movements of the UAV according to the flight data, and determines adjustments to the portion of the 3D virtual scene, to control displaying of the 3D virtual scene based on the recognized movements while maintaining the representation icon of the UAV on the preset position and maintaining a direction the user presumed to be viewing the 3D virtual scene the same as a flight orientation of the UAV."
Autonomous drone play and directional alignment,https://lens.org/081-853-158-959-792,2022,"Embodiments provide for autonomous drone play and directional alignment by in response to receiving a command for a remotely controlled device to perform a behavior, monitoring a first series of actions performed by the remotely controlled device that comprise the behavior; receiving feedback related to how the remotely controlled device performs the behavior, wherein the feedback is received from at least one of a user, a second device, and environmental sensors; updating, according to the feedback, a machine learning model used by the remotely controlled device to produce a second, different series of actions to perform the behavior; and in response to receiving a subsequent command to perform the behavior, instructing the remotely controlled device to perform the second series of actions."
Autonomous drone play and directional alignment,https://lens.org/081-853-158-959-792,2022,"Embodiments provide for autonomous drone play and directional alignment by in response to receiving a command for a remotely controlled device to perform a behavior, monitoring a first series of actions performed by the remotely controlled device that comprise the behavior; receiving feedback related to how the remotely controlled device performs the behavior, wherein the feedback is received from at least one of a user, a second device, and environmental sensors; updating, according to the feedback, a machine learning model used by the remotely controlled device to produce a second, different series of actions to perform the behavior; and in response to receiving a subsequent command to perform the behavior, instructing the remotely controlled device to perform the second series of actions."
AUTONOMOUS DRONE PLAY AND DIRECTIONAL ALIGNMENT,https://lens.org/083-909-941-851-17X,2020,"Embodiments provide for autonomous drone play and directional alignment by in response to receiving a command for a remotely controlled device to perform a behavior, monitoring a first series of actions performed by the remotely controlled device that comprise the behavior; receiving feedback related to how the remotely controlled device performs the behavior, wherein the feedback is received from at least one of a user, a second device, and environmental sensors; updating, according to the feedback, a machine learning model used by the remotely controlled device to produce a second, different series of actions to perform the behavior; and in response to receiving a subsequent command to perform the behavior, instructing the remotely controlled device to perform the second series of actions."
Drone aircraft flight control system and method,https://lens.org/069-634-084-930-377,2015,"The invention provides a drone aircraft flight control system and method. The drone aircraft flight control system comprises a flight execution unit, a sensor unit and a flight control unit. By means of the relation existing among the wing area, the drone aircraft lift force and the flight rotating speed, the swing angle of a leading edge flap and a leading edge flap is controlled strictly, so that power consumption of an aircraft engine is reduced while enough drone aircraft lift force is ensured."
Method of remotely obtaining drone footage.,https://lens.org/001-609-039-669-753,2020,"This invention is directed toward a method by which a user desiring drone footage from a location can hire a drone owner near that location to set up the drone for remote control flight at the location. The user and owner can agree to a set of parameters prior to the flight which determine the environmental conditions under which the flight can take place, the duration of the flight, any safety protocols the parties agree to, etc. One the parameters are met, the drone owner takes the drone to the location, the user remotely connects to the drone and flies the drone subject to the parameters, then downloads the footage taken by the drone during the flight."
Method of remotely obtaining drone footage,https://lens.org/056-026-056-456-670,2021,"This invention is directed toward a method by which a user desiring drone footage from a location can hire a drone owner near that location to set up the drone for remote control flight at the location. The user and owner can agree to a set of parameters prior to the flight which determine the environmental conditions under which the flight can take place, the duration of the flight, any safety protocols the parties agree to, etc. One the parameters are met, the drone owner takes the drone to the location, the user remotely connects to the drone and flies the drone subject to the parameters, then downloads the footage taken by the drone during the flight."
UNMANNED AERIAL VEHICLE FLEET MANAGEMENT,https://lens.org/007-902-073-588-771,2020,"An unmanned aerial vehicle (UAV) includes one or more sources of propulsion coupled to provide propulsion to the UAV, and a power source coupled to power the one or more sources of propulsion. A communication system is coupled to communicate with an external device, and a controller is coupled to the communication system, the power source, and the one or more sources of propulsion. The controller includes logic that when executed by the controller causes the UAV to perform operations, including: measuring a status of the UAV; sending the status of the UAV to the external device; receiving movement instructions from the external device; and engaging the one or more sources of propulsion to move the UAV from a first location to a second location within a storage facility."
Unmanned aerial vehicle fleet management,https://lens.org/052-569-921-425-031,2022,"An unmanned aerial vehicle (UAV) includes one or more sources of propulsion coupled to provide propulsion to the UAV, and a power source coupled to power the one or more sources of propulsion. A communication system is coupled to communicate with an external device, and a controller is coupled to the communication system, the power source, and the one or more sources of propulsion. The controller includes logic that when executed by the controller causes the UAV to perform operations, including: measuring a status of the UAV; sending the status of the UAV to the external device; receiving movement instructions from the external device; and engaging the one or more sources of propulsion to move the UAV from a first location to a second location within a storage facility."
Unmanned aerial vehicle fleet management,https://lens.org/083-388-921-055-001,2020,"An unmanned aerial vehicle (UAV) includes one or more sources of propulsion coupled to provide propulsion to the UAV, and a power source coupled to power the one or more sources of propulsion. A communication system is coupled to communicate with an external device, and a controller is coupled to the communication system, the power source, and the one or more sources of propulsion. The controller includes logic that when executed by the controller causes the UAV to perform operations, including: measuring a status of the UAV; sending the status of the UAV to the external device; receiving movement instructions from the external device; and engaging the one or more sources of propulsion to move the UAV from a first location to a second location within a storage facility."
SYSTEMS AND METHODS FOR PERSONAL SECURITY USING AUTONOMOUS DRONES,https://lens.org/115-135-870-227-224,2017,"A security system includes an autonomous unmanned aerial vehicle (UAV) including an airframe with a power source and a propulsive system operatively mounted to the airframe for sustained, autonomous flight of the UAV. A flight control system is operatively connected to the airframe, propulsive system, and power source to control the sustained, autonomous flight of the UAV. An imaging device is mounted to the airframe. A wireless communication device is operatively connected to the imaging device to wirelessly transmit data including images from the imaging device. A remote server is operatively connected to receive the data transmitted wirelessly from the wireless communication device, wherein the remote server is operatively connected to communicate the data to emergency responders."
METHOD AND APPARATUS FOR PROVIDING DRONE-BASED ALERTING OF MOVEMENT OF A PART OF A VEHICLE INTO A PATH OF TRAVEL,https://lens.org/156-523-592-879-530,2020,"A method, apparatus and computer program product are provided to utilize an unmanned drone to warn a bicyclist or another vehicle of a part of a vehicle moving into the path of travel of the bicyclist or the other vehicle. In the context of a method, at least one event indicative of a door of a vehicle being opened is detected. Responsive to detection of the at least one event, the method also includes causing the drone to take an action regarding the door of the vehicle being opened into the path of the bicyclist or the other vehicle."
System and method for assisting autonomous driving of vehicle using drone,https://lens.org/012-755-798-435-039,2021,A system assisting autonomous driving using a drone include: a drone obtaining peripheral information through at least one or more detectors; a vehicle performing autonomous driving by using the peripheral information; and a server lending the drone in response to a drone rental request of the vehicle and assisting the autonomous driving of the vehicle.
SYSTEM AND METHOD FOR ASSISTING AUTONOMOUS DRIVING OF VEHICLE USING DRONE,https://lens.org/041-645-037-782-460,2020,A system assisting autonomous driving using a drone include: a drone obtaining peripheral information through at least one or more detectors; a vehicle performing autonomous driving by using the peripheral information; and a server lending the drone in response to a drone rental request of the vehicle and assisting the autonomous driving of the vehicle.
SYSTEM AND METHOD FOR GROUND OBJECTS MANIPULATION USING A DRONE,https://lens.org/084-871-900-879-729,2023,"The present invention relates to a system and method for ground object manipulation using a drone (UAV). The drone is configured with the camera(s) facing downwards to capture a real-time video feed of a top view of an AOI, which is then transmitted to the display screen of the mobile device associated with a user. The video feed is displayed on the display screen, which facilitates the user to use a marker on the display screen to select a target 2D location (object) in the AOI. The user can then operate a trigger of the remote controller to start the movement of the drone. The system then determines an optimal target velocity command for the drone to reach the selected target location, and automatically maneuvers the drone to the target location at the target velocity, and converges the drone around the desired target. The vertical movement of the drone above the target location is then controlled using the controller. The drone includes a motorized arm to grab/release the target objects."
SYSTEM AND METHOD FOR GROUND OBJECTS MANIPULATION USING A DRONE,https://lens.org/084-871-900-879-729,2023,"The present invention relates to a system and method for ground object manipulation using a drone (UAV). The drone is configured with the camera(s) facing downwards to capture a real-time video feed of a top view of an AOI, which is then transmitted to the display screen of the mobile device associated with a user. The video feed is displayed on the display screen, which facilitates the user to use a marker on the display screen to select a target 2D location (object) in the AOI. The user can then operate a trigger of the remote controller to start the movement of the drone. The system then determines an optimal target velocity command for the drone to reach the selected target location, and automatically maneuvers the drone to the target location at the target velocity, and converges the drone around the desired target. The vertical movement of the drone above the target location is then controlled using the controller. The drone includes a motorized arm to grab/release the target objects."
Method for controlling unmanned aerial vehicle,https://lens.org/059-571-226-785-841,2015,"The invention discloses a method for controlling an unmanned aerial vehicle. The method includes the steps that position information of a remote controller is sent to the unmanned aerial vehicle through the remote controller; the unmanned aerial vehicle follows the remote controller to move; when signals of the unmanned aerial vehicle and the remote controller are interrupted, the unmanned aerial vehicle calls the all stored position information and the received time of the position information to calculate and obtain an estimated path and the average speed of the remote controller; the unmanned aerial vehicle calls map data to calculate and obtain estimated tracking time; the unmanned aerial vehicle flies at the maximum speed in the possible movement direction till being in communication with the remote controller again; if the unmanned aerial vehicle is not in communication with the remote controller in the estimated tracking time, the unmanned aerial vehicle directly flies to a preset coordinate position. By means of the method, the unmanned aerial vehicle is convenient to control when the remote controller is moved."
External microphone for an unmanned aerial vehicle,https://lens.org/049-170-586-555-329,2018,"Several embodiments include a remote tracker for a videography drone. The remote tracker can include a spatial information sensor and a microphone configured to capture audio data surrounding the remote tracker. The remote tracker can also include a logic control component configured to decorate the audio data with location-based metadata or temporal metadata. A network interface of the remote tracker can communicate with the videography drone, including streaming the audio data captured by the microphone to the videography drone."
SYSTEMS AND METHODS FOR 3D MODEL BASED DRONE FLIGHT PLANNING AND CONTROL,https://lens.org/081-456-567-476-506,2022,"A method for controlling a plurality of drones to survey a location, the method comprising, at a computing system: automatically generating preliminary' flight plans for a plurality of drones to survey the location based on a 3D model; receiving survey data from the plurality of drones as the plurality of drones are surveying the location based on the preliminary flight plans: updating the 3D model based on the survey data received from the plurality of drones; and automatically updating at least a portion of the flight plans based on the updated 3D model."
SYSTEMS AND METHODS FOR 3D MODEL BASED DRONE FLIGHT PLANNING AND CONTROL,https://lens.org/081-456-567-476-506,2022,"A method for controlling a plurality of drones to survey a location, the method comprising, at a computing system: automatically generating preliminary' flight plans for a plurality of drones to survey the location based on a 3D model; receiving survey data from the plurality of drones as the plurality of drones are surveying the location based on the preliminary flight plans: updating the 3D model based on the survey data received from the plurality of drones; and automatically updating at least a portion of the flight plans based on the updated 3D model."
SYSTEMS AND METHODS FOR 3D MODEL BASED DRONE FLIGHT PLANNING AND CONTROL,https://lens.org/081-456-567-476-506,2022,"A method for controlling a plurality of drones to survey a location, the method comprising, at a computing system: automatically generating preliminary' flight plans for a plurality of drones to survey the location based on a 3D model; receiving survey data from the plurality of drones as the plurality of drones are surveying the location based on the preliminary flight plans: updating the 3D model based on the survey data received from the plurality of drones; and automatically updating at least a portion of the flight plans based on the updated 3D model."
SYSTEM AND METHOD FOR INDICATING DRONES FLYING OVERHEAD,https://lens.org/101-892-268-639-752,2019,"A system and method for tracking and alerting a drone flying overhead are provided herein. The method includes acquiring a first data associated with a user device position; detecting a path corresponding to movement of the user device; receiving, from a server at the user device, drone data associated with a plurality of drones; filtering the drone data to obtain a second data associated with a drone position and a respective drone route which intersects with the path; predicting an intersection area; determining a distance between the user device position and the drone position based on the first data and the second data; determining whether a determined distance is equal to or less than a preset distance; and instructing a user to change the path or the speed of travel down a path when the determined distance is equal to or less than the preset distance."
System and method for indicating drones flying overhead,https://lens.org/084-328-646-200-025,2020,"A system and method for tracking and alerting a drone flying overhead are provided herein. The method includes acquiring a first data associated with a user device position; detecting a path corresponding to movement of the user device; receiving, from a server at the user device, drone data associated with a plurality of drones; filtering the drone data to obtain a second data associated with a drone position and a respective drone route which intersects with the path; predicting an intersection area; determining a distance between the user device position and the drone position based on the first data and the second data; determining whether a determined distance is equal to or less than a preset distance; and instructing a user to change the path or the speed of travel down a path when the determined distance is equal to or less than the preset distance."
SYSTEM AND METHOD FOR INDICATING DRONES FLYING OVERHEAD,https://lens.org/096-815-890-725-628,2019,"A system and method for tracking and alerting a drone flying overhead are provided herein. The method includes acquiring a first data associated with a user device position; detecting a path corresponding to movement of the user device; receiving, from a server at the user device, drone data associated with a plurality of drones; filtering the drone data to obtain a second data associated with a drone position and a respective drone route which intersects with the path; predicting an intersection area; determining a distance between the user device position and the drone position based on the first data and the second data; determining whether a determined distance is equal to or less than a preset distance; and instructing a user to change the path or the speed of travel down a path when the determined distance is equal to or less than the preset distance."
Automation methods for UAV perching on pipes,https://lens.org/080-185-417-582-110,2022,"An unmanned aerial vehicle (UAV) autonomously perching on a curved surface from a starting position is provided. The UAV includes: a 3D depth camera configured to capture and output 3D point clouds of scenes from the UAV including the curved surface; a 2D LIDAR system configured to capture and output 2D slices of the scenes; and a control circuit. The control circuit is configured to: control the depth camera and the LIDAR system to capture the 3D point clouds and the 2D slices, respectively, of the scenes; input the captured 3D point clouds from the depth camera and the captured 2D slices from the LIDAR system; autonomously detect and localize the curved surface using the captured 3D point clouds and 2D slices; and autonomously direct the UAV from the starting position to a landing position on the curved surface based on the autonomous detection and localization of the curved surface."
Quadcopter combined with intelligent mobile phone,https://lens.org/061-131-145-393-937,2015,"The invention discloses a quadcopter combined with an intelligent mobile phone. The quadcopter comprises a remote end control end, the intelligent mobile phone and a flight control circuit board, wherein the intelligent mobile phone is communicated with the remote end control end, and is connected with the flight control circuit board; the remote end control end is used for sending control commas to the intelligent mobile phone; in addition, the intelligent mobile phone sends the control commands to the flight control circuit board; the intelligent mobile phone further obtains one or total sensor parameters of a self GPS (global positioning system), an accelerator and a compass when the quadcopter flies; in addition, all parameters are transmitted to the flight control circuit board; the flight control circuit board calculates the rotating speed of a motor according to the command parameters and the sensor parameters, so that the motor outputs the corresponding rotating speed, and the positioning and the flight of the quadcopter are realized."
Remotely controlled multirotor aircraft controlled by human voice,https://lens.org/164-542-125-371-416,2022,"A multi-rotor remote control aircraft for capturing audio and/or video signals and a method for remote controlling the aircraft by way of voice commands. The aircraft and method mitigate the effects of audio noise produced by motors and propellers on reception and detection of the voice commands. Audio acquisition components are provided for receiving the voice commands while noise acquisition components are devoted for capturing the environmental noise. The mitigation of the noise effects is achieved by filtering and a cancellation technique. With the cancellation technique, the noise part contained in the signal captured by the noise acquisition components is equalized to the noise part contained in an audio signal carrying the voice commands and then it is subtracted from the audio signal."
Remotely Controlled Multirotor Aircraft Controlled by Human Voice,https://lens.org/125-735-049-198-485,2020,"A multi-rotor remote control aircraft for capturing audio and/or video signals and a method for remote controlling the aircraft by way of voice commands. The aircraft and method mitigate the effects of audio noise produced by motors and propellers on reception and detection of the voice commands. Audio acquisition components are provided for receiving the voice commands while noise acquisition components are devoted for capturing the environmental noise. The mitigation of the noise effects is achieved by filtering and a cancellation technique. With the cancellation technique, the noise part contained in the signal captured by the noise acquisition components is equalized to the noise part contained in an audio signal carrying the voice commands and then it is subtracted from the audio signal."
Remotely controlled multirotor aircraft controlled by human voice,https://lens.org/164-542-125-371-416,2022,"A multi-rotor remote control aircraft for capturing audio and/or video signals and a method for remote controlling the aircraft by way of voice commands. The aircraft and method mitigate the effects of audio noise produced by motors and propellers on reception and detection of the voice commands. Audio acquisition components are provided for receiving the voice commands while noise acquisition components are devoted for capturing the environmental noise. The mitigation of the noise effects is achieved by filtering and a cancellation technique. With the cancellation technique, the noise part contained in the signal captured by the noise acquisition components is equalized to the noise part contained in an audio signal carrying the voice commands and then it is subtracted from the audio signal."
AUDIO TONE ASSISTED RCU PROGRAMMING,https://lens.org/124-584-489-791-416,2022,A control device is used to autonomously program a remote control device based on media device information received from a media device. The control device selects a program code set based on the media device information. The control device transmits a program code set to the remote control device and a test command. The test command causes the remote control device to transmit a program code from the program code set based on the test command. The control device monitors the media device and verifies that the program code associated with the test command controlled the associated function of the media device.
AUDIO TONE ASSISTED RCU PROGRAMMING,https://lens.org/124-584-489-791-416,2022,A control device is used to autonomously program a remote control device based on media device information received from a media device. The control device selects a program code set based on the media device information. The control device transmits a program code set to the remote control device and a test command. The test command causes the remote control device to transmit a program code from the program code set based on the test command. The control device monitors the media device and verifies that the program code associated with the test command controlled the associated function of the media device.
AUDIO TONE ASSISTED RCU PROGRAMMING,https://lens.org/110-912-972-798-88X,2022,A control device is used to autonomously program a remote control device based on media device information received from a media device. The control device selects a program code set based on the media device information. The control device transmits a program code set to the remote control device and a test command. The test command causes the remote control device to transmit a program code from the program code set based on the test command. The control device monitors the media device and verifies that the program code associated with the test command controlled the associated function of the media device.
AUDIO TONE ASSISTED RCU PROGRAMMING,https://lens.org/110-912-972-798-88X,2022,A control device is used to autonomously program a remote control device based on media device information received from a media device. The control device selects a program code set based on the media device information. The control device transmits a program code set to the remote control device and a test command. The test command causes the remote control device to transmit a program code from the program code set based on the test command. The control device monitors the media device and verifies that the program code associated with the test command controlled the associated function of the media device.
DRONE BLADE GUARD SYSTEM,https://lens.org/009-782-979-544-571,2020,"A drone capable of flight includes a frame, an engine supported by the frame, a blade connected to the engine and rotatable in response to operation of the engine, a blade stop mechanism coupled to the frame and movable between a first position in which the blade is free to rotate and a second position in which rotation of the blade is inhibited, and a sense line coupled to the frame and at least partially surrounding the blade, the sense line operable to detect an external object, and wherein the blade stop mechanism transitions from the first position to the second position in response to the detection of the external object."
OPTIMIZING PROPELLER DIRECTION IN DRONE DESIGN USING ONBOARD NETWORK OF SENSORS,https://lens.org/186-471-737-024-194,2019,"A drone (100) includes one or more rotatable propellers (104a, 104b) and one or more fixed propellers (104c, 104d, 104e) powered by one or more battery powered electric motors for providing upward and forward thrust to the drone (100) during upward and forward movement of the drone (100) respectively. The drone (100) includes a set of sensors, so as to align the rotatable propellers (104a, 104b) in the direction of the movement of the drone (100) based on sensed data."
Personal Security Robotic Vehicle,https://lens.org/023-700-104-315-974,2019,"Various methods for monitoring a target user by a drone include tracking the target user by the drone, detecting an object in the presence of the target user based on one or more detection criteria, determining whether the object is a potential threat to the target user based on one or more threat criteria, determining whether to notify the third party of the potential threat to the target user based on one or more notification criteria in response to determining that the object is a potential threat, notifying the third party of the potential threat to the target user in response to determining that the third party should be notified, receiving a response from the third party including a command, and performing an action based on the command."
Personal security robotic vehicle,https://lens.org/024-775-833-503-919,2020,"Various methods for monitoring a target user by a drone include tracking the target user by the drone, detecting an object in the presence of the target user based on one or more detection criteria, determining whether the object is a potential threat to the target user based on one or more threat criteria, determining whether to notify the third party of the potential threat to the target user based on one or more notification criteria in response to determining that the object is a potential threat, notifying the third party of the potential threat to the target user in response to determining that the third party should be notified, receiving a response from the third party including a command, and performing an action based on the command."
SYSTEM FOR INTEGRATING A DIESEL ENGINE IN A DRONE,https://lens.org/145-301-132-091-678,2012,"The present invention relates to a rotary-wing drone (1) comprising a frame in which are located: - a set of sensors (13) designed for performing tasks of surveillance and/or intelligence gathering and/or assisting with the guidance of the drone (1), and - a control unit (14) associated with this set of sensors (13), characterized in that it comprises a diesel engine (4)."
Surveillance Drone with Microbots,https://lens.org/073-952-695-267-98X,2020,"A drone which carries out surveillance by surveilling the user's property. Items in the property can be mapped by the drone. People come on the property can be imaged, and use image processing to compare the image of the people with known images of known people. An alarm can because when an unknown person comes. When the packages delivered, the drone can carry out surveillance on the package, including imaging the outside of the package in the inside of the package."
Surveillance drone with microbots,https://lens.org/136-880-688-680-577,2022,"A drone which carries out surveillance by surveilling the user's property. Items in the property can be mapped by the drone. People come on the property can be imaged, and use image processing to compare the image of the people with known images of known people. An alarm can because when an unknown person comes. When the packages delivered, the drone can carry out surveillance on the package, including imaging the outside of the package in the inside of the package."
Unmanned aerial vehicle with detachable computing device,https://lens.org/015-575-579-770-057,2019,"This disclosure is generally directed to an Unmanned Aerial Device (UAV) that uses a removable computing device for command and control. The UAV may include an airframe with rotors and an adjustable cradle to attach a computing device. The computing device, such as a smart phone, tablet, MP3 player, or the like, may provide the necessary avionics and computing equipment to control the UAV autonomously. For example, the adjustable cradle may be extended to fit a tablet or other large computing device, or retracted to fit a smart phone or other small computing device. Thus, the adjustable cradle may provide for the attachment and use of a plurality of different computing devices in conjunction with a single airframe. Additionally the UAV may comprise adjustable arms to assist in balancing the load of the different computing devices and/or additional equipment attached to the airframe."
UNMANNED AERIAL VEHICLE WITH DETACHABLE COMPUTING DEVICE,https://lens.org/028-106-155-860-809,2016,"This disclosure is generally directed to an Unmanned Aerial Device (UAV) that uses a removable computing device for command and control. The UAV may include an airframe with rotors and an adjustable cradle to attach a computing device. The computing device, such as a smart phone, tablet, MP3 player, or the like, may provide the necessary avionics and computing equipment to control the UAV autonomously. For example, the adjustable cradle may be extended to fit a tablet or other large computing device, or retracted to fit a smart phone or other small computing device. Thus, the adjustable cradle may provide for the attachment and use of a plurality of different computing devices in conjunction with a single airframe. Additionally the UAV may comprise adjustable arms to assist in balancing the load of the different computing devices and/or additional equipment attached to the airframe."
UNMANNED AERIAL VEHICLE WITH DETACHABLE COMPUTING DEVICE,https://lens.org/031-586-235-997-999,2018,"This disclosure is generally directed to an Unmanned Aerial Device (UAV) that uses a removable computing device for command and control. The UAV may include an airframe with rotors and an adjustable cradle to attach a computing device. The computing device, such as a smart phone, tablet, MP3 player, or the like, may provide the necessary avionics and computing equipment to control the UAV autonomously. For example, the adjustable cradle may be extended to fit a tablet or other large computing device, or retracted to fit a smart phone or other small computing device. Thus, the adjustable cradle may provide for the attachment and use of a plurality of different computing devices in conjunction with a single airframe. Additionally the UAV may comprise adjustable arms to assist in balancing the load of the different computing devices and/or additional equipment attached to the airframe."
Unmanned aerial vehicle with detachable computing device,https://lens.org/105-073-558-008-234,2019,"This disclosure is generally directed to an Unmanned Aerial Device (UAV) that uses a removable computing device for command and control. The UAV may include an airframe with rotors and an adjustable cradle to attach a computing device. The computing device, such as a smart phone, tablet, MP3 player, or the like, may provide the necessary avionics and computing equipment to control the UAV autonomously. For example, the adjustable cradle may be extended to fit a tablet or other large computing device, or retracted to fit a smart phone or other small computing device. Thus, the adjustable cradle may provide for the attachment and use of a plurality of different computing devices in conjunction with a single airframe. Additionally the UAV may comprise adjustable arms to assist in balancing the load of the different computing devices and/or additional equipment attached to the airframe."
Unmanned aerial vehicle with detachable computing device,https://lens.org/175-631-671-726-070,2017,"This disclosure is generally directed to an Unmanned Aerial Device (UAV) that uses a removable computing device for command and control. The UAV may include an airframe with rotors and an adjustable cradle to attach a computing device. The computing device, such as a smart phone, tablet, MP3 player, or the like, may provide the necessary avionics and computing equipment to control the UAV autonomously. For example, the adjustable cradle may be extended to fit a tablet or other large computing device, or retracted to fit a smart phone or other small computing device. Thus, the adjustable cradle may provide for the attachment and use of a plurality of different computing devices in conjunction with a single airframe. Additionally the UAV may comprise adjustable arms to assist in balancing the load of the different computing devices and/or additional equipment attached to the airframe."
Unmanned aerial vehicle with detachable computing device,https://lens.org/072-398-606-861-919,2017,"This disclosure is generally directed to an Unmanned Aerial Device (UAV) that uses a removable computing device for command and control. The UAV may include an airframe with rotors and an adjustable cradle to attach a computing device. The computing device, such as a smart phone, tablet, MP3 player, or the like, may provide the necessary avionics and computing equipment to control the UAV autonomously. For example, the adjustable cradle may be extended to fit a tablet or other large computing device, or retracted to fit a smart phone or other small computing device. Thus, the adjustable cradle may provide for the attachment and use of a plurality of different computing devices in conjunction with a single airframe. Additionally the UAV may comprise adjustable arms to assist in balancing the load of the different computing devices and/or additional equipment attached to the airframe."
UNMANNED AERIAL VEHICLE WITH DETACHABLE COMPUTING DEVICE,https://lens.org/063-608-663-235-523,2016,"This disclosure is generally directed to an Unmanned Aerial Device (UAV) that uses a removable computing device for command and control. The UAV may include an airframe with rotors and an adjustable cradle to attach a computing device. The computing device, such as a smart phone, tablet, MP3 player, or the like, may provide the necessary avionics and computing equipment to control the UAV autonomously. For example, the adjustable cradle may be extended to fit a tablet or other large computing device, or retracted to fit a smart phone or other small computing device. Thus, the adjustable cradle may provide for the attachment and use of a plurality of different computing devices in conjunction with a single airframe. Additionally the UAV may comprise adjustable arms to assist in balancing the load of the different computing devices and/or additional equipment attached to the airframe."
Virtual reality system with drone integration,https://lens.org/011-864-478-496-517,2020,"A virtual reality system includes a drone including a rotor, a display, an audio speaker, a body harness having adjustable straps, and one or more processors in operative communication with the display, the audio speaker, and the drone. The drone may be fixed to the body harness. The one or more processors may be configured to issue audio-visual content to the display and audio speaker and control the rotor based on the issued audio-visual content."
Drone provided with a video camera and means for compensating for the artefacts produced at the highest roll angles,https://lens.org/108-759-722-840-889,2019,"The drone comprises a camera, an inertial unit measuring the drone angles, and an extractor module delivering data of an image area (ZI) of reduced size defined inside a capture area (ZC) of the sensor. A feedback-control module dynamically modifies the position and the orientation of the image area inside the capture area, in a direction opposite to that of the angle variations measured by the inertial unit. The sensor may operate according to a plurality of different configurations able to be dynamically selected, with a base configuration using a base capture area (ZCB) for low values of roll angle (), and at least one degraded mode configuration using an extended capture area (ZCE) of greater size than the base capture area (ZCB), for high values of roll angle ()."
DRONE PROVIDED WITH A VIDEO CAMERA AND MEANS FOR COMPENSATING FOR THE ARTEFACTS PRODUCED AT THE HIGHEST ROLL ANGLES,https://lens.org/110-921-167-817-368,2018,"The drone comprises a camera, an inertial unit measuring the drone angles, and an extractor module delivering data of an image area (ZI) of reduced size defined inside a capture area (ZC) of the sensor. A feedback-control module dynamically modifies the position and the orientation of the image area inside the capture area, in a direction opposite to that of the angle variations measured by the inertial unit. The sensor may operate according to a plurality of different configurations able to be dynamically selected, with a base configuration using a base capture area (ZCB) for low values of roll angle (), and at least one degraded mode configuration using an extended capture area (ZCE) of greater size than the base capture area (ZCB), for high values of roll angle ()."
DRONE PROVIDED WITH A VIDEO CAMERA AND MEANS FOR COMPENSATING FOR THE ARTEFACTS PRODUCED AT THE HIGHEST ROLL ANGLES,https://lens.org/145-283-480-048-493,2016,"The drone comprises a camera, an inertial unit measuring the drone angles, and an extractor module delivering data of an image area (ZI) of reduced size defined inside a capture area (ZC) of the sensor. A feedback-control module dynamically modifies the position and the orientation of the image area inside the capture area, in a direction opposite to that of the angle variations measured by the inertial unit. The sensor may operate according to a plurality of different configurations able to be dynamically selected, with a base configuration using a base capture area (ZCB) for low values of roll angle (), and at least one degraded mode configuration using an extended capture area (ZCE) of greater size than the base capture area (ZCB), for high values of roll angle ()."
Drone provided with a video camera and means for compensating for the artefacts produced at the highest roll angles,https://lens.org/150-262-030-549-264,2018,"The drone comprises a camera, an inertial unit measuring the drone angles, and an extractor module delivering data of an image area (ZI) of reduced size defined inside a capture area (ZC) of the sensor. A feedback-control module dynamically modifies the position and the orientation of the image area inside the capture area, in a direction opposite to that of the angle variations measured by the inertial unit. The sensor may operate according to a plurality of different configurations able to be dynamically selected, with a base configuration using a base capture area (ZCB) for low values of roll angle (), and at least one degraded mode configuration using an extended capture area (ZCE) of greater size than the base capture area (ZCB), for high values of roll angle ()."
Commercial drone detection,https://lens.org/126-943-072-171-38X,2019,"One embodiment provides a method of capturing the presence of a drone, including: collecting, using at least one sensor, data associated with an aerial object; analyzing, using a processor, the data to determine at least one characteristic of the aerial object; accessing, in a database, a library of stored characteristics of commercially available drones; determining, based on the analyzing, if the at least one characteristic of the aerial object matches a characteristic of a commercially available drone; and responsive to the determining, generating an indication of a positive match. Other aspects are described and claimed."
COMMERCIAL DRONE DETECTION,https://lens.org/070-069-377-459-925,2017,"One embodiment provides a method of capturing the presence of a drone, including: collecting, using at least one sensor, data associated with an aerial object; analyzing, using a processor, the data to determine at least one characteristic of the aerial object; accessing, in a database, a library of stored characteristics of commercially available drones; determining, based on the analyzing, if the at least one characteristic of the aerial object matches a characteristic of a commercially available drone; and responsive to the determining, generating an indication of a positive match. Other aspects are described and claimed."
GEOFENCED AUTONOMOUS AQUATIC DRONE,https://lens.org/079-328-978-030-885,2022,"A geofenced autonomous aquatic drone for repelling sharks from a shoreline. The drone employs a buoyant housing resembling a portion of a predator such as an orca whale. A battery positioned within the drone is recharged through a floating inductive charging station. A transmitter unit coupled to at least one under water transducer introduces certain sounds, such as reproduction of orca whale or dolphin calling sounds. A propulsion system controlled a microprocessor receives location information via DGPS for providing a geofence around an area to be patrolled. The drone travels within the geofence area, monitored by the DGPS receiver, while said transducer produces certain sounds and or a solution of shark repellant is dispensed."
GEOFENCED AUTONOMOUS AQUATIC DRONE,https://lens.org/079-328-978-030-885,2022,"A geofenced autonomous aquatic drone for repelling sharks from a shoreline. The drone employs a buoyant housing resembling a portion of a predator such as an orca whale. A battery positioned within the drone is recharged through a floating inductive charging station. A transmitter unit coupled to at least one under water transducer introduces certain sounds, such as reproduction of orca whale or dolphin calling sounds. A propulsion system controlled a microprocessor receives location information via DGPS for providing a geofence around an area to be patrolled. The drone travels within the geofence area, monitored by the DGPS receiver, while said transducer produces certain sounds and or a solution of shark repellant is dispensed."
Handsfree Autonomous Umbrella Assembly,https://lens.org/177-997-721-609-892,2021,"A handsfree autonomous umbrella assembly for shielding a user from the elements includes an umbrella and a drone module. The umbrella comprises a shaft and a frame, which has a canopy engaged thereto. The frame is engaged to a first end of the shaft and can be selectively positioned in a collapsed configuration and a deployed configuration, wherein the frame has a concave face and a convex face. The shaft extends from the concave face. The drone module is engaged to the shaft and receives commands to selectively provide directional thrust. A control unit transmits commands to the drone module, enabling the drone module to track the control unit. The control unit is positioned to command the drone module to maintain a relative position above a user who possesses the control unit. The canopy thus shields the user from the elements."
Vehicle inspection,https://lens.org/151-757-511-663-931,2020,"A system includes a computer that is programmed to receive, from an aerial drone, image data that identifies a vehicle, a vehicle location, and a vehicle status; and based on the received image data, transmit an instruction to the vehicle to actuate a vehicle component."
VEHICLE INSPECTION,https://lens.org/180-265-815-926-260,2019,"A system includes a computer that is programmed to receive, from an aerial drone, image data that identifies a vehicle, a vehicle location, and a vehicle status; and based on the received image data, transmit an instruction to the vehicle to actuate a vehicle component."
Systems and methods for the remote piloting of an electric aircraft,https://lens.org/000-007-980-088-097,2023,"A system and method for the remote piloting of an electric aircraft is illustrated. The system comprises a remote device located outside an electric aircraft, wherein the remote device is configured to receive a flight command input from a user and transmit the flight command input to a flight controller located on the aircraft. The flight controller is located inside the aircraft and configured to receive the flight command input from the remote device and enact the flight command autonomously as a function of the flight command input."
Remote control device with smart card capability,https://lens.org/053-925-670-143-922,2005,"A remote control device including a processor, a transmitter in communication with the processor, a receiver in communication with the processor, and a smart card reader/writer in communication with the processor."
Remote control device with smart card capability,https://lens.org/060-240-450-833-173,2002,"A remote control device including a processor, a transmitter in communication with the processor, a receiver in communication with the processor, and a smart card reader/writer in communication with the processor."
ANTENNA APPARATUS FOR IDENTIFYING DRONE AND OPERATION METHOD THEREOF,https://lens.org/169-444-580-640-06X,2022,An antenna apparatus for drone identification and an operating method thereof are provided. The antenna apparatus includes: a plurality of horizontal directional antennas; a vertical directional antenna positioned at a center of an area surrounded by the plurality of horizontal directional antennas; a beamforming unit controlling beamforming of the vertical directional antenna and the plurality of horizontal antennas to transmit and receive signals in all directions; and a power supply unit for suppling power.
ANTENNA APPARATUS FOR IDENTIFYING DRONE AND OPERATION METHOD THEREOF,https://lens.org/169-444-580-640-06X,2022,An antenna apparatus for drone identification and an operating method thereof are provided. The antenna apparatus includes: a plurality of horizontal directional antennas; a vertical directional antenna positioned at a center of an area surrounded by the plurality of horizontal directional antennas; a beamforming unit controlling beamforming of the vertical directional antenna and the plurality of horizontal antennas to transmit and receive signals in all directions; and a power supply unit for suppling power.
DRONE-BASED INTERACTIVE AND ACTIVE AUDIO SYSTEM,https://lens.org/007-379-671-712-310,2019,A drone-based audio system comprising a microphone mounted to a drone body for receiving environmental sound information. The drone-based audio system additionally comprising a processing unit configured to analyze the environmental sound information and calculate active noise cancellation information. The drone-based audio system further comprising a speaker mounted to the drone body for emitting the active noise cancellation information.
METHOD FOR CONTROLLING A ROBOT-AIRCRAFT AND CORRESPONDING CONTROL SYSTEM,https://lens.org/003-774-408-866-026,2023,"Method for controlling an unmanned aircraft piloted by a fully autonomous control system including a first decision module and a simplex piloting control module including a high-performance controller, a high-safety controller and a second decision module, the high-performance and high-safety controllers determining piloting commands for the robot-aircraft, according to which: as long as a set of conditions is verified, implementation by the first decision module of a nominal piloting mode with delivery to the output of the automatic control system of the piloting commands delivered to the output of the simplex piloting control module; otherwise, switching to an emergency piloting mode, an emergency piloting command is delivered to the output of the automatic control system for execution by the robot-aircraft, the first decision module preventing the delivery to the output of the automatic control system of the piloting commands delivered to the output of the simplex module."
Property Preview Drone System and Method,https://lens.org/199-568-652-857-050,2016,"A method of home inspection comprising guiding a drone through a home along a selected inspection path, transmitting signals from the drone to establishing a flight path through the home, storing the flight path on a server, accessing the flight path from a programmed interactive digital device, launching the drone using said programmed interactive digital device, directing the drone through the home along the flight path and transmitting video signals from the drone and employing the video signals to provide a visual view of the property on a display of the interactive digital device. In another embodiment, the buyer can guide the drone along a flight path determined by the buyer in real time."
Property preview drone system and method,https://lens.org/095-832-755-648-146,2017,"A method of home inspection comprising guiding a drone through a home along a selected inspection path, transmitting signals from the drone to establishing a flight path through the home, storing the flight path on a server, accessing the flight path from a programmed interactive digital device, launching the drone using said programmed interactive digital device, directing the drone through the home along the flight path and transmitting video signals from the drone and employing the video signals to provide a visual view of the property on a display of the interactive digital device. In another embodiment, the buyer can guide the drone along a flight path determined by the buyer in real time."
POLICE DRONE,https://lens.org/063-696-612-080-739,2014,"To provide a police drone (20) for assisting in controlling road traffic issues. A modified drone (20) is used with many built-in devices and mechanisms; a camera (21) is installed in the front side to update a policeman in a patrol, or a control/command center. A mini-scanner (22) is installed in the rear side to scan the documents of a driver sharing in an accident or violating traffic rules, while a mini-printer (23) is installed in the front side under the camera (21) to print traffic fine, police report... etc. The communication in-between the policeman and a driver can be monitored via the camera (21), the speaker (24) at the front bottom side, and the microphone (25) that is installed in the front side in- between the printer (23) and the camera (21 ). A net of diodes (27) screen (26), rotatable around a tubular motor (28) built-in along the lower body of the drone, is expanded down, to show orders to guide drivers."
POLICE DRONE,https://lens.org/008-460-421-175-772,2014,"To provide a police drone (20) for assisting in controlling road traffic issues. A modified drone (20) is used with many built-in devices and mechanisms; a camera (21) is installed in the front side to update a policeman in a patrol, or a control/command center. A mini-scanner (22) is installed in the rear side to scan the documents of a driver sharing in an accident or violating traffic rules, while a mini-printer (23) is installed in the front side under the camera (21) to print traffic fine, police report... etc. The communication in-between the policeman and a driver can be monitored via the camera (21), the speaker (24) at the front bottom side, and the microphone (25) that is installed in the front side in- between the printer (23) and the camera (21 ). A net of diodes (27) screen (26), rotatable around a tubular motor (28) built-in along the lower body of the drone, is expanded down, to show orders to guide drivers."
COOPERATIVE UNMANNED AUTONOMOUS AERIAL VEHICLES FOR POWER GRID INSPECTION AND MANAGEMENT,https://lens.org/025-252-321-065-779,2021,"An embodiment provides unmanned aerial vehicles (UAVs) for infrastructure surveillance and monitoring. One example includes monitoring power grid components such as high voltage power lines. The UAVs may coordinate, for example using swarm behavior, and be controlled via a platform system. Other embodiments are described and claimed."
POLICE DRONE,https://lens.org/063-295-821-700-829,2015,"To provide a police drone (20) for assisting in controlling road traffic issues. A modified drone (20) is used with many built-in devices and mechanisms; a camera (21) is installed in the front side to update a policeman in a patrol, or a control/command center. A mini- scanner (22) is installed in the rear side to scan the documents of a driver sharing in an accident or violating traffic rules, while a mini-printer (23) is installed in the front side under the camera (21) to print traffic fine, police report... etc. The communication in-between the policeman and a driver can be monitored via the camera (21), the speaker (24) at the front bottom side, and the microphone (25) that is installed in the front side in- between the printer (23) and the camera (21 ). A net of diodes (27) screen (26), rotatable around a tubular motor (28) built-in along the lower body of the drone, is expanded down, to show orders to guide drivers."
POLICE DRONE,https://lens.org/197-893-163-109-197,2015,"To provide a police drone (20) for assisting in controlling road traffic issues. A modified drone (20) is used with many built-in devices and mechanisms; a camera (21) is installed in the front side to update a policeman in a patrol, or a control/command center. A mini- scanner (22) is installed in the rear side to scan the documents of a driver sharing in an accident or violating traffic rules, while a mini-printer (23) is installed in the front side under the camera (21) to print traffic fine, police report... etc. The communication in-between the policeman and a driver can be monitored via the camera (21), the speaker (24) at the front bottom side, and the microphone (25) that is installed in the front side in- between the printer (23) and the camera (21 ). A net of diodes (27) screen (26), rotatable around a tubular motor (28) built-in along the lower body of the drone, is expanded down, to show orders to guide drivers."
"UNMANNED AERIAL VEHICLE SYSTEM, AND COMMUNICATION METHOD AND REMOTE CONTROL DEVICE THEREFOR",https://lens.org/171-130-404-268-836,2020,"The present disclosure provides an unmanned aerial vehicle (UAV) system. The UAV system includes a first remote control device, a second remote control device, a UAV, and a functional device mounted on the UAV. The first remote control device is configured to send remote control information to control the UAV, and the second remote control device is configured to send remote control information to control the functional device. The first remote control device and the second remote control device are communicatively connected to form a communication link, and the first remote control device and the second remote control device exchange interactive data based on the communication link. The interactive data at least include text data or audio data."
Interactive behavior engagement and management in subordinate airborne robots,https://lens.org/103-784-831-530-698,2018,"An unmanned aerial vehicle (UAV) is disclosed. The UAV comprises a battery, a flight mechanism, a radio frequency (RF) transceiver, a processor, a memory, and an application stored in the memory. When executed by the processor, the application discovers an environment where the UAV operates by flying in the environment to determine its boundaries; creates a map of the environment that the UAV flew through; and shares the map with a social robot. The application receives a command from the social robot via the RF transceiver, wherein the social robot receives a verbal request from a user of the social robot, wherein the social robot transforms the user request to a command for the UAV. The application then performs the command from the social robot. The application then lands on a designated charging pad to conserve energy. The application then transmits a report back to the social robot."
Interactive behavior engagement and management in subordinate airborne robots,https://lens.org/076-484-620-780-687,2016,"An unmanned aerial vehicle (UAV) is disclosed. The UAV comprises a battery, a flight mechanism, a radio frequency (RF) transceiver, a processor, a memory, and an application stored in the memory. When executed by the processor, the application discovers an environment where the UAV operates by flying in the environment to determine its boundaries; creates a map of the environment that the UAV flew through; and shares the map with a social robot. The application receives a command from the social robot via the RF transceiver, wherein the social robot receives a verbal request from a user of the social robot, wherein the social robot transforms the user request to a command for the UAV. The application then performs the command from the social robot. The application then lands on a designated charging pad to conserve energy. The application then transmits a report back to the social robot."
Unmanned aerial vehicle 3D mapping system,https://lens.org/058-304-364-047-799,2017,"An automatic unmanned aerial vehicle (UAV) flight control system for 3D aerial mapping includes a UAV with an onboard camera, and a controller capable of communication with a flight control module of the UAV. The controller is configured to determine an area mapping flight path based on terrain characteristics of an area to be mapped. The controller also can determine a structure mapping flight path based on the existence and location of vertical structures within the area to be mapped. The area mapping flight path can be appended with the structure mapping flight path, thus providing an integrated and optimized UAV flight path for 3D mapping and modeling."
UNMANNED AERIAL VEHICLE 3D MAPPING SYSTEM,https://lens.org/197-521-553-110-575,2016,"An automatic unmanned aerial vehicle (UAV) flight control system for 3D aerial mapping includes a UAV with an onboard camera, and a controller capable of communication with a flight control module of the UAV. The controller is configured to determine an area mapping flight path based on terrain characteristics of an area to be mapped. The controller also can determine a structure mapping flight path based on the existence and location of vertical structures within the area to be mapped. The area mapping flight path can be appended with the structure mapping flight path, thus providing an integrated and optimized UAV flight path for 3D mapping and modeling."
AUTONOMOUS VEHICLE AND DRONE-BASED EMERGENCY RESPONSE METHOD THEREOF,https://lens.org/101-098-758-361-476,2022,An autonomous vehicle and a drone-based emergency response method thereof are provided. The autonomous vehicle includes a communication device that supports communication with a drone and a detection device that detects vehicle status information and driving environment information. A processing device detects an emergency situation occurring on a road based on the vehicle status information and the driving environment information while autonomous driving and performs a response logic matching the recognized emergency situation using the drone.
Landing Platform for a Drone,https://lens.org/118-140-494-900-379,2022,"A landing platform (100) for a drone (102) is disclosed. The platform (100) comprises a body (104) having a landing surface (106) on a top and a wheel assembly (108 and 110). The wheel assembly (108 and 110) is coupled to electrical motors via gears or hydraulics to enable the platform (100) to autonomously propel itself via a control system, wherein the electrical motors are securely disposed in the body (104) and configured to electrically connect to batteries. The control system is configured to control the operation of the platform (100) by collecting information and data from sensors, a GPS sensor, and cameras. The platform (100) is configured to autonomously self-propel to different locations and provide electrical power for charging drones power sources from the batteries via the control system, while driving to the desired location and enabling continuous flight operations after charging with an extended operational range asper desired."
Remote controlled aircraft,https://lens.org/169-592-098-229-947,2018,"A remote controlled aircraft includes an aircraft that may be flown. A plurality of light emitters is coupled to the aircraft. A plurality of fans is coupled to the aircraft. Each of the fans may move air thereby facilitating each of the fans to urge the aircraft to fly. A control unit is coupled to the aircraft and the control unit is electrically coupled to each of the fans. The control unit includes a global positioning system. Thus, the control unit may identify a position of the aircraft with respect to Earth. A remote control is provided and the remote control may be manipulated. The remote control is in electrical communication with the control unit such that the remote control controls directional flight of the aircraft."
Remote Controlled Aircraft,https://lens.org/075-689-375-018-906,2017,"A remote controlled aircraft includes an aircraft that may be flown. A plurality of light emitters is coupled to the aircraft. A plurality of fans is coupled to the aircraft. Each of the fans may move air thereby facilitating each of the fans to urge the aircraft to fly. A control unit is coupled to the aircraft and the control unit is electrically coupled to each of the fans. The control unit includes a global positioning system. Thus, the control unit may identify a position of the aircraft with respect to Earth. A remote control is provided and the remote control may be manipulated. The remote control is in electrical communication with the control unit such that the remote control controls directional flight of the aircraft."
IMPROVED VISUAL MONITORING ON SMARTPHONE SCREEN,https://lens.org/013-015-390-000-923,2016,"An unmanned aerial vehicle UAV comprising a base, four extendible arms, a motor attached to each extendible arm, with a rotor coupled to each motor, the UAV further comprising a processor for controlling the motors, and a radio receiver for receiving control signals, wherein the UAV folds flat and is configured to clip onto a back of a mobile phone."
IMPROVED VISUAL MONITORING ON SMARTPHONE SCREEN,https://lens.org/098-598-042-485-187,2017,"An unmanned aerial vehicle UAV comprising a base, four extendible arms, a motor attached to each extendible arm, with a rotor coupled to each motor, the UAV further comprising a processor for controlling the motors, and a radio receiver for receiving control signals, wherein the UAV folds flat and is configured to clip onto a back of a mobile phone."
Object image recognition and instant active response with enhanced application and utility,https://lens.org/037-356-773-238-409,2017,"A device for pollinating plants such as flowering trees. The device is a movable platform such as a drone that has an image capturing device that is in communication with image recognition software. Images of plants are analyzed to detect objects that are consistent with pollen-receiving plants and/or plant areas. Once such plant object is detected, the device automatically disperses pollen in the proximity of the detected plant or plant object."
OBJECT IMAGE RECOGNITION AND INSTANT ACTIVE RESPONSE WITH ENHANCED APPLICATION AND UTILITY,https://lens.org/136-383-804-619-101,2017,"A device for pollinating plants such as flowering trees. The device is a movable platform such as a drone that has an image capturing device that is in communication with image recognition software. Images of plants are analyzed to detect objects that are consistent with pollen-receiving plants and/or plant areas. Once such plant object is detected, the device automatically disperses pollen in the proximity of the detected plant or plant object."
OBJECT IMAGE RECOGNITION AND INSTANT ACTIVE RESPONSE WITH ENHANCED APPLICATION AND UTILITY,https://lens.org/053-914-619-671-638,2016,"A device for pollinating plants such as flowering trees. The device is a movable platform such as a drone that has an image capturing device that is in communication with image recognition software. Images of plants are analyzed to detect objects that are consistent with pollen-receiving plants and/or plant areas. Once such plant object is detected, the device automatically disperses pollen in the proximity of the detected plant or plant object."
SYSTEMS AND METHODS FOR TRACKING AND CONTROLLING A MOBILE CAMERA TO IMAGE OBJECTS OF INTEREST,https://lens.org/163-464-287-201-279,2020,"A mobile camera system includes a camera affixed to a drone, a video transmitter that wirelessly transmits a video feed outputted by the camera, and At least one tracking tag that wirelessly transmits a location signal receivable by a tracking system to determine a drone position and a drone orientation of the drone. A local controller, also affixed to the drone, is configured to (a) wireless receive, from a camera controller, movement instructions derived from the drone position and the drone orientation, and (b) control the drone position and the drone orientation, based on the movement instructions, such that the camera maintains a perspective view of an object. The tracking system receives location signals to determine the drone position and object position. The camera controller determines movement instructions, based on the drone and object positions, and wirelessly communicates the movement instructions to the mobile camera system."
Autonomous mobile device and control method therefor,https://lens.org/103-179-238-979-421,2023,"An autonomous mobile device and a control method therefor, which relate to the technical field of smart homes, and are used for solving the technical problem that an autonomous mobile device is difficult to determine its own working state when the autonomous mobile device is located below an obstacle (60). The autonomous mobile device comprises a body (10), and a photographing unit (20), a detection apparatus (30), a light source assembly (40) and a controller (70) which are arranged on the body (10), wherein the photographing unit (20) is used for collecting image information of a preset direction of the body (10), the preset direction comprises the portion above the body (10), the detection apparatus (30) is used for detecting information of the obstacle (60) above the body (10), the light emitting direction of the light source assembly (40) comprise the portion above the body (10), and the controller (70) is electrically connected to the detection apparatus (30) and the light source assembly (40), and is used for controlling the startup of light source assembly (40) when the detection apparatus (30) detects the obstacle (60) within a preset distance range above the body (10), and providing illumination for the photographing unit (20). The control method is applied to the autonomous mobile device, so that the autonomous mobile device can determine its own working state when below the obstacle (60)."
Autonomous mobile device and control method therefor,https://lens.org/103-179-238-979-421,2023,"An autonomous mobile device and a control method therefor, which relate to the technical field of smart homes, and are used for solving the technical problem that an autonomous mobile device is difficult to determine its own working state when the autonomous mobile device is located below an obstacle (60). The autonomous mobile device comprises a body (10), and a photographing unit (20), a detection apparatus (30), a light source assembly (40) and a controller (70) which are arranged on the body (10), wherein the photographing unit (20) is used for collecting image information of a preset direction of the body (10), the preset direction comprises the portion above the body (10), the detection apparatus (30) is used for detecting information of the obstacle (60) above the body (10), the light emitting direction of the light source assembly (40) comprise the portion above the body (10), and the controller (70) is electrically connected to the detection apparatus (30) and the light source assembly (40), and is used for controlling the startup of light source assembly (40) when the detection apparatus (30) detects the obstacle (60) within a preset distance range above the body (10), and providing illumination for the photographing unit (20). The control method is applied to the autonomous mobile device, so that the autonomous mobile device can determine its own working state when below the obstacle (60)."
SYSTEM OF MULTI-DRONE VISUAL CONTENT CAPTURING,https://lens.org/065-601-578-366-060,2021,"A system of imaging a scene includes a plurality of drones, each drone moving along a corresponding flight path over the scene and having a drone camera capturing, at a corresponding first pose and first time, a corresponding first image of the scene; a fly controller that controls the flight path of each drone, in part by using estimates of the first pose of each drone camera provided by a camera controller, to create and maintain a desired pattern of drones with desired camera poses; and the camera controller, which receives, from the drones, a corresponding plurality of captured images, processing the received images to generate a 3D representation of the scene as a system output, and to provide the estimates of the first pose of each drone camera to the fly controller. The system is fully operational with as few as one human operator."
SYSTEM OF MULTI-DRONE VISUAL CONTENT CAPTURING,https://lens.org/177-550-435-920-355,2022,"A system of imaging a scene includes a plurality of drones, each drone moving along a corresponding flight path over the scene and having a drone camera capturing, at a corresponding first pose and first time, a corresponding first image of the scene; a fly controller that controls the flight path of each drone, in part by using estimates of the first pose of each drone camera provided by a camera controller, to create and maintain a desired pattern of drones with desired camera poses; and the camera controller, which receives, from the drones, a corresponding plurality of captured images, processing the received images to generate a 3D representation of the scene as a system output, and to provide the estimates of the first pose of each drone camera to the fly controller. The system is fully operational with as few as one human operator."
MODULAR CAMERA DRONE,https://lens.org/098-760-219-832-803,2018,"A camera drone has an array of eight camera-light units arranged so as to enable capture of photographs and video providing a spherical 360360 field of view. Such an expansive field of view enables image capture for use in virtual reality, augmented reality, and similar uses. The camera drone is preferably spherical in shape so as to minimize any obstructions in the expansive field of view. The camera drone is modular with separate but coordinated modules for a main body module, a base module along an equator of the main body, a thruster module, and a camera-light module. The camera drone is also capable of operation in air or water (submersible) having both a tethered and autonomous version."
Modular camera drone,https://lens.org/127-849-632-670-466,2018,"A camera drone has an array of eight camera-light units arranged so as to enable capture of photographs and video providing a spherical 360360 field of view. Such an expansive field of view enables image capture for use in virtual reality, augmented reality, and similar uses. The camera drone is preferably spherical in shape so as to minimize any obstructions in the expansive field of view. The camera drone is modular with separate but coordinated modules for a main body module, a base module along an equator of the main body, a thruster module, and a camera-light module. The camera drone is also capable of operation in air or water (submersible) having both a tethered and autonomous version."
UNMANNED AERIAL VEHICLE AND METHOD FOR CONTROLLING THE SAME,https://lens.org/173-002-023-539-619,2018,"An electronic device is provided. The electronic device includes a user interface configured to receive a first direction input, a second direction input, a third direction input, and a fourth direction input, the first direction input used to move the electronic device horizontally in a left direction, the second direction input used to move the electronic device horizontally in a right direction, the third direction input used to move the electronic device vertically in an upper direction, and the fourth direction input used to move the electronic device vertically in a lower direction, a wireless communication circuit configured to establish a wireless communication channel with an unmanned aerial vehicle (UAV) including a camera, and a processor configured to control the UAV based on the directional inputs."
Electronic device and method for controlling the same,https://lens.org/009-213-654-254-760,2020,"An electronic device is provided. The electronic device includes a user interface configured to receive a first direction input, a second direction input, a third direction input, and a fourth direction input, the first direction input used to move the electronic device horizontally in a left direction, the second direction input used to move the electronic device horizontally in a right direction, the third direction input used to move the electronic device vertically in an upper direction, and the fourth direction input used to move the electronic device vertically in a lower direction, a wireless communication circuit configured to establish a wireless communication channel with an unmanned aerial vehicle (UAV) including a camera, and a processor configured to control the UAV based on the directional inputs."
CONNECTION ESTABLISHMENT BETWEEN A ROBOT DEVICE AND A ROBOT CONTROLLER,https://lens.org/011-536-467-471-063,2018,"A robot device for establishing a connection with a robot controller in cloud is provided. The robot device being configured, so that upon a trigger, to send a connection request to the robot controller, and to receive from the robot controller a response so as to establish the connection."
User interaction paradigms for a flying digital assistant,https://lens.org/160-170-906-875-57X,2019,"Methods and systems are described for new paradigms for user interaction with an unmanned aerial vehicle (referred to as a flying digital assistant or FDA) using a portable multifunction device (PMD) such as smart phone. In some embodiments, a user may control image capture from an FDA by adjusting the position and orientation of a PMD. In other embodiments, a user may input a touch gesture via a touch display of a PMD that corresponds with a flight path to be autonomously flown by the FDA."
User interaction paradigms for a flying digital assistant,https://lens.org/007-104-247-364-051,2020,"Methods and systems are described for new paradigms for user interaction with an unmanned aerial vehicle (referred to as a flying digital assistant or FDA) using a portable multifunction device (PMD) such as smart phone. In some embodiments, a user may control image capture from an FDA by adjusting the position and orientation of a PMD. In other embodiments, a user may input a touch gesture via a touch display of a PMD that corresponds with a flight path to be autonomously flown by the FDA."
USER INTERACTION PARADIGMS FOR A FLYING DIGITAL ASSISTANT,https://lens.org/002-185-626-069-541,2020,"Methods and systems are described for new paradigms for user interaction with an unmanned aerial vehicle (referred to as a flying digital assistant or FDA) using a portable multifunction device (PMD) such as smart phone. In some embodiments, a user may control image capture from an FDA by adjusting the position and orientation of a PMD. In other embodiments, a user may input a touch gesture via a touch display of a PMD that corresponds with a flight path to be autonomously flown by the FDA."
User Interaction Paradigms For A Flying Digital Assistant,https://lens.org/031-225-853-544-66X,2022,"Methods and systems are described for new paradigms for user interaction with an unmanned aerial vehicle (referred to as a flying digital assistant or FDA) using a portable multifunction device (PMD) such as smart phone. In some embodiments, a user may control image capture from an FDA by adjusting the position and orientation of a PMD. In other embodiments, a user may input a touch gesture via a touch display of a PMD that corresponds with a flight path to be autonomously flown by the FDA."
User interaction paradigms for a flying digital assistant,https://lens.org/182-578-483-365-910,2023,"Methods and systems are described for new paradigms for user interaction with an unmanned aerial vehicle (referred to as a flying digital assistant or FDA) using a portable multifunction device (PMD) such as smart phone. In some embodiments, a user may control image capture from an FDA by adjusting the position and orientation of a PMD. In other embodiments, a user may input a touch gesture via a touch display of a PMD that corresponds with a flight path to be autonomously flown by the FDA."
User interaction paradigms for a flying digital assistant,https://lens.org/060-105-103-445-238,2022,"Methods and systems are described for new paradigms for user interaction with an unmanned aerial vehicle (referred to as a flying digital assistant or FDA) using a portable multifunction device (PMD) such as smart phone. In some embodiments, a user may control image capture from an FDA by adjusting the position and orientation of a PMD. In other embodiments, a user may input a touch gesture via a touch display of a PMD that corresponds with a flight path to be autonomously flown by the FDA."
User Interaction Paradigms For A Flying Digital Assistant,https://lens.org/031-225-853-544-66X,2022,"Methods and systems are described for new paradigms for user interaction with an unmanned aerial vehicle (referred to as a flying digital assistant or FDA) using a portable multifunction device (PMD) such as smart phone. In some embodiments, a user may control image capture from an FDA by adjusting the position and orientation of a PMD. In other embodiments, a user may input a touch gesture via a touch display of a PMD that corresponds with a flight path to be autonomously flown by the FDA."
Virtual camera interface and other user interaction paradigms for a flying digital assistant,https://lens.org/151-068-067-088-016,2017,"Methods and systems are described for new paradigms for user interaction with an unmanned aerial vehicle (referred to as a flying digital assistant or FDA) using a portable multifunction device (PMD) such as smart phone. In some embodiments, a user may control image capture from an FDA by adjusting the position and orientation of a PMD. In other embodiments, a user may input a touch gesture via a touch display of a PMD that corresponds with a flight path to be autonomously flown by the FDA."
User Interaction Paradigms For A Flying Digital Assistant,https://lens.org/168-870-123-952-75X,2023,"Methods and systems are described for new paradigms for user interaction with an unmanned aerial vehicle (referred to as a flying digital assistant or FDA) using a portable multifunction device (PMD) such as smart phone. In some embodiments, a user may control image capture from an FDA by adjusting the position and orientation of a PMD. In other embodiments, a user may input a touch gesture via a touch display of a PMD that corresponds with a flight path to be autonomously flown by the FDA."
USER INTERACTION PARADIGMS FOR A FLYING DIGITAL ASSISTANT,https://lens.org/152-056-548-610-774,2021,"Methods and systems are described for new paradigms for user interaction with an unmanned aerial vehicle (referred to as a flying digital assistant or FDA) using a portable multifunction device (PMD) such as smart phone. In some embodiments, a user may control image capture from an FDA by adjusting the position and orientation of a PMD. In other embodiments, a user may input a touch gesture via a touch display of a PMD that corresponds with a flight path to be autonomously flown by the FDA."
VIRTUAL CAMERA INTERFACE AND OTHER USER INTERACTION PARADIGMS FOR A FLYING DIGITAL ASSISTANT,https://lens.org/077-533-615-769-12X,2016,"Methods and systems are described for new paradigms for user interaction with an unmanned aerial vehicle (referred to as a flying digital assistant or FDA) using a portable multifunction device (PMD) such as smart phone. In some embodiments, a user may control image capture from an FDA by adjusting the position and orientation of a PMD. In other embodiments, a user may input a touch gesture via a touch display of a PMD that corresponds with a flight path to be autonomously flown by the FDA."
User interaction paradigms for a flying digital assistant,https://lens.org/182-578-483-365-910,2023,"Methods and systems are described for new paradigms for user interaction with an unmanned aerial vehicle (referred to as a flying digital assistant or FDA) using a portable multifunction device (PMD) such as smart phone. In some embodiments, a user may control image capture from an FDA by adjusting the position and orientation of a PMD. In other embodiments, a user may input a touch gesture via a touch display of a PMD that corresponds with a flight path to be autonomously flown by the FDA."
USER INTERACTION PARADIGMS FOR A FLYING DIGITAL ASSISTANT,https://lens.org/091-523-223-563-374,2018,"Methods and systems are described for new paradigms for user interaction with an unmanned aerial vehicle (referred to as a flying digital assistant or FDA) using a portable multifunction device (PMD) such as smart phone. In some embodiments, a user may control image capture from an FDA by adjusting the position and orientation of a PMD. In other embodiments, a user may input a touch gesture via a touch display of a PMD that corresponds with a flight path to be autonomously flown by the FDA."
"Systems, Devices, and/or Methods for Managing Drone Tethering",https://lens.org/008-749-266-730-760,2021,"Certain exemplary embodiments can provide a method, which comprises causing an article to be picked up and delivered via a working drone substantially without human intervention. The working drone is coupled to a support drone via a tether. The working drone is controlled via a wireless communication system that transmits signals from the support drone to the working drone. The wireless communication system constructed to communicate with a box that receives deliveries via the drone."
LAUNCHING UNMANNED AERIAL COPTER FROM MID-AIR,https://lens.org/023-962-106-025-591,2016,"An unmanned aerial vehicle (UAV) copter for consumer photography or videography can be launched by a user throwing the UAV copter into mid-air. The UAV copter can detect that the UAV copter has been thrown upward while propeller drivers of the UAV copter are inert. In response to detecting that the UAV copter has been thrown upward, the UAV copter can compute power adjustments for propeller drivers of the UAV copter to have the UAV copter reach a predetermined elevation above an operator device. The UAV copter can then supply power to the propeller drivers in accordance with the computed power adjustments."
LAUNCHING UNMANNED AERIAL COPTER FROM MID-AIR,https://lens.org/096-086-901-614-871,2017,"An unmanned aerial vehicle (UAV) copter for consumer photography or videography can be launched by a user throwing the UAV copter into mid-air. The UAV copter can detect that the UAV copter has been thrown upward while propeller drivers of the UAV copter are inert. In response to detecting that the UAV copter has been thrown upward, the UAV copter can compute power adjustments for propeller drivers of the UAV copter to have the UAV copter reach a predetermined elevation above an operator device. The UAV copter can then supply power to the propeller drivers in accordance with the computed power adjustments."
Launching unmanned aerial copter from mid-air,https://lens.org/178-900-780-071-992,2017,"An unmanned aerial vehicle (UAV) copter for consumer photography or videography can be launched by a user throwing the UAV copter into mid-air. The UAV copter can detect that the UAV copter has been thrown upward while propeller drivers of the UAV copter are inert. In response to detecting that the UAV copter has been thrown upward, the UAV copter can compute power adjustments for propeller drivers of the UAV copter to have the UAV copter reach a predetermined elevation above an operator device. The UAV copter can then supply power to the propeller drivers in accordance with the computed power adjustments."
Release unit for drones,https://lens.org/058-874-693-725-575,2021,"A unit that is mountable to an underside of drone to attach an attachment to the drone and then release the attachment after the drone is airborne. The unit is provide with a retractable bar that is controllable via a remote controller. In use, an attachment is suspended from the bar and once the drone becomes airborne, a user may retract the bar via remote control to drop the attachment previously suspended from the bar."
RELEASE UNIT FOR DRONES,https://lens.org/129-516-148-918-412,2019,"A unit that is mountable to an underside of drone to attach an attachment to the drone and then release the attachment after the drone is airborne. The unit is provide with a retractable bar that is controllable via a remote controller. In use, an attachment is suspended from the bar and once the drone becomes airborne, a user may retract the bar via remote control to drop the attachment previously suspended from the bar."
RELEASE UNIT FOR DRONES,https://lens.org/180-200-118-332-056,2021,"A unit that is mountable to an underside of drone to attach an attachment to the drone and then release the attachment after the drone is airborne. The unit is provide with a retractable bar that is controllable via a remote controller. In use, an attachment is suspended from the bar and once the drone becomes airborne, a user may retract the bar via remote control to drop the attachment previously suspended from the bar."
Access Authorization via Location-Aware Authorization Device,https://lens.org/082-942-951-417-658,2013,"An apparatus and method are provided to allow a user to authorize control of a remote device using a location-aware control device. The location-aware control device compares its location to a target position. When within a user-defined proximity of the target position, the control device offers a user the ability to communicate with a remote device. The remote device may be a movable barrier operator or a web server in communication with a movable barrier operator."
Controller for voice-controlled device and associated method,https://lens.org/117-406-545-077-28X,2016,A controller for a voice-controlled device is provided. The controller includes a setting module and a recognition module. The setting module generates a threshold according to an environmental parameter. The recognition module compares a confident score of speech recognition with the threshold to accordingly execute voice control.
CONTROLLER FOR VOICE-CONTROLLED DEVICE AND ASSOCIATED METHOD,https://lens.org/051-054-807-424-255,2015,A controller for a voice-controlled device is provided. The controller includes a setting module and a recognition module. The setting module generates a threshold according to an environmental parameter. The recognition module compares a confident score of speech recognition with the threshold to accordingly execute voice control.
Mobile robot for telecommunication,https://lens.org/045-379-429-507-78X,2013,"A remote control unit configured to wirelessly control a mobile robot moving through an environment and having a robot camera. The remote control unit comprises a privacy button operable by a local user and configured to engage a privacy mode of the mobile robot, and a wireless transmitter configured to emit a wireless control signal to the mobile robot based on input from a keypad of the RC unit. The wireless control signal is configured to cause the robot camera to block the field of view of the robot camera such that the environment of the mobile robot is obscured when the privacy mode of the mobile robot is engaged."
Mobile Robot for Telecommunication,https://lens.org/173-486-115-011-030,2013,"A remote control unit configured to wirelessly control a mobile robot moving through an environment and having a robot camera. The remote control unit comprises a privacy button operable by a local user and configured to engage a privacy mode of the mobile robot, and a wireless transmitter configured to emit a wireless control signal to the mobile robot based on input from a keypad of the RC unit. The wireless control signal is configured to cause the robot camera to block the field of view of the robot camera such that the environment of the mobile robot is obscured when the privacy mode of the mobile robot is engaged."
Apparatus for controlling behavior of autonomous vehicle and method thereof,https://lens.org/164-985-087-994-438,2022,"An apparatus for controlling a behavior of an autonomous vehicle includes: a joystick that inputs an adjustment value corresponding to an amount of manipulation by a user, and a controller to control the behavior of the autonomous vehicle based on the adjustment value corresponding to the amount of manipulation being input from the joystick."
APPARATUS FOR CONTROLLING BEHAVIOR OF AUTONOMOUS VEHICLE AND METHOD THEREOF,https://lens.org/108-141-477-037-018,2021,"An apparatus for controlling a behavior of an autonomous vehicle includes: a joystick that inputs an adjustment value corresponding to an amount of manipulation by a user, and a controller to control the behavior of the autonomous vehicle based on the adjustment value corresponding to the amount of manipulation being input from the joystick."
Arial Based Parolee Tracking and Pursuit,https://lens.org/197-736-139-834-584,2020,"A method for controlling an unmanned aerial vehicle (UAV) to track a monitored person is provided. The method includes directing the UAV toward a target location the target location being based on past or present location information provided by a personal monitoring device attached to a monitored person, the location information representing the location of the personal monitoring device; assuming with the UAV a surveillance position relative to the target location; and determining that the monitored device is proximate to the target location by receiving signals from the personal monitoring device and/or observing the monitored person through a camera on the UAV."
Arial based parolee tracking and pursuit,https://lens.org/065-632-384-104-080,2022,"A method for controlling an unmanned aerial vehicle (UAV) to track a monitored person is provided. The method includes directing the UAV toward a target location the target location being based on past or present location information provided by a personal monitoring device attached to a monitored person, the location information representing the location of the personal monitoring device; assuming with the UAV a surveillance position relative to the target location; and determining that the monitored device is proximate to the target location by receiving signals from the personal monitoring device and/or observing the monitored person through a camera on the UAV."
Camera Drone,https://lens.org/067-198-635-374-565,2019,Devices and methods improving the ability to capture images remotely and manually with a camera integrated with or attached to a drone. A display screen on the drone body allows viewing of captured image data. Booms are configured to both support the flight components of the drone and allow manipulation. Boom handles allow a user to hold and manually aim the camera.
Camera drone,https://lens.org/068-357-390-178-014,2020,Devices and methods improving the ability to capture images remotely and manually with a camera integrated with or attached to a drone. A display screen on the drone body allows viewing of captured image data. Booms are configured to both support the flight components of the drone and allow manipulation. Boom handles allow a user to hold and manually aim the camera.
INTEGRATED CONTROL/COMMAND MODULE FOR A FLYING DRONE,https://lens.org/134-502-469-758-054,2018,"A module for a drone that integrates an electronic circuit and one or more sensors for the attitude, altitude, speed, orientation and/or position of the drone in the same one-piece housing. The module also integrates an electronic power circuit that receives set command values prepared by the processor of the electronic circuit on the basis of the data provided by the integrated sensors and provides, as an output, corresponding signals for directly supplying current or voltage to the propulsion means of the drone and to the control surfaces."
Jump start drone,https://lens.org/033-154-530-445-605,2022,A system includes an aerial drone. The aerial drone includes first and second electrically conductive end effectors. The first and second electrically conductive end effectors are electrically connected to a power source.
Unmanned device interaction methods and systems,https://lens.org/085-228-117-285-586,2017,"Structures and protocols are presented for configuring an unmanned aerial device to participate in the performance of tasks, for using data resulting from such a configuration or performance, or for facilitating other interactions with such devices."
Unmanned device interaction methods and systems,https://lens.org/137-831-321-935-989,2015,"Structures and protocols are presented for configuring an unmanned aerial device to participate in the performance of tasks, for using data resulting from such a configuration or performance, or for facilitating other interactions with such devices."
Unmanned device interaction methods and systems,https://lens.org/066-072-825-335-823,2017,"Structures and protocols are presented for configuring an unmanned aerial device to participate in the performance of tasks, for using data resulting from such a configuration or performance, or for facilitating other interactions with such devices."
Unmanned device interaction methods and systems,https://lens.org/174-976-480-000-696,2017,"Structures and protocols are presented for configuring an unmanned aerial device to participate in the performance of tasks, for using data resulting from such a configuration or performance, or for facilitating other interactions with such devices."
Unmanned device interaction methods and systems,https://lens.org/087-082-617-748-595,2016,"Structures and protocols are presented for configuring an unmanned aerial device to participate in the performance of tasks, for using data resulting from such a configuration or performance, or for facilitating other interactions with such devices."
UNMANNED DEVICE INTERACTION METHODS AND SYSTEMS,https://lens.org/190-429-284-996-681,2014,"Structures and protocols are presented for configuring an unmanned aerial device to participate in the performance of tasks, for using data resulting from such a configuration or performance, or for facilitating other interactions with such devices."
PERSONAL COMMUNICATION DRONE,https://lens.org/019-879-232-501-200,2016,"A system of using a drone for network connectivity, the system may comprise: a connectivity module to: detect an error associated with network traffic on a network connection utilized by a user device; query a connection datastore to retrieve at least one access point location that at least one device of the user has utilized within a predetermined period; a drone coordination module to: transmit configuration settings to a drone, the configuration settings including the at least one access point location and a mode of operation for the drone; and route at least a portion of the network traffic of the user device to the drone for transmission according to the configuration settings."
Personal communication drone,https://lens.org/036-771-187-984-38X,2016,"A system of using a drone for network connectivity, the system may comprise: a connectivity module to: detect an error associated with network traffic on a network connection utilized by a user device; query a connection datastore to retrieve at least one access point location that at least one device of the user has utilized within a predetermined period; a drone coordination module to: transmit configuration settings to a drone, the configuration settings including the at least one access point location and a mode of operation for the drone; and route at least a portion of the network traffic of the user device to the drone for transmission according to the configuration settings."
"UNMANNED AERIAL VEHICLE WITH IMMUNUTY TO HIJACKING, JAMMING, AND SPOOFING ATTACKS",https://lens.org/067-261-928-779-370,2022,"An unmanned aerial vehicle (UAV) or ""drone"" executes a neural network to assist with detecting and responding to attacks. The neural network may monitor, in real time, the data stream from a plurality of onboard sensors during navigation and may communicate with a high-altitude pseudosatellite (""HAPS"") platform. For example, if the neural network detects a cyber-attack but determines that it does not interfere with external communications, it may shift navigation control of the drone to the HAPS."
"UNMANNED AERIAL VEHICLE WITH IMMUNUTY TO HIJACKING, JAMMING, AND SPOOFING ATTACKS",https://lens.org/195-539-727-032-419,2022,"An unmanned aerial vehicle (UAV) or ""drone"" executes a neural network to assist with detecting and responding to attacks. The neural network may monitor, in real time, the data stream from a plurality of onboard sensors during navigation and may communicate with a high-altitude pseudosatellite (""HAPS"") platform. For example, if the neural network detects a cyber-attack but determines that it does not interfere with external communications, it may shift navigation control of the drone to the HAPS."
"UNMANNED AERIAL VEHICLE WITH IMMUNUTY TO HIJACKING, JAMMING, AND SPOOFING ATTACKS",https://lens.org/067-261-928-779-370,2022,"An unmanned aerial vehicle (UAV) or ""drone"" executes a neural network to assist with detecting and responding to attacks. The neural network may monitor, in real time, the data stream from a plurality of onboard sensors during navigation and may communicate with a high-altitude pseudosatellite (""HAPS"") platform. For example, if the neural network detects a cyber-attack but determines that it does not interfere with external communications, it may shift navigation control of the drone to the HAPS."
A SYSTEM AND METHOD FOR UNMANNED AERIAL VEHICLE FOR ASSISTING IN AN EMERGENCY/DISASTER,https://lens.org/130-365-702-333-148,2022,"The present invention generally relates to a system and method for unmanned aerial vehicle for assisting in an emergency/disaster, the system comprises a smart device worn/carried by a user configured with SOS buttons for generating a help signal in case of emergency/disaster upon pressing the buttons; a microphone equipped with a microphone button associated with the smart device for inputting audible help for customized or special requirement; and a central processing unit connected with a control room for activating one of the drones from the plurality of drones according to type of help signal received from the smart device. 6 a o .0 u. RII 8 Og (I____O"
Method and apparatus for controlling flight of unmanned aerial vehicle,https://lens.org/086-203-326-519-663,2022,"A method and apparatus for controlling the flight of an Unmanned Aerial Vehicle (UAV) are provided. The method includes: determining a starting flight position where a UAV is parked currently and a nose direction of the UAV (101); starting off from the starting flight position, and flying along a straight line in the nose direction (102); and when receiving a route adjustment instruction during the flight of the UAV, adjusting an air route of the UAV according to the route adjustment instruction (103). During the flight, an operator can correct an air route via a remote control apparatus without surveying and mapping when detecting that the UAV is flying off course; and the operator can make the UAV precisely fly along a desired straight line by means of simple operations."
Method and apparatus for controlling flight of unmanned aerial vehicle,https://lens.org/086-203-326-519-663,2022,"A method and apparatus for controlling the flight of an Unmanned Aerial Vehicle (UAV) are provided. The method includes: determining a starting flight position where a UAV is parked currently and a nose direction of the UAV (101); starting off from the starting flight position, and flying along a straight line in the nose direction (102); and when receiving a route adjustment instruction during the flight of the UAV, adjusting an air route of the UAV according to the route adjustment instruction (103). During the flight, an operator can correct an air route via a remote control apparatus without surveying and mapping when detecting that the UAV is flying off course; and the operator can make the UAV precisely fly along a desired straight line by means of simple operations."
Method and Apparatus for Controlling Flight of Unmanned Aerial Vehicle,https://lens.org/112-876-784-729-198,2020,"A method and apparatus for controlling the flight of an Unmanned Aerial Vehicle (UAV) are provided. The method includes: determining a starting flight position where a UAV is parked currently and a nose direction of the UAV (101); starting off from the starting flight position, and flying along a straight line in the nose direction (102); and when receiving a route adjustment instruction during the flight of the UAV, adjusting an air route of the UAV according to the route adjustment instruction (103). During the flight, an operator can correct an air route via a remote control apparatus without surveying and mapping when detecting that the UAV is flying off course; and the operator can make the UAV precisely fly along a desired straight line by means of simple operations."
"AUTONOMOUS IN-TUNNEL INTELLIGENCE, SURVEILLANCE, AND RECONNAISSANCE DRONE",https://lens.org/071-428-225-172-472,2018,"A small unmanned aircraft system is outfitted with a variety of sensors, and communications equipment to enable autonomous, remote exploration and mapping of spaces non line of sight (NLOS), and in the absence of global positioning signals."
Unmanned aerial vehicle control method and unmanned aerial vehicle using same,https://lens.org/070-823-045-629-029,2017,"A control method for an unmanned aerial vehicle (UAV) is provided. The method includes: obtaining, from a depth-sensing camera, images of a surface below the unmanned aerial vehicle; obtaining, from a gyroscope, current pitch angle of the unmanned aerial vehicle; determining, at the unmanned aerial vehicle, a current altitude of the unmanned aerial vehicle based on the images and the current pitch angle; determining, at the unmanned aerial vehicle, whether the current altitude of the unmanned aerial vehicle is less than a predefined value; and controlling, at the unmanned aerial vehicle, a drive unit to rotate so as to cause the unmanned aerial vehicle to slow down in a balanced condition if the current altitude of the unmanned aerial vehicle is less than a predefined value."
UNMANNED AERIAL VEHICLE CONTROL METHOD AND UNMANNED AERIAL VEHICLE USING SAME,https://lens.org/025-202-914-782-911,2017,"A control method for an unmanned aerial vehicle (UAV) is provided. The method includes: obtaining, from a depth-sensing camera, images of a surface below the unmanned aerial vehicle; obtaining, from a gyroscope, current pitch angle of the unmanned aerial vehicle; determining, at the unmanned aerial vehicle, a current altitude of the unmanned aerial vehicle based on the images and the current pitch angle; determining, at the unmanned aerial vehicle, whether the current altitude of the unmanned aerial vehicle is less than a predefined value; and controlling, at the unmanned aerial vehicle, a drive unit to rotate so as to cause the unmanned aerial vehicle to slow down in a balanced condition if the current altitude of the unmanned aerial vehicle is less than a predefined value."
Systems and methods for walking pets,https://lens.org/040-877-643-991-701,2018,Systems and methods are provided for guiding a target object with an unmanned aerial vehicle (UAV) in an environment. The UAV may be able to recognize and locate the target object. The UAV can be configured to communicate the actions and behavior of the target object to a user through a user device in communication with the UAV. The UAV can provide positive and negative stimuli to the target object to encourage an action or behavior. The UAV can be configured to recognize and manage waste generated by the target object.
SYSTEMS AND METHODS FOR WALKING PETS,https://lens.org/040-188-197-410-773,2018,Systems and methods are provided for guiding a target object with an unmanned aerial vehicle (UAV) in an environment. The UAV may be able to recognize and locate the target object. The UAV can be configured to communicate the actions and behavior of the target object to a user through a user device in communication with the UAV. The UAV can provide positive and negative stimuli to the target object to encourage an action or behavior. The UAV can be configured to recognize and manage waste generated by the target object.
Systems and methods for walking pets,https://lens.org/095-833-539-326-85X,2018,Systems and methods are provided for guiding a target object with an unmanned aerial vehicle (UAV) in an environment. The UAV may be able to recognize and locate the target object. The UAV can be configured to communicate the actions and behavior of the target object to a user through a user device in communication with the UAV. The UAV can provide positive and negative stimuli to the target object to encourage an action or behavior. The UAV can be configured to recognize and manage waste generated by the target object.
SYSTEMS AND METHODS FOR WALKING PETS,https://lens.org/170-761-557-821-692,2017,Systems and methods are provided for guiding a target object with an unmanned aerial vehicle (UAV) in an environment. The UAV may be able to recognize and locate the target object. The UAV can be configured to communicate the actions and behavior of the target object to a user through a user device in communication with the UAV. The UAV can provide positive and negative stimuli to the target object to encourage an action or behavior. The UAV can be configured to recognize and manage waste generated by the target object.
Systems and methods for walking pets,https://lens.org/191-410-376-061-644,2017,Systems and methods are provided for guiding a target object with an unmanned aerial vehicle (UAV) in an environment. The UAV may be able to recognize and locate the target object. The UAV can be configured to communicate the actions and behavior of the target object to a user through a user device in communication with the UAV. The UAV can provide positive and negative stimuli to the target object to encourage an action or behavior. The UAV can be configured to recognize and manage waste generated by the target object.
SYSTEMS AND METHODS FOR WALKING PETS,https://lens.org/008-033-469-027-748,2017,Systems and methods are provided for guiding a target object with an unmanned aerial vehicle (UAV) in an environment. The UAV may be able to recognize and locate the target object. The UAV can be configured to communicate the actions and behavior of the target object to a user through a user device in communication with the UAV. The UAV can provide positive and negative stimuli to the target object to encourage an action or behavior. The UAV can be configured to recognize and manage waste generated by the target object.
SYSTEMS AND METHODS FOR WALKING PETS,https://lens.org/072-311-353-385-656,2016,Systems and methods are provided for guiding a target object with an unmanned aerial vehicle (UAV) in an environment. The UAV may be able to recognize and locate the target object. The UAV can be configured to communicate the actions and behavior of the target object to a user through a user device in communication with the UAV. The UAV can provide positive and negative stimuli to the target object to encourage an action or behavior. The UAV can be configured to recognize and manage waste generated by the target object.
Method and apparatus for using drone in moving object,https://lens.org/062-672-385-657-40X,2022,"A method of operating a moving object on which a drone is mounted includes detecting, by the moving object, occurrence of an event; determining whether to use the drone, on the basis of the detected event; and determining an operation mode, among a first operation mode and a second operation mode, of the drone when the drone is used."
METHOD AND APPARATUS FOR USING DRONE ON MOVING OBJECT,https://lens.org/101-424-950-232-579,2020,"A method of operating a moving object on which a drone is mounted includes detecting, by the moving object, occurrence of an event; determining whether to use the drone, on the basis of the detected event; and determining an operation mode, among a first operation mode and a second operation mode, of the drone when the drone is used."
Method and apparatus for using drone in moving object,https://lens.org/062-672-385-657-40X,2022,"A method of operating a moving object on which a drone is mounted includes detecting, by the moving object, occurrence of an event; determining whether to use the drone, on the basis of the detected event; and determining an operation mode, among a first operation mode and a second operation mode, of the drone when the drone is used."
Controllable miniature mono-wing aircraft,https://lens.org/061-639-141-315-314,2013,"Micro/nano mono-wing aircraft with the wing configured as a winged seed (Samara) is uniquely suited for autonomous or remotely controlled operation in confined environments for surrounding images acquisition. The aircraft is capable of effective autorotation and steady hovering. The wing is flexibly connected to a fuselage via a servo-mechanism which is controlled to change the wing's orientation to control the flight trajectory and characteristics. A propeller on the fuselage rotates about the axis oriented to oppose a torque created about the longitudinal axis of the fuselage and is controlled to contribute in the aircraft maneuvers. A controller, either ON-board or OFF-board, creates input command signals to control the operation of the aircraft based on a linear control model identified as a result of extensive experimentations with a number of models."
CONTROLLABLE MINIATURE MONO-WING AIRCRAFT,https://lens.org/178-859-754-856-364,2011,"Micro/nano mono-wing aircraft with the wing configured as a winged seed (Samara) is uniquely suited for autonomous or remotely controlled operation in confined environments for surrounding images acquisition. The aircraft is capable of effective autorotation and steady hovering. The wing is flexibly connected to a fuselage via a servo-mechanism which is controlled to change the wing's orientation to control the flight trajectory and characteristics. A propeller on the fuselage rotates about the axis oriented to oppose a torque created about the longitudinal axis of the fuselage and is controlled to contribute in the aircraft maneuvers. A controller, either ON-board or OFF-board, creates input command signals to control the operation of the aircraft based on a linear control model identified as a result of extensive experimentations with a number of models."
Unmanned aerial vehicle (UAV) compliance using standard protocol requirements and components to enable identifying and controlling rogue UAVS,https://lens.org/095-752-264-525-301,2020,"A computer-implemented method for controlling an unmanned aerial vehicle (UAV) includes: receiving, by a computer device, UAV data from a UAV; displaying, by the computer device, a representation of the UAV on a map based on the UAV data; receiving, by the computer device, a user input to control the UAV; and transmitting, by the computer device, an authenticated control signal to the UAV based on the received user input, wherein the control signal is configured to override control of the UAV from a UAV remote controller associated with the UAV."
UNMANNED AERIAL VEHICLE (UAV) COMPLIANCE USING STANDARD PROTOCOL REQUIREMENTS AND COMPONENTS TO ENABLE IDENTIFYING AND CONTROLLING ROGUE UAVS,https://lens.org/167-355-989-810-397,2018,"A computer-implemented method for controlling an unmanned aerial vehicle (UAV) includes: receiving, by a computer device, UAV data from a UAV; displaying, by the computer device, a representation of the UAV on a map based on the UAV data; receiving, by the computer device, a user input to control the UAV; and transmitting, by the computer device, an authenticated control signal to the UAV based on the received user input, wherein the control signal is configured to override control of the UAV from a UAV remote controller associated with the UAV."
UNMANNED AERIAL VEHICLE CONTROL METHOD AND DEVICE AND OBSTACLE NOTIFICATION METHOD AND DEVICE,https://lens.org/139-442-057-649-097,2020,A method for controlling an unmanned aerial vehicle (UAV) includes obtaining depth data of one or more obstacles in a flight space. The method also includes determining information of an obstacle that triggers an obstacle avoidance operation based on the depth data. The method further includes transmitting the information of the obstacle to a control terminal of the UAV.
TOUCH SCREEN REMOTE CONTROL DEVICE FOR USE WITH A TOY,https://lens.org/058-994-652-560-547,2009,"A remote control device having a touch screen for remotely directing a toy, such as a remote control vehicle or airplane, is provided."
TOUCH SCREEN REMOTE CONTROL DEVICE FOR USE WITH A TOY,https://lens.org/065-306-222-413-426,2009,"A remote control device having a touch screen for remotely directing a toy, such as a remote control vehicle or airplane, is provided."
Touch screen remote control device for use with a toy,https://lens.org/007-024-097-308-66X,2013,"A remote control device having a touch screen for remotely directing a toy, such as a remote control vehicle or airplane, is provided."
Unmanned aerial vehicle for transporting a payload,https://lens.org/161-729-413-469-160,2020,"An unmanned aerial vehicle (UAV) 100 for autonomously transporting a payload 118. The UAV 100 comprises a flight control system 122 which is configured to autonomously operate a steering and propulsion system 112 such that the UAV 100 is able to autonomously fly to a predetermined destination. The UAV 100 has a first navigation system 128 and a second navigation system 130, which are arranged to determine a position of the UAV 100 in dependence on different sources of data. The flight control system 122 is configured to determine whether the first navigation system 128 and the second navigation system 130 are providing a correct indication of the position of the UAV 100. The flight control system 122 disregards the position provided by the first navigation system 128 and/or the second navigation system 130 if it is determined that the first navigation system 128 and/or the second navigation system 130 are/is not providing a correct indication of position."
AUTOMATIC FLIGHT CONTROL HELICOPTER,https://lens.org/034-697-826-215-208,2010,"The invention relates to an autonomous helicopter for recreational purposes or for a swarm-type surveillance system, characterised in that the helicopter has a complete automatic flight control, and in that the flight thereof is stable and automatic due to a device for the automatic control of the altitude, comprising at least two optical receivers, at least one optical emitter, at least two channels for processing signals of the receivers, and at least two motors controlling at least two propellers, at a speed proportional to the total amount of signals received. Said helicopter avoids obstacles by means of an orientation device controlled by the difference between the signals of the two receivers. It advances at a regular speed by means of a shift of the centre of gravity thereof in front of the axis of the two lifting propellers."
SYSTEM AND METHOD FOR CONTROLLING TAKEOFF AND LANDING OF DRONE,https://lens.org/132-479-165-716-802,2017,"Disclosed herein is a system and method for controlling the takeoff and landing of a drone. The system for controlling the takeoff and landing of a drone includes: a landing control device configured to vary the transmission range of Low Frequency (LF) landing control signals based on whether a response signal to a transmitted landing control signal in the transmission range is received, and to transmit a landing signal if the varied transmission range is less than a minimum radius; and a drone configured to fly in a control signal-based flight mode based on a landing control signal when receiving the landing control signal transmitted from the landing control device during GPS signal-based flight, and to land at a destination by flying in a landing mode when receiving a landing signal from the landing control device during flight in the control signal-based flight mode."
System and method for controlling takeoff and landing of drone,https://lens.org/010-707-764-810-102,2018,"Disclosed herein is a system and method for controlling the takeoff and landing of a drone. The system for controlling the takeoff and landing of a drone includes: a landing control device configured to vary the transmission range of Low Frequency (LF) landing control signals based on whether a response signal to a transmitted landing control signal in the transmission range is received, and to transmit a landing signal if the varied transmission range is less than a minimum radius; and a drone configured to fly in a control signal-based flight mode based on a landing control signal when receiving the landing control signal transmitted from the landing control device during GPS signal-based flight, and to land at a destination by flying in a landing mode when receiving a landing signal from the landing control device during flight in the control signal-based flight mode."
"AUTONOMOUS VEHICLE, CONTROL SYSTEM FOR REMOTELY CONTROLLING THE SAME, AND METHOD THEREOF",https://lens.org/104-652-080-581-110,2023,"An autonomous vehicle, a control system for remotely controlling the same, and a method thereof provides a control system including a processor configured to search for an external person around an autonomous vehicle when receiving a request for help of the external person from the autonomous vehicle, and to request the help of the external person through a user terminal of the searched external person or an external notification of the autonomous vehicle."
"AUTONOMOUS VEHICLE, CONTROL SYSTEM FOR REMOTELY CONTROLLING THE SAME, AND METHOD THEREOF",https://lens.org/104-652-080-581-110,2023,"An autonomous vehicle, a control system for remotely controlling the same, and a method thereof provides a control system including a processor configured to search for an external person around an autonomous vehicle when receiving a request for help of the external person from the autonomous vehicle, and to request the help of the external person through a user terminal of the searched external person or an external notification of the autonomous vehicle."
UAS DETECTION AND NEGATION,https://lens.org/128-865-001-401-610,2021,"Unauthorized operation of a UAV may present privacy or security risks. A software-defined radio (SDR) or other receiver can be used to monitor a specified range of frequencies to provide detection of wireless communication signals suspected of relating to UAV operation. A protocol detector corresponding to a trained classifier can be applied to data packets demodulated by the SDR. A transmitter can then be triggered to provide warnings by injecting warning data into a video channel in response to the detected protocol. Control of the UAV can be established by transmitting simulated control commands that overwhelm the signals received from the UAVs normal remote control. If transmission of warnings or simulated control signals fail to suppress unwanted UAV operation, other actions can be triggered such as jamming or dispatch of an interceptor such as a surveillance UAV."
UAS DETECTION AND NEGATION,https://lens.org/143-200-359-979-086,2020,"Unauthorized operation of a UAV may present privacy or security risks. A software-defined radio (SDR) or other receiver can be used to monitor a specified range of frequencies to provide detection of wireless communication signals suspected of relating to UAV operation. A protocol detector corresponding to a trained classifier can be applied to data packets demodulated by the SDR. A transmitter can then be triggered to provide warnings by injecting warning data into a video channel in response to the detected protocol. Control of the UAV can be established by transmitting simulated control commands that overwhelm the signals received from the UAVs normal remote control. If transmission of warnings or simulated control signals fail to suppress unwanted UAV operation, other actions can be triggered such as jamming or dispatch of an interceptor such as a surveillance UAV."
UAS DETECTION AND NEGATION,https://lens.org/005-272-420-883-34X,2021,"Unauthorized operation of a UAV may present privacy or security risks. A software-defined radio (SDR) or other receiver can be used to monitor a specified range of frequencies to provide detection of wireless communication signals suspected of relating to UAV operation. A protocol detector corresponding to a trained classifier can be applied to data packets demodulated by the SDR. A transmitter can then be triggered to provide warnings by injecting warning data into a video channel in response to the detected protocol. Control of the UAV can be established by transmitting simulated control commands that overwhelm the signals received from the UAVs normal remote control. If transmission of warnings or simulated control signals fail to suppress unwanted UAV operation, other actions can be triggered such as jamming or dispatch of an interceptor such as a surveillance UAV."
SYSTEM AND METHOD FOR CALCULATING WEIGHT DISTRIBUTION OF DRONE,https://lens.org/195-485-466-614-902,2017,"A system having a drone and a payload frame connected to the drone, wherein the payload frame includes a mechanism for attaching at least one payload module to the payload frame and electrically coupling the at least one payload module to the payload frame. The electrical coupling includes a communication interface for communicating with a controller of the drone, and is configured to communicate a relative location of the at least one payload module in the payload frame, a weight of the at least one payload module and a volume of the at least one payload module. The controller of the drone is configured to calculate a weight distribution within the payload frame, based on the relative location of the at least one payload module, the weight of the at least one payload module and the volume of the at least one payload volume."
System and method for calculating weight distribution of drone,https://lens.org/033-502-672-064-144,2017,"A system having a drone and a payload frame connected to the drone, wherein the payload frame includes a mechanism for attaching at least one payload module to the payload frame and electrically coupling the at least one payload module to the payload frame. The electrical coupling includes a communication interface for communicating with a controller of the drone, and is configured to communicate a relative location of the at least one payload module in the payload frame, a weight of the at least one payload module and a volume of the at least one payload module. The controller of the drone is configured to calculate a weight distribution within the payload frame, based on the relative location of the at least one payload module, the weight of the at least one payload module and the volume of the at least one payload volume."
SYSTEMS AND METHODS FOR NONINVASIVE AERIAL DETECTION OF IMPERMISSIBLE OBJECTS,https://lens.org/197-952-311-169-536,2022,"An apparatus comprises an aerial drone with a coherent radar system on a chip that operates in the terahertz range, the chip being in physical contact with the drone and configured to conduct a noninvasive scan of a target in a line of site field of view of the drone."
SYSTEMS AND METHODS FOR NONINVASIVE AERIAL DETECTION OF IMPERMISSIBLE OBJECTS,https://lens.org/197-952-311-169-536,2022,"An apparatus comprises an aerial drone with a coherent radar system on a chip that operates in the terahertz range, the chip being in physical contact with the drone and configured to conduct a noninvasive scan of a target in a line of site field of view of the drone."
DRONE BASED SECURITY AND DEFENSE SYSTEM,https://lens.org/155-543-687-327-052,2023,"Embodiments of the present disclosure may include a method to augment pilot control of a drone, the method including receiving a planned flight route. Embodiments may also include receiving sensor information from an at least one environment sensor along the planned flight route. In some embodiments, the at least one environment sensor may be located at a predefined location. Embodiments may also include estimating a drone location from the sensor information. Embodiments may also include receiving a speed vector of the drone. Embodiments may also include comparing the drone location to an expected drone location along the planned flight route. Embodiments may also include deriving a flight control command and a speed vector command to return the drone to a point along the planned flight route."
DRONE BASED SECURITY AND DEFENSE SYSTEM,https://lens.org/155-543-687-327-052,2023,"Embodiments of the present disclosure may include a method to augment pilot control of a drone, the method including receiving a planned flight route. Embodiments may also include receiving sensor information from an at least one environment sensor along the planned flight route. In some embodiments, the at least one environment sensor may be located at a predefined location. Embodiments may also include estimating a drone location from the sensor information. Embodiments may also include receiving a speed vector of the drone. Embodiments may also include comparing the drone location to an expected drone location along the planned flight route. Embodiments may also include deriving a flight control command and a speed vector command to return the drone to a point along the planned flight route."
ANTI-DRONE DEVICE BASED ON KINETIC AND LINEAR MOMENTUM PROJECTION,https://lens.org/194-560-260-296-209,2022,"A device that allows a safe countermeasure against a wide range of micro and small drone models.It could act also against the menace of swarms of these micro and small drone vehicles. It makes no interference with the environment. It is safe for the operator and all the people, animals, and properties in the operational area.It can operate from ranges of a few ten of meters till more than a kilometre.It can be operated manually by the user or autonomously with an Artificial Intelligence tracking and deployment control."
ANTI-DRONE DEVICE BASED ON KINETIC AND LINEAR MOMENTUM PROJECTION,https://lens.org/194-560-260-296-209,2022,"A device that allows a safe countermeasure against a wide range of micro and small drone models.It could act also against the menace of swarms of these micro and small drone vehicles. It makes no interference with the environment. It is safe for the operator and all the people, animals, and properties in the operational area.It can operate from ranges of a few ten of meters till more than a kilometre.It can be operated manually by the user or autonomously with an Artificial Intelligence tracking and deployment control."
Method for deploying a parachute on a drone,https://lens.org/168-059-424-182-549,2001,"A flying drone includes a flight control computer, a parachute system with a parachute, a power supply system, a propulsion system, and an actuating drive system, without any of these systems being redundantly duplicated. To prevent uncontrolled crashing of the drone due to a critical error of any subsystem, signals or data are supplied from the power supply system, the propulsion system, and the actuating drive system, to an error detection or recognition device, which detects defined errors or error combinations in the provided signals or data and then supplies a deployment signal to the parachute system, which responsively generates a control signal that triggers an ejection mechanism to eject the parachute."
Method for deploying a parachute on a drone,https://lens.org/074-022-558-140-304,2002,"A flying drone includes a flight control computer, a parachute system with a parachute, a power supply system, a propulsion system, and an actuating drive system, without any of these systems being redundantly duplicated. To prevent uncontrolled crashing of the drone due to a critical error of any subsystem, signals or data are supplied from the power supply system, the propulsion system, and the actuating drive system, to an error detection or recognition device, which detects defined errors or error combinations in the provided signals or data and then supplies a deployment signal to the parachute system, which responsively generates a control signal that triggers an ejection mechanism to eject the parachute."
Unmanned aerial vehicle express deliver unit remotely controlled and received by mobile phone,https://lens.org/104-919-182-042-88X,2015,"The invention relates to an unmanned aerial vehicle express deliver unit remotely controlled and received by a mobile phone and belongs to the technical field of mobile phone control by using Internet of things. A transmitter opens a mobile phone remote control and reception application program in the mobile phone I and realizes wireless connection with a mobile phone terminal module in an unmanned aerial vehicle by network signals; the transmitter clicks an authorization light key on a mobile phone display screen in the mobile phone I, starts the unmanned plant to fly in the sky by a command information processor and a flying control device, and then selects a target place which the unmanned aerial vehicle flies to on the mobile phone display screen; the unmanned aerial vehicle flies to the target place according to a command sent by the mobile phone; similarly, a receiver at the target place opens the mobile phone remote control and reception application program in a mobile phone II and realizes wireless network connection with the unmanned aerial vehicle by the mobile phone terminal module in the unmanned aerial vehicle; the reliever acquires the authorization of the transmitter by pressing the authorization light key in the mobile phone II, starts to operate the unmanned aerial vehicle to land at a specified safe place and then takes out goods in a goods cabin."
Fixed drone visualization in security systems,https://lens.org/037-098-201-867-374,2022,"A method of aerial surveillance including sending from a building management system (BMS), to a computer system, an alarm condition. The method further including programming, by the computer system, a drone with a route to a location of interest, wherein the route includes a portion of a map, the map including a data structure representation of a number of radio-frequency (RF) devices associated with one or more surveillance locations. The drone navigates to the location of interest by triangulating its position on the route using signals from the number of RF devices. The method further including sending, by the drone, to the computer system, sensor data including image data in response to arriving at the location of interest."
FIXED DRONE VISUALIZATION IN SECURITY SYSTEMS,https://lens.org/136-740-549-221-739,2019,"A method of aerial surveillance including sending from a building management system (BMS), to a computer system, an alarm condition. The method further including programming, by the computer system, a drone with a route to a location of interest, wherein the route includes a portion of a map, the map including a data structure representation of a number of radio-frequency (RF) devices associated with one or more surveillance locations. The drone navigates to the location of interest by triangulating its position on the route using signals from the number of RF devices. The method further including sending, by the drone, to the computer system, sensor data including image data in response to arriving at the location of interest."
Fixed drone visualization in security systems,https://lens.org/037-098-201-867-374,2022,"A method of aerial surveillance including sending from a building management system (BMS), to a computer system, an alarm condition. The method further including programming, by the computer system, a drone with a route to a location of interest, wherein the route includes a portion of a map, the map including a data structure representation of a number of radio-frequency (RF) devices associated with one or more surveillance locations. The drone navigates to the location of interest by triangulating its position on the route using signals from the number of RF devices. The method further including sending, by the drone, to the computer system, sensor data including image data in response to arriving at the location of interest."
Multimode unmanned aerial vehicle,https://lens.org/111-131-522-692-652,2015,"A system comprising an unmanned aerial vehicle (UAV) configured to transition from a terminal homing mode to a target search mode, responsive to an uplink signal and/or an autonomous determination of scene change."
Multimode unmanned aerial vehicle,https://lens.org/144-480-913-899-32X,2019,"A system comprising an unmanned aerial vehicle (UAV) configured to transition from a terminal homing mode to a target search mode, responsive to an uplink signal and/or an autonomous determination of scene change."
MULTIMODE UNMANNED AERIAL VEHICLE,https://lens.org/016-989-352-875-504,2023,"A system comprising an unmanned aerial vehicle (UAV) configured to transition from a terminal homing mode to a target search mode, responsive to an uplink signal and/or an autonomous determination of scene change."
MULTIMODE UNMANNED AERIAL VEHICLE,https://lens.org/016-989-352-875-504,2023,"A system comprising an unmanned aerial vehicle (UAV) configured to transition from a terminal homing mode to a target search mode, responsive to an uplink signal and/or an autonomous determination of scene change."
MULTIMODE UNMANNED AERIAL VEHICLE,https://lens.org/152-379-374-121-052,2010,"A system comprising an unmanned aerial vehicle (UAV) configured to transition from a terminal homing mode to a target search mode, responsive to an uplink signal and/or an autonomous determination of scene change."
Multimode unmanned aerial vehicle,https://lens.org/186-734-849-529-762,2023,"A system comprising an unmanned aerial vehicle (UAV) configured to transition from a terminal homing mode to a target search mode, responsive to an uplink signal and/or an autonomous determination of scene change."
Multimode unmanned aerial vehicle,https://lens.org/141-258-179-229-113,2019,"A system comprising an unmanned aerial vehicle (UAV) configured to transition from a terminal homing mode to a target search mode, responsive to an uplink signal and/or an autonomous determination of scene change."
Multimode unmanned aerial vehicle,https://lens.org/186-734-849-529-762,2023,"A system comprising an unmanned aerial vehicle (UAV) configured to transition from a terminal homing mode to a target search mode, responsive to an uplink signal and/or an autonomous determination of scene change."
MULTIMODE UNMANNED AERIAL VEHICLE,https://lens.org/028-929-994-199-350,2020,"A system comprising an unmanned aerial vehicle (UAV) configured to transition from a terminal homing mode to a target search mode, responsive to an uplink signal and/or an autonomous determination of scene change."
MULTIMODE UNMANNED AERIAL VEHICLE,https://lens.org/081-401-767-521-270,2016,"A system comprising an unmanned aerial vehicle (UAV) configured to transition from a terminal homing mode to a target search mode, responsive to an uplink signal and/or an autonomous determination of scene change."
SECURITY SYSTEM USING UNMANNED AERIAL VEHICLES,https://lens.org/142-218-492-899-076,2018,"A security system utilizes at least one unmanned aerial vehicle (UAV) that is equipped with a video camera and a motion detector. The UAV is controlled remotely by a ground control station having a computer. When not in flight, the UAV is mounted on a docking station that has a battery charger for charging a battery in the UAV when the UAV is docked at the docking station. The UAV has a transmitter that transmits an alert signal to the ground control station when an intruder is detected via the video camera or motion detector. The ground control station is configured to deploy and control the UAV to follow the intruder upon receiving the signal from the UAV. The UAV is controlled by personnel at the ground control station, who can direct the flight path of the UAV based on the movements of the intruders."
UNMANNED AERIAL VEHICLE FOR TRANSPORTING A PAYLOAD,https://lens.org/022-867-751-552-640,2021,"An unmanned aerial vehicle (UAV) (100) for autonomously transporting a payload (118). The UAV (100) comprises a flight control system (122) which is configured to autonomously operate a steering and propulsion system (112) such that the UAV (100) is able to autonomously fly to a predetermined destination. The UAV (100) has a first navigation system (e.g. 128) and a second navigation system (e.g. 130), which are arranged to determine a position of the UAV (100) in dependence on different sources of data. The flight control system (122) is configured to determine whether the first navigation system (e.g. 128) and the second navigation system (e.g. 130) are providing a correct indication of the position of the UAV (100). The flight control system (122) disregards the position provided by the first navigation system (e.g. 128) and/or the second navigation system (e.g. 130) if it is determined that the first navigation system (e.g. 128) and/or the second navigation system (e.g. 130) are/is not providing a correct indication of position."
UNMANNED AERIAL VEHICLE COLLISION AVOIDANCE SYSTEM,https://lens.org/048-264-323-398-027,2019,"A drone detection system is configured to detect a presence of an unmanned aerial vehicle (UAV) in a potential flight path of a piloted aircraft. A system processor in communication with the drone detection system determines whether the unmanned aerial vehicle presents a threat of collision and needs to be avoided by the piloted aircraft. A transmitter is controlled by the system processor and is configured to transmit, in response to detecting the presence of the unmanned aerial vehicle, a signal to interrupt flight commands sent to the unmanned aerial vehicle by a control transmitter for the unmanned aerial vehicle so as to remove the unmanned aerial vehicle from the potential flight path of the piloted aircraft."
SELF-MAINTAINED 5TH GENERATION NETWORK,https://lens.org/089-307-121-293-141,2023,"A drone can maintain a communications network. A first arm of the drone is caused to be coupled to a cell tower of the communications network or a network entity coupled to the cell tower. Subsequent to the first arm being coupling to the cell tower or the network entity, the drone can perform maintenance on the network entity."
SELF-MAINTAINED 5TH GENERATION NETWORK,https://lens.org/089-307-121-293-141,2023,"A drone can maintain a communications network. A first arm of the drone is caused to be coupled to a cell tower of the communications network or a network entity coupled to the cell tower. Subsequent to the first arm being coupling to the cell tower or the network entity, the drone can perform maintenance on the network entity."
"CONTROL DEVICE, CONTROL METHOD, AND PROGRAM",https://lens.org/060-819-516-534-508,2020,There is provided a control device including: an identification unit that identifies a sign installed on the ground on the basis of information acquired by a UAV; and a control unit that controls the flight of the UAV in accordance with the identification.
System and method for automated landing of an unmanned aerial vehicle,https://lens.org/085-384-732-330-013,2019,"A system for the automated landing of an unmanned aerial vehicle includes an unmanned aerial vehicle having a control module, a first remote control device located at a remote location and controllable by a pilot, the first remote control device being configured to communicate with the unmanned aerial vehicle, and a second remote control system device located at a landing area and controllable by an observer, the second remote control device being configured to communicate with the unmanned aerial vehicle. The first remote control device and the second remote control device are configured for continuous communication with the unmanned aerial vehicle for landing of the unmanned aerial vehicle at a landmark at the landing area."
Operating a UAV with a narrow obstacle-sensor field-of-view,https://lens.org/177-324-209-644-086,2017,"A method for autonomously operating an unmanned aerial vehicle (UAV) that includes one or more imaging devices is provided. The imaging devices are pointed away from a direction in which the UAV is flying, and subsequently, an upcoming portion of a current flight path of the UAV is imaged, using the imaging devices. In response to the imaging, an obstacle on the current flight path is detected, and an alternate flight path is planned in response thereto. The UAV is then flown along the alternate flight path, instead of the current flight path. Other embodiments are also described."
OPERATING A UAV WITH A NARROW OBSTACLE-SENSOR FIELD-OF-VIEW,https://lens.org/160-839-028-467-100,2017,"A method for autonomously operating an unmanned aerial vehicle (UAV) that includes one or more imaging devices is provided. The imaging devices are pointed away from a direction in which the UAV is flying, and subsequently, an upcoming portion of a current flight path of the UAV is imaged, using the imaging devices. In response to the imaging, an obstacle on the current flight path is detected, and an alternate flight path is planned in response thereto. The UAV is then flown along the alternate flight path, instead of the current flight path. Other embodiments are also described."
"Device, system and method for installing an object on a power line",https://lens.org/000-400-220-085-37X,2022,"There is described a drone (1) for installing an object (10) on a power line (2), where the drone (1) comprises: - a connection means (6) for connecting the drone (1) to the object (10), so that the drone (1) may carry the object (10); - a first engagement member (8) for engaging a second engagement member on the object (10), - a power source for operating the first engagement member (8) so as to actuate a locking means (12) on the object, via the second engagement member, for securely locking the object (10) to the power line (2), wherein the drone (1) further comprises a device (14) for limiting one or more degrees of freedom of the object (10) relative to the power line (2) before engaging the locking means (12)."
"Device, system and method for installing an object on a power line",https://lens.org/000-400-220-085-37X,2022,"There is described a drone (1) for installing an object (10) on a power line (2), where the drone (1) comprises: - a connection means (6) for connecting the drone (1) to the object (10), so that the drone (1) may carry the object (10); - a first engagement member (8) for engaging a second engagement member on the object (10), - a power source for operating the first engagement member (8) so as to actuate a locking means (12) on the object, via the second engagement member, for securely locking the object (10) to the power line (2), wherein the drone (1) further comprises a device (14) for limiting one or more degrees of freedom of the object (10) relative to the power line (2) before engaging the locking means (12)."
"Device, system and method for installing an object on a power line",https://lens.org/087-518-280-049-290,2021,"There is described a drone (1) for installing an object (10) on a power line (2), where the drone (1) comprises: - a connection means (6) for connecting the drone (1) to the object (10), so that the drone (1) may carry the object (10); - a first engagement member (8) for engaging a second engagement member on the object (10), - a power source for operating the first engagement member (8) so as to actuate a locking means (12) on the object, via the second engagement member, for securely locking the object (10) to the power line (2), wherein the drone (1) further comprises a device (14) for limiting one or more degrees of freedom of the object (10) relative to the power line (2) before engaging the locking means (12)."
"Device, system and method for installing an object on a power line",https://lens.org/000-400-220-085-37X,2022,"There is described a drone (1) for installing an object (10) on a power line (2), where the drone (1) comprises: - a connection means (6) for connecting the drone (1) to the object (10), so that the drone (1) may carry the object (10); - a first engagement member (8) for engaging a second engagement member on the object (10), - a power source for operating the first engagement member (8) so as to actuate a locking means (12) on the object, via the second engagement member, for securely locking the object (10) to the power line (2), wherein the drone (1) further comprises a device (14) for limiting one or more degrees of freedom of the object (10) relative to the power line (2) before engaging the locking means (12)."
"DEVICE, SYSTEM AND METHOD FOR INSTALLING AN OBJECT ON A POWER LINE",https://lens.org/053-816-658-946-623,2020,"There is described a drone (1) for installing an object (10) on a power line (2), where the drone (1) comprises: - a connection means (6) for connecting the drone (1) to the object (10), so that the drone (1) may carry the object (10); - a first engagement member (8) for engaging a second engagement member on the object (10), - a power source for operating the first engagement member (8) so as to actuate a locking means (12) on the object, via the second engagement member, for securely locking the object (10) to the power line (2), wherein the drone (1) further comprises a device (14) for limiting one or more degrees of freedom of the object (10) relative to the power line (2) before engaging the locking means (12)."
METHOD FOR FOLLOWING WEARABLE DEVICE AND ROBOT THEREOF,https://lens.org/010-082-826-324-533,2020,"An embodiment provides an unmanned flying robot including a communication unit configured to communicate with at least one of a wearable device and a user terminal and receive at least one of state information of a wearer of the wearable device and positional information of the wearable device, a drive unit configured to track the wearable device and adjust a driving altitude of the unmanned flying robot based on the positional information, and a controller configured to control the drive unit so as to track the wearable device based on the positional information and adjust the driving altitude to at least one predetermined altitude based on the state information and an operating method thereof. An embodiment provides a user terminal of tracking a wearable device using an unmanned flying robot."
An extensible multifunctional quadcopter aiming for simplifying trip,https://lens.org/031-715-281-799-246,2018,"Abstract A quadcopter with an umbrella attached for convenience of the users is disclosed. The umbrella UAV for covering the user during rain, snow or sunshine by wireless control is composed of: visual transmitter with Wi-Fi transmitter, attached to the main flight control processor, for sending captured images or videos from the built-in camera to the operating device of the user; GPS, connected to the processor, for locating the drone in a relatively liable range; receiver, cooperating with Wi-Fi transmitter and flight control, for receiving commands from the user through the controlling device; vocal recognition unit, attached to the flight control, for recognizing vocal commands from the administrator and operate corresponding maneuver; and a power distribution board, attached to the flight control panel, for distributing different electrical power into different rotors of the multirotor UAV and achieve different maneuvers."
SAFETY SYSTEM INSPECTION APPARATUS AND METHOD,https://lens.org/086-709-617-660-93X,2018,"An apparatus and system for performing inspections including a drone having circuitry configured to communicate wirelessly with automated fire safety systems. A homing device may be attached to the drone, and the system may further include a second drone with a camera, such that the second drone may detect the homing device and follow and record the first drone's operations with the camera."
Remote token-based control of autonomous vehicles,https://lens.org/079-088-288-637-372,2020,"A network device receives input from an operator that selects parameters associated with issuing at least one remote control command to at least one autonomous vehicle. The network device generates an autonomous vehicle control token based on the selected parameters, and transmits the control token, via a wireless network, to the at least one autonomous vehicle."
REMOTE TOKEN-BASED CONTROL OF AUTONOMOUS VEHICLES,https://lens.org/132-182-610-231-292,2018,"A network device receives input from an operator that selects parameters associated with issuing at least one remote control command to at least one autonomous vehicle. The network device generates an autonomous vehicle control token based on the selected parameters, and transmits the control token, via a wireless network, to the at least one autonomous vehicle."
Enhanced flight plan for unmanned traffic aircraft systems,https://lens.org/029-199-581-923-384,2023,"A method for controlling an Unmanned Aerial Vehicle (UAV) is described. The method includes receiving an enhanced flight plan, wherein the enhanced flight plan includes one or more predefined points and each of the predefined points is associated with a set of conditions and a set of locations; storing the one or more predefined points in the UAV; flying the UAV according to the enhanced flight plan; detecting, by the UAV, a condition associated with a predefined point in the one or more predefined points stored in the UAV; and adjusting, autonomously by the UAV and in response to detecting the condition, a flight of the UAV using a set of locations associated with the predefined point and associated with the detected condition."
ENHANCED FLIGHT PLAN FOR UNMANNED TRAFFIC AIRCRAFT SYSTEMS,https://lens.org/082-518-445-848-989,2020,"A method for controlling an Unmanned Aerial Vehicle (UAV) is described. The method includes receiving an enhanced flight plan, wherein the enhanced flight plan includes one or more predefined points and each of the predefined points is associated with a set of conditions and a set of locations; storing the one or more predefined points in the UAV; flying the UAV according to the enhanced flight plan; detecting, by the UAV, a condition associated with a predefined point in the one or more predefined points stored in the UAV; and adjusting, autonomously by the UAV and in response to detecting the condition, a flight of the UAV using a set of locations associated with the predefined point and associated with the detected condition."
Enhanced flight plan for unmanned traffic aircraft systems,https://lens.org/029-199-581-923-384,2023,"A method for controlling an Unmanned Aerial Vehicle (UAV) is described. The method includes receiving an enhanced flight plan, wherein the enhanced flight plan includes one or more predefined points and each of the predefined points is associated with a set of conditions and a set of locations; storing the one or more predefined points in the UAV; flying the UAV according to the enhanced flight plan; detecting, by the UAV, a condition associated with a predefined point in the one or more predefined points stored in the UAV; and adjusting, autonomously by the UAV and in response to detecting the condition, a flight of the UAV using a set of locations associated with the predefined point and associated with the detected condition."
METHOD AND APPARATUS FOR CONTROLLING FLIGHT OF UNMANNED AERIAL VEHICLE,https://lens.org/160-542-504-168-762,2019,"A method and apparatus for controlling the flight of an Unmanned Aerial Vehicle (UAV) are provided. The method includes: determining a starting flight position where a UAV is parked currently and a nose direction of the UAV (101); starting off from the starting flight position, and flying along a straight line in the nose direction (102); and when receiving a route adjustment instruction during the flight of the UAV, adjusting an air route of the UAV according to the route adjustment instruction (103). During the flight, an operator can correct an air route via a remote control apparatus without surveying and mapping when detecting that the UAV is flying off course; and the operator can make the UAV precisely fly along a desired straight line by means of simple operations, thereby simplifying an operation process and promoting the adaptability to changes of the UAV."
METHOD OF CONTROLLING OPERATION OF AN UNMANNED AERIAL VEHICLE,https://lens.org/079-919-905-672-769,2014,A method of controlling operation of an unmanned aerial vehicle having a flight control system (110) comprising: a flight controller (300) for implementing a flight control strategy; and an engine control unit (117) interfaced with said flight controller (300) for controlling engine (115) operation. An engine speed target is set for said flight control system in response to one or more signals communicated by said flight controller (300) to the engine control unit (117) which controls operation of engine (115) to achieve the engine speed target.
METHOD OF CONTROLLING OPERATION OF AN UNMANNED AERIAL VEHICLE,https://lens.org/160-601-476-603-92X,2013,A method of controlling operation of an unmanned aerial vehicle having a flight control system (110) comprising: a flight controller (300) for implementing a flight control strategy; and an engine control unit (117) interfaced with said flight controller (300) for controlling engine (115) operation. An engine speed target is set for said flight control system in response to one or more signals communicated by said flight controller (300) to the engine control unit (117) which controls operation of engine (115) to achieve the engine speed target.
Unmanned Aerial Vehicle Assembly,https://lens.org/035-374-658-462-671,2022,An unmanned aerial vehicle assembly includes an unmanned aerial vehicle including a plurality of propulsion units thereby facilitating the unmanned aerial vehicle to fly. A plurality of cameras is each coupled to the unmanned aerial vehicle to capture imagery of the area surrounding the unmanned aerial vehicle. A microphone is coupled to the unmanned aerial vehicle to capture audible sounds in the area surrounding the unmanned aerial vehicle. A transceiver is integrated into the unmanned aerial vehicle and the transceiver is in communication with an extrinsic communication network. In this way the transceiver can receive flight control commands from a personal electronic device that is in communication with the extrinsic communication network thereby facilitating an authorized user to remotely control the unmanned aerial vehicle. A user interface is integrated into the unmanned aerial vehicle to capture a signature from a person. The user interface is in electrical communication with the transceiver thereby facilitating the signature to be communicated to the authorized user.
"COMPUTER SYSTEM, DRONE CONTROL METHOD, AND PROGRAM",https://lens.org/194-121-985-110-833,2021,"Provided are a computer system, a drone control method, and a program that can obtain information about the object while reducing the power consumption. When the computer system acquires an image captured by a drone, the computer system performs image analysis on the acquired image, extract, in a result of the image analysis, a point whose an edge variation amount is equal to or greater than a predetermined threshold, acquires a position coordinate of the extracted point; and controls the drone to fly towards the acquired position coordinate and perform capturing with a camera using light other than visible light."
"Autonomous flying device, control method of autonomous flying device, and non-transitory recording medium",https://lens.org/057-767-081-285-492,2019,"An autonomous flying device that tracks a moving object and flies includes a sensor that obtains first information related to a velocity of the moving object, a controller that controls flight of the autonomous flying device, and a driver that drives the autonomous flying device, the controller setting a velocity of the autonomous flying device in accordance with the first information so that the velocity of the autonomous flying device increases as a distance between the moving object and the autonomous flying device increases, the driver causing the autonomous flying device to fly at the velocity set by the controller."
"AUTONOMOUS FLYING DEVICE, CONTROL METHOD OF AUTONOMOUS FLYING DEVICE, AND NON-TRANSITORY RECORDING MEDIUM",https://lens.org/147-062-109-760-658,2017,"An autonomous flying device that tracks a moving object and flies includes a sensor that obtains first information related to a velocity of the moving object, a controller that controls flight of the autonomous flying device, and a driver that drives the autonomous flying device, the controller setting a velocity of the autonomous flying device in accordance with the first information so that the velocity of the autonomous flying device increases as a distance between the moving object and the autonomous flying device increases, the driver causing the autonomous flying device to fly at the velocity set by the controller."
Method and apparatus for controlling unmanned aerial vehicle,https://lens.org/162-088-149-779-424,2020,"A method and an apparatus for controlling an unmanned aerial vehicle are provided. The method includes: detecting an abnormality occurring on the unmanned aerial vehicle in a flight process; obtaining a hover instruction in response to detecting the abnormality; and controlling, in response to the hover instruction, the unmanned aerial vehicle to hover based on the hover instruction."
METHOD AND APPARATUS FOR CONTROLLING UNMANNED AERIAL VEHICLE,https://lens.org/058-980-593-161-126,2018,"A method and an apparatus for controlling an unmanned aerial vehicle are provided. The method includes: detecting an abnormality occurring on the unmanned aerial vehicle in a flight process; obtaining a hover instruction in response to detecting the abnormality; and controlling, in response to the hover instruction, the unmanned aerial vehicle to hover based on the hover instruction."
Navigating a UAV under remote control and manual control with three dimensional flight depiction,https://lens.org/061-812-702-807-121,2005,"Navigating a UAV including receiving in a remote control device a user's selection of a GUI map pixel that represents a waypoint for UAV navigation, mapping the pixel's location on the GUI to Earth coordinates of the waypoint, transmitting the coordinates of the waypoint to the UAV, reading a starting position from a GPS receiver on the UAV, piloting the UAV, under control of a navigation computer on the UAV, from the starting position to the waypoint in accordance with a navigation algorithm, and changing from piloting the UAV under control of a navigation computer on the UAV to piloting the UAV under manual control. While piloting the UAV under manual control, reading from the GPS receiver a sequence of GPS data representing a flight path of the UAV, and depicting the flight of the UAV with 3D computer graphics."
Control of a drone,https://lens.org/088-456-877-676-794,2016,"A pilotless drone 110 has a wireless transceiver configured to relay information between a user equipment 120 and a base station130, a memory configured to store at least one parameter relating to at least one of: at least one wireless connection, a location of the user equipment, a location of the base station, a geographic feature and an audio signal emitted by the user equipment, and at least one processing core configured to determine navigation information for the pilotless drone based at least in part on the at least one parameter. The drone may navigate to a position based on signal strength of signals from user equipment and/or base station and may take into account stored map information. It may maintain a line of sight communications. Where simultaneous connection to user equipment and base station is not possible the drone may move to alternately enable each wireless connection."
SYSTEM AND METHOD FOR CONTROLLING DRONE DELIVERY OR PICK UP DURING A DELIVERY OR PICK UP PHASE OF DRONE OPERATION,https://lens.org/031-068-744-333-103,2019,"A system including a landing location where a drone at least one of delivers and acquires a parcel, and a homing device to interact with the drone to guide the drone to the landing location independent of interaction from another source. The homing device guides the drone during the landing phase of a flight plan. A method is also disclosed."
SYSTEM AND METHOD FOR CONTROLLING DRONE DELIVERY OR PICK UP DURING A DELIVERY OR PICK UP PHASE OF DRONE OPERATION,https://lens.org/163-669-155-654-769,2021,"A system including a landing location where a drone at least one of delivers and acquires a parcel, and a homing device to interact with the drone to guide the drone to the landing location independent of interaction from another source. The homing device guides the drone during the landing phase of a flight plan. A method is also disclosed."
System and method for controlling drone delivery or pick up during a delivery or pick up phase of drone operation,https://lens.org/012-409-096-657-284,2018,"A system including a landing location where a drone at least one of delivers and acquires a parcel, and a homing device to interact with the drone to guide the drone to the landing location independent of interaction from another source. The homing device guides the drone during the landing phase of a flight plan. A method is also disclosed."
SYSTEM AND METHOD FOR CONTROLLING DRONE DELIVERY,https://lens.org/063-602-490-572-750,2023,"A system including a landing location where a drone at least one of delivers and acquires a parcel, and a homing device to interact with the drone to guide the drone to the landing location independent of interaction from another source. The homing device guides the drone during the landing phase of a flight plan. A method is also disclosed."
SYSTEM AND METHOD FOR CONTROLLING DRONE DELIVERY,https://lens.org/187-226-826-163-580,2016,"A system including a landing location where a drone at least one of delivers and acquires a parcel, and a homing device to interact with the drone to guide the drone to the landing location independent of interaction from another source. The homing device guides the drone during the landing phase of a flight plan. A method is also disclosed."
METHODS AND SYSTEMS FOR SHIFTING OBJECTS,https://lens.org/133-361-899-768-014,2021,"Systems, and methods of shifting objects using a vehicle and at least one drone are provided. The vehicle and drone are configured to communicate using communication components to coordinate movement of the at least one drone relative to the wheeled object. The system for shifting objects may include sensors for detecting characteristics of the environment. The system may include shifting the object to a second location based on the characteristics detected."
Methods and systems for shifting objects,https://lens.org/056-923-265-273-520,2022,"Systems, and methods of shifting objects using a vehicle and at least one drone are provided. The vehicle and drone are configured to communicate using communication components to coordinate movement of the at least one drone relative to the wheeled object. The system for shifting objects may include sensors for detecting characteristics of the environment. The system may include shifting the object to a second location based on the characteristics detected."
Methods and systems for shifting objects,https://lens.org/056-923-265-273-520,2022,"Systems, and methods of shifting objects using a vehicle and at least one drone are provided. The vehicle and drone are configured to communicate using communication components to coordinate movement of the at least one drone relative to the wheeled object. The system for shifting objects may include sensors for detecting characteristics of the environment. The system may include shifting the object to a second location based on the characteristics detected."
"Methods, systems and devices for delivery drone security",https://lens.org/080-038-784-154-644,2016,"Methods, systems and devices are provided for securing a drone delivering a package of goods to a delivery destination. A notification may be provided to a device of the purchaser that the drone has arrived near the delivery destination. The drone may hover at a secure altitude from a landing zone at the delivery destination. The drone may receive a purchase code associated with a purchase of the package of goods. The drone may authenticate the purchase code as a condition for landing. The drone may land in the landing zone at the delivery destination when the purchase code is authenticated. The drone may abort the landing when the purchase code is not authenticated. The drone may receive a delivery code associated with completing delivery the package of goods. The drone may require the delivery code as a condition for releasing the package of goods."
"METHODS, SYSTEMS AND DEVICES FOR DELIVERY DRONE SECURITY",https://lens.org/086-020-166-813-430,2016,"Methods, systems and devices are provided for securing a drone delivering a package of goods to a delivery destination. A notification may be provided to a device of the purchaser that the drone has arrived near the delivery destination. The drone may hover at a secure altitude from a landing zone at the delivery destination. The drone may receive a purchase code associated with a purchase of the package of goods. The drone may authenticate the purchase code as a condition for landing. The drone may land in the landing zone at the delivery destination when the purchase code is authenticated. The drone may abort the landing when the purchase code is not authenticated. The drone may receive a delivery code associated with completing delivery the package of goods. The drone may require the delivery code as a condition for releasing the package of goods."
"Methods, Systems and Devices for Delivery Drone Security",https://lens.org/032-713-661-725-73X,2016,"Methods, systems and devices are provided for securing a drone delivering a package of goods to a delivery destination. A notification may be provided to a device of the purchaser that the drone has arrived near the delivery destination. The drone may hover at a secure altitude from a landing zone at the delivery destination. The drone may receive a purchase code associated with a purchase of the package of goods. The drone may authenticate the purchase code as a condition for landing. The drone may land in the landing zone at the delivery destination when the purchase code is authenticated. The drone may abort the landing when the purchase code is not authenticated. The drone may receive a delivery code associated with completing delivery the package of goods. The drone may require the delivery code as a condition for releasing the package of goods."
AUTONOMOUS UNMANNED AERIAL VEHICLE DECISION-MAKING,https://lens.org/177-167-393-140-219,2017,"A method and apparatus for autonomously managing operation of an unmanned aerial vehicle (202). Sensor data (228) is received by a computer system (224) located onboard the unmanned aerial vehicle (202). The sensor data (228) is processed by the computer system (224) to generate information of interest (230) related to at least one target, while the unmanned aerial vehicle (202) is out of a communications range (218) of a control station (210). A number of actions (225) to be performed is identified by the computer system (224) based on the information of interest (230) related to the at least one target, while the unmanned aerial vehicle (202) is out of the communications range (218) of the control station (210).
"
Systems and methods for monitoring objects at sporting events,https://lens.org/130-088-463-528-198,2022,"A system for monitoring objects at sporting events or other types of events uses a wearable drone that has at least one camera or other sensor for capturing or otherwise sensing data. When the drone is to be used for monitoring, such as monitoring an object at a sporting event, the wearable drone may be detached from its user, and it may hover or otherwise fly within a certain position of an object to be monitored. While flying, the drone's sensor may be used to capture information, such as performance data or images, of the object during the sporting event."
Systems and methods for monitoring objects at sporting events,https://lens.org/141-229-722-662-101,2022,"A system for monitoring objects at sporting events or other types of events uses a wearable drone that has at least one camera or other sensor for capturing or otherwise sensing data. When the drone is to be used for monitoring, such as monitoring an object at a sporting event, the wearable drone may be detached from its user, and it may hover or otherwise fly within a certain position of an object to be monitored. While flying, the drone's sensor may be used to capture information, such as performance data or images, of the object during the sporting event."
SYSTEMS AND METHODS FOR MONITORING OBJECTS AT SPORTING EVENTS,https://lens.org/130-528-608-258-755,2017,"A system for monitoring objects at sporting events or other types of events uses a wearable drone that has at least one camera or other sensor for capturing or otherwise sensing data. When the drone is to be used for monitoring, such as monitoring an object at a sporting event, the wearable drone may be detached from its user, and it may hover or otherwise fly within a certain position of an object to be monitored. While flying, the drone's sensor may be used to capture information, such as performance data or images, of the object during the sporting event."
SYSTEMS AND METHODS FOR MONITORING OBJECTS AT SPORTING EVENTS,https://lens.org/029-098-639-825-160,2022,"A system for monitoring objects at sporting events or other types of events uses a wearable drone that has at least one camera or other sensor for capturing or otherwise sensing data. When the drone is to be used for monitoring, such as monitoring an object at a sporting event, the wearable drone may be detached from its user, and it may hover or otherwise fly within a certain position of an object to be monitored. While flying, the drone's sensor may be used to capture information, such as performance data or images, of the object during the sporting event."
Systems and methods for monitoring objects at sporting events,https://lens.org/130-088-463-528-198,2022,"A system for monitoring objects at sporting events or other types of events uses a wearable drone that has at least one camera or other sensor for capturing or otherwise sensing data. When the drone is to be used for monitoring, such as monitoring an object at a sporting event, the wearable drone may be detached from its user, and it may hover or otherwise fly within a certain position of an object to be monitored. While flying, the drone's sensor may be used to capture information, such as performance data or images, of the object during the sporting event."
SYSTEMS AND METHODS FOR MONITORING OBJECTS AT SPORTING EVENTS,https://lens.org/138-564-914-869-916,2022,"A system for monitoring objects at sporting events or other types of events uses a wearable drone that has at least one camera or other sensor for capturing or otherwise sensing data. When the drone is to be used for monitoring, such as monitoring an object at a sporting event, the wearable drone may be detached from its user, and it may hover or otherwise fly within a certain position of an object to be monitored. While flying, the drone's sensor may be used to capture information, such as performance data or images, of the object during the sporting event."
SYSTEMS AND METHODS FOR MONITORING OBJECTS AT SPORTING EVENTS,https://lens.org/029-098-639-825-160,2022,"A system for monitoring objects at sporting events or other types of events uses a wearable drone that has at least one camera or other sensor for capturing or otherwise sensing data. When the drone is to be used for monitoring, such as monitoring an object at a sporting event, the wearable drone may be detached from its user, and it may hover or otherwise fly within a certain position of an object to be monitored. While flying, the drone's sensor may be used to capture information, such as performance data or images, of the object during the sporting event."
SYSTEMS AND METHODS FOR MONITORING OBJECTS AT SPORTING EVENTS,https://lens.org/029-098-639-825-160,2022,"A system for monitoring objects at sporting events or other types of events uses a wearable drone that has at least one camera or other sensor for capturing or otherwise sensing data. When the drone is to be used for monitoring, such as monitoring an object at a sporting event, the wearable drone may be detached from its user, and it may hover or otherwise fly within a certain position of an object to be monitored. While flying, the drone's sensor may be used to capture information, such as performance data or images, of the object during the sporting event."
SYSTEMS AND METHODS FOR MONITORING OBJECTS AT SPORTING EVENTS,https://lens.org/052-632-573-624-411,2017,"A system for monitoring objects at sporting events or other types of events uses a wearable drone that has at least one camera or other sensor for capturing or otherwise sensing data. When the drone is to be used for monitoring, such as monitoring an object at a sporting event, the wearable drone may be detached from its user, and it may hover or otherwise fly within a certain position of an object to be monitored. While flying, the drone's sensor may be used to capture information, such as performance data or images, of the object during the sporting event."
SYSTEMS AND METHODS FOR MONITORING OBJECTS AT SPORTING EVENTS,https://lens.org/138-564-914-869-916,2022,"A system for monitoring objects at sporting events or other types of events uses a wearable drone that has at least one camera or other sensor for capturing or otherwise sensing data. When the drone is to be used for monitoring, such as monitoring an object at a sporting event, the wearable drone may be detached from its user, and it may hover or otherwise fly within a certain position of an object to be monitored. While flying, the drone's sensor may be used to capture information, such as performance data or images, of the object during the sporting event."
Unmanned aerial vehicles,https://lens.org/025-052-485-099-792,2018,"An unmanned aerial vehicle, UAV 100, is operable in an autonomous mode. The UAV 100 comprises an upwards-configurable sensor 105, which may be a camera, ultrasonic sensor or LIDAR sensor, an actuator 125 and a controller 120. The upwards-configurable sensor 105 is configurable in an upwards-facing configuration during an autonomous procedure such that a field of view of the upwards-configurable sensor includes airspace 115 directly above the UAV 100. The controller 120 controls the actuator 125 during the autonomous procedure based on data captured by the upwards-configurable sensor 105 to cause the UAV 100 to make physical contact with an object in the airspace 115 directly above the UAV 100 during the autonomous procedure. Other inventions relate to a UAV which obtains data from the object above the UAV, and a UAV with an upwards configurable light."
Artificial intelligence,https://lens.org/147-081-436-949-451,2021,"Autonomous control of an entity such as a UAV or unmanned aircraft is used to perform an action. Control is based upon received situational awareness data and a generated random number. A control signal to control the entity to perform an action is based on the situational awareness data and the random number. Situation data may be location or type of threat, presence of clouds etc. Control actions may be change of course, altitude or speed or deploying weapons. The use of a random number gives rise to unpredictable behaviour by the entity which is useful in e.g. combat situations."
"METHOD FOR CONTROLLING UNMANNED AIRCRAFT, SERVER, AND REMOTE CONTROL DEVICE",https://lens.org/147-581-153-527-065,2020,"A method for controlling an unmanned aerial vehicle (UAV) includes receiving locking instruction information from a user terminal for locking the UAV. The method also includes transmitting a locking command to a remote control device of the UAV based on the locking instruction information, to instruct the remote control device to lock the UAV based on the locking command."
"Method for controlling unmanned aircraft, server, and remote control device",https://lens.org/149-302-002-997-56X,2022,"A method for controlling an unmanned aerial vehicle (UAV) includes receiving locking instruction information from a user terminal for locking the UAV. The method also includes transmitting a locking command to a remote control device of the UAV based on the locking instruction information, to instruct the remote control device to lock the UAV based on the locking command."
"Miniature, unmanned aircraft with onboard stabilization and automated ground control of flight path",https://lens.org/074-339-460-036-651,2005,"A miniature, unmanned aircraft for acquiring and/or transmitting data, capable of automatically maintaining desired airframe stability while operating by remote directional commands. The aircraft comprises a fuselage and a wing, a piston engine and propeller, a fuel supply, at least one data sensor and/or radio transceiver, a microprocessor disposed to manage flight, a radio transceiver for receiving remotely generated flight direction commands, a GPS receiver, a plurality of control surfaces and associated servomechanisms, for controlling flight stabilization and direction, roll, pitch, yaw, velocity, and altitude sensors. The microprocessor uses roll, pitch, yaw, and altitude data to control attitude and altitude of the aircraft automatically, but controls flight direction solely based on external commands. The aircraft does not exceed fifty-five pounds."
"APPARATUS, SYSTEM, AND METHOD OF JAMMING AN UNMANNED AERIAL VEHICLE",https://lens.org/191-506-212-267-474,2020,"An apparatus, system, and method for detecting and soft jamming unmanned aerial vehicle are provided. The apparatus includes a wireless communication chipset, a scan and detection circuit, a jamming circuit, and a controller. The controller is configured to control the scan and detection circuit to identify an unmanned aerial vehicle, and the controller is configured to control the jamming circuit to disable a video recording function of the unmanned aerial vehicle without disabling other functions of the unmanned aerial vehicle."
Smart controlling device and method of controlling therefor,https://lens.org/022-612-098-588-485,2019,"The present specification relates to a smart controlling device capable of utilizing machine learning for voice recognition and a method of controlling therefor. The smart controlling device according to the present invention includes a receiver configured to receive an input including a command trigger, and a controller configured to detect one or more external display devices, select a display device of the detected one or more external display devices, cause a power status of the selected display device to be changed to a first state, and cause a response data corresponding to a first command data received after the command trigger to be output on a display of the selected display device."
Smart controlling device and method of controlling therefor,https://lens.org/115-556-938-763-089,2022,"The present specification relates to a smart controlling device capable of utilizing machine learning for voice recognition and a method of controlling therefor. The smart controlling device according to the present invention includes a receiver configured to receive an input including a command trigger, and a controller configured to detect one or more external display devices, select a display device of the detected one or more external display devices, cause a power status of the selected display device to be changed to a first state, and cause a response data corresponding to a first command data received after the command trigger to be output on a display of the selected display device."
Smart controlling device and method of controlling therefor,https://lens.org/071-663-294-055-341,2022,"The present specification relates to a smart controlling device capable of utilizing machine learning for voice recognition and a method of controlling therefor. The smart controlling device according to the present invention includes a receiver configured to receive an input including a command trigger, and a controller configured to detect one or more external display devices, select a display device of the detected one or more external display devices, cause a power status of the selected display device to be changed to a first state, and cause a response data corresponding to a first command data received after the command trigger to be output on a display of the selected display device."
Smart controlling device and method of controlling therefor,https://lens.org/071-663-294-055-341,2022,"The present specification relates to a smart controlling device capable of utilizing machine learning for voice recognition and a method of controlling therefor. The smart controlling device according to the present invention includes a receiver configured to receive an input including a command trigger, and a controller configured to detect one or more external display devices, select a display device of the detected one or more external display devices, cause a power status of the selected display device to be changed to a first state, and cause a response data corresponding to a first command data received after the command trigger to be output on a display of the selected display device."
SMART CONTROLLING DEVICE AND METHOD OF CONTROLLING THEREFOR,https://lens.org/018-858-451-892-927,2018,"The present specification relates to a smart controlling device capable of utilizing machine learning for voice recognition and a method of controlling therefor. The smart controlling device according to the present invention includes a receiver configured to receive an input including a command trigger, and a controller configured to detect one or more external display devices, select a display device of the detected one or more external display devices, cause a power status of the selected display device to be changed to a first state, and cause a response data corresponding to a first command data received after the command trigger to be output on a display of the selected display device."
Smart controlling device and method of controlling therefor,https://lens.org/115-556-938-763-089,2022,"The present specification relates to a smart controlling device capable of utilizing machine learning for voice recognition and a method of controlling therefor. The smart controlling device according to the present invention includes a receiver configured to receive an input including a command trigger, and a controller configured to detect one or more external display devices, select a display device of the detected one or more external display devices, cause a power status of the selected display device to be changed to a first state, and cause a response data corresponding to a first command data received after the command trigger to be output on a display of the selected display device."
SMART CONTROLLING DEVICE AND METHOD OF CONTROLLING THEREFOR,https://lens.org/182-838-828-168-962,2020,"The present specification relates to a smart controlling device capable of utilizing machine learning for voice recognition and a method of controlling therefor. The smart controlling device according to the present invention includes a receiver configured to receive an input including a command trigger, and a controller configured to detect one or more external display devices, select a display device of the detected one or more external display devices, cause a power status of the selected display device to be changed to a first state, and cause a response data corresponding to a first command data received after the command trigger to be output on a display of the selected display device."
DRONE,https://lens.org/083-575-145-775-72X,2019,"An assembly comprising a drone (1) and at least one releasable load (37) mounted on the drone, the drone comprising an on-board data processing system, the releasable load (37) comprising at least one sensor delivering a piece of information that can be used to ascertain the path of same and actuators for controlling flight control surfaces allowing it to be oriented as it falls, being linked to the drone (1) by an optical fibre (70), the load and the drone being arranged to exchange information via the optical fibre while the load is falling, the load transmitting data originating from said at least one sensor and the drone transmitting data for controlling the actuators, established taking into account that received from the load, in order to guide the load towards a predefined target."
DRONE WITH WIDE FRONTAL FIELD OF VIEW,https://lens.org/075-797-188-421-722,2021,A drone includes a frame and a plurality of motors attached to the frame. Each motor of the plurality of motors is connected to a respective propeller located below the frame. A tail motor is attached to the frame. The tail motor is connected to a tail propeller located above the frame. Cameras are attached to the frame and located above the frame. The cameras have fields of view extending over the plurality of propellers.
Drone with wide frontal field of view,https://lens.org/125-740-790-108-426,2022,A drone includes a frame and a plurality of motors attached to the frame. Each motor of the plurality of motors is connected to a respective propeller located below the frame. A tail motor is attached to the frame. The tail motor is connected to a tail propeller located above the frame. Cameras are attached to the frame and located above the frame. The cameras have fields of view extending over the plurality of propellers.
Remote control device,https://lens.org/150-600-461-593-821,2019,"A remote control device for an unmanned helicopter includes an orientation sensor that detects a flight orientation of the unmanned helicopter, a GPS antenna and a GPS receiver that detect speed information of the unmanned helicopter, and a CPU that detects a flight distance of the unmanned helicopter by integrating the speed information. A memory stores information concerning a base point of the unmanned helicopter. Based on a flight orientation of the unmanned helicopter and a flight distance of the unmanned helicopter, which is obtained by integration of the speed information, the CPU determines a relative position, which indicates a position of the unmanned helicopter with respect to the base point, and controls the flight of unmanned helicopter based on the relative position."
REMOTE CONTROL DEVICE,https://lens.org/117-738-184-344-581,2017,"A remote control device for an unmanned helicopter includes an orientation sensor that detects a flight orientation of the unmanned helicopter, a GPS antenna and a GPS receiver that detect speed information of the unmanned helicopter, and a CPU that detects a flight distance of the unmanned helicopter by integrating the speed information. A memory stores information concerning a base point of the unmanned helicopter. Based on a flight orientation of the unmanned helicopter and a flight distance of the unmanned helicopter, which is obtained by integration of the speed information, the CPU determines a relative position, which indicates a position of the unmanned helicopter with respect to the base point, and controls the flight of unmanned helicopter based on the relative position."
Natural language control of secondary device,https://lens.org/013-732-088-455-793,2017,"Natural language controlled devices may be configured to activate command recognition in response to one or more wake words. Techniques are provided to enable a voice controlled system to detect or receive an indication of a secondary device available to be controlled. The voice controlled system communicates with the secondary device to obtain information related to the secondary device. The voice controlled system may output of an audio query requesting audio input data related to controlling the secondary device from a user and generate, based on the requested audio input data, recognition data utilized to recognize of at least part of one or more commands to issue one or more controls to the secondary device."
Natural Language Control of Secondary Device,https://lens.org/193-980-812-726-604,2015,"Natural language controlled devices may be configured to activate command recognition in response to one or more wake words. Techniques are provided to enable a voice controlled system to detect or receive an indication of a secondary device available to be controlled. The voice controlled system communicates with the secondary device to obtain information related to the secondary device. The voice controlled system may output of an audio query requesting audio input data related to controlling the secondary device from a user and generate, based on the requested audio input data, recognition data utilized to recognize of at least part of one or more commands to issue one or more controls to the secondary device."
NATURAL LANGUAGE CONTROL OF SECONDARY DEVICE,https://lens.org/003-190-245-055-579,2015,"Natural language controlled devices may be configured to activate command recognition in response to one or more wake words. Techniques are provided to enable a voice controlled system to detect or receive an indication of a secondary device available to be controlled. The voice controlled system communicates with the secondary device to obtain information related to the secondary device. The voice controlled system may output of an audio query requesting audio input data related to controlling the secondary device from a user and generate, based on the requested audio input data, recognition data utilized to recognize of at least part of one or more commands to issue one or more controls to the secondary device."
MANAGEMENT APP FOR DRONE WITH REMOTE ID,https://lens.org/059-840-174-066-580,2022,"A global positioning satellite (GPS) receiver and a transmitter are at a base remote from a drone, and the transmitter sends GPS packets along with control packets to the drone. In turn, the drone also has a GPS receiver and a transmitter that transmits both the controller and drone GPS coordinates to the remote base. A management app for law enforcement is provided."
MANAGEMENT APP FOR DRONE WITH REMOTE ID,https://lens.org/059-840-174-066-580,2022,"A global positioning satellite (GPS) receiver and a transmitter are at a base remote from a drone, and the transmitter sends GPS packets along with control packets to the drone. In turn, the drone also has a GPS receiver and a transmitter that transmits both the controller and drone GPS coordinates to the remote base. A management app for law enforcement is provided."
FOLLOWING METHOD AND DEVICE FOR UNMANNED AERIAL VEHICLE AND WEARABLE DEVICE,https://lens.org/172-839-206-195-87X,2019,"A following method and device for an unmanned aerial vehicle and a wearable device are provided. The following method comprises: installing a plurality of receiving sensors on the unmanned aerial vehicle, wherein the plurality of receiving sensors match with one transmitting sensor in a smart control device at the user side; receiving a distance signal transmitted by the user in real time by using the receiving sensors, and calculating a relative position of the unmanned aerial vehicle with respect to the user according to the distance signal; and adjusting the horizontal position of the unmanned aerial vehicle according to the relative position, so that the relative position of the unmanned aerial vehicle with respect to the user agrees with a preset position, to realize automatic following of the unmanned aerial vehicle."
Following method and device for unmanned aerial vehicle and wearable device,https://lens.org/009-155-332-964-695,2020,"A following method and device for an unmanned aerial vehicle and a wearable device are provided. The following method comprises: installing a plurality of receiving sensors on the unmanned aerial vehicle, wherein the plurality of receiving sensors match with one transmitting sensor in a smart control device at the user side; receiving a distance signal transmitted by the user in real time by using the receiving sensors, and calculating a relative position of the unmanned aerial vehicle with respect to the user according to the distance signal; and adjusting the horizontal position of the unmanned aerial vehicle according to the relative position, so that the relative position of the unmanned aerial vehicle with respect to the user agrees with a preset position, to realize automatic following of the unmanned aerial vehicle."
FLYING DRONE AND METHOD FOR CONTROLLING THE SAME,https://lens.org/109-543-444-262-487,2015,"A flying drone comprises:  a memory (16) for storing a forecasted flying trajectory, said trajectory being defined by a list (26) of 3D coordinates points and comprising a main trajectory and at least one alternative trajectory, said main and alternative trajectories being each defined by a sublist of 3D coordinates points;  a control and command computer (18) for driving drone directional and motorization means, said control and command computer (18) being connected to the memory (16) for reading the forecasted trajectory so that the flying drone is able to move along said forecasted trajectory, said control and command computer (18) being adapted to read said alternative trajectory in the memory (16) so that the flying drone is able to move along said alternative trajectory only if at least one predetermined condition is verified."
DRONE SOUND BEAM,https://lens.org/192-373-926-066-850,2022,"A drone includes a motor, a noise receiver, a camera, a distance measure, and a directed sound beam generator. The noise receiver is configured to detect a noise caused by the motor. The camera is configured to capture an image of an area when the drone is in the air. The distance measure is configured to measure a distance between the drone and a particular point in the captured image. The directed sound beam generator is configured to emit a sound beam that is directed to a particular direction. The drone further includes a processor configured to analyze the detected noise to determine a frequency spectrum of the detected noise. The processor is further configured to analyze the captured image to identify a target, and cause the directed sound beam generator to emit a sound beam to actively cancel at least a portion of the noise directed to the target."
DRONE SOUND BEAM,https://lens.org/192-373-926-066-850,2022,"A drone includes a motor, a noise receiver, a camera, a distance measure, and a directed sound beam generator. The noise receiver is configured to detect a noise caused by the motor. The camera is configured to capture an image of an area when the drone is in the air. The distance measure is configured to measure a distance between the drone and a particular point in the captured image. The directed sound beam generator is configured to emit a sound beam that is directed to a particular direction. The drone further includes a processor configured to analyze the detected noise to determine a frequency spectrum of the detected noise. The processor is further configured to analyze the captured image to identify a target, and cause the directed sound beam generator to emit a sound beam to actively cancel at least a portion of the noise directed to the target."
DRONE WITH AN OBSTACLE AVOIDING SYSTEM,https://lens.org/078-397-509-254-07X,2018,"A rotary-wing drone includes a drone body including an electronic card controlling the piloting of the drone and one or more linking arms, one or more propulsion units mounted on respective ones of the linking arms, and at least one obstacle sensor integral with the drone body, whose main direction of detection is located in a substantially horizontal plane. The drone additionally includes logic executing by a processor in the electronic card and adapted to perform the controlling by correcting the drone orientationspecifically the yaw orientationof the drone in flight so as to maintain one of the at least one obstacle sensor in the direction of displacement of the drone."
AUDIO PLAYBACK DEVICE AND VOICE CONTROL METHOD THEREOF,https://lens.org/087-821-930-497-16X,2019,"An audio playback device comprises: a microphone component configured to collect sound from outside and process the sound into an audio signal; a communication component configured to establish a communication connection with a separate device for communication; a memory configured to store a smart voice library containing a plurality of control command texts; and a main controller configured to perform voice recognition on the audio signal from the microphone component to generate voice text information, to perform matching between the voice text information and the plurality of control command texts in the smart voice library, and in response to the voice text information being successfully matched with one of the plurality of control command texts in the smart voice library, to execute a control command corresponding to the control command text, or control the communication component to transmit the control command to the separate device so as to control the separate device."
TACTICAL UNMANNED AERIAL VEHICLE,https://lens.org/035-652-012-797-058,2022,"An unmanned vehicle is disclosed. The unmanned vehicle includes an aerial platform, a piloting system supported by the aerial platform, a medium source supported by the aerial platform, and a control system having a processor running computer executable code that actuates the medium source to emit a medium away from the aerial vehicle with an intensity sufficient to disorient a subject when the medium interacts with an exteroceptive sense of a subject."
TACTICAL UNMANNED AERIAL VEHICLE,https://lens.org/035-652-012-797-058,2022,"An unmanned vehicle is disclosed. The unmanned vehicle includes an aerial platform, a piloting system supported by the aerial platform, a medium source supported by the aerial platform, and a control system having a processor running computer executable code that actuates the medium source to emit a medium away from the aerial vehicle with an intensity sufficient to disorient a subject when the medium interacts with an exteroceptive sense of a subject."
Inverted Drone,https://lens.org/026-419-176-429-73X,2017,"A rotorcraft in which lift and thrust can be supplied by rotors, and specifically a drone comprising a camera that is used for making optical and/or sound recordings, especially during (live) events, such as concerts, gatherings, dance events, etc. The camera gives an impression of the events and is capable of recording specific details thereof, such as individual people."
"Device for launching and recovering a drone, and an associated aircraft",https://lens.org/100-663-760-230-128,2014,A device for launching and recovering a drone for being fastened to an aircraft is provided. The device includes a docking plate for a drone provided with a securing/releasing mechanism for the drone. The docking plate being secured to a flared guide for guiding the drone towards the docking plate.
SYSTEM AND METHOD FOR AUTONOMOUS REMOTE DRONE CONTROL,https://lens.org/046-227-990-085-82X,2019,"Methods and systems for establishing a daisy-chain connection with autonomous remote pilots are provided. An example method can include: under control of a computing device configured with executable instructions: generating a mission instruction for a drone to navigate from an original location to a destination along the flight route; instructing the drone with the mission instruction to navigate to the destination; generating, based on a pre-defined criteria, a first verification code based on the mission instruction; broadcasting the first verification code with the mission instruction to a plurality of remote pilots; selecting a first pilot from the plurality of the remote pilots; verifying the first verification code provided by the first pilot to authorize the first pilot to monitor, control, or backup the drone along the flight route; and generating a second verification code based on the mission instruction"
SYSTEM AND METHOD FOR AUTONOMOUS REMOTE DRONE CONTROL,https://lens.org/090-823-621-331-358,2020,"Methods and systems for establishing a daisy-chain connection with autonomous remote pilots are provided. An example method can include: under control of a computing device configured with executable instructions: generating a mission instruction for a drone to navigate from an original location to a destination along the flight route; instructing the drone with the mission instruction to navigate to the destination; generating, based on a pre-defined criteria, a first verification code based on the mission instruction; broadcasting the first verification code with the mission instruction to a plurality of remote pilots; selecting a first pilot from the plurality of the remote pilots; verifying the first verification code provided by the first pilot to authorize the first pilot to monitor, control, or backup the drone along the flight route; and generating a second verification code based on the mission instruction"
Drone system and method of capturing image of vehicle by drone,https://lens.org/164-527-846-439-622,2022,"A controller of a drone includes a storage unit that stores a scene information database containing a plurality of scene information sets arranged in time series of a video, in each of the scene information sets, a relative position with respect to a vehicle in capturing a scene of the video and a duration of the scene are associated with each other, a vehicle information acquisition unit that receives vehicle information from the vehicle, a traveling position estimation unit that estimates a future traveling position of the vehicle based on the vehicle information, and a flight path calculation unit that, based on the estimated traveling position and the scene information database, calculates, for each of the scenes, a flight path that passes through the relative position with respect to the vehicle."
Drone system and method of capturing image of vehicle by drone,https://lens.org/164-527-846-439-622,2022,"A controller of a drone includes a storage unit that stores a scene information database containing a plurality of scene information sets arranged in time series of a video, in each of the scene information sets, a relative position with respect to a vehicle in capturing a scene of the video and a duration of the scene are associated with each other, a vehicle information acquisition unit that receives vehicle information from the vehicle, a traveling position estimation unit that estimates a future traveling position of the vehicle based on the vehicle information, and a flight path calculation unit that, based on the estimated traveling position and the scene information database, calculates, for each of the scenes, a flight path that passes through the relative position with respect to the vehicle."
DRONE SYSTEM AND METHOD OF CAPTURING IMAGE OF VEHICLE BY DRONE,https://lens.org/092-784-800-149-467,2021,"A controller of a drone includes a storage unit that stores a scene information database containing a plurality of scene information sets arranged in time series of a video, in each of the scene information sets, a relative position with respect to a vehicle in capturing a scene of the video and a duration of the scene are associated with each other, a vehicle information acquisition unit that receives vehicle information from the vehicle, a traveling position estimation unit that estimates a future traveling position of the vehicle based on the vehicle information, and a flight path calculation unit that, based on the estimated traveling position and the scene information database, calculates, for each of the scenes, a flight path that passes through the relative position with respect to the vehicle."
Remote object capture,https://lens.org/137-073-916-511-173,2022,"A drone swarm (100) including a set of drones configured to include a network for providing communication throughout the system, where sensing drones include a node to detect a remote object (180) and determine a location of the remote object. The sensing drones may move in a geometric pattern, where the nodes on two sensing drones are configured to detect signals that are emitted from the remote object, and two of the sensing drones are may be configured to use frequency doppler shift detection to determine a velocity of the remote object. Entanglement drones may be configured to carry an entanglement device i.e. net"
Model aircraft with altitude change indicating means,https://lens.org/026-567-034-640-550,1980,"A model aircraft with wireless earth-to-craft control. A device is aboard to emit signals indicating altitude change and visible by the operator on earth, this device being triggered operatively by signals produced by an air-pressure transducer of small size and having low inertia of movable parts."
"INDOOR MAPPING AND MODULAR CONTROL FOR UAVS AND OTHER AUTONOMOUS VEHICLES, AND ASSOCIATED SYSTEMS AND METHODS",https://lens.org/034-428-098-033-493,2018,"Indoor mapping and modular control for UAVs and other autonomous vehicles, and associated systems and methods. A representative unmanned aerial vehicle system includes a body, a propulsion system carried by the body, a sensor system carried by the body, and a controller carried at least in part by the body and operatively coupled to the propulsion system and the sensor system. The controller is programmed with instructions that, when executed, operate in a first autonomous mode and a second autonomous mode. In the first autonomous mode, the instructions autonomously direct the propulsion system to convey the body along a first route within an indoor environment. While the body travels along the first route, the instructions receive inputs from the sensor system corresponding to features of the indoor environment. The features are stored as part of a 3-D map. In the second autonomous mode, the instructions direct the propulsion system to convey the body along a second route within the indoor environment, based at least in part on the 3-D map, and direct performance of an operation on the second route."
"INDOOR MAPPING AND MODULAR CONTROL FOR UAVS AND OTHER AUTONOMOUS VEHICLES, AND ASSOCIATED SYSTEMS AND METHODS",https://lens.org/146-527-018-847-556,2018,"Indoor mapping and modular control for UAVs and other autonomous vehicles, and associated systems and methods. A representative unmanned aerial vehicle system includes a body, a propulsion system carried by the body, a sensor system carried by the body, and a controller carried at least in part by the body and operatively coupled to the propulsion system and the sensor system. The controller is programmed with instructions that, when executed, operate in a first autonomous mode and a second autonomous mode. In the first autonomous mode, the instructions autonomously direct the propulsion system to convey the body along a first route within an indoor environment. While the body travels along the first route, the instructions receive inputs from the sensor system corresponding to features of the indoor environment. The features are stored as part of a 3-D map. In the second autonomous mode, the instructions direct the propulsion system to convey the body along a second route within the indoor environment, based at least in part on the 3-D map, and direct performance of an operation on the second route."
"INDOOR MAPPING AND MODULAR CONTROL FOR UAVS AND OTHER AUTONOMOUS VEHICLES, AND ASSOCIATED SYSTEMS AND METHODS",https://lens.org/196-698-198-521-210,2021,"Indoor mapping and modular control for UAVs and other autonomous vehicles, and associated systems and methods. A representative unmanned aerial vehicle system includes a body, a propulsion system carried by the body, a sensor system carried by the body, and a controller carried at least in part by the body and operatively coupled to the propulsion system and the sensor system. The controller is programmed with instructions that, when executed, operate in a first autonomous mode and a second autonomous mode. In the first autonomous mode, the instructions autonomously direct the propulsion system to convey the body along a first route within an indoor environment. While the body travels along the first route, the instructions receive inputs from the sensor system corresponding to features of the indoor environment. The features are stored as part of a 3-D map. In the second autonomous mode, the instructions direct the propulsion system to convey the body along a second route within the indoor environment, based at least in part on the 3-D map, and direct performance of an operation on the second route."
Drones with Self-Generating Function,https://lens.org/049-133-003-493-363,2019,"A drone with its own power generating function is introduced. The drone includes a central body, a battery attached to the bottom of the central body, multiple arms extended from the central body radially, drive rotors to be fitted on the top of the arms, a ring-shaped subsidiary guide positioned below the arms and supported by the multiple arms and multiple 1st generators arranged in parallel to the drive rotors on the subsidiary guide"
AUTONOMOUS DATA DELIVERY AND RETRIEVAL SYSTEM,https://lens.org/166-698-414-899-325,2019,"An automated error monitoring system for intelligent appliances includes an unmanned drone having at least one of a short range wireless communication system and a physical data connection. The unmanned drone further includes a memory and a processor, with the memory storing instructions for causing the unmanned drone to move into a short range communication zone of an intelligent appliance, establish a data connection between the unmanned drone and the intelligent appliance, and perform a data transfer between the unmanned drone and the intelligent appliance."
UNMANNED AERIAL VEHICLE UPDATER,https://lens.org/132-667-618-871-740,2022,"Various arrangements for communicating with a device utilizing an unmanned aerial vehicle (UAV) are presented. A backend system may detect a triggering event associated with a device based upon data received via a first connection. In response to detecting the first triggering event, the UAV may receive a first data set and a location associated with the device from the backend system. The UAV may deploy to the received location. A second connection between the UAV and the device can be established at the received location. The UAV may transmit the first data set to the device via the second connection at the received location."
MOBILE TERMINAL AND METHOD OF CONTROLLING SAME,https://lens.org/126-712-431-670-95X,2018,"The present invention relates to a mobile terminal that is wirelessly connected to a master drone which images an outdoor environment including a plurality of slave drones having cameras. The mobile terminal includes: a wireless receiver for receiving control screen information comprised of the image of the outdoor environment; a display for outputting the control screen information; and a controller for transmitting a control command, for controlling a target slave drone selected from the plurality of slave drones on the basis of a touch applied on the control screen information, to the master drone. A preview image captured by the target slave drone based on the control command is output on the display."
DUCKING AND ERASING AUDIO FROM NEARBY DEVICES,https://lens.org/183-447-428-335-424,2023,"A smart home device (e.g., a voice assistant device) includes an audio control system that determines a set of one or more audio devices to include nearby devices that are capable of providing audio streams that are audibly detected by a microphone of the smart home device. The audio control system initiates a voice-interaction mode for operating the smart home device to receive voice commands from a user and provide audio output in response to the voice commands. The audio control system transmits an audio control signal to nearby devices that configures each nearby device to implement one or more of: reducing a volume level associated with the audio streams generated by the nearby devices while the smart home device is operating in the voice-interaction mode; and transmitting, to the smart home device, audio stream data associated with a current audio stream generated for audible output by the nearby device."
Ducking and erasing audio from nearby devices,https://lens.org/055-733-715-370-966,2022,"A smart home device (e.g., a voice assistant device) includes an audio control system that determines a set of one or more audio devices to include nearby devices that are capable of providing audio streams that are audibly detected by a microphone of the smart home device. The audio control system initiates a voice-interaction mode for operating the smart home device to receive voice commands from a user and provide audio output in response to the voice commands. The audio control system transmits an audio control signal to nearby devices that configures each nearby device to implement one or more of: reducing a volume level associated with the audio streams generated by the nearby devices while the smart home device is operating in the voice-interaction mode; and transmitting, to the smart home device, audio stream data associated with a current audio stream generated for audible output by the nearby device."
Ducking and erasing audio from nearby devices,https://lens.org/055-733-715-370-966,2022,"A smart home device (e.g., a voice assistant device) includes an audio control system that determines a set of one or more audio devices to include nearby devices that are capable of providing audio streams that are audibly detected by a microphone of the smart home device. The audio control system initiates a voice-interaction mode for operating the smart home device to receive voice commands from a user and provide audio output in response to the voice commands. The audio control system transmits an audio control signal to nearby devices that configures each nearby device to implement one or more of: reducing a volume level associated with the audio streams generated by the nearby devices while the smart home device is operating in the voice-interaction mode; and transmitting, to the smart home device, audio stream data associated with a current audio stream generated for audible output by the nearby device."
DUCKING AND ERASING AUDIO FROM NEARBY DEVICES,https://lens.org/101-098-981-059-982,2021,"A smart home device (e.g., a voice assistant device) includes an audio control system that determines a set of one or more audio devices to include nearby devices that are capable of providing audio streams that are audibly detected by a microphone of the smart home device. The audio control system initiates a voice-interaction mode for operating the smart home device to receive voice commands from a user and provide audio output in response to the voice commands. The audio control system transmits an audio control signal to nearby devices that configures each nearby device to implement one or more of: reducing a volume level associated with the audio streams generated by the nearby devices while the smart home device is operating in the voice-interaction mode; and transmitting, to the smart home device, audio stream data associated with a current audio stream generated for audible output by the nearby device."
DUCKING AND ERASING AUDIO FROM NEARBY DEVICES,https://lens.org/157-417-352-046-086,2019,"A smart home device (e.g., a voice assistant device) includes an audio control system that determines a set of one or more audio devices to include nearby devices that are capable of providing audio streams that are audibly detected by a microphone of the smart home device. The audio control system initiates a voice-interaction mode for operating the smart home device to receive voice commands from a user and provide audio output in response to the voice commands. The audio control system transmits an audio control signal to nearby devices that configures each nearby device to implement one or more of: reducing a volume level associated with the audio streams generated by the nearby devices while the smart home device is operating in the voice-interaction mode; and transmitting, to the smart home device, audio stream data associated with a current audio stream generated for audible output by the nearby device."
Ducking and erasing audio from nearby devices,https://lens.org/007-469-867-170-655,2021,"A smart home device (e.g., a voice assistant device) includes an audio control system that determines a set of one or more audio devices to include nearby devices that are capable of providing audio streams that are audibly detected by a microphone of the smart home device. The audio control system initiates a voice-interaction mode for operating the smart home device to receive voice commands from a user and provide audio output in response to the voice commands. The audio control system transmits an audio control signal to nearby devices that configures each nearby device to implement one or more of: reducing a volume level associated with the audio streams generated by the nearby devices while the smart home device is operating in the voice-interaction mode; and transmitting, to the smart home device, audio stream data associated with a current audio stream generated for audible output by the nearby device."
UAV controller device,https://lens.org/105-247-280-851-821,2021,"An UAV controller device is provided. In some embodiments, the device may include a control panel having one or more user control inputs, and a processing unit may be in communication with the control inputs. A display screen may also be in communication with the processing unit. Optionally, the display screen may be movable between an open and a closed position. A side wall may be coupled to a proximal wall and to a distal wall, the side wall, proximal wall, and distal wall forming a storage compartment. The storage compartment may have a storage cavity for removably receiving a UAV, and the UAV may be in wireless communication with the processing unit. A camera, for recording video, may be coupled to the UAV. Video recorded by the camera may be displayed on the display screen, and one or more of the control inputs may govern movement of the UAV."
DRONE-BASED GOODS TRANSPORTATION,https://lens.org/179-287-899-738-030,2020,"A container includes a transportation section and a drone section. The drone section has a drone place holder and a door. The drone place holder is accessible when the door is in an open position. The container includes a processor that is programmed to actuate the door to the open position, actuate a drone, fittable in the drone place holder, to fly out of the container, and actuate the drone to transport the container to a destination."
DRONE-BASED GOODS TRANSPORTATION,https://lens.org/065-789-400-786-647,2018,"A container includes a transportation section and a drone section. The drone section has a drone place holder and a door. The drone place holder is accessible when the door is in an open position. The container includes a processor that is programmed to actuate the door to the open position, actuate a drone, fittable in the drone place holder, to fly out of the container, and actuate the drone to transport the container to a destination."
Drone-based goods transportation,https://lens.org/181-468-108-935-113,2022,"A container includes a transportation section and a drone section. The drone section has a drone place holder and a door. The drone place holder is accessible when the door is in an open position. The container includes a processor that is programmed to actuate the door to the open position, actuate a drone, fittable in the drone place holder, to fly out of the container, and actuate the drone to transport the container to a destination."
DRONE-BASED GOODS TRANSPORTATION,https://lens.org/183-628-947-889-093,2018,"A container includes a transportation section and a drone section. The drone section has a drone place holder and a door. The drone place holder is accessible when the door is in an open position. The container includes a processor that is programmed to actuate the door to the open position, actuate a drone, fittable in the drone place holder, to fly out of the container, and actuate the drone to transport the container to a destination."
Drone-based goods transportation,https://lens.org/181-468-108-935-113,2022,"A container includes a transportation section and a drone section. The drone section has a drone place holder and a door. The drone place holder is accessible when the door is in an open position. The container includes a processor that is programmed to actuate the door to the open position, actuate a drone, fittable in the drone place holder, to fly out of the container, and actuate the drone to transport the container to a destination."
MOBILE TERMINAL AND CONTROLLING METHOD THEREOF,https://lens.org/128-932-345-140-490,2016,"A mobile terminal and controlling method thereof are disclosed, by which a flying object equipped with a camera can be remotely controlled. The present disclosure includes a wireless communication unit configured to perform a communication with a flying object, a touchscreen configured to output a preview image received from the flying object, and a controller outputting a shot mode list on the preview image, the controller, if at least one shot mode is selected from the shot mode list, remotely controlling a flight location of the flying object in accordance with the selected at least one shot mode."
MOBILE TERMINAL AND CONTROLLING METHOD THEREOF,https://lens.org/132-534-480-896-62X,2018,"A mobile terminal and controlling method thereof are disclosed, by which a flying object equipped with a camera can be remotely controlled. The present disclosure includes a wireless communication unit configured to perform a communication with a flying object, a touchscreen configured to output a preview image received from the flying object, and a controller outputting a shot mode list on the preview image, the controller, if at least one shot mode is selected from the shot mode list, remotely controlling a flight location of the flying object in accordance with the selected at least one shot mode."
Drone-based insect sample-collection system and the method thereof,https://lens.org/089-302-529-189-652,2020,"A drone-based insect sample-collection system is disclosed, comprising a drone, a flight-control module and a sample-collection module. The flight-control module comprises a communication unit to transmit or receive signal to/from a user and a control unit to control the route of flight and collection site for the drone. The sample-collection module comprises a container, a gate-controlling unit, a chemicals-releasing unit and an optical-sensing unit. The container is provided with a gate which is controlled by the gate-controlling unit. The chemicals-releasing unit releases one or multiple chemicals to attract insects into the container. The optical-sensing unit is provided in the container and generates different signal according to the sensed light intensity. As the amount of the insect inside the container increases to gradually block the light intensity that the optical-sensing unit could sense, the signal generated by the optical-sensing unit is varied and transmitted to the gate-controlling unit."
ELECTRONIC DEVICE AND METHOD FOR CONTROLLING THE ELECTRONIC DEVICE THEREOF,https://lens.org/099-235-103-503-486,2021,"An electronic device and a method for controlling the electronic device are disclosed. The method includes receiving a trigger speech of a user; entering a speech recognition mode to recognize a speech command of the user in response, and transmitting information to enter the speech recognition mode to at least one external device located at home. Further, the method includes obtaining a first speech information corresponding to a speech uttered by a user from a microphone included in the electronic device and receiving at least one second speech information corresponding to a speech uttered by the user from the at least one external device; identifying a task corresponding to a speech uttered by the user and an external device to perform the task based on the first speech information and the at least one second speech information; and transmitting, to the identified external device, information about the task."
METHOD FOR OPTIMIZING THE ORIENTATION OF A REMOTE-CONTROL DEVICE WITH RESPECT TO A ROLLING DRONE,https://lens.org/079-553-947-208-880,2016,"The remote-control device (16) comprises an antenna for the radio link with the drone, and a touch screen (20) displaying an image captured by the camera of the drone. The method comprises the steps of: a) determination of the active antenna (28b); b) determination of the device model used; c) search, in a table of an applicative piloting software, for information of relative orientation with respect to the active antenna with respect to the device body; d) display of the image on the touch screen so that the top of a scene captured by the camera of the drone appears (A) to the user at the bottom of the screen (20) if the orientation of the antenna with respect to the device body does not correspond to the direction (D) of the drone, and appears (B) to the user at the top of the screen (20) if the orientation of the antenna with respect to the device body corresponds to the direction (D) of the drone, so as to produce an anti-natural display (A) leading the user to return the device (A), hence placing the antenna in the direction (D) of the drone."
UNMANNED AERIAL VEHICLE-MOUNTED APPARATUS,https://lens.org/074-808-062-113-171,2019,"A device can include an unmanned aerial vehicle (UAV) frame physically connected to a UAV, two or more support arms connected to and extending from the frame, a first servomotor coupled to a first support arm and providing rotatable movement of the first support arm in a first plane; a second servomotor coupled to a second support arm and providing rotatable movement of the second support arm in a second plane, a second frame connected to the support arms, and an end effector connected to the second frame."
Unmanned aerial vehicle-mounted apparatus,https://lens.org/080-765-279-579-319,2021,"A device can include an unmanned aerial vehicle (UAV) frame physically connected to a UAV, two or more support arms connected to and extending from the frame, a first servomotor coupled to a first support arm and providing rotatable movement of the first support arm in a first plane; a second servomotor coupled to a second support arm and providing rotatable movement of the second support arm in a second plane, a second frame connected to the support arms, and an end effector connected to the second frame."
A STABILIZED DRONE,https://lens.org/121-783-578-508-515,2022,"A stabilized drone, comprising a drone comprising a drone body, landing skids, propulsion and flight control means for enabling the basic flight operations, wherein the drone further comprises, suitable control, navigation and communication hardware and software for being operated remotely and autonomously; one or more terrain shape detection means, for acquiring the terrain shape at an intended landing site; one or more stabilizers adapted to extend to a desired extent and to support the stabilized drone on the ground. The stabilized drone further comprises suitable control hardware and software for operating the terrain shape detection means while approaching a desired landing site and for correspondingly activating the one or more stabilization means, thereby enabling the stabilized drone to stably land on various terrain types and to withstand dynamic loads induced by dynamic operations thereon."
A STABILIZED DRONE,https://lens.org/121-783-578-508-515,2022,"A stabilized drone, comprising a drone comprising a drone body, landing skids, propulsion and flight control means for enabling the basic flight operations, wherein the drone further comprises, suitable control, navigation and communication hardware and software for being operated remotely and autonomously; one or more terrain shape detection means, for acquiring the terrain shape at an intended landing site; one or more stabilizers adapted to extend to a desired extent and to support the stabilized drone on the ground. The stabilized drone further comprises suitable control hardware and software for operating the terrain shape detection means while approaching a desired landing site and for correspondingly activating the one or more stabilization means, thereby enabling the stabilized drone to stably land on various terrain types and to withstand dynamic loads induced by dynamic operations thereon."
DRONE WAYPOINT NAVIGATION SYSTEM,https://lens.org/044-024-802-912-611,2020,"A method of navigating a drone from a first waypoint to a second waypoint includes providing a detection system coupled to the drone, operating the detection system to detect a bearing and distance from a current position of the drone to an obstacle, operating the drone in a go to goal state in response to not detecting the obstacle on a bearing between the current position and the second waypoint within a predefined first distance, wherein the drone travels on a direct path from the current position toward the second waypoint, and operating the drone in a divert state in response to detecting the obstacle on the bearing between the current position and the second waypoint within the predefined first distance, wherein the detection system analyzes potential paths to a left side and a right side of the obstacle and selects a desired divert path for continued travel."
VEHICLE CONTROLS FOR AUTONOMOUS VEHICLES,https://lens.org/167-771-511-130-213,2020,"Methods and apparatus are provided for controlling an autonomous vehicle. The control device includes an interface that establishes a connection to an autonomous vehicle, a processor that processes inputs and generates control commands to control at least one function of the autonomous vehicle, and an input arrangement with at least one control element that is assigned to a function of the autonomous vehicle. The control device transitions a controller of the autonomous vehicle to operate in at least one of a first remote operation mode and a second remote operation mode in which the autonomous vehicle is controlled by the control device, when the control device is connected to the autonomous vehicle via the interface. At least one function of a scope of functions of the autonomous vehicle is restricted in the first remote operation mode and the second remote operation mode."
TAIL TRACKING ANTENNA,https://lens.org/175-358-295-248-268,2019,"An unmanned aerial vehicle (UAV) and a system of communication between an unmanned aerial vehicle with a ground controller, the UAV having a top side, a bottom side, and an antenna side. The antenna side of the UAV can have a hinge to which a flat panel antenna can be disposed is pivotably coupled. The flat panel antenna can be actively controlled or passively controlled by gravity."
Tail tracking antenna,https://lens.org/103-696-884-978-840,2019,"An unmanned aerial vehicle (UAV) and a system of communication between an unmanned aerial vehicle with a ground controller, the UAV having a top side, a bottom side, and an antenna side. The antenna side of the UAV can have a hinge to which a flat panel antenna can be disposed is pivotably coupled. The flat panel antenna can be actively controlled or passively controlled by gravity."
WIRED DRONE GROUP,https://lens.org/103-826-469-258-806,2019,"The present invention relates to a drone which is an unmanned mobile which can move in the air or in the water or in both areas, and a wired drone group having a plurality of drones. The wired drone group includes a plurality of drones (1) coupled in series by a wired cable (2) having a function for performing power feeding to the respective drones and/or communication with the respective drones (1), and a controller (3) connected to the drone (1) at one end side of the drone group and configured to control movement of the drone group."
Methods and apparatus for remotely processing locally generated commands to control a local device,https://lens.org/167-076-123-318-308,2009,A technique for remotely processing a local audio command to control a local device includes: receiving at a local site an acoustic signal and generating a corresponding audio signal; transmitting the audio signal to a remote site; performing speech recognition processing on the audio signal at the remote site to determine whether the audio signal includes a command; performing voice recognition processing on the audio signal at the remote site to determine whether the audio signal has been supplied by an authorized user; generating a command signal in response to the audio signal including a command and being supplied by an authorized user; and transmitting the command signal to a device at the local site to effect a change in a state of the local device.
PERCHING UAV WITH RELEASABLE CRAWLER,https://lens.org/142-337-501-945-591,2023,"An unmanned aerial vehicle (UAV) a fixed frame and a rotating arm pivotably coupled to the fixed frame at a central axis. The fixed frame includes peripheral propellers and corresponding motors for flying the UAV, and a central electronics enclosure for housing electronics used to control the UAV. The rotating arm is between the propellers and configured to rotate with respect to the fixed frame about the central axis. The rotating arm includes magnetic feet at a first end of the rotating arm and configured to perch and magnetically attach the UAV to a ferromagnetic surface, a docking station at the first end and configured to release and dock a releasable crawler, and a battery at a second end of the rotating arm opposite the first end and configured to supply power to the motors and the housed electronics, and to counterbalance the first end about the central axis."
PERCHING UAV WITH RELEASABLE CRAWLER,https://lens.org/142-337-501-945-591,2023,"An unmanned aerial vehicle (UAV) a fixed frame and a rotating arm pivotably coupled to the fixed frame at a central axis. The fixed frame includes peripheral propellers and corresponding motors for flying the UAV, and a central electronics enclosure for housing electronics used to control the UAV. The rotating arm is between the propellers and configured to rotate with respect to the fixed frame about the central axis. The rotating arm includes magnetic feet at a first end of the rotating arm and configured to perch and magnetically attach the UAV to a ferromagnetic surface, a docking station at the first end and configured to release and dock a releasable crawler, and a battery at a second end of the rotating arm opposite the first end and configured to supply power to the motors and the housed electronics, and to counterbalance the first end about the central axis."
METHODS AND APPARATUSES RELATED TO TRANSFORMABLE REMOTE CONTROLLERS,https://lens.org/019-257-562-648-241,2020,"A remote controller for operating an unmanned aerial vehicle (UAV) includes a user input component configured to receive user input from a user and a communication circuit configured to transmit an instruction to operate at least one of the UAV or a load carried by the UAV based on the user input. The remote controller is configured to transform between (1) a single-hand operation mode that enables the user to control an operation of the at least one of the UAV or the load using the user input from a single hand while being held by the single hand, and (2) a multi-hand operation mode that enables the user to control the operation of the at least one of the UAV or the load using at least two hands while holding the remote controller using the at least two hands."
Methods and apparatuses related to transformable remote controllers,https://lens.org/116-967-960-445-426,2022,"A remote controller for operating an unmanned aerial vehicle (UAV) includes a user input component configured to receive user input from a user and a communication circuit configured to transmit an instruction to operate at least one of the UAV or a load carried by the UAV based on the user input. The remote controller is configured to transform between (1) a single-hand operation mode that enables the user to control an operation of the at least one of the UAV or the load using the user input from a single hand while being held by the single hand, and (2) a multi-hand operation mode that enables the user to control the operation of the at least one of the UAV or the load using at least two hands while holding the remote controller using the at least two hands."
Methods and apparatuses related to transformable remote controllers,https://lens.org/116-967-960-445-426,2022,"A remote controller for operating an unmanned aerial vehicle (UAV) includes a user input component configured to receive user input from a user and a communication circuit configured to transmit an instruction to operate at least one of the UAV or a load carried by the UAV based on the user input. The remote controller is configured to transform between (1) a single-hand operation mode that enables the user to control an operation of the at least one of the UAV or the load using the user input from a single hand while being held by the single hand, and (2) a multi-hand operation mode that enables the user to control the operation of the at least one of the UAV or the load using at least two hands while holding the remote controller using the at least two hands."
UNMANNED AERIAL VEHICLE THROW MODE,https://lens.org/149-326-729-258-270,2020,"An Unmanned Aerial Vehicle (UAV), comprising at least one power supply; at least one motor; at least one sensor configured to sense a throw action; and a controller connected with the at least one power supply, the at least one motor and the at least one sensor; wherein the UAV is configured to be thrown, detect a unique throw signature according to at least one measurement received from the at least one sensor and activate the at least one motor upon a the unique throw signature being detected"
NAVIGATING A UAV WITH ON-BOARD NAVIGATION ALGORITHMS WITH FLIGHT DEPICTION,https://lens.org/193-468-460-352-844,2006,"Navigating a UAV including receiving in a remote control device a user's selection of a GUI map pixel that represents a waypoint for UAV navigation, mapping the pixel's location on the GUI to Earth coordinates of the waypoint, transmitting the coordinates of the waypoint to the UAV, reading a starting position from a GPS receiver on the UAV, and piloting the UAV, under control of a navigation computer on the UAV, from the starting position to the waypoint in accordance with a navigation algorithm. While piloting the UAV from the starting position to the waypoint, such embodiments include reading from the GPS receiver a sequence of GPS data representing a flight path of the UAV, and depicting the flight of the UAV with 3D computer graphics, including a computer graphic display of a satellite image of the Earth, in dependence upon the GPS data."
VEHICLE-BASED REMOTE CONTROL SYSTEM AND METHOD,https://lens.org/015-392-606-069-716,2020,"A remote control system of a vehicle is configured to control a remote device via a first electronic device. The first electronic device is configured to control the transmission of a semi-generic user voice command and the voice command is updated based on one or more spoken words generating an updated voice command. The remote control system comprises a second electronic device in communication with the first electronic device. A controller is configured to prompt the first electronic device to cause the updated voice command to be accessed and transmitted to a remote device controller located remotely from the vehicle in response to the input from a user-input mechanism of the second electronic device. The remote device controller processes the updated voice command, generates a control command based on the updated voice command, and executes the control command."
Droneboarding Tow Bar With Integrated Flight Controller,https://lens.org/058-517-197-759-391,2020,A tow bar assembly for use in a droneboarding system is disclosed. The tow bar assembly includes a shaft adapted to be connected to an unmanned aerial vehicle via at least one tension line. A multi-axis interface device is associated with the shaft and is adapted to receive flight control commands from a user holding onto the shaft. A flight controller is mounted to the shaft and is adapted to generate flight control signals for controlling the flight path of the unmanned aerial vehicle according to the flight control commands received from the user via the multi-axis interface device. The flight controller is further adapted to wirelessly transmit the flight control signals to the unmanned aerial vehicle.
Drone used for authentication and authorization for restricted access via an electronic lock,https://lens.org/174-446-983-003-161,2018,"In an electronic lock authentication method using a drone, authentication information input by a person is received at an electronic lock, a first level verification of the authentication information is performed at the electronic lock, and a drone request signal is transmitted from the electronic lock to the drone. The drone request signal instructs the drone to proceed to the electronic lock and perform a second level verification of the person when the first level verification has passed. Further in the method, the second level verification of the person is performed with the drone, a grant access signal is transmitted from the drone to the electronic lock, the grant access signal instructs the electronic lock to unlock when the second level verification has passed, and the electronic lock is unlocked in response to the grant access signal."
Unmanned aerial vehicles,https://lens.org/122-858-194-382-28X,2019,A UAV 100 comprises an upwardly facing lighting arrangement 130 and a controller 110 configured to control the upwards facing lighting arrangement. Control of the light while the UAV 100 is in-flight is based on data received from a control device of a human operator of the UAV 100. The UAV may include a camera arrangement 120 and together with the lighting arrangement enables airspace above the UAV to be monitored and any objects detected to aid in take-off and landing situations.
DRONE GUIDANCE METHODS AND SYSTEMS,https://lens.org/145-292-251-822-064,2022,"The following describes a drone guidance system and method utilizing a plurality of Bluetooth emitters that transmit indicator information to the drone, which can utilize the indicator information to determine if it is on the intended path or alternatively determine if it is near a prohibited flying zone. In alternative embodiments, the drone can communicate with the emitters, which can relay information to a pre-flight database."
Inverted Drone.,https://lens.org/123-104-787-205-831,2016,"The present invention is in the field of a rotorcraft in which lift and optionally thrust are supplied by rotors, and specifically a drone. The drone is used for making optical and/or sound recordings, especially during (live) events, such as concerts, gatherings, dance events, etc. The drone gives an impression of the events and is capable of recording specific details thereof, such as individual people."
Multi-dimensional controlling device,https://lens.org/040-815-919-694-895,2012,"A controlling device is provided and is configured to detect a device and to control the detected device. Alternatively, a controlling device is provided and is configured to detect a device and to receive at least one command from a remote control device. The controlling device may control the device using the received command."
MULTI-DIMENSIONAL CONTROLLING DEVICE,https://lens.org/139-388-239-869-467,2011,"A controlling device is provided and is configured to detect a device and to control the detected device. Alternatively, a controlling device is provided and is configured to detect a device and to receive at least one command from a remote control device. The controlling device may control the device using the received command."
Controller for an unmanned aerial vehicle,https://lens.org/130-277-342-817-324,2023,"A controller for an unmanned aerial vehicle (UAV) comprising an image capture means, the controller comprising: inputs arranged to receive: positional data relating to the UAV, a vehicle and a user device; image data captured by the image capture means; a processor arranged to process the received positional data to determine the relative locations of the UAV, vehicle and user device; an output arranged to output a control signal for controlling the UAV and to output an image signal comprising captured image data; wherein the processor is arranged to: generate the control signal for the UAV such that the image data captured by the image capture means comprises at least an image of an obscured portion of the vehicle that is obscured from a field of view of a user of the user device."
Controller for an unmanned aerial vehicle,https://lens.org/130-277-342-817-324,2023,"A controller for an unmanned aerial vehicle (UAV) comprising an image capture means, the controller comprising: inputs arranged to receive: positional data relating to the UAV, a vehicle and a user device; image data captured by the image capture means; a processor arranged to process the received positional data to determine the relative locations of the UAV, vehicle and user device; an output arranged to output a control signal for controlling the UAV and to output an image signal comprising captured image data; wherein the processor is arranged to: generate the control signal for the UAV such that the image data captured by the image capture means comprises at least an image of an obscured portion of the vehicle that is obscured from a field of view of a user of the user device."
CONTROLLER FOR AN UNMANNED AERIAL VEHICLE,https://lens.org/147-867-695-161-874,2019,"A controller for an unmanned aerial vehicle (UAV) comprising an image capture means, the controller comprising: inputs arranged to receive: positional data relating to the UAV, a vehicle and a user device; image data captured by the image capture means; a processor arranged to process the received positional data to determine the relative locations of the UAV, vehicle and user device; an output arranged to output a control signal for controlling the UAV and to output an image signal comprising captured image data; wherein the processor is arranged to: generate the control signal for the UAV such that the image data captured by the image capture means comprises at least an image of an obscured portion of the vehicle that is obscured from a field of view of a user of the user device."
METHOD AND APPARATUS FOR DYNAMICALLY DETERMINING A DESTINATION OF A DRONE,https://lens.org/147-632-302-211-679,2020,"A method, apparatus and computer program product are provided in order to dynamically determine the destination for a drone. In the context of a method, location-related data may be collected with a drone. After having collected at least some of the location-related data, a destination for the drone is determined based at least in part upon a location of the drone. The drone is then caused to travel from the location to the destination. In some instances, the drone may travel toward the destination by being carried by a vehicle that is traveling along a route toward the destination."
Method for controlling unmanned aerial vehicle and electronic device for controlling unmanned aerial vehicle,https://lens.org/087-494-903-203-642,2020,"An electronic device is provided that includes a communication circuit configured to transmit and receive wireless data with the unmanned aerial vehicle (UAV), a display configured to display a user interface (UI) for operating the UAV, a memory, and a processor electrically coupled with the communication circuit, the display, and the memory. The processor is configured to receive information about a direction of a first point of the UAV from the UAV, display a direction indication object corresponding to a direction of the first point on the display, in response to receiving a user input associated with movement or rotation of the UAV, generate a control signal for moving or rotating the UAV with respect to the first point in response to a location of the direction indication object and the user input, and transmit the generated control signal to the UAV using the communication circuit."
METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE AND ELECTRONIC DEVICE FOR CONTROLLING UNMANNED AERIAL VEHICLE,https://lens.org/002-779-791-379-728,2018,"An electronic device is provided that includes a communication circuit configured to transmit and receive wireless data with the unmanned aerial vehicle (UAV), a display configured to display a user interface (UI) for operating the UAV, a memory, and a processor electrically coupled with the communication circuit, the display, and the memory. The processor is configured to receive information about a direction of a first point of the UAV from the UAV, display a direction indication object corresponding to a direction of the first point on the display, in response to receiving a user input associated with movement or rotation of the UAV, generate a control signal for moving or rotating the UAV with respect to the first point in response to a location of the direction indication object and the user input, and transmit the generated control signal to the UAV using the communication circuit."
"AUTONOMOUS SYSTEM FOR SHOOTING MOVING IMAGES FROM A DRONE, WITH TARGET TRACKING AND HOLDING OF THE TARGET SHOOTING ANGLE",https://lens.org/102-088-081-103-543,2018,"A system for shooting moving images includes a drone provided with a camera and a ground station, the camera being directed along a sight axis, the drone being adapted to fly autonomously to shoot moving images of a target moving with the ground station, the direction of the sight axis being such that the target remains present in the successive images produced by said shooting. The system further comprises means for determining the speed vector of the target and the position of the target in a given reference system, and control means configured to generate flight instructions based on the speed vector determined, the position determined, and a predetermined direction angle so as to hold the angle between the sight axis of the camera and the direction of the speed vector substantially at the value of said predetermined direction angle."
System and method of last mile delivery,https://lens.org/162-275-286-819-297,2023,A vehicle to transport a first drone and a second drone includes a controller and a storage unit. The storage unit is configured to store a plurality of package containers. The controller is configured to initiate movement of a package container from the storage unit to the first drone and to initiate coupling of a first electromechanical interface of a plurality of electromechanical interfaces of the package container to the first drone. The controller is also configured to release the first drone from the vehicle with instructions for the first drone to move the package container to a package container reception point configured to couple to a second electromechanical interface of the plurality of electromechanical interfaces. The second drone is configured to provide data to the first drone. The data is related to a route from the vehicle to the package container reception point.
SYSTEM AND METHOD OF LAST MILE DELIVERY,https://lens.org/128-761-400-797-177,2021,A vehicle to transport a first drone and a second drone includes a controller and a storage unit. The storage unit is configured to store a plurality of package containers. The controller is configured to initiate movement of a package container from the storage unit to the first drone and to initiate coupling of a first electromechanical interface of a plurality of electromechanical interfaces of the package container to the first drone. The controller is also configured to release the first drone from the vehicle with instructions for the first drone to move the package container to a package container reception point configured to couple to a second electromechanical interface of the plurality of electromechanical interfaces. The second drone is configured to provide data to the first drone. The data is related to a route from the vehicle to the package container reception point.
System and method of utilizing a drone to deploy frac balls in an open well bore,https://lens.org/032-279-265-613-796,2020,A system includes an aerial drone having a dispensing mechanism and a remote control for wirelessly controlling movement of the aerial drone and the dispensing mechanism. The dispensing mechanism includes a storage area for storing a frac ball and a device for remotely releasing the frac ball from the drone. The aerial drone is remotely controlled to position the drone over the open well bore and where the frac ball is released into the open well bore.
DRONE-BASED PAINTING SYSTEM,https://lens.org/154-220-422-567-672,2019,"A painting system that makes use of drones such as modified quadrotors. The drone includes a support arm that carries a paint nozzle configured for pan and tilt motion. A power supply line is connected from an external power supply to the drone to allow extended flight time. A paint supply line is also connected from an external paint supply to the drone to allow extended painting time and/or surface coverage with each flight. The drone has an onboard controller so painting is autonomous with no human input being required. The drone stores a 3D model of the target structure annotated with the drone trajectory plus commands to control the pan-tilt paint nozzle to perform the painting. At runtime, the controller uses a sensor to view the target structure and localizes itself. The drone then traverses the stored trajectory and implements the painting commands to paint the 3D structure's surfaces."
Drone-based painting system,https://lens.org/150-121-542-590-288,2020,"A painting system that makes use of drones such as modified quadrotors. The drone includes a support arm that carries a paint nozzle configured for pan and tilt motion. A power supply line is connected from an external power supply to the drone to allow extended flight time. A paint supply line is also connected from an external paint supply to the drone to allow extended painting time and/or surface coverage with each flight. The drone has an onboard controller so painting is autonomous with no human input being required. The drone stores a 3D model of the target structure annotated with the drone trajectory plus commands to control the pan-tilt paint nozzle to perform the painting. At runtime, the controller uses a sensor to view the target structure and localizes itself. The drone then traverses the stored trajectory and implements the painting commands to paint the 3D structure's surfaces."
DYNAMIC DRONE NAVIGATION,https://lens.org/027-480-284-717-05X,2022,"Techniques are described for enabling a drone device to use a dynamic multi dimensional spatial representation of an indoor property environment to improve autonomous navigation. In some implementations, an instruction to perform an action at a particular location of a property is received by a drone device. A spatial representation of the property that identifies a dynamic object is obtained by the drone device. The status of the dynamic object impacts an ability of the drone device to navigate near the dynamic object. Sensor data collected by one or more sensors of a monitoring system of the property and that indicates a present status of the dynamic object is obtained by the drone device. A path to the particular location is determined by the drone device. The path to the particular location is finally navigated by the drone device."
DYNAMIC DRONE NAVIGATION,https://lens.org/027-480-284-717-05X,2022,"Techniques are described for enabling a drone device to use a dynamic multi dimensional spatial representation of an indoor property environment to improve autonomous navigation. In some implementations, an instruction to perform an action at a particular location of a property is received by a drone device. A spatial representation of the property that identifies a dynamic object is obtained by the drone device. The status of the dynamic object impacts an ability of the drone device to navigate near the dynamic object. Sensor data collected by one or more sensors of a monitoring system of the property and that indicates a present status of the dynamic object is obtained by the drone device. A path to the particular location is determined by the drone device. The path to the particular location is finally navigated by the drone device."
"Control method for photographing using unmanned aerial vehicle, photographing method using unmanned aerial vehicle, mobile terminal, and unmanned aerial vehicle",https://lens.org/073-843-403-601-93X,2020,"A method for controlling photography using an unmanned aerial vehicle (UAV) is performed by a mobile terminal. After obtaining a photographing start command, the photographing start command being associated with a photographic sample, the mobile terminal generates a combined operation command according to the photographic sample. The combined operation command may include one or more flight parameters of the UAV. Next, the mobile terminal establishes a wireless connection with the UAV and then sends the combined operation command to the UAV via the wireless connection. The UAV then performs a corresponding series of actions sequentially according to the combined operation command to capture an image."
SYSTEMS AND METHODS FOR UNMANNED AERIAL VEHICLES,https://lens.org/043-018-323-326-669,2017,"An unmanned aerial system (UAS) may comprise an unmanned aerial vehicle (UAV) configured to display advertising. The UAV may include a connector configured to attach to a display screen. The display screen may be configured to receive data from the UAV and display a message based on the data. The UAS may be controlled by a remote control, which may command the UAV to display a specific message. The remote control may control the flight of the UAV as well as the functionality of the one or more components. The components attached to the UAV, may include a camera, a robotic arm, or a display screen. The UAS may be configured to, for example, display advertising messages in a predetermined area, display advertising messages in response to the UAV determining a specific event or recognizing a specific person, and/or launch fireworks."
SYSTEMS AND METHODS FOR UNMANNED AERIAL VEHICLES,https://lens.org/004-568-904-473-896,2019,"An unmanned aerial system (UAS) may comprise an unmanned aerial vehicle (UAV) configured to display advertising. The UAV may include a connector configured to attach to a display screen. The display screen may be configured to receive data from the UAV and display a message based on the data. The UAS may be controlled by a remote control, which may command the UAV to display a specific message. The remote control may control the flight of the UAV as well as the functionality of the one or more components. The components attached to the UAV, may include a camera, a robotic arm, or a display screen. The UAS may be configured to, for example, display advertising messages in a predetermined area, display advertising messages in response to the UAV determining a specific event or recognizing a specific person, and/or launch fireworks."
Navigating a UAV with a remote control device,https://lens.org/025-759-579-900-439,2005,"Navigating a UAV, including receiving in a remote control device a user's selection of a GUI map pixel that represents a waypoint for UAV navigation, the pixel having a location on the GUI; mapping the pixel's location on the GUI to Earth coordinates of the waypoint; receiving a starting position from a GPS receiver on the UAV; calculating a heading in dependence upon the starting position, the coordinates of the waypoint, and a navigation algorithm; identifying flight control instructions for flying the UAV on the heading; and transmitting the flight control instructions from the remote control device to the UAV."
Navigating a UAV with a remote control device,https://lens.org/059-559-653-365-540,2006,"Navigating a UAV, including receiving in a remote control device a user's selection of a GUI map pixel that represents a waypoint for UAV navigation, the pixel having a location on the GUI; mapping the pixel's location on the GUI to Earth coordinates of the waypoint; receiving a starting position from a GPS receiver on the UAV; calculating a heading in dependence upon the starting position, the coordinates of the waypoint, and a navigation algorithm; identifying flight control instructions for flying the UAV on the heading; and transmitting the flight control instructions from the remote control device to the UAV."
"AUTONOMOUS SYSTEM FOR TAKING MOVING IMAGES, COMPRISING A DRONE AND A GROUND STATION, AND ASSOCIATED METHOD",https://lens.org/127-590-115-235-001,2018,"The displacements of the drone are defined by piloting commands applied to a set of propulsion units of the drone, the drone flying along a trajectory that is at least in part predetermined, to take moving images of a target. The drone adjusts the camera sight angle during its displacements, and as the case may be, those of the target, so that at each instant, the image taken by the camera contain the position of the target. The system comprises means for determining a static trajectory of the drone for the shooting, means for determining a dynamics of displacement of the drone along the static trajectory, and means for generating flying instructions for the drone based on the two determinations and on information about the target position over time."
CLEANING DIFFICULT TO REACH STRUCTURES USING DRONES,https://lens.org/023-753-488-689-404,2021,"A drone system includes a drone aircraft connected to an air duct that terminates in a nozzle that emits a jet of air with a blowing force from the blower nozzle, such as for cleaning tall and hard to reach surfaces of structures and buildings or to otherwise blow objects, debris, substances and floating materials."
DRONE DOCKING PORT AND METHOD OF USE,https://lens.org/012-138-480-896-763,2021,"A drone docking port (DDP) mounted on a pole and having an openable and closable convertible top (CT), a docking plate having integrated battery wired or wireless recharging pads, and a control module. The control module (CM) is adapted to autonomously control all functions of the DDP including actuation of the CT and relay of video, audio, and flight control information between the CM and a central monitoring center and/or emergency personnel. The DDP is positioned in close proximity to an intended monitoring site. When the CT is in an open position, a drone may initiate flight from the DDP and when a drone flight is completed and a drone has re-docked therein, the CT may be closed to protect the drone docked therein from external weather. The DDP may further include Electro-Optical/Infra-Red (EO/IR) cameras and sensors to detect disruptive or other predetermined behavior."
"Flight Control Method and Device of Unmanned Aerial Vehicle, and Unmanned Aerial Vehicle",https://lens.org/132-820-170-829-680,2021,"A flight control method and device of an Unmanned Aerial Vehicle (UAV), and a UAV, the method includes that: a flight track of the UAV is determined (101); a remote control signal sent by a remote control apparatus is received; the remote control signal is converted into a flight controlled quantity of the UAV; a flight adjustment controlled quantity of the UAV is generated according to the current location, the flight track and the flight controlled quantity, of the UAV; and a flight mission is executed according to an action indicated by the flight adjustment controlled quantity, as to enable the UAV to run on the flight track."
Drone with Distributed Electrical Storage,https://lens.org/157-879-728-432-388,2018,"Drone comprising a central body and a plurality of arms, preferably at least three arms, each arm comprising a first end mounted on the central body, each arm comprising, in the vicinity of a second end, at least one electric motor and at least one propeller coupled to said electric motor, each arm accommodating at least one electric battery."
SYSTEM AND METHOD OF DELIVERING PACKAGE BY USING DRONE,https://lens.org/125-084-857-968-445,2022,"A system and a method of delivering a package by use of at least one drone, may include the at least one drone configured for picking up and delivering the package; and a server configured for receiving a request for delivering the package, selecting a drone to be used for delivery of the package among the at least one drone, making the selected drone pick up the package at a pick-up place, making a delivery plan from the pick-up place to a delivery destination, and making the selected drone deliver the package directly to the delivery destination or deliver the package to an intermediate destination before the delivery destination."
Automated drone delivery system,https://lens.org/033-334-100-289-313,2022,"A drone conveyance system and a wellhead receiver for deploying drones into a wellbore is described. The system includes a platform, a drone magazine, a platform receiver, a conveyance, and a wellhead receiver. The wellhead receiver prepares the drone to be inserted into the wellbore via the wellhead. Preparation of the drone may include adjusting the physical conditions surrounding the drone to approximate the physical conditions in the wellbore, which may be done with fluid inputs and outputs connected to a compartment of the wellhead receiver. Other preparation processes may also take place in the wellhead receiver, such as assuring the appropriate drone is being inserted, that the drone has been programmed appropriately, that safety devices have been deactivated and charging an onboard power supply of the drone."
AUTOMATED DRONE DELIVERY SYSTEM,https://lens.org/119-948-347-626-304,2022,"A drone conveyance system and a wellhead receiver for deploying drones into a wellbore is described. The system includes a platform, a drone magazine, a platform receiver, a conveyance, and a wellhead receiver. The wellhead receiver prepares the drone to be inserted into the wellbore via the wellhead. Preparation of the drone may include adjusting the physical conditions surrounding the drone to approximate the physical conditions in the wellbore, which may be done with fluid inputs and outputs connected to a compartment of the wellhead receiver. Other preparation processes may also take place in the wellhead receiver, such as assuring the appropriate drone is being inserted, that the drone has been programmed appropriately, that safety devices have been deactivated and charging an onboard power supply of the drone."
Automated drone delivery system,https://lens.org/033-334-100-289-313,2022,"A drone conveyance system and a wellhead receiver for deploying drones into a wellbore is described. The system includes a platform, a drone magazine, a platform receiver, a conveyance, and a wellhead receiver. The wellhead receiver prepares the drone to be inserted into the wellbore via the wellhead. Preparation of the drone may include adjusting the physical conditions surrounding the drone to approximate the physical conditions in the wellbore, which may be done with fluid inputs and outputs connected to a compartment of the wellhead receiver. Other preparation processes may also take place in the wellhead receiver, such as assuring the appropriate drone is being inserted, that the drone has been programmed appropriately, that safety devices have been deactivated and charging an onboard power supply of the drone."
Unmanned aerial vehicle for situational awareness to first responders and alarm investigation,https://lens.org/009-611-073-882-340,2017,"A device, and method for situational awareness of an emergency scene for first responders uses an unmanned aerial vehicle- equipped with a sensor package in populated or otherwise restricted areas. The unmanned aerial vehicle is assigned to a control center for a designated incident while automatically tasking the unmanned aerial vehicle with the initiation of the incident response to autonomously proceed to the incident prior the control center taking active control of the unmanned aerial vehicle."
UNMANNED AERIAL VEHICLE FOR SITUATIONAL AWARENESS TO FIRST RESPONDERS AND ALARM INVESTIGATION,https://lens.org/152-626-762-171-524,2015,"A device, and method for situational awareness of an emergency scene for first responders uses an unmanned aerial vehicle- equipped with a sensor package in populated or otherwise restricted areas. The unmanned aerial vehicle is assigned to a control center for a designated incident while automatically tasking the unmanned aerial vehicle with the initiation of the incident response to autonomously proceed to the incident prior the control center taking active control of the unmanned aerial vehicle."
MULTIMODE UNMANNED AERIAL VEHICLE,https://lens.org/175-048-962-648-799,2021,"A system comprising an unmanned aerial vehicle (UAV) (100) configured to transition (520) from a terminal homing mode (510) to a target search mode (530), responsive to an uplink signal (451) and/or an autonomous determination of scene change."
Multimode unmanned aerial vehicle,https://lens.org/016-400-570-494-158,2022,"A system comprising an unmanned aerial vehicle (UAV) (100) configured to transition (520) from a terminal homing mode (510) to a target search mode (530), responsive to an uplink signal (451) and/or an autonomous determination of scene change."
Multimode unmanned aerial vehicle,https://lens.org/040-572-839-209-067,2011,"A system comprising an unmanned aerial vehicle (UAV) (100) configured to transition (520) from a terminal homing mode (510) to a target search mode (530), responsive to an uplink signal (451) and/or an autonomous determination of scene change."
Multimode unmanned aerial vehicle,https://lens.org/191-435-172-131-170,2015,"A system comprising an unmanned aerial vehicle (UAV) (100) configured to transition (520) from a terminal homing mode (510) to a target search mode (530), responsive to an uplink signal (451) and/or an autonomous determination of scene change."
MULTIMODE UNMANNED AERIAL VEHICLE,https://lens.org/000-633-032-863-83X,2011,"A system comprising an unmanned aerial vehicle (UAV) (100) configured to transition (520) from a terminal homing mode (510) to a target search mode (530), responsive to an uplink signal (451) and/or an autonomous determination of scene change."
Multimode unmanned aerial vehicle,https://lens.org/044-773-363-698-171,2015,"A system comprising an unmanned aerial vehicle (UAV) (100) configured to transition (520) from a terminal homing mode (510) to a target search mode (530), responsive to an uplink signal (451) and/or an autonomous determination of scene change."
Multimode unmanned aerial vehicle,https://lens.org/072-235-269-007-01X,2018,"A system comprising an unmanned aerial vehicle (UAV) (100) configured to transition (520) from a terminal homing mode (510) to a target search mode (530), responsive to an uplink signal (451) and/or an autonomous determination of scene change."
Multimode unmanned aerial vehicle,https://lens.org/083-494-472-461-301,2020,"A system comprising an unmanned aerial vehicle (UAV) (100) configured to transition (520) from a terminal homing mode (510) to a target search mode (530), responsive to an uplink signal (451) and/or an autonomous determination of scene change."
MULTIMODE UNMANNED AERIAL VEHICLE,https://lens.org/154-485-232-860-88X,2010,"A system comprising an unmanned aerial vehicle (UAV) (100) configured to transition (520) from a terminal homing mode (510) to a target search mode (530), responsive to an uplink signal (451) and/or an autonomous determination of scene change."
Multimode unmanned aerial vehicle,https://lens.org/000-805-621-417-828,2019,"A system comprising an unmanned aerial vehicle (UAV) (100) configured to transition (520) from a terminal homing mode (510) to a target search mode (530), responsive to an uplink signal (451) and/or an autonomous determination of scene change."
PROPULSION UNIT ALLOWING THE DISPLAY OF A MESSAGE,https://lens.org/010-858-999-950-116,2017,"A drone propulsion unit includes a propeller with a hub and a plurality of blades, an electric motor with a motor support, and a motor control device, wherein the electric motor includes a fixed part with a stator connected to the motor support and a mobile part with a rotor mobile about an axis of rotation for driving the propeller, the propeller includes a blade with a plurality of electroluminescent diodes and a diode control device, the motor includes a hollow central shaft, and the motor support includes a communication device adapted to communicate with a communication device integrated in the propeller, with the communication devices being positioned on either side of the hollow shaft."
OBJECT IMAGE RECOGNITION AND INSTANT ACTIVE RESPONSE,https://lens.org/105-648-220-444-56X,2018,"A device for use in a security system includes a sensor, an image capture device, an action arm, and a processor in communication with the sensor, the image capture device, and the action arm. The processor is configured to receive data from the sensor and the image capture device and identify a target based on an analysis of the received data. The processor is also configured to determine, based on the analysis of the received data, that the target is a drone or other mechanical device. The processor is also configured to determine an action to take on the identified target. The processor is further configured to cause the action arm to perform the determined action on the target."
DRONE AND DRONE FALL PREVENTION SYSTEM,https://lens.org/087-331-273-134-358,2022,"A drone according to an example embodiment includes a main body; a propulsion portion provided outside the main body to generate a thrust force; a first rotation stabilizing portion disposed inside the main body or on a top surface of the main body to generate an angular velocity with respect to a yaw axis of the main body; and a controller configured to control driving of the first rotation stabilizing portion, wherein when the propulsion portion fails, the controller stabilizes a posture of the main body by driving the first rotation stabilizing portion, to prevent an occurrence of a tumbling phenomenon."
Drone-enabled operator rounds,https://lens.org/182-731-908-952-140,2022,"Drones (e.g., unmanned aerial vehicles, or UAVs) equipped with cameras and sensors may be configured to travel throughout the field environment of a process plant to monitor process plant conditions. Onboard computing devices associated with the drones control the movement of the drones through the field environment of the process plant. The onboard computing devices interface with the cameras and other sensors and communicate with user interface devices, controllers, servers and/or databases via a network. The onboard computing devices may receive drone commands from user interface devices and/or servers, or may access drone commands stored in one or more databases. The onboard computing devices may transmit data captured by the cameras and/or other sensors to UI devices, controllers, servers, etc. Accordingly, the user interface devices may display data (including live video feeds) captured by the drone cameras and/or drone sensors to an operator in a human machine interface application."
DRONE-ENABLED OPERATOR ROUNDS,https://lens.org/156-165-248-794-725,2020,"Drones (e.g., unmanned aerial vehicles, or UAVs) equipped with cameras and sensors may be configured to travel throughout the field environment of a process plant to monitor process plant conditions. Onboard computing devices associated with the drones control the movement of the drones through the field environment of the process plant. The onboard computing devices interface with the cameras and other sensors and communicate with user interface devices, controllers, servers and/or databases via a network. The onboard computing devices may receive drone commands from user interface devices and/or servers, or may access drone commands stored in one or more databases. The onboard computing devices may transmit data captured by the cameras and/or other sensors to UI devices, controllers, servers, etc. Accordingly, the user interface devices may display data (including live video feeds) captured by the drone cameras and/or drone sensors to an operator in a human machine interface application."
System and method for analyzing drone flight risk,https://lens.org/183-801-714-156-653,2018,"A system for analyzing risk for operating drones, the system comprising a mobile device comprising program code that when executed by a programmable processor causes the mobile device to determine a location of a user of the mobile device by accessing a location tracking system, transmit the location to a server, receive, from the server, geospatial data and temporal data for a surrounding area of the location, calculate risks of operating a drone for a duration of time in a given coverage area within the surrounding area using at least the geospatial data and temporal data, generate a quote for an insurance policy for operating the drone for the duration of time in the given coverage area based on the calculated risks, facilitate a purchase of the insurance policy with the server, and generate a timer for the duration of time for operating the drone in the given coverage area."
SYSTEM AND METHOD FOR ANALYZING DRONE FLIGHT RISK,https://lens.org/080-299-970-149-764,2017,"A system for analyzing risk for operating drones, the system comprising a mobile device comprising program code that when executed by a programmable processor causes the mobile device to determine a location of a user of the mobile device by accessing a location tracking system, transmit the location to a server, receive, from the server, geospatial data and temporal data for a surrounding area of the location, calculate risks of operating a drone for a duration of time in a given coverage area within the surrounding area using at least the geospatial data and temporal data, generate a quote for an insurance policy for operating the drone for the duration of time in the given coverage area based on the calculated risks, facilitate a purchase of the insurance policy with the server, and generate a timer for the duration of time for operating the drone in the given coverage area."
System and method for analyzing drone flight risk,https://lens.org/137-397-515-419-641,2019,"A system for analyzing risk for operating drones, the system comprising a mobile device comprising program code that when executed by a programmable processor causes the mobile device to determine a location of a user of the mobile device by accessing a location tracking system, transmit the location to a server, receive, from the server, geospatial data and temporal data for a surrounding area of the location, calculate risks of operating a drone for a duration of time in a given coverage area within the surrounding area using at least the geospatial data and temporal data, generate a quote for an insurance policy for operating the drone for the duration of time in the given coverage area based on the calculated risks, facilitate a purchase of the insurance policy with the server, and generate a timer for the duration of time for operating the drone in the given coverage area."
SYSTEM AND METHOD FOR ANALYZING DRONE FLIGHT RISK,https://lens.org/093-955-667-369-478,2018,"A system for analyzing risk for operating drones, the system comprising a mobile device comprising program code that when executed by a programmable processor causes the mobile device to determine a location of a user of the mobile device by accessing a location tracking system, transmit the location to a server, receive, from the server, geospatial data and temporal data for a surrounding area of the location, calculate risks of operating a drone for a duration of time in a given coverage area within the surrounding area using at least the geospatial data and temporal data, generate a quote for an insurance policy for operating the drone for the duration of time in the given coverage area based on the calculated risks, facilitate a purchase of the insurance policy with the server, and generate a timer for the duration of time for operating the drone in the given coverage area."
SYSTEM AND METHOD FOR ANALYZING DRONE FLIGHT RISK,https://lens.org/148-468-737-457-98X,2017,"A system for analyzing risk for operating drones, the system comprising a mobile device comprising program code that when executed by a programmable processor causes the mobile device to determine a location of a user of the mobile device by accessing a location tracking system, transmit the location to a server, receive, from the server, geospatial data and temporal data for a surrounding area of the location, calculate risks of operating a drone for a duration of time in a given coverage area within the surrounding area using at least the geospatial data and temporal data, generate a quote for an insurance policy for operating the drone for the duration of time in the given coverage area based on the calculated risks, facilitate a purchase of the insurance policy with the server, and generate a timer for the duration of time for operating the drone in the given coverage area."
Monitoring a Construction Site Using an Unmanned Aerial Vehicle,https://lens.org/150-000-135-626-908,2017,"Described embodiments include apparatus for operating an unmanned aerial vehicle (UAV). The apparatus includes a receiver, a transmitter, and a processor. The processor is configured to receive, via the receiver, coordinates of a position sensor coupled to a portion of a crane, a configuration of the crane changing over time due at least to movement of the portion of the crane relative to a tower of the crane, to compute, in response to the received coordinates, a flight path that passes under a boom of the crane while circumventing the crane, and to cause the UAV to follow the computed flight path, by transmitting flight instructions, via the transmitter, to the UAV. Other embodiments are also described."
UNMANNED AERIAL VEHICLE AND A METHOD OF LANDING SAME,https://lens.org/086-045-224-380-794,2023,"An unmanned aerial vehicle (UAV) is disclosed. The UAV comprises a body; a propulsion unit; a controller; and at least one adjustable camera unit. In some embodiments, each adjustable camera unit comprises, a camera; and a gimbal, mounting the camera, and configured to move the field of view (FOV) of the camera in at least two axes. In some embodiments, the controller is configured to: continuously receive a stream of images from the at least one camera; identify a tilted target in the stream of images; control the propulsion unit to approach the tilted target; and simultaneously control at least one gimble to rotate a corresponding camera such that the tilted target is continuously being identified in the stream of images."
UNMANNED AIR AERIAL VEHICLE BASED DELIVERY SYSTEM,https://lens.org/091-982-085-358-745,2020,"The present disclosure describes an unmanned aerial vehicle (UAV) or a drone configured to autonomously deliver an item of inventory to a landing station or destination location. The drone receives inventory information and a destination location and autonomously retrieve the inventory from a source station. The drone is having a GPS module and communication module to communicate with the external devices and the GPS module helps the drone to determine the shortest route to the destination. At the destination location, the landing station has GPS guided lasers which help the drone to deliver the item safely. Further, the landing station also comprises an automatic lithium-ion battery switching system to replace the existing battery of the drone with a freshly charged battery."
FIRE SUPPRESSION DRONE FOR SKYSCRAPERS,https://lens.org/013-254-611-211-74X,2020,"A fire suppression drone comprises a main body, a plurality of propellers provided on an outer circumference of the main body and driven by a driving motor, a pump provided in the main body and connected to a water feeding vehicle through a water feeding hose, at least one water jet nozzle provided on the outer circumference of the main body to jet water supplied by the pump, a camera provided on the outer circumference of the main body, and a controller connected with the driving motor, the pump, and the camera and connected with a remote controller to be wirelessly communicable with the remote controller, wherein the remote controller includes a monitor, the monitor capable of display, in real-time, an image captured by the camera."
Autonomous helicopter blade end lighting device,https://lens.org/183-860-808-256-460,2000,"An autonomous helicopter blade end lighting device including a light source being connectable to a helicopter blade end, and a power source being connectable to the helicopter blade end for providing the light source with power for operation."
"UNMANNED AERIAL VEHICLE, CONTROL SYSTEM AND METHOD THEREOF, AND UNMANNED AERIAL VEHICLE LANDING CONTROL METHOD",https://lens.org/024-332-228-166-325,2020,"An unmanned aerial vehicle includes a fuselage, a power device connected to the fuselage, and a control device disposed at the fuselage and electrically connected with the power device. The control device is configured to control the power device to switch an operating mode of the power device to cause the unmanned aerial vehicle to fly in air or navigate on a water surface. The control device includes a depth detector and a main controller. The depth detector is configured to detect a water depth. The main controller is configured to control the unmanned aerial vehicle not to land in response to the depth detector determining that the depth falls within a pre-depth range."
Drone Base Station Companion,https://lens.org/053-438-921-965-501,2017,Use of a drone base station companion increases diversity gain in a communications system to reduce error rates and the probability of the need for a retransmission due to channel fading. An apparatus includes a drone base station companion configured as a relay between a base station in a first cell and wireless user equipment in the first cell. The drone base station companion includes a wireless receiver path configured to receive a wireless communication including data from the base station. The drone base station companion includes a wireless transmitter path configured to transmit the data to the wireless user equipment. The drone base station companion may include a second wireless receiver path configured to receive a second wireless communication including the data from the wireless user equipment. The drone base station companion may include a second wireless transmitter path configured to transmit the second data to the base station.
Drone base station companion,https://lens.org/176-078-578-959-465,2018,Use of a drone base station companion increases diversity gain in a communications system to reduce error rates and the probability of the need for a retransmission due to channel fading. An apparatus includes a drone base station companion configured as a relay between a base station in a first cell and wireless user equipment in the first cell. The drone base station companion includes a wireless receiver path configured to receive a wireless communication including data from the base station. The drone base station companion includes a wireless transmitter path configured to transmit the data to the wireless user equipment. The drone base station companion may include a second wireless receiver path configured to receive a second wireless communication including the data from the wireless user equipment. The drone base station companion may include a second wireless transmitter path configured to transmit the second data to the base station.
Technical layer for portable electronic assistant,https://lens.org/123-819-045-178-044,2022,"A method of controlling an environment using a roaming electronic assistant. The method comprises receiving user environment setting preferences, user entertainment service authorizations, and user entertainment authorization credentials from devices in a home environment by an application executing on a computer system, establishing communication by the application with a destination location, receiving information about application programming interfaces (APIs) of devices located in the destination location by the application, establishing communication with the devices located in the destination location by the application based on the API information, whereby a presentation layer of the application is enabled to control the environment of the user at the destination location based on the user environment setting preferences, the user entertainment service authorizations, and the user entertainment authorization credentials."
Technical layer for portable electronic assistant,https://lens.org/072-965-448-592-01X,2021,"A method of controlling an environment using a roaming electronic assistant. The method comprises receiving user environment setting preferences, user entertainment service authorizations, and user entertainment authorization credentials from devices in a home environment by an application executing on a computer system, establishing communication by the application with a destination location, receiving information about application programming interfaces (APIs) of devices located in the destination location by the application, establishing communication with the devices located in the destination location by the application based on the API information, whereby a presentation layer of the application is enabled to control the environment of the user at the destination location based on the user environment setting preferences, the user entertainment service authorizations, and the user entertainment authorization credentials."
Technical layer for portable electronic assistant,https://lens.org/123-819-045-178-044,2022,"A method of controlling an environment using a roaming electronic assistant. The method comprises receiving user environment setting preferences, user entertainment service authorizations, and user entertainment authorization credentials from devices in a home environment by an application executing on a computer system, establishing communication by the application with a destination location, receiving information about application programming interfaces (APIs) of devices located in the destination location by the application, establishing communication with the devices located in the destination location by the application based on the API information, whereby a presentation layer of the application is enabled to control the environment of the user at the destination location based on the user environment setting preferences, the user entertainment service authorizations, and the user entertainment authorization credentials."
MATERIAL HANDLING SOLUTIONS FOR DRONES,https://lens.org/022-107-428-861-580,2021,"A drone comprises at least one propeller for generating lift and an article containment area for containing an article to be carried by the drone. The floor of the article containment area comprises a dynamic support surface for supporting the article and allowing the article to move into, out of and through the article containment area. The dynamic support surface may be a conveyor belt forming the floor of the article containment area."
MATERIAL HANDLING SOLUTIONS FOR DRONES,https://lens.org/021-973-606-691-161,2017,"A drone comprises at least one propeller for generating lift and an article containment area for containing an article to be carried by the drone. The floor of the article containment area comprises a dynamic support surface for supporting the article and allowing the article to move into, out of and through the article containment area. The dynamic support surface may be a conveyor belt forming the floor of the article containment area."
MATERIAL HANDLING SOLUTIONS FOR DRONES,https://lens.org/066-887-928-504-826,2018,"A drone comprises at least one propeller for generating lift and an article containment area for containing an article to be carried by the drone. The floor of the article containment area comprises a dynamic support surface for supporting the article and allowing the article to move into, out of and through the article containment area. The dynamic support surface may be a conveyor belt forming the floor of the article containment area."
Material handling solutions for drones,https://lens.org/016-401-864-218-815,2022,"A drone comprises at least one propeller for generating lift and an article containment area for containing an article to be carried by the drone. The floor of the article containment area comprises a dynamic support surface for supporting the article and allowing the article to move into, out of and through the article containment area. The dynamic support surface may be a conveyor belt forming the floor of the article containment area."
Material handling solutions for drones,https://lens.org/016-401-864-218-815,2022,"A drone comprises at least one propeller for generating lift and an article containment area for containing an article to be carried by the drone. The floor of the article containment area comprises a dynamic support surface for supporting the article and allowing the article to move into, out of and through the article containment area. The dynamic support surface may be a conveyor belt forming the floor of the article containment area."
Material handling solutions for drones,https://lens.org/013-781-891-339-944,2020,"A drone comprises at least one propeller for generating lift and an article containment area for containing an article to be carried by the drone. The floor of the article containment area comprises a dynamic support surface for supporting the article and allowing the article to move into, out of and through the article containment area. The dynamic support surface may be a conveyor belt forming the floor of the article containment area."
UNMANNED AERIAL VEHICLE IN CONTROLLED AIRSPACE,https://lens.org/039-979-613-845-940,2019,"A method performed by an unmanned aerial vehicle, UAV (10), or a remote control (30) for the UAV, for executing an operating session for the UAV in controlled airspace, comprises the steps of transmitting a request for permission to operate in the airspace to an airspace authority function (20) and receiving a reply to the request. If permission to operate is granted, the following steps are performed: receiving a message comprising information about a space-time region of airspace to operate in, monitoring a position of the UAV in space and time, and, if the position of the UAV is within the region and the UAV is either within a predetermined distance from a geographical border of the region, or predicted to reach the geographical border of the region within a predetermined time, activating assisted control of the UAV to keep the UAV within the region."
UNMANNED AERIAL VEHICLE IN CONTROLLED AIRSPACE,https://lens.org/176-569-841-823-28X,2018,"A method performed by an unmanned aerial vehicle, UAV (10), or a remote control (30) for the UAV, for executing an operating session for the UAV in controlled airspace, comprises the steps of transmitting a request for permission to operate in the airspace to an airspace authority function (20) and receiving a reply to the request. If permission to operate is granted, the following steps are performed: receiving a message comprising information about a space-time region of airspace to operate in, monitoring a position of the UAV in space and time, and, if the position of the UAV is within the region and the UAV is either within a predetermined distance from a geographical border of the region, or predicted to reach the geographical border of the region within a predetermined time, activating assisted control of the UAV to keep the UAV within the region."
Unmanned aerial vehicle in controlled airspace,https://lens.org/029-961-200-141-058,2021,"A method performed by an unmanned aerial vehicle, UAV (10), or a remote control (30) for the UAV, for executing an operating session for the UAV in controlled airspace, comprises the steps of transmitting a request for permission to operate in the airspace to an airspace authority function (20) and receiving a reply to the request. If permission to operate is granted, the following steps are performed: receiving a message comprising information about a space-time region of airspace to operate in, monitoring a position of the UAV in space and time, and, if the position of the UAV is within the region and the UAV is either within a predetermined distance from a geographical border of the region, or predicted to reach the geographical border of the region within a predetermined time, activating assisted control of the UAV to keep the UAV within the region."
DRONE ASSISTED NAVIGATION SYSTEM FOR A VEHICLE,https://lens.org/149-978-056-705-497,2019,"A includes a vehicle and a drone. The vehicle includes a sensor system, a navigation system, a map, and a receiver. The sensor system provides vehicle location data to the navigation system that locates the vehicle on a roadway represented by the map. The sensor system includes one or more of a computer vision system, a radar system, and a LIDAR system. The drone includes a transmitter and at least one position-tracking device configured to determine drone location data. Drone use is initiated from the vehicle in accordance with a determination by the processor that the vehicle location data provided by the sensor system is insufficient for the navigation system to navigate the vehicle. The transmitter is configured to transmit the drone location data to the receiver."
Radio beacon system,https://lens.org/120-193-938-083-420,2022,"A radio beacon system configured to assist autonomous flight of one or more unmanned aerial vehicles (UAVs), wherein the radio beacon system comprises: a drone device (200), configured to be installed on an UAV and including a radio transceiver, and a radio beacon device (100), configured to be installed on ground and including N antenna arrays (110, 120) with N2, one or more radio transceivers configured to communicate with the radio transceiver of the drone device (200), and at least one processing unit (130), wherein each antenna array (110, 120) has M antenna elements (115, 125) with M2 associated to respective beamforming electronic weights w(n, m), with n ranging from 1 to N and m ranging from 1 to M, wherein said at least one processing unit (130) is configured to perform an adaptive beamforming method for assisting autonomous flight of the UAV."
Radio beacon system,https://lens.org/120-193-938-083-420,2022,"A radio beacon system configured to assist autonomous flight of one or more unmanned aerial vehicles (UAVs), wherein the radio beacon system comprises: a drone device (200), configured to be installed on an UAV and including a radio transceiver, and a radio beacon device (100), configured to be installed on ground and including N antenna arrays (110, 120) with N2, one or more radio transceivers configured to communicate with the radio transceiver of the drone device (200), and at least one processing unit (130), wherein each antenna array (110, 120) has M antenna elements (115, 125) with M2 associated to respective beamforming electronic weights w(n, m), with n ranging from 1 to N and m ranging from 1 to M, wherein said at least one processing unit (130) is configured to perform an adaptive beamforming method for assisting autonomous flight of the UAV."
ROBOT AND DRONE ARRAY,https://lens.org/187-218-651-763-022,2019,"A mobile robot and drone device configured to dynamically allocate one or more task objectives and handling objectives, the mobile robot and drone device systematically couples to one another creating a hybrid robot-drone. The robot and drone array are utilized to work and obtain target objects in an environment, wherein the mobile robot and drone device comprise robotic arms and legs comprising propulsion drive wheels managed accordingly by AI system components including; an adaptive robot control system, an autonomous coupling system and an autonomous charging system configured with processors, and subsystems including; user interface, Cloud- Based Analysis and Data Usage Network, a sensor I/O devices including; LIDAR, RADAR, an altitude gyroscope sensors and cameras for scanning surrounding objects in an environment, and an identifier scanning system configured for identifying users, mobile robots, drone devices and target objects in a work environment and in a game environment. The work environment can include a consigned robot and drone array to work inside a cargo vehicle to gather cargo boxes and packages for delivery, and the array of working mobile robot and subsequently the drone device transports the boxes and packages by a flight plan and by a land-based drone device drive mode in flight restricted zones, and the game environment includes real-time gameplay, virtual reality and augmented E Sports game platforms."
VOICE ENABLED IOT USING SECOND LINE SERVICE,https://lens.org/129-187-840-702-015,2023,Enablement of a voice channel being established between an IoT device and a controller through the use of a voice-line service system.
Method and apparatus for controlling the motion of a robotic device,https://lens.org/117-072-267-783-995,2012,A robot movement control device is connected to a communications network in a remote location relative to a robotic device that is also connected to the communications network. The robot movement control device is an electronic device with a video display for displaying a real-time video image sent to it by a camera associated with the robot. A robot movement control overlay is displayed in the field of the real-time video image at the robot control device and robot control commands are generated by selecting locations within the boundary of the movement control overlay which include speed and directional information. The control commands are sent by the robot control device over the network to the robot which uses the commands to adjust its speed and direction of movement.
METHOD & APPARATUS FOR CONTROLLING THE MOTION OF A ROBOTIC DEVICE,https://lens.org/058-372-842-215-844,2010,A robot movement control device is connected to a communications network in a remote location relative to a robotic device that is also connected to the communications network. The robot movement control device is an electronic device with a video display for displaying a real-time video image sent to it by a camera associated with the robot. A robot movement control overlay is displayed in the field of the real-time video image at the robot control device and robot control commands are generated by selecting locations within the boundary of the movement control overlay which include speed and directional information. The control commands are sent by the robot control device over the network to the robot which uses the commands to adjust its speed and direction of movement.
HIGH EFFICIENCY LONG RANGE DRONE,https://lens.org/125-410-193-329-106,2019,"Provided is a high efficiency long range drone, and more particularly, a high efficiency long range drone capable of increasing flight time and efficiently using power during long range cruising flight by selectively using the power among an engine generator and a battery and applying an auxiliary wing."
High efficiency long range drone,https://lens.org/147-707-827-866-364,2022,"Provided is a high efficiency long range drone, and more particularly, a high efficiency long range drone capable of increasing flight time and efficiently using power during long range cruising flight by selectively using the power among an engine generator and a battery and applying an auxiliary wing."
METHOD AND DEVICE FOR LANDING UNMANNED AERIAL VEHICLE,https://lens.org/163-119-956-336-713,2021,"The present disclosure determines whether an unmanned aerial robot is able to land in an empty area of a station as the unmanned aerial robot checks the empty space of the station or the station checks the empty space of the station, and leads the landing of the unmanned aerial robot. A drone according to the present disclosure may be associated with an artificial intelligence module, an unmanned aerial vehicle (UAV), a robot, an augmented reality (AR) device, a virtual reality (VR) device, devices related to 5G services, and the like."
METHODS AND APPARATUS TO PROVIDE PRIVACY FROM DRONES USING SHORT TERM MEMORY LOSS,https://lens.org/199-417-464-949-072,2018,"Methods and apparatus for preserving privacy from a drone are disclosed herein. An example drone includes a privacy mode controller to, when the drone is within a restricted zone, flag data gathered by the drone in the restricted zone; and a private data deleter to, when the drone exits the restricted zone, delete the flagged data."
METHODS AND SYSTEMS FOR CONTROLLING AN UNMANNED AERIAL VEHICLE,https://lens.org/054-615-166-824-65X,2017,"A method for controlling an unmanned aerial vehicle (UAV) is provided. The UAV includes an external system configured to generate information about its surrounding environment and a communication system configured to provide a data link for transmission of the information to a remote controller associated with the UAV. The method comprises: determining whether a distance between the UAV and the remote controller exceeds a predetermined range; determining whether the UAV is capable of transmitting the information about its surrounding environment to the remote controller, the determination including determining whether at least one of the external system and the data link is in a normal state of operation; and after determining that the distance exceeds the predetermined range and that the UAV is not capable of transmitting the information to the remote controller, controlling the UAV to operate in a return mode."
SYSTEMS AND METHODS FOR UAV INTERACTIVE INSTRUCTIONS AND CONTROL,https://lens.org/090-018-577-222-485,2021,"A method for controlling an unmanned aerial vehicle (UAV) includes receiving, by a processor of the UAV, a plurality of images captured by an imaging device coupled to the UAV, identifying, by the processor, a target in at least one image of the plurality of images, determining, by the processor, whether the target is a stationary target or a moving target based on analyzing the plurality of images, and automatically effecting, by the processor, movement of the UAV based on determining the target is the stationary target or the moving target."
Systems and methods for UAV interactive instructions and control,https://lens.org/176-544-726-198-406,2023,"A method for controlling an unmanned aerial vehicle (UAV) includes receiving, by a processor of the UAV, a plurality of images captured by an imaging device coupled to the UAV, identifying, by the processor, a target in at least one image of the plurality of images, determining, by the processor, whether the target is a stationary target or a moving target based on analyzing the plurality of images, and automatically effecting, by the processor, movement of the UAV based on determining the target is the stationary target or the moving target."
Systems and methods for UAV interactive instructions and control,https://lens.org/176-544-726-198-406,2023,"A method for controlling an unmanned aerial vehicle (UAV) includes receiving, by a processor of the UAV, a plurality of images captured by an imaging device coupled to the UAV, identifying, by the processor, a target in at least one image of the plurality of images, determining, by the processor, whether the target is a stationary target or a moving target based on analyzing the plurality of images, and automatically effecting, by the processor, movement of the UAV based on determining the target is the stationary target or the moving target."
Dynamic drone navigation,https://lens.org/115-461-654-981-410,2022,"Techniques are described for enabling a drone device to use a dynamic multi-dimensional spatial representation of an indoor property environment to improve autonomous navigation. In some implementations, an instruction to perform an action at a particular location of a property is received by a drone device. A spatial representation of the property that identifies a dynamic object is obtained by the drone device. The status of the dynamic object impacts an ability of the drone device to navigate near the dynamic object. Sensor data collected by one or more sensors of a monitoring system of the property and that indicates a present status of the dynamic object is obtained by the drone device. A path to the particular location is determined by the drone device. The path to the particular location is finally navigated by the drone device."
Dynamic drone navigation,https://lens.org/073-188-667-490-673,2020,"Techniques are described for enabling a drone device to use a dynamic multi-dimensional spatial representation of an indoor property environment to improve autonomous navigation. In some implementations, an instruction to perform an action at a particular location of a property is received by a drone device. A spatial representation of the property that identifies a dynamic object is obtained by the drone device. The status of the dynamic object impacts an ability of the drone device to navigate near the dynamic object. Sensor data collected by one or more sensors of a monitoring system of the property and that indicates a present status of the dynamic object is obtained by the drone device. A path to the particular location is determined by the drone device. The path to the particular location is finally navigated by the drone device."
DYNAMIC DRONE NAVIGATION,https://lens.org/127-840-766-523-217,2018,"Techniques are described for enabling a drone device to use a dynamic multi-dimensional spatial representation of an indoor property environment to improve autonomous navigation. In some implementations, an instruction to perform an action at a particular location of a property is received by a drone device. A spatial representation of the property that identifies a dynamic object is obtained by the drone device. The status of the dynamic object impacts an ability of the drone device to navigate near the dynamic object. Sensor data collected by one or more sensors of a monitoring system of the property and that indicates a present status of the dynamic object is obtained by the drone device. A path to the particular location is determined by the drone device. The path to the particular location is finally navigated by the drone device."
Dynamic drone navigation,https://lens.org/115-461-654-981-410,2022,"Techniques are described for enabling a drone device to use a dynamic multi-dimensional spatial representation of an indoor property environment to improve autonomous navigation. In some implementations, an instruction to perform an action at a particular location of a property is received by a drone device. A spatial representation of the property that identifies a dynamic object is obtained by the drone device. The status of the dynamic object impacts an ability of the drone device to navigate near the dynamic object. Sensor data collected by one or more sensors of a monitoring system of the property and that indicates a present status of the dynamic object is obtained by the drone device. A path to the particular location is determined by the drone device. The path to the particular location is finally navigated by the drone device."
Dynamic drone navigation,https://lens.org/189-301-681-365-682,2019,"Techniques are described for enabling a drone device to use a dynamic multi-dimensional spatial representation of an indoor property environment to improve autonomous navigation. In some implementations, an instruction to perform an action at a particular location of a property is received by a drone device. A spatial representation of the property that identifies a dynamic object is obtained by the drone device. The status of the dynamic object impacts an ability of the drone device to navigate near the dynamic object. Sensor data collected by one or more sensors of a monitoring system of the property and that indicates a present status of the dynamic object is obtained by the drone device. A path to the particular location is determined by the drone device. The path to the particular location is finally navigated by the drone device."
DYNAMIC DRONE NAVIGATION,https://lens.org/122-934-890-502-937,2021,"Techniques are described for enabling a drone device to use a dynamic multi-dimensional spatial representation of an indoor property environment to improve autonomous navigation. In some implementations, an instruction to perform an action at a particular location of a property is received by a drone device. A spatial representation of the property that identifies a dynamic object is obtained by the drone device. The status of the dynamic object impacts an ability of the drone device to navigate near the dynamic object. Sensor data collected by one or more sensors of a monitoring system of the property and that indicates a present status of the dynamic object is obtained by the drone device. A path to the particular location is determined by the drone device. The path to the particular location is finally navigated by the drone device."
METHOD AND DEVICE FOR SETTING DRONE FLIGHT PATH,https://lens.org/013-862-056-742-371,2023,Provided are a method and device for setting a flight path reflecting an air space of a drone. The method may include receiving flight data collected by the drone; calculating a path error score indicating an extent of deviation of the drone from a planned flight path by comparing the received flight data with the planned flight path of the drone; adjusting the preset air space of the drone based on the path error score; and generating a new flight path of the drone based on the adjusted air space of the drone and a destination.
METHOD AND DEVICE FOR SETTING DRONE FLIGHT PATH,https://lens.org/013-862-056-742-371,2023,Provided are a method and device for setting a flight path reflecting an air space of a drone. The method may include receiving flight data collected by the drone; calculating a path error score indicating an extent of deviation of the drone from a planned flight path by comparing the received flight data with the planned flight path of the drone; adjusting the preset air space of the drone based on the path error score; and generating a new flight path of the drone based on the adjusted air space of the drone and a destination.
VOICE RECOGNITION METHOD OF ARTIFICIAL INTELLIGENCE ROBOT DEVICE,https://lens.org/016-418-793-540-081,2021,"A voice recognition method of an artificial intelligence robot device is disclosed. The voice recognition method includes collecting a first voice spoken by a user and determining whether a wake-up word of the artificial intelligence robot device is recognized based on the collected first voice; if the wake-up word is not recognized, sensing a location of the user using at least one sensor and determining whether the sensed location of the user is included in a set voice collection range; if the location of the user is included in the voice collection range, learning the first voice and determining a noise state of the first voice based on the learned first voice; collecting a second voice in an opposite direction of the location of the user according to a result of the determined noise state of the first voice; and extracting a feature value of a noise based on the second voice and removing the extracted feature value of the noise from the first voice to obtain the wake-up word. The artificial intelligence robot device may be associated with an artificial intelligence module, an unmanned aerial vehicle (UAV), a robot, an augmented reality (AR) device, a virtual reality (VR) device, devices related to 5G services, and the like."
Voice recognition method of artificial intelligence robot device,https://lens.org/165-392-950-466-015,2022,"A voice recognition method of an artificial intelligence robot device is disclosed. The voice recognition method includes collecting a first voice spoken by a user and determining whether a wake-up word of the artificial intelligence robot device is recognized based on the collected first voice; if the wake-up word is not recognized, sensing a location of the user using at least one sensor and determining whether the sensed location of the user is included in a set voice collection range; if the location of the user is included in the voice collection range, learning the first voice and determining a noise state of the first voice based on the learned first voice; collecting a second voice in an opposite direction of the location of the user according to a result of the determined noise state of the first voice; and extracting a feature value of a noise based on the second voice and removing the extracted feature value of the noise from the first voice to obtain the wake-up word. The artificial intelligence robot device may be associated with an artificial intelligence module, an unmanned aerial vehicle (UAV), a robot, an augmented reality (AR) device, a virtual reality (VR) device, devices related to 5G services, and the like."
Voice recognition method of artificial intelligence robot device,https://lens.org/165-392-950-466-015,2022,"A voice recognition method of an artificial intelligence robot device is disclosed. The voice recognition method includes collecting a first voice spoken by a user and determining whether a wake-up word of the artificial intelligence robot device is recognized based on the collected first voice; if the wake-up word is not recognized, sensing a location of the user using at least one sensor and determining whether the sensed location of the user is included in a set voice collection range; if the location of the user is included in the voice collection range, learning the first voice and determining a noise state of the first voice based on the learned first voice; collecting a second voice in an opposite direction of the location of the user according to a result of the determined noise state of the first voice; and extracting a feature value of a noise based on the second voice and removing the extracted feature value of the noise from the first voice to obtain the wake-up word. The artificial intelligence robot device may be associated with an artificial intelligence module, an unmanned aerial vehicle (UAV), a robot, an augmented reality (AR) device, a virtual reality (VR) device, devices related to 5G services, and the like."
Method and device for controlling and monitoring the surrounding areas of an unmanned aerial vehicle (UAV),https://lens.org/043-966-628-230-182,2014,"A method and a remote control for controlling and monitoring surrounding areas of an Unmanned Aerial Vehicle (UAV) by an operator with a remote control comprising a flight display are provided. The method and remote control provide an advantageously effect for the purposes of controlling and monitoring the surroundings of a UAV by combining the image captured by a UAV camera with a transparently overlaid positional and navigation map providing a perception enabling the operator to have a complete overall view of the situation, utilizing a common screen section of a flight display and thereby not having to shift eye view. Viewing images and positional and navigation information should not interfere with each other."
"UNMANNED AERIAL VEHICLE CONTROL METHODS AND SYSTEMS, AND UNMANNED AERIAL VEHICLES",https://lens.org/120-786-218-151-740,2021,"A method for controlling an unmanned aerial vehicle control includes: obtaining sensing information of the unmanned aerial vehicle, wherein the sensing information includes at least one of status information or environment information; obtaining at least one control mode; calling and/or invoking at least one execution device in the at least one control mode; generating a control instruction based on the at least one control mode and a sensing value of the sensing information; sending the control instruction to the at least one execution device; receiving, by the at least one execution device, the control instruction; and performing, by the at least one execution device, a corresponding action based on the control instruction. Intelligent outputting of the execution device may be achieved by intelligently integrating a plurality of sensing assemblies of the unmanned aerial vehicle and obtaining corresponding control modes."
"Method and device for controlling photography of unmanned aerialvehicle, andwearable device",https://lens.org/049-789-510-740-789,2020,"A method and apparatus for controlling photography of an unmanned aerial vehicle and a wearable device are disclosed. The method includes: acquiring position information of a target on the ground and a user, and calculating relative position between the target and the user by using the acquired position information to obtain relative position information between the target and the user; according to the relative position information, obtaining predetermined photographing position information matching the relative position information and corresponding to the user, and generating a movement control instruction, wherein the predetermined photographing position information comprises: straight line distance information between the unmanned aerial vehicle and the target, angle information between the unmanned aerial vehicle and the target, and height information between the unmanned aerial vehicle and the ground; and sending the movement control instruction to the unmanned aerial vehicle, and controlling the unmanned aerial vehicle to move and perform photography."
"METHOD AND DEVICE FOR CONTROLLING PHOTOGRAPHY OF UNMANNED AERIALVEHICLE, ANDWEARABLE DEVICE",https://lens.org/159-963-319-857-646,2019,"A method and apparatus for controlling photography of an unmanned aerial vehicle and a wearable device are disclosed. The method includes: acquiring position information of a target on the ground and a user, and calculating relative position between the target and the user by using the acquired position information to obtain relative position information between the target and the user; according to the relative position information, obtaining predetermined photographing position information matching the relative position information and corresponding to the user, and generating a movement control instruction, wherein the predetermined photographing position information comprises: straight line distance information between the unmanned aerial vehicle and the target, angle information between the unmanned aerial vehicle and the target, and height information between the unmanned aerial vehicle and the ground; and sending the movement control instruction to the unmanned aerial vehicle, and controlling the unmanned aerial vehicle to move and perform photography."
GROUND VEHICLE-LIKE CONTROL FOR REMOTE CONTROL AIRCRAFT,https://lens.org/145-726-617-641-328,2017,"A hand-held radio transmit controller for remotely controlling an aircraft, and a method for controlling a remote control aircraft offering ground vehicle-like control."
Ground vehicle-like control for remote control aircraft,https://lens.org/184-272-069-683-228,2016,"A hand-held radio transmit controller for remotely controlling an aircraft, and a method for controlling a remote control aircraft offering ground vehicle-like control."
GROUND VEHICLE-LIKE CONTROL FOR REMOTE CONTROL AIRCRAFT,https://lens.org/015-503-414-867-309,2015,"A hand-held radio transmit controller for remotely controlling an aircraft, and a method for controlling a remote control aircraft offering ground vehicle-like control."
GROUND VEHICLE-LIKE CONTROL FOR REMOTE CONTROL AIRCRAFT,https://lens.org/105-365-744-182-505,2015,"A hand-held radio transmit controller for remotely controlling an aircraft, and a method for controlling a remote control aircraft offering ground vehicle-like control."
Ground vehicle-like control for remote control aircraft,https://lens.org/197-482-824-261-561,2016,"A hand-held radio transmit controller for remotely controlling an aircraft, and a method for controlling a remote control aircraft offering ground vehicle-like control."
Ground vehicle-like control for remote control aircraft,https://lens.org/032-689-050-222-837,2018,"A hand-held radio transmit controller for remotely controlling an aircraft, and a method for controlling a remote control aircraft offering ground vehicle-like control."
DRONE OPTICAL GUIDANCE SYSTEM,https://lens.org/017-178-251-045-20X,2022,"A system for guiding a drone to an intended destination using a remote guidance system, independent of a global positioning system installed on the drone and independent of radio guidance. The system uses a two-way optical communication channel between the guidance system and the drone. The drone and the guidance system each have a light source emitting a beam of encoded light, such as a modulated laser beam, and having an extended field of illumination, and a detector receiving the impinging light beam. The guidance system can detect the angular location of the drone emission, and can transmit instructions optically to the drone, while the drone can receive flight path instructions from the guidance system. The drone can be launched from a position that is not in the line of sight of its intended destination and guided optically from the launch position to its intended target destination."
DRONE OPTICAL GUIDANCE SYSTEM,https://lens.org/020-732-726-844-827,2020,"A system for guiding a drone to an intended destination using a remote guidance system, independent of a global positioning system installed on the drone and independent of radio guidance. The system uses a two-way optical communication channel between the guidance system and the drone. The drone and the guidance system each have a light source emitting a beam of encoded light, such as a modulated laser beam, and having an extended field of illumination, and a detector receiving the impinging light beam. The guidance system can detect the angular location of the drone emission, and can transmit instructions optically to the drone, while the drone can receive flight path instructions from the guidance system. The drone can be launched from a position that is not in the line of sight of its intended destination and guided optically from the launch position to its intended target destination."
Drone,https://lens.org/009-124-920-145-301,2015,"The utility model discloses a drone, including the drone body, reach the remote control steering wheel with the communication of drone body, the drone body includes the hull, and installs in the receiving antenna of hull top, installs in inboard screw motor, rudder and the receipt control circuit of hull, the remote control steering wheel includes the disk body, and sets up steering wheel and emit antenna on the disk body, and sets up in the inboard transmission control circuit of disk body, transmission control circuit includes the 2.4G expelling plate, reaches direction potentiometre, forward back switch and the timing board be connected with 2.4G expelling plate electricity in proper order, direction potentiometre and steering wheel cooperation installation, emit antenna is connected with 2.4G expelling plate electricity. The utility model discloses a drone adopts 2.4G transmission receiving circuit, can not lead to the fact the mutual interference, through increasing regularly board, adopts digital display timing circuit, and the setting -up time carries out the bed hedgehopping in addition on present drone's basis at will, guarantees that its waterproof nature is good."
Unmanned aerial vehicles,https://lens.org/086-297-221-793-025,2020,A UAV 100 comprises a camera arrangement 120 configurable such that a field of view of a camera within the arrangement 120 includes airspace directly above the UAV 100. A lighting arrangement 130 is configurable in an upward-facing direction. A controller 110 is operable to cause the lighting arrangement 130 to illuminate an object in the airspace directly above the UAV 100. The arrangements are intended to reduce the risk of collision with objects that may be in the vicinity of the UAV especially when the UAV is taking off or landing and when the UAV is being operated autonomously.
Unmanned aerial vehicles,https://lens.org/178-852-549-270-530,2019,A UAV 100 comprises a camera arrangement 120 configurable such that a field of view of a camera within the arrangement 120 includes airspace directly above the UAV 100. A lighting arrangement 130 is configurable in an upward-facing direction. A controller 110 is operable to cause the lighting arrangement 130 to illuminate an object in the airspace directly above the UAV 100. The arrangements are intended to reduce the risk of collision with objects that may be in the vicinity of the UAV especially when the UAV is taking off or landing and when the UAV is being operated autonomously.
Remotely controlled aircraft,https://lens.org/105-686-196-219-537,2001,A remotely controlled aircraft has a motor controlled by a remotely located control unit having a flight string releasibly coupled at the aircraft. The aircraft receives a signal at the aircraft activating the remote control motor. The flight string is released at the aircraft and the flight direction of the aircraft is controlled by the remote control motor based on the received signal.
DRONE-BASED NEUTRON BACKSCATTER INSPECTION SYSTEM,https://lens.org/042-101-360-415-477,2023,"An apparatus for inspection of a target asset comprises a drone including a body, one or more propellers coupled to the body that enable the drone to fly, and an electronic control unit coupled to or positioned within the body of the drone and coupled to the one or more propellers. The apparatus also comprises a neutron emission source and a neutron detector that are both coupled to the body of the drone and also communicatively coupled to the electronic control unit. The electronic control unit is configured to control navigation of the drone to reach the target asset, to activate the neutron emission source to radiate neutrons onto the asset and to gather data from the neutron detector which detects neutrons backscattered from the asset, indicative of a state of the asset and materials contained within the asset."
Landing and delivery robot,https://lens.org/034-238-412-662-419,2022,"A delivery robot may provide an approach notification to enable people to understand and interpret actions by an unmanned aerial vehicle (UAV), such as an intention to land or deposit a package at a particular location. The delivery robot may include a display, lights, a speaker, and one or more sensors to enable the robot to provide information, barcodes, and text to the UAV and/or bystanders. The robot can provide final landing authority, and can wave-off the UAV, if an obstacle or person exists in the landing zone. The delivery robot can receive packages and (1) store them for retrieval (2) deliver them to the delivery location and/or (3) deliver them to an automated locker system. The delivery robot can temporarily close lanes or streets to enable a package to be delivered by UAV. The system may include a shelter to secure, maintain, and charge the delivery robot."
Rotor head of remotely-controlled helicopter and remotely-controlled helicopter,https://lens.org/169-352-978-244-405,2012,"A remote controlled helicopter of a single rotor type to be used indoors, having a flying operation that can be stabilized and operability that can be improved. The helicopter includes a center hub that supports a rotor head to a mainmast, and is divided into an upper center hub and a lower center hub. The upper and the lower center hubs are fixed around the shaft of the mainmast with a predetermined angle. A phase angle of a main rotor as an output with respect to an operation input from a swash plate becomes an acute angle, and the main rotor and a stabilizer are mounted to rotate with a phase difference of the acute angle."
SYSTEMS AND METHODS FOR GUIDING A TARGET,https://lens.org/086-856-182-655-559,2022,"A method of using an unmanned aerial vehicle (UAV) to guide a target includes receiving sensor data from one or more sensors of the UAV, detecting a behavior or an action of the target based on the received sensor data, and initiating a feedback to the target in response to the detected behavior or action for guiding the target while the UAV is in flight. The feedback includes at least one of an audio stimulus, a visual stimulus, an olfactory stimulus, or an attractor."
MULTIPOINT CABLE CAM SYSTEM AND METHOD,https://lens.org/087-584-742-812-795,2023,This disclosure describes a method of controlling an unmanned aerial vehicle (UAV). The steps of controlling include acquiring images with an image capture device of an unmanned aerial vehicle (UAV). The steps include analyzing the images to determine navigation information of the UAV with a vision-based navigation system. The steps include tracking a position of the UAV with the vision-based navigation system. The steps include controlling rotors of the UAV to prevent deviations in movement from a desired flight path or position of the UAV. The steps include limiting travel or flight of the UAV to a physical region determined by the desired flight path.
Controlling a group of drones for image capture,https://lens.org/021-919-082-701-842,2022,"Drones are controlled by one or more control devices and comprise a respective camera for image capture. The one or more control devices perform a method including obtaining projected flight paths of the drones, obtaining a projected camera setting of the respective camera, computing, as a function of the projected camera setting, a projected viewing frustum of the respective camera, defining, for the drones, projected time-space trajectories of no-fly zones based on the projected viewing frustum of the respective camera, analyzing the projected flight paths of the drones in relation to the projected time-space trajectories for detection of a violation of one or more of the no-fly zones, and setting an operative flight path and/or an operative camera setting for at least one selected drone to prevent the violation."
CONTROLLING A GROUP OF DRONES FOR IMAGE CAPTURE,https://lens.org/004-995-777-984-592,2020,"Drones are controlled by one or more control devices and comprise a respective camera for image capture. The one or more control devices perform a method including obtaining projected flight paths of the drones, obtaining a projected camera setting of the respective camera, computing, as a function of the projected camera setting, a projected viewing frustum of the respective camera, defining, for the drones, projected time-space trajectories of no-fly zones based on the projected viewing frustum of the respective camera, analyzing the projected flight paths of the drones in relation to the projected time-space trajectories for detection of a violation of one or more of the no-fly zones, and setting an operative flight path and/or an operative camera setting for at least one selected drone to prevent the violation."
Controlling a group of drones for image capture,https://lens.org/021-919-082-701-842,2022,"Drones are controlled by one or more control devices and comprise a respective camera for image capture. The one or more control devices perform a method including obtaining projected flight paths of the drones, obtaining a projected camera setting of the respective camera, computing, as a function of the projected camera setting, a projected viewing frustum of the respective camera, defining, for the drones, projected time-space trajectories of no-fly zones based on the projected viewing frustum of the respective camera, analyzing the projected flight paths of the drones in relation to the projected time-space trajectories for detection of a violation of one or more of the no-fly zones, and setting an operative flight path and/or an operative camera setting for at least one selected drone to prevent the violation."
Improved Multirotor Aircraft and Interface Device,https://lens.org/194-624-678-130-724,2020,"A remotely controlled multirotor aircraft for acquiring images and an interface device for controlling the aircraft, wherein the aircraft includes a receiving component adapted to receive a direction and/or orientation signal which can be transmitted by an interface device, wherein the direction and/or orientation signal defines a direction in which the aircraft must move and/or be oriented, and a flight control component adapted to control the attitude of the aircraft and configured for reading the direction and/or orientation signal, determining, on the basis of the direction and/or orientation signal, the direction in which the aircraft must move and/or be oriented, and generating a control signal adapted to make the aircraft take an attitude such as to make it move and/or be oriented in the predetermined direction."
DEVICE AND METHOD FOR CONTROLLING FLIGHT OF UNMANNED AERIAL VEHICLE,https://lens.org/108-076-260-856-815,2022,"A device and a method for controlling flight of an unmanned aerial vehicle are provided. To efficiently acquire environment information required to generate a navigation route of a vehicle, the device include a receiver that receives departure point information and destination information of a vehicle. A controller that generates a flight route corresponding to a travel route from a departure point to a destination of the vehicle based on at least one of a sensing range of a sensor mounted on the unmanned aerial vehicle, a flight available distance based on a fuel amount, and a communication available distance of a communication device mounted on the unmanned aerial vehicle, and operates the unmanned aerial vehicle to follow the generated flight route."
DEVICE AND METHOD FOR CONTROLLING FLIGHT OF UNMANNED AERIAL VEHICLE,https://lens.org/108-076-260-856-815,2022,"A device and a method for controlling flight of an unmanned aerial vehicle are provided. To efficiently acquire environment information required to generate a navigation route of a vehicle, the device include a receiver that receives departure point information and destination information of a vehicle. A controller that generates a flight route corresponding to a travel route from a departure point to a destination of the vehicle based on at least one of a sensing range of a sensor mounted on the unmanned aerial vehicle, a flight available distance based on a fuel amount, and a communication available distance of a communication device mounted on the unmanned aerial vehicle, and operates the unmanned aerial vehicle to follow the generated flight route."
POSITION-BASED ANTENNA SWITCHING,https://lens.org/074-186-344-269-269,2017,A method includes identifying an access point through which a drone can connect to a network based on a first location along a route of the drone. The method includes determining an orientation for an antenna of the drone based on the first location and configuring the antenna based on the orientation. The method also includes determining a second orientation based on a second location along the route.
ROBOTICALLY ASSISTED LAUNCH/CAPTURE PLATFORM FOR AN UNMANNED AIR VEHICLE,https://lens.org/110-576-556-522-331,2007,"A platform for launching and/or capturing an unmanned aerial vehicle (UAV), particularly a small UAV. The platform Includes a frame and a floor connected to an external support structure and a means for acquiring and tracking the UAV in flight. A robotic arm maneuvers the platform and facilitates capture of the approaching UAV. The platform is responsive to relative position information relayed from the UAV, and is capable of moving the capture means to the position and altitude of the approaching UAV. The captured UAV may be secured to or launched from the platform."
A fire detection system,https://lens.org/032-639-079-681-732,2017,"A fire detection system comprising: a system controller 160 having a digital processor and wireless communication in a local area within a building or warehouse; at least one drone 150, 151, 152 or unmanned aerial vehicle (UAV) having a body, at least one rotor, controller and wireless communication connection to system controller 160; at least one fire sensor, which may be a smoke detector mounted on the upstream side of a rotor axis, or a thermal imaging video recording camera mounted on a retractable armature on its underside. The drones 150, 151, 152 fly a flight path in a structure and sends fire alert information to the system controller 160. The system controller 160 may store reference maps and associated characteristic, such as temperature or flammability of materials, which may update dynamically from an inventory or ambient and weather conditions. RFID tags may be used to identify items. The system controller 160 may transmit the fire alarm to an external party with location, material and stage of fire data."
A VOICE ACTIVATED UNMANNED AERIAL VEHICLE (UAV) ASSISTANCE SYSTEM,https://lens.org/153-736-397-089-234,2018,"Described in detail herein is a voice activated UAV assistance system. A computing system can receive a request for assistance from a mobile device via one or more wireless access points. The computing system can estimate and track a current location of the mobile device based on an interaction between the mobile device and the one or more wireless access points. A UAV can receive, the request for assistance and the current location of the mobile device from the computing system. The UAV can autonomously navigate to the current location of the mobile device. The UAV can receive a voice input of a user associated with the mobile device via the microphone. The UAV can determine the voice input is associated with a set of physical objects disposed in the facility. The UAV can autonomously guiding the user to an object locations physical objects in the facility."
Unmanned aerial vehicle and method for controlling the unmanned aerial vehicle,https://lens.org/181-534-058-713-610,2013,"In a method for controlling an unmanned aerial vehicle (UAV), a digital image is obtained by an image capturing device of the UAV. The method detects an object in the digital image, determines a distance between the detected object and the UAV, and obtains a flight direction of the UAV if the distance is less than a preset value. The method further calculates a relative position and a relative angle between the detected object and the UAV, determines a flight limiting range of the UAV according to the relative position and the relative angle, and controls the flight direction of the UAV according to the flight limiting range."
UNMANNED AERIAL VEHICLE AND METHOD FOR CONTROLLING THE UNMANNED AERIAL VEHICLE,https://lens.org/166-667-510-729-092,2012,"In a method for controlling an unmanned aerial vehicle (UAV), a digital image is obtained by an image capturing device of the UAV. The method detects an object in the digital image, determines a distance between the detected object and the UAV, and obtains a flight direction of the UAV if the distance is less than a preset value. The method further calculates a relative position and a relative angle between the detected object and the UAV, determines a flight limiting range of the UAV according to the relative position and the relative angle, and controls the flight direction of the UAV according to the flight limiting range."
Postal cube,https://lens.org/195-477-370-766-848,2015,"A device configured to securely and automatically receive parcel is described. The device is equipped with a front door and an automatic top rolling door in order to accommodate parcel delivery via conventional parcel delivery personnel, or delivery via airlift from an unmanned aerial vehicle (UAV). The device is also equipped with a secure internet connection which facilitates communication between recipient and delivery personnel, as well as expedites the delivery confirmation process upon parcel delivery. Audio and video capture and transmission equipment on-board the device permit the recipient to remotely provide access to the device upon authentication of identity and/or credentials."
Drone Operated Umbrella,https://lens.org/020-811-987-498-243,2021,A drone operated umbrella is shown and described. The drone operated umbrella includes a waterproof canopy secured to a framing. The framing is secured to a drone housing. The drone housing has a plurality of arms which extend through the waterproof canopy. Each of the plurality of arms has a propeller rotatably attached to an end of the arm. The drone is comprised of at least one power source. The at least one power source is coupled to at least one motor. The power source is further coupled to a wireless transceiver.
UNMANNED AERIAL VEHICLE AND CONTROL DEVICE THEREOF,https://lens.org/127-037-536-279-527,2017,"A UAV control device includes: a control circuit board; a navigation module disposed on the control circuit board; a wireless communication module disposed on the control circuit board and coupled to the navigation module; a first antenna connection module disposed on the control circuit board and coupled to the wireless communication module, wherein the first antenna connection module is configured to connect with a first antenna; a positioning module disposed on the control circuit board and coupled to the navigation module; a second antenna connection module disposed on the control circuit board and coupled to the positioning module, wherein the second antenna connection module is configured to connect with a second antenna; a set of rotor driving modules and one or more camera connection modules disposed on the control circuit board and coupled to the navigation module."
METHODS AND APPARATUS FOR FACILITATING TASK EXECUTION USING A DRONE,https://lens.org/145-245-221-521-605,2020,"Methods, apparatus, systems, and articles of manufacture for facilitating task execution using a drone are disclosed. An example method includes accessing a result of a task performed by a task executor. The result includes one or more images of a task objective captured by the task executor. The result is validated based on a task definition provided by a task issuer. In response to the validation of the result indicating that the result complies with the task definition, the result is provided to the task issuer, and a reward is issued to the task executor."
METHODS AND APPARATUS FOR FACILITATING TASK EXECUTION USING A DRONE,https://lens.org/084-941-879-512-738,2019,"Methods, apparatus, systems, and articles of manufacture for facilitating task execution using a drone are disclosed. An example method includes accessing a result of a task performed by a task executor. The result includes one or more images of a task objective captured by the task executor. The result is validated based on a task definition provided by a task issuer. In response to the validation of the result indicating that the result complies with the task definition, the result is provided to the task issuer, and a reward is issued to the task executor."
A SELF-CONTROLLED UNMANNED AERIAL VEHICLE SYSTEM FOR FARMING APPLICATIONS AND ITS WORKING METHOD THEREOF,https://lens.org/002-770-826-457-087,2022,"The present invention generally relates to a self-controlled unmanned aerial vehicle system for farming applications and its working method thereof. The system comprises a cross-configured drone configured to takeoff upon receiving instructions from a ground control centre or a transmitter for flying in a complete angle, wherein butterfly net-wings are attached to proximal ends of the drone. A serial communication controller configured with a GPS (global positioning system) guidance unit to receive real-time coordinates from a pre-loaded trajectory to navigate said drone. A remote sensing camera positioned at distal end of said drone to monitor plants closely and take images/videos in a desired frame under stable flight condition configured to deliver image, audio, and video transmission to said control center and a prediction unit adapting deep learning approach to diagnose said images to detect diseases and other problems of plants and to control flight via a user interface, wherein said user interface comprises preloaded location coordinates and controlling data for complete controlling via a mission plan script feature which send threw a ground telemetry module to aircraft's air telemetry module to avoid human interference in flight control process. co C 2 . ,a & E 03 -! C L Z, 4-f. m f 4 -LL 2 . -l ir LoV O4 e jm r 4 -c A fo Z E-f CL4 ' m m1~ -- a Z, w c aC w -F 0 4 . LO u"
Unmanned aerial vehicle for situational awareness to first responders and alarm investigation,https://lens.org/142-555-683-079-633,2018,"A device, and method, for situational awareness of an emergency scene for first responders uses an unmanned aerial vehicle equipped with a sensor package in populated or otherwise restricted areas. The unmanned aerial vehicle is assigned to a control center for a designated incident while automatically tasking the unmanned aerial vehicle with the initiation of the incident response to autonomously proceed to the incident prior the control center taking active control of the unmanned aerial vehicle."
UNMANNED AERIAL VEHICLE FOR SITUATIONAL AWARENESS TO FIRST RESPONDERS AND ALARM INVESTIGATION,https://lens.org/028-276-472-114-481,2017,"A device, and method, for situational awareness of an emergency scene for first responders uses an unmanned aerial vehicle equipped with a sensor package in populated or otherwise restricted areas. The unmanned aerial vehicle is assigned to a control center for a designated incident while automatically tasking the unmanned aerial vehicle with the initiation of the incident response to autonomously proceed to the incident prior the control center taking active control of the unmanned aerial vehicle."
VOICE CONTROL,https://lens.org/108-494-927-337-020,2020,"A method of using speech recognition to control a utility, comprising: receiving a speech command spoken by a user and captured by at least one microphone; processing the speech command in order to automatically recognize and enact an intention of the user in each of a sequence of spoken elements in the command, the elements having an order from first to last in time, with at least one of the elements indicating an intention of the user to control the utility and a further one or more of the elements each specifying a respective parameter of the control intended by the user; and after the speaking of the first element in the voice command but prior to enacting the last element of the command, controlling illumination emitted by one or more luminaires of a lighting system to provide feedback to the user regarding the processing of the speech command, wherein the utility comprises one of: heating, air conditioning, ventilation, a window treatment, or play-out of media from an entertainment system."
VOICE CONTROL,https://lens.org/108-494-927-337-020,2020,"A method of using speech recognition to control a utility, comprising: receiving a speech command spoken by a user and captured by at least one microphone; processing the speech command in order to automatically recognize and enact an intention of the user in each of a sequence of spoken elements in the command, the elements having an order from first to last in time, with at least one of the elements indicating an intention of the user to control the utility and a further one or more of the elements each specifying a respective parameter of the control intended by the user; and after the speaking of the first element in the voice command but prior to enacting the last element of the command, controlling illumination emitted by one or more luminaires of a lighting system to provide feedback to the user regarding the processing of the speech command, wherein the utility comprises one of: heating, air conditioning, ventilation, a window treatment, or play-out of media from an entertainment system."
"Methods, systems and apparatus for voice control of a utility",https://lens.org/186-273-143-511-852,2021,"A method of using speech recognition to control a utility, comprising: receiving a speech command spoken by a user and captured by at least one microphone; processing the speech command in order to automatically recognize and enact an intention of the user in each of a sequence of spoken elements in the command, the elements having an order from first to last in time, with at least one of the elements indicating an intention of the user to control the utility and a further one or more of the elements each specifying a respective parameter of the control intended by the user; and after the speaking of the first element in the voice command but prior to enacting the last element of the command, controlling illumination emitted by one or more luminaires of a lighting system to provide feedback to the user regarding the processing of the speech command, wherein the utility comprises one of: heating, air conditioning, ventilation, a window treatment, or play-out of media from an entertainment system."
VOICE CONTROL,https://lens.org/052-127-635-304-046,2018,"A method of using speech recognition to control a utility, comprising: receiving a speech command spoken by a user and captured by at least one microphone; processing the speech command in order to automatically recognize and enact an intention of the user in each of a sequence of spoken elements in the command, the elements having an order from first to last in time, with at least one of the elements indicating an intention of the user to control the utility and a further one or more of the elements each specifying a respective parameter of the control intended by the user; and after the speaking of the first element in the voice command but prior to enacting the last element of the command, controlling illumination emitted by one or more luminaires of a lighting system to provide feedback to the user regarding the processing of the speech command, wherein the utility comprises one of: heating, air conditioning, ventilation, a window treatment, or play-out of media from an entertainment system."
METHOD AND APPARATUS FOR CABLE-DRIVEN ADAPTIVE VIBRATION CONTROL,https://lens.org/184-602-576-186-911,2019,"A vibration control system for an unmanned aerial vehicle (UAV) is disclosed. The system includes a base platform fixedly coupled to a UAV structure, a working platform coupled to the base platform by two or more cables at two or more connection points on the working platform, and two or more actuators positioned either on the base platform or the working platform, each actuator configured to receive a signal to adjust tension in a corresponding cable, wherein by adjusting tension in the two or more cables, natural frequency of the working platform can be adjusted in response to frequency of vibration experienced by the working platform in order to maintain a frequency ratio (FR) of the vibration frequency to the natural frequency at or above a predetermined value."
"Method performed in an autonomous unmanned aerial vehicle for enabling autonomous emergency assistance for a communication device registered in a regular cellular network, vehicle and device therefore",https://lens.org/143-711-169-487-704,2022,"A method for enabling autonomous emergency assistance for one or more communication device, CD, registered in a regular cellular network. The method is performed in an autonomous unmanned aerial vehicle, UAV, and comprises emulating a cellular network in a geographical region, wherein the UAV and the one or more CD are without connectivity with the regular cellular network, sending an information message in the geographical region, the message comprising an emergency response trigger, receiving an automatic emergency data response from the one or more CD in the geographical region, in response to the sent message, and determining an action based on the received automatic emergency data response. A CD, a UAV, a computer program and a computer program product are also presented."
"Method performed in an autonomous unmanned aerial vehicle for enabling autonomous emergency assistance for a communication device registered in a regular cellular network, vehicle and device therefore",https://lens.org/143-711-169-487-704,2022,"A method for enabling autonomous emergency assistance for one or more communication device, CD, registered in a regular cellular network. The method is performed in an autonomous unmanned aerial vehicle, UAV, and comprises emulating a cellular network in a geographical region, wherein the UAV and the one or more CD are without connectivity with the regular cellular network, sending an information message in the geographical region, the message comprising an emergency response trigger, receiving an automatic emergency data response from the one or more CD in the geographical region, in response to the sent message, and determining an action based on the received automatic emergency data response. A CD, a UAV, a computer program and a computer program product are also presented."
"Method performed in an autonomous unmanned aerial vehicle for enabling autonomous emergency assistance for a communication device registered in a regular cellular network, vehicle and device therefore",https://lens.org/143-711-169-487-704,2022,"A method for enabling autonomous emergency assistance for one or more communication device, CD, registered in a regular cellular network. The method is performed in an autonomous unmanned aerial vehicle, UAV, and comprises emulating a cellular network in a geographical region, wherein the UAV and the one or more CD are without connectivity with the regular cellular network, sending an information message in the geographical region, the message comprising an emergency response trigger, receiving an automatic emergency data response from the one or more CD in the geographical region, in response to the sent message, and determining an action based on the received automatic emergency data response. A CD, a UAV, a computer program and a computer program product are also presented."
"METHOD PERFORMED IN AN AUTONOMOUS UNMANNED AERIAL VEHICLE FOR ENABLING AUTONOMOUS EMERGENCY ASSISTANCE FOR A COMMUNICATION DEVICE REGISTERED IN A REGULAR CELLULAR NETWORK, VEHICLE AND DEVICE THEREFORE",https://lens.org/178-259-506-618-333,2020,"A method for enabling autonomous emergency assistance for one or more communication device, CD, registered in a regular cellular network. The method is performed in an autonomous unmanned aerial vehicle, UAV, and comprises emulating a cellular network in a geographical region, wherein the UAV and the one or more CD are without connectivity with the regular cellular network, sending an information message in the geographical region, the message comprising an emergency response trigger, receiving an automatic emergency data response from the one or more CD in the geographical region, in response to the sent message, and determining an action based on the received automatic emergency data response. A CD, a UAV, a computer program and a computer program product are also presented."
ROBOTIC DRONE,https://lens.org/158-952-072-059-553,2018,"Various aspects of the present disclosure are directed to autonomous drones for indoor environments. In some example embodiments, an autonomous drone may include a simultaneous localization and mapping system that facilitates autonomous flight of the drone within a warehouse. The simultaneous localization and mapping system may operate in conjunction with a vision-based navigation system that corrects for at least one of drift and yaw."
SYSTEMS AND METHODS FOR STARTING A SENSORLESS MOTOR,https://lens.org/005-194-684-030-155,2021,"Systems, devices, and methods for: an unmanned aerial vehicle (UAV); at least one sensorless motor comprising a set of windings and a rotor; at least one propeller connected to the at least one sensorless motor; a microcontroller in communication with the at least one sensorless motor, wherein the microcontroller is configured to: determine a rotation rate of the at least one propeller; determine a rotation direction of the at least one propeller; provide an output to stop the at least one propeller and provide an output to start the at least one propeller."
Systems and methods for starting a sensorless motor,https://lens.org/106-951-698-394-838,2022,"Systems, devices, and methods for: an unmanned aerial vehicle (UAV); at least one sensorless motor comprising a set of windings and a rotor; at least one propeller connected to the at least one sensorless motor; a microcontroller in communication with the at least one sensorless motor, wherein the microcontroller is configured to: determine a rotation rate of the at least one propeller; determine a rotation direction of the at least one propeller; provide an output to stop the at least one propeller and provide an output to start the at least one propeller."
Systems and methods for starting a sensorless motor,https://lens.org/106-951-698-394-838,2022,"Systems, devices, and methods for: an unmanned aerial vehicle (UAV); at least one sensorless motor comprising a set of windings and a rotor; at least one propeller connected to the at least one sensorless motor; a microcontroller in communication with the at least one sensorless motor, wherein the microcontroller is configured to: determine a rotation rate of the at least one propeller; determine a rotation direction of the at least one propeller; provide an output to stop the at least one propeller and provide an output to start the at least one propeller."
UAV PANORAMIC IMAGING,https://lens.org/120-791-916-925-869,2022,"A method includes in response to receiving an instruction for starting a panoramic mode, controlling an unmanned aerial vehicle (UAV) to hover at or near a predetermined location; while the UAV is hovering at or near the predetermined location, causing an image capturing device to capture a plurality of images by controlling a carrier that couples the image capturing device to the UAV to rotate the image capturing device about a first axis of the carrier; and stabilizing the image capturing device against motions with respect to a second axis or a third axis of the carrier while the image capturing device is rotating about the first axis of the carrier."
UAV PANORAMIC IMAGING,https://lens.org/120-791-916-925-869,2022,"A method includes in response to receiving an instruction for starting a panoramic mode, controlling an unmanned aerial vehicle (UAV) to hover at or near a predetermined location; while the UAV is hovering at or near the predetermined location, causing an image capturing device to capture a plurality of images by controlling a carrier that couples the image capturing device to the UAV to rotate the image capturing device about a first axis of the carrier; and stabilizing the image capturing device against motions with respect to a second axis or a third axis of the carrier while the image capturing device is rotating about the first axis of the carrier."
UAV AND UAV LANDING CONTROL DEVICE AND METHOD,https://lens.org/101-106-989-254-86X,2018,"The present invention relates to an unmanned aerial vehicle (UAV) (200), a UAV landing control device (100) and method. The UAV landing control method includes: receiving a trigger command; starting to monitor under control of the trigger command and outputting monitoring information based on a landing platform below the UAV (200), where the UAV (200) has one or more rotors; and determining whether to control the one or more rotors of the UAV (200) to stop rotation based on the monitoring information.
"
UAV AND UAV LANDING CONTROL DEVICE AND METHOD,https://lens.org/072-653-063-757-511,2017,"The present invention relates to an unmanned aerial vehicle (UAV) (200), a UAV landing control device (100) and method. The UAV landing control method includes: receiving a trigger command; starting to monitor under control of the trigger command and outputting monitoring information based on a landing platform below the UAV (200), where the UAV (200) has one or more rotors; and determining whether to control the one or more rotors of the UAV (200) to stop rotation based on the monitoring information."
System and method for countering drones,https://lens.org/174-121-850-355-256,2020,"In accordance with various embodiments of the disclosed subject matter, a system, apparatus and method is configured to receive/process radio frequency emanations of a potentially threatening drone to generate therefrom a human-recognizable audio signal characteristic of the drone (i.e., a voice of the drone) so that a warfighter may be alerted to the activity of the drone and respond accordingly."
Unmanned aerial vehicle approach notification,https://lens.org/135-668-596-563-651,2018,"An unmanned aerial vehicle (UAV) may provide an approach notification to enable people to understand and interpret actions by the UAV, such as an intention to land or deposit a package at a particular location. The UAV may communicate a specific intention of the UAV and/or communicate a request to a person. The UAV may monitor the person or data signals for a response from the person, such as movement of the person that indicates a response. The UAV may be equipped with hardware and/or software configured to provide notifications and/or exchange information with a person at or near a destination. The UAV may include lights, a speaker, and possibly a projector to enable the UAV to project information and/or text on a surface. The UAV may control a moveable mechanism to point toward the person, at an object, or in another direction."
TWO-WAY CONTROL OF IOT DEVICES USING AR CAMERA,https://lens.org/192-636-379-420-954,2023,"Systems and methods for controlling Internet of Things (IoT) devices using an augmented reality (AR) camera are provided. The system includes a sensor and a server that receives an input from the sensor and presents an AR object on the display of the AR camera device that corresponds to the input from the sensor. A response to the displayed AR object from a user of the AR camera device is used to select a command to send to one or more IoT devices to perform an action corresponding to the user response to the displayed AR object. In an example, an AR smoke object is overlayed on the AR camera display in response to a smoke detection signal from a smoke detector. In response to the user swiping or gesturing to push away the AR smoke object, a window opening command is sent to one or more IoT enabled windows."
TWO-WAY CONTROL OF IOT DEVICES USING AR CAMERA,https://lens.org/192-636-379-420-954,2023,"Systems and methods for controlling Internet of Things (IoT) devices using an augmented reality (AR) camera are provided. The system includes a sensor and a server that receives an input from the sensor and presents an AR object on the display of the AR camera device that corresponds to the input from the sensor. A response to the displayed AR object from a user of the AR camera device is used to select a command to send to one or more IoT devices to perform an action corresponding to the user response to the displayed AR object. In an example, an AR smoke object is overlayed on the AR camera display in response to a smoke detection signal from a smoke detector. In response to the user swiping or gesturing to push away the AR smoke object, a window opening command is sent to one or more IoT enabled windows."
System and method for preventing inadvertent loss of surveillance coverage for an unmanned aerial system (UAS),https://lens.org/054-762-605-063-70X,2022,"An unmanned aerial system (UAS) is disclosed. In embodiments, the UAS includes an unmanned aerial vehicle (UAV) and a controller communicatively coupled to the UAV. In embodiments, the UAS controller may be configured to: acquire a surveillance quality model for a prescribed flight path; generate one or more control signals configured to cause the UAV to perform a monitored flight along the prescribed flight path; acquire actual surveillance quality data during the monitored flight along the prescribed flight path; compare the actual surveillance quality data to the surveillance quality model; identify a surveillance quality deviation between the actual surveillance quality and the surveillance quality model; and generate one or more control signals configured to cause the UAV to perform one or more corrective actions or maneuvers if the identified surveillance quality deviation exceeds a threshold deviation value."
ELECTRONIC SPEED CONTROLLER ARM FOR VEHICLE,https://lens.org/136-558-357-290-675,2017,"According to various embodiments, an unmanned aerial vehicle (UAV) is provided. The UAV may include a motor controller. The UAV may further include a motor connected to the motor controller. The UAV may further include an arm connected between the motor controller and the motor. The UAV may further include a plurality of electronic speed control components integrated within the arm, the electronic speed control components configured to control the speed of the motor."
Electronic speed controller arm for vehicle,https://lens.org/051-496-110-569-129,2018,"According to various embodiments, an unmanned aerial vehicle (UAV) is provided. The UAV may include a motor controller. The UAV may further include a motor connected to the motor controller. The UAV may further include an arm connected between the motor controller and the motor. The UAV may further include a plurality of electronic speed control components integrated within the arm, the electronic speed control components configured to control the speed of the motor."
SYSTEMS AND METHOD FOR CONTROLLING ELECTRONIC DEVICES USING RADIO FREQUENCY IDENTIFICATION (RFID) DEVICES,https://lens.org/170-701-366-371-006,2015,A control system includes an RFID device and an RFID reader antenna configured to receive a signal from the RFID device. The signal is associated with a command. A transmitter transmits the command to an electronic device to operate the electronic device.
SYSTEMS AND METHOD FOR CONTROLLING ELECTRONIC DEVICES USING RADIO FREQUENCY IDENTIFICATION (RFID) DEVICES,https://lens.org/033-253-531-939-344,2017,A control system includes an RFID device and an RFID reader antenna configured to receive a signal from the RFID device. The signal is associated with a command. A transmitter transmits the command to an electronic device to operate the electronic device.
Systems and method for controlling electronic devices using radio frequency identification (RFID) devices,https://lens.org/034-398-913-721-379,2017,A control system includes an RFID device and an RFID reader antenna configured to receive a signal from the RFID device. The signal is associated with a command. A transmitter transmits the command to an electronic device to operate the electronic device.
Systems and method for controlling electronic devices using radio frequency identification (RFID) devices,https://lens.org/012-632-995-554-678,2016,A control system includes an RFID device and an RFID reader antenna configured to receive a signal from the RFID device. The signal is associated with a command. A transmitter transmits the command to an electronic device to operate the electronic device.
System and method for monitoring a moving vehicle,https://lens.org/032-525-375-854-866,2021,"A system includes a drone for monitoring a second vehicle moving along a route. The drone includes a processing unit, a speed control unit, a sensor system, and a communication module. The processing unit determines a braking distance for the second vehicle in response to a current speed of the second vehicle and determines a leading distance for the drone based on the braking distance. The speed control unit adjusts a guide speed and a position of the unmanned vehicle such that the drone travels ahead of the second vehicle by at least the leading distance. The sensor system detects a hazardous condition along the route ahead of the unmanned vehicle, and the communication module enables a wireless communication link between the drone and the second vehicle for notifying the second vehicle of the hazardous condition."
SYSTEM AND METHOD FOR MONITORING A MOVING VEHICLE,https://lens.org/192-811-023-478-130,2021,"A system includes a drone for monitoring a second vehicle moving along a route. The drone includes a processing unit, a speed control unit, a sensor system, and a communication module. The processing unit determines a braking distance for the second vehicle in response to a current speed of the second vehicle and determines a leading distance for the drone based on the braking distance. The speed control unit adjusts a guide speed and a position of the unmanned vehicle such that the drone travels ahead of the second vehicle by at least the leading distance. The sensor system detects a hazardous condition along the route ahead of the unmanned vehicle, and the communication module enables a wireless communication link between the drone and the second vehicle for notifying the second vehicle of the hazardous condition."
"SYSTEM, METHOD, AND PROGRAM FOR CONTROLLING DRONE",https://lens.org/011-175-563-656-331,2019,"The present invention is to provide a system, a method, and a program for controlling a drone to taken an image at high resolution if a predetermined condition is satisfied. The system includes an image acquisition unit that acquires an image taken by a drone; an image analysis unit that analyzes the acquired image; an extraction unit that extracts a point that satisfies a predetermined condition based on the result of the image analysis; a position coordinate acquisition unit that acquires the position coordinate of the extracted point; and a control unit that controls the drone to fly to the acquired position coordinate and take an image at a higher resolution than that of the analyzed image."
RENDERING METHOD FOR DRONE GAME,https://lens.org/146-067-792-964-597,2022,"A rendering method for a drone game includes the following steps. Firstly, a drone, a control device, a display device and an information node are provided. The drone includes a plurality of cameras. Then, a plurality of images acquired from the plurality of cameras of the drone are stitched as a panoramic image by the control device, and the panoramic image is displayed on the display device. Then, a ready signal is issued from the information node to the display device, and the control device accesses the drone game through an authorization of the information node in response to the ready signal. Then, at least one virtual object is generated in the panoramic image. Consequently, the sound, light and entertainment effects of the drone game are effectively enhanced, and the fun and diversity of the drone game are increased."
Rendering method for drone game,https://lens.org/156-087-857-559-877,2023,"A rendering method for a drone game includes the following steps. Firstly, a drone, a control device, a display device and an information node are provided. The drone includes a plurality of cameras. Then, a plurality of images acquired from the plurality of cameras of the drone are stitched as a panoramic image by the control device, and the panoramic image is displayed on the display device. Then, a ready signal is issued from the information node to the display device, and the control device accesses the drone game through an authorization of the information node in response to the ready signal. Then, at least one virtual object is generated in the panoramic image. Consequently, the sound, light and entertainment effects of the drone game are effectively enhanced, and the fun and diversity of the drone game are increased."
Rendering method for drone game,https://lens.org/156-087-857-559-877,2023,"A rendering method for a drone game includes the following steps. Firstly, a drone, a control device, a display device and an information node are provided. The drone includes a plurality of cameras. Then, a plurality of images acquired from the plurality of cameras of the drone are stitched as a panoramic image by the control device, and the panoramic image is displayed on the display device. Then, a ready signal is issued from the information node to the display device, and the control device accesses the drone game through an authorization of the information node in response to the ready signal. Then, at least one virtual object is generated in the panoramic image. Consequently, the sound, light and entertainment effects of the drone game are effectively enhanced, and the fun and diversity of the drone game are increased."
RENDERING METHOD FOR DRONE GAME,https://lens.org/146-067-792-964-597,2022,"A rendering method for a drone game includes the following steps. Firstly, a drone, a control device, a display device and an information node are provided. The drone includes a plurality of cameras. Then, a plurality of images acquired from the plurality of cameras of the drone are stitched as a panoramic image by the control device, and the panoramic image is displayed on the display device. Then, a ready signal is issued from the information node to the display device, and the control device accesses the drone game through an authorization of the information node in response to the ready signal. Then, at least one virtual object is generated in the panoramic image. Consequently, the sound, light and entertainment effects of the drone game are effectively enhanced, and the fun and diversity of the drone game are increased."
RENDERING METHOD FOR DRONE GAME,https://lens.org/146-067-792-964-597,2022,"A rendering method for a drone game includes the following steps. Firstly, a drone, a control device, a display device and an information node are provided. The drone includes a plurality of cameras. Then, a plurality of images acquired from the plurality of cameras of the drone are stitched as a panoramic image by the control device, and the panoramic image is displayed on the display device. Then, a ready signal is issued from the information node to the display device, and the control device accesses the drone game through an authorization of the information node in response to the ready signal. Then, at least one virtual object is generated in the panoramic image. Consequently, the sound, light and entertainment effects of the drone game are effectively enhanced, and the fun and diversity of the drone game are increased."
Drone airborne monitoring system,https://lens.org/052-759-342-805-379,2015,"The invention discloses a drone monitoring system. An emergency buffer parachute is installed on the top of a drone, and semicircular propeller protectors are additionally installed between pairs of upper propellers and lower propellers respectively. Two vidicons and four 100-watt LED lamps are mounted on a mounting rod. Two angle adjustable high-definition mini-type cameras are installed at the lower portion of the drone. An annular drone base is installed at the bottom of the drone. A launching platform frame located on the ground is connected with the drone in a butt joint mode. A power source and video line rolling frame is installed at the lower portion of the launching platform frame, and the inlet end of a power line on the power source and video line rolling frame is connected with a direct current voltage regulator. The drone airborne monitoring system is further provided with an induction motor and a remote control box. The drone airborne monitoring system has a very good lighting function, and shot pictures are clear; by means of a ground power supplying system and a video synchronous downloading system, monitoring can be carried out for a long time; the induction motor device is arranged, and the motor can automatically induct the height of the drone and automatically rotate to take up and pay off the wire, and the wire is reasonably utilized to the maximum extent."
Four rotor crafts of wireless video monitoring and many PID regulation control gesture,https://lens.org/185-074-139-892-658,2015,"The utility model provides a four rotor crafts of wireless video monitoring and many PID regulation control gesture, include: electrical power generating system, video monitor system, remote control system, motion control system, four brushless DC motor speed regulators and four brushless DC motor. The advantage does: being strong four rotor crafts of stablizing of an interference killing feature, simultaneously, expanding taking photo by plane and the local record of four rotor crafts, open intelligent robot's research and development platform can be regarded as to this aircraft, also can be used to the research and the teaching in fields such as control theory, robotechnology."
Multi function photo electro acoustic ions drone,https://lens.org/082-668-154-610-624,2018,"An autonomous drone integrated with wide bandwidth, high energy acoustic wave generators sent to evict and eradicate agricultural pests within a patrolling area. The drone hovering close to a plant bombards its leaves and fruits with high energy acoustic waves via frequency and tone determined by an onboard synthesizer through acoustic power amplified to drive the sideways and bottom mounted acoustic wave generators. Agricultural pests such as caterpillar, beetle and the like are bombarded with powerful acoustic waves causing their bodies to vigorously vibrate and resonate with synthesizer frequency to dislodge or kill the pests. Other insects such as moths are forced airborne by a propeller's strong downdraft and are electrocuted by integrated high voltage screens. Inside a hotel room, the drone hovers close to a surface of a bedding mattress, bombarding the surfaces with powerful acoustic waves tuned to frequencies that cause bed bugs to resonate and die."
Multi Function Photo Electro Acoustic Ions Drone,https://lens.org/135-583-038-183-715,2018,"An autonomous drone integrated with wide bandwidth, high energy acoustic wave generators sent to evict and eradicate agricultural pests within a patrolling area. The drone hovering close to a plant bombards its leaves and fruits with high energy acoustic waves via frequency and tone determined by an onboard synthesizer through acoustic power amplified to drive the sideways and bottom mounted acoustic wave generators. Agricultural pests such as caterpillar, beetle and the like are bombarded with powerful acoustic waves causing their bodies to vigorously vibrate and resonate with synthesizer frequency to dislodge or kill the pests. Other insects such as moths are forced airborne by a propeller's strong downdraft and are electrocuted by integrated high voltage screens. Inside a hotel room, the drone hovers close to a surface of a bedding mattress, bombarding the surfaces with powerful acoustic waves tuned to frequencies that cause bed bugs to resonate and die."
MULTI-FUNCTION PHOTO ELECTRO ACOUSTIC IONS DRONE,https://lens.org/151-236-329-672-23X,2018,"An autonomous drone integrated with wide bandwidth, high energy acoustic wave generators sent to evict and eradicate agricultural pests within a patrolling area. The drone hovering close to a plant bombards its leaves and fruits with high energy acoustic waves via frequency and tone determined by an onboard synthesizer through acoustic power amplified to drive the sideways and bottom mounted acoustic wave generators. Agricultural pests such as caterpillar, beetle and the like are bombarded with powerful acoustic waves causing their bodies to vigorously vibrate and resonate with synthesizer frequency to dislodge or kill the pests. Other insects such as moths are forced airborne by a propeller's strong downdraft and are electrocuted by integrated high voltage screens. Inside a hotel room, the drone hovers close to a surface of a bedding mattress, bombarding the surfaces with powerful acoustic waves tuned to frequencies that cause bed bugs to resonate and die."
APPARATUS FOR REMOTE SENSING USING DRONE,https://lens.org/196-447-008-205-967,2017,"Disclosed herein is an apparatus for remote sensing using a drone. An apparatus for remote sensing using a drone includes: a drone station which communicates with a server through a satellite and includes a containment portion at an upper portion and a post portion at a lower portion; and a drone which is contained in a containment portion of the drone station and communicates with the drone station, and further includes: a solar panel which is installed at the drone station and converts solar energy into electric energy; an capacitor which is installed at the drone station and stores electric energy generated by the solar panel; and a charging container access deck which is installed at the containment portion and charges the drone."
Wild-life surveillance and protection,https://lens.org/128-816-441-109-583,2020,"At least two unmanned air vehicle (UAV) drones are deployed to a target location, the target location being associated with a species. At least one robot is deployed to the target location, wherein the at least one robot mimics an appearance of the species. Sensor data is collected from the at least two UAV drones. The sensor data is analyzed to determine whether a threat condition exists. In response to a determination of the threat condition, the at least one robot is repositioned to counteract the threat condition."
RADIO BEACON SYSTEM,https://lens.org/033-272-922-106-335,2020,"A radio beacon system configured to assist autonomous flight of one or more unmanned aerial vehicles (UAVs), wherein the radio beacon system comprises:a drone device (200), configured to be installed on an UAV and including a radio transceiver, anda radio beacon device (100), configured to be installed on ground and including N antenna arrays (110, 120) with N2, one or more radio transceivers configured to communicate with the radio transceiver of the drone device (200), and at least one processing unit (130), wherein each antenna array (110, 120) has M antenna elements (115, 125) with M2 associated to respective beamforming electronic weights w(n, m), with n ranging from 1 to N and m ranging from 1 to M, wherein said at least one processing unit (130) is configured to perform an adaptive beamforming method for assisting autonomous flight of the UAV."
AUTONOMOUS CARGO DELIVERY SYSTEM,https://lens.org/023-213-422-813-110,2019,"An autonomous aerial vehicle includes a flight controller and a mission manager in communication with the flight controller. The flight controller is configured to navigate the autonomous aerial vehicle. The mission manager is configured to receive mission data. The mission data identifies both a landing zone and a designated touchdown zone located within the landing zone. The mission manager is further configured to provide flight control data to the flight controller. The flight control data causes the flight controller to navigate the autonomous aerial vehicle to a predetermined distance from the landing zone. The mission manager is further configured to determine, subsequent to the autonomous aerial vehicle reaching the predetermined distance, whether landing at the designated touchdown zone is feasible. The mission manager is further configured, in response to determining that landing at the designated touchdown zone is not feasible, to identify an alternate touchdown zone located within the landing zone for landing the autonomous aerial vehicle."
Autonomous cargo delivery system,https://lens.org/109-212-870-691-181,2020,"An autonomous aerial vehicle includes a flight controller and a mission manager in communication with the flight controller. The flight controller is configured to navigate the autonomous aerial vehicle. The mission manager is configured to receive mission data. The mission data identifies both a landing zone and a designated touchdown zone located within the landing zone. The mission manager is further configured to provide flight control data to the flight controller. The flight control data causes the flight controller to navigate the autonomous aerial vehicle to a predetermined distance from the landing zone. The mission manager is further configured to determine, subsequent to the autonomous aerial vehicle reaching the predetermined distance, whether landing at the designated touchdown zone is feasible. The mission manager is further configured, in response to determining that landing at the designated touchdown zone is not feasible, to identify an alternate touchdown zone located within the landing zone for landing the autonomous aerial vehicle."
Adjustable antenna system for unmanned aerial vehicle,https://lens.org/060-728-768-994-144,2020,"An antenna system for an unmanned aerial vehicle (UAV) includes one or more antennas, a reflector, and a control system. The control system is configured to determine a density of antenna towers near the UAV, determine a position for an active antenna of the one or more antennas based on the density, and adjust the active antenna to the determined position. In some embodiments, the antenna system further includes one or more switches, each of the one or more antennas is a different distance from the reflector, and the switches are used to adjust the active antenna to the determined position by selecting a one of the one or more antennas closest to the determined position as the active antenna. In some embodiments, the antenna system further includes an actuator and the active antenna is moved to the determined position using the actuator."
Adjustable antenna system for unmanned aerial vehicle,https://lens.org/164-191-939-806-544,2023,"An antenna system for an unmanned aerial vehicle (UAV) includes one or more antennas, a reflector, and a control system. The control system is configured to determine a density of antenna towers near the UAV, determine a position for an active antenna of the one or more antennas based on the density, and adjust the active antenna to the determined position. In some embodiments, the antenna system further includes one or more switches, each of the one or more antennas is a different distance from the reflector, and the switches are used to adjust the active antenna to the determined position by selecting a one of the one or more antennas closest to the determined position as the active antenna. In some embodiments, the antenna system further includes an actuator and the active antenna is moved to the determined position using the actuator."
ADJUSTABLE ANTENNA SYSTEM FOR UNMANNED AERIAL VEHICLE,https://lens.org/055-034-743-094-046,2019,"An antenna system for an unmanned aerial vehicle (UAV) includes one or more antennas, a reflector, and a control system. The control system is configured to determine a density of antenna towers near the UAV, determine a position for an active antenna of the one or more antennas based on the density, and adjust the active antenna to the determined position. In some embodiments, the antenna system further includes one or more switches, each of the one or more antennas is a different distance from the reflector, and the switches are used to adjust the active antenna to the determined position by selecting a one of the one or more antennas closest to the determined position as the active antenna. In some embodiments, the antenna system further includes an actuator and the active antenna is moved to the determined position using the actuator."
Adjustable antenna system for unmanned aerial vehicle,https://lens.org/164-191-939-806-544,2023,"An antenna system for an unmanned aerial vehicle (UAV) includes one or more antennas, a reflector, and a control system. The control system is configured to determine a density of antenna towers near the UAV, determine a position for an active antenna of the one or more antennas based on the density, and adjust the active antenna to the determined position. In some embodiments, the antenna system further includes one or more switches, each of the one or more antennas is a different distance from the reflector, and the switches are used to adjust the active antenna to the determined position by selecting a one of the one or more antennas closest to the determined position as the active antenna. In some embodiments, the antenna system further includes an actuator and the active antenna is moved to the determined position using the actuator."
ADJUSTABLE ANTENNA SYSTEM FOR UNMANNED AERIAL VEHICLE,https://lens.org/062-881-697-238-547,2021,"An antenna system for an unmanned aerial vehicle (UAV) includes one or more antennas, a reflector, and a control system. The control system is configured to determine a density of antenna towers near the UAV, determine a position for an active antenna of the one or more antennas based on the density, and adjust the active antenna to the determined position. In some embodiments, the antenna system further includes one or more switches, each of the one or more antennas is a different distance from the reflector, and the switches are used to adjust the active antenna to the determined position by selecting a one of the one or more antennas closest to the determined position as the active antenna. In some embodiments, the antenna system further includes an actuator and the active antenna is moved to the determined position using the actuator."
Fusion of images from drone and vehicle,https://lens.org/185-165-946-564-830,2018,"A driver assistance system (100) comprises a drone (110), which communicates wirelessly with a communication unit (120), and a control unit (130) which is configured to provide information to a driver of a vehicle based on information acquired by the drone about a vicinity of the vehicle. The system may comprise a camera (140, 150) for each of the drone and vehicle, and the control unit may generate a fused surround view image using the image data obtained by these cameras (Fig. 2). The fused image may be generated in real time and as the drone flies. The image data may be combined to give a three-dimensional image. The control unit may be configured to change the perspective of the fused image, or may be configured to select a sub-set of the image data received from the drone for data fusion."
Intelligent robot capable of voice recognition and tracking,https://lens.org/189-254-328-741-115,2020,"The utility model discloses an intelligent robot capable of voice recognition and tracking. The unmanned aerial vehicle comprises a shell, four sets of rotor wing frames, a pickup, a monitoring probe,a circuit board, a CCD chip, a CPU, a voice recognition chip and a wireless signal module, wherein the CCD chip, the CPU, the voice recognition chip and the wireless signal module are installed on the surface of the circuit board in a spot welding mode. Four corners of the shell are connected with the rotor frames through electric rotating shafts; according to the utility model, the rotors and the driving wheels are matched for use; air and ground working state conversion is realized through the control of the CPU; a tracking function is realized by using two modes; meanwhile, the rotor wingframe is closed into the limiting groove under the driving of the electric rotating shaft; the whole occupied area of the robot is reduced, under two different working states, the lifting mechanism isused for achieving up-down telescopic use of the pickup, the pickup is driven to automatically push the opening and closing plate to conduct one-way pickup work, due to the closing state of the opening and closing plate, noise interference in the direction of the other face is avoided through the pickup opening in the other face, and practicability is high."
Tacticle unmanned aerial vehicle,https://lens.org/083-601-568-195-168,2020,"An unmanned vehicle capable of operating in harsh environments is disclosed. The unmanned vehicle includes an aerial platform, a piloting system supported by the aerial platform, a medium source supported by the aerial platform, and a control system having a processor running computer executable code that actuates the medium source to emit a medium away from the aerial vehicle with an intensity sufficient to disorient a subject when the medium interacts with an exteroceptive sense of a subject."
TACTICAL UNMANNED AERIAL VEHICLE,https://lens.org/091-265-893-800-616,2020,"An unmanned vehicle capable of operating in harsh environments is disclosed. The unmanned vehicle includes an aerial platform, a piloting system supported by the aerial platform, a medium source supported by the aerial platform, and a control system having a processor running computer executable code that actuates the medium source to emit a medium away from the aerial vehicle with an intensity sufficient to disorient a subject when the medium interacts with an exteroceptive sense of a subject."
Tactical unmanned aerial vehicle,https://lens.org/097-671-394-914-055,2022,"An unmanned vehicle capable of operating in harsh environments is disclosed. The unmanned vehicle includes an aerial platform, a piloting system supported by the aerial platform, a medium source supported by the aerial platform, and a control system having a processor running computer executable code that actuates the medium source to emit a medium away from the aerial vehicle with an intensity sufficient to disorient a subject when the medium interacts with an exteroceptive sense of a subject."
TACTICAL UNMANNED AERIAL VEHICLE,https://lens.org/051-105-108-814-008,2019,"An unmanned vehicle capable of operating in harsh environments is disclosed. The unmanned vehicle includes an aerial platform, a piloting system supported by the aerial platform, a medium source supported by the aerial platform, and a control system having a processor running computer executable code that actuates the medium source to emit a medium away from the aerial vehicle with an intensity sufficient to disorient a subject when the medium interacts with an exteroceptive sense of a subject."
Remote Control Devices and Methods,https://lens.org/177-541-160-244-17X,2010,"A remote control device comprising a motion detector consisting of a single accelerometer, means for receiving data from the motion detector and mapping the received motion detector data to at least one user instruction, and means for transmitting a signal indicative of the at least one user instruction."
Remote control devices and methods,https://lens.org/061-603-191-646-600,2013,"A remote control device comprising a motion detector consisting of a single accelerometer, means for receiving data from the motion detector and mapping the received motion detector data to at least one user instruction, and means for transmitting a signal indicative of the at least one user instruction."
INTELLIGENT ROBOT DEVICE,https://lens.org/030-603-090-430-152,2021,"An intelligent robot device is disclosed. The intelligent robot device includes a body, a communication module, a photographing module, a controller, and a travel driver and can provide the best airport services to airport users by accessing the airport users while searching an optimal path capable of efficiently avoiding an obstacle in an airport. The intelligent robot device can be associated with an artificial intelligence module, unmanned aerial vehicle (UAV), a robot, an augmented reality (AR) device, a virtual reality (VR) device, devices related to 5G services, and the like."
FLYING TOYS,https://lens.org/126-694-226-533-300,2020,"In one embodiment there is provided a flying toy having a figurine positioned on top of a housing with a two propeller sets and flybars rotating in directions to create stable flight. A controller is provided to control the motor and flight conditions, which may include predetermine flight instructions and lights based on IR detected signaling."
"SYSTEM, METHOD AND COMPUTER PROGRAM PRODUCT FOR DRONE SWARM ROAD LIGHTING",https://lens.org/078-042-656-324-83X,2018,"A drone road lighting method, system, and computer program product, includes detecting a need for illumination near a road and deploying a drone to perform an illumination action based on the detected need."
Detecting an illumination need,https://lens.org/108-640-209-058-433,2019,"A drone road lighting method, system, and computer program product, includes detecting a need for illumination near a road and deploying a drone to perform an illumination action based on the detected need."
INVERTED DRONE,https://lens.org/066-120-072-461-668,2016,"The present invention is in the field of a rotorcraft in which lift and thrust can be supplied by rotors, and specifically relates to a drone (100). The drone comprises a camera (15) which is used for making optical and/or sound recordings, especially during (live) events, such as concerts, gatherings, dance events, etc. The camera gives an impression of the events and is capable of recording specific details thereof, such as individual people."
Unmanned aerial vehicles,https://lens.org/134-785-903-279-818,2019,"The method comprises causing an unmanned aerial vehicle (UAV) 110 to fly to a vehicle 120, causing the UAV to physically engage with the vehicle such that the UAV 110 is transported by the vehicle when the vehicle moves, and causing the UAV to disengage and fly away from the vehicle. The method is performed whilst the UAV is operating in an autonomous mode by a controller 140 comprised in the UAV. The UAV provides energy to the vehicle whilst the UAV is physically engaged with the vehicle, and the UAV receives energy from the vehicle, whilst physically engaged with the vehicle in order to charge the battery of the UAV. Also provided is a UAV configured to perform the method, a controller configured to perform the method, and a computer programme arranged to perform the method. The method may further comprise a step of determining that the UAV is authorised to be transported by the vehicle by way of an authorisation token. The UAV may have an operating range 190 and a target flight destination 180 is outside the operating range."
"System, Method and Apparatus for a Monitoring Drone",https://lens.org/177-112-100-196-414,2020,"A monitoring drone method, apparatus and system. The monitoring drone includes an image capture device for taking one or more images, a charge module for powering the monitoring drone, and a move module for allowing the monitoring drone to move about a shelf wherein the image capturing device captures images as the monitoring drone moves about the shelf to produce a virtual stereoscopic vision."
"SYSTEM, METHOD AND APPARATUS FOR A MONITORING DRONE",https://lens.org/181-537-350-540-984,2020,"A monitoring drone method, apparatus and system. The monitoring drone includes an image capture device for taking one or more images, a charge module for powering the monitoring drone, and a move module for allowing the monitoring drone to move about a shelf wherein the image capturing device captures images as the monitoring drone moves about the shelf to produce a virtual stereoscopic vision."
"SYSTEM, METHOD AND APPARATUS FOR A MONITORING DRONE",https://lens.org/072-066-718-696-048,2019,"A monitoring drone method, apparatus and system. The monitoring drone includes an image capture device for taking one or more images, a charge module for powering the monitoring drone, and a move module for allowing the monitoring drone to move about a shelf wherein the image capturing device captures images as the monitoring drone moves about the shelf to produce a virtual stereoscopic vision."
"System, method and apparatus for a monitoring drone",https://lens.org/181-679-132-485-327,2020,"A monitoring drone method, apparatus and system. The monitoring drone includes an image capture device for taking one or more images, a charge module for powering the monitoring drone, and a move module for allowing the monitoring drone to move about a shelf wherein the image capturing device captures images as the monitoring drone moves about the shelf to produce a virtual stereoscopic vision."
"SYSTEM, METHOD AND APPARATUS FOR A MONITORING DRONE",https://lens.org/181-537-350-540-984,2020,"A monitoring drone method, apparatus and system. The monitoring drone includes an image capture device for taking one or more images, a charge module for powering the monitoring drone, and a move module for allowing the monitoring drone to move about a shelf wherein the image capturing device captures images as the monitoring drone moves about the shelf to produce a virtual stereoscopic vision."
"METHOD FOR INDUCING AN AUTONOMOUS BEHAVIOR INTO AN UNMANNED VEHICLE, AND A COMMUNICATION UNIT FOR USE IN SUCH A METHOD",https://lens.org/100-720-122-249-666,2021,A communication unit is adapted for being mounted on an unmanned vehicle. A corresponding method is provided for inducing an autonomous behavior into the unmanned vehicle.
METHODS AND APPARATUSES RELATED TO TRANSFORMABLE REMOTE CONTROLLERS,https://lens.org/005-906-618-708-231,2018,"A remote controller for operating an unmanned aerial vehicle (UAV) can comprise a user input component configured to receive user input from a user; and a communication unit for at least one of transmitting and receiving data between the remote controller and the UAV or a load carried by the UAV. The communication unit can be configured to transmit an instruction to operate at least one of the UAV and the load based on the user input. The remote controller can be configured to transform between (1) a single-hand operation mode that enables the user to control an operation of both the UAV and the load using the user input from a single hand while being held by the single hand, and (2) a multi-hand operation mode that enables the user to control the operation of both the UAV and the load using at least two hands while holding the remote controller using the at least two hands."
TARGET MARKING DEVICE AND TARGET TRACKING AND PROCESSING SYSTEMS COMPRISING SUCH A DEVICE,https://lens.org/186-557-390-685-571,2022,"The target marking device (1) comprises a drone (2) which is provided with at least one transmitter (4), the transmitter (4) comprising an activation element (10) for activating it so that it transmits at a given time a signal (S) which represents a position information item, the transmitter (4) being configured to transmit at least one of the following signals: an infrared signal, a light signal, a sound signal, a signal generated by a chemical substance, the target marking device (1) being part of a target tracking system (6) and/or a target processing system which is provided with movable machinery (7)."
TARGET MARKING DEVICE AND TARGET TRACKING AND PROCESSING SYSTEMS COMPRISING SUCH A DEVICE,https://lens.org/186-557-390-685-571,2022,"The target marking device (1) comprises a drone (2) which is provided with at least one transmitter (4), the transmitter (4) comprising an activation element (10) for activating it so that it transmits at a given time a signal (S) which represents a position information item, the transmitter (4) being configured to transmit at least one of the following signals: an infrared signal, a light signal, a sound signal, a signal generated by a chemical substance, the target marking device (1) being part of a target tracking system (6) and/or a target processing system which is provided with movable machinery (7)."
IMPROVEMENTS IN AND RELATING TO A GUIDED WEAPON,https://lens.org/041-330-097-362-752,2022,"Disclosed is an unmanned Aerial Vehicle, UAV, comprising a plurality of rotors, a camera and an explosive payload, wherein the UAV comprises a generally elongate body, and the camera and the payload are arranged substantially in-line within the body."
IMPROVEMENTS IN AND RELATING TO A GUIDED WEAPON,https://lens.org/041-330-097-362-752,2022,"Disclosed is an unmanned Aerial Vehicle, UAV, comprising a plurality of rotors, a camera and an explosive payload, wherein the UAV comprises a generally elongate body, and the camera and the payload are arranged substantially in-line within the body."
RADIO BEACON SYSTEM,https://lens.org/159-780-792-110-714,2018,"A radio beacon system configured to assist autonomous flight of one or more unmanned aerial vehicles (UAVs), wherein the radio beacon system comprises: - a drone device (200), configured to be installed on an UAV and including a radio transceiver, and - a radio beacon device (100), configured to be installed on ground and including N antenna arrays (110, 120) with N  2, one or more radio transceivers configured to communicate with the radio transceiver of the drone device (200), and at least one processing unit (130), wherein each antenna array (110, 120) has M antenna elements (115, 125) with M  2 associated to respective beamforming electronic weights w(n, m), with n ranging from 1 to N and m ranging from 1 to M, wherein said at least one processing unit (130) is configured to perform an adaptive beamforming method for assisting autonomous flight of the UAV."
SELF-PROPELLED LUGGAGE,https://lens.org/086-858-951-398-454,2014,"A container with a propelling system that can be controlled remotely, and a sensor system to help to navigate the container."
Remote control methods and systems,https://lens.org/018-662-406-390-739,2019,"An unmanned aerial vehicle (UAV) includes a first communication module, a second communication module, and one or more processors. The first communication module is configured to directly receive control data from a controlling terminal via a first communication link and the control data is used to control operations of the UAV. The second communication module is configured to transmit feedback data to a monitoring terminal via a second communication link. The monitoring terminal is located remotely from the UAV. The one or more processors are, individually or collectively, configured to terminate and reactivate the first wireless communication link based on one or more predetermined criteria."
REMOTE CONTROL METHODS AND SYSTEMS,https://lens.org/179-899-172-657-173,2018,"An unmanned aerial vehicle (UAV) includes a first communication module, a second communication module, and one or more processors. The first communication module is configured to directly receive control data from a controlling terminal via a first communication link and the control data is used to control operations of the UAV. The second communication module is configured to transmit feedback data to a monitoring terminal via a second communication link. The monitoring terminal is located remotely from the UAV. The one or more processors are, individually or collectively, configured to terminate and reactivate the first wireless communication link based on one or more predetermined criteria."
SYSTEMS AND METHODS FOR LANDING A DRONE ON A MOVING BASE,https://lens.org/033-110-311-060-399,2018,"A drone is described. The drone includes a depth sensor configured to provide information for determining a distance between the drone and a moving base. The drone also includes a processor configured to control a computer vision tracking algorithm based on the distance, and to control drone movement based on the computer vision tracking algorithm. A vehicle is also described. The vehicle includes a depth sensor configured to provide information for determining a distance between a drone and the vehicle. The vehicle also includes a processor configured to control a computer vision tracking algorithm based on the distance and to send information for controlling drone movement based on the computer vision tracking algorithm."
SYSTEMS AND METHODS FOR LANDING A DRONE ON A MOVING BASE,https://lens.org/076-534-857-539-114,2018,"A drone is described. The drone includes a depth sensor configured to provide information for determining a distance between the drone and a moving base. The drone also includes a processor configured to control a computer vision tracking algorithm based on the distance, and to control drone movement based on the computer vision tracking algorithm. A vehicle is also described. The vehicle includes a depth sensor configured to provide information for determining a distance between a drone and the vehicle. The vehicle also includes a processor configured to control a computer vision tracking algorithm based on the distance and to send information for controlling drone movement based on the computer vision tracking algorithm."
Systems and methods for landing a drone on a moving base,https://lens.org/011-544-019-190-479,2018,"A drone is described. The drone includes a depth sensor configured to provide information for determining a distance between the drone and a moving base. The drone also includes a processor configured to control a computer vision tracking algorithm based on the distance, and to control drone movement based on the computer vision tracking algorithm. A vehicle is also described. The vehicle includes a depth sensor configured to provide information for determining a distance between a drone and the vehicle. The vehicle also includes a processor configured to control a computer vision tracking algorithm based on the distance and to send information for controlling drone movement based on the computer vision tracking algorithm."
Systems and methods for operating drones in response to an incident,https://lens.org/063-934-450-223-67X,2023,"A response system may be provided. The response system may include a security system and an autonomous drone. The security system includes a security sensor and a controller. The drone includes a processor, a memory in communication with the processor, and a drone sensor. The processor may be programmed to receive the deployment request from the security system, navigate to the one or more zones of the coverage area included in the deployment request, collect drone sensor data of the one or more zones of the coverage area using the at least one drone sensor, determine that an incident has occurred, and/or transmit the collected drone sensor data and incident verification to the security system, wherein, in response to receiving the collected drone sensor data and incident verification, the security system is configured to generate a command for responding to the incident."
METHOD AND RELATED APPARATUSES FOR AUTOMATICALLY CONTROLLING TARGET DEVICES,https://lens.org/141-767-246-539-433,2008,"A control method for automatically controlling a target device is provided. The method comprises the following steps. First, present position information is acquired according to a locating signal. Next, the present position information and position information of the target device are compared to determine whether the target device is being approached. Then, a control signal corresponding to the target device is found if the target device is being approached. Finally, the target device is controlled by sending the control signal thereto."
CONTROL OF AUTONOMOUS MOBILE ROBOTS,https://lens.org/007-293-183-820-972,2022,"An autonomous mobile robot includes a drive system to support the robot above a surface, a sensor system configured to generate a signal indicative of a location of the robot on the surface, and a controller operably connected to the drive system and the sensor system. The drive system is operable to navigate the robot about the surface. The controller is configured to execute instructions to perform operations including establishing a behavior control zone on the surface, controlling the drive system, in response to establishing the behavior control zone on the surface, to maneuver the robot to a location of the behavior control zone on the surface, and maneuvering, using the drive system, the robot about the surface and initiating a behavior in response to determining, based on the signal indicative of the location of the robot, that the robot is proximate the behavior control zone."
CONTROL OF AUTONOMOUS MOBILE ROBOTS,https://lens.org/139-045-573-934-952,2020,"An autonomous mobile robot includes a drive system to support the robot above a surface, a sensor system configured to generate a signal indicative of a location of the robot on the surface, and a controller operably connected to the drive system and the sensor system. The drive system is operable to navigate the robot about the surface. The controller is configured to execute instructions to perform operations including establishing a behavior control zone on the surface, controlling the drive system, in response to establishing the behavior control zone on the surface, to maneuver the robot to a location of the behavior control zone on the surface, and maneuvering, using the drive system, the robot about the surface and initiating a behavior in response to determining, based on the signal indicative of the location of the robot, that the robot is proximate the behavior control zone."
Control of autonomous mobile robots,https://lens.org/011-280-618-181-56X,2022,"An autonomous mobile robot includes a drive system to support the robot above a surface, a sensor system configured to generate a signal indicative of a location of the robot on the surface, and a controller operably connected to the drive system and the sensor system. The drive system is operable to navigate the robot about the surface. The controller is configured to execute instructions to perform operations including establishing a behavior control zone on the surface, controlling the drive system, in response to establishing the behavior control zone on the surface, to maneuver the robot to a location of the behavior control zone on the surface, and maneuvering, using the drive system, the robot about the surface and initiating a behavior in response to determining, based on the signal indicative of the location of the robot, that the robot is proximate the behavior control zone."
CONTROL OF AUTONOMOUS MOBILE ROBOTS,https://lens.org/007-293-183-820-972,2022,"An autonomous mobile robot includes a drive system to support the robot above a surface, a sensor system configured to generate a signal indicative of a location of the robot on the surface, and a controller operably connected to the drive system and the sensor system. The drive system is operable to navigate the robot about the surface. The controller is configured to execute instructions to perform operations including establishing a behavior control zone on the surface, controlling the drive system, in response to establishing the behavior control zone on the surface, to maneuver the robot to a location of the behavior control zone on the surface, and maneuvering, using the drive system, the robot about the surface and initiating a behavior in response to determining, based on the signal indicative of the location of the robot, that the robot is proximate the behavior control zone."
VOICE CONTROL FOR AUTONOMOUS VEHICLES,https://lens.org/070-560-224-104-920,2022,"A method and apparatus for controlling an autonomous vehicle is described. An audio signal is detected and processed the to determine whether the speech comprises a vehicle-navigation command. The audio signal is analyzed to determine whether the signal includes speech from an authorised occupant of the vehicle. If the speech includes an authorised vehicle-navigation command which is feasible to execute given the current position of the vehicle, the command is executed to control the direction and speed of the autonomous vehicle."
"METHOD OF CONTROLLING GIMBAL, GIMBAL AND UAV",https://lens.org/183-369-282-578-296,2021,"A method of controlling a gimbal mounted at an unmanned aerial vehicle (UAV) includes: obtaining a current attitude of the UAV and a current attitude of the gimbal at a current moment; predicting a flight speed of the UAV; and controlling the gimbal to rotate to maintain an angle of the gimbal relative to the UAV within a particular angle range according to the current attitude of the UAV, the current attitude of the gimbal, and the predicted flight speed of the UAV, such that a ratio of a propeller assembly of the UAV appearing in an image photographed by a capturing device mounted at the gimbal is lower than a pre-configured ratio threshold."
ROBOT AND CONTROL METHOD THEREOF,https://lens.org/053-321-908-628-878,2016,"A robot and a control method thereof are provided. The method includes the following steps: receiving a manual control command from a remote control device, and accumulating a duration of issuing the manual control commands; estimating an estimated moving velocity corresponding to the manual control command; detecting a surrounding environment of the robot and generating an autonomous navigation command based on the surrounding environment; determining a first weighting value associated with the manual control command based on the duration, the estimated moving velocity and the distance to obstacles; determining a second weighting value associated with the autonomous navigation command based on the first weighting value; linearly combining the manual control command and the autonomous navigation command based on the first weighting value and the second weighting value to generate a moving control command; and moving based on the moving control command."
Robot and control method thereof,https://lens.org/180-991-353-444-481,2016,"A robot and a control method thereof are provided. The method includes the following steps: receiving a manual control command from a remote control device, and accumulating a duration of issuing the manual control commands; estimating an estimated moving velocity corresponding to the manual control command; detecting a surrounding environment of the robot and generating an autonomous navigation command based on the surrounding environment; determining a first weighting value associated with the manual control command based on the duration, the estimated moving velocity and the distance to obstacles; determining a second weighting value associated with the autonomous navigation command based on the first weighting value; linearly combining the manual control command and the autonomous navigation command based on the first weighting value and the second weighting value to generate a moving control command; and moving based on the moving control command."
UNMANNED AERIAL VEHICLE SYSTEM AND COMMUNICATION METHOD,https://lens.org/041-199-968-141-680,2020,"An unmanned aerial vehicle includes a camera, a first communication system, a second communication system, and a controller. The camera captures images or videos. The first communication system communicates according to a proprietary protocol. The second communication system communicates according to a standard communication protocol. The controller controls operations of the first communication system and the second communication system, to allow the first communication system and the second communication system to simultaneously transmit an image or video captured by the camera."
"A DEVICE, METHOD AND SYSTEM FOR AN UNMANNED AERIAL VEHICLE HEALTH CARE COMPANION",https://lens.org/110-390-633-716-565,2020,"The present invention is a companion unit and companion system. The companion unit comprises an UAV that further comprises one or more of the following elements: propulsion units, circuit boards, navigation sensors, cameras, speakers, microphones, chassis, processors, and batteries. The companion system comprises one or more bases wirelessly connected to the companion unit and in possibly to one or more computer devices and/or to the Internet. The elements thereby facilitate one or more of the following Internet connectivity, wireless local area network (WiFi) connectivity, computer device connectivity (e.g. connectivity to a cell phone, a smart phone, a laptop, a tablet, a smart television, a WiFi enabled appliance, or any other computer device), base connectivity, and cloud storage connectivity. The companion system and/or the companion unit is connected to an artificial intelligence module. The companion unit and system are programmed to function as a companion to a human user."
AUTONOMOUS MONITORING ROBOT SYSTEMS,https://lens.org/125-587-696-417-195,2017,"An autonomous mobile robot includes a chassis, a drive supporting the chassis above a floor surface in a home and configured to move the chassis across the floor surface, a variable height member being coupled to the chassis and being vertically extendible, a camera supported by the variable height member, and a controller. The controller is configured to operate the drive to navigate the robot to locations within the home and to adjust a height of the variable height member upon reaching a first of the locations. The controller is also configured to, while the variable height member is at the adjusted height, operate the camera to capture digital imagery of the home at the first of the locations."
AUTONOMOUS MONITORING ROBOT SYSTEMS,https://lens.org/021-409-761-512-314,2020,"An autonomous mobile robot includes a chassis, a drive supporting the chassis above a floor surface in a home and configured to move the chassis across the floor surface, a variable height member being coupled to the chassis and being vertically extendible, a camera supported by the variable height member, and a controller. The controller is configured to operate the drive to navigate the robot to locations within the home and to adjust a height of the variable height member upon reaching a first of the locations. The controller is also configured to, while the variable height member is at the adjusted height, operate the camera to capture digital imagery of the home at the first of the locations."
Autonomous monitoring robot systems,https://lens.org/121-521-899-541-244,2019,"An autonomous mobile robot includes a chassis, a drive supporting the chassis above a floor surface in a home and configured to move the chassis across the floor surface, a variable height member being coupled to the chassis and being vertically extendible, a camera supported by the variable height member, and a controller. The controller is configured to operate the drive to navigate the robot to locations within the home and to adjust a height of the variable height member upon reaching a first of the locations. The controller is also configured to, while the variable height member is at the adjusted height, operate the camera to capture digital imagery of the home at the first of the locations."
Enhancing branch opening and closing procedures using autonomous drone security and monitoring,https://lens.org/039-910-732-112-840,2022,"Systems, methods, and apparatuses for performing an opening or closing security procedure at a provider location using an unmanned aerial vehicle (UAV) are described herein. An autonomous security system includes a UAV, a user device, and a UAV security system. The UAV security system includes a processing circuit structured to guide the UAV along a predetermined route within or near the provider location. The processing circuit is further structured to receive monitoring data associated with the provider location and its surroundings from the UAV, the monitoring data comprising ultra-wideband (UWB) data and radio-frequency identification (RFID) data. The processing circuit is further configured to identify a foreign object based on the monitoring data, determine that the foreign object is one of a security threat or a defect, and provide a notification to the user device regarding the one of the security threat or the defect."
Enhancing branch opening and closing procedures using autonomous drone security and monitoring,https://lens.org/039-910-732-112-840,2022,"Systems, methods, and apparatuses for performing an opening or closing security procedure at a provider location using an unmanned aerial vehicle (UAV) are described herein. An autonomous security system includes a UAV, a user device, and a UAV security system. The UAV security system includes a processing circuit structured to guide the UAV along a predetermined route within or near the provider location. The processing circuit is further structured to receive monitoring data associated with the provider location and its surroundings from the UAV, the monitoring data comprising ultra-wideband (UWB) data and radio-frequency identification (RFID) data. The processing circuit is further configured to identify a foreign object based on the monitoring data, determine that the foreign object is one of a security threat or a defect, and provide a notification to the user device regarding the one of the security threat or the defect."
Aerial reconnaissance drone and method,https://lens.org/010-551-726-135-080,2022,"An aerial reconnaissance system includes an aerial drone 1 with an elongate fuselage 2 and four wings 3 providing lift by flapping (i.e. a dragonfly or ornithopter arrangement), and a remote control unit 6. A first camera 4 is arranged at a front end of the fuselage pointing forwards, a second camera 4 is arranged at a rear end of the fuselage pointing rearwards. Each camera has a respective square/rectangular field of view, the second camera has a diagonal field of view angle 5 that is at most half that of the first cameras diagonal field of view angle 5. The remote control unit wirelessly transmits instructions to the drone and receives images from the drone; the remote control unit also provides a user with an option 7 to switch between two imagery modes, which rotates the drone to reverse the orientation of the cameras and change the images displayed on a user interface of the remote control unit from one camera to the other camera. Preferably, the first camera is an illuminator with a field of view angle of between 80-230; and the second camera may have a mirror, and a field of view angle between 1-80."
AUTOMATED FLIGHT CONTROL SYSTEM FOR UNMANNED AERIAL VEHICLES,https://lens.org/117-731-250-528-185,2016,"An automated flight control system for an unmanned aerial vehicle (UAV), comprising a flight computer for managing functions related to a flight of the UAV, an application processor for managing functions on the UAV not related to flight, a flight data recorder to record data related to a flight of the UAV, an attitude and heading reference system, a global navigation satellite system receiver, a self-separation module for communicating with another aircraft for the purpose of avoiding a collision, and a wireless communications module for communicating with the remote system, wherein the automated flight control system is capable of receiving operational instructions via the wireless communications module from the remote system."
Autonomous home security devices,https://lens.org/012-825-565-735-023,2020,"An autonomous vehicle such as a drone or a robot is programmed or configured to respond to reports of alarm events or conditions within one or more spaces of a facility. The autonomous vehicle travels to a location of a reported alarm event or condition and captures data using onboard sensors. The autonomous vehicle independently determines whether the reported alarm event or condition is false, or is otherwise properly addressed by resources that are available at the location, using images or other data captured by the onboard sensors. Alternatively, the autonomous vehicle transmits a request for additional resources to be provided at the location, where necessary. A physical map of the location generated based on the images or other data captured by the onboard sensors may be utilized for any purpose, such as to make one or more recommendations of products that are appropriate for use at the facility."
UNMANNED AERIAL VEHICLE AND METHOD FOR ADJUSTING FLIGHT DIRECTION OF THE SAME,https://lens.org/041-229-329-597-029,2012,"A method for adjusting a flight direction of an unmanned aerial vehicle (UAV) using a control device receives a first direction of the control device and a control command of the UAV, obtains a second direction of the UAV, and calculates an angle deviation between the first direction and the second direction. The method further adjusts the control command of the UAV according to the angle deviation to obtain an adjusted control command, and controls a flight direction of the UAV according to the adjusted control command"
"Low-cost, expendable, crushable target aircraft",https://lens.org/067-401-903-226-253,1989,"An expendable drone aircraft to be used as a target for advanced weapons platforms is made of a lightweight crushable foam material. The drone is adapted to realistically converge upon the weapons platform so as to activate the tracking/fire control sensors thereof. A solid fuel rocket motor is encased in a non-metallic lightweight housing and is used to power the drone in free flight. A simple optical seeking device is used to input a signal to a guidance control system which directs the drone in free flight to converge upon the weapons platform. If the weapons platform fails to neutralize the drone during convergence thereon, the impact hazard of the drone is neutralized by the lightweight crushable foam material which acts to harmlessly absorb the kinetic energy of the drone thereby minimizing danger to equipment and personnel of the weapons platform."
SYSTEM AND METHOD FOR PREVENTING INADVERTENT LOSS OF COMMAND AND CONTROL LINK TO AN UNMANNED AERIAL SYSTEM,https://lens.org/132-847-949-120-077,2021,"An unmanned aerial system (UAS) is disclosed. In embodiments, the UAS includes an unmanned aerial vehicle (UAV) (101), and a controller communicatively coupled to the UAV. In embodiments, the UAS controller may be configured to: acquire a command and control (C2) link quality model for a planned route (103); generate one or more control signals configured to cause the UAV to perform a monitored flight along a planned route; acquire actual C2 link quality data during the monitored flight along the planned route; compare the actual C2 link quality data to the C2 link quality model; identify a C2 link quality deviation between the actual C2 link quality and the C2 link quality model; and generate one or more control signals configured to cause the UAV to perform one or more prescribed flight plan maneuvers if the identified C2 link quality deviation (C2<sub>LQ</sub>) exceeds a threshold deviation value (C2<sub>thresh</sub>)."
REMOTE-CONTROL DEVICE,https://lens.org/092-922-125-095-313,2017,"A remote control device (10) includes: an orientation sensor (44) which detects a flight orientation of an unmanned helicopter (1); a GPS antenna (40) and a GPS receiver section (42) for detecting speed information of the unmanned helicopter (1); and a CPU (34a) which detects a flight distance of the unmanned helicopter (1) by integrating the speed information. A memory (34b) stores information concerning a base point of the unmanned helicopter (1). Based on a flight orientation of the unmanned helicopter (1), and a flight distance of the unmanned helicopter (1) which is obtained by integration of the speed information, the CPU (34a) detects a relative position, which indicates a position of the unmanned helicopter (1) with respect to the base point, and controls the flight of unmanned helicopter (1) based on the relative position."
SYSTEM AND METHOD FOR TRACKING UNAUTHORIZED INTRUDERS USING DRONES INTEGRATED WITH A SECURITY SYSTEM,https://lens.org/037-778-185-200-260,2017,"System and method for tracking unauthorized intruders (120) using a drone (110) integrated with a security system (100) are provided. The drone can carry a transceiver device and an image capturing device, the transceiver device can receive an alarm signal from a security system monitoring a region such that the alarm signal indicates an unauthorized intruder is located in the region, the drone can move to an initial location of the unauthorized intruder, the image capturing device can capture an initial image of the unauthorized intruder at the initial location, and the drone can track the unauthorized intruder."
Cascade recognition for personal tracking via unmanned aerial vehicle (UAV),https://lens.org/042-803-736-610-630,2019,"Systems and methods for tracking a subject using an unmanned aerial vehicle (UAV) are disclosed. The UAV includes an onboard camera to capture/stream multiple images. The camera captures reference images of a subject to be stored in memory; the reference images may portray gestures performed by the subject and associated with specific command procedures. The camera may capture subsequent images portraying the subject; the control system may, based on cascade recognition, identify the subject and a stored gesture to a determined confidence level. Once the subject and gesture are positively identified, the control system and/or propulsion system of the UAV may execute the associated command procedures to change the position, velocity, or heading of the UAV."
Unmanned vehicle,https://lens.org/123-052-075-079-206,2018,"An unmanned vehicle, such as a UAV, comprises a main body portion 306, a neck portion (418 fig 4) and a head portion 318. The main body of the vehicle includes control surfaces and/or control actuators which are able to influence vehicle movement. The vehicle includes flight control sensors that are carried in the head of the vehicle which is stabilised relative to the vehicle body. The stabilized flight control sensors experience less noise or generate less noise as a consequence of vehicle manoeuvring."
"A DEVICE, METHOD AND SYSTEM FOR AN UNMANNED AERIAL VEHICLE HEALTH CARE COMPANION",https://lens.org/107-315-222-307-822,2018,"The present invention is a companion unit and companion system. The companion unit comprises an UAV that further comprises one or more of the following elements: propulsion units, circuit boards, navigation sensors, cameras, speakers, microphones, chassis, processors, and batteries. The companion system comprises one or more bases wirelessly connected to the companion unit and possibly to one or more computer devices and/or to the Internet. The elements thereby facilitate one or more of the following Internet connectivity, wireless local area network (WiFi) connectivity, computer device connectivity (e.g. connectivity to a cell phone, a smart phone, a laptop, a tablet, a smart television, a WiFi enabled appliance, or any other computer device), base connectivity, and cloud storage connectivity. The companion system and/or the companion unit is connected to an artificial intelligence module. The companion unit and system are programmed to function as a companion to a human user."
Robot,https://lens.org/134-830-952-973-240,2022,"Disclosed is a robot including a microphone configured to acquire a voice, a camera configured to acquire a first image including a gesture, and a controller configured to recognize the acquired voice, recognize a pointed position corresponding to the gesture included in the first image, control the camera to acquire a second image including the recognized pointed position, identify a pointed target included in the second image, and perform a control operation on the basis of the identified pointed target and a command included in the recognized voice."
Methods and systems for relaying signals,https://lens.org/121-163-976-990-071,2015,An unmanned aerial vehicle (UAV) includes at least one passive reflective device having an elongated configuration defining a long axis and comprising a material configured to reflect radio signals. The UAV also includes a control system configured to control the UAV along a flight path that orients the at least one passive reflective device such that the long axis remains substantially tangential to an ellipsoid whose foci are at two points between which radio communication is desired.
Unmanned device utilization methods and systems,https://lens.org/064-116-918-660-464,2015,"Structures and protocols are presented for configuring an unmanned aerial device to perform a task, alone or in combination with other entities, or for using data resulting from such a configuration or performance."
Unmanned device utilization methods and systems,https://lens.org/046-102-877-373-804,2015,"Structures and protocols are presented for configuring an unmanned aerial device to perform a task, alone or in combination with other entities, or for using data resulting from such a configuration or performance."
UNMANNED DEVICE UTILIZATION METHODS AND SYSTEMS,https://lens.org/085-217-977-391-190,2014,"Structures and protocols are presented for configuring an unmanned aerial device to perform a task, alone or in combination with other entities, or for using data resulting from such a configuration or performance."
Unmanned device utilization methods and systems,https://lens.org/124-980-763-883-466,2018,"Structures and protocols are presented for configuring an unmanned aerial device to perform a task, alone or in combination with other entities, or for using data resulting from such a configuration or performance."
UNMANNED DEVICE UTILIZATION METHODS AND SYSTEMS,https://lens.org/076-242-061-393-055,2016,"Structures and protocols are presented for configuring an unmanned aerial device to perform a task, alone or in combination with other entities, or for using data resulting from such a configuration or performance."
"A SYSTEM, APPARATUS AND METHOD SUITABLE FOR INSPECTION OF A STRUCTURE",https://lens.org/030-220-964-401-611,2022,"There is provided an apparatus (102) suitable for inspection of a structure (101). Specifically, there is provided an apparatus (102) such as a drone which can be capable of flight. Moreover, the apparatus (102) can be suitable for performing flight-based inspection of a structure (101). The apparatus (102) can include at least one arm (202a) (e.g., corresponding to a manipulator arm which can, for example, have 3 Degrees of freedom of movement). The arm (202a) can be capable of carrying one or both of a sensor (202b) and a localization system (202d). The sensor (202b) and/or the localization system (202d) can be configured for performing inspection of the structure (101). Based on the inspection of the structure (101), at least one input signal can be generated and communicated from the apparatus (102). The input signal can be communicated from the apparatus (102) for further processing."
SCALABLE TUBULAR DRONE ARCHITECTURE,https://lens.org/049-837-224-242-07X,2022,"The present embodiment provides a scalable drone architecture or drone (100) having a frame (102), a number of arms (104), a number of landing gears (106), a number of modules (204, 206) and having an enhanced strength irrespective of the employed material. The number of arms (104) are hingedly connected to a channel (208) of the frame (102) and the number of modules (204, 206) are connected to each other in a horizontal or in a vertical plane or in both horizontal and vertical plane of the frame (102)."
Drones with sensors used in insurance applications,https://lens.org/188-452-134-813-978,2023,"Drones are engineered with sensors for use in insurance applications. After locating an object of interest, a drone performs an investigation by probing the object of interest. Sensors receive feedback from the object of interest. An electronic fingerprint of the drone is produced. Afterward, perils are computed based on the feedback and the fingerprint of the drone is used in insuring the object of interest. The act of probing includes thumping, drumming, or radiating ultrasound waves against the object of interest. The sensors can be turned off when they are within a geographic zone of prohibited operations."
Drones with sensors used in insurance applications,https://lens.org/188-452-134-813-978,2023,"Drones are engineered with sensors for use in insurance applications. After locating an object of interest, a drone performs an investigation by probing the object of interest. Sensors receive feedback from the object of interest. An electronic fingerprint of the drone is produced. Afterward, perils are computed based on the feedback and the fingerprint of the drone is used in insuring the object of interest. The act of probing includes thumping, drumming, or radiating ultrasound waves against the object of interest. The sensors can be turned off when they are within a geographic zone of prohibited operations."
Vehicle control system including related methods and components,https://lens.org/081-548-232-187-188,2011,"An unmanned aerial vehicle variable autonomy control system is disclosed herein. In one embodiment, the system includes a control mode interface that provides a plurality of selectable control modes for an unmanned aerial vehicle, wherein one of the plurality of selectable control modes comprises a target tracking mode. Also included is a target editor interface provided in response to a selection of the target tracking mode, wherein the target editor interface facilitates receipt of an input indicative of a ground based moving target. The system also includes a communications component that transmits a command to the unmanned aerial vehicle, wherein the command is based at least in part on the input indicative of a target."
VEHICLE CONTROL SYSTEM INCLUDING RELATED METHODS AND COMPONENTS,https://lens.org/092-781-508-415-939,2010,"An unmanned aerial vehicle variable autonomy control system is disclosed herein. In one embodiment, the system includes a control mode interface that provides a plurality of selectable control modes for an unmanned aerial vehicle, wherein one of the plurality of selectable control modes comprises a target tracking mode. Also included is a target editor interface provided in response to a selection of the target tracking mode, wherein the target editor interface facilitates receipt of an input indicative of a ground based moving target. The system also includes a communications component that transmits a command to the unmanned aerial vehicle, wherein the command is based at least in part on the input indicative of a target."
MOBILE TERMINAL AND METHOD FOR CONTROLLING THE SAME,https://lens.org/128-584-398-372-318,2016,"A mobile terminal including a touchscreen configured to receive a touch input; a wireless communication unit configured to perform wireless communication with an unmanned aerial vehicle having a camera to capture an external environment during flight; a sensing unit configured to sense a posture and movement of the mobile terminal; and a controller configured to control the wireless communication unit to transmit a flight control command to the unmanned aerial vehicle based on the touch input and the movement of the mobile terminal in a first mode in which the posture of the mobile terminal is disposed in a length direction with respect to gravity, and control the wireless communication unit to transmit a capture control command of the camera to the unmanned aerial vehicle based on the touch input along with the flight control command in a second mode in which the posture of the mobile terminal is disposed in a width direction with respect to gravity."
MOBILE TERMINAL AND METHOD FOR CONTROLLING THE SAME,https://lens.org/011-205-386-413-682,2016,"A mobile terminal including a touchscreen configured to receive a touch input; a wireless communication unit configured to perform wireless communication with an unmanned aerial vehicle having a camera to capture an external environment during flight; a sensing unit configured to sense a posture and movement of the mobile terminal; and a controller configured to control the wireless communication unit to transmit a flight control command to the unmanned aerial vehicle based on the touch input and the movement of the mobile terminal in a first mode in which the posture of the mobile terminal is disposed in a length direction with respect to gravity, and control the wireless communication unit to transmit a capture control command of the camera to the unmanned aerial vehicle based on the touch input along with the flight control command in a second mode in which the posture of the mobile terminal is disposed in a width direction with respect to gravity."
MOBILE TERMINAL AND METHOD FOR CONTROLLING THE SAME,https://lens.org/055-387-819-369-995,2016,"A mobile terminal including a touchscreen configured to receive a touch input; a wireless communication unit configured to perform wireless communication with an unmanned aerial vehicle having a camera to capture an external environment during flight; a sensing unit configured to sense a posture and movement of the mobile terminal; and a controller configured to control the wireless communication unit to transmit a flight control command to the unmanned aerial vehicle based on the touch input and the movement of the mobile terminal in a first mode in which the posture of the mobile terminal is disposed in a length direction with respect to gravity, and control the wireless communication unit to transmit a capture control command of the camera to the unmanned aerial vehicle based on the touch input along with the flight control command in a second mode in which the posture of the mobile terminal is disposed in a width direction with respect to gravity.
"
Autonomous robotic device and associated control method,https://lens.org/140-265-540-674-816,2023,"An autonomous device and method for controlling an autonomous device are disclosed. The autonomous device is configured for performing at least one task, selected from a household task, a commercial task and an industrial task. The autonomous device comprises at least one spatial sensor for generating location information and at least one further sensor for determining at least one further parameter. The autonomous device further comprises at least one task unit arranged to perform the household and/or commercial and/or industrial task, and at least one electronics unit, wherein the electronics unit is configured to generate a map using the location information, wherein the electronics unit further is configured for connecting the further parameter to the location information and adding the location of the further parameter to the map, thereby creating a parameter map containing location-correlated values of the at least one further parameter."
AUTONOMOUS ROBOTIC DEVICE AND ASSOCITED CONTROL METHOD,https://lens.org/164-513-398-287-006,2020,"An autonomous device and method for controlling an autonomous device are disclosed. The autonomous device is configured for performing at least one task, selected from a household task, a commercial task and an industrial task. The autonomous device comprises at least one spatial sensor for generating location information and at least one further sensor for determining at least one further parameter. The autonomous device further comprises at least one task unit arranged to perform the household and/or commercial and/or industrial task, and at least one electronics unit, wherein the electronics unit is configured to generate a map using the location information, wherein the electronics unit further is configured for connecting the further parameter to the location information and adding the location of the further parameter to the map, thereby creating a parameter map containing location-correlated values of the at least one further parameter."
DRONE-ASSISTED COMMISSIONING OF INDOOR POSITIONING SYSTEM FOR LIGHT FIXTURES,https://lens.org/191-587-059-796-616,2020,"Provided is an indoor positioning system for light fixtures that includes a drone device which determines a respective location of each light fixture, and assigns identifying information to each light fixture. The system also includes a remote controller which controls operation of the drone device; and a control system configured to receive the respective location of each light fixture and the identifying information associated with each light fixture, from the drone device."
Easy landing drone,https://lens.org/045-715-674-410-834,2015,"Disclosed is an easy landing drone, including: a propeller for changing direction; a propeller tower for supporting the propeller; a body connected to the propeller tower; a main wing with both sides arranged symmetrically with reference to the horizontal axis of the body, a pair of openings being formed in the part of the main wing at the weight center of the body; a pair of auxiliary wings arranged in the pair of openings respectively; and an actuator connected to a reference shaft fixed to the main wing through the pair of auxiliary wings for controlling the sloping angle of the pair of auxiliary wings."
ROBOT,https://lens.org/163-750-359-510-95X,2020,"A robot includes: a microphone assembly to which a voice is input; an accelerometer connected to a noise source; and a controller configured to control the microphone assembly, wherein the microphone assembly includes: a microphone housing formed in one surface thereof with an opening and formed therein with a space; a microphone accommodated in the space; and an anti-noise speaker accommodated in the space and spaced apart from the microphone, and the controller includes an anti-noise generator configured to output a signal corresponding to an anti-noise against the acquired noise to the anti-noise speaker."
Robot with anti-noise speaker,https://lens.org/000-734-900-923-242,2020,"A robot includes: a microphone assembly to which a voice is input; an accelerometer connected to a noise source; and a controller configured to control the microphone assembly, wherein the microphone assembly includes: a microphone housing formed in one surface thereof with an opening and formed therein with a space; a microphone accommodated in the space; and an anti-noise speaker accommodated in the space and spaced apart from the microphone, and the controller includes an anti-noise generator configured to output a signal corresponding to an anti-noise against the acquired noise to the anti-noise speaker."
UNMANNED AERIAL VEHICLE AND UNMANNED AERIAL VEHICLE CONTROLLING SYSTEM,https://lens.org/025-814-717-936-640,2020,"The present invention provides an unmanned aerial vehicle and an unmanned aerial vehicle controlling system. The unmanned aerial vehicle controlling system includes the unmanned aerial vehicle and a controller. The unmanned aerial vehicle has a body, a first localization module and a second localization module. The first localization module and the second localization module are disposed on the body respectively facing a first direction and a second direction. The controller is used for sending a localization signal to the first localization module and a second localization module. The unmanned aerial vehicle controls the direction that the body faces and the distance between the unmanned aerial vehicle and the controller."
System for recognizing and responding to environmental noises,https://lens.org/128-415-723-922-014,2019,"An audio controlled assistant captures environmental noise and converts the environmental noise into audio signals. The audio signals are provided to a system which analyzes the audio signals for a plurality of audio prompts, which have been customized for the acoustic environment surrounding the audio controlled assistant by an acoustic modeling system. The system configured to detect the presence of an audio prompt in the audio signals and transmit instructions associated with the detected audio prompt to at least one of the audio controlled assistant or one or more cloud based services, in response."
METHOD AND SYSTEM FOR REMOTELY GUIDING AN AUTONOMOUS VEHICLE,https://lens.org/121-092-044-458-688,2019,"A system and method for remotely guiding an autonomous vehicle. The method includes receiving, by a controller of the autonomous vehicle, captured information relating to a scene. Controlling the autonomous vehicle through the scene requires input from a remote operator. The method also includes prioritizing the captured information. The method also includes transmitting the captured information to the remote operator based on the prioritizing. Higher priority information is transmitted to the remote operator."
Autonomous Unmanned Aerial Vehicle Decision-Making,https://lens.org/198-026-739-417-266,2016,"A method and apparatus for autonomously managing operation of an unmanned aerial vehicle. Sensor data is received by a computer system located onboard the unmanned aerial vehicle. The sensor data is processed by the computer system to generate information of interest related to at least one target, while the unmanned aerial vehicle is out of a communications range of a control station. A number of actions to be performed is identified by the computer system based on the information of interest related to the at least one target, while the unmanned aerial vehicle is out of the communications range of the control station."
Autonomous unmanned aerial vehicle decision-making,https://lens.org/150-611-373-800-353,2017,"A method and apparatus for autonomously managing operation of an unmanned aerial vehicle. Sensor data is received by a computer system located onboard the unmanned aerial vehicle. The sensor data is processed by the computer system to generate information of interest related to at least one target, while the unmanned aerial vehicle is out of a communications range of a control station. A number of actions to be performed is identified by the computer system based on the information of interest related to the at least one target, while the unmanned aerial vehicle is out of the communications range of the control station."
METHOD FOR MONITORING AUTONOMOUS ROBOTIC LAWNMOWERS,https://lens.org/187-043-170-940-559,2021,"A user device, such as a smartphone or a tablet computer, can provide a user with information pertaining to operations of an autonomous robotic lawnmower to assist the user with monitoring the operations of the robotic lawnmower and with setting up the autonomous robotic lawnmower. For example, the user device can present example lawn shapes and recommended locations of beacons suitable for these lawn shapes, can indicate the quantity of beacons detected by the autonomous robotic lawnmower, can be used to establish a region on a lawn where the autonomous robotic lawnmower performs a particular behavior, can be used to select a grass height that the autonomous robotic lawnmower cuts the lawn, and can be taught a particular path to take when returning to a docking station to charge the autonomous robotic lawnmower."
SYSTEMS AND METHODS FOR MONITORING AUTONOMOUS ROBOTIC LAWNMOWERS,https://lens.org/031-382-749-818-236,2023,"A user device, such as a smartphone or a tablet computer, can provide a user with information pertaining to operations of an autonomous robotic lawnmower to assist the user with monitoring the operations of the robotic lawnmower and with setting up the autonomous robotic lawnmower. For example, the user device can present example lawn shapes and recommended locations of beacons suitable for these lawn shapes, can indicate the quantity of beacons detected by the autonomous robotic lawnmower, can be used to establish a region on a lawn where the autonomous robotic lawnmower performs a particular behavior, can be used to select a grass height that the autonomous robotic lawnmower cuts the lawn, and can be taught a particular path to take when returning to a docking station to charge the autonomous robotic lawnmower."
SYSTEMS AND METHODS FOR MONITORING AUTONOMOUS ROBOTIC LAWNMOWERS,https://lens.org/031-382-749-818-236,2023,"A user device, such as a smartphone or a tablet computer, can provide a user with information pertaining to operations of an autonomous robotic lawnmower to assist the user with monitoring the operations of the robotic lawnmower and with setting up the autonomous robotic lawnmower. For example, the user device can present example lawn shapes and recommended locations of beacons suitable for these lawn shapes, can indicate the quantity of beacons detected by the autonomous robotic lawnmower, can be used to establish a region on a lawn where the autonomous robotic lawnmower performs a particular behavior, can be used to select a grass height that the autonomous robotic lawnmower cuts the lawn, and can be taught a particular path to take when returning to a docking station to charge the autonomous robotic lawnmower."
"METHOD PERFORMED IN AN AUTONOMOUS UNMANNED AERIAL VEHICLE FOR ENABLING AUTONOMOUS EMERGENCY ASSISTANCE FOR A COMMUNICATION DEVICE REGISTERED IN A REGULAR CELLULAR NETWORK, VEHICLE AND DEVICE THEREFORE",https://lens.org/074-296-693-885-796,2019,"A method for enabling autonomous emergency assistance for one or more communication device, CD, registered in a regular cellular network. The method is performed in an autonomous unmanned aerial vehicle, UAV, and comprises emulating (S210) a cellular network in a geographical region, wherein the UAV and the one or more CD are without connectivity with the regular cellular network, sending (S230) an information message in the geographical region, the message comprising an emergency response trigger, receiving (S240) an automatic emergency data response from the one or more CD in the geographical region, in response to the sent message, and determining (S250) an action based on the received automatic emergency data response. A CD, a UAV, a computer program and a computer program product are also presented."
DRONE CAPABLE OF OPERATING IN AN AQUEOUS ENVIRONMENT,https://lens.org/175-564-343-467-332,2017,"Disclosed is a drone capable of operating in an aqueous environment. The drone may include a buoyant structure configured to provide buoyancy. Further, the drone may include one or more propulsion units configured to propel the drone. Furthermore, the drone may include an upper camera disposed on an upper side of the drone. Additionally, the drone may include a lower camera disposed on a lower side of the drone. Further, each of the upper camera and the lower camera may be configured to capture images. Furthermore, one or more legs configured to enable the drone to stand on a solid surface. Additionally, the drone may include one or more leg-actuators coupled to the one or more legs. Further, the one or more leg-actuators may be configured to change a state of the one or more legs to one of an extended state and a retracted state."
"ADS-B RECEIVER-BASED FLIGHT CONTROL METHOD FOR UNMANNED AERIAL VEHICLE, UNMANNED AERIAL VEHICLE, AND CONTROL TERMINAL",https://lens.org/026-085-693-853-46X,2020,"A method for controlling an unmanned aerial vehicle (UAV) includes obtaining flight status information of an aircraft detected by an automatic dependent surveillance-broadcast (ADS-B) receiver carried by the UAV, obtaining flight status information of the UAV, and controlling a flight status of the UAV according to the flight status information of the aircraft and the flight status information of the UAV."
TELEVISION REMOTE CONTROL DEVICE,https://lens.org/035-456-108-016-342,2006,"There is disclosed a remote control unit comprising a body having a user interface for receiving a command from a user. The body also comprises a controller for generating and transmitting one or more control signals for remotely controlling an electronic device in response to said command; and one or more handles attached to said body, each handle having an aperture through which the user grips the unit."
Television remote Control Device,https://lens.org/103-335-490-257-510,2008,"There is disclosed a remote control unit comprising a body having a user interface for receiving a command from a user. The body also comprises a controller for generating and transmitting one or more control signals for remotely controlling an electronic device in response to said command; and one or more handles attached to said body, each handle having an aperture through which the user grips the unit."
Tow control handle for unmanned aerial vehicle,https://lens.org/192-095-234-169-077,2020,"A towing system is provided that includes a tow control handle that is attached by a tow line to an unmanned aerial vehicle (UAV) for towing a user. The tow control handle may include various control elements (e.g., sensors, buttons, switches, rotatable portions, etc.) which may be actuated by a user to provide control signals that are utilized for controlling various aspects of the flight of the UAV (e.g., direction, speed, etc.) A user device that is worn or otherwise carried by the user enables the user to summon the UAV to the user's location when a towing process is to begin and/or when a user is to re-acquire the tow control handle (e.g., after the user releases the tow control handle during the towing process, etc.)"
Drone Umbrella Device,https://lens.org/027-372-820-171-719,2022,"The present invention relates generally to a drone umbrella device primarily comprised of an umbrella, at least one drone and a mobile application. The at least one drone is attached to the umbrella, such that the umbrella can hover over the top of a user. The umbrella is comprised of a telescoping handle assembly that has a detachable handle. The detachable handle has an internal GPS transmitter that communicates with a receiver on the drone, such that the drone follows the location of the detachable handle. In this manner, a user can retain the detachable handle, while the device hovers over the user as he or she sits, walks, runs, etc."
Drone Umbrella Device,https://lens.org/027-372-820-171-719,2022,"The present invention relates generally to a drone umbrella device primarily comprised of an umbrella, at least one drone and a mobile application. The at least one drone is attached to the umbrella, such that the umbrella can hover over the top of a user. The umbrella is comprised of a telescoping handle assembly that has a detachable handle. The detachable handle has an internal GPS transmitter that communicates with a receiver on the drone, such that the drone follows the location of the detachable handle. In this manner, a user can retain the detachable handle, while the device hovers over the user as he or she sits, walks, runs, etc."
TELEOPERATION WITH A WEARABLE SENSOR SYSTEM,https://lens.org/114-268-626-022-641,2019,"A method for remotely controlling an operated unmanned object, comprises defining of a set of control movements of an operator; selecting of minimal necessary signals to reliably acquire the operator's control movements; defining of a mapping of the control movements to commands for the operated unmanned object; sensing of operator's body movements; and transmitting of the minimal necessary signals corresponding to the operator's movements to the operated unmanned object."
TELEOPERATION WITH A WEARABLE SENSOR SYSTEM,https://lens.org/031-298-178-681-851,2021,"A method for remotely controlling an operated unmanned object, comprises defining of a set of control movements of an operator; selecting of minimal necessary signals to reliably acquire the operator's control movements; defining of a mapping of the control movements to commands for the operated unmanned object; sensing of operator's body movements; and transmitting of the minimal necessary signals corresponding to the operator's movements to the operated unmanned object."
Automatic tracking camera system,https://lens.org/129-349-792-217-064,1993,"A camera system which is controllable with a remote-control device is arranged to detect the incoming flight direction of a signal sent from the remote-control device, to adjust the facing direction of the camera to the incoming flight direction of the signal, and to be capable of shifting the facing direction of the camera to a given direction according to an instruction signal coming from the remote-control device after the facing direction of the camera is adjusted to the incoming flight direction of the signal."
METHOD AND APPARATUS TO CONTROL ONE OR MORE DRONES BASED ON REAL-TIME OR PREDICTIVE POSITION INFORMATION,https://lens.org/131-562-070-475-023,2021,"A method, apparatus and system are provided for operating one or more drones in a building. In the context of a method, information is determined that includes at least one of real time information or predictive information. The real time information is indicative of a position of at least one individual in the building, while the predictive information is indicative of a predicted location of the at least one individual in the building at a certain time. The method also includes controlling the one or more drones in the building according to the at least one of the real time information or the predictive information to avoid the at least one individual while the drone is performing a task."
Method and apparatus to control one or more drones based on real-time or predictive position information,https://lens.org/053-399-336-211-494,2023,"A method, apparatus and system are provided for operating one or more drones in a building. In the context of a method, information is determined that includes at least one of real time information or predictive information. The real time information is indicative of a position of at least one individual in the building, while the predictive information is indicative of a predicted location of the at least one individual in the building at a certain time. The method also includes controlling the one or more drones in the building according to the at least one of the real time information or the predictive information to avoid the at least one individual while the drone is performing a task."
Hover control,https://lens.org/064-454-283-898-007,2021,"An unmanned aerial vehicle (UAV) includes a power device communicatively configured to provide power for the UAV and one or more processors coupled to the power device. The one or more processors are configured to obtain a flight velocity of the UAV corresponding to the power, obtain an image frame as a keyframe in response to that the flight velocity satisfies a preset condition, and control the UAV to hover using the keyframe as a reference object."
HOVER CONTROL,https://lens.org/067-404-976-934-852,2020,"An unmanned aerial vehicle (UAV) includes a power device communicatively configured to provide power for the UAV and one or more processors coupled to the power device. The one or more processors are configured to obtain a flight velocity of the UAV corresponding to the power, obtain an image frame as a keyframe in response to that the flight velocity satisfies a preset condition, and control the UAV to hover using the keyframe as a reference object."
"UAV, METHOD AND SYSTEM FOR CLEANING A WALL BODY",https://lens.org/170-247-580-423-607,2022,"A cleaning method includes controlling an unmanned aerial vehicle (UAV) to fly to a region of a wall body according to a path to be cleaned, determining a distance between the UAV and a wall surface of the region of the wall body based on a cleaning mode, and controlling the UAV to clean the wall surface via the cleaning mode and at the determined distance away from the wall surface."
"Autonomous catapult-assisted take-off, recycling, and reuse device and method of flapping-wing unmanned aerial vehicle (UAV)",https://lens.org/168-641-694-007-453,2023,"An autonomous catapult-assisted take-off, recycling, and reuse device and method of a flapping-wing unmanned aerial vehicle (UAV) are provided. The device includes a base, an attitude adjusting mechanism, a catapult mechanism, a recycling mechanism, a control processing unit, a power supply module, and a sensor unit, where the attitude adjusting mechanism includes a connector, a counterweight, an adjusting motor, an attitude adjusting input gear, an attitude adjusting output gear, an attitude adjusting output gear shaft, and an installation platform; the catapult mechanism includes a catapult motor, a catapult motor frame, a pulley, a pull rope, a winch, a pull rope fixing part, a flapping-wing aircraft fixing part, two slide bars, two compression springs, and a catapult gear set; and the recycling mechanism includes a recycling motor, a recycling mechanical arm, a recycling platform, two sprockets, and a recycling gear set."
"AUTONOMOUS CATAPULT-ASSISTED TAKE-OFF, RECYCLING, AND REUSE DEVICE AND METHOD OF FLAPPING-WING UNMANNED AERIAL VEHICLE (UAV)",https://lens.org/189-383-763-580-29X,2022,"An autonomous catapult-assisted take-off, recycling, and reuse device and method of a flapping-wing unmanned aerial vehicle (UAV) are provided. The device includes a base, an attitude adjusting mechanism, a catapult mechanism, a recycling mechanism, a control processing unit, a power supply module, and a sensor unit, where the attitude adjusting mechanism includes a connector, a counterweight, an adjusting motor, an attitude adjusting input gear, an attitude adjusting output gear, an attitude adjusting output gear shaft, and an installation platform; the catapult mechanism includes a catapult motor, a catapult motor frame, a pulley, a pull rope, a winch, a pull rope fixing part, a flapping-wing aircraft fixing part, two slide bars, two compression springs, and a catapult gear set; and the recycling mechanism includes a recycling motor, a recycling mechanical arm, a recycling platform, two sprockets, and a recycling gear set."
"AUTONOMOUS CATAPULT-ASSISTED TAKE-OFF, RECYCLING, AND REUSE DEVICE AND METHOD OF FLAPPING-WING UNMANNED AERIAL VEHICLE (UAV)",https://lens.org/189-383-763-580-29X,2022,"An autonomous catapult-assisted take-off, recycling, and reuse device and method of a flapping-wing unmanned aerial vehicle (UAV) are provided. The device includes a base, an attitude adjusting mechanism, a catapult mechanism, a recycling mechanism, a control processing unit, a power supply module, and a sensor unit, where the attitude adjusting mechanism includes a connector, a counterweight, an adjusting motor, an attitude adjusting input gear, an attitude adjusting output gear, an attitude adjusting output gear shaft, and an installation platform; the catapult mechanism includes a catapult motor, a catapult motor frame, a pulley, a pull rope, a winch, a pull rope fixing part, a flapping-wing aircraft fixing part, two slide bars, two compression springs, and a catapult gear set; and the recycling mechanism includes a recycling motor, a recycling mechanical arm, a recycling platform, two sprockets, and a recycling gear set."
LIGHT IDENTIFICATION SYSTEM FOR UNMANNED AERIAL VEHICLES,https://lens.org/144-211-788-575-59X,2022,"A drone identification system including a drone having an LED license plate and an identification device is disclosed. The drones LEDs emit a color pattern signal that is captured by the identification device, which is then used to uniquely identify the drone. Specifically, the identification device translates the color pattern signal into a unique identification code that is used to identify the drone. The identification code may be transmitted to a server to store the identification information in a directory for future use."
LIGHT IDENTIFICATION SYSTEM FOR UNMANNED AERIAL VEHICLES,https://lens.org/144-211-788-575-59X,2022,"A drone identification system including a drone having an LED license plate and an identification device is disclosed. The drones LEDs emit a color pattern signal that is captured by the identification device, which is then used to uniquely identify the drone. Specifically, the identification device translates the color pattern signal into a unique identification code that is used to identify the drone. The identification code may be transmitted to a server to store the identification information in a directory for future use."
CONTINGENT USE OF COMMANDED SPEED IN LIEU OF SENSED AIRSPEED TO INFORM FLIGHT CONTROL DECISIONS,https://lens.org/081-550-315-072-899,2021,"A technique for controlling an unmanned aerial vehicle (UAV) includes monitoring a sensed airspeed of the UAV, obtaining a commanded speed for the UAV, wherein the commanded speed representing a command to fly the UAV at a given speed relative to an airmass or to Earth, and when the commanded speed is greater than the sensed airspeed, using the commanded speed in lieu of the sensed airspeed to inform flight control decisions of the UAV."
Contingent use of commanded speed in lieu of sensed airspeed to inform flight control decisions,https://lens.org/178-935-670-616-656,2022,"A technique for controlling an unmanned aerial vehicle (UAV) includes monitoring a sensed airspeed of the UAV, obtaining a commanded speed for the UAV, wherein the commanded speed representing a command to fly the UAV at a given speed relative to an airmass or to Earth, and when the commanded speed is greater than the sensed airspeed, using the commanded speed in lieu of the sensed airspeed to inform flight control decisions of the UAV."
Contingent use of commanded speed in lieu of sensed airspeed to inform flight control decisions,https://lens.org/178-935-670-616-656,2022,"A technique for controlling an unmanned aerial vehicle (UAV) includes monitoring a sensed airspeed of the UAV, obtaining a commanded speed for the UAV, wherein the commanded speed representing a command to fly the UAV at a given speed relative to an airmass or to Earth, and when the commanded speed is greater than the sensed airspeed, using the commanded speed in lieu of the sensed airspeed to inform flight control decisions of the UAV."
Contingent use of commanded speed in lieu of sensed airspeed to inform flight control decisions,https://lens.org/001-712-392-856-766,2022,"A technique for controlling an unmanned aerial vehicle (UAV) includes monitoring a sensed airspeed of the UAV, obtaining a commanded speed for the UAV, wherein the commanded speed representing a command to fly the UAV at a given speed relative to an airmass or to Earth, and when the commanded speed is greater than the sensed airspeed, using the commanded speed in lieu of the sensed airspeed to inform flight control decisions of the UAV."
Unmanned aerial vehicle search and rescue system,https://lens.org/128-668-652-042-428,2020,"A search and rescue drone system includes a buoyant body member, a frame attached to the buoyant body member for carrying a motor and propeller, and an electronic array including a camera, GPS, an EPIRB radio distress beacon, and a transmitter/receiver for remote control flying the drone and communicating with an operator. The search and rescue drone may be flown manually, or may have some autonomous flight and locator capabilities. For example, in one embodiment, the search and rescue drone may be programmed to simply fly to the location of an electronic wearable device, like a bracelet, that is worn by a man overboard. In another embodiment, the search and rescue drone includes a basket, harness, or other means for actually recovering a swimmer in distress, and flying that person back to safety on a ship or on shore."
Unmanned Aerial Vehicle Search and Rescue System,https://lens.org/092-738-758-601-060,2020,"A search and rescue drone system includes a buoyant body member, a frame attached to the buoyant body member for carrying a motor and propeller, and an electronic array including a camera, GPS, an EPIRB radio distress beacon, and a transmitter/receiver for remote control flying the drone and communicating with an operator. The search and rescue drone may be flown manually, or may have some autonomous flight and locator capabilities. For example, in one embodiment, the search and rescue drone may be programmed to simply fly to the location of an electronic wearable device, like a bracelet, that is worn by a man overboard. In another embodiment, the search and rescue drone includes a basket, harness, or other means for actually recovering a swimmer in distress, and flying that person back to safety on a ship or on shore."
Drone-enabled operator rounds,https://lens.org/091-300-128-007-371,2020,"Drones, unmanned aerial vehicles or UAVs 72 are equipped with cameras 74 and travel throughout the environment of a process plant to monitor process plant conditions. Onboard computing devices control movement of the drones 72 through the environment. The onboard computing devices interface with the camera 74 and communicate with a user interface device 8. The onboard computing devices receive drone commands from the user interface device 8 and transmit data captured by the cameras 74. The user interface device 8 may display data captured by the drone camera 74. The user interface 8 allows a user to select a piece of equipment from an overview of the plant as a destination for the UAV. The UAV may carry sensors 76 to interact with the plant equipment."
NAVIGATION SYSTEM AND METHOD USING DRONE,https://lens.org/174-580-312-107-426,2021,"A navigation system and a method using a drone are provided. The navigation system includes a communicator configured to communicate with the drone and a vehicle, storage configured to store traffic information and map information, and a processor configured to detect a congested section using the traffic information and the map information, or image information of the drone and to guide a detour lane or a detour route to the vehicle based on road information of the congested section obtained by the drone."
Multi-level premise mapping with security camera drone,https://lens.org/009-299-391-946-684,2021,"A drone is used to map difficult transition spaces within buildings such as staircases between different levels of a multi-level building. The mapping technique used may vary based on the type of building space. For instance, for linear staircases, an orthogonal trajectory path or a smooth trajectory path may be used to map the transition space. The orthogonal trajectory path and the smooth trajectory path may be derived, at least in part, on initial and terminating points provided by a user. For circular staircases, a user may move the drone from the initial point to the terminating point, and the drone may determine a trajectory path based on the user's movement of the drone from the initial point to the terminating point."
MULTI-LEVEL PREMISE MAPPING WITH SECURITY CAMERA DRONE,https://lens.org/058-142-160-253-102,2022,"A drone is used to map difficult transition spaces within buildings such as staircases between different levels of a multi-level building. The mapping technique used may vary based on the type of building space. For instance, for linear staircases, an orthogonal trajectory path or a smooth trajectory path may be used to map the transition space. The orthogonal trajectory path and the smooth trajectory path may be derived, at least in part, on initial and terminating points provided by a user. For circular staircases, a user may move the drone from the initial point to the terminating point, and the drone may determine a trajectory path based on the user's movement of the drone from the initial point to the terminating point."
CAMERA DRONE SYSTEMS AND METHODS FOR MAINTAINING CAPTURED REAL-TIME IMAGES VERTICAL,https://lens.org/125-338-048-312-830,2016,"A camera drone with a function of providing real-time captured images in a certain angle (e.g., vertical to the horizon) is disclosed. The camera drone includes multiple rotor wings, a support structure, a wireless transmitter, a controller, and a camera device. The camera device includes a processor, a gravity sensor, a gyroscope, and an image module. The image module is configured to capture an original image in a real time manner. The gravity sensor and the gyroscope are used to calculate a current dip angle (i.e., inclination of a geological plane down from the horizon) of the camera drone. The current dip angle is used to calculate an angle of rotation. The camera device then generates an edited image based on the original image and the angle of rotation."
System and method for conducting a drone race or game,https://lens.org/187-308-015-798-872,2020,A system and method of conducting a drone race or game in a contained area is disclosed herein. The system may also include cameras attached to the drones and the video feed from the camera is transmitted to a computing device used to control the drone and to display the video feed. The system may also use computing devices and monitors to display the video feeds from the cameras attached to the drones. The system may also be configured as a game with information points.
SYSTEM AND METHOD FOR CONDUCTING A DRONE RACE OR GAME,https://lens.org/133-901-203-449-125,2018,A system and method of conducting a drone race or game in a contained area is disclosed herein. The system may also include cameras attached to the drones and the video feed from the camera is transmitted to a computing device used to control the drone and to display the video feed. The system may also use computing devices and monitors to display the video feeds from the cameras attached to the drones. The system may also be configured as a game with information points.
SYSTEM AND METHOD FOR CONDUCTING A DRONE RACE OR GAME,https://lens.org/153-199-410-072-963,2020,A system and method of conducting a drone race or game in a contained area is disclosed herein. The system may also include cameras attached to the drones and the video feed from the camera is transmitted to a computing device used to control the drone and to display the video feed. The system may also use computing devices and monitors to display the video feeds from the cameras attached to the drones. The system may also be configured as a game with information points.
PORTABLE DRONE POD,https://lens.org/186-089-673-306-581,2018,"A drone pod includes a pod shell, a door, a motor and a computer. The pod shell includes a base, a top, and a wall. The top has an opening sized to receive a drone. The wall connects the base and the top. The door is disposed in the opening. The motor is drivingly connected to the door. The computer is programmed actuate the motor to open and close the door responsive to an operation of the drone."
PORTABLE DRONE POD,https://lens.org/071-673-316-208-257,2020,"A drone pod includes a pod shell, a door, a motor and a computer. The pod shell includes a base, a top, and a wall. The top has an opening sized to receive a drone. The wall connects the base and the top. The door is disposed in the opening. The motor is drivingly connected to the door. The computer is programmed actuate the motor to open and close the door responsive to an operation of the drone."
"Aerial Camera Device, Systems, and Methods",https://lens.org/076-664-300-951-019,2023,"Systems and techniques may be used to operate an aerial camera device. An example method may include using a mobile device for controlling an aerial device. The method may include receiving a sensor data, for example from the mobile device or the aerial device, establishing a centered position for the mobile device or the aerial device based on sensor information, and converting movement identified in sensor data to an instruction for movement of the aerial device. The instruction for movement may be sent to the aerial device, in an example."
"AERIAL CAMERA DEVICE, SYSTEMS, AND METHODS",https://lens.org/127-597-715-296-010,2021,"Systems and techniques may be used to operate an aerial camera device. An example method may include using a mobile device for controlling an aerial device. The method may include receiving a sensor data, for example from the mobile device or the aerial device, establishing a centered position for the mobile device or the aerial device based on sensor information, and converting movement identified in sensor data to an instruction for movement of the aerial device. The instruction for movement may be sent to the aerial device, in an example."
"Aerial Camera Device, Systems, and Methods",https://lens.org/076-664-300-951-019,2023,"Systems and techniques may be used to operate an aerial camera device. An example method may include using a mobile device for controlling an aerial device. The method may include receiving a sensor data, for example from the mobile device or the aerial device, establishing a centered position for the mobile device or the aerial device based on sensor information, and converting movement identified in sensor data to an instruction for movement of the aerial device. The instruction for movement may be sent to the aerial device, in an example."
"DIAL STRUCTURE, REMOTE CONTROLLER EMPLOYING THE SAME, AND CONTROLLING METHOD",https://lens.org/094-832-653-295-179,2020,"Disclosed is a controlling method for an unmanned aerial vehicle (UAV) that includes an image device. The controlling method includes transmitting, by a remote controller when a dial of a dial structure of the remote controller is rotated, a first control signal for changing imaging device information of an imaging device of the UAV via a signal transmitting device of the remote controller. The imaging device information comprises at least one of an operating mode of the imaging device, a shutter speed of the imaging device, an aperture size of the imaging device, a light sensitivity of the imaging device, or a preview image of the imaging device. The controlling method further includes transmitting a second control signal for confirming imaging device information via the signal transmitting device by the controller when the dial is slid with a displacement,?"
"UNMANNED AERIAL VEHICLE, CONTROL SYSTEM AND METHOD THEREOF, AND UNMANNED AERIAL VEHICLE LANDING CONTROL METHOD",https://lens.org/010-608-502-092-071,2018,"An unmanned aerial vehicle includes a fuselage, a power device connected to the fuselage, and a control device disposed at the fuselage and electrically connected with the power device. The control device is configured to control the power device to switch an operating mode of the power device to cause the unmanned aerial vehicle to fly in air or navigate on a water surface."
"Unmanned aerial vehicle, control system and method thereof, and unmanned aerial vehicle landing control method",https://lens.org/165-447-370-065-579,2020,"An unmanned aerial vehicle includes a fuselage, a power device connected to the fuselage, and a control device disposed at the fuselage and electrically connected with the power device. The control device is configured to control the power device to switch an operating mode of the power device to cause the unmanned aerial vehicle to fly in air or navigate on a water surface."
Method for remote control of an audio device,https://lens.org/194-407-789-796-501,2006,"A method for remote control of an audio device ( 1 ) is described, which receives an audio data stream (A) from a transmission system. A control command in the form of an audio data sample (AM) within the audio data stream (A) is sent to the audio device ( 1 ). The received audio data stream (A) is analyzed by means of an audio sample recognition system ( 2 ) in or on the audio device ( 1 ). A recognized audio data sample (AM) is converted into control data (SD, ST) and depending on the control data (SD, ST), certain components ( 7, 8 ) of the audio device ( 1 ) are activated in a certain manner."
On-board emergency response system for a vehicle,https://lens.org/180-690-432-401-712,2021,"An on-board emergency response system for a vehicle include a drone being integrated with a vehicle to become separated only when the vehicle is in trouble or experiencing difficulties. Activation of the drone may be from inside the vehicle or remotely via a communication link. The drone is automatically ejected or activated when abnormal conditions inside or outside the vehicle are detected. The drone may provide a backup communication when needed. Once the drone is ejected from the plane, it then follows the vehicle from above at a predetermined distance. It also sends its location, video and images taken inside and outside the vehicle to the command center. If a disaster is inevitable, the drone then tracks the vehicle all the way to its destination. Since the vehicle's actual location is immediately known to the central command, the rescue team can take off in no time, skipping the search altogether."
ON-BOARD EMERGENCY RESPONSE SYSTEM FOR A VEHICLE,https://lens.org/159-577-060-467-255,2019,"An on-board emergency response system for a vehicle include a drone being integrated with a vehicle to become separated only when the vehicle is in trouble or experiencing difficulties. Activation of the drone may be from inside the vehicle or remotely via a communication link. The drone is automatically ejected or activated when abnormal conditions inside or outside the vehicle are detected. The drone may provide a backup communication when needed. Once the drone is ejected from the plane, it then follows the vehicle from above at a predetermined distance. It also sends its location, video and images taken inside and outside the vehicle to the command center. If a disaster is inevitable, the drone then tracks the vehicle all the way to its destination. Since the vehicle's actual location is immediately known to the central command, the rescue team can take off in no time, skipping the search altogether."
DRONE FOR MEASURING DATA REPRESENTATIVE OF AMOUNTS OF AT LEAST TWO GASES PRESENT IN THE ATMOSPHERE AWAY FROM THE GROUND AND ASSOCIATED METHOD,https://lens.org/034-856-870-457-007,2023,"This drone comprises a sensor for measuring representative data, comprising at least one measurement cell that is open to the atmosphere, at least a first laser source configured to inject, into the measurement cell, a first laser beam at a first wavelength characteristic of a first gas to be detected and a second laser source configured to inject, into the measurement cell, a second laser beam at a second wavelength characteristic of a second gas to be detected. The measuring sensor comprises a detector common to the two laser sources, said detector being configured to detect a first measurement signal originating from the measurement cell and resulting from injection of the first laser beam into the measurement cell and a second measurement signal originating from the measurement cell and resulting from injection of the second laser beam into the measurement cell."
DRONE FOR MEASURING DATA REPRESENTATIVE OF AMOUNTS OF AT LEAST TWO GASES PRESENT IN THE ATMOSPHERE AWAY FROM THE GROUND AND ASSOCIATED METHOD,https://lens.org/034-856-870-457-007,2023,"This drone comprises a sensor for measuring representative data, comprising at least one measurement cell that is open to the atmosphere, at least a first laser source configured to inject, into the measurement cell, a first laser beam at a first wavelength characteristic of a first gas to be detected and a second laser source configured to inject, into the measurement cell, a second laser beam at a second wavelength characteristic of a second gas to be detected. The measuring sensor comprises a detector common to the two laser sources, said detector being configured to detect a first measurement signal originating from the measurement cell and resulting from injection of the first laser beam into the measurement cell and a second measurement signal originating from the measurement cell and resulting from injection of the second laser beam into the measurement cell."
Emergency Communications System For Vehicle,https://lens.org/132-905-455-423-775,2019,An emergency communication system for a vehicle. The system includes a drone docking station configured to be mounted to a vehicle. An aerial drone is configured to be docked to the docking station and released from the docking station when the vehicle is disabled and/or a driver is incapacitated at a location that is out of range of communication with emergency authorities.
Emergency communications system for vehicle,https://lens.org/114-409-890-118-454,2020,An emergency communication system for a vehicle. The system includes a drone docking station configured to be mounted to a vehicle. An aerial drone is configured to be docked to the docking station and released from the docking station when the vehicle is disabled and/or a driver is incapacitated at a location that is out of range of communication with emergency authorities.
METHOD AND APPARATUS FOR CONTROLLING DEVICE,https://lens.org/096-803-912-678-386,2019,"A method of controlling a device is provided including identifying a registered device from a screen input by a camera, receiving a user input for the identified device, and transmitting a control command corresponding to the input to the identified device."
METHOD AND APPARATUS FOR CONTROLLING DEVICE,https://lens.org/003-006-225-915-831,2012,"A method of controlling a device is provided including identifying a registered device from a screen input by a camera, receiving a user input for the identified device, and transmitting a control command corresponding to the input to the identified device."
Method and apparatus for controlling a device identified from a screen input by a camera,https://lens.org/060-265-012-873-037,2018,"A method of controlling a device is provided including identifying a registered device from a screen input by a camera, receiving a user input for the identified device, and transmitting a control command corresponding to the input to the identified device."
Method and apparatus for controlling device,https://lens.org/041-439-847-673-488,2016,"A method of controlling a device is provided including identifying a registered device from a screen input by a camera, receiving a user input for the identified device, and transmitting a control command corresponding to the input to the identified device."
Method and apparatus for identifying a device from a camera input,https://lens.org/112-946-491-153-106,2020,"A method of controlling a device is provided including identifying a registered device from a screen input by a camera, receiving a user input for the identified device, and transmitting a control command corresponding to the input to the identified device."
METHOD AND APPARATUS FOR CONTROLLING DEVICE,https://lens.org/015-601-295-601-629,2018,"A method of controlling a device is provided including identifying a registered device from a screen input by a camera, receiving a user input for the identified device, and transmitting a control command corresponding to the input to the identified device."
Method and apparatus for controlling a device identified from a screen input by a camera,https://lens.org/178-017-555-871-181,2017,"A method of controlling a device is provided including identifying a registered device from a screen input by a camera, receiving a user input for the identified device, and transmitting a control command corresponding to the input to the identified device."
Method and apparatus for controlling device,https://lens.org/122-561-494-595-124,2013,"A method of controlling a device is provided including identifying a registered device from a screen input by a camera, receiving a user input for the identified device, and transmitting a control command corresponding to the input to the identified device."
METHOD AND APPARATUS FOR CONTROLLING DEVICE,https://lens.org/011-327-142-204-775,2017,"A method of controlling a device is provided including identifying a registered device from a screen input by a camera, receiving a user input for the identified device, and transmitting a control command corresponding to the input to the identified device."
Method and apparatus for controlling device,https://lens.org/186-881-996-146-403,2015,"A method of controlling a device is provided including identifying a registered device from a screen input by a camera, receiving a user input for the identified device, and transmitting a control command corresponding to the input to the identified device."
Method and apparatus for controlling a device identified from a screen input by a camera,https://lens.org/096-455-217-249-24X,2019,"A method of controlling a device is provided including identifying a registered device from a screen input by a camera, receiving a user input for the identified device, and transmitting a control command corresponding to the input to the identified device."
"FLIGHT CONTROL METHOD AND APPARATUS FOR UNMANNED AERIAL VEHICLE, AND REMOTE CONTROLLER",https://lens.org/057-364-674-963-221,2019,"A flight control method and device for an unmanned aerial vehicle and a remote controller are provided. The method includes that: multiple pieces of locating data obtained by a locating operation are acquired in a remote controller (201); multiple target positions are determined according to the multiple pieces of locating data (202); a flight route is calculated according to the multiple target positions (203); and the flight route is sent to the unmanned aerial vehicle for flight according to the flight route (204). According to the method, carrying of multiple sets of equipment is avoided, and hardware cost is reduced. Since remote control equipment is integrated with a surveying and mapping function, carrying of multiple kinds of equipment is avoided, that is, data exchange among multiple kinds of equipment is avoided, convenience for operation is further improved, operation efficiency of the unmanned aerial vehicle is improved, moreover, a probability of a data sending error during data exchange is reduced, and operation reliability of the unmanned aerial vehicle is improved."
VEHICLE CONTROLLABLE BY A REMOTE COMPUTER,https://lens.org/135-615-424-794-454,2017,"A remotely controlled vehicle for receiving control instructions and data from a remote control device and for transmitting control instructions and data back to said remote control device. The vehicle includes a radio antenna adapted for communication with a smart phone, a transceiver, compass unit, a GPS unit, an electric power source, a servo controlled drive motor, a programmable microcontroller (including sensors) and a servo controlled steering motor."
Lateral Avoidance Maneuver Solver,https://lens.org/073-808-900-440-627,2011,"A system on-board an unmanned aerial vehicle for controlling a lateral maneuver to avoid a loss of separation between the unmanned aerial vehicle and an intruder into its airspace. The system receives as inputs the desired miss distance, desired bank angle, state vectors for the unmanned aerial vehicle, wind, and an intruder, and a target vector; and outputs a lateral route change which will achieve the desired miss distance and return the unmanned aerial vehicle back to path. In one embodiment, the system comprises a computer programmed with software that runs automatically and guides the unmanned aerial vehicle to perform a lateral maneuver that avoids loss of separation. In another embodiment, the software runs automatically and advises a pilot on the ground (who is flying the drone by remote control) that a maneuver is about to happen, which maneuver the pilot can either accept or reject."
Lateral avoidance maneuver solver,https://lens.org/145-732-105-401-444,2016,"A system on-board an unmanned aerial vehicle for controlling a lateral maneuver to avoid a loss of separation between the unmanned aerial vehicle and an intruder into its airspace. The system receives as inputs the desired miss distance, desired bank angle, state vectors for the unmanned aerial vehicle, wind, and an intruder, and a target vector; and outputs a lateral route change which will achieve the desired miss distance and return the unmanned aerial vehicle back to path. In one embodiment, the system comprises a computer programmed with software that runs automatically and guides the unmanned aerial vehicle to perform a lateral maneuver that avoids loss of separation. In another embodiment, the software runs automatically and advises a pilot on the ground (who is flying the drone by remote control) that a maneuver is about to happen, which maneuver the pilot can either accept or reject."
SYSTEMS AND METHODS FOR COMMUNICATING WITH AN UNMANNED AERIAL VEHICLE,https://lens.org/176-378-011-301-114,2022,"A system including: an unmanned aerial vehicle (UAV) and a wireless control system. The UAV includes one or more sensors, and a UAV communication subsystem. The one or more sensors configured to capture contextual information associated with capture of visual information. The UAV communication subsystem includes a UAV radio frequency transceiver configured to communicate with a network. The wireless control system includes a housing, a wireless communication subsystem, a flight control setting component, a power component, and a processor. The power component configured to obtain a current power consumption of a power source of the UAV. The processor is configured to: obtain visual information; display the visual information; and communicate with the flight control setting component. The processor communicates with the power component to obtain the current power consumption and effectuate presentation of a power display field including a first portion and a second portion."
SYSTEMS AND METHODS FOR COMMUNICATING WITH AN UNMANNED AERIAL VEHICLE,https://lens.org/176-378-011-301-114,2022,"A system including: an unmanned aerial vehicle (UAV) and a wireless control system. The UAV includes one or more sensors, and a UAV communication subsystem. The one or more sensors configured to capture contextual information associated with capture of visual information. The UAV communication subsystem includes a UAV radio frequency transceiver configured to communicate with a network. The wireless control system includes a housing, a wireless communication subsystem, a flight control setting component, a power component, and a processor. The power component configured to obtain a current power consumption of a power source of the UAV. The processor is configured to: obtain visual information; display the visual information; and communicate with the flight control setting component. The processor communicates with the power component to obtain the current power consumption and effectuate presentation of a power display field including a first portion and a second portion."
OPTIMIZING PROPELLER SPEED IN DRONE DESIGN USING ONBOARD NETWORK OF SENSORS,https://lens.org/011-236-170-564-811,2019,"A drone includes one or more rotatable propellers and one or more fixed propellers powered by one or more battery powered electric motors for providing upward and forward thrust to the drone during upward and forward movement of the drone respectively. The drone includes a set of sensors, so as to adjust a speed of the fixed and rotatable propellers in accordance with a speed and direction of the wind."
"UNMANNED AERIAL VEHICLE, COMMUNICATION SYSTEM AND TESTING METHOD, DEVICE AND SYSTEM THEREOF",https://lens.org/043-738-874-238-572,2021,"An unmanned aerial vehicle includes a communication controller configured to receive a control instruction from a remote control, a flight controller electrically connected to the communication interface through a communication interface and a universal serial bus (USB) interface, and a center board controller electrically connected to the flight controller through a controller area network (CAN) bus and electrically connected to a load of the unmanned aerial vehicle. The communication interface is configured to transmit the control instruction. The USB interface is configured to transmit upgrade data of the flight controller. The flight controller is configured to control the unmanned aerial vehicle according to the control instruction. The center board controller is configured to receive the control instruction from the communication controller and forward the control instruction to the load."
System and a method for facilitating testing of plurality of devices using a drone,https://lens.org/045-830-580-823-068,2017,"Disclosed is a system and method for facilitating testing of a plurality of devices using a drone. At first, a locating module locates position of the drone relative to the plurality of devices. Further, a receiving module receives an image, of a device of the plurality of devices, from image capturing unit of the drone. Then, a comparing module compares the image with a reference image corresponding to the device. Based on the comparison, a determining module determines an action to be performed for testing the device. Further, a facilitating module facilitates the testing by enabling a snout associated with the drone to perform the action on the device."
SYSTEM AND A METHOD FOR FACILITATING TESTING OF PLURALITY OF DEVICES USING A DRONE,https://lens.org/114-935-294-401-392,2016,"Disclosed is a system and method for facilitating testing of a plurality of devices using a drone. At first, a locating module locates position of the drone relative to the plurality of devices. Further, a receiving module receives an image, of a device of the plurality of devices, from image capturing unit of the drone. Then, a comparing module compares the image with a reference image corresponding to the device. Based on the comparison, a determining module determines an action to be performed for testing the device. Further, a facilitating module facilitates the testing by enabling a snout associated with the drone to perform the action on the device."
DRONE ESCORT SYSTEM,https://lens.org/181-881-509-940-246,2021,"The present disclosure describes systems and methods for escorting small unmanned aircraft (herein drones). An escorting drone approaches the escorted drone and transmits to it an escort signal. In an embodiment, the escort signal is a GNSS signal fashioned to be the same as the GNSS signal that would be received by the escorted drone, other than being slightly stronger in signal strength and having slightly altered component delays. In another embodiment, the escort signal is a radio frequency control channel signal. Escorting may be utilized to guide a drone from a preprogrammed point to a docking zone in a droneport; to guide a drone though an urban canyon or inside a building where GNSS signals are not reliably received; to retrieve a drone with which communications has been lost; or to escort a drone to safety out of a no-flight zone such as around an airport."
Drone escort system,https://lens.org/132-609-923-165-097,2022,"The present disclosure describes systems and methods for escorting small unmanned aircraft (herein drones). An escorting drone approaches the escorted drone and transmits to it an escort signal. In an embodiment, the escort signal is a GNSS signal fashioned to be the same as the GNSS signal that would be received by the escorted drone, other than being slightly stronger in signal strength and having slightly altered component delays. In another embodiment, the escort signal is a radio frequency control channel signal. Escorting may be utilized to guide a drone from a preprogrammed point to a docking zone in a droneport; to guide a drone though an urban canyon or inside a building where GNSS signals are not reliably received; to retrieve a drone with which communications has been lost; or to escort a drone to safety out of a no-flight zone such as around an airport."
Drone escort system,https://lens.org/132-609-923-165-097,2022,"The present disclosure describes systems and methods for escorting small unmanned aircraft (herein drones). An escorting drone approaches the escorted drone and transmits to it an escort signal. In an embodiment, the escort signal is a GNSS signal fashioned to be the same as the GNSS signal that would be received by the escorted drone, other than being slightly stronger in signal strength and having slightly altered component delays. In another embodiment, the escort signal is a radio frequency control channel signal. Escorting may be utilized to guide a drone from a preprogrammed point to a docking zone in a droneport; to guide a drone though an urban canyon or inside a building where GNSS signals are not reliably received; to retrieve a drone with which communications has been lost; or to escort a drone to safety out of a no-flight zone such as around an airport."
Shooting method controlling movement of unmanned aerial robot in unmanned aerial system and apparatus for supporting same,https://lens.org/133-456-874-010-102,2020,"A unmanned aerial vehicle system which includes a unmanned aerial robot, a unmanned aerial robot station, and a base station to control a movement of the unmanned aerial robot is provided. The unmanned aerial robot photographs an area of a predetermined range using a camera in a state of being seated on the unmanned aerial robot station, photographs a set path while flying along the set path according to a preset condition, and transmits information on a photographed image to the base station. The base station transmits control information instructing a specific operation to the unmanned aerial robot based on the information on the photographed image, and the unmanned aerial robot station can charges a battery of the unmanned aerial robot through a charging pad when the unmanned aerial robot is seated on the unmanned aerial robot station."
SHOOTING METHOD CONTROLLING MOVEMENT OF UNMANNED AERIAL ROBOT IN UNMANNED AERIAL SYSTEM AND APPARATUS FOR SUPPORTING SAME,https://lens.org/137-324-956-217-204,2020,"A unmanned aerial vehicle system which includes a unmanned aerial robot, a unmanned aerial robot station, and a base station to control a movement of the unmanned aerial robot is provided. The unmanned aerial robot photographs an area of a predetermined range using a camera in a state of being seated on the unmanned aerial robot station, photographs a set path while flying along the set path according to a preset condition, and transmits information on a photographed image to the base station. The base station transmits control information instructing a specific operation to the unmanned aerial robot based on the information on the photographed image, and the unmanned aerial robot station can charges a battery of the unmanned aerial robot through a charging pad when the unmanned aerial robot is seated on the unmanned aerial robot station."
Objective-based control of an autonomous unmanned aerial vehicle,https://lens.org/169-577-691-403-47X,2021,"A technique is described for controlling an autonomous vehicle such as an unmanned aerial vehicle (UAV) using objective-based inputs. In an embodiment, the underlying functionality of an autonomous navigation system is via an application programming interface (API). In such an embodiment, the UAV can be controlled trough specifying a behavioral objective, for example, using a call to the API to set parameters for the behavioral objective. The autonomous navigation system can then incorporate perception inputs such as sensor data from sensors mounted to the UAV and the set parameters using a multi-objective motion planning process to generate a proposed trajectory that most closely satisfies the behavioral objective in view of certain constraints. In some embodiments, developers can utilize the API to build customized applications for utilizing the UAV to capture images. Such applications, also referred to as skills, can be developed, shared, and executed to control the behavior of an autonomous UAV and to aid in overall system improvement."
Objective-Based Control Of An Autonomous Unmanned Aerial Vehicle,https://lens.org/168-988-353-325-413,2022,"A technique is described for controlling an autonomous vehicle such as an unmanned aerial vehicle (UAV) using objective-based inputs. In an embodiment, the underlying functionality of an autonomous navigation system is via an application programming interface (API). In such an embodiment, the UAV can be controlled trough specifying a behavioral objective, for example, using a call to the API to set parameters for the behavioral objective. The autonomous navigation system can then incorporate perception inputs such as sensor data from sensors mounted to the UAV and the set parameters using a multi-objective motion planning process to generate a proposed trajectory that most closely satisfies the behavioral objective in view of certain constraints. In some embodiments, developers can utilize the API to build customized applications for utilizing the UAV to capture images. Such applications, also referred to as skills, can be developed, shared, and executed to control the behavior of an autonomous UAV and to aid in overall system improvement."
DRONE,https://lens.org/036-072-239-301-876,2023,"A drone including a front section, a wing structure supported by a rotor located behind the front section, and a propeller at the rear. The wing structure including two wings rotating the rotor, the wing structure being able to move between a flight configuration, in which the rotor is immobile relative to the front section and the propulsion provided by the propeller, and a flight configuration with the wing structure rotating, in which the rotor is rotated relative to the front section, the rotor being connected to the front section with a possibility of orienting its axis of rotation relative thereto in order able to direct the drone in the rotary wing structure configuration by acting on said orientation."
DRONE,https://lens.org/036-072-239-301-876,2023,"A drone including a front section, a wing structure supported by a rotor located behind the front section, and a propeller at the rear. The wing structure including two wings rotating the rotor, the wing structure being able to move between a flight configuration, in which the rotor is immobile relative to the front section and the propulsion provided by the propeller, and a flight configuration with the wing structure rotating, in which the rotor is rotated relative to the front section, the rotor being connected to the front section with a possibility of orienting its axis of rotation relative thereto in order able to direct the drone in the rotary wing structure configuration by acting on said orientation."
Autonomous safety and security device on an unmanned platform under command and control of a cellular phone,https://lens.org/028-352-505-163-899,2017,A safety and security device is housed on either an unmanned aerial vehicle or its land-based docking station and is combined with a cellular telephone for self-defense purposes. The phone broadcasts both recorded audio and video warnings on the device. A flashing light may be activated on the aerial platform or the docking station. The device may be integrated into a modular unit that combines numerous defensive mechanisms. These defensive mechanisms operate autonomously and respond to perceived threats.
AUTONOMOUS SAFETY AND SECURITY DEVICE ON AN UNMANNED PLATFORM UNDER COMMAND AND CONTROL OF A CELLULAR PHONE,https://lens.org/193-298-880-085-691,2017,A safety and security device is housed on either an unmanned aerial vehicle or its land-based docking station and is combined with a cellular telephone for self-defense purposes. The phone broadcasts both recorded audio and video warnings on the device. A flashing light may be activated on the aerial platform or the docking station. The device may be integrated into a modular unit that combines numerous defensive mechanisms. These defensive mechanisms operate autonomously and respond to perceived threats.
AUTONOMOUS SAFETY AND SECURITY DEVICE ON AN UNMANNED PLATFORM UNDER COMMAND AND CONTROL OF A CELLULAR PHONE,https://lens.org/186-819-033-244-61X,2017,A safety and security device is housed on either an unmanned aerial vehicle or its land-based docking station and is combined with a cellular telephone for self-defense purposes. The phone broadcasts both recorded audio and video warnings on the device. A flashing light may be activated on the aerial platform or the docking station. The device may be integrated into a modular unit that combines numerous defensive mechanisms. These defensive mechanisms operate autonomously and respond to perceived threats.
"SYSTEMS, APPARATUS, AND METHODS FOR SAFETY EQUIPMENT DEPLOYMENT FROM A DRONE",https://lens.org/018-248-740-254-499,2019,"Systems, apparatus, and methods to deploy safety equipment from a drone are disclosed. An example apparatus includes a sensor to gather environmental data and an analyzer in communication with the sensor. In this example, the analyzer is to identify an anchor site based on the environmental data and produce an assessment of stability of the anchor site based on the environmental data and model data. The example apparatus also includes one or more actuators to deploy a securing device in response to the assessment of the analyzer indicating the anchor site is stable and to deploy the safety equipment."
"Systems, apparatus, and methods for safety equipment deployment from a drone",https://lens.org/108-934-928-363-227,2020,"Systems, apparatus, and methods to deploy safety equipment from a drone are disclosed. An example apparatus includes a sensor to gather environmental data and an analyzer in communication with the sensor. In this example, the analyzer is to identify an anchor site based on the environmental data and produce an assessment of stability of the anchor site based on the environmental data and model data. The example apparatus also includes one or more actuators to deploy a securing device in response to the assessment of the analyzer indicating the anchor site is stable and to deploy the safety equipment."
METHOD FOR MONITORING A STORAGE SYSTEM WITH A FLYING DRONE,https://lens.org/134-407-507-788-671,2021,A method of monitoring an automated storage and retrieval system (1) utilizing a flying drone (400) to locate and inspect anomalies in the operation of the system.
UNMANNED AERIAL VEHICLE AND A LANDING GUIDANCE METHOD USING THE SAME,https://lens.org/080-207-520-436-351,2017,"An unmanned aerial vehicle (UAV) is provided. The UAV includes a main body, a plurality of motors connected to the main body, each of the plurality of motors having a rotor blade, a plurality of ultrasonic sensors located at least one of the plurality of motors and the main body, and transmitting and receiving ultrasonic waves to and from a ground surface, and measuring distances from the ground surface, a gyro sensor disposed at the main body and maintaining the UAV in a horizontal state, and a controller disposed at the main body, detecting an unevenness of the ground surface based on the distances from the plurality of ultrasonic sensors to the ground surface, generating a control signal whether to land on the ground surface or not in response to the detection of the unevenness, and transmitting the control signal to the plurality of motors."
Unmanned aerial vehicle and a landing guidance method using the same,https://lens.org/145-904-417-853-739,2019,"An unmanned aerial vehicle (UAV) is provided. The UAV includes a main body, a plurality of motors connected to the main body, each of the plurality of motors having a rotor blade, a plurality of ultrasonic sensors located at least one of the plurality of motors and the main body, and transmitting and receiving ultrasonic waves to and from a ground surface, and measuring distances from the ground surface, a gyro sensor disposed at the main body and maintaining the UAV in a horizontal state, and a controller disposed at the main body, detecting an unevenness of the ground surface based on the distances from the plurality of ultrasonic sensors to the ground surface, generating a control signal whether to land on the ground surface or not in response to the detection of the unevenness, and transmitting the control signal to the plurality of motors."
DISRUPTION TO AN OPERATION OF AN UNMANNED AERIAL VEHICLE,https://lens.org/111-535-108-904-85X,2022,"A method for inducing a disruption to an operation of an unmanned aerial vehicle (UAV) that communicates with a remote controller. The method may include determining to induce the disruption to the operation of the UAV; and transmitting, to the UAV, one or more disrupting commands that once executed by the at UAV causes a unit of the UAV to malfunction, the malfunction induces the disruption to the operation of the UAV."
"Unmanned flying object, control method, and non-transitory recording medium storing program that switch flight state upon capturing an object in the air",https://lens.org/140-586-043-851-372,2020,"An unmanned flying object that flies in the air includes a capturer, including at least one of a net, a sucking device, a stick, a rope or a spear, that captures an object other than the unmanned flying object in the air, a sensor that detects that the capturer has captured the object, and a processor that performs operations including: receiving an operation signal via wireless communication; performing a manual flight control that controls the unmanned flying object on the basis of the operation signal; switching from the manual flight control to an autonomous flight control that controls the unmanned flying object to not be dependent on the operation signal received via the wireless communication, when the sensor detects the capture of the object while the manual flight control is being performed."
DISRUPTION TO AN OPERATION OF AN UNMANNED AERIAL VEHICLE,https://lens.org/111-535-108-904-85X,2022,"A method for inducing a disruption to an operation of an unmanned aerial vehicle (UAV) that communicates with a remote controller. The method may include determining to induce the disruption to the operation of the UAV; and transmitting, to the UAV, one or more disrupting commands that once executed by the at UAV causes a unit of the UAV to malfunction, the malfunction induces the disruption to the operation of the UAV."
Flying robot for remote sound signal acquisition,https://lens.org/052-218-469-872-470,2015,"The invention discloses a flying robot for remote sound signal acquisition. The flying robot comprises a four-axis aircraft and a remote ground station. A waveform acquisition layer, a flight control layer and an image acquisition layer are arranged on a center aircraft body of the four-axis aircraft, a partition plate 1, a rotary platform, a connecting platform 1 and a laser remote sound acquisition device are arranged on the waveform acquisition layer, the laser remote sound acquisition device is composed of a laser transmitting device and a laser receiving device, and the laser transmitting device is connected with the rotary platform through the connecting platform 1. The image acquisition layer is formed by a connecting platform 2 and a high-accuracy infrared camera, the flight control layer and the remote ground station are combined for remote control, the waveform acquisition layer and the remote ground station are combined for remote sound acquisition, and the image acquisition layer and the remote ground station are combined for navigation and auxiliary adjustment. By the utilization of the remote wireless control technology and the laser remote sound acquisition device and through the cooperation of the high-accuracy infrared camera and a GPS positioning system, a target position is accurately positioned, the laser remote sound acquisition device can be moved to a position where target sound is remotely captured, remote sound acquisition under remote control is achieved, the safety of personnel is improved, and the integrity of a scene is kept."
Environment Illumination For Autonomous Aerial Vehicles,https://lens.org/194-562-233-994-350,2021,"The technology described herein relates to autonomous aerial vehicle technology and, more specifically, to environment illumination for autonomous unmanned aerial vehicles. In some embodiments, a UAV includes upward-facing image capture devices, downward-facing image capture devices, one or more illumination sources, and a computer system. The computer system is configured to direct the one or more illumination sources to selectively emit light into a surrounding physical environment while the UAV is in flight, process images captured by any one or more of the plurality of upward-facing image capture devices or the plurality of downward-facing image capture devices to estimate a position and/or orientation of the aerial vehicle, generate a planned trajectory for the aerial vehicle through a physical environment based on the processing of the images, and control a propulsion system and/or flight surface of the aerial vehicle to cause the aerial vehicle to autonomously maneuver along the planned trajectory."
RAPID AIRCRAFT INSPECTION WITH AUTONOMOUS DRONE BASE STATION SYSTEMS,https://lens.org/125-382-857-461-623,2022,"A system for inspecting an aircraft includes a drone, a base station, and a controller. The drone includes one or more cameras. The base station has a storage compartment configured to store the autonomous drone therein. The controller has a processor and a memory. The memory has instructions stored thereon, which when executed by the processor, cause the base station to drive to a first predetermined location relative to the aircraft, and cause the drone to fly from the storage compartment of the base station to a first predetermined position relative to the aircraft so that the drone can record image data of at least portions of the aircraft with the one or more cameras."
Method of Flying an Unmanned Aerial Vehicle,https://lens.org/187-421-659-977-766,2014,"A method of flying an unmanned aerial vehicle (UAV) in response to emergency conditions, the method including steps implemented using a controller forming part of the unmanned aerial vehicle, said steps comprising: defining a plurality of emergency conditions; associating each emergency condition with a priority level; associating each emergency condition with an objective; sensing a plurality of operating parameters of the unmanned aerial vehicle to detect whether one of the plurality of emergency conditions exists; when one or more emergency condition is detected: generating a trajectory for the detected emergency condition having a highest associated priority level, wherein the trajectory is generated in accordance with the objective associated with the emergency condition that has the highest associated priority level; and instructing the unmanned aerial vehicle to follow the generated trajectory."
FIXED DRONE VISUALIZATION IN SECURITY SYSTEMS,https://lens.org/196-464-156-879-597,2022,"An unmanned aerial vehicle is described and includes a computer carried by the unmanned aerial vehicle to control flight of the unmanned aerial vehicle and at least one sensor. The unmanned aerial vehicle is caused to fly to a specific location within a facility, where the unmanned aerial vehicle enters a hover mode, where the unmanned aerial vehicle remains in a substantially fixed location hovering over the specific location within the facility and sends raw or processing results of sensor data from the sensor to a remote server system."
Fixed Drone Visualization In Security Systems,https://lens.org/005-377-596-943-896,2016,"An unmanned aerial vehicle is described and includes a computer carried by the unmanned aerial vehicle to control flight of the unmanned aerial vehicle and at least one sensor. The unmanned aerial vehicle is caused to fly to a specific location within a facility, where the unmanned aerial vehicle enters a hover mode, where the unmanned aerial vehicle remains in a substantially fixed location hovering over the specific location within the facility and sends raw or processing results of sensor data from the sensor to a remote server system."
Fixed drone visualization in security systems,https://lens.org/132-796-883-835-899,2023,"An unmanned aerial vehicle is described and includes a computer carried by the unmanned aerial vehicle to control flight of the unmanned aerial vehicle and at least one sensor. The unmanned aerial vehicle is caused to fly to a specific location within a facility, where the unmanned aerial vehicle enters a hover mode, where the unmanned aerial vehicle remains in a substantially fixed location hovering over the specific location within the facility and sends raw or processing results of sensor data from the sensor to a remote server system."
Fixed drone visualization in security systems,https://lens.org/124-600-395-296-382,2019,"An unmanned aerial vehicle is described and includes a computer carried by the unmanned aerial vehicle to control flight of the unmanned aerial vehicle and at least one sensor. The unmanned aerial vehicle is caused to fly to a specific location within a facility, where the unmanned aerial vehicle enters a hover mode, where the unmanned aerial vehicle remains in a substantially fixed location hovering over the specific location within the facility and sends raw or processing results of sensor data from the sensor to a remote server system."
FIXED DRONE VISUALIZATION IN SECURITY SYSTEMS,https://lens.org/196-464-156-879-597,2022,"An unmanned aerial vehicle is described and includes a computer carried by the unmanned aerial vehicle to control flight of the unmanned aerial vehicle and at least one sensor. The unmanned aerial vehicle is caused to fly to a specific location within a facility, where the unmanned aerial vehicle enters a hover mode, where the unmanned aerial vehicle remains in a substantially fixed location hovering over the specific location within the facility and sends raw or processing results of sensor data from the sensor to a remote server system."
Method and apparatus for robotic launch and capture of a UAV,https://lens.org/022-783-811-880-980,2020,"An apparatus and system for launching and/or capturing an unmanned aerial vehicle (UAV). The apparatus includes a moving substrate having an electromagnetic end effector and a UAV with a metallic strike plate to be attracted to the end effector when the electromagnet is activated. The system includes a movable robotic arm having a free end and a secured end; an electromagnetic end effector connected proximate to the free end of the robotic arm; a UAV with a metallic strike to be attracted and held to the electromagnetic end effector when the electromagnetic end effector is active; trajectory software configured to control a location of the free end of the robotic arm; and a control module for receiving input data, analyzing the data and using the trajectory software to control the location of and activate or deactivate the electromagnetic end effector. Also described are methods for launching and capturing the UAV."
Method and Apparatus for Robotic Launch and Capture of a UAV,https://lens.org/148-314-975-653-159,2019,"An apparatus and system for launching and/or capturing an unmanned aerial vehicle (UAV). The apparatus includes a moving substrate having an electromagnetic end effector and a UAV with a metallic strike plate to be attracted to the end effector when the electromagnet is activated. The system includes a movable robotic arm having a free end and a secured end; an electromagnetic end effector connected proximate to the free end of the robotic arm; a UAV with a metallic strike to be attracted and held to the electromagnetic end effector when the electromagnetic end effector is active; trajectory software configured to control a location of the free end of the robotic arm; and a control module for receiving input data, analyzing the data and using the trajectory software to control the location of and activate or deactivate the electromagnetic end effector. Also described are methods for launching and capturing the UAV."
Electronic fishing device steerable in azimuth and depth by remote control or preprogrammed instructions,https://lens.org/062-149-010-749-010,2003,"An electronic fishing device and control system. The fishing device includes an electro-mechanically actuated dive plane and rudder for steering the device in azimuth and depth by remote control or by preprogrammed instructions. In an autonomous mode, a device memory is preprogrammed with control instructions, and the device executes the instructions when placed in the water. In a remote control mode, the device is controlled by a remote control box located on a boat or shore. Preprogrammed instructions or user inputs may be utilized to steer the device. The control box may be interfaced with a fish finder to automatically generate commands to steer the device to fish detected by the fish finder."
Electronic fishing device steerable in azimuth and depth by remote control or preprogrammed instructions,https://lens.org/014-717-403-315-549,2004,"An electronic fishing device and control system. The fishing device includes an electro-mechanically actuated dive plane and rudder for steering the device in azimuth and depth by remote control or by preprogrammed instructions. In an autonomous mode, a device memory is preprogrammed with control instructions, and the device executes the instructions when placed in the water. In a remote control mode, the device is controlled by a remote control box located on a boat or shore. Preprogrammed instructions or user inputs may be utilized to steer the device. The control box may be interfaced with a fish finder to automatically generate commands to steer the device to fish detected by the fish finder."
Multi-Configuration Autonomous Platform With Mounted Camera,https://lens.org/001-471-374-834-403,2017,"A system for video imaging and photographing using an autonomous aerial platform. The system may be a quad rotor system using electrically powered propellers. The aerial platform may be commanded by the user to follow an object of interest. The aerial platform may have multiple configurations for its thrust units such that they are clear of the field of view of the imaging device in a first configuration, such that they protect the imaging device during landing in a second configuration, and that allows for efficient storage in a stowed configuration."
Multi-configuration autonomous platform with mounted camera,https://lens.org/009-573-444-147-130,2019,"A system for video imaging and photographing using an autonomous aerial platform. The system may be a quad rotor system using electrically powered propellers. The aerial platform may be commanded by the user to follow an object of interest. The aerial platform may have multiple configurations for its thrust units such that they are clear of the field of view of the imaging device in a first configuration, such that they protect the imaging device during landing in a second configuration, and that allows for efficient storage in a stowed configuration."
"A METHOD FOR INDUCING AN AUTONOMOUS BEHAVIOR INTO AN UNMANNED VEHICLE, AND A COMMUNICATION UNIT FOR USE IN SUCH A METHOD",https://lens.org/034-029-898-437-906,2020,"The present invention relates to a method for inducing an autonomous behavior into an unmanned vehicle, and a communication unit adapted for being mounted on an unmanned vehicle for use in such a method."
"A METHOD FOR INDUCING AN AUTONOMOUS BEHAVIOR INTO AN UNMANNED VEHICLE, AND A COMMUNICATION UNIT FOR USE IN SUCH A METHOD",https://lens.org/034-029-898-437-906,2020,"The present invention relates to a method for inducing an autonomous behavior into an unmanned vehicle, and a communication unit adapted for being mounted on an unmanned vehicle for use in such a method."
"A METHOD FOR INDUCING AN AUTONOMOUS BEHAVIOR INTO AN UNMANNED VEHICLE, AND A COMMUNICATION UNIT FOR USE IN SUCH A METHOD",https://lens.org/084-536-489-952-130,2021,"The present invention relates to a method for inducing an autonomous behavior into an unmanned vehicle, and a communication unit adapted for being mounted on an unmanned vehicle for use in such a method."
Unmanned aerial vehicles,https://lens.org/053-545-828-837-349,2020,"An unmanned aerial vehicle, UAV, includes (i) a camera having a field of vision including, in use, a portion of a vehicle to be cleaned, (ii) a liquid container comprising waterless carwash liquid, (iii) a liquid dispenser operable to cause the waterless carwash liquid comprised in the liquid container to be dispensed from the liquid container, (iv) a cleaning implement, and (v) a controller communicatively coupled to the camera, the liquid dispenser and the cleaning implement. The controller is operable (a) to cause the liquid dispenser to dispense the waterless carwash liquid from the liquid container onto the portion of the vehicle to be cleaned and (b) to control the cleaning implement to clean the portion of the vehicle to be cleaned."
"System, method, and program for controlling drone",https://lens.org/119-463-972-302-166,2019,"The present invention is to provide a system, a method, and a program for controlling a drone to take an image at high resolution if a predetermined condition is satisfied. The system includes an image acquisition unit that acquires an image taken by a drone; an image analysis unit that analyzes the acquired image; an extraction unit that extracts a point that satisfies a predetermined condition based on the result of the image analysis; a position coordinate acquisition unit that acquires the position coordinate of the extracted point; and a control unit that controls the drone to fly to the acquired position coordinate and take an image at a higher resolution than that of the analyzed image."
AUTONOMOUS ROBOTIC DEVICE AND ASSOCIATED CONTROL METHOD,https://lens.org/165-242-858-959-550,2019,"An autonomous device (110) and a method for controlling an autonomous device are disclosed. The autonomous device (110) is configured for performing at least one task, selected from a household task, a commercial task and an industrial task and comprises at least one spatial sensor (112) for generating location information; at least one further sensor (114) for determining at least one further parameter; at least one task unit (124) arranged to perform the household and/or commercial and/or industrial task; at least one electronics unit (126) configured to generate a map (128) using the location information and further configured for connecting the further parameter to the location information and for adding the location of the further parameter to the map (128), thereby creating a parameter map containing location- correlated values of the at least one further parameter."
"CONTROL DEVICE FOR CONTROLLING ROBOT BY LEARNING ACTION OF PERSON, ROBOT SYSTEM, AND PRODUCTION SYSTEM",https://lens.org/114-888-602-398-887,2018,"A control device for a robot for performing an operation in cooperation with a person, the control device includes a machine learning device including a recognition unit for classifying an action of the person, and a learning unit for learning the action of the person, while the person performs an operation in cooperation with the robot; and an action control unit for controlling the action of the robot based on a result of the classification of the recognition unit."
"Control device for controlling robot by learning action of person, robot system, and production system",https://lens.org/130-445-598-259-741,2019,"A control device for a robot for performing an operation in cooperation with a person, the control device includes a machine learning device including a recognition unit for classifying an action of the person, and a learning unit for learning the action of the person, while the person performs an operation in cooperation with the robot; and an action control unit for controlling the action of the robot based on a result of the classification of the recognition unit."
Power-driven ornithopter piloted by remote controller,https://lens.org/123-891-433-817-019,2003,"A power-driven ornithopter piloted by a remote controller wherein a takeoff and landing motion, a climbing and descending motion, and a turning motion of the ornithopter can be controlled using the remote controller. The ornithopter comprises a body, a main wing attached to an upper portion of a front section of the body, and tail wings attached to a rear section of the body. An electric motor, a power transmission mechanism, a battery, first and second servo motors and a controller are installed within a housing of the body. A crank arm is connected to a rotating shaft of the first servo motor and a connecting rod attached to a free end of the crank arm is then pivotally connected to a lower edge of the horizontal tail support. The second servo motor is mounted into a recess formed at an upper side of a rectangular parallelepiped of the horizontal tail support and a rotating shaft of the second servo motor is disposed on a central axis of the horizontal tail. A vertical tail support is supported by the rotating shaft of the second servo motor so that it can be swung on the rotating shaft of the second servo motor in a right and left direction as the rotating shaft of the second servo motor rotates."
"UNMANNED AERIAL VEHICLE, CONTROL METHOD, AND RECORDING MEDIUM",https://lens.org/152-963-838-346-501,2021,"Unmanned aerial vehicle includes a microphone which picks up a sound emitted by a target, an actuator which extends to change a position of the microphone, and a processor. The processor obtains positional relationship information which indicates at least one of a position of the target or a distance from the unmanned aerial vehicle to the target, causes the unmanned aerial vehicle to move to a first position at which the unmanned aerial vehicle and the target have a predetermined positional relationship based on the positional relationship information, and causes actuator to extend toward the target after unmanned aerial vehicle moves to the first position."
MOTOR POSITIONAL SENSING,https://lens.org/047-570-667-575-161,2021,"An unmanned aerial vehicle (UAV) includes a UAV body, and a stabilizing platform mounted on the UAV body and configured to stabilize a payload device. The stabilizing platform includes a frame assembly adapted to hold the payload device and a brushless motor coupled to the frame assembly. The brushless motor is configured to directly drive the frame assembly in response to one or more motor signals to allow the payload device to rotate around at least one of a pitch axis, a roll axis, or a yaw axis of the payload device. A brushless motor includes a rotor housing; a stator disposed within the rotor housing; and a linear Hall effect sensor. A posture of the payload device is controlled by adjusting a rotational angle of the brushless motor, and the rotational angle of the brushless motor is determined using the linear Hall effect sensor."
Motor positional sensing,https://lens.org/075-227-088-612-156,2022,"An unmanned aerial vehicle (UAV) includes a UAV body, and a stabilizing platform mounted on the UAV body and configured to stabilize a payload device. The stabilizing platform includes a frame assembly adapted to hold the payload device and a brushless motor coupled to the frame assembly. The brushless motor is configured to directly drive the frame assembly in response to one or more motor signals to allow the payload device to rotate around at least one of a pitch axis, a roll axis, or a yaw axis of the payload device. A brushless motor includes a rotor housing; a stator disposed within the rotor housing; and a linear Hall effect sensor. A posture of the payload device is controlled by adjusting a rotational angle of the brushless motor, and the rotational angle of the brushless motor is determined using the linear Hall effect sensor."
Motor positional sensing,https://lens.org/075-227-088-612-156,2022,"An unmanned aerial vehicle (UAV) includes a UAV body, and a stabilizing platform mounted on the UAV body and configured to stabilize a payload device. The stabilizing platform includes a frame assembly adapted to hold the payload device and a brushless motor coupled to the frame assembly. The brushless motor is configured to directly drive the frame assembly in response to one or more motor signals to allow the payload device to rotate around at least one of a pitch axis, a roll axis, or a yaw axis of the payload device. A brushless motor includes a rotor housing; a stator disposed within the rotor housing; and a linear Hall effect sensor. A posture of the payload device is controlled by adjusting a rotational angle of the brushless motor, and the rotational angle of the brushless motor is determined using the linear Hall effect sensor."
INDOOR AUTONOMOUS NAVIGATION SYSTEM,https://lens.org/167-192-025-034-131,2017,A system for autonomous navigation within an enclosed area is provided. The system can have a remote control station having a route management system operable to determine a flight plan. The system can further have a device configured for unmanned operation having a transceiver operable to receive the flight plan from the remote control station. The device can have a memory operable to store the flight plan and an electromagnetic (EM) map of the enclosed area. The device can have a location determination sensor (LDS) operable to determine a three dimensional position of the device within the enclosed area based on the EM map. The device can then execute the flight plan based on the three dimensional position and the EM map.
Drone with no external propeller blades,https://lens.org/027-436-220-843-059,2019,"A drone having a main housing unit, wherein a set of turbines, a speed controller and an electrical controlling unit are located and is powered by an engine without the necessity for external propellers such that the blade-less engines allows the propellers (or blades) to remain hidden instead of removing them from the overall system. A power source is located within a main housing of the drone system that allows for accelerated airflow for the blade-less engine thus lifting the drone up in the air. The turbines facilitate air flow radially outward from a center of the main housing unit, wherein air is fed to the turbines through an air intake unit at the top of the main housing unit and is then accelerated by the turbines through a plurality of arm units, which force the air into an inlet tunnel located along the perimeter of a nozzle."
Remotely Controlled Multirotor Aircraft Comprising an Improved Frame,https://lens.org/094-118-472-725-346,2020,"A remotely controlled multirotor aircraft having a frame that includes a first and a second peripheral portions, to which at least one first and one second motor can be respectively coupled, and a central portion including a first end and a second end, to which the first peripheral portion and the second peripheral portion are respectively coupled, so that the first peripheral portion develops in a plane that is different from that in which the second peripheral portion develops; furthermore, the central portion also includes a coupling mechanism allowing the coupling between the central portion and a mobile device having video acquisition ability."
Remotely controlled multirotor aircraft comprising an improved frame,https://lens.org/030-484-816-239-818,2023,"A remotely controlled multirotor aircraft having a frame that includes a first and a second peripheral portions, to which at least one first and one second motor can be respectively coupled, and a central portion including a first end and a second end, to which the first peripheral portion and the second peripheral portion are respectively coupled, so that the first peripheral portion develops in a plane that is different from that in which the second peripheral portion develops; furthermore, the central portion also includes a coupling mechanism allowing the coupling between the central portion and a mobile device having video acquisition ability."
Remotely controlled multirotor aircraft comprising an improved frame,https://lens.org/030-484-816-239-818,2023,"A remotely controlled multirotor aircraft having a frame that includes a first and a second peripheral portions, to which at least one first and one second motor can be respectively coupled, and a central portion including a first end and a second end, to which the first peripheral portion and the second peripheral portion are respectively coupled, so that the first peripheral portion develops in a plane that is different from that in which the second peripheral portion develops; furthermore, the central portion also includes a coupling mechanism allowing the coupling between the central portion and a mobile device having video acquisition ability."
"ACCELEROMETER BASED CONTROLLER, CONTROLLED DEVICE AND CONTROL METHODS THEREOF",https://lens.org/122-928-976-686-481,2011,"An accelerometer (101, 202) based controller (102), a controlled device (104) and control methods thereof. The controller (102) is adapted to control the controlled device (104). In response to hand movement, the accelerometer (101, 202) in the controller (102) produces acceleration and/or angle signals. The signals are sent to a processor (204) in the controller (102). The processor (204) is configured to determine a trajectory based on the signals and/or identify a command which is used to control the controlled device (104). The controlled device (104), for example, a cleaning unit for washing windows, can be secured to, for example, a window. Upon identifying the command from the controller (102), the controlled device (104) can respond to the command. The command can be instructions for the controlled device (104) to move about the window and/or activate a cleaning system."
UNMANNED AERIAL VEHICLE (UAV) HAVING VERTICAL TAKEOFF AND LANDING (VTOL) CAPABILITY,https://lens.org/164-825-378-763-696,2017,"An unmanned aerial vehicle (10) (UAV), or drone, includes a fuselage (12), left and right airfoil-shaped wings (14, 16) connected to the fuselage (12) to generate lift in forward flight, a left thrust-generating device (18) supported by the left wing (14), and a right thrust-generating device (20) supported by the right wing (16). The UAV further includes a vertical stabilizer (26, 32), a top thrust-generating device (28) mounted to a top portion of the vertical stabilizer (26, 32), and a bottom thrust-generating device (30) mounted to a bottom portion of the vertical stabilizer. An onboard power source (38) is provided for powering the thrust-generating devices. The left, right, top and bottom thrust-generating devices (18, 20, 28, 34) provide forward thrust during forward flight and also provide vertical thrust to enable the unmanned aerial vehicle (10) to take-off and land vertically when the fuselage (12) is substantially vertical and further enabling the unmanned aerial vehicle (10) to transition between forward flight and vertical take-off and landing."
Ducted rotor unmanned aerial vehicles,https://lens.org/127-527-737-794-80X,2018,"Systems and methods in accordance with various embodiments of the invention can be utilized to implement unmanned aerial vehicles (UAVs) designed for autonomous operation in cluttered environments, indoor environments and/or as photography drones. One embodiment includes: launching an unmanned aerial vehicle (UAV); performing in flight path planning to scan an area for people using the UAV; detecting the presence of at least one subject by processing image data captured by at least one camera on the UAV; determining at least one pose from which to capture images of detected at least one subject using the UAV; performing path planning to navigate the UAV to the determined at least one pose; and capturing images of the detected at least one subject using at least one camera on the UAV when the UAV is posed in one of the determined at least one pose."
A drone,https://lens.org/027-918-272-125-544,2021,"A drone comprising a plurality of hollow struts (Fig. 1, 16a  16f), which extend from the body of the drone, each comprising a motor (Fig. 2, 18a  18f) for driving a propeller (Fig. 2, 17a  17f) and a fan. The fan draws air down the hollow struts in order to cool the components within the body. The fan may be located at the end of the strut nearest the drone body, such that the fan draws air from an inlet and exhausts it through the end of the strut further from the drone body. Inlet includes a cowl to prevent the ingress of rainwater. A drone body comprising electrical circuitry and a fan in order to cool the components, driving exhaust air from a vent port. The components of the drone may have a heat sink, possibly including a fin, and the fans may be positioned so as to force air over the heat sink. The drone may include: image capture and image transmitter for a remote receiver; air quality monitor and signal transmitter; a tether for the drone, which comprises a winch, and may be used to receive an electrical current."
Drone Stabilizing Handgrip,https://lens.org/160-540-986-389-20X,2019,"A method of manually photographing or recording video footage with a drone or other unmanned vehicle. The drone is securely attached to a handgrip or handgrips. The method enables stabilization and control of the images a drone camera records. Risk of damage to the drone is reduced, while quality of the captured footage is enhanced. A phone or other portable electronic display is attached to allow viewing and control of recorded images."
DEVICE AND METHOD FOR BLASTING AVALANCHES,https://lens.org/037-489-729-620-896,2020,"The invention relates to a device and to a method for avalanche blasting. The device comprises a drone, an explosive charge which is fastened by means of a cord in a freely suspended manner to the drone. An ignition mechanism is provided for igniting the explosive charge. The ignition mechanism can be triggered in a remote-controlled or automatic manner. Any desired destinations can be reached using this device in order to blast avalanches. The explosive charge can be positioned above the snow cover that is to be blasted."
State and context dependent voice based interface for an unmanned vehicle or robot,https://lens.org/099-169-886-081-335,2017,"A voice-based method to control unmanned vehicles (UV) or robots that makes use of the UV or robot state and context information to constrain the output of automatic speech recognition (ASR) language models (LM) to improve the ASR accuracy and robustness in controlled and adverse environments. The voiced interaction between the human user and the machine provides a natural human-machine interface that is easy and straightforward for the human being, and reduces users' training requirements."
STATE AND CONTEXT DEPENDENT VOICE BASED INTERFACE FOR AN UNMANNED VEHICLE OR ROBOT,https://lens.org/195-931-010-000-678,2016,"A voice-based method to control unmanned vehicles (UV) or robots that makes use of the UV or robot state and context information to constrain the output of automatic speech recognition (ASR) language models (LM) to improve the ASR accuracy and robustness in controlled and adverse environments. The voiced interaction between the human user and the machine provides a natural human-machine interface that is easy and straightforward for the human being, and reduces users' training requirements."
"Drone based accident,traffic surveillance",https://lens.org/148-137-012-892-283,2018,"A drone 200 with a camera 202 which captures images of a roadway 302 beneath it and wirelessly sends live images to an analysis centre 400; an operator 420 analyses the real time images 308 and sends out information over a cellular network 327. The information may be the live image taken by the drone 308, which was selected by the operator; or transferred via two way audio communication. The drone may comprise a network access device 204 through which the analysis centre 400 accesses the cameras images. The drone may communicate over radio frequency (rf) signals with the analysis centre and preferably will use a cellular network. The information provided by the analysis centre may is provided to a vehicle 326 which may alter its route based on the information provided. The information may be sent to subscribers who have paid to receive the information.Also disclosed is an up pole hangar for the drone (figure 5)."
System and method for returning a drone to a dock after flight,https://lens.org/184-159-515-367-555,2022,"Methods, systems, apparatus, including computer programs encoded on a computer storage medium, for returning a drone to a drone dock. In one aspect, a method includes detecting, by the drone and using a drone-mounted light detection unit, a first light signal and a second light signal generated by one of a plurality of visible light communication devices coupled to the drone dock, obtaining, by the drone, location information based on the first detected light signal and the second detected light signal, determining, by the drone, a position of the drone relative to the drone dock based on the obtained location information, and adjusting, by the drone, the navigation path of the drone in a manner that alters an alignment of at least a portion of the drone relative to the drone dock based on the determined position."
System and method for preventing inadvertent loss of command and control link to an unmanned aerial system,https://lens.org/062-979-532-396-315,2022,"An unmanned aerial system (UAS) is disclosed. In embodiments, the UAS includes an unmanned aerial vehicle (UAV), and a controller communicatively coupled to the UAV. In embodiments, the UAS controller may be configured to: acquire a command and control (C2) link quality model for a planned route; generate one or more control signals configured to cause the UAV to perform a monitored flight along a planned route; acquire actual C2 link quality data during the monitored flight along the planned route; compare the actual C2 link quality data to the C2 link quality model; identify a C2 link quality deviation between the actual C2 link quality and the C2 link quality model; and generate one or more control signals configured to cause the UAV to perform one or more prescribed flight plan maneuvers if the identified C2 link quality deviation (C2LQ) exceeds a threshold deviation value (C2thresh)."
SYSTEM AND METHOD FOR PREVENTING INADVERTENT LOSS OF COMMAND AND CONTROL LINK TO AN UNMANNED AERIAL SYSTEM,https://lens.org/109-668-997-731-043,2022,"An unmanned aerial system (UAS) is disclosed. In embodiments, the UAS includes an unmanned aerial vehicle (UAV), and a controller communicatively coupled to the UAV. In embodiments, the UAS controller may be configured to: acquire a command and control (C2) link quality model for a planned route; generate one or more control signals configured to cause the UAV to perform a monitored flight along a planned route; acquire actual C2 link quality data during the monitored flight along the planned route; compare the actual C2 link quality data to the C2 link quality model; identify a C2 link quality deviation between the actual C2 link quality and the C2 link quality model; and generate one or more control signals configured to cause the UAV to perform one or more prescribed flight plan maneuvers if the identified C2 link quality deviation (C2LQ) exceeds a threshold deviation value (C2thresh)."
System and method for preventing inadvertent loss of command and control link to an unmanned aerial system,https://lens.org/062-979-532-396-315,2022,"An unmanned aerial system (UAS) is disclosed. In embodiments, the UAS includes an unmanned aerial vehicle (UAV), and a controller communicatively coupled to the UAV. In embodiments, the UAS controller may be configured to: acquire a command and control (C2) link quality model for a planned route; generate one or more control signals configured to cause the UAV to perform a monitored flight along a planned route; acquire actual C2 link quality data during the monitored flight along the planned route; compare the actual C2 link quality data to the C2 link quality model; identify a C2 link quality deviation between the actual C2 link quality and the C2 link quality model; and generate one or more control signals configured to cause the UAV to perform one or more prescribed flight plan maneuvers if the identified C2 link quality deviation (C2LQ) exceeds a threshold deviation value (C2thresh)."
SYSTEM AND METHOD FOR PREVENTING INADVERTENT LOSS OF COMMAND AND CONTROL LINK TO AN UNMANNED AERIAL SYSTEM,https://lens.org/109-668-997-731-043,2022,"An unmanned aerial system (UAS) is disclosed. In embodiments, the UAS includes an unmanned aerial vehicle (UAV), and a controller communicatively coupled to the UAV. In embodiments, the UAS controller may be configured to: acquire a command and control (C2) link quality model for a planned route; generate one or more control signals configured to cause the UAV to perform a monitored flight along a planned route; acquire actual C2 link quality data during the monitored flight along the planned route; compare the actual C2 link quality data to the C2 link quality model; identify a C2 link quality deviation between the actual C2 link quality and the C2 link quality model; and generate one or more control signals configured to cause the UAV to perform one or more prescribed flight plan maneuvers if the identified C2 link quality deviation (C2LQ) exceeds a threshold deviation value (C2thresh)."
Active maple seed flyer,https://lens.org/135-786-649-328-848,2012,"An unmanned aerial vehicle (UAV) has a payload or body affixed at one end of an elongated airfoil. The entire airfoil/payload combination rotates about a center of mass to define a rotor disk. Thrust is provided by air-augmented rocket engine thrusting tangentially at a location remote from the payload. A control system maintains knowledge of its environment, as by a camera, to produce directional control signals which actuate lift control means in synchronism with the rotational position of the vehicle. A deployable object may be carried. Protection of the stowed vehicle is provided by blister packaging."
Active maple seed flyer,https://lens.org/171-531-360-947-286,2010,"An unmanned aerial vehicle (UAV) has a payload or body affixed at one end of an elongated airfoil. The entire airfoil/payload combination rotates about a center of mass to define a rotor disk. Thrust is provided by air-augmented rocket engine thrusting tangentially at a location remote from the payload. A control system maintains knowledge of its environment, as by a camera, to produce directional control signals which actuate lift control means in synchronism with the rotational position of the vehicle. A deployable object may be carried. Protection of the stowed vehicle is provided by blister packaging."
"Drone Remote Piloting Electronic System, Associated Method and Computing Program",https://lens.org/121-533-206-135-605,2019,"Electronic system for the remote control ( 3 ) of drones ( 2 ), designed to detect a risk of passing authorized flight zone limits as a function of authorized flight zone limit definition data of the authorized flight limit(s) and the geographical location of the drone or a remote control command received and for determining, as a function of the control command and extrapolation over time of control according to this command, a limit-passing status, and triggering an alarm as a function of the determination; ordetermining another remote control command intended for the drone to prevent the passing of a flight zone limit; orblocking the transmission to the drone of the remote control command received in order to prevent the drone passing the flight zone limit."
"Drone remote piloting electronic system, associated method and computing program",https://lens.org/166-797-606-661-163,2021,"Electronic system for the remote control ( 3 ) of drones ( 2 ), designed to detect a risk of passing authorized flight zone limits as a function of authorized flight zone limit definition data of the authorized flight limit(s) and the geographical location of the drone or a remote control command received and for determining, as a function of the control command and extrapolation over time of control according to this command, a limit-passing status, and triggering an alarm as a function of the determination; ordetermining another remote control command intended for the drone to prevent the passing of a flight zone limit; orblocking the transmission to the drone of the remote control command received in order to prevent the drone passing the flight zone limit."
NEURAL NETWORK-BASED IMAGE TARGET TRACKING BY AERIAL VEHICLE,https://lens.org/128-238-882-440-317,2019,Structural and/or computational parameters of a neural network used for flight control in an unmanned aerial vehicle (UAV) are computed remotely and uploaded to the UAV. The parameters may correspond to a recomputation of previously optimized neural network parameters based on data obtained by imaging by the UAV.
UNMANNED AERIAL DELIVERY DEVICE,https://lens.org/011-793-093-510-239,2016,"An unmanned aerial delivery device has a plurality of rotors for propulsion and control, including redundant rotors in case of failure of a primary rotor, and uses a Laser Rangefinder system to guide the delivery device around an obstacle in its path until an acceptable straight-line path to a recipient is found, detect when a rotor is inoperable, and detect the distance from a take-off or landing surface to retract or extend support legs. The device has an insulated payload chamber that can only be opened by entering an unlock code on a touchscreen"
UNMANNED AERIAL DELIVERY DEVICE,https://lens.org/075-974-444-134-365,2016,"An unmanned aerial delivery device has a plurality of rotors for propulsion and control, including redundant rotors in case of failure of a primary rotor, and uses a Laser Rangefinder system to guide the delivery device around an obstacle in its path until an acceptable straight-line path to a recipient is found, detect when a rotor is inoperable, and detect the distance from a take-off or landing surface to retract or extend support legs. The device has an insulated payload chamber that can only be opened by entering an unlock code on a touchscreen"
SYSTEM AND METHOD FOR SUPPORTING PHYSICAL EXERCISES,https://lens.org/089-611-350-311-522,2017,"The present invention relates to a person performing physical exercises, comprising: - a flying, and/or ground-moving drone; - a projector arranged at the drone; - a surveillance sensor arranged at the drone for observing spatial confinements in an environment of the person and for identifying one or more surfaces in the environment of the person; - a memory unit for storing images or image sequences relating to training instructions for different kinds of physical exercises; and - a control unit which is configured: to select at least one of the one or more surfaces identified by the surveillance sensor, based on at least one of: (i) the observed spatial confinements, (ii) the kind of physical exercise, and (iii) characteristics of the one or more surfaces, and to control the projector upon request to project at least one of the images or image sequences of the at least one subset onto the at least one surface that has been selected for said at least one image or image sequence."
MODULAR DRONE AND METHODS FOR USE,https://lens.org/046-073-795-053-903,2014,Various exemplary embodiments relate to a drone. The drone may include: a navigation unit configured to determine the location of the drone and navigate the drone to designated locations; a radio frequency identification (RFID) reader configured to read RFID tag information from RFID tags; and a wireless network transceiver configured to periodically transmit the location of the drone and RFID tag information to an inventory management system. Various exemplary embodiments relate to a method performed by a drone. The method may include: receiving navigation path information; navigating the drone along the navigation path based on satellite location signals; determining current position information based on the satellite location signals; reading RFID tag information from a first RFID tag; and transmitting the RFID tag information and the current position information via a wireless client to a central computing system.
MODULAR DRONE AND METHODS FOR USE,https://lens.org/037-209-361-488-76X,2015,Various exemplary embodiments relate to a drone. The drone may include: a navigation unit configured to determine the location of the drone and navigate the drone to designated locations; a radio frequency identification (RFID) reader configured to read RFID tag information from RFID tags; and a wireless network transceiver configured to periodically transmit the location of the drone and RFID tag information to an inventory management system. Various exemplary embodiments relate to a method performed by a drone. The method may include: receiving navigation path information; navigating the drone along the navigation path based on satellite location signals; determining current position information based on the satellite location signals; reading RFID tag information from a first RFID tag; and transmitting the RFID tag information and the current position information via a wireless client to a central computing system.
Modular drone and methods for use,https://lens.org/054-841-207-685-488,2015,Various exemplary embodiments relate to a drone. The drone may include: a navigation unit configured to determine the location of the drone and navigate the drone to designated locations; a radio frequency identification (RFID) reader configured to read RFID tag information from RFID tags; and a wireless network transceiver configured to periodically transmit the location of the drone and RFID tag information to an inventory management system. Various exemplary embodiments relate to a method performed by a drone. The method may include: receiving navigation path information; navigating the drone along the navigation path based on satellite location signals; determining current position information based on the satellite location signals; reading RFID tag information from a first RFID tag; and transmitting the RFID tag information and the current position information via a wireless client to a central computing system.
MODULAR DRONE AND METHODS FOR USE,https://lens.org/061-356-485-956-422,2014,Various exemplary embodiments relate to a drone. The drone may include: a navigation unit configured to determine the location of the drone and navigate the drone to designated locations; a radio frequency identification (RFID) reader configured to read RFID tag information from RFID tags; and a wireless network transceiver configured to periodically transmit the location of the drone and RFID tag information to an inventory management system. Various exemplary embodiments relate to a method performed by a drone. The method may include: receiving navigation path information; navigating the drone along the navigation path based on satellite location signals; determining current position information based on the satellite location signals; reading RFID tag information from a first RFID tag; and transmitting the RFID tag information and the current position information via a wireless client to a central computing system.
Modular drone and methods for use,https://lens.org/089-216-960-623-54X,2017,Various exemplary embodiments relate to a drone. The drone may include: a navigation unit configured to determine the location of the drone and navigate the drone to designated locations; a radio frequency identification (RFID) reader configured to read RFID tag information from RFID tags; and a wireless network transceiver configured to periodically transmit the location of the drone and RFID tag information to an inventory management system. Various exemplary embodiments relate to a method performed by a drone. The method may include: receiving navigation path information; navigating the drone along the navigation path based on satellite location signals; determining current position information based on the satellite location signals; reading RFID tag information from a first RFID tag; and transmitting the RFID tag information and the current position information via a wireless client to a central computing system.
EASY LANDING DRONE,https://lens.org/145-400-188-358-89X,2016,"Disclosed is an easy landing drone. The drone includes: a propeller changing direction; a propeller tower supporting the propeller; a body connected to the propeller tower; a main wing arranged left-right symmetrically with respect to a horizontal axis of the body and having a pair of holes around a center of gravity of the body; a pair of auxiliary wings disposed in the pair of holes, respectively; and an actuator connected to a base shaft fixed to the main wing through the pair of auxiliary wings and controlling angles of the pair of auxiliary wings."
LOCALIZED VIRTUAL PERSONAL ASSISTANT,https://lens.org/146-330-864-186-778,2020,"An embodiment sets forth a technique for controlling a device at a location via a localized assistant application that processes locally inputs for controlling the device. The technique includes detecting a device at a location, associating the device with at least one device command, receiving an input, processing the input locally to determine a device command associated with the input and included in the at least one device command, and causing at least one operation to be performed by the device in accordance with the device command."
"UNMANNED FLIGHT BODY, CONTROL METHOD, AND PROGRAM",https://lens.org/086-274-020-644-697,2022,"Unmanned aerial vehicle (100) includes a microphone (111) which picks up a sound emitted by a target, an actuator (130) which extends to change a position of the microphone (111), and a processor (151). The processor (151) obtains positional relationship information which indicates at least one of a position of the target or a distance from the unmanned aerial vehicle (100) to the target, causes the unmanned aerial vehicle (100) to move to a first position at which the unmanned aerial vehicle (100) and the target have a predetermined positional relationship based on the positional relationship information, and causes actuator (130) to extend toward the target after unmanned aerial vehicle (100) moves to the first position."
"UNMANNED FLYING OBJECT, CONTROL METHOD, AND NON-TRANSITORY RECORDING MEDIUM STORING PROGRAM",https://lens.org/037-027-059-608-700,2017,"A capture drone is an unmanned flying object that flies in the air. The capture drone includes a capture net that captures other object in the air, a weight capture determining unit that detects that the capture net has captured the object, and an autonomous flight controller that controls a flight state of the capture drone to be an autonomous flight state not dependent on an operation signal from the outside if the weight capture determining unit detects the capture of the object."
SYSTEMS AND METHODS FOR STARTING A SENSORLESS MOTOR,https://lens.org/069-186-268-166-645,2023,"Systems, devices, and methods for: an unmanned aerial vehicle (UAV); at least one sensorless motor of the UAV, the at least one sensorless motor comprising a set of windings and a rotor; at least one propeller connected to the at least one sensorless motor; a microcontroller in communication with the at least one sensorless motor, wherein the microcontroller is configured to: determine a rotation rate of the at least one propeller; determine a rotation direction of the at least one propeller; provide an output to stop the at least one propeller if at least one of: the determined rotation rate is not a desired rotation rate and the determined rotation direction is not a desired rotation direction; and provide an output to start the at least one propeller if the at least one propeller is stopped at the desired rotation rate and the desired rotation direction."
SYSTEMS AND METHODS FOR STARTING A SENSORLESS MOTOR,https://lens.org/069-186-268-166-645,2023,"Systems, devices, and methods for: an unmanned aerial vehicle (UAV); at least one sensorless motor of the UAV, the at least one sensorless motor comprising a set of windings and a rotor; at least one propeller connected to the at least one sensorless motor; a microcontroller in communication with the at least one sensorless motor, wherein the microcontroller is configured to: determine a rotation rate of the at least one propeller; determine a rotation direction of the at least one propeller; provide an output to stop the at least one propeller if at least one of: the determined rotation rate is not a desired rotation rate and the determined rotation direction is not a desired rotation direction; and provide an output to start the at least one propeller if the at least one propeller is stopped at the desired rotation rate and the desired rotation direction."
"Unmanned aerial vehicle with electrically powered, counterrotating ducted rotors",https://lens.org/021-784-507-998-042,2010,"An unmanned aerial vehicle having counterrotating ducted rotors that are driven by electric motors. The vehicle has a low weight and a small profile. The unmanned aerial vehicle is suitable for a number of different tasks, including control, surveillance and reconnaissance, communication, and other tasks without exposing personnel to dangerous situations. The vehicle is particularly suited for entering buildings and other enclosed structures and spaces such as caves. The unmanned aerial vehicle can also be equipped for potential offensive actions."
UNMANNED AERIAL VEHICLE CONTROL METHOD AND DEVICE,https://lens.org/067-509-120-998-999,2021,"A method for controlling an unmanned aerial vehicle includes receiving update data of a flight restriction database of the unmanned aerial vehicle returned by a server in response to an updating request and carrying current position information of the unmanned aerial vehicle, and, if the update data satisfies a condition controlling, controlling flight of the unmanned aerial vehicle according to the update data."
A dual-function landing gear and rotor protector for a UAV,https://lens.org/171-996-584-767-698,2012,"An unmanned aerial vehicle (UAV) includes at least one rotor 6 driven by a motor 4 that is mounted to a housing 12. A dual-function member is connected to the housing and comprises an arm 8 and a beam 10. The dual-function member is movable between a first position where it acts as a landing gear and a second position where it acts as a rotor protector. A control means is arranged to control movement of the member. The control means may include a processor (40, fig 5) and a sensor (44, fig 5) for determining height from ground. The processor may determine to move the member to one or other of the positions based on the height of the UAV. Reconfiguration of the landing gear as a rotor protector prevents the view of a camera carried by the UAV from being obscured and allows a strong and light rotor protector without significant added weight. A rotor protector or landing gear may include a dampening means to absorb forces of impact."
Unmanned Aerial Vehicle Deployment System,https://lens.org/041-535-953-645-982,2017,"A system for enabling an unmanned aerial vehicle (UAV) to respond to an alert on a premises, where the UAV may either confront the alert situation or monitor the alert situation from a distance. The UAV may respond to the alert situation after a controller receives alert event data from an alert generator. The controller may further match the data received to a number of event types stored in a database. This information allows a flight plan to be determined which will allow the UAV to navigate to a location associated with the alert situation."
Unmanned aerial vehicle deployment system,https://lens.org/120-374-527-672-08X,2019,"A system for enabling an unmanned aerial vehicle (UAV) to respond to an alert on a premises, where the UAV may either confront the alert situation or monitor the alert situation from a distance. The UAV may respond to the alert situation after a controller receives alert event data from an alert generator. The controller may further match the data received to a number of event types stored in a database. This information allows a flight plan to be determined which will allow the UAV to navigate to a location associated with the alert situation."
Unmanned aerial vehicle achieving positioning and landing through image recognition,https://lens.org/002-706-215-263-64X,2015,"An unmanned aerial vehicle achieving positioning and landing through image recognition is characterized by comprising a vehicle body, electric rotor wings, a flight state computer control system, a remote controller and a ground control center; one or more shooting devices are arranged at the bottom of the vehicle body, and the shooting device is in signal connection with a host of the flight state computer control system; and the flight state computer control system carries out the comparison analysis on pictures provided by the shooting device in real time and picture information in a database, and a flight instruction is given comprehensively to control the unmanned aerial vehicle to fly and land. For a remote control aircraft only executing the flight task in the small space range, positioning of the remote control aircraft can be well achieved through image recognition, and aircraft explosion is avoided. Under the situation, the number of needed software and hardware resources is not large. The communication secrecy performance is good through communication optical fibers or power transmission lines. An external power source can prolong the hang time of the unmanned aerial vehicle."
"GIMBAL CONTROL METHOD AND DEVICE, GIMBAL, AND UNMANNED AERIAL VEHICLE",https://lens.org/167-197-612-732-199,2020,"A gimbal is provided for an unmanned aerial vehicle (UAV). The gimbal includes a processor, a rotational axis mechanism, a motor for driving the rotational axis mechanism, and a first sensor for providing first attitude data of the gimbal. The processor is configured to obtain a first instruction to control movement of the gimbal; acquire the first attitude data from the first sensor; acquire second attitude data of the UAV that is connected to the gimbal; adjust a control direction of the first instruction based on the first attitude data and the second attitude data to obtain a second instruction for controlling the gimbal; and control movement of the motor using the second instruction to drive the rotational axis mechanism so as to realize the controlling of the gimbal."
Apparatus for Sustained Surveillance and Deterrence with Unmanned Aerial Vehicles (UAV),https://lens.org/029-741-805-132-360,2019,"An apparatus for sustained surveillance and/or deterrence of animals, such as birds, from an area, comprising one or more unmanned aerial vehicles (UAVs) controlled autonomously or remotely or with minimal human intervention and having a plurality of deterrence capabilities, including but not limited to flight path changes, movement changes, flight speed changes, visual projections and audio projections."
"SYSTEMS, APPARATUSES AND METHODS FOR UNMANNED AERIAL VEHICLE",https://lens.org/053-322-449-212-156,2018,"A system includes an unmanned aerial vehicle (UAV). The UAV may include a camera device configured to capture at least video data; a receiver configured to receive wireless communications; a transmitter configured to transmit wireless communications; storage linked with the camera device, the receiver, and the transmitter and configured to store data captured by the camera device and wireless communications received by the receiver; and a processor linked with and configured to exercise control over the camera device, the receiver, the transmitter, and the storage. The UAV is configured to dock with a docking station mounted on a vehicle. The UAV may have other components such as a microphone and sensors, and may perform various functions such as surveillance, tracking, warning, and data storage, transmission and relay. Associated methods and docking stations are also disclosed."
"Systems, apparatuses and methods for unmanned aerial vehicle",https://lens.org/198-156-793-824-95X,2019,"A system includes an unmanned aerial vehicle (UAV). The UAV may include a camera device configured to capture at least video data; a receiver configured to receive wireless communications; a transmitter configured to transmit wireless communications; storage linked with the camera device, the receiver, and the transmitter and configured to store data captured by the camera device and wireless communications received by the receiver; and a processor linked with and configured to exercise control over the camera device, the receiver, the transmitter, and the storage. The UAV is configured to dock with a docking station mounted on a vehicle. The UAV may have other components such as a microphone and sensors, and may perform various functions such as surveillance, tracking, warning, and data storage, transmission and relay. Associated methods and docking stations are also disclosed."
Autonomously motile device with audio reflection detection,https://lens.org/177-625-224-786-698,2022,"A device capable of autonomous motion may move in response to a user speaking an utterance, such as a command. Before moving, the device processes audio data received from a microphone array to identify different audio signals arriving at the device from different directions. Based on properties of the audio signals, the device determines which of the audio signals are merely reflections of other audio."
DRONE WITH REMOTE ID,https://lens.org/130-691-144-100-473,2022,"A global positioning satellite (GPS) receiver (300) and a transmitter (e.g., 314, 321A, 321B) are at a base (202) remote from a drone (204), and the transmitter sends GPS packets along with control packets to the drone. In turn, the drone (204) also has a GPS receiver (328) and a transmitter (322) that transmits both the controller and drone GPS coordinates to the remote base."
DRONE WITH REMOTE ID,https://lens.org/130-691-144-100-473,2022,"A global positioning satellite (GPS) receiver (300) and a transmitter (e.g., 314, 321A, 321B) are at a base (202) remote from a drone (204), and the transmitter sends GPS packets along with control packets to the drone. In turn, the drone (204) also has a GPS receiver (328) and a transmitter (322) that transmits both the controller and drone GPS coordinates to the remote base."
"FLIGHT CONTROL METHOD, DEVICE, AIRCRAFT, SYSTEM, AND STORAGE MEDIUM",https://lens.org/168-990-166-482-934,2020,"A method is provided for controlling flight of an aircraft carrying an imaging device. The method includes obtaining an environment image captured by the imaging device. The method also includes determining a characteristic part of a target user based on the environment image, determining a target image area based on the characteristic part, and recognizing a control object of the target user in the target image area. The method further includes generating a control command based on the control object to control the flight of the aircraft."
SECURE CONTROL AND OPERATION OF DRONES,https://lens.org/145-363-534-556-128,2019,"Techniques are described for the exchange of control signals between a controlled unmanned aircraft (i.e. drone) and a ground control station and for the transmission of communication signals, such as video, from the drone to the ground control station so that the signals are more difficult to intercept or jam. The video signal transmitted from the drone can be an analog RF signal employing one or more of video ""scrambling"", RF signal inversion, hopping, usage of a wide frequency range and other techniques. To secure the control signals between the drone and the ground control station, techniques can include hopping, encryption and use of a wide frequency range."
Systems and methods for remote building security and automation,https://lens.org/131-445-402-150-282,2014,"A system and method for remotely monitoring and controlling building security are provided. A controller is communicatively coupled to security devices of a building and can communicate an activity event detected by one of the security devices to a remote user device. The controller can then establish a communication session between the remote device and a security device via the controller, thereby allowing the user to communicate with any visitors. Video from a security device can be transmitted by the controller to the user device or an alternative user-device. Access instructions can be provided by the user, in response to which the controller can deactivate various building security measures. Security measures can be reactivated by the controller automatically or in response to a user command. Additionally, the controller can monitor visitor compliance with the deactivated security measures and activate alarms or notify security agencies if necessary."
Systems and Methods for Remote Building Security and Automation,https://lens.org/015-764-938-759-849,2013,"A system and method for remotely monitoring and controlling building security are provided. A controller is communicatively coupled to security devices of a building and can communicate an activity event detected by one of the security devices to a remote user device. The controller can then establish a communication session between the remote device and a security device via the controller, thereby allowing the user to communicate with any visitors. Video from a security device can be transmitted by the controller to the user device or an alternative user-device. Access instructions can be provided by the user, in response to which the controller can deactivate various building security measures. Security measures can be reactivated by the controller automatically or in response to a user command. Additionally, the controller can monitor visitor compliance with the deactivated security measures and activate alarms or notify security agencies if necessary."
Robot capable of detecting an edge,https://lens.org/074-261-806-038-287,2006,A robot with an edge detector and two operating modes. The first operating mode is a remote control mode. The second operating mode is a processor controlled mode.
"Smart device control method and apparatus, and storage medium",https://lens.org/070-505-378-714-607,2022,"A smart device control method and apparatus, and a storage medium, relating to the technical field of smart devices. Said method comprises: when a smart device is in a dormant state, acquiring an image of an environment surrounding the smart device; if a character feature is detected in the acquired image and the distance between a target having the character feature and the smart device is within a first specified distance, triggering the smart device to perform voice broadcasting; and after voice broadcasting, if it is detected that the distance between the target and the smart device is within a second specified distance, waking up the smart device, the second specified distance being less than the first specified distance"
"SMART DEVICE CONTROL METHOD AND APPARATUS, AND STORAGE MEDIUM",https://lens.org/043-971-763-863-624,2021,"A smart device control method and apparatus, and a storage medium, relating to the technical field of smart devices. Said method comprises: when a smart device is in a dormant state, acquiring an image of an environment surrounding the smart device; if a character feature is detected in the acquired image and the distance between a target having the character feature and the smart device is within a first specified distance, triggering the smart device to perform voice broadcasting; and after voice broadcasting, if it is detected that the distance between the target and the smart device is within a second specified distance, waking up the smart device, the second specified distance being less than the first specified distance"
SECURITY SYSTEM,https://lens.org/102-514-875-367-654,2017,"A security system is provided. An unmanned flying vehicle is remotely controlled to collect an environment information of a target environment, and whether a prompt signal is outputted is determined according to an environment variation obtained by comparing the environment information with a reference environmental information."
Drone launch systems and methods,https://lens.org/190-914-603-390-062,2018,"A drone launch system includes a canister defining an internal cavity, and a drone positioned within the internal cavity in a stowed state. The drone is configured to be ejected from the canister and transition from the stowed state into a deployed state outside of the canister. A method for launching a drone, the method includes positioning the drone in a stowed state in an internal cavity of a canister, ejecting the drone from the canister, and transitioning the drone into a deployed state after the ejecting operation."
DRONE LAUNCH SYSTEMS AND METHODS,https://lens.org/093-434-431-857-041,2017,"A drone launch system includes a canister defining an internal cavity, and a drone positioned within the internal cavity in a stowed state. The drone is configured to be ejected from the canister and transition from the stowed state into a deployed state outside of the canister. A method for launching a drone, the method includes positioning the drone in a stowed state in an internal cavity of a canister, ejecting the drone from the canister, and transitioning the drone into a deployed state after the ejecting operation."
Intelligent lighting device and system,https://lens.org/186-898-627-137-422,2020,"A lighting device includes a microphone, a camera, and a controller. The controller is configured to control a light source of the lighting device and determine whether an utterance captured by the microphone or a gesture captured by the camera corresponds to a wake-word. The controller is further configured to generate a command based on at least an image of an item captured by the camera if the controller determines that the utterance or the gesture corresponds to the wake-word. The controller is also configured to send the command to a cloud server and to provide a response to the command, where the response is received from the cloud server."
Garage security and convenience features,https://lens.org/002-175-640-534-738,2023,"A garage door is controlled to open using an audio/video (A/V) recording and communication device. The device detects a vehicle within an area about the garage door and receives, using a camera, image data representative of an object associated with the vehicle. The device also compares the image data representative of the object associated with the vehicle with previously stored image data and identifies the object based on the comparing of the image data representative of the object with the previously stored image data. The device also authenticates an electronic device within the vehicle that is associated with the object by wirelessly communicating with the electronic device and determines, based at least in part on the authenticating of the electronic device within the vehicle, that the vehicle is an authorized vehicle. The device also transmits an actuation command to the garage door to cause the garage door to open."
Garage security and convenience features,https://lens.org/120-248-449-980-142,2020,"A garage door is controlled to open using an audio/video (A/V) recording and communication device. The device detects a vehicle within an area about the garage door and receives, using a camera, image data representative of an object associated with the vehicle. The device also compares the image data representative of the object associated with the vehicle with previously stored image data and identifies the object based on the comparing of the image data representative of the object with the previously stored image data. The device also authenticates an electronic device within the vehicle that is associated with the object by wirelessly communicating with the electronic device and determines, based at least in part on the authenticating of the electronic device within the vehicle, that the vehicle is an authorized vehicle. The device also transmits an actuation command to the garage door to cause the garage door to open."
GARAGE SECURITY AND CONVENIENCE FEATURES,https://lens.org/189-235-896-944-339,2021,"A garage door is controlled to open using an audio/video (A/V) recording and communication device. The device detects a vehicle within an area about the garage door and receives, using a camera, image data representative of an object associated with the vehicle. The device also compares the image data representative of the object associated with the vehicle with previously stored image data and identifies the object based on the comparing of the image data representative of the object with the previously stored image data. The device also authenticates an electronic device within the vehicle that is associated with the object by wirelessly communicating with the electronic device and determines, based at least in part on the authenticating of the electronic device within the vehicle, that the vehicle is an authorized vehicle. The device also transmits an actuation command to the garage door to cause the garage door to open."
"CONTROL DEVICE, METHOD, AND NON-TRANSITORY COMPUTER READABLE MEDIUM FOR CONTROLLING AN UNMANNED AERIAL VEHICLE",https://lens.org/042-962-887-895-299,2021,"A control device, non-transitory computer readable medium, and method for controlling an unmanned aerial vehicle (UAV), which acquires an allowable noise level identified on the basis of at least one of a time when the UAV is flying, an altitude at which the UAV is flying, an area where the UAV is flying, and weather in an airspace in which the UAV is flying; and controls flight of the UAV on the basis of the allowable noise level."
METHODS AND SYSTEMS FOR ASSISTING OPERATION OF A ROAD VEHICLE WITH AN AERIAL DRONE,https://lens.org/095-209-684-346-970,2019,"Methods and systems for assisting operation of a road vehicle with an aerial drone are provided. In an exemplary embodiment, a method for assisting operation of a road vehicle with an aerial drone includes flying the aerial drone on a route ahead of the road vehicle and sensing an object at a location on the route ahead of the road vehicle with the aerial drone. Further, the method includes communicating data associated with the object and/or the location to the road vehicle. Also, the method includes utilizing the data to operate the road vehicle."
Method and system for warehouse inventory management using drones,https://lens.org/091-280-521-635-993,2021,"A system that employs aerial drones for inventory management is disclosed. The system includes at least one aerial drone with an optical sensor, an indoor positioning system, and a controller on the aerial drone. The controller is communicatively coupled to the optical sensor and the indoor positioning system. The controller is configured to localize and navigate the aerial drone within a facility based on one or more signals from the indoor positioning system. The controller is further configured to detect identifiers attached to respective inventory items via the optical sensor and to store information associated with the detected identifiers in an onboard memory. The controller may be further configured to transmit the information associated with the detected identifiers to a warehouse management system."
METHOD AND SYSTEM FOR WAREHOUSE INVENTORY MANAGEMENT USING DRONES,https://lens.org/136-990-299-162-079,2022,"A system that employs aerial drones for inventory management is disclosed. The system includes at least one aerial drone with an optical sensor, an indoor positioning system, and a controller on the aerial drone. The controller is communicatively coupled to the optical sensor and the indoor positioning system. The controller is configured to localize and navigate the aerial drone within a facility based on one or more signals from the indoor positioning system. The controller is further configured to detect identifiers attached to respective inventory items via the optical sensor and to store information associated with the detected identifiers in an onboard memory. The controller may be further configured to transmit the information associated with the detected identifiers to a warehouse management system."
AUGMENTATIVE CONTROL OF DRONES,https://lens.org/044-100-269-598-063,2017,"A method may include monitoring location information associated with a drone. The method may also include comparing the location information with an authorized zone. The method may also include, based on the comparison, determining a violation by the drone of a rule associated with the authorized zone. The method may include, in response to the violation, augmenting control of the drone to alter operation of the drone. The location information may include at least one of a current or predicted future location of the drone."
Augmentative control of drones,https://lens.org/086-061-102-714-549,2020,"A method may include monitoring location information associated with a drone. The method may also include comparing the location information with an authorized zone. The method may also include, based on the comparison, determining a violation by the drone of a rule associated with the authorized zone. The method may include, in response to the violation, augmenting control of the drone to alter operation of the drone. The location information may include at least one of a current or predicted future location of the drone."
Augmentative control of drones,https://lens.org/053-188-338-113-222,2018,"A method may include monitoring location information associated with a drone. The method may also include comparing the location information with an authorized zone. The method may also include, based on the comparison, determining a violation by the drone of a rule associated with the authorized zone. The method may include, in response to the violation, augmenting control of the drone to alter operation of the drone. The location information may include at least one of a current or predicted future location of the drone."
AUGMENTATIVE CONTROL OF DRONES,https://lens.org/188-072-696-591-751,2018,"A method may include monitoring location information associated with a drone. The method may also include comparing the location information with an authorized zone. The method may also include, based on the comparison, determining a violation by the drone of a rule associated with the authorized zone. The method may include, in response to the violation, augmenting control of the drone to alter operation of the drone. The location information may include at least one of a current or predicted future location of the drone."
Aerial photography collection unmanned aerial vehicle for law enforcement of police fire protection and control method thereof,https://lens.org/121-480-135-120-396,2016,"The invention provides an aerial photography collection unmanned aerial vehicle for law enforcement of police fire protection and a control method thereof. The unmanned aerial vehicle comprises four groups of propeller actuating arm components, a square frame component, a camera component, a battery box and a support plate component. The four groups of propeller actuating arm components are fixed to the four ends of the square frame component. The battery box is fixed to the square frame component which is fixed to one side of the support plate component. The camera component is fixed to the other side of the support plate component. A battery in the battery box is electrically connected with the camera component. Through wireless communication connection, a control terminal controls the propeller actuating arm components to provide ascending power and drive the square frame component, the camera component, the battery box and the support plate component to leave the ground and ascend to appointed places for shooting recording of the camera. The unmanned aerial vehicle has the advantages of excellent maneuvering property, low demand for take-off and landing conditions and great cruising ability and is suitable for demanding flight missions in the process of law enforcement of police fire protection."
DRONE ESCORT SYSTEM,https://lens.org/067-453-304-714-110,2019,"The present disclosure describes systems and methods for escorting small unmanned aircraft (herein drones). An escorting drone approaches the escorted drone and transmits to it an escort signal. In an embodiment, the escort signal is a GNSS signal fashioned to be the same as the GNSS signal that would be received by the escorted drone, other than being slightly stronger in signal strength and having slightly altered component delays. In another embodiment, the escort signal is a radio frequency control channel signal. Escorting may be utilized to guide a drone from a preprogrammed point to a docking zone in a droneport; to guide a drone though an urban canyon or inside a building where GNSS signals are not reliably received; to retrieve a drone with which communications has been lost; or to escort a drone to safety out of a no- flight zone such as around an airport."
Systems and Methods for Autonomous Operations of Unmanned Aerial Vehicles,https://lens.org/159-287-045-571-745,2012,"Systems and methods are disclosed for autonomous or remote-controlled operation of unmanned aerial vehicles (UAVs). An integrated mechanical and electrical system is capable of launching, controlling, snagging, recovering, securing, parking, and servicing UAVs without human intervention at the site of the system. The illustrative embodiment comprises a boom and a container that houses the boom and UAV(s). The boom rotates about its longitudinal axis to operationally orient a plurality of faces thereof. Each face is associated with certain system operations, including but not limited to: launching a UAV, snagging a UAV from the air, and securing a UAV to the boom."
OVERHEAD TETHERED DRONE SYSTEM,https://lens.org/037-842-112-426-131,2018,"An overhead tethered drone system can include a least one camera-bearing drone tethered by a retractable electrical power carrying tether line to a retraction assembly attached to venue infrastructure located above a live activity occurring within the venue. Controlling x-y-z orientation of the camera bearing drone can be accomplished via power to drone propellers and/or a tether line retraction motor located in the retraction assembly attached above the drone to venue infrastructure (e.g., ceiling rafters). Control over drone movement can be conducted remotely from a remote controller (e.g., control booth) while capturing high definition images of perspective within the venue by one or more drone cameras. Video images captured by the camera bearing drone can be provided to at least one of a production server or mobile devices via a wired and/or wireless data network where the images can be processed and rendered on display screens viewable by media directors, editors and spectators located either at the venue or remote from the venue (e.g., at home)."
SYSTEMS AND METHODS FOR WALKING PETS,https://lens.org/049-268-184-674-70X,2020,"A method of using an unmanned aerial vehicle (UAV) to guide a target includes receiving a location signal from one or more sensors of the UAV, receiving an input signal from a user device for guiding the target that defines at least one of a travel route, a permissible region, or an impermissible region, comparing the location signal to the input signal to determine whether the target is deviating from the travel route, exiting the permissible region, or entering the impermissible region, and initiating, via the UAV or an attachment mechanism coupled between the UAV and the target, a deterrent mechanism in response to determining that the target is deviating from the travel route, exiting the permissible region, or entering the impermissible region."
Systems and methods for walking pets,https://lens.org/157-349-170-893-16X,2022,"A method of using an unmanned aerial vehicle (UAV) to guide a target includes receiving a location signal from one or more sensors of the UAV, receiving an input signal from a user device for guiding the target that defines at least one of a travel route, a permissible region, or an impermissible region, comparing the location signal to the input signal to determine whether the target is deviating from the travel route, exiting the permissible region, or entering the impermissible region, and initiating, via the UAV or an attachment mechanism coupled between the UAV and the target, a deterrent mechanism in response to determining that the target is deviating from the travel route, exiting the permissible region, or entering the impermissible region."
ARTIFICIAL INTELLIGENCE APPARATUS AND METHOD FOR CONTROLLING AUTHORITY TO USE EXTERNAL DEVICE BASED ON USER IDENTIFICATION USING IMAGE RECOGNITION,https://lens.org/135-652-995-544-259,2023,"An artificial intelligence (AI) home monitoring device including a camera configured to monitor a home environment including a home appliance controlled by the AI home monitoring device; and a processor configured to in response to the monitored home environment including a detection of a first user intending to use the home appliance, check an authority of the first user based on mapping data mapping the home appliance, the first user and a predetermined condition associated with using the home appliance, and compare the predetermined condition with a condition of a current state of the authority of the first user based on the mapping data, in response to the authority of the user matching a preset authority authorizing the first user to use the home appliance, and the predetermined condition associated with using the home appliance matching the condition of the current state of the authority of the user, control the home appliance to allow the first user to use the home appliance, and in response to the authority of the user not matching the preset authority authorizing the first user to use the home appliance, control the home appliance to prevent the first user from using the home appliance."
ARTIFICIAL INTELLIGENCE APPARATUS AND METHOD FOR CONTROLLING AUTHORITY TO USE EXTERNAL DEVICE BASED ON USER IDENTIFICATION USING IMAGE RECOGNITION,https://lens.org/135-652-995-544-259,2023,"An artificial intelligence (AI) home monitoring device including a camera configured to monitor a home environment including a home appliance controlled by the AI home monitoring device; and a processor configured to in response to the monitored home environment including a detection of a first user intending to use the home appliance, check an authority of the first user based on mapping data mapping the home appliance, the first user and a predetermined condition associated with using the home appliance, and compare the predetermined condition with a condition of a current state of the authority of the first user based on the mapping data, in response to the authority of the user matching a preset authority authorizing the first user to use the home appliance, and the predetermined condition associated with using the home appliance matching the condition of the current state of the authority of the user, control the home appliance to allow the first user to use the home appliance, and in response to the authority of the user not matching the preset authority authorizing the first user to use the home appliance, control the home appliance to prevent the first user from using the home appliance."
System and methods for wireless remote control over cameras with audio processing to generate a refined audio signal,https://lens.org/068-418-458-714-650,2017,"Systems and methods for wireless remote control operation of cameras are provided. This system includes a remote controller which includes an interface for receiving commands from a user (such as turning on or off a camera), and a transceiver for transmitting the commands to one or more camera transceivers which are coupled to cameras. The remote controller may also include a display that indicates battery levels, camera status and even video feeds. Camera status and video feeds are transmitted from the camera transceiver which is coupled to the camera via an electrical bus interface. It may include a video converter that accepts raw video data from the camera and converts it into a video feed that is transmitted. Additionally, the camera transceiver may include an advanced audio circuit which subtracts measured pressure data from audio feeds to cancel out wind sounds."
System and Methods for Wireless Remote Control over Cameras,https://lens.org/158-827-893-070-255,2013,"Systems and methods for wireless remote control operation of cameras are provided. This system includes a remote controller which includes an interface for receiving commands from a user (such as turning on or off a camera), and a transceiver for transmitting the commands to one or more camera transceivers which are coupled to cameras. The remote controller may also include a display that indicates battery levels, camera status and even video feeds. Camera status and video feeds are transmitted from the camera transceiver which is coupled to the camera via an electrical bus interface. It may include a video converter that accepts raw video data from the camera and converts it into a video feed that is transmitted. Additionally, the camera transceiver may include an advanced audio circuit which subtracts measured pressure data from audio feeds to cancel out wind sounds."
SYSTEM AND METHODS FOR WIRELESS REMOTE CONTROL OVER CAMERAS,https://lens.org/040-313-876-380-158,2013,"Systems and methods for wireless remote control operation of cameras are provided. This system includes a remote controller which includes an interface for receiving commands from a user (such as turning on or off a camera), and a transceiver for transmitting the commands to one or more camera transceivers which are coupled to cameras. The remote controller may also include a display that indicates battery levels, camera status and even video feeds. Camera status and video feeds are transmitted from the camera transceiver which is coupled to the camera via an electrical bus interface. It may include a video converter that accepts raw video data from the camera and converts it into a video feed that is transmitted. Additionally, the camera transceiver may include an advanced audio circuit which subtracts measured pressure data from audio feeds to cancel out wind sounds."
ROBOT SYSTEM AND METHOD OF MANUFACTURING OBJECT BY USING THE ROBOT SYSTEM,https://lens.org/182-978-961-155-874,2020,"The robot system includes a robot having a robot body and a robot controller configured to control operation of the robot body, and an unmanned aerial vehicle capable of autonomous flight. The unmanned aerial vehicle acquires at least one of image pick-up data of a work of the robot body and positional information of a work object of the robot body, and transmits at least one of the image pick-up data and the positional information to the robot controller. The robot controller receives at least one of the image pick-up data and the positional information of the work object, and controls the operation of the robot body by using at least one of the image pick-up data and the positional information of the work object."
XR DEVICE AND METHOD FOR CONTROLLING THE SAME,https://lens.org/167-006-346-585-899,2021,"The present disclosure relates to an XR device and a method for controlling the same, and more particularly, is applicable to a 5G communication technology field, a robot technology field, an autonomous technology field and an artificial intelligence (AI) technology field. The method for controlling an XR device of a vehicle includes acquiring a camera view by capturing an image in front of the vehicle; acquiring position information of the vehicle by detecting a position of the vehicle, acquiring movement information of the vehicle by detecting movement of the vehicle, and providing navigation of an augmented reality (AR) mode displaying at least one virtual object for guiding a path by overlapping the at least one virtual object on the camera view based on at least the position information of the vehicle or the movement information of the vehicle."
XR DEVICE AND METHOD FOR CONTROLLING THE SAME,https://lens.org/176-352-671-300-293,2022,"The present disclosure relates to an XR device and a method for controlling the same, and more particularly, is applicable to a 5G communication technology field, a robot technology field, an autonomous technology field and an artificial intelligence (AI) technology field. The method for controlling an XR device of a vehicle includes acquiring a camera view by capturing an image in front of the vehicle; acquiring position information of the vehicle by detecting a position of the vehicle, acquiring movement information of the vehicle by detecting movement of the vehicle, and providing navigation of an augmented reality (AR) mode displaying at least one virtual object for guiding a path by overlapping the at least one virtual object on the camera view based on at least the position information of the vehicle or the movement information of the vehicle."
XR device and method for controlling the same,https://lens.org/178-217-829-217-504,2022,"The present disclosure relates to an XR device and a method for controlling the same, and more particularly, is applicable to a 5G communication technology field, a robot technology field, an autonomous technology field and an artificial intelligence (AI) technology field. The method for controlling an XR device of a vehicle includes acquiring a camera view by capturing an image in front of the vehicle; acquiring position information of the vehicle by detecting a position of the vehicle, acquiring movement information of the vehicle by detecting movement of the vehicle, and providing navigation of an augmented reality (AR) mode displaying at least one virtual object for guiding a path by overlapping the at least one virtual object on the camera view based on at least the position information of the vehicle or the movement information of the vehicle."
XR device and method for controlling the same,https://lens.org/178-217-829-217-504,2022,"The present disclosure relates to an XR device and a method for controlling the same, and more particularly, is applicable to a 5G communication technology field, a robot technology field, an autonomous technology field and an artificial intelligence (AI) technology field. The method for controlling an XR device of a vehicle includes acquiring a camera view by capturing an image in front of the vehicle; acquiring position information of the vehicle by detecting a position of the vehicle, acquiring movement information of the vehicle by detecting movement of the vehicle, and providing navigation of an augmented reality (AR) mode displaying at least one virtual object for guiding a path by overlapping the at least one virtual object on the camera view based on at least the position information of the vehicle or the movement information of the vehicle."
XR DEVICE AND METHOD FOR CONTROLLING THE SAME,https://lens.org/176-352-671-300-293,2022,"The present disclosure relates to an XR device and a method for controlling the same, and more particularly, is applicable to a 5G communication technology field, a robot technology field, an autonomous technology field and an artificial intelligence (AI) technology field. The method for controlling an XR device of a vehicle includes acquiring a camera view by capturing an image in front of the vehicle; acquiring position information of the vehicle by detecting a position of the vehicle, acquiring movement information of the vehicle by detecting movement of the vehicle, and providing navigation of an augmented reality (AR) mode displaying at least one virtual object for guiding a path by overlapping the at least one virtual object on the camera view based on at least the position information of the vehicle or the movement information of the vehicle."
XR DEVICE AND METHOD FOR CONTROLLING THE SAME,https://lens.org/176-352-671-300-293,2022,"The present disclosure relates to an XR device and a method for controlling the same, and more particularly, is applicable to a 5G communication technology field, a robot technology field, an autonomous technology field and an artificial intelligence (AI) technology field. The method for controlling an XR device of a vehicle includes acquiring a camera view by capturing an image in front of the vehicle; acquiring position information of the vehicle by detecting a position of the vehicle, acquiring movement information of the vehicle by detecting movement of the vehicle, and providing navigation of an augmented reality (AR) mode displaying at least one virtual object for guiding a path by overlapping the at least one virtual object on the camera view based on at least the position information of the vehicle or the movement information of the vehicle."
"METHOD, APPARATUS, AND SYSTEM FOR MANAGING IMAGE CAPTURED BY DRONE",https://lens.org/071-624-213-019-831,2022,"Provided is a system for managing an image captured by a drone, the system including a drone configured to capture an image of a subject, generate image information about a captured image, and transmit an image and image information by wired or wireless communication, an image management apparatus configured to receive the image and the image information from the drone, store the received image and image information, analyze whether the image includes personal information, and transmit the image information by wired or wireless communication, and a personal information protection target configured to receive the image information from the image management apparatus, and transmit a read signal of reading the image information to the image management apparatus by wired or wireless communication."
"METHOD, APPARATUS, AND SYSTEM FOR MANAGING IMAGE CAPTURED BY DRONE",https://lens.org/071-624-213-019-831,2022,"Provided is a system for managing an image captured by a drone, the system including a drone configured to capture an image of a subject, generate image information about a captured image, and transmit an image and image information by wired or wireless communication, an image management apparatus configured to receive the image and the image information from the drone, store the received image and image information, analyze whether the image includes personal information, and transmit the image information by wired or wireless communication, and a personal information protection target configured to receive the image information from the image management apparatus, and transmit a read signal of reading the image information to the image management apparatus by wired or wireless communication."
DRONE LANDING SYSTEM,https://lens.org/178-492-755-603-360,2022,Disclosed herein is a drone landing system. The drone landing system can provide precise landing guidance for drones through detection of X/Y distances and a Z distance of a drone from a center point of a station using an X/Y-axis camera and a Z-axis camera disposed on the station and through automatic or manual control over the drone using a controller.
DRONE LANDING SYSTEM,https://lens.org/178-492-755-603-360,2022,Disclosed herein is a drone landing system. The drone landing system can provide precise landing guidance for drones through detection of X/Y distances and a Z distance of a drone from a center point of a station using an X/Y-axis camera and a Z-axis camera disposed on the station and through automatic or manual control over the drone using a controller.
Surveillance system control unit,https://lens.org/162-337-727-851-876,2008,A control unit for use in a surveillance system is provided. The control unit is configured to access or retrieve surveillance data. The control is further configured to issue commands for control of a sensor device.
Systems and Methods for Remote Building Security and Automation,https://lens.org/124-827-099-799-547,2011,"A system and method for remotely monitoring and controlling building security are provided. A controller is communicatively coupled to various security devices of a building and can communicate an activity event detected by one of the security devices to a remote user device. The controller can then establish a communication session between the remote device and a security communication device via the controller, thereby allowing the user to communicate with any visitors. Video from a security device can be transmitted by the controller to the user device or an alternative user-device. Access instructions can be provided by the user to the controller, in response to which the controller can deactivate various building security measures. Security measures can be reactivated by the controller automatically or in response to a user command. Additionally, the controller can monitor visitor compliance with the deactivated security measures and activate alarms or notify security agencies if necessary."
Systems and methods for remote building security and automation,https://lens.org/078-089-983-153-597,2012,"A system and method for remotely monitoring and controlling building security are provided. A controller is communicatively coupled to various security devices of a building and can communicate an activity event detected by one of the security devices to a remote user device. The controller can then establish a communication session between the remote device and a security communication device via the controller, thereby allowing the user to communicate with any visitors. Video from a security device can be transmitted by the controller to the user device or an alternative user-device. Access instructions can be provided by the user to the controller, in response to which the controller can deactivate various building security measures. Security measures can be reactivated by the controller automatically or in response to a user command. Additionally, the controller can monitor visitor compliance with the deactivated security measures and activate alarms or notify security agencies if necessary."
"Pre-determining UAV attitude changes based on commanded component movements, and associated systems and methods",https://lens.org/038-498-036-760-328,2020,"An unmanned aerial vehicle (UAV) apparatus includes an airframe, a propulsion system carried by the airframe and including at least one propulsion device, a movable component carried by the airframe, and a control system. The control system is programmed with instructions that, when executed, cause the control system to receive a first input corresponding to a characteristic of the movable component, receive a second input corresponding to a command to move the movable component, and direct a change in a setting of the at least one propulsion device in response to the first input and the second input."
"PRE-DETERMINING UAV ATTITUDE CHANGES BASED ON COMMANDED COMPONENT MOVEMENTS, AND ASSOCIATED SYSTEMS AND METHODS",https://lens.org/085-720-433-317-329,2019,"An unmanned aerial vehicle (UAV) apparatus includes an airframe, a propulsion system carried by the airframe and including at least one propulsion device, a movable component carried by the airframe, and a control system. The control system is programmed with instructions that, when executed, cause the control system to receive a first input corresponding to a characteristic of the movable component, receive a second input corresponding to a command to move the movable component, and direct a change in a setting of the at least one propulsion device in response to the first input and the second input."
"DRONE CONTROL METHOD AND DEVICE, DRONE AND CORE NETWORK DEVICE",https://lens.org/032-420-372-600-296,2020,"An unmanned aerial vehicle (UAV) control method is applied to a UAV and includes: sending attachment request information to a core network; receiving information, acquired by the core network from a preset server, of a UAV no-fly zone; and determining whether the UAV is allowed to fly according to a relationship between a position of the UAV and the UAV no-fly zone. As such, a UAV may access a core network to acquire the information of a UAV no-fly zone from a preset server through the core network and further determine whether it is allowed to fly or not according to the relationship between its position and the UAV no-fly zone."
"STORAGE MEDIUM, UNMANNED AERIAL VEHICLE AND METHOD AND SYSTEM FOR VIBRATION DETECTION AND TRACKING CONTROL",https://lens.org/091-511-777-576-38X,2019,"A method for tracking control of an unmanned aerial vehicle (UAV) includes obtaining flight data of the UAV, determining, within a preset period of time and according to the flight data, a number of switching times of the UAV switching between different flight directions, determining whether the UAV is vibrating according to the number of switching times, and determining whether to continue tracking a target according to whether the UAV is vibrating."
DRONE CONTROL REGISTRATION,https://lens.org/134-073-723-649-10X,2017,"A drone includes technology for tracking controllers. A controller registration module (CRM) in the drone enables the drone to receive a first controller identifier from a first remote device. In response to receiving the first controller identifier, the CRM registers the first remote device as the current controller for the drone. Registering comprises adding the first controller identifier to a drone control registration record (DCRR) in the drone. Also, the DCRR is added to a block chain in remote storage. The CRM then receives a second controller identifier from a second remote device. In response, the CRM registers the second remote device as the current controller. Registering comprises creating an updated DCRR that identifies the second controller as the current controller. The updated DCRR is then added to the block chain. Other embodiments are described and claimed."
Drone control registration,https://lens.org/125-775-573-564-994,2021,"A drone includes technology for tracking controllers. A controller registration module (CRM) in the drone enables the drone to receive a first controller identifier from a first remote device. In response to receiving the first controller identifier, the CRM registers the first remote device as the current controller for the drone. Registering comprises adding the first controller identifier to a drone control registration record (DCRR) in the drone. Also, the DCRR is added to a block chain in remote storage. The CRM then receives a second controller identifier from a second remote device. In response, the CRM registers the second remote device as the current controller. Registering comprises creating an updated DCRR that identifies the second controller as the current controller. The updated DCRR is then added to the block chain. Other embodiments are described and claimed."
DRONE CONTROL REGISTRATION,https://lens.org/170-074-512-367-444,2022,"A drone includes technology for tracking controllers. A controller registration module (CRM) in the drone enables the drone to receive a first controller identifier from a first remote device. In response to receiving the first controller identifier, the CRM registers the first remote device as the current controller for the drone. Registering comprises adding the first controller identifier to a drone control registration record (DCRR) in the drone. Also, the DCRR is added to a block chain in remote storage. The CRM then receives a second controller identifier from a second remote device. In response, the CRM registers the second remote device as the current controller. Registering comprises creating an updated DCRR that identifies the second controller as the current controller. The updated DCRR is then added to the block chain. Other embodiments are described and claimed."
COMPUTING DEVICE AND METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE TO CAPTURE IMAGES,https://lens.org/021-043-920-036-498,2013,"In a method for controlling an unmanned aerial vehicle (UAV) equipped with a camera to capture images of a target, the computing device sets coordinates of a target, initial coordinates of the camera, and an initial viewing direction of the camera. Real-time coordinates and a real-time viewing direction of the camera are obtained when the UAV flies around the target. Accordingly, adjustment parameters of the camera are calculated and transferred to a driver system connected to the camera, such that the driver system adjusts the camera to face the target according to the adjusting parameters."
Computing device and method for controlling unmanned aerial vehicle to capture images,https://lens.org/047-608-013-206-78X,2015,"In a method for controlling an unmanned aerial vehicle (UAV) equipped with a camera to capture images of a target, the computing device sets coordinates of a target, initial coordinates of the camera, and an initial viewing direction of the camera. Real-time coordinates and a real-time viewing direction of the camera are obtained when the UAV flies around the target. Accordingly, adjustment parameters of the camera are calculated and transferred to a driver system connected to the camera, such that the driver system adjusts the camera to face the target according to the adjusting parameters."
Method and device for controlling flight of unmanned aerial vehicle and remote controller,https://lens.org/038-329-106-324-031,2021,"A flight control method and device for an unmanned aerial vehicle and a remote controller are provided. The method includes that: multiple pieces of locating data obtained by a locating operation are acquired in a remote controller; multiple target positions are determined according to the multiple pieces of locating data; a flight route is calculated according to the multiple target positions; and the flight route is sent to the unmanned aerial vehicle for flight according to the flight route. According to the method, carrying of multiple sets of equipment is avoided, and hardware cost is reduced."
METHOD AND DEVICE FOR CONTROLLING FLIGHT OF UNMANNED AERIAL VEHICLE AND REMOTE CONTROLLER,https://lens.org/007-749-578-441-187,2019,"A flight control method and device for an unmanned aerial vehicle and a remote controller are provided. The method includes that: multiple pieces of locating data obtained by a locating operation are acquired in a remote controller; multiple target positions are determined according to the multiple pieces of locating data; a flight route is calculated according to the multiple target positions; and the flight route is sent to the unmanned aerial vehicle for flight according to the flight route. According to the method, carrying of multiple sets of equipment is avoided, and hardware cost is reduced."
"Flight control method and apparatus for unmanned aerial vehicle, and remote controller",https://lens.org/011-105-182-191-944,2018,"A flight control method and apparatus for an unmanned aerial vehicle, and a remote controller. The method comprises: acquiring, from a remote controller, a plurality of pieces of positioning data obtained through performing a positioning operation (201); according to the plurality of pieces of positioning data, determining a plurality of target locations (202); according to the plurality of target locations, calculating a flight route (203); and sending the flight route to an unmanned aerial vehicle so same flies according to the flight route (204). In this method, there is no need to carry a plurality of sets of devices, thereby reducing hardware costs. Since a remote control device is integrated with a surveying and mapping function, there is no need to carry various devices, and there is also no need to exchange data between various devices, thereby improving the simplicity and convenience of operations, and improving the operation efficiency of an unmanned aerial vehicle. In addition, the probability of a data sending error during data exchange is reduced, and the reliability of an unmanned aerial vehicle operation is improved."
Tethered unmanned aerial vehicle,https://lens.org/110-618-384-883-490,2020,"A tethered UAV (102) is disclosed. The UAV (102) may carry a payload (104). The payload may include camera, radio mast, or sensors. Power supply to the UAV (102) via a tether cable (108) from a ground station (106) may be varied using a reconfigurable power converter. Further, the UAV (102) may enter an autopilot mode based on a disruption of power supply from a power source at the ground station (106), low energy level of the power source, and a temperature of the power converter. In the autopilot mode, power may be supplied to the UAV (102) from an on-board battery and wireless communication may be initiated between the UAV (102) and the ground station (106) via a network (110)."
TETHERED UNMANNED AERIAL VEHICLE,https://lens.org/174-209-733-454-665,2018,"A tethered UAV (102) is disclosed. The UAV (102) may carry a payload (104). The payload may include camera, radio mast, or sensors. Power supply to the UAV (102) via a tether cable (108) from a ground station (106) may be varied using a reconfigurable power converter. Further, the UAV (102) may enter an autopilot mode based on a disruption of power supply from a power source at the ground station (106), low energy level of the power source, and a temperature of the power converter. In the autopilot mode, power may be supplied to the UAV (102) from an on-board battery and wireless communication may be initiated between the UAV (102) and the ground station (106) via a network (110)."
TETHERED UNMANNED AERIAL VEHICLE,https://lens.org/023-139-080-902-03X,2018,"A tethered UAV (102) is disclosed. The UAV (102) may carry a payload (104). The payload may include camera, radio mast, or sensors. Power supply to the UAV (102) via a tether cable (108) from a ground station (106) may be varied using a reconfigurable power converter. Further, the UAV (102) may enter an autopilot mode based on a disruption of power supply from a power source at the ground station (106), low energy level of the power source, and a temperature of the power converter. In the autopilot mode, power may be supplied to the UAV (102) from an on-board battery and wireless communication may be initiated between the UAV (102) and the ground station (106) via a network (110).
"
DRONE WITH EXTENDABLE AND ROTATABLE WINGS AND MULTIPLE ACCESSORY SECURING PANEL,https://lens.org/168-028-547-529-141,2023,A drone with extendable and rotatable wings and a multiple accessory securing panel is provided. The extendable wings help increase the lift of the drone and reduce the air drag on the drone. The multiple accessory securing panel allows various tools and objects to be temporarily and selectively secured to the drone. The multiple accessories may be secured to the drone by a ground based rotating delivery unit. The drone may have a removable front nose and legs which receive power from a power unit.
DRONE WITH EXTENDABLE AND ROTATABLE WINGS AND MULTIPLE ACCESSORY SECURING PANEL,https://lens.org/102-393-088-984-794,2023,A drone with extendable and rotatable wings and a multiple accessory securing panel is provided. The extendable wings help increase the lift of the drone and reduce the air drag on the drone. The multiple accessory securing panel allows various tools and objects to be temporarily and selectively secured to the drone. The multiple accessories may be secured to the drone by a ground based rotating delivery unit. The drone may have a removable front nose and legs which receive power from a power unit.
Privacy control in a connected environment,https://lens.org/123-875-387-596-875,2019,Privacy control in a connected environment is described. An assistant device can detect speech spoken by a user. The speech can include a hardware activation phrase that indicates whether the user intends for at least a portion of the speech to be provided to local resources or cloud resources. The speech can then be provided to the appropriate resource based on the hardware activation phrase.
PRIVACY CONTROL IN A CONNECTED ENVIRONMENT,https://lens.org/084-970-443-162-928,2018,Privacy control in a connected environment is described. An assistant device can detect speech spoken by a user. The speech can include a hardware activation phrase that indicates whether the user intends for at least a portion of the speech to be provided to local resources or cloud resources. The speech can then be provided to the appropriate resource based on the hardware activation phrase.
In flight transfer of packages between aerial drones,https://lens.org/076-393-051-927-541,2020,"Aspects include a system for transferring a payload between drones. The system includes a first aerial drone having a first transfer member and a first controller. The first controller including a processor configured to change a first altitude and first orientation of the first aerial drone. A second aerial drone is provided having a second transfer member and a second controller, the second transfer member having a cone member on one end, the second transfer member being configured to receive the payload. The second controller including a processor configured to change a second altitude and a second orientation of the second aerial drone. The controllers cooperate to dispose the first transfer member within the cone member and transfer the payload from the first aerial drone to the second aerial drone."
IN FLIGHT TRANSFER OF PACKAGES BETWEEN AERIAL DRONES,https://lens.org/033-426-229-927-871,2018,"Aspects include a system for transferring a payload between drones. The system includes a first aerial drone having a first transfer member and a first controller. The first controller including a processor configured to change a first altitude and first orientation of the first aerial drone. A second aerial drone is provided having a second transfer member and a second controller, the second transfer member having a cone member on one end, the second transfer member being configured to receive the payload. The second controller including a processor configured to change a second altitude and a second orientation of the second aerial drone. The controllers cooperate to dispose the first transfer member within the cone member and transfer the payload from the first aerial drone to the second aerial drone."
In flight transfer of packages between aerial drones,https://lens.org/076-393-051-927-541,2020,"Aspects include a system for transferring a payload between drones. The system includes a first aerial drone having a first transfer member and a first controller. The first controller including a processor configured to change a first altitude and first orientation of the first aerial drone. A second aerial drone is provided having a second transfer member and a second controller, the second transfer member having a cone member on one end, the second transfer member being configured to receive the payload. The second controller including a processor configured to change a second altitude and a second orientation of the second aerial drone. The controllers cooperate to dispose the first transfer member within the cone member and transfer the payload from the first aerial drone to the second aerial drone."
ENABLING REMOTE CONTROL OF A VEHICLE,https://lens.org/113-047-891-714-264,2020,"It is provided a method for enabling remote control of a vehicle with autonomous propulsion capability. The method is performed by a vehicle data provider and comprises: detecting a need for manual assistance of the vehicle by an operator being remote from the vehicle; obtaining a stream of vehicle data, the vehicle data relating to a time prior to when remote control starts; modifying the vehicle data, which comprises adjusting a duration of playback of the vehicle data; providing the modified vehicle data for playback to the operator; providing, once the playback of modified vehicle data has ended, vehicle data in real-time to the operator; and enabling remote control of the vehicle by the operator."
Enabling remote control of a vehicle,https://lens.org/033-857-581-834-353,2022,"It is provided a method for enabling remote control of a vehicle with autonomous propulsion capability. The method is performed by a vehicle data provider and comprises: detecting a need for manual assistance of the vehicle by an operator being remote from the vehicle; obtaining a stream of vehicle data, the vehicle data relating to a time prior to when remote control starts; modifying the vehicle data, which comprises adjusting a duration of playback of the vehicle data; providing the modified vehicle data for playback to the operator; providing, once the playback of modified vehicle data has ended, vehicle data in real-time to the operator; and enabling remote control of the vehicle by the operator."
ENABLING REMOTE CONTROL OF A VEHICLE,https://lens.org/095-293-040-557-283,2018,"It is provided a method for enabling remote control of a vehicle with autonomous propulsion capability. The method is performed by a vehicle data provider and comprises: detecting a need for manual assistance of the vehicle by an operator being remote from the vehicle; obtaining a stream of vehicle data, the vehicle data relating to a time prior to when remote control starts; modifying the vehicle data, which comprises adjusting a duration of playback of the vehicle data; providing the modified vehicle data for playback to the operator; providing, once the playback of modified vehicle data has ended, vehicle data in real-time to the operator; and enabling remote control of the vehicle by the operator."
Unmanned aerial vehicle autonomous flight system based on image recognition,https://lens.org/074-326-819-378-816,2015,"The invention discloses an unmanned aerial vehicle autonomous flight system based on image recognition. The unmanned aerial vehicle autonomous flight system is applied to an autonomous flight task composed of n unmanned aerial vehicles and a ground command center. The unmanned aerial vehicle autonomous flight system is characterized by comprising a flight communication module, a ground communication module, an input module, an FFMPEG module, a video display module, an image recognition module, an instruction generation module and an output module. The flight communication module and the ground communication module each comprise a UDP5556 port and a TCP5555 port. When the unmanned aerial vehicles fly autonomously, the unmanned aerial vehicle autonomous flight system can make more timely response and adjustment according to the random environmental change to ensure stability and flexibility of autonomous flight of the unmanned aerial vehicles."
A system and apparatus for delivery of items via drone,https://lens.org/052-972-090-520-766,2019,"A delivery drone including a motorised, unmanned aerial vehicle; a wireless communication module to enable sending and receiving of information to and from the delivery drone; at least one location receiver to obtain location data indicative of a location of the drone in real time or near real time; a signal receiver to receive a customer identification transmission; and a delivery unit mounted to the drone for containing one or more items during delivery and to present items stored therein to a customer once the delivery drone has reached a delivery location and the customer identification transmission has been received and verified."
A SYSTEM AND APPARATUS FOR DELIVERY OF ITEMS VIA DRONE,https://lens.org/027-214-523-935-408,2018,"A delivery drone including a motorised, unmanned aerial vehicle; a wireless communication module to enable sending and receiving of information to and from the delivery drone; at least one location receiver to obtain location data indicative of a location of the drone in real time or near real time; a signal receiver to receive a customer identification transmission; and a delivery unit mounted to the drone for containing one or more items during delivery and to present items stored therein to a customer once the delivery drone has reached a delivery location and the customer identification transmission has been received and verified."
IMPROVEMENTS IN AND RELATING TO A GUIDED WEAPON,https://lens.org/018-848-294-815-573,2021,"Disclosed is an unmanned Aerial Vehicle, UAV (1), comprising a plurality of rotors (5), a camera (3) and an explosive payload (4), wherein the UAV comprises a generally elongate body, and the camera and the payload are arranged substantially in-line within the body."
SYSTEMS AND METHODS FOR ADJUSTING A PICK UP SCHEDULE FOR AN UNMANNED AERIAL VEHICLE,https://lens.org/063-520-405-743-916,2017,An unmanned aerial vehicle (UAV) may be used to deliver a package. The UAV may include a communication interface configured to receive a request to transport a package from a customer and a navigation unit configured to direct the UAV to the package. The UAV may also include a sensor configured to determine at least one of a weight and a plurality of dimensions of the package and a schedule unit configured to adjust a pick up schedule for a one or more other packages based on at least one of the weight and the plurality of dimensions of the package.
DRONE INCLUDING A PIEZOELECTRIC STRUCTURE AND/OR A SELF-ENERGIZING CAPABILITY,https://lens.org/072-879-981-569-95X,2021,"A drone equipped with piezoelectric structures and/or a self-energizing capability has increased functionality. The piezoelectric structures can act as a variety of sensors and/or can implement or perform a variety of tasks, especially those associated with assisting a vehicle. The self-energizing capability can extend operations and/or permit a drone low on power to sufficiently recharge to fly home."
DRONE WITH WIND GUIDE PART,https://lens.org/130-744-928-686-915,2017,"Provided is a drone with a wind guide part, which is configured such that it can lift off or aviate using the flow of wind. The drone has a lift force by wind discharged towards the ground through a connecting duct and a wind guide part, so that the drone may lift off or aviate using the flow of the wind. Further, the drone may aviate without a propeller, thus preventing an accident due to the contact of the propeller, saving maintenance cost, and reducing weight and noise."
SURVEILLANCE DRONE INCLUDING GAS-FILLED CONTAINER AND PROPELLERS FOR AERIAL MOBILITY,https://lens.org/167-957-253-772-656,2018,"A surveillance drone is disclosed. The surveillance drone includes a gas-filled container and propellers for aerial mobility. The surveillance drone also includes an electronic surveillance sensing device positioned below the gas-filled container. The gas-filled container may be filled with a lighter than air gas such as, for example, helium."
Surveillance drone including gas-filled container and propellers for aerial mobility,https://lens.org/037-789-623-802-768,2019,"A surveillance drone is disclosed. The surveillance drone includes a gas-filled container and propellers for aerial mobility. The surveillance drone also includes an electronic surveillance sensing device positioned below the gas-filled container. The gas-filled container may be filled with a lighter than air gas such as, for example, helium."
HYBRID UNMANNED AERIAL VEHICLE SYSTEMS WITH AUTOMATED TETHER ASSEMBLY,https://lens.org/129-787-493-987-827,2022,"An unmanned aerial vehicle system includes an unmanned aerial vehicle, a user input device, and ground station. The user input device is configured to generate a signal and control the unmanned aerial vehicle based on the generated signal. The ground station is coupled to the unmanned aerial vehicle via a tether assembly. The ground station includes a motorized spool and a controller. The motorized spool is coupled to the tether assembly and configured to electromechanically control spooling and unspooling of a tether of the tether assembly. The controller is configured to control operation of the motorized spool based on an anticipated movement of the unmanned aerial vehicle."
MOTION ACTIVATED FLYING CAMERA SYSTEMS,https://lens.org/139-438-391-845-681,2018,"A remotely controlled flying camera system can to disable recording and/or streaming by a camera system on a flying device based on one or more programmed criteria. The programmed criteria can be based on predictions of when the flying camera system is likely being used as a surveillance camera and/or in situations that can result in an invasion of privacy. The predictions can be based on movements of the flying device and/or the surrounding. The system can reduce privacy invasion concerns with the use of the flying camera system, without completely removing or disabling the associated camera system."
Autonomous drone based package reception and surveillance system,https://lens.org/123-297-033-084-07X,2019,"A system and method for autonomous drone-based package reception and surveillance of the present invention. In accordance with the inventive method, an at least partially enclosed chute is provided with dimensions sufficient to receive packages. A platform is mounted within the chute to receiving the packages. A mechanism is provided to move the platform from a first position within the chute to receive the packages to a second position within the chute to deliver the packages. In the best mode, the platform is a second drone. Multiple drones, equipped with wireless transceivers, cameras, lasers, lights, detectors and even weapons are networked to provide perimeter security. The chute includes a door secured with a wireless latch activated by a system controller. One or more identification symbols, such as QR codes, bar codes, symbols etc. are provided on the door to be read by the airborne delivery vehicle. Nodes are included for charging the airborne delivery vehicle and the site-based drones as well. The deployment of the nodes within the chute is controlled by the site-based drones. An optional scale is provided in the platform for weighing package upon delivery. The system is adapted for operation via a smartphone."
Robot system,https://lens.org/188-169-892-339-204,2004,"When commands are inputted by voice through any one of voice input devices, digitalized voice signals are transmitted to a robot controller. The robot controller transmits the signals to a voice recognition device using a communication means. The voice recognition device executes voice recognition processing to convert the signals into command data and then send back the command data to the robot controller which transmitted the signals using communication means. Receiving the command data, the robot controller executes the commands."
"Flight control method and device of unmanned aerial vehicle, and unmanned aerial vehicle",https://lens.org/119-397-360-917-634,2021,"A flight control method and device of an unmanned aerial vehicle, and an unmanned aerial vehicle. The method comprises: determining a flight track of the unmanned aerial vehicle (101); receiving a remote control signal sent by a remote control device (102); converting the remote control signal into a flight controlled quantity of the unmanned aerial vehicle (103); generating a flight adjustment controlled quantity of the unmanned aerial vehicle according to the current location, the flight track and the flight controlled quantity of the unmanned aerial vehicle (104); and executing a flight mission according to the action indicated by the flight adjustment controlled quantity so that the unmanned aerial vehicle runs on the flight track (105). When the flight of the unmanned aerial vehicle is manually controlled by using the remote control device, the unmanned aerial vehicle is ensured, according to a transversal adjustment controlled quantity, not to yaw but to fly on the correct track all the time in the case of a long flight; therefore, flight accuracy is improved."
"Flight control method and device of unmanned aerial vehicle, and unmanned aerial vehicle",https://lens.org/007-087-858-682-727,2019,"A flight control method and device of an unmanned aerial vehicle, and an unmanned aerial vehicle. The method comprises: determining a flight track of the unmanned aerial vehicle (101); receiving a remote control signal sent by a remote control device (102); converting the remote control signal into a flight controlled quantity of the unmanned aerial vehicle (103); generating a flight adjustment controlled quantity of the unmanned aerial vehicle according to the current location, the flight track and the flight controlled quantity of the unmanned aerial vehicle (104); and executing a flight mission according to the action indicated by the flight adjustment controlled quantity so that the unmanned aerial vehicle runs on the flight track (105). When the flight of the unmanned aerial vehicle is manually controlled by using the remote control device, the unmanned aerial vehicle is ensured, according to a transversal adjustment controlled quantity, not to yaw but to fly on the correct track all the time in the case of a long flight; therefore, flight accuracy is improved."
"HYBRID DRONE, BASE STATION AND METHODS THEREFOR",https://lens.org/098-570-415-450-725,2023,A drone system and method for deploying and autonomously refuelling. The drone system includes a base station and a drone. The base station and drone are configured for autonomous refuelling when the drone has landed in the base station. The base station also provides portability and security of the drone.
"HYBRID DRONE, BASE STATION AND METHODS THEREFOR",https://lens.org/098-570-415-450-725,2023,A drone system and method for deploying and autonomously refuelling. The drone system includes a base station and a drone. The base station and drone are configured for autonomous refuelling when the drone has landed in the base station. The base station also provides portability and security of the drone.
AUTONOMOUS LOW-ALTITUDE UAV DETECTION SYSTEM,https://lens.org/161-696-229-426-226,2023,"An autonomous unmanned aerial vehicle detecting system for monitoring a geographic area includes an unmanned blimp adapted to hover in air, at least one camera mounted on the blimp to scan at least a portion of the geographic area, a location sensor to determine a location of the blimp, and a controller arranged in communication with blimp, the at least one camera, and the location sensor. The controller is configured to position the blimp at a desired location in the air based on inputs received from the location sensor, and monitor the geographic area based on the images received from at least one camera. The controller is also configured to detect a presence of an unmanned aerial vehicle within the geographic area based on the received images, and determine whether the detected unmanned aerial vehicle is an unauthorized unmanned aerial vehicle based on the received images."
GROUND STATION FOR DELIVERIES AND PICK-UPS BY DRONE AND METHOD OF LOAD DELIVERY AND PICK-UP BY DRONE,https://lens.org/090-819-391-520-484,2023,"A ground station for deliveries and pick-ups by a drone comprising a vertical structure (4) fixable to the ground or to a fixed structure and provided with an arm (5) movable between a rest position and an extended activation position wherein the arm (5) extends transversely in a cantilever fashion from the vertical structure (4); the vertical structure (4) carries a first marker Ml at the top that is designed to be recognised by the drone during flight to activate a step of approach of the drone to the ground station while maintaining a predetermined horizontal distance from the ground station and a first and a second laser emitter (8, 9) defining respectively a first /a second position reference for the drone wherein a portion (3f) of the drone has a first or a second vertical distance DI, D2 from the arm (5) arranged in the extended position; the ground station (2) is configured to carry out a coupling procedure of an end portion (5f) of the arm (5) with a support structure (11) of a load (12) carried by the drone (3)."
Programmable Fan,https://lens.org/162-242-963-430-422,2019,"A fan assembly is disclosed. The fan assembly is comprised of a fan with a motor and a blade as to create an airflow, and an actuator which is adapted to move the fan in vertical and horizontal directions, such that the fan directs airflow below it. The fan further comprises a controller adapted to control the adapter, and a remote control which is adapted to control the controller. The remote control sends signals to direct the controller, and both are adapted such that the movement of the fan can be programmed to a path set by a user and can also be manipulated to a static position set by the user. Preferably, the remote control is a smart device, such as a smart phone."
Building quality inspection system and inspection robot,https://lens.org/040-848-345-850-377,2021,"A building quality inspection system includes a controller, a drone, and a robot that are communicably connected to one another. The controller includes circuitry configured to, when exterior of a building is inspected, sends an inspection objective to the drone to instruct the drone to carry out a visual inspection of the exterior of the building, receives inspection data collected by the drone during the visual inspection of the exterior of the building, extracts a location where damage is suspected from the inspection data collected by the drone, sends the location where damage is suspected to the robot to carry out an exterior inspection at the location where damage is suspected, receives inspection data collected by the robot during the exterior inspection, and determines current quality of the exterior of the building based on the inspection data collected by the drone and the robot."
BUILDING QUALITY INSPECTION SYSTEM AND INSPECTION ROBOT,https://lens.org/053-177-489-604-690,2020,"A building quality inspection system includes a controller, a drone, and a robot that are communicably connected to one another. The controller includes circuitry configured to, when exterior of a building is inspected, sends an inspection objective to the drone to instruct the drone to carry out a visual inspection of the exterior of the building, receives inspection data collected by the drone during the visual inspection of the exterior of the building, extracts a location where damage is suspected from the inspection data collected by the drone, sends the location where damage is suspected to the robot to carry out an exterior inspection at the location where damage is suspected, receives inspection data collected by the robot during the exterior inspection, and determines current quality of the exterior of the building based on the inspection data collected by the drone and the robot."
METHOD FOR CONTROLLING A FORMATION OF A COLLABORATING SWARM OF UNMANNED MOBILE UNITS,https://lens.org/182-096-875-362-733,2021,"A method for controlling a formation of a collaborating swarm of unmanned mobile units, in particular a flight formation of a swarm of drones, comprises emitting tracking signals by a plurality of signal emitters arranged on each mobile unit, wherein the signal emitters are distributed over each mobile unit in a geometric arrangement characteristic of the respective mobile unit; detecting the tracking signals of at least adjacent mobile units within the swarm by a signal acquisition system of each mobile unit; determining a current relative position and/or a current orientation of the at least adjacent mobile units with respect to each mobile unit based on the detected tracking signals of the signal emitters on the at least adjacent mobile units; and steering each mobile unit based on the respectively determined current relative positions and/or current orientations of the at least adjacent mobile units to establish and/or maintain a specified formation of the swarm."
WWAN radio link quality navigation for a drone,https://lens.org/107-597-120-087-644,2019,Various embodiments include methods of navigating a drone that may include determining whether a radio link quality trigger event associated with communications with the drone has occurred while the drone travels along a set route to a destination. The radio link quality trigger event may correspond to predetermined characteristics of radio link quality. The drone may be steered to follow a search maneuver for improving radio link quality in response to determining the radio link quality trigger event has occurred. The search maneuver may follow a preconfigured deviation pattern that is configured before determining whether the radio link quality trigger event has occurred and departs from the set route.
WWAN RADIO LINK QUALITY NAVIGATION FOR A DRONE,https://lens.org/043-267-712-589-494,2018,Various embodiments include methods of navigating a drone that may include determining whether a radio link quality trigger event associated with communications with the drone has occurred while the drone travels along a set route to a destination. The radio link quality trigger event may correspond to predetermined characteristics of radio link quality. The drone may be steered to follow a search maneuver for improving radio link quality in response to determining the radio link quality trigger event has occurred. The search maneuver may follow a preconfigured deviation pattern that is configured before determining whether the radio link quality trigger event has occurred and departs from the set route.
DRONE WITH DYNAMIC ANTENNA DIVERSITY,https://lens.org/174-951-758-992-714,2018,"The drone comprises M antennas, with in particular two offset antennas located symmetrically at the ends of two arms for the connection to the propulsion units (24), and a ventral antenna under the drone body. The radio transmission is operated simultaneously on N similar RF channels, with 2N<M. An antenna switching circuit couples selectively each of the N RF channels to N antennas out of the M antennas according to a plurality of different coupling schemes, dynamically through a piloting logic selecting one of the coupling schemes. The selection is operated as a function of a signal delivered by the drone-borne microprocessor, as a function of the flight and signal transmission conditions, determined at a given instant."
Drone with dynamic antenna diversity,https://lens.org/045-573-712-855-658,2019,"The drone comprises M antennas, with in particular two offset antennas located symmetrically at the ends of two arms for the connection to the propulsion units (24), and a ventral antenna under the drone body. The radio transmission is operated simultaneously on N similar RF channels, with 2N<M. An antenna switching circuit couples selectively each of the N RF channels to N antennas out of the M antennas according to a plurality of different coupling schemes, dynamically through a piloting logic selecting one of the coupling schemes. The selection is operated as a function of a signal delivered by the drone-borne microprocessor, as a function of the flight and signal transmission conditions, determined at a given instant."
DRONE,https://lens.org/062-732-855-958-373,2016,"There is disclosed a drone including a main body comprising a motor, a shaft inserted in the main body vertically, a wing unit rotatable on the shaft by a power generated from the motor, the wing unit comprising a propeller unfolded horizontally and folded vertically, wherein the motor comprises a first motor and a second motor, and the shaft comprises an upper shaft inserted in the main body from a top vertically and a lower shaft inserted in the main body from a bottom vertically, and the wing unit comprises a first wing unit rotated on the upper shaft in a first direction by a power generated from the first motor, and a second wing unit rotated on the lower shaft in a second direction, which is the reverse of the first direction, by a power generated from the second motor."
Drone,https://lens.org/146-057-936-456-817,2018,"There is disclosed a drone including a main body comprising a motor, a shaft inserted in the main body vertically, a wing unit rotatable on the shaft by a power generated from the motor, the wing unit comprising a propeller unfolded horizontally and folded vertically, wherein the motor comprises a first motor and a second motor, and the shaft comprises an upper shaft inserted in the main body from a top vertically and a lower shaft inserted in the main body from a bottom vertically, and the wing unit comprises a first wing unit rotated on the upper shaft in a first direction by a power generated from the first motor, and a second wing unit rotated on the lower shaft in a second direction, which is the reverse of the first direction, by a power generated from the second motor."
EMERGENCY UAV METHOD AND APPARATUS,https://lens.org/011-839-719-037-65X,2019,"Apparatus, method and storage medium associated with UAV assisted emergency responses are disclosed herein. In embodiments, an UAV may comprise a flight controller to control at least one or more engines of the UAV to navigate the UAV to condition road traffic for an emergency vehicle on emergency en route to a destination, wherein to condition road traffic, the flight controller is to receive navigation data of the emergency vehicle, and in response, control at least the one or more engines to navigate the UAV in advance of the emergency vehicle, to alert road traffics ahead of the emergency vehicle of pending transit of the emergency vehicle. Other embodiments may be disclosed or claimed"
EMERGENCY UAV METHOD AND APPARATUS,https://lens.org/100-074-778-437-05X,2018,"Apparatus, method and storage medium associated with UAV assisted emergency responses are disclosed herein. In embodiments, an UAV may comprise a flight controller to control at least one or more engines of the UAV to navigate the UAV to condition road traffic for an emergency vehicle on emergency en route to a destination, wherein to condition road traffic, the flight controller is to receive navigation data of the emergency vehicle, and in response, control at least the one or more engines to navigate the UAV in advance of the emergency vehicle, to alert road traffics ahead of the emergency vehicle of pending transit of the emergency vehicle. Other embodiments may be disclosed or claimed"
"MOBILE OBJECT, REMOTE-CONTROL DEVICE, REMOTE-CONTROL SYSTEM, REMOTE-CONTROL METHOD, AND RECORDING MEDIUM HAVING REMOTE-CONTROL PROGRAM RECORDED THEREON",https://lens.org/173-722-127-585-252,2020,"To enable flexibly altering the configuration of an unmanned aircraft, the remote-control device is provided with: a receiving part which receives, via a communication network, sensor information transmitted from one or more mobile objects; a control unit that calculates, on the basis of the received sensor information and attitude control information that pertains to attitude control of a collective including as inputted elements at least one mobile object and that is set on the basis of configuration information pertaining to the configuration of the collective, a control manipulation quantity for manipulating the mobile objects, and generates a control signal including the control manipulation quantity; and a transmission part which transmits the generated control signal to the mobile objects."
Portable device controlling unmanned aerial vehicle and method of controlling therefor,https://lens.org/037-550-089-944-533,2017,"The present specification relates to a portable device controlling an unmanned aerial vehicle and a method of controlling therefor. According to one embodiment, a method of controlling a portable device controlling an unmanned aerial vehicle capturing an image includes the steps of obtaining first image information of a target object using a camera unit, transmitting a capture control signal controlling image capture for the target object to the unmanned aerial vehicle, receiving second image information of the target object captured based on the capture control signal from the unmanned aerial vehicle and generating a 3D image corresponding to the target object using the first image information and the second image information."
"Remote control device, remote control setting method, and program",https://lens.org/137-334-571-537-118,2014,"There is provided a remote control device including: a communication unit that can perform communication through a network; a remote control unit that can transmit one or more control commands to a controlled device in response to an operation by a user; a storage unit that stores control command information specifying the one or more control commands to be transmitted from the remote control unit; and a setting unit that sets the control command information to the storage unit based on a result of communication by the communication unit with a controlled device through the network, wherein the setting unit detects a controlled device connected to the network by transmitting a device search signal from the communication unit, acquires device information of the detected controlled device from the controlled device, and decides the control command information to be set to the storage unit based on the acquired device information."
"REMOTE CONTROL DEVICE, REMOTE CONTROL SETTING METHOD, AND PROGRAM",https://lens.org/191-964-691-400-962,2012,"There is provided a remote control device including: a communication unit that can perform communication through a network; a remote control unit that can transmit one or more control commands to a controlled device in response to an operation by a user; a storage unit that stores control command information specifying the one or more control commands to be transmitted from the remote control unit; and a setting unit that sets the control command information to the storage unit based on a result of communication by the communication unit with a controlled device through the network, wherein the setting unit detects a controlled device connected to the network by transmitting a device search signal from the communication unit, acquires device information of the detected controlled device from the controlled device, and decides the control command information to be set to the storage unit based on the acquired device information."
METHODS OF SAVING UAV'S ENERGY CONSUMPTION AND IMPROVING ITS HOVERING ACCURACY,https://lens.org/052-584-395-515-541,2021,"A multi-rotor unmanned aerial vehicle (""UAV"") is provided with a method of operating it so that it can perch on a surface in the environment without additional equipment so as to save power. The UAV has a frame supporting at least four variable speed reversible motors spaced about the frame. Each motor drives a propeller arranged to cause the frame to hover. A sensor is provided on the UAV for detecting the distance between the UAV and a target surface. A computer is provided for executing software modules so as to control the operation of the motors to cause the UAV to execute flight maneuvers including at least (a) an approach to the target surface, (b) contacting the target surface using the ""ceiling effect"" so as to perch on the surface and reduce the energy consumption of the UAV and (c) detach from the target surface."
ROBOT AND CONTROLLING METHOD THEREOF,https://lens.org/046-095-090-147-085,2016,"A robot and a controlling method thereof are provided. The robot includes a driver unit configured to move a location of the robot, a sensor unit configured to sense an environment around the robot, and a controller configured to, in response to the location of the robot being changed by a user, check a current location of the robot by using the environment of the changed location sensed by the sensor unit and pre-stored map information, determine a task to be performed, based on the checked location and the environment of the changed location, and control the driver unit according to the determined task."
Robot and controlling method thereof,https://lens.org/025-114-643-819-486,2019,"A robot and a controlling method thereof are provided. The robot includes a driver unit configured to move a location of the robot, a sensor unit configured to sense an environment around the robot, and a controller configured to, in response to the location of the robot being changed by a user, check a current location of the robot by using the environment of the changed location sensed by the sensor unit and pre-stored map information, determine a task to be performed, based on the checked location and the environment of the changed location, and control the driver unit according to the determined task."
"Radio controlled aircraft, remote controller and methods for use therewith",https://lens.org/174-826-161-468-415,2018,A radio controlled (RC) vehicle includes a receiver configured to receive a radio frequency (RF) signal from a remote control device. The RF signal indicates command data in accordance with a first coordinate system that is from a perspective of the remote control device. The command data includes a lift command associated with a hovering state of the RC vehicle. One or more motion sensors are configured to generate motion data that indicates a position of the RC vehicle and an orientation of the RC vehicle. A processor is configured to transform the command data into control data based on the motion data and in accordance with a second coordinate system that is from a perspective of the RC vehicle. A plurality of control devices are configured to control motion of the RC vehicle based on the control data.
Accelerometer inside of a microphone unit,https://lens.org/065-553-462-413-909,2023,A system includes a microphone unit coupled to a roof of an autonomous vehicle. The microphone unit includes a microphone board having a first opening. The microphone unit also includes a first microphone positioned over the first opening and coupled to the microphone board. The microphone unit further includes an accelerometer. The system also includes a processor coupled to the microphone unit.
Accelerometer Inside of a Microphone Unit,https://lens.org/002-194-211-082-941,2022,A system includes a microphone unit coupled to a roof of an autonomous vehicle. The microphone unit includes a microphone board having a first opening. The microphone unit also includes a first microphone positioned over the first opening and coupled to the microphone board. The microphone unit further includes an accelerometer. The system also includes a processor coupled to the microphone unit.
Accelerometer inside of a microphone unit,https://lens.org/063-174-225-112-632,2022,A system includes a microphone unit coupled to a roof of an autonomous vehicle. The microphone unit includes a microphone board having a first opening. The microphone unit also includes a first microphone positioned over the first opening and coupled to the microphone board. The microphone unit further includes an accelerometer. The system also includes a processor coupled to the microphone unit.
ACCELEROMETER INSIDE OF A MICROPHONE UNIT,https://lens.org/095-589-709-045-11X,2022,A system includes a microphone unit coupled to a roof of an autonomous vehicle. The microphone unit includes a microphone board having a first opening. The microphone unit also includes a first microphone positioned over the first opening and coupled to the microphone board. The microphone unit further includes an accelerometer. The system also includes a processor coupled to the microphone unit.
Accelerometer inside of a microphone unit,https://lens.org/063-174-225-112-632,2022,A system includes a microphone unit coupled to a roof of an autonomous vehicle. The microphone unit includes a microphone board having a first opening. The microphone unit also includes a first microphone positioned over the first opening and coupled to the microphone board. The microphone unit further includes an accelerometer. The system also includes a processor coupled to the microphone unit.
ACCELEROMETER INSIDE OF A MICROPHONE UNIT,https://lens.org/095-589-709-045-11X,2022,A system includes a microphone unit coupled to a roof of an autonomous vehicle. The microphone unit includes a microphone board having a first opening. The microphone unit also includes a first microphone positioned over the first opening and coupled to the microphone board. The microphone unit further includes an accelerometer. The system also includes a processor coupled to the microphone unit.
Using unmanned aerial vehicles (UAVs or drones) in forestry machine-connectivity applications,https://lens.org/028-700-399-263-72X,2020,"A method includes controlling an unmanned aerial vehicle (UAV) to collect and forward information pertaining to a forestry worksite area. The UAV is controlled to fly to a first location and capture image information at the first location. The UAV is also controlled to fly to a second location, establish a communication connection between the UAV and a communication system at the second location, and send the captured image information to the communication system via the established connection. In another example, the UAV uploads (e.g., sends) the data to a communication system (e.g., computing device operated by an operator), and the uploaded data is further sent to a remote computing system (e.g., a forestry analysis system)."
STABILITY SYSTEMS FOR TETHERED UNMANNED AERIAL VEHICLES,https://lens.org/158-605-711-076-522,2021,"An unmanned aerial vehicle including a body, a platform, a rotor, a tether cable, and an actuation system. The platform is coupled to the body such that the platform is rotatable relative to the body about a first horizontal axis of rotation. The rotor is rigidly coupled to the platform such that the rotor and the platform rotate together about the first horizontal axis of rotation. The tether cable extends away from the body and is coupled to the body such that the tether cable is rotatable relative to the body about a second horizontal axis of rotation. The first and second horizontal axes of rotation are normal to a vertical plane. The actuation system is configured to rotate the platform in a clockwise direction about the first horizontal axis of rotation when the tether cable rotates in a counter-clockwise direction about the second horizontal axis of rotation."
STABILITY SYSTEMS FOR TETHERED UNMANNED AERIAL VEHICLES,https://lens.org/080-610-440-178-305,2019,"An unmanned aerial vehicle including a body, a platform, a rotor, a tether cable, and an actuation system. The platform is coupled to the body such that the platform is rotatable relative to the body about a first horizontal axis of rotation. The rotor is rigidly coupled to the platform such that the rotor and the platform rotate together about the first horizontal axis of rotation. The tether cable extends away from the body and is coupled to the body such that the tether cable is rotatable relative to the body about a second horizontal axis of rotation. The first and second horizontal axes of rotation are normal to a vertical plane. The actuation system is configured to rotate the platform in a clockwise direction about the first horizontal axis of rotation when the tether cable rotates in a counter-clockwise direction about the second horizontal axis of rotation."
Stability systems for tethered unmanned aerial vehicles,https://lens.org/146-196-707-964-21X,2020,"An unmanned aerial vehicle including a body, a platform, a rotor, a tether cable, and an actuation system. The platform is coupled to the body such that the platform is rotatable relative to the body about a first horizontal axis of rotation. The rotor is rigidly coupled to the platform such that the rotor and the platform rotate together about the first horizontal axis of rotation. The tether cable extends away from the body and is coupled to the body such that the tether cable is rotatable relative to the body about a second horizontal axis of rotation. The first and second horizontal axes of rotation are normal to a vertical plane. The actuation system is configured to rotate the platform in a clockwise direction about the first horizontal axis of rotation when the tether cable rotates in a counter-clockwise direction about the second horizontal axis of rotation."
A dynamic bionic grabbing UAV with cognitive function,https://lens.org/146-818-085-779-696,2023,"A dynamic bionic grabbing UAV with cognitive function comprises a rotorcraft body, a grabbing mechanism, a positioning unit, a camera unit and a control unit, wherein an installation platform is installed on the top of the rotorcraft body, rotor wings are fixedly connected around the rotorcraft body, and two symmetrical supports are fixedly connected at the bottom of the rotorcraft body; the top of the grabbing mechanism is fixed under the rotorcraft body and between the two supports; the positioning unit is fixed on the installation platform; the camera unit is fixed on the installation platform; the control unit is fixedly connected on the installation platform and electrically connected with the rotor wings and the grabbing mechanism, the positioning unit and the camera unit. The UAV has autonomous cognitive ability to control flight autonomously and recognize the target. The bionic claws can accurately grab various objects with complex surfaces."
AERIAL DRONE CLEANING DEVICE AND METHOD OF CLEANING A TARGET SURFACE THEREWITH,https://lens.org/016-916-511-040-372,2017,"A drone which can be piloted by a user. The drone has at least one or both of a depending head and an outwardly extending elongate handle. A cleaning sheet may be removably disposed on the head, to clean a target surface, such as a floor or countertop. A duster may be removably disposed on the handle, to clean a target surface, such as an elevated surface or clean personal items."
AERIAL DRONE CLEANING DEVICE AND METHOD OF CLEANING A TARGET SURFACE THEREWITH,https://lens.org/087-363-957-637-649,2017,"A drone which can be piloted by a user. The drone has at least one or both of a depending head and an outwardly extending elongate handle. A cleaning sheet may be removably disposed on the head, to clean a target surface, such as a floor or countertop. A duster may be removably disposed on the handle, to clean a target surface, such as an elevated surface or clean personal items."
Aerial drone cleaning device and method of cleaning a target surface therewith,https://lens.org/045-311-213-475-001,2018,"A drone which can be piloted by a user. The drone has at least one or both of a depending head and an outwardly extending elongate handle. A cleaning sheet may be removably disposed on the head, to clean a target surface, such as a floor or countertop. A duster may be removably disposed on the handle, to clean a target surface, such as an elevated surface or clean personal items."
Unmanned aerial vehicle for situational awareness to first responders and alarm investigation,https://lens.org/165-244-645-489-478,2019,"A device, and method, for situational awareness of an emergency scene for first responders uses an unmanned aerial vehicle- equipped with a sensor package in populated or otherwise restricted areas. The unmanned aerial vehicle is assigned to a control center for a designated incident while automatically tasking the unmanned aerial vehicle with the initiation of the incident response to autonomously proceed to the incident prior the control center taking active control of the unmanned aerial vehicle. P254218D1_22766217_1"
AUTONOMOUS AERIAL CABLE INSPECTION SYSTEM,https://lens.org/080-632-072-216-212,2017,"An aerial inspection system (100) is provided, including an unmanned aerial vehicle (UAV) (110) having an articulated arm (120) coupled thereto. An end effector (150) is coupled to a second end of the articulated arm (120), the end effector (150) sized and shaped to extend at least partially around an aerial cable in close proximity. One or more sensors are positioned along an inner surface of the end effector, and provide feedback to a control unit. In response, the control unit adjusts a position of at least one of the UAV (110), the articulated arm (120), and the end effector (150) such that the end effector maintains a close, non-contact position with respect to the cable."
DEVICE INCLUDING A DRONED COVER,https://lens.org/056-873-999-837-679,2018,"A device (1) adapted to be used as a sunshade, an umbrella or the like, comprising a canvas (2) configured to take a closed position in which it is folded over itself in a compact manner, and an open position in which it is at least par- tially extended. The device (1) comprises a main control unit (4) connected to a plurality of drones (3, 30, 300) which are structurally independent from one an- other and evenly distributed over the surface of the canvas (2), said main control unit (4) being configured to receive commands from at least one remote control unit (5) adapted to control the flight of said drones (3, 30, 300) and thus define the shape taken by the canvas (2) in the air."
"A Design Method of a Variable-parameter Neural Dynamic Controller for Drones, and Application Thereof",https://lens.org/101-991-736-810-164,2021,"Abstract This invention discloses a design method of a variable-parameter neural dynamic controller for drones, and application thereof. The method comprising the following steps: building a drone model; based on the drone model, using a variable-parameter recursive neural dynamic method based on an activation function to design an altitude controller, a yaw angle controller, a roll angle controller, a pitch angle controller, a X controller and a Y controller of a drone respectively; inputting control target parameters and drone status information collected by a drone sensor to a controller of each drone; the controller of each drone output control components to control a flight of the drone. The present invention utilizes a non-linear activation function, and the obtained controller may make a drone converge to a target faster when the error is large, and achieve higher accuracy when it is close to the mission target, so that the drone may control the drone to track a time-varying trajectory quickly, accurately and in real time. z (M) - Tut 0.4 0.4 ~ Initial y (M) 0.25x (M) o o Figure 5"
METHOD FOR REMOTE CONTROL OF AN AUDIO DEVICE,https://lens.org/193-909-503-637-219,2004,"A method for remote control of an audio device (1) is described, which receives an audio data stream (A) from a transmission system. A control command in the form of an audio data sample (AM) within the audio data stream (A) is sent to the audio device (1). The received audio data stream (A) is analyzed by means of an audio sample recognition system (2) in or on the audio device (1). A recognized audio data sample (AM) is converted into control data (SD, ST) and depending on the control data (SD, ST), certain components (7, 8) of the audio device (1) are activated in a certain manner."
METHOD OF USING A DEVICE CAPABLE OF CONTROLLED FLIGHT,https://lens.org/099-282-427-040-256,2015,"There is provided a method of using a device capable of controlled flight in a surrounding environment, the device comprising: lifting means for providing lift to the device; object-retaining means for holding an object to be affixed to a target site; and a dispensing assembly for dispensing an adhesive, wherein the method comprises: controlling the lifting means so as to controllably fly the device in the surrounding environment; and using the device to affix an object held by the object-retaining means to a target site in the surrounding environment by dispensing an adhesive from the dispensing assembly. Thus, an aerial device, for example a robotic device, may be used to fly to a desired location and affix an object at the desired location, by dispensing, ejecting or otherwise applying an adhesive."
Method of using a device capable of controlled flight,https://lens.org/190-854-210-508-398,2020,"There is provided a method of using a device capable of controlled flight in a surrounding environment, the device comprising: lifting means for providing lift to the device; object-retaining means for holding an object to be affixed to a target site; and a dispensing assembly for dispensing an adhesive, wherein the method comprises: controlling the lifting means so as to controllably fly the device in the surrounding environment; and using the device to affix an object held by the object-retaining means to a target site in the surrounding environment by dispensing an adhesive from the dispensing assembly. Thus, an aerial device, for example a robotic device, may be used to fly to a desired location and affix an object at the desired location, by dispensing, ejecting or otherwise applying an adhesive."
Method of Using a Device Capable Of Controlled Flight,https://lens.org/086-707-494-163-634,2017,"There is provided a method of using a device capable of controlled flight in a surrounding environment, the device comprising: lifting means for providing lift to the device; object-retaining means for holding an object to be affixed to a target site; and a dispensing assembly for dispensing an adhesive, wherein the method comprises: controlling the lifting means so as to controllably fly the device in the surrounding environment; and using the device to affix an object held by the object-retaining means to a target site in the surrounding environment by dispensing an adhesive from the dispensing assembly. Thus, an aerial device, for example a robotic device, may be used to fly to a desired location and affix an object at the desired location, by dispensing, ejecting or otherwise applying an adhesive."
METHOD OF USING A DEVICE CAPABLE OF CONTROLLED FLIGHT,https://lens.org/152-624-503-592-958,2016,"There is provided a method of using a device capable of controlled flight in a surrounding environment, the device comprising: lifting means for providing lift to the device; object-retaining means for holding an object to be affixed to a target site; and a dispensing assembly for dispensing an adhesive, wherein the method comprises: controlling the lifting means so as to controllably fly the device in the surrounding environment; and using the device to affix an object held by the object-retaining means to a target site in the surrounding environment by dispensing an adhesive from the dispensing assembly. Thus, an aerial device, for example a robotic device, may be used to fly to a desired location and affix an object at the desired location, by dispensing, ejecting or otherwise applying an adhesive."
"AUTONOMOUS UNDERWATER VEHICLE HOVER APPARATUS, METHOD, AND APPLICATIONS",https://lens.org/052-728-955-194-978,2014,An autonomous underwater vehicle (AUV) including a deployable anchor and a method for operating an AUV having a deployable anchor in a hover mode.
"Autonomous underwater vehicle hover apparatus, method, and applications",https://lens.org/182-615-152-898-982,2018,An autonomous underwater vehicle (AUV) including a deployable anchor and a method for operating an AUV having a deployable anchor in a hover mode.
"AUTONOMOUS UNDERWATER VEHICLE HOVER APPARATUS, METHOD, AND APPLICATIONS",https://lens.org/155-189-663-886-328,2015,An autonomous underwater vehicle (AUV) including a deployable anchor and a method for operating an AUV having a deployable anchor in a hover mode.
"Autonomous Underwater Vehicle Hover Apparatus, Method, and Applications",https://lens.org/063-891-859-953-937,2016,An autonomous underwater vehicle (AUV) including a deployable anchor and a method for operating an AUV having a deployable anchor in a hover mode.
Method and apparatus for performing water sampling with an unmanned aerial vehicle,https://lens.org/148-211-731-264-489,2022,"A UAV capable of sampling a hazardous body of water and a method of using the same. An electronic controller of the attached apparatus receives a first instruction to lower a sampling device at a specified rate into the body of water. The sampling device is connected to the apparatus via a line, and the sampling device is lowered by unspooling the line from a reel. The sampling device is lowered at the specified rate into the body of water based on the instruction and is retrieved from the body of water. A line-cutting device can cut the line should the sampling device get caught up in an obstruction."
Method and apparatus for performing water sampling with an unmanned aerial vehicle,https://lens.org/148-211-731-264-489,2022,"A UAV capable of sampling a hazardous body of water and a method of using the same. An electronic controller of the attached apparatus receives a first instruction to lower a sampling device at a specified rate into the body of water. The sampling device is connected to the apparatus via a line, and the sampling device is lowered by unspooling the line from a reel. The sampling device is lowered at the specified rate into the body of water based on the instruction and is retrieved from the body of water. A line-cutting device can cut the line should the sampling device get caught up in an obstruction."
High-Altitude Airborne Remote Sensing,https://lens.org/097-503-715-628-904,2022,"A UAV-carried surveillance and remote sensing platform is launched from a high altitude and flies over a target area, collecting remote sensing imagery before returning to earth. The UAV may be towed to a desired altitude by a powered aircraft or a balloon and then launched for cruising over a target area while capturing data. Instead of being piloted remotely, the UAV employs an autonomous flight control system."
High-Altitude Airborne Remote Sensing,https://lens.org/097-503-715-628-904,2022,"A UAV-carried surveillance and remote sensing platform is launched from a high altitude and flies over a target area, collecting remote sensing imagery before returning to earth. The UAV may be towed to a desired altitude by a powered aircraft or a balloon and then launched for cruising over a target area while capturing data. Instead of being piloted remotely, the UAV employs an autonomous flight control system."
High-Altitude Airborne Remote Sensing,https://lens.org/097-503-715-628-904,2022,"A UAV-carried surveillance and remote sensing platform is launched from a high altitude and flies over a target area, collecting remote sensing imagery before returning to earth. The UAV may be towed to a desired altitude by a powered aircraft or a balloon and then launched for cruising over a target area while capturing data. Instead of being piloted remotely, the UAV employs an autonomous flight control system."
SYSTEM AND METHOD FOR CONTROLLING AUTONOMOUS FLYING VEHICLE FLIGHT PATHS,https://lens.org/071-723-561-402-152,2016,"A method is provided for limiting access to airspace by drones. The method includes receiving position information from a user associated with a property identified by the position information. The method also includes assembling the position information with other position information to compile a comprehensive configurable flight zone database. The method further includes pushing the configurable flight zone database to at least one drone. The drone accesses the configurable flight zone database to determine if movement is allowed, and the drone is programmed to not fly into areas identified in the configurable flight zone database. In the method, the drone may be further programmed to prohibit directing a camera into the areas identified in the configurable flight zone database."
SYSTEM AND METHOD FOR CONTROLLING AUTONOMOUS FLYING VEHICLE FLIGHT PATHS,https://lens.org/178-569-868-178-172,2017,"A method is provided for limiting access to airspace by drones. The method includes receiving position information from a user associated with a property identified by the position information. The method also includes assembling the position information with other position information to compile a comprehensive configurable flight zone database. The method further includes pushing the configurable flight zone database to at least one drone. The drone accesses the configurable flight zone database to determine if movement is allowed, and the drone is programmed to not fly into areas identified in the configurable flight zone database. In the method, the drone may be further programmed to prohibit directing a camera into the areas identified in the configurable flight zone database."
SYSTEM AND METHOD FOR CONTROLLING AUTONOMOUS FLYING VEHICLE FLIGHT PATHS,https://lens.org/109-863-915-804-303,2016,"A method is provided for limiting access to airspace by drones. The method includes receiving position information from a user associated with a property identified by the position information. The method also includes assembling the position information with other position information to compile a comprehensive configurable flight zone database. The method further includes pushing the configurable flight zone database to at least one drone. The drone accesses the configurable flight zone database to determine if movement is allowed, and the drone is programmed to not fly into areas identified in the configurable flight zone database. In the method, the drone may be further programmed to prohibit directing a camera into the areas identified in the configurable flight zone database."
System and method for controlling autonomous flying vehicle flight paths,https://lens.org/013-908-745-619-10X,2017,"A method is provided for limiting access to airspace by drones. The method includes receiving position information from a user associated with a property identified by the position information. The method also includes assembling the position information with other position information to compile a comprehensive configurable flight zone database. The method further includes pushing the configurable flight zone database to at least one drone. The drone accesses the configurable flight zone database to determine if movement is allowed, and the drone is programmed to not fly into areas identified in the configurable flight zone database. In the method, the drone may be further programmed to prohibit directing a camera into the areas identified in the configurable flight zone database."
SYSTEM AND METHOD FOR CONTROLLING AUTONOMOUS FLYING VEHICLE FLIGHT PATHS,https://lens.org/019-215-398-717-704,2016,"A method is provided for limiting access to airspace by drones. The method includes receiving position information from a user associated with a property identified by the position information. The method also includes assembling the position information with other position information to compile a comprehensive configurable flight zone database. The method further includes pushing the configurable flight zone database to at least one drone. The drone accesses the configurable flight zone database to determine if movement is allowed, and the drone is programmed to not fly into areas identified in the configurable flight zone database. In the method, the drone may be further programmed to prohibit directing a camera into the areas identified in the configurable flight zone database."
System and method for controlling autonomous flying vehicle flight paths,https://lens.org/134-120-924-259-051,2017,"A method is provided for limiting access to airspace by drones. The method includes receiving position information from a user associated with a property identified by the position information. The method also includes assembling the position information with other position information to compile a comprehensive configurable flight zone database. The method further includes pushing the configurable flight zone database to at least one drone. The drone accesses the configurable flight zone database to determine if movement is allowed, and the drone is programmed to not fly into areas identified in the configurable flight zone database. In the method, the drone may be further programmed to prohibit directing a camera into the areas identified in the configurable flight zone database."
High-Altitude Airborne Remote Sensing,https://lens.org/105-611-488-073-545,2023,"An unmanned aerial vehicle capable of vertical takeoff and landing carries a remote sensing platform to a high altitude cruising altitude and flies over a target area, collecting remote sensing imagery before returning to earth. Instead of being piloted remotely, the vehicle employs an autonomous flight control system."
High-Altitude Airborne Remote Sensing,https://lens.org/105-611-488-073-545,2023,"An unmanned aerial vehicle capable of vertical takeoff and landing carries a remote sensing platform to a high altitude cruising altitude and flies over a target area, collecting remote sensing imagery before returning to earth. Instead of being piloted remotely, the vehicle employs an autonomous flight control system."
CAMERA APPARATUS AND METHOD FOR REMOTELY CONTROLLING ELECTRONIC DEVICES,https://lens.org/109-350-186-337-253,2015,"A networked camera for controlling electronic devices is provided. The camera includes a camera module for obtaining images, a remote control module for generating remote control signals for electronic devices, and an orientation module for controlling orientation of the remote control module. The remote control module includes an IR (infrared) beam emitter for generating IR remote control signals. In response to a control command from a user device, the camera identifies a target electronic device, an orientation associated with the target electronic device, and a code associated with the target electronic device based on the control command. The camera changes orientation of a remote control module toward the target electronic device using the identified orientation and transmit an IR control signal using the identified code. Then, in response to that transmitted IR control signal, the target electronic device executes one or more functions that correspond to the control command."
REMOTE STEERING OF AN UNMANNED AERIAL VEHICLE,https://lens.org/187-174-882-814-390,2019,"According to various aspects, an unmanned aerial vehicle controlling device may include: a receiver configured to receive a spherical image of a vicinity from an unmanned aerial vehicle; a display configured to display a first person view of the spherical image; a plurality of motion sensors configured to sense a movement within a tracked space; one or more processors configured to map the sensed movement within the tracked space to a mapped movement within the vicinity of the unmanned aerial vehicle and generate a control signal based on the mapped movement; and a transmitter configured to transmit the control signal to the unmanned aerial vehicle."
VOICE ASSISTANT FOR RECORDS,https://lens.org/010-299-073-052-277,2019,A voice assistant device can be used by a user to have a conversation to retrieve or generate database records.
Voice assistant for records,https://lens.org/191-607-211-728-702,2021,A voice assistant device can be used by a user to have a conversation to retrieve or generate database records.
FLIGHT CONTROL FOR FLIGHT-RESTRICTED REGIONS,https://lens.org/115-745-886-496-566,2021,"A method for controlling an unmanned aerial vehicle (UAV) includes determining whether the UAV is within a first flight restriction zone or a second flight restriction zone and effecting a restriction on the UAV in accordance with a result of the determination, including prohibiting the UAV from flying in response to determining that the UAV is within the first flight restriction zone, or controlling the UAV to fly below a flight ceiling in response to determining that the UAV is within the second flight restriction zone."
Systems and methods for operating drones in response to an incident,https://lens.org/015-801-450-914-462,2019,"A response system may be provided. The response system may include a security system and an autonomous drone. The security system includes a security sensor and a controller. The drone includes a processor, a memory in communication with the processor, and a drone sensor. The processor may be programmed to link the drone to the controller, build a virtual navigation map of the coverage area based, at least in part, upon initial sensor data stored by the drone, determine that the coverage area is unoccupied, deploy the drone from a docking station, control movement of the drone within the coverage area based upon the virtual navigation map, collect drone sensor data of the coverage area using the drone sensor, and/or analyze the collected drone sensor data to identify an abnormal condition within the coverage area, the abnormal condition including at least one of damage or theft occurring within the coverage area."
Systems and methods for operating drones in response to an incident,https://lens.org/145-051-440-063-813,2021,"A response system may be provided. The response system may include a security system and an autonomous drone. The security system includes a security sensor and a controller. The drone includes a processor, a memory in communication with the processor, and a drone sensor. The processor may be programmed to link the drone to the controller, build a virtual navigation map of the coverage area based, at least in part, upon initial sensor data stored by the drone, determine that the coverage area is unoccupied, deploy the drone from a docking station, control movement of the drone within the coverage area based upon the virtual navigation map, collect drone sensor data of the coverage area using the drone sensor, and/or analyze the collected drone sensor data to identify an abnormal condition within the coverage area, the abnormal condition including at least one of damage or theft occurring within the coverage area."
Systems and methods for operating drones in response to an incident,https://lens.org/138-909-260-314-938,2020,"A response system may be provided. The response system may include a security system and an autonomous drone. The security system includes a security sensor and a controller. The drone includes a processor, a memory in communication with the processor, and a drone sensor. The processor may be programmed to link the drone to the controller, build a virtual navigation map of the coverage area based, at least in part, upon initial sensor data stored by the drone, determine that the coverage area is unoccupied, deploy the drone from a docking station, control movement of the drone within the coverage area based upon the virtual navigation map, collect drone sensor data of the coverage area using the drone sensor, and/or analyze the collected drone sensor data to identify an abnormal condition within the coverage area, the abnormal condition including at least one of damage or theft occurring within the coverage area."
PEST ABATEMENT UTILIZING AN AERIAL DRONE,https://lens.org/116-063-899-062-298,2017,"An aerial drone includes a pest sensor, an environmental sensor, a drone on-board computer, and a pest abatement mechanism. The pest sensor senses a pest based on emissions from the pest. The environmental sensor detects an environment of the pest. The drone on-board computer identifies a pest type of the pest based on the emission from the pest, and establishes a risk level posed by the presence of the pest based on the pest type and the environment of the pest. The pest abatement mechanism performs a pest abatement of the pest based on the pest type and the risk level posed by the presence of the pest."
"PACKAGE ACCEPTANCE, GUIDANCE, AND REFUEL SYSTEM FOR DRONE TECHNOLOGY",https://lens.org/003-437-084-850-29X,2018,Some embodiments described herein relate to a drone landing platform. One or more sensors (122A) coupled to the drone landing platform (120A) can detect local conditions in the vicinity of the drone landing platform. A communications system can be operable to transmit information related local conditions to a drone.
APPARATUS AND METHODS FOR CONTROLLING ATTENTION OF A ROBOT,https://lens.org/007-250-364-952-261,2022,"An automated control system including an unmanned aerial vehicle (UAV) and an input device. The UAV includes: a sensor, a receiver; and memory. The memory includes a task association data including one or more tasks for execution by the UAV. The input device includes a tagging block. The tagging block allows an operator to tag an object of interest and send a tag regarding the object of interest to the UAV, via the receiver, wherein the object of interest is located within a visual field of the UAV. The sensor processes data within the visual field and the input device is configured to communicate the object of interest from the visual field tagged by the operator. The task is selected from the task association data and the UAV executes the task with respect to the object of interest from the visual field."
APPARATUS AND METHODS FOR CONTROLLING ATTENTION OF A ROBOT,https://lens.org/007-250-364-952-261,2022,"An automated control system including an unmanned aerial vehicle (UAV) and an input device. The UAV includes: a sensor, a receiver; and memory. The memory includes a task association data including one or more tasks for execution by the UAV. The input device includes a tagging block. The tagging block allows an operator to tag an object of interest and send a tag regarding the object of interest to the UAV, via the receiver, wherein the object of interest is located within a visual field of the UAV. The sensor processes data within the visual field and the input device is configured to communicate the object of interest from the visual field tagged by the operator. The task is selected from the task association data and the UAV executes the task with respect to the object of interest from the visual field."
"Control apparatus, control system, and control method",https://lens.org/165-781-554-707-592,2020,"A control apparatus, that can expand a range in which noise generated in an unmanned flying object is reduced, is provided. The control apparatus acquires position information of one or more unmanned flying objects and noise information concerning first noises generated by the one or more unmanned flying objects. The control apparatus also acquires output region information indicating an output region of sound output from a speaker. The control apparatus calculates, using the position information, the output region information, and the noise information, second noises that reach the output region. The second noises are caused by the first noises which are generated by the one or more unmanned flying objects. The control apparatus generates opposite phase signals for outputting opposite phase sounds with respect to the calculated second noises, and causes the speaker to output sound on a basis of the generated opposite phase signals."
Hand launchable unmanned aerial vehicle,https://lens.org/105-393-069-609-816,2014,"An unmanned aerial vehicle including a controller operating in a search mode of operation where a receiver of an acquisition sensor searches for a target and causes flight control surfaces to guide the vehicle in a downward spiral path, a terminal mode of operation where the acquisition sensor detects a target and causes flight control surfaces to direct the vehicle toward the target, and an activation mode of operation where a trigger sensor detects a target within a predetermined distance to the vehicle and the controller activates a responder."
Hand launchable unmanned aerial vehicle,https://lens.org/170-449-413-353-889,2014,"An unmanned aerial vehicle including a controller operating in a search mode of operation where a receiver of an acquisition sensor searches for a target and causes flight control surfaces to guide the vehicle in a downward spiral path, a terminal mode of operation where the acquisition sensor detects a target and causes flight control surfaces to direct the vehicle toward the target, and an activation mode of operation where a trigger sensor detects a target within a predetermined distance to the vehicle and the controller activates a responder."
DRONE-ASSISTED SENSOR MAPPING,https://lens.org/114-227-696-755-954,2021,"Methods, systems, and apparatus for drone-assisted sensor mapping are disclosed. A method includes detecting a sensor in a detection area of a drone; based on detecting the sensor in the detection area of the drone, detecting the drone in sensor data captured by the sensor; determining a detection area of the sensor based on movement of the drone after the drone is detected; and determining a destination for the drone based on the detection area of the sensor. The method may include mapping boundaries of the detection area of the sensor to a map of an area where the sensor is located. The sensor can be a passive infrared sensor, an active infrared sensor, a radar sensor, a sonar sensor, a time of flight sensor, a structured light sensor, or a lidar sensor."
Drone-assisted sensor mapping,https://lens.org/125-095-610-235-446,2023,"Methods, systems, and apparatus for drone-assisted sensor mapping are disclosed. A method includes detecting a sensor in a detection area of a drone; based on detecting the sensor in the detection area of the drone, detecting the drone in sensor data captured by the sensor; determining a detection area of the sensor based on movement of the drone after the drone is detected; and determining a destination for the drone based on the detection area of the sensor. The method may include mapping boundaries of the detection area of the sensor to a map of an area where the sensor is located. The sensor can be a passive infrared sensor, an active infrared sensor, a radar sensor, a sonar sensor, a time of flight sensor, a structured light sensor, or a lidar sensor."
Emergency UAV method and apparatus,https://lens.org/000-419-365-014-652,2021,"Apparatus, method and storage medium associated with UAV assisted emergency responses are disclosed herein. In embodiments, an UAV may comprise a flight controller to control at least one or more engines of the UAV to navigate the UAV to condition road traffic for an emergency vehicle on emergency en route to a destination, wherein to condition road traffic, the flight controller is to receive navigation data of the emergency vehicle, and in response, control at least the one or more engines to navigate the UAV in advance of the emergency vehicle, to alert road traffics ahead of the emergency vehicle of pending transit of the emergency vehicle. Other embodiments may be disclosed or claimed."
CONTROL METHOD OF ROBOT,https://lens.org/001-143-349-840-243,2020,"A method of controlling a robot, including operating in a following travel mode of following a user, operating in a guide mode for providing an escort service of providing guidance to a predetermined destination according to a received detection signal, and switching back to the following travel mode upon detecting specific movement of the user, in the guide mode."
Droneboarding system with mechanical flight control,https://lens.org/102-391-644-317-505,2021,"A droneboarding system is disclosed. The droneboarding system includes an unmanned aerial vehicle (drone) for pulling a droneboarder riding a board over a surface, a harness, a tow handle and a plurality of tension lines. Each tension line is attached to the drone and to either the tow handle or the harness. The tension lines are configured in a manner that provides mechanical control of the flight path of the drone. A remote power supply is adapted to be carried by the droneboarder. One of the tension line carries an electrical conductor from the remote power supply to the drone. The electrical conductor provides electrical power from the remote power supply to the drone."
Droneboarding System With Remote Power Supply,https://lens.org/033-516-632-048-817,2018,"A droneboarding system is disclosed. The droneboarding system includes an unmanned aerial vehicle (drone) for pulling a droneboarder riding a board over a surface, a harness, a tow handle and a plurality of tension lines. Each tension line is attached to the drone and to either the tow handle or the harness. The tension lines are configured in a manner that provides mechanical control of the flight path of the drone. A remote power supply is adapted to be carried by the droneboarder. One of the tension line carries an electrical conductor from the remote power supply to the drone. The electrical conductor provides electrical power from the remote power supply to the drone."
Apparatus and methods for landing unmanned aerial vehicle,https://lens.org/161-610-388-968-989,2021,"An unmanned aerial vehicle (UAV) includes one or more processors, and a memory storing instructions. When executed by the one or more processors, the instructions cause the UAV to perform operations including: recognizing a first gesture of a hand; responsive to a recognition of the first gesture, moving the unmanned aerial vehicle to hover above the hand; detecting a distance between the unmanned aerial vehicle and the hand; responsive to a determination that the distance falls in a range, monitoring the hand to recognize a second gesture of the hand; and responsive to a recognition of the second gesture, landing the unmanned aerial vehicle on the hand."
APPARATUS AND METHODS FOR LANDING UNMANNED AERIAL VEHICLE,https://lens.org/186-542-282-330-667,2020,"An unmanned aerial vehicle (UAV) includes one or more processors, and a memory storing instructions. When executed by the one or more processors, the instructions cause the UAV to perform operations including: recognizing a first gesture of a hand; responsive to a recognition of the first gesture, moving the unmanned aerial vehicle to hover above the hand; detecting a distance between the unmanned aerial vehicle and the hand; responsive to a determination that the distance falls in a range, monitoring the hand to recognize a second gesture of the hand; and responsive to a recognition of the second gesture, landing the unmanned aerial vehicle on the hand."
A REPORTER DRONE,https://lens.org/156-125-731-138-06X,2014,"To provide a reporter drone (20), to approch a specific speaker in-between audience inside a big hole, a stadium, or in an open yard, or to take photos, record videos, and registers sounds from inside a narrow location where the drone's body (21) or a reporter can not approach, or can not get in. A triple camera (22) assemby, and a mike-speaker screen assembly (23), are installed and based separately at the ends of a two separate retractable motorized aerials (24), (30), installed at the ends of the bottom of the body (21) of a normal drone (20). When a drone (20) is used for reporting meetings with persons, the camera's antenna (24) is moving in the reverse direction of that moved by the antenna (30) of the mike-speaker screen (23), such that the mike-speaker screen (23) moves toward a speaker (person) while the cameras (22) are keeping a destance from him to get manage to get a photo for him."
Remote forensic investigation,https://lens.org/196-796-115-131-866,2018,"A method includes dispatching a drone to a site. The drone includes audio/visual equipment. The method includes logging a plurality of timestamped locations of the drone and receiving, from the audio/visual equipment, site data captured by an on-site operator of the audio/visual equipment. The method includes correlating a portion of the site data with at least one of the timestamped locations of the drone."
REMOTE FORENSIC INVESTIGATION,https://lens.org/126-232-860-869-526,2018,"A method includes dispatching a drone to a site. The drone includes audio/visual equipment. The method includes logging a plurality of timestamped locations of the drone and receiving, from the audio/visual equipment, site data captured by an on-site operator of the audio/visual equipment. The method includes correlating a portion of the site data with at least one of the timestamped locations of the drone."
UAV Fire-fighting System,https://lens.org/038-701-998-694-000,2013,"An unmanned aerial vehicle (UAV) designed to extinguish fires from the air while remaining tethered to the ground via a tether system fashioned to provide the UAV with power and extinguishant. The UAV is preferably electrically powered and is stabilized in the air via a system of gyroscopes fashioned to work in concert with a series of electric motors capable of moving to counteract the opposing recoil force exhibited as water escapes the nozzle of the tether. A command and control unit on the ground supplies the UAV with electricity and water via the tether. The UAV is preferably stored within and launched from the command and control unit. Controls and sensor readings are communicated to a controller-be it autonomous or human-on the ground, preferably within or proximal to the command and control unit."
Method and system for autonomously operating an aircraft,https://lens.org/023-787-244-840-900,2021,"A method and system for autonomously operating an aircraft. The method comprises a pre-flight training step comprising: retrieving recorded surveillance data of a plurality of flights corresponding to at least one aircraft type and at least one route; inferring aircraft intent from the recorded surveillance data; computing reconstructed trajectories using the inferred aircraft intent; selecting a training dataset comprising aircraft intent and reconstructed trajectories of flights corresponding to a particular aircraft type and route; and applying a machine learning algorithm on the training dataset to obtain a mapping function between aircraft states and actions. The method further comprises a real-time control step executed during a flight of an aircraft, the real-time control step comprising: repeatedly retrieving onboard sensor data; obtaining real-time aircraft states from the onboard sensor data; determining actions associated to the real-time aircraft states using the mapping function; and executing the selected actions on the aircraft."
METHOD AND SYSTEM FOR AUTONOMOUSLY OPERATING AN AIRCRAFT,https://lens.org/113-741-211-700-927,2019,"A method and system for autonomously operating an aircraft. The method comprises a pre-flight training step comprising: retrieving recorded surveillance data of a plurality of flights corresponding to at least one aircraft type and at least one route; inferring aircraft intent from the recorded surveillance data; computing reconstructed trajectories using the inferred aircraft intent; selecting a training dataset comprising aircraft intent and reconstructed trajectories of flights corresponding to a particular aircraft type and route; and applying a machine learning algorithm on the training dataset to obtain a mapping function between aircraft states and actions. The method further comprises a real-time control step executed during a flight of an aircraft, the real-time control step comprising: repeatedly retrieving onboard sensor data; obtaining real-time aircraft states from the onboard sensor data; determining actions associated to the real-time aircraft states using the mapping function; and executing the selected actions on the aircraft."
SYSTEMS AND METHODS OF UNMANNED AERIAL VEHICLE FLIGHT RESTRICTION FOR STATIONARY AND MOVING OBJECTS,https://lens.org/101-893-964-335-909,2018,"In an aspect, a method for controlling flight of an unmanned aerial vehicle (UAV) comprises: obtaining information about a location of an object of interest; calculating, during operation of the UAV, a flight-restricted distance for the UAV to maintain relative to the object of interest, wherein the flight-restricted distance is calculated based on a safety factor, wherein the safety factor is determined based on an object classification; and controlling flight of the UAV to maintain the flight-restricted distance relative to the object of interest."
METHOD FOR GUIDING AND CONTROLLING DRONE USING INFORMATION FOR CONTROLLING CAMERA OF DRONE,https://lens.org/090-929-276-246-245,2018,"The present invention relates to a method of guiding and controlling an unmanned aerial system based on camera control information of the unmanned aerial system, the method comprising the steps of: (a) controlling a vertical axis of the unmanned aerial system by controlling a zoom of a gimbal camera 330 by a zoom controller 120 of a camera control unit 100 so as to control an elevation and speed of the unmanned aerial system 300 with a corresponding camera control signal; and (b) controlling a horizontal axis of the unmanned aerial system by controlling an angle of the gimbal camera 330 by an angle controller 110 of the camera control unit 100. Accordingly, the present invention is applicable by just modifying software without changing a general system of an unmanned aerial system, has an advantage that a camera controller is enough to control a mission flight of the unmanned aerial system, and is improved in convenience and tracking performance since the speed, elevation, flight path, etc. of the unmanned aerial system are automatically controlled when a camera is used to continuously track a specific target."
Method for guiding and controlling drone using information for controlling camera of drone,https://lens.org/049-663-694-080-768,2017,"The present invention relates to a method of guiding and controlling an unmanned aerial system based on camera control information of the unmanned aerial system, the method comprising the steps of: (a) controlling a vertical axis of the unmanned aerial system by controlling a zoom of a gimbal camera 330 by a zoom controller 120 of a camera control unit 100 so as to control an elevation and speed of the unmanned aerial system 300 with a corresponding camera control signal; and (b) controlling a horizontal axis of the unmanned aerial system by controlling an angle of the gimbal camera 330 by an angle controller 110 of the camera control unit 100. Accordingly, the present invention is applicable by just modifying software without changing a general system of an unmanned aerial system, has an advantage that a camera controller is enough to control a mission flight of the unmanned aerial system, and is improved in convenience and tracking performance since the speed, elevation, flight path, etc. of the unmanned aerial system are automatically controlled when a camera is used to continuously track a specific target."
Method for guiding and controlling drone using information for controlling camera of drone,https://lens.org/126-986-411-508-208,2021,"The present invention relates to a method of guiding and controlling an unmanned aerial system based on camera control information of the unmanned aerial system, the method comprising the steps of: (a) controlling a vertical axis of the unmanned aerial system by controlling a zoom of a gimbal camera 330 by a zoom controller 120 of a camera control unit 100 so as to control an elevation and speed of the unmanned aerial system 300 with a corresponding camera control signal; and (b) controlling a horizontal axis of the unmanned aerial system by controlling an angle of the gimbal camera 330 by an angle controller 110 of the camera control unit 100. Accordingly, the present invention is applicable by just modifying software without changing a general system of an unmanned aerial system, has an advantage that a camera controller is enough to control a mission flight of the unmanned aerial system, and is improved in convenience and tracking performance since the speed, elevation, flight path, etc. of the unmanned aerial system are automatically controlled when a camera is used to continuously track a specific target."
Method for guiding and controlling drone using information for controlling camera of drone,https://lens.org/029-536-474-844-810,2020,"The present invention relates to a method of guiding and controlling an unmanned aerial system based on camera control information of the unmanned aerial system, the method comprising the steps of: (a) controlling a vertical axis of the unmanned aerial system by controlling a zoom of a gimbal camera 330 by a zoom controller 120 of a camera control unit 100 so as to control an elevation and speed of the unmanned aerial system 300 with a corresponding camera control signal; and (b) controlling a horizontal axis of the unmanned aerial system by controlling an angle of the gimbal camera 330 by an angle controller 110 of the camera control unit 100. Accordingly, the present invention is applicable by just modifying software without changing a general system of an unmanned aerial system, has an advantage that a camera controller is enough to control a mission flight of the unmanned aerial system, and is improved in convenience and tracking performance since the speed, elevation, flight path, etc. of the unmanned aerial system are automatically controlled when a camera is used to continuously track a specific target."
Method for guiding and controlling drone using information for controlling camera of drone,https://lens.org/029-536-474-844-810,2020,"The present invention relates to a method of guiding and controlling an unmanned aerial system based on camera control information of the unmanned aerial system, the method comprising the steps of: (a) controlling a vertical axis of the unmanned aerial system by controlling a zoom of a gimbal camera 330 by a zoom controller 120 of a camera control unit 100 so as to control an elevation and speed of the unmanned aerial system 300 with a corresponding camera control signal; and (b) controlling a horizontal axis of the unmanned aerial system by controlling an angle of the gimbal camera 330 by an angle controller 110 of the camera control unit 100. Accordingly, the present invention is applicable by just modifying software without changing a general system of an unmanned aerial system, has an advantage that a camera controller is enough to control a mission flight of the unmanned aerial system, and is improved in convenience and tracking performance since the speed, elevation, flight path, etc. of the unmanned aerial system are automatically controlled when a camera is used to continuously track a specific target."
Drone Remaining Undetectable from Current Target Location During Surveillance,https://lens.org/195-684-359-510-616,2019,An approach is provided that identifies a current position of a drone. The approach further detects a current target location and determines a surveillance position with the surveillance position being predicted to be undetectable from the current target location. The approach then instructs the drone to move from the current position to the surveillance position.
Drone remaining undetectable from current target location during surveillance,https://lens.org/153-839-682-182-878,2020,An approach is provided that identifies a current position of a drone. The approach further detects a current target location and determines a surveillance position with the surveillance position being predicted to be undetectable from the current target location. The approach then instructs the drone to move from the current position to the surveillance position.
ROBOT ARM AND UNMANNED AERIAL VEHICLE EQUIPPED WITH THE ROBOT ARM,https://lens.org/099-003-296-864-700,2019,"A robot arm that can be suitably used in aerial vehicles and an unmanned aerial vehicle equipped with the robot arm. The robot arm includes: an arm unit includes a plurality of joints; arm controlling means for controlling driving of the joints; and a displacement detector configured to detect a change of a position and inclination of the arm unit. The arm unit has a base end connected to the aerial vehicle. At least a leading end of the arm unit is exposed to an outside of the aerial vehicle. When the displacement detector has detected a position error that is an unexpected change of the position or inclination of the arm unit, the arm unit controlling means is configured to cause the joints to absorb the position error so as to prevent the position error from being transmitted to a side of the leading end of the arm unit."
Robot arm and unmanned aerial vehicle equipped with the robot arm,https://lens.org/020-965-474-540-401,2019,"A robot arm that can be suitably used in aerial vehicles and an unmanned aerial vehicle equipped with the robot arm. The robot arm includes: an arm unit includes a plurality of joints; arm controlling means for controlling driving of the joints; and a displacement detector configured to detect a change of a position and inclination of the arm unit. The arm unit has a base end connected to the aerial vehicle. At least a leading end of the arm unit is exposed to an outside of the aerial vehicle. When the displacement detector has detected a position error that is an unexpected change of the position or inclination of the arm unit, the arm unit controlling means is configured to cause the joints to absorb the position error so as to prevent the position error from being transmitted to a side of the leading end of the arm unit."
MOBILE TELE-PRESENCE SYSTEM WITH A MICROPHONE SYSTEM,https://lens.org/185-359-095-572-597,2009,"A remote controlled robot system that includes a robot and a remote control station. The robot includes a binaural microphone system that is coupled to a speaker system of the remote control station. The binaural microphone system may include a pair of microphones located at opposite sides of a robot head, the location of the microphones roughly coincides with the location of ears on a human body. Such microphone location creates a mobile robot that more effectively simulates the tele-presence of an operator of the system. The robot may include two different microphone systems and the ability to switch between systems. For example, the robot may also include a zoom camera system and a directional microphone. The directional microphone may be utilized to capture sound from a direction that corresponds to an object zoomed upon by the camera system."
User interface device of remote control system for robot device and method using the same,https://lens.org/036-538-506-550-140,2017,"A user interface device of a remote control system for a robot and a method using the same are provided. The user interface device includes: a radio frequency (RF) unit for receiving, from a remote control robot, camera data and at least one sensor data detecting a distance; a display unit having a main screen and at least one auxiliary screen; and a controller having an environment evaluation module for determining whether the received camera data are in a normal condition, and having a screen display mode change module for displaying, if the received camera data are in a normal condition, the camera data on the main screen and displaying, if the received camera data are in an abnormal condition, the sensor data on the main screen."
USER INTERFACE DEVICE OF REMOTE CONTROL SYSTEM FOR ROBOT DEVICE AND METHOD USING THE SAME,https://lens.org/198-933-820-193-73X,2009,"A user interface device of a remote control system for a robot and a method using the same are provided. The user interface device includes: a radio frequency (RF) unit for receiving, from a remote control robot, camera data and at least one sensor data detecting a distance; a display unit having a main screen and at least one auxiliary screen; and a controller having an environment evaluation module for determining whether the received camera data are in a normal condition, and having a screen display mode change module for displaying, if the received camera data are in a normal condition, the camera data on the main screen and displaying, if the received camera data are in an abnormal condition, the sensor data on the main screen."
USER INTERFACE DEVICE OF REMOTE CONTROL SYSTEM FOR ROBOT DEVICE AND METHOD USING THE SAME,https://lens.org/198-368-351-630-52X,2015,"A user interface device of a remote control system for a robot and a method using the same are provided. The user interface device includes: a radio frequency (RF) unit for receiving, from a remote control robot, camera data and at least one sensor data detecting a distance; a display unit having a main screen and at least one auxiliary screen; and a controller having an environment evaluation module for determining whether the received camera data are in a normal condition, and having a screen display mode change module for displaying, if the received camera data are in a normal condition, the camera data on the main screen and displaying, if the received camera data are in an abnormal condition, the sensor data on the main screen."
User interface device of remote control system for robot device and method using the same,https://lens.org/054-415-200-460-372,2015,"A user interface device of a remote control system for a robot and a method using the same are provided. The user interface device includes: a radio frequency (RF) unit for receiving, from a remote control robot, camera data and at least one sensor data detecting a distance; a display unit having a main screen and at least one auxiliary screen; and a controller having an environment evaluation module for determining whether the received camera data are in a normal condition, and having a screen display mode change module for displaying, if the received camera data are in a normal condition, the camera data on the main screen and displaying, if the received camera data are in an abnormal condition, the sensor data on the main screen."
AN OPERATION-AWARE AERIAL NAVIGATION SYSTEM,https://lens.org/104-151-250-615-470,2018,"The present invention refers to an operation-aware aerial navigation system comprising as modules at least one navigation server (100), one navigation agent (130) and one navigation client (120), each module consisting of several sub-modules, wherein the navigation server (100) is configured to aggregate and correlate multiple data received from different data sources (150) and from a navigation client (120), and to dynamically provide to a drone operator a geo-zoned map based on the aggregated and correlated data; the navigation agent (130) is running on a drone and configured to master steering of the drone; the navigation client (120) is running locally by the drone operator and acting as interface between the drone operator, the navigation server (100) and the navigation agent (130) running on the drone and configured to compute and update a route for the drone that is involved in the operation, based on the geo-zoned map, feedback from the navigation agent (130) and an initial input of the drone operator. Further, the present invention provides a respective method to fly at least one drone beyond visual line of sight by using the claimed system."
REMOTE-CONTROLLED AUDIO RESPONSE SYSTEM AND REMOTE-CONTROLLED AUDIO RESPONSE DEVICE,https://lens.org/075-859-199-374-07X,2001,"A transmitter (14) transmits a remote control signal corresponding to a command from the input (11) of a remote control device (1). A receiver (21) of an indoor unit (2) receives the remote control signal from the transmitter (14) of the remote control device (1), and a controller (22) controls the indoor unit (2) according to the received remote control signal. A remote controller (12) selects the setting to be produced by a voice output (24) of the indoor unit (2). A voice generator (23) of the indoor unit (2) generates speech corresponding to the selected setting and outputs it through the voice output (24). Such a remote-controlled audio system allows a remote setting to be confirmed easily by voice."
An unmanned aerial vehicle for short distance delivery,https://lens.org/021-696-533-319-496,2020,"The invention provides a civilian unmanned aerial vehicle for short-range transportation of goods. The UAV mainly includes the following equipment: processor, laser sensor, ultrasonic sensor, camera, mechanical claw, network module, touch screen, etc. The UVA has a GPS module and processor(2) inside. The UVA has propellers(1) at each end. The lower end of the UAV is equipped with a mechanical clamp(5) and four supporting legs(6). A ""detected ball""(3) is mounted on one side of the UAV. The upper end of the UAV is equipped with a touch screen(4). After receiving the instruction to transport the goods, the UAV will take off and fly to the side of the goods to scan the qr code on the packaging of the goods and obtain the detailed information of the goods and orders. Figure 1"
DRONE LANDING SYSTEM AND METHOD,https://lens.org/068-749-485-540-525,2020,"A drone landing method and system are provided. The method includes illuminator configured to determining a position and a speed of a vehicle based on vehicle information received via wireless communication, synchronizing the speed of the drone to the speed of the vehicle and maneuvering a drone to a position above a landing point on the vehicle based on the vehicle information, and landing the drone at the landing point of the vehicle."
"CONTROL DEVICE, SYSTEM, PROGRAM, CONTROL INSTRUMENT, FLYING OBJECT, SENSOR, AND METHOD OF OPERATING SYSTEM",https://lens.org/015-654-458-372-621,2022,"A control device includes: a communication unit; and a control unit that transmits and receives information via the communication unit. When a flying object flies around a complex housing, the control unit transmits, to the flying object, information on a flight route in which a transported object of the flying object enters a blind spot from inside of the complex housing based on information on the complex housing."
ARMED UNMANNED AERIAL VEHICLE AND METHODS OF USE THEREOF,https://lens.org/071-514-879-714-032,2022,"The present invention relates to an armed unmanned aerial vehicle (UAV), an armed UAV control system, and methods of use thereof. In one form, the armed UAV includes: an elongate body, a pair opposed side rotor arm assemblies extending from the sides of the body, a tail rotor arm assembly extending from a rear end of the body, a weapons system including at least one firearm associated with the body, and a flight and targeting controller operatively associated with the side rotor arm assemblies and the tail rotor arm assembly. The controller configured to: determine at least a pitch angle and yaw angle required to strike a target with the weapons system, based on target information received; and selectively control operation of each rotor arm assembly for aiming the weapons system, based on at least the pitch angle and the yaw angle determined."
ARMED UNMANNED AERIAL VEHICLE AND METHODS OF USE THEREOF,https://lens.org/071-514-879-714-032,2022,"The present invention relates to an armed unmanned aerial vehicle (UAV), an armed UAV control system, and methods of use thereof. In one form, the armed UAV includes: an elongate body, a pair opposed side rotor arm assemblies extending from the sides of the body, a tail rotor arm assembly extending from a rear end of the body, a weapons system including at least one firearm associated with the body, and a flight and targeting controller operatively associated with the side rotor arm assemblies and the tail rotor arm assembly. The controller configured to: determine at least a pitch angle and yaw angle required to strike a target with the weapons system, based on target information received; and selectively control operation of each rotor arm assembly for aiming the weapons system, based on at least the pitch angle and the yaw angle determined."
Unmanned autonomous submarine,https://lens.org/076-419-059-296-396,2007,"An unmanned autonomous submarine which can float, dive and move in water to perform various tasks. The submarine includes a pressurized cabin which is necessary for the diving and flotation system to work properly. This also helps to increase its sealing power against water leakage into the cabin. The submarine is autonomous, that is automatic and self controlled. It is propelled by water jet propulsion. It can be programmed to dive to preset depths, move along preset trajectories, and return to the base after completing the assigned tasks. A remote control option is provided in order to perform special tasks. The submarine is equipped with several sensors that can measure depth, orientation, attitude, location and speed. It is also equipped with an underwater video camera that can send wireless video pictures from underwater to a monitor above water surface."
Unmanned autonomous submarine,https://lens.org/083-431-329-337-692,2007,"An unmanned autonomous submarine which can float, dive and move in water to perform various tasks. The submarine includes a pressurized cabin which is necessary for the diving and flotation system to work properly. This also helps to increase its sealing power against water leakage into the cabin. The submarine is autonomous, that is automatic and self controlled. It is propelled by water jet propulsion. It can be programmed to dive to preset depths, move along preset trajectories, and return to the base after completing the assigned tasks. A remote control option is provided in order to perform special tasks. The submarine is equipped with several sensors that can measure depth, orientation, attitude, location and speed. It is also equipped with an underwater video camera that can send wireless video pictures from underwater to a monitor above water surface."
Wirelessly controlling unmanned aircraft and accessing associated surveillance data,https://lens.org/046-632-000-780-460,2016,"Controlling an unmanned aerial vehicle (UAV) may be accomplished by using a wireless device (e.g., cell phone) to send a control message to a receiver at the UAV via a wireless telecommunication network (e.g., an existing cellular network configured primarily for mobile telephone communication). In addition, the wireless device may be used to receive communications from a transmitter at the UAV, wherein the wireless device receives the communications from the transmitter via the wireless network. Examples of such communications include surveillance information and UAV monitoring information."
WIRELESSLY CONTROLLING UNMANNED AIRCRAFT AND ACCESSING ASSOCIATED SURVEILLANCE DATA,https://lens.org/032-112-789-847-281,2008,"Controlling an unmanned aerial vehicle (UAV) may be accomplished by using a wireless device (e.g., cell phone) to send a control message to a receiver at the UAV via a wireless telecommunication network (e.g., an existing cellular network configured primarily for mobile telephone communication). In addition, the wireless device may be used to receive communications from a transmitter at the UAV, wherein the wireless device receives the communications from the transmitter via the wireless network. Examples of such communications include surveillance information and UAV monitoring information."
Wirelessly controlling unmanned aircraft and accessing associated surveillance data,https://lens.org/046-342-797-419-318,2009,"Controlling an unmanned aerial vehicle (UAV) may be accomplished by using a wireless device (e.g., cell phone) to send a control message to a receiver at the UAV via a wireless telecommunication network (e.g., an existing cellular network configured primarily for mobile telephone communication). In addition, the wireless device may be used to receive communications from a transmitter at the UAV, wherein the wireless device receives the communications from the transmitter via the wireless network. Examples of such communications include surveillance information and UAV monitoring information."
WIRELESSLY CONTROLLING UNMANNED AIRCRAFT AND ACCESSING ASSOCIATED SURVEILLANCE DATA,https://lens.org/128-191-094-944-084,2010,"Controlling an unmanned aerial vehicle (UAV) may be accomplished by using a wireless device (e.g., cell phone) to send a control message to a receiver at the UAV via a wireless telecommunication network (e.g., an existing cellular network configured primarily for mobile telephone communication). In addition, the wireless device may be used to receive communications from a transmitter at the UAV, wherein the wireless device receives the communications from the transmitter via the wireless network. Examples of such communications include surveillance information and UAV monitoring information."
Wirelessly controlling unmanned aircraft and accessing associated surveillance data,https://lens.org/051-988-783-159-440,2007,"Controlling an unmanned aerial vehicle (UAV) may be accomplished by using a wireless device (e.g., cell phone) to send a control message to a receiver at the UAV via a wireless telecommunication network (e.g., an existing cellular network configured primarily for mobile telephone communication). In addition, the wireless device may be used to receive communications from a transmitter at the UAV, wherein the wireless device receives the communications from the transmitter via the wireless network. Examples of such communications include surveillance information and UAV monitoring information."
Wirelessly controlling unmanned aircraft and accessing associated surveillance data,https://lens.org/190-847-323-746-813,2013,"Controlling an unmanned aerial vehicle (UAV) may be accomplished by using a wireless device (e.g., cell phone) to send a control message to a receiver at the UAV via a wireless telecommunication network (e.g., an existing cellular network configured primarily for mobile telephone communication). In addition, the wireless device may be used to receive communications from a transmitter at the UAV, wherein the wireless device receives the communications from the transmitter via the wireless network. Examples of such communications include surveillance information and UAV monitoring information."
Control system for remote controlled aircraft,https://lens.org/055-904-328-680-394,1991,"The invention relates to a control system for a remote controlled aircraft. This system comprises on one hand, an substructure on the ground provided with computing means, data acquisition means and radio transmission means, and on the other hand, an on-board apparatus provided with analogous means and sensors for the parameters of the behavior of the aircraft. The substructure on the ground and the on-board apparatus are adapted to exchange data in order to assure the stabilization and the piloting of the aircraft, and the provide specific orders as a function of the application."
"Automated escort drone device, system and method",https://lens.org/140-817-847-059-386,2021,"Embodiments of an escort drone device, system and method provide one or more autonomous or semi-autonomous escort drones capable of being summoned by an individual to a first location, wherein the escort drone(s) includes a payload with threat deterring components and wherein the threat deterring components can be engaged by a remote operator at a different location from the first location. In embodiments, the system can employ intelligent mesh networking to allocate one or more escort drones to one or more specific locations."
MULTIMODE UNMANNED AERIAL VEHICLE,https://lens.org/154-495-001-916-240,2017,"A system comprising an unmanned aerial vehicle (UAV) (100) configured to transition (520) from a terminal homing mode (510) to a target search mode (530), responsive to an uplink signal (451) and/or an au-tonomous determination of scene change."
Unmanned aerial vehicle and flying method thereof,https://lens.org/173-845-750-575-152,2017,"An Unmanned Aerial Vehicle (UAV) includes a fuselage, a plurality of rotors, and a sensor, wherein the fuselage includes a control module and a signal processing module, and the control module is connected the arms, which is used to control the rotation of arms. The sensor is configured to the fuselage of the UAV, which is used to detect the rotation change value of the UAV. The signal processing module is connected with the sensor and the control module, which is used to receive and analyze the signal of the sensor, and the control module controls the following flying of the UAV."
UNMANNED AERIAL VEHICLE AND FLYING METHOD THEREOF,https://lens.org/170-234-559-361-816,2017,"An Unmanned Aerial Vehicle (UAV) includes a fuselage, a plurality of rotors, and a sensor, wherein the fuselage includes a control module and a signal processing module, and the control module is connected the arms, which is used to control the rotation of arms. The sensor is configured to the fuselage of the UAV, which is used to detect the rotation change value of the UAV. The signal processing module is connected with the sensor and the control module, which is used to receive and analyze the signal of the sensor, and the control module controls the following flying of the UAV."
Driving Test System for a Moving Object,https://lens.org/188-865-222-256-097,2016,"and a controller configured to control the flight of the unmanned aircraft to follow the moving object and to transmit to the vision sensor and to receive from the vision censor, detected motion characteristics of the moving object."
Remote Controlled Lock Box Assembly,https://lens.org/153-576-126-492-283,2021,A remote controlled lock box assembly includes a box that is positionable adjacent to a parcel delivery location for receiving a parcel. A lid is hingedly coupled to the box for opening and closing the box. A locking unit is coupled to the lid and the locking unit is actuatable into a locking condition and an unlocked condition. The locking unit is in wireless communication with a remote control such that the remote control actuates the locking unit between the locked condition and the unlocked condition. A video camera is coupled to the box to capture video footage of the parcel delivery location. The video camera is in remote communication with the remote control thereby facilitating the remote control to receive the video footage captured by the video camera.
Deploying cell on drone or droneap to mitigate radio capacity and coverage issues,https://lens.org/027-859-755-284-77X,2017,"Embodiments herein describe a system that includes an autonomous vehicle (referred to herein as a drone) which is controlled by a self-organizing network (SON) to expand the capabilities of a cellular network in real time. In one embodiment, the SON monitors the cellular network and identifies congestion or capacity issues where the cell towers covering the geographic region may be unable to satisfy the large number of requests for data by the users in the region. Once a congestion or capacity issue is detected, the SON determines whether dispatching a drone access point (AP) may improve or resolve the issue. In one example, the drone AP is an autonomous vehicle that includes a radio that permits the drone to serve as a mobile cell site for the cellular network."
Unmanned vehicle control and operation in a marine environment,https://lens.org/000-646-525-780-031,2023,"Many different types of systems are utilized or tasks are performed in a marine environment. The present invention provides various configurations of unmanned vehicles, or drones, that can be operated and/or controlled for such systems or tasks. One or more unmanned vehicles can be integrated with a dedicated marine electronic device of a marine vessel for autonomous control and operation. Additionally or alternatively, the unmanned vehicle can be manually remote operated during use in the marine environment. Such unmanned vehicles can be utilized in many different marine environment systems or tasks, including, for example, navigation, sonar, radar, search and rescue, video streaming, alert functionality, among many others. However, as contemplated by the present invention, the marine environment provides many unique challenges that may be accounted for with operation and control of an unmanned vehicle."
Unmanned Vehicle Control and Operation in a Marine Environment,https://lens.org/005-373-097-161-007,2018,"Many different types of systems are utilized or tasks are performed in a marine environment. The present invention provides various configurations of unmanned vehicles, or drones, that can be operated and/or controlled for such systems or tasks. One or more unmanned vehicles can be integrated with a dedicated marine electronic device of a marine vessel for autonomous control and operation. Additionally or alternatively, the unmanned vehicle can be manually remote operated during use in the marine environment. Such unmanned vehicles can be utilized in many different marine environment systems or tasks, including, for example, navigation, sonar, radar, search and rescue, video streaming, alert functionality, among many others. However, as contemplated by the present invention, the marine environment provides many unique challenges that may be accounted for with operation and control of an unmanned vehicle."
Unmanned vehicle control and sonar operation in a marine environment,https://lens.org/162-369-794-062-187,2022,"Many different types of systems are utilized or tasks are performed in a marine environment. The present invention provides various configurations of unmanned vehicles, or drones, that can be operated and/or controlled for such systems or tasks. One or more unmanned vehicles can be integrated with a dedicated marine electronic device of a marine vessel for autonomous control and operation. Additionally or alternatively, the unmanned vehicle can be manually remote operated during use in the marine environment. Such unmanned vehicles can be utilized in many different marine environment systems or tasks, including, for example, navigation, sonar, radar, search and rescue, video streaming, alert functionality, among many others. However, as contemplated by the present invention, the marine environment provides many unique challenges that may be accounted for with operation and control of an unmanned vehicle."
UNMANNED VEHICLE CONTROL AND OPERATION IN A MARINE ENVIRONMENT,https://lens.org/033-504-726-812-275,2020,"Many different types of systems are utilized or tasks are performed in a marine environment. The present invention provides various configurations of unmanned vehicles, or drones, that can be operated and/or controlled for such systems or tasks. One or more unmanned vehicles can be integrated with a dedicated marine electronic device of a marine vessel for autonomous control and operation. Additionally or alternatively, the unmanned vehicle can be manually remote operated during use in the marine environment. Such unmanned vehicles can be utilized in many different marine environment systems or tasks, including, for example, navigation, sonar, radar, search and rescue, video streaming, alert functionality, among many others. However, as contemplated by the present invention, the marine environment provides many unique challenges that may be accounted for with operation and control of an unmanned vehicle."
UNMANNED VEHICLE CONTROL AND SONAR OPERATION IN A MARINE ENVIRONMENT,https://lens.org/064-039-621-548-854,2019,"Many different types of systems are utilized or tasks are performed in a marine environment. The present invention provides various configurations of unmanned vehicles, or drones, that can be operated and/or controlled for such systems or tasks. One or more unmanned vehicles can be integrated with a dedicated marine electronic device of a marine vessel for autonomous control and operation. Additionally or alternatively, the unmanned vehicle can be manually remote operated during use in the marine environment. Such unmanned vehicles can be utilized in many different marine environment systems or tasks, including, for example, navigation, sonar, radar, search and rescue, video streaming, alert functionality, among many others. However, as contemplated by the present invention, the marine environment provides many unique challenges that may be accounted for with operation and control of an unmanned vehicle."
Unmanned vehicle control and operation in a marine environment,https://lens.org/095-720-632-740-173,2022,"Many different types of systems are utilized or tasks are performed in a marine environment. The present invention provides various configurations of unmanned vehicles, or drones, that can be operated and/or controlled for such systems or tasks. One or more unmanned vehicles can be integrated with a dedicated marine electronic device of a marine vessel for autonomous control and operation. Additionally or alternatively, the unmanned vehicle can be manually remote operated during use in the marine environment. Such unmanned vehicles can be utilized in many different marine environment systems or tasks, including, for example, navigation, sonar, radar, search and rescue, video streaming, alert functionality, among many others. However, as contemplated by the present invention, the marine environment provides many unique challenges that may be accounted for with operation and control of an unmanned vehicle."
UNMANNED VEHICLE CONTROL AND OPERATION IN A MARINE ENVIRONMENT,https://lens.org/000-168-375-573-825,2023,"Many different types of systems are utilized or tasks are performed in a marine environment. The present invention provides various configurations of unmanned vehicles, or drones, that can be operated and/or controlled for such systems or tasks. One or more unmanned vehicles can be integrated with a dedicated marine electronic device of a marine vessel for autonomous control and operation. Additionally or alternatively, the unmanned vehicle can be manually remote operated during use in the marine environment. Such unmanned vehicles can be utilized in many different marine environment systems or tasks, including, for example, navigation, sonar, radar, search and rescue, video streaming, alert functionality, among many others. However, as contemplated by the present invention, the marine environment provides many unique challenges that may be accounted for with operation and control of an unmanned vehicle."
UNMANNED VEHICLE CONTROL AND OPERATION IN A MARINE ENVIRONMENT,https://lens.org/154-377-375-584-482,2018,"Many different types of systems are utilized or tasks are performed in a marine environment. The present invention provides various configurations of unmanned vehicles, or drones, that can be operated and/or controlled for such systems or tasks. One or more unmanned vehicles can be integrated with a dedicated marine electronic device of a marine vessel for autonomous control and operation. Additionally or alternatively, the unmanned vehicle can be manually remote operated during use in the marine environment. Such unmanned vehicles can be utilized in many different marine environment systems or tasks, including, for example, navigation, sonar, radar, search and rescue, video streaming, alert functionality, among many others. However, as contemplated by the present invention, the marine environment provides many unique challenges that may be accounted for with operation and control of an unmanned vehicle."
Unmanned vehicle control and operation in a marine environment,https://lens.org/125-025-466-637-366,2020,"Many different types of systems are utilized or tasks are performed in a marine environment. The present invention provides various configurations of unmanned vehicles, or drones, that can be operated and/or controlled for such systems or tasks. One or more unmanned vehicles can be integrated with a dedicated marine electronic device of a marine vessel for autonomous control and operation. Additionally or alternatively, the unmanned vehicle can be manually remote operated during use in the marine environment. Such unmanned vehicles can be utilized in many different marine environment systems or tasks, including, for example, navigation, sonar, radar, search and rescue, video streaming, alert functionality, among many others. However, as contemplated by the present invention, the marine environment provides many unique challenges that may be accounted for with operation and control of an unmanned vehicle."
Unmanned vehicle control and operation in a marine environment,https://lens.org/127-220-430-295-479,2018,"Many different types of systems are utilized or tasks are performed in a marine environment. The present invention provides various configurations of unmanned vehicles, or drones, that can be operated and/or controlled for such systems or tasks. One or more unmanned vehicles can be integrated with a dedicated marine electronic device of a marine vessel for autonomous control and operation. Additionally or alternatively, the unmanned vehicle can be manually remote operated during use in the marine environment. Such unmanned vehicles can be utilized in many different marine environment systems or tasks, including, for example, navigation, sonar, radar, search and rescue, video streaming, alert functionality, among many others. However, as contemplated by the present invention, the marine environment provides many unique challenges that may be accounted for with operation and control of an unmanned vehicle."
AIRBORNE DRONES WITH NON-PHYSICAL DISTRACTORS,https://lens.org/036-570-228-775-509,2021,"Embodiments of the invention include a drone system or method for distracting a threat with a light source. In some embodiments, an environment can be scanned with a sensor that produces sensor data. A threat within the environment can be identified from the sensor data, and the location of the threat can be determined. The light source can be aimed toward the threat; and light may be directed from the light source toward the threat."
"DRONE SYSTEM, DRONE, PLAN MANAGEMENT APPARATUS, PLAN MANAGEMENT METHOD FOR DRONE SYSTEM, AND PLAN MANAGEMENT PROGRAM FOR DRONE SYSTEM",https://lens.org/177-116-322-819-718,2022,"In a drone system in which a drone and a movable body operate in coordination with each other, the drone performing a predetermined operation in an agricultural field, the movable body being capable of moving with the drone aboard and allowing the drone to make a takeoff and a landing, the plan determining section determines a flight plan for the drone and a movement plan for the movable body in accordance with the flight plan, and the instructing section instructs the drone to execute an operation in accordance with the flight plan and instructs the movable body to move or to be on standby in accordance with the movement plan."
Objective-based control of an autonomous unmanned aerial vehicle,https://lens.org/054-651-138-364-500,2023,"Techniques are described for controlling an autonomous vehicle such as an unmanned aerial vehicle (UAV) using objective-based inputs. In an embodiment, the underlying functionality of an autonomous navigation system is exposed via an application programming interface (API) allowing the UAV to be controlled through specifying a behavioral objective, for example, using a call to the API to set parameters for the behavioral objective. The autonomous navigation system can then incorporate perception inputs such as sensor data from sensors mounted to the UAV and the set parameters using a multi-objective motion planning process to generate a proposed trajectory that most closely satisfies the behavioral objective in view of certain constraints. In some embodiments, developers can utilize the API to build customized applications for the UAV. Such applications, also referred to as skills, can be developed, shared, and executed to control behavior of an autonomous UAV and aid in overall system improvement."
UNMANNED AERIAL VEHICLE FLIGHT MANAGEMENT,https://lens.org/178-885-753-805-564,2019,"A device can be configured to receive a flight request including at least one flight characteristic for an unmanned aerial vehicle (UAV) flight; identify flight characteristics associated with the flight request; identify a flight guideline associated with the flight request, the flight guideline specifying a limitation for an identified flight characteristic; determine, based on the flight guideline, that one of the identified flight characteristics is a questionable flight characteristic; and/or perform an action based on the questionable flight characteristic."
Method for controlling small-size unmanned aerial vehicle,https://lens.org/038-580-926-808-576,2019,"Provided is a small unmanned aircraft control method that makes it possible to set a flight path in accordance with present ground conditions and fly a small unmanned aircraft. A method for controlling the flight of a small unmanned aircraft that has: a plurality of rotor blades; and a photography unit that can capture images of what is below. The method involves the execution of: an information acquisition step wherein the small unmanned aircraft is raised above the ground, ground conditions are photographed by the photography unit, and a photographic image I is obtained; a path-setting step wherein a flight path R for flying the small unmanned aircraft is set on the photographic image I; and a flying step for flying the small unmanned aircraft along the flight path R."
Small unmanned aircraft control method,https://lens.org/129-717-985-309-068,2018,"Provided is a small unmanned aircraft control method that makes it possible to set a flight path in accordance with present ground conditions and fly a small unmanned aircraft. A method for controlling the flight of a small unmanned aircraft that has: a plurality of rotor blades; and a photography unit that can capture images of what is below. The method involves the execution of: an information acquisition step wherein the small unmanned aircraft is raised above the ground, ground conditions are photographed by the photography unit, and a photographic image I is obtained; a path-setting step wherein a flight path R for flying the small unmanned aircraft is set on the photographic image I; and a flying step for flying the small unmanned aircraft along the flight path R."
"Remote control device for a target designator from an attack module, attack module and designator implementing such device",https://lens.org/013-826-419-633-564,2011,"The invention relates to a remote control device from an attack module flying over a target, module of the projectile or sub-projectile, missile or attack drone type, for a target designator positioned on a terrain of operations, comprising means to emit a remote control signal that are arranged in the attack module and at least one receiver means for the remote control signal that are integral with the designator and are associated with means to activate the start-up of the designator, wherein the emitter means incorporate at least one light source oriented so as to illuminate the terrain and in that the receiver means incorporate a detector for the radiation emitted by the light source or sources."
"Remote control device for a target designator from an attack module, attack module and designator implementing such device",https://lens.org/171-903-394-403-943,2009,"The invention relates to a remote control device from an attack module flying over a target, module of the projectile or sub-projectile, missile or attack drone type, for a target designator positioned on a terrain of operations, comprising means to emit a remote control signal that are arranged in the attack module and at least one receiver means for the remote control signal that are integral with the designator and are associated with means to activate the start-up of the designator, wherein the emitter means incorporate at least one light source oriented so as to illuminate the terrain and in that the receiver means incorporate a detector for the radiation emitted by the light source or sources."
"UNMANNED AERIAL VEHICLE SYSTEM PROVIDING SECURE COMMUNICATION, DATA TRANSFER, AND TRACKING",https://lens.org/143-476-083-427-113,2020,"A system provides secure communication, data generation and data transfer, and tracking between a drone and a plurality of interactive entities. One entity comprises a base station including a transmitter and a receiver tuned to communicate with a drone having an RFID tag. The drone tag stores information on flight plan parameters and reports condition-responsive information. From a multitude of data fields, unique data sets are created in correspondence with requirements of stakeholders. Drone tags including encryption, communication, and processing circuitry which are operated to interact with individual drone operators communicates with specific drones, subscribers, and with outside agencies on behalf of subscribers. Data at rest may be encrypted or decrypted. RFID tags for inclusion in drone electronics include microprocessors capable of encryption and decryption. interacts with internal components, such as sensors and databases."
Chemical and biological warfare agent decontamination drone,https://lens.org/044-477-838-304-580,2022,"A drone that can pour a variety of chemical agents such as oxidizers, silica gelling agents, enzymes, and neutralizers onto areas contaminated with chemical and biological weapons of mass destruction. The use of a drone to destroy the chemical and biological weapons of mass destruction is highly beneficial since it allows the exposed toxic areas to be remotely decontaminated without the presence of humans."
Autonomous unmanned underwater vehicle with buoyancy engine,https://lens.org/143-517-675-284-986,2012,"An autonomous unmanned underwater vehicle (AUV) includes a body, a controller, a buoyancy engine, a rotary propulsion system and pitch control surface(s). The buoyancy engine is for alternately ingesting and expelling ambient water to change the mass of the AUV and thereby cause the AUV to alternately descend and ascend in the water. The pitch control surface(s) are for causing the AUV to move forward while alternately descending and ascending in the water. The rotary propulsion system includes a motor for rotating a propeller in the water to provide thrust. The controller is operative for responsively, automatically switching between at least the glider and rotary propulsion modes. In the glider mode, the buoyancy engine and the pitch control surface(s) are cooperative for causing the AUV to move forward while alternately descending and ascending. In the rotary propulsion mode, the rotary propulsion system is operative for causing the AUV to move forward."
Drone-target hunting/shooting system,https://lens.org/030-397-861-490-58X,2019,"In a target-shooting simulation system, a master control unit issues flight control instructions to a flight-capable drone to cause the drone to fly along a predetermined flight path and receives GPS coordinates transmitted by a control unit of the drone as the drone flies along the predetermined flight path. The master control unit additionally obtains GPS coordinates, orientation and motion information with respect to a replica firearm, detects actuation of a trigger of the replica firearm and, in response to detecting actuation of the trigger, determines, based on the GPS coordinates of the drone and the GPS coordinates, orientation and motion information with respect to the replica firearm, whether a trajectory of a theoretical shot fired by the replica firearm at time of the trigger actuation will intercept the drone as it flies along the predetermined flight path."
Drone-target hunting/shooting system,https://lens.org/038-760-311-674-127,2017,"In a target-shooting simulation system, a master control unit issues flight control instructions to a flight-capable drone to cause the drone to fly along a predetermined flight path and receives GPS coordinates transmitted by a control unit of the drone as the drone flies along the predetermined flight path. The master control unit additionally obtains GPS coordinates, orientation and motion information with respect to a replica firearm, detects actuation of a trigger of the replica firearm and, in response to detecting actuation of the trigger, determines, based on the GPS coordinates of the drone and the GPS coordinates, orientation and motion information with respect to the replica firearm, whether a trajectory of a theoretical shot fired by the replica firearm at time of the trigger actuation will intercept the drone as it flies along the predetermined flight path."
Drone-target hunting/shooting system,https://lens.org/068-010-897-734-574,2017,"In a target-shooting simulation system, a master control unit issues flight control instructions to a flight-capable drone to cause the drone to fly along a predetermined flight path and receives GPS coordinates transmitted by a control unit of the drone as the drone flies along the predetermined flight path. The master control unit additionally obtains GPS coordinates, orientation and motion information with respect to a replica firearm, detects actuation of a trigger of the replica firearm and, in response to detecting actuation of the trigger, determines, based on the GPS coordinates of the drone and the GPS coordinates, orientation and motion information with respect to the replica firearm, whether a trajectory of a theoretical shot fired by the replica firearm at time of the trigger actuation will intercept the drone as it flies along the predetermined flight path."
A CONTROL UNIT AND METHOD THEREIN FOR OPERATING AN AUTONOMOUS VEHICLE,https://lens.org/003-799-666-450-286,2023,"A method performed by a control unit for operating an autonomous vehicle is provided. The control unit is arranged to communicate via at least one antenna. The control unit obtains, based on a signal from the at least one antenna, information relating to at least one geographical zone associated with a transponder as the autonomous vehicle moves in proximity of the transponder. Also, the control unit determines an autonomous operating mode of the autonomous vehicle based on the obtained information relating to the at least one geographical zone associated with the transponder. The control unit further operates the autonomous vehicle in accordance with the determined autonomous operating mode."
A CONTROL UNIT AND METHOD THEREIN FOR OPERATING AN AUTONOMOUS VEHICLE,https://lens.org/003-799-666-450-286,2023,"A method performed by a control unit for operating an autonomous vehicle is provided. The control unit is arranged to communicate via at least one antenna. The control unit obtains, based on a signal from the at least one antenna, information relating to at least one geographical zone associated with a transponder as the autonomous vehicle moves in proximity of the transponder. Also, the control unit determines an autonomous operating mode of the autonomous vehicle based on the obtained information relating to the at least one geographical zone associated with the transponder. The control unit further operates the autonomous vehicle in accordance with the determined autonomous operating mode."
AIR TRANSPORTABLE FUEL CELL POWER SYSTEM,https://lens.org/131-603-928-754-903,2017,Disclosed herein is a system for delivering a power source to a remote location. The system includes an unmanned aerial vehicle (UAV) with a primary power system connected to it to fly the UAV to the remote location. The UAV is autonomously controlled. The primary power system is capable of being converted to a secondary power system to provide a power source at the remote location. A controller in communication with the UAV is used to operate the UAV and fly the UAV to the remote location.
Mobile tele-presence system with a microphone system,https://lens.org/039-964-973-427-273,2012,"A remote controlled robot system that includes a robot and a remote control station. The robot includes a binaural microphone system that is coupled to a speaker system of the remote control station. The binaural microphone system may include a pair of microphones located at opposite sides of a robot head. The location of the microphones roughly coincides with the location of ears on a human body. Such microphone location creates a mobile robot that more effectively simulates the tele-presence of an operator of the system. The robot may include two different microphone systems and the ability to switch between systems. For example, the robot may also include a zoom camera system and a directional microphone. The directional microphone may be utilized to capture sound from a direction that corresponds to an object zoomed upon by the camera system."
Mobile tele-presence system with a microphone system,https://lens.org/175-601-034-830-353,2010,"A remote controlled robot system that includes a robot and a remote control station. The robot includes a binaural microphone system that is coupled to a speaker system of the remote control station. The binaural microphone system may include a pair of microphones located at opposite sides of a robot head. The location of the microphones roughly coincides with the location of ears on a human body. Such microphone location creates a mobile robot that more effectively simulates the tele-presence of an operator of the system. The robot may include two different microphone systems and the ability to switch between systems. For example, the robot may also include a zoom camera system and a directional microphone. The directional microphone may be utilized to capture sound from a direction that corresponds to an object zoomed upon by the camera system."
Autonomous Unmanned Aerial Vehicle and Method of Control Thereof,https://lens.org/073-790-219-377-687,2020,"An autonomous unmanned aerial vehicle (10) comprising an airframe body; at least one flight system mounted to the airframe body (12); an onboard flight controller (18) which is adapted to control the or each flight system; a memory storage unit having machine-readable flight control instructions which are implementable by the onboard flight controller; an onboard feedback system which is communicatively coupled with the or each flight system to provide real-time internal flight characteristic data to the onboard flight controller (18); and an external feedback system adapted to receive and provide to the onboard flight controller (18) real-time external flight characteristic data; wherein the onboard flight controller (18) is arranged to receive mission parameter data from an external source, determine a pre-take-off flight plan in accordance with the mission parameter data, and dynamically implement the machine-readable flight control instructions to adapt the pre-take-off flight plan to control the or each flight system based on the real-time internal flight characteristic data and real-time external flight characteristic data."
SYSTEM FOR PILOTING A DRONE IN IMMERSION,https://lens.org/043-431-225-320-131,2016,"The system comprises a drone and a ground station. The ground station includes a console provided with a directional antenna adapted to be directed towards the drone maintain the quality of the wireless link with the latter, and virtual reality glasses rendering images taken by a camera of the drone. The system comprises means for determining the position of the drone with respect to a heading of the console, and means for including in the images (I) rendered in the virtual reality glasses a visual indication (C, Ce, G, Id) of misalignment of the drone with respect to the console heading. Although he is isolated from the external real environment, the pilot is able, based on this visual indication, to reorient the console, typically by turning on himself, so that the directional antenna thereof suitably points towards the drone."
System for piloting a drone in immersion,https://lens.org/066-360-317-057-085,2018,"The system comprises a drone and a ground station. The ground station includes a console provided with a directional antenna adapted to be directed towards the drone maintain the quality of the wireless link with the latter, and virtual reality glasses rendering images taken by a camera of the drone. The system comprises means for determining the position of the drone with respect to a heading of the console, and means for including in the images (I) rendered in the virtual reality glasses a visual indication (C, Ce, G, Id) of misalignment of the drone with respect to the console heading. Although he is isolated from the external real environment, the pilot is able, based on this visual indication, to reorient the console, typically by turning on himself, so that the directional antenna thereof suitably points towards the drone."
AERIAL VEHICLE,https://lens.org/011-991-029-795-660,2016,"An aerial vehicle includes a body, a plurality of rotors coupled to the body and configured to provide lift, a plurality of driving devices coupled to the rotors respectively and configured to drive the rotors to rotate, and a control device coupled to the body and the driving devices. The control device includes a gyroscope and a controller. The gyroscope is configured to collect information of rotation speed of the body and transmit the information of the rotation speed to the controller. The controller is configured to provide a driving power for adjusting the rotation speed of the body according the information of the rotation speed, and produce and transmit a control signal of the driving power to the driving devices to output the driving power to corresponding rotors to adjust the rotation speed of the body."
ISUAV-Woman Security: Intelligent Woman Security Using Streetlight and Auto Run Unmanned Aerial Vehicle Using IOT- Based Technology,https://lens.org/013-195-872-406-185,2020,"Our Invention ""ISUAV-Woman Security"" is a street lighting system and Auto Run Unmanned Aerial Vehicle Using IoT based Technology is to provide having a movement system a light source repositionable via the moving object. A sensor, controller and an IoT based communication system the controller may control characteristics of the light emitted by the light source and detect the object who needed to help then rotation of the panel by the movement system receiving signal information from the sensor. The invented technology the movement system, the controller, the sensor, and the communication system are installable in a drone. Wearable apparatus may be used with the system. Objects may be tracked and illuminated. An aerial device automatically maintains a relative position with respect to a target and the aerial device can set a relatively multi-dimensional position with respect to the target. The invented technology the target can have an indicator (e.g., a visual marker for image capture tracking, or a radio indicator for tracking via signaling) that the aerial device reads. The aerial device can automatically adjust its path in response to the movement of the target as indicated by the indicator. Systems and methods for unmanned aerial vehicle (UAV) navigation are presented and a preferred, UAV is configured with at least one corridor and path, and a first UAV pat VCc R$8 U 3 2.5 3 r0'h 5% yRST 3u 3 M 100 THR 74N m!jR 5 CON F-,-GND 1 : sv C2 - LM555CN 1 KEY = SPACE 510nF vCC 5v X1 11 HuA R1 4 0 3U2 2.5 J 390k0hm 5% yRST 3 0XWG1 1 RT 7408N D 16USA :7432N R2TREJ 390k~hm 5% 5 CON 0 c1 LM555CN 5V EY=SPC 510nF -. 0 - -743N 73N X Me 5 31 ~ 7432N U120 C0US 25 R Tu7c 7432N 390k~hm 5% 7 UT SU 7432N RBTRI J.3 390~hm5% CN 1 C3 LM55CN 1 KEY = SPACE 610nF FIG. 1: IS A CONTROL CIRCUIT TO SELECT PANELS FOR INTENSITY AND DIRECTIONAL CONTROL."
DEEP LEARNING-BASED LOCALIZATION OF UAVS WITH RESPECT TO NEARBY PIPES,https://lens.org/191-226-477-523-510,2022,"A system and methodology for launching, flying and perching on a cylindrically curved surface in an environment without human intervention. The system and methodology include an environment awareness sensor device suite having a depth camera arranged to capture and output image data and 3D point cloud data of a field of view; an asset targeting unit arranged to set an asset as a destination location for a landing; a trajectory path determiner arranged to calculate a trajectory path to the destination location; a flight controller arranged to launch and fly the autonomous aerial vehicle to the destination location according to the trajectory path; a situational status determiner arranged to, in real-time, predict a location of an object with respect to the autonomous aerial vehicle based on 3D point cloud data for the object, determine the object is the asset based on a confidence score and autonomously land on the asset."
Deep learning-based localization of UAVs with respect to nearby pipes,https://lens.org/048-047-701-061-00X,2023,"A system and methodology for launching, flying and perching on a cylindrically curved surface in an environment without human intervention. The system and methodology include an environment awareness sensor device suite having a depth camera arranged to capture and output image data and 3D point cloud data of a field of view; an asset targeting unit arranged to set an asset as a destination location for a landing; a trajectory path determiner arranged to calculate a trajectory path to the destination location; a flight controller arranged to launch and fly the autonomous aerial vehicle to the destination location according to the trajectory path; a situational status determiner arranged to, in real-time, predict a location of an object with respect to the autonomous aerial vehicle based on 3D point cloud data for the object, determine the object is the asset based on a confidence score and autonomously land on the asset."
Deep learning-based localization of UAVs with respect to nearby pipes,https://lens.org/048-047-701-061-00X,2023,"A system and methodology for launching, flying and perching on a cylindrically curved surface in an environment without human intervention. The system and methodology include an environment awareness sensor device suite having a depth camera arranged to capture and output image data and 3D point cloud data of a field of view; an asset targeting unit arranged to set an asset as a destination location for a landing; a trajectory path determiner arranged to calculate a trajectory path to the destination location; a flight controller arranged to launch and fly the autonomous aerial vehicle to the destination location according to the trajectory path; a situational status determiner arranged to, in real-time, predict a location of an object with respect to the autonomous aerial vehicle based on 3D point cloud data for the object, determine the object is the asset based on a confidence score and autonomously land on the asset."
DEEP LEARNING-BASED LOCALIZATION OF UAVS WITH RESPECT TO NEARBY PIPES,https://lens.org/191-226-477-523-510,2022,"A system and methodology for launching, flying and perching on a cylindrically curved surface in an environment without human intervention. The system and methodology include an environment awareness sensor device suite having a depth camera arranged to capture and output image data and 3D point cloud data of a field of view; an asset targeting unit arranged to set an asset as a destination location for a landing; a trajectory path determiner arranged to calculate a trajectory path to the destination location; a flight controller arranged to launch and fly the autonomous aerial vehicle to the destination location according to the trajectory path; a situational status determiner arranged to, in real-time, predict a location of an object with respect to the autonomous aerial vehicle based on 3D point cloud data for the object, determine the object is the asset based on a confidence score and autonomously land on the asset."
MODULAR CAMERA CORE CONTROL,https://lens.org/156-724-276-717-282,2015,"A method of controlling a modular camera using an external device, the method comprising receiving a command to capture a digital video and/or a digital image from the external device via a wireless communication, capturing the digital video and/or the digital image according to the command from the external device, storing the digital video and/or the digital image in a memory, receiving a command to transfer the digital video and/or the digital image to the external device via the wireless communication, and transferring the digital video and/or the digital image to the external device via the wireless communication."
UNIVERSAL MOUNTING PANEL FOR A ROTARY-WING DRONE,https://lens.org/139-663-564-500-00X,2016,"The drone body (10) comprises a frame (12), integral with arms (14) for connection to propulsion units (16), an electronic board (24) carrying components as well as accelerometer, inertial and altimeter sensors, a support for this board, and an elastic interface (26) between the frame and the board support, to filter and absorb the mechanical vibrations. The board support is a panel (22) made of an electrically conductive metal material. The panel carries on a back side thermally conductive areas at places located opposite heat-sink electronic components mounted on the board on the back side. The panel is moreover electrically connected to a ground potential of the electronic board, so as to form an electromagnetic shielding screen. It is further mechanically connected to the frame with uncoupling by the elastic interface (26) interposed between the panel and the frame."
"Package acceptance, guidance, and refuel system for drone technology",https://lens.org/181-651-354-700-040,2019,Some embodiments described herein relate to a drone landing platform. One or more sensors coupled to the drone landing platform can detect local conditions in the vicinity of the drone landing platform. A communications system can be operable to transmit information related local conditions to a drone.
"PACKAGE ACCEPTANCE, GUIDANCE, AND REFUEL SYSTEM FOR DRONE TECHNOLOGY",https://lens.org/057-302-642-346-815,2020,Some embodiments described herein relate to a drone landing platform. One or more sensors coupled to the drone landing platform can detect local conditions in the vicinity of the drone landing platform. A communications system can be operable to transmit information related local conditions to a drone.
"PACKAGE ACCEPTANCE, GUIDANCE, AND REFUEL SYSTEM FOR DRONE TECHNOLOGY",https://lens.org/057-302-642-346-815,2020,Some embodiments described herein relate to a drone landing platform. One or more sensors coupled to the drone landing platform can detect local conditions in the vicinity of the drone landing platform. A communications system can be operable to transmit information related local conditions to a drone.
VEHICLE CONTROLLER,https://lens.org/058-631-779-688-73X,2023,"An apparatus for controlling an unmanned vehicle is described. The apparatus comprises: a receiver for receiving a first vehicle control signal from a remote controller; a memory for storing a route for the vehicle to follow; and a processor. The processor is configured to: determine characteristics of the first vehicle control signal; and generate a second vehicle control signal, wherein the second vehicle control signal comprises an instruction for the vehicle to perform a manoeuvre to follow the route. The apparatus further comprises a transmitter configured to transmit the second vehicle control signal, arranged to have the determined characteristics, to the vehicle. A system and method for controlling an unmanned vehicle are also described."
AN APPARATUS FOR CONTROLLING AN UNMANNED VEHICLE AND A METHOD OF CONTROLLING AN UNMANNED VEHICLE,https://lens.org/058-507-442-118-581,2022,"An apparatus for controlling an unmanned vehicle is described. The apparatus comprises: a receiver for receiving a first vehicle control signal from a remote controller; a memory for storing a route for the vehicle to follow; and a processor. The processor is configured to: determine characteristics of the first vehicle control signal; and generate a second vehicle control signal, wherein the second vehicle control signal comprises an instruction for the vehicle to perform a manoeuvre to follow the route. The apparatus further comprises a transmitter configured to transmit the second vehicle control signal, arranged to have the determined characteristics, to the vehicle. A system and method for controlling an unmanned vehicle are also described."
CONTROL SYSTEMS FOR UNMANNED AERIAL VEHICLES,https://lens.org/195-986-776-233-609,2022,"A method for controlling an unmanned aerial vehicle within a flight operating space. The unmanned aerial vehicle includes one or more sensor arrays on each spar. The method includes determining, using a plurality of sensor arrays, a flight path for the unmanned aerial vehicle. The method also includes receiving, by at least one sensor array of the plurality of sensor arrays, sensor data identifying at least one object in the operating space. The sensor data is transmitted over a communications bus connecting components of the UAV. The method further includes determining, by one or more processors onboard the unmanned aerial vehicle, a flight path around the at least one object. The method also includes generating, by the one or more onboard processors, a first signal to cause the unmanned aerial vehicle to navigate within the operating space around the at least one object."
CONTROL SYSTEMS FOR UNMANNED AERIAL VEHICLES,https://lens.org/146-508-121-946-284,2018,"A method for controlling an unmanned aerial vehicle within a flight operating space. The unmanned aerial vehicle includes one or more sensor arrays on each spar. The method includes determining, using a plurality of sensor arrays, a flight path for the unmanned aerial vehicle. The method also includes receiving, by at least one sensor array of the plurality of sensor arrays, sensor data identifying at least one object in the operating space. The sensor data is transmitted over a communications bus connecting components of the UAV. The method further includes determining, by one or more processors onboard the unmanned aerial vehicle, a flight path around the at least one object. The method also includes generating, by the one or more onboard processors, a first signal to cause the unmanned aerial vehicle to navigate within the operating space around the at least one object."
Control systems for unmanned aerial vehicles,https://lens.org/177-672-637-021-476,2023,"A method for controlling an unmanned aerial vehicle within a flight operating space. The unmanned aerial vehicle includes one or more sensor arrays on each spar. The method includes determining, using a plurality of sensor arrays, a flight path for the unmanned aerial vehicle. The method also includes receiving, by at least one sensor array of the plurality of sensor arrays, sensor data identifying at least one object in the operating space. The sensor data is transmitted over a communications bus connecting components of the UAV. The method further includes determining, by one or more processors onboard the unmanned aerial vehicle, a flight path around the at least one object. The method also includes generating, by the one or more onboard processors, a first signal to cause the unmanned aerial vehicle to navigate within the operating space around the at least one object."
Control systems for unmanned aerial vehicles,https://lens.org/045-654-861-942-864,2022,"A method for controlling an unmanned aerial vehicle within a flight operating space. The unmanned aerial vehicle includes one or more sensor arrays on each spar. The method includes determining, using a plurality of sensor arrays, a flight path for the unmanned aerial vehicle. The method also includes receiving, by at least one sensor array of the plurality of sensor arrays, sensor data identifying at least one object in the operating space. The sensor data is transmitted over a communications bus connecting components of the UAV. The method further includes determining, by one or more processors onboard the unmanned aerial vehicle, a flight path around the at least one object. The method also includes generating, by the one or more onboard processors, a first signal to cause the unmanned aerial vehicle to navigate within the operating space around the at least one object."
CONTROL SYSTEMS FOR UNMANNED AERIAL VEHICLES,https://lens.org/124-144-488-060-380,2018,"A method for controlling an unmanned aerial vehicle within a flight operating space. The unmanned aerial vehicle includes one or more sensor arrays on each spar. The method includes determining, using a plurality of sensor arrays, a flight path for the unmanned aerial vehicle. The method also includes receiving, by at least one sensor array of the plurality of sensor arrays, sensor data identifying at least one object in the operating space. The sensor data is transmitted over a communications bus connecting components of the UAV. The method further includes determining, by one or more processors onboard the unmanned aerial vehicle, a flight path around the at least one object. The method also includes generating, by the one or more onboard processors, a first signal to cause the unmanned aerial vehicle to navigate within the operating space around the at least one object."
CONTROL SYSTEMS FOR UNMANNED AERIAL VEHICLES,https://lens.org/195-986-776-233-609,2022,"A method for controlling an unmanned aerial vehicle within a flight operating space. The unmanned aerial vehicle includes one or more sensor arrays on each spar. The method includes determining, using a plurality of sensor arrays, a flight path for the unmanned aerial vehicle. The method also includes receiving, by at least one sensor array of the plurality of sensor arrays, sensor data identifying at least one object in the operating space. The sensor data is transmitted over a communications bus connecting components of the UAV. The method further includes determining, by one or more processors onboard the unmanned aerial vehicle, a flight path around the at least one object. The method also includes generating, by the one or more onboard processors, a first signal to cause the unmanned aerial vehicle to navigate within the operating space around the at least one object."
CONTROL SYSTEMS FOR UNMANNED AERIAL VEHICLES,https://lens.org/172-195-021-141-348,2020,"A method for controlling an unmanned aerial vehicle within a flight operating space. The unmanned aerial vehicle includes one or more sensor arrays on each spar. The method includes determining, using a plurality of sensor arrays, a flight path for the unmanned aerial vehicle. The method also includes receiving, by at least one sensor array of the plurality of sensor arrays, sensor data identifying at least one object in the operating space. The sensor data is transmitted over a communications bus connecting components of the UAV. The method further includes determining, by one or more processors onboard the unmanned aerial vehicle, a flight path around the at least one object. The method also includes generating, by the one or more onboard processors, a first signal to cause the unmanned aerial vehicle to navigate within the operating space around the at least one object."
UAV SYSTEM,https://lens.org/095-330-608-121-598,2019,"An unmanned aerial vehicle (UAV) system includes a first device including a housing space, a second device configured to be housed and held at the housing space, and a retaining structure configured to hold the second device at the housing space."
Domestic appliance having variable security based on automatic determination of user supervision,https://lens.org/171-510-060-129-14X,2020,"A domestic appliance includes a user interface for a user to input commands, a camera for taking an image of an operating area from which the user interface can be operated by the user, a speech recognition device for detecting a speech command, and a control device configured to determine a level of security depending on the image that was taken by the camera and to execute the speech command detected by the speech recognition device depending on the level of security that has been determined."
DOMESTIC APPLIANCE AND METHOD FOR OPERATING A DOMESTIC APPLIANCE,https://lens.org/042-333-174-751-605,2018,"A domestic appliance includes a user interface for a user to input commands, a camera for taking an image of an operating area from which the user interface can be operated by the user, a speech recognition device for detecting a speech command, and a control device configured to determine a level of security depending on the image that was taken by the camera and to execute the speech command detected by the speech recognition device depending on the level of security that has been determined."
Method and apparatus for extending the recording time of a remotely controllable electronic device using a hand-held autonomous remote control,https://lens.org/190-060-567-309-039,2002,"A remote control is used to extend the recording time of a recording device (typically a camcorder (20)). The remote control periodically commands the camcorder (20) to record for a relatively short period of time and then stop recording. In this way, the camcorder (20) is caused to record in a time-lapse fashion. Also, the remote control is used to disable all recording for periods of time when it is known that an event of interest will not occur during these periods. Provisions are made for extending both the recording tape time and the camcorder battery (34) life."
Recording time extension using a remote control,https://lens.org/073-830-173-371-338,2002,"A remote control is used to extend the recording time of a recording device (typically a camcorder (20)). The remote control periodically commands the camcorder (20) to record for a relatively short period of time and then stop recording. In this way, the camcorder (20) is caused to record in a time-lapse fashion. Also, the remote control is used to disable all recording for periods of time when it is known that an event of interest will not occur during these periods. Provisions are made for extending both the recording tape time and the camcorder battery (34) life."
Recording time extension using a remote control,https://lens.org/101-611-501-295-615,2003,"A remote control is used to extend the recording time of a recording device (typically a camcorder (20)). The remote control periodically commands the camcorder (20) to record for a relatively short period of time and then stop recording. In this way, the camcorder (20) is caused to record in a time-lapse fashion. Also, the remote control is used to disable all recording for periods of time when it is known that an event of interest will not occur during these periods. Provisions are made for extending both the recording tape time and the camcorder battery (34) life."
Remote-control apparatus and image input apparatus,https://lens.org/111-847-369-362-30X,1998,"A remote-control apparatus for remotely controlling one or more controlled apparatuses includes a video camera capable of inputting an image of a controlled apparatus and outputting the input image to outside the remote-control apparatus, and a controller for controlling the controlled apparatus the image of which has been input by the video camera, by using a wireless signal. The video camera and the controller are disposed in one body."
"CONTROL METHOD FOR UNMANNED AERIAL VEHICLE, FLIGHT CONTROLLER AND UNMANNED AERIAL VEHICLE",https://lens.org/072-105-682-396-164,2020,"A control method for an unmanned aerial vehicle (UAV) includes obtaining location information of the UAV and location information of a flight restriction area, obtaining a flight mode of the UAV in response to determining that the UAV enters a buffer area of the flight restriction zone according to the location information of the UAV and the location information of the flight restriction zone, in response to the flight mode of the UAV being a non-velocity-control mode, switching the flight mode of the UAV from the non-velocity-control mode to a velocity-control mode, and controlling a velocity of the UAV according to the location information of the flight restriction zone."
"CONTROL APPARATUS FOR UNMANNED AERIAL VEHICLE, AND UNMANNED AERIAL VEHICLE",https://lens.org/063-731-485-698-886,2019,"Provided are a control device for unmanned aerial vehicle and an unmanned aerial vehicle. The control device for unmanned aerial vehicle includes a shell, an inertial measurement device fixed in the shell, a main flight control circuit board electrically connected to the inertial measurement device, and a flexible interface board electrically connected to the main flight control circuit board and appressed against the inwall of the shell. At least one external device is connected to two opposite sides of the flexible interface board through the shell."
CONTROL DEVICE FOR UNMANNED AERIAL VEHICLE AND UNMANNED AERIAL VEHICLE,https://lens.org/123-688-774-455-497,2021,"Provided are a control device for unmanned aerial vehicle and an unmanned aerial vehicle. The control device for unmanned aerial vehicle includes a shell, an inertial measurement device fixed in the shell, a main flight control circuit board electrically connected to the inertial measurement device, and a flexible interface board electrically connected to the main flight control circuit board and appressed against the inwall of the shell. At least one external device is connected to two opposite sides of the flexible interface board through the shell."
Control device for unmanned aerial vehicle and unmanned aerial vehicle,https://lens.org/028-397-756-717-816,2021,"Provided are a control device for unmanned aerial vehicle and an unmanned aerial vehicle. The control device for unmanned aerial vehicle includes a shell, an inertial measurement device fixed in the shell, a main flight control circuit board electrically connected to the inertial measurement device, and a flexible interface board electrically connected to the main flight control circuit board and appressed against the inwall of the shell. At least one external device is connected to two opposite sides of the flexible interface board through the shell."
Robot Virtualization Leveraging Geo Analytics And Augmented Reality,https://lens.org/050-330-062-789-752,2018,"Robots, users, or a central controller may leverage Geo analytics and/or augmented reality to search for, discover, access and use robots. The robots may perform tasks to provide selective services on-demand within medicine, agriculture, military, entertainment, manufacturing, personal, or public safety, among other things."
Robot virtualization leveraging geo analytics and augmented reality,https://lens.org/167-780-532-430-084,2021,"Robots, users, or a central controller may leverage Geo analytics and/or augmented reality to search for, discover, access and use robots. The robots may perform tasks to provide selective services on-demand within medicine, agriculture, military, entertainment, manufacturing, personal, or public safety, among other things."
Robot Virtualization Leveraging Geo Analytics And Augmented Reality,https://lens.org/175-541-690-217-862,2020,"Robots, users, or a central controller may leverage Geo analytics and/or augmented reality to search for, discover, access and use robots. The robots may perform tasks to provide selective services on-demand within medicine, agriculture, military, entertainment, manufacturing, personal, or public safety, among other things."
IDENTIFYING ANTENNA COMMUNICATION ISSUES USING UNMANNED AERIAL VEHICLES,https://lens.org/070-110-722-312-337,2023,"An unmanned aerial vehicle (UAV) is dispatched to automatically fly to a location of an antenna indicated by GPS coordinates, automatically recognize the antenna at that location using automated image analysis and object detection, and then start capturing still or video imagery of the antenna in response to the recognition of the antenna. The UAV may be automatically activated to start looking for debris, obstructions or other objects affecting line-of-sight signal reception by the antenna in response to arriving at the location of the antenna and/or detection of the antenna. The UAV may automatically transmit (e.g., in real time) the still or video aerial imagery of the antenna to a backend system for analysis to determine whether there exists a specific issue (e.g., snow or other debris on the antenna) affecting wireless communication involving the antenna."
IDENTIFYING ANTENNA COMMUNICATION ISSUES USING UNMANNED AERIAL VEHICLES,https://lens.org/070-110-722-312-337,2023,"An unmanned aerial vehicle (UAV) is dispatched to automatically fly to a location of an antenna indicated by GPS coordinates, automatically recognize the antenna at that location using automated image analysis and object detection, and then start capturing still or video imagery of the antenna in response to the recognition of the antenna. The UAV may be automatically activated to start looking for debris, obstructions or other objects affecting line-of-sight signal reception by the antenna in response to arriving at the location of the antenna and/or detection of the antenna. The UAV may automatically transmit (e.g., in real time) the still or video aerial imagery of the antenna to a backend system for analysis to determine whether there exists a specific issue (e.g., snow or other debris on the antenna) affecting wireless communication involving the antenna."
METHOD AND DEVICE FOR REMOTE-CONTROLLING AUTONOMOUS VEHICLE CAPABLE OF CHANGING DRIVING MODE BETWEEN AUTONOMOUS DRIVING MODE AND MANUAL DRIVING MODE,https://lens.org/033-726-777-358-125,2020,"A method for remotely controlling at least one autonomous vehicle is provided. The method includes steps of: an autonomous driving control device, (a) on condition that the autonomous driving control device detects driving environment by referring to sensor information and allows the autonomous vehicle to travel on an autonomous driving mode or a manual driving mode, determining whether the autonomous driving control device fails to establish a driving plan by using the driving environment and whether the autonomous driving control device fails to change to the manual driving mode by using the driving environment; and (b) if the autonomous driving control device fails to establish the driving plan or fails to change to the manual driving mode, selecting a remote control mode and transmitting request information to a remote control service providing server, to allow a remote driver to control the autonomous vehicle by using a specific remote vehicle."
METHOD AND DEVICE FOR REMOTE-CONTROLLING AUTONOMOUS VEHICLE CAPABLE OF CHANGING DRIVING MODE BETWEEN AUTONOMOUS DRIVING MODE AND MANUAL DRIVING MODE,https://lens.org/171-686-960-605-34X,2020,"A method for remotely controlling at least one autonomous vehicle is provided. The method includes steps of: an autonomous driving control device, (a) on condition that the autonomous driving control device detects driving environment by referring to sensor information and allows the autonomous vehicle to travel on an autonomous driving mode or a manual driving mode, determining whether the autonomous driving control device fails to establish a driving plan by using the driving environment and whether the autonomous driving control device fails to change to the manual driving mode by using the driving environment; and (b) if the autonomous driving control device fails to establish the driving plan or fails to change to the manual driving mode, selecting a remote control mode and transmitting request information to a remote control service providing server, to allow a remote driver to control the autonomous vehicle by using a specific remote vehicle."
Vehicle management,https://lens.org/184-379-096-890-214,2020,"A method of controlling an autonomous vehicle (AV), comprising: detecting a fault in a first AV 210; in response to detecting said fault, transmitting a communication for alerting a second AV of the fault 220, wherein said communication is a device-to-device wireless communication; receiving said communication at a second AV; identifying the second AV as being capable of retrieving at least part of the first AV 230 and delivering said at least part to an intended destination; and instructing the second AV to perform the retrieving and delivering 250."
"Control apparatus, camera apparatus, flying object, control method and program",https://lens.org/030-406-713-405-357,2021,"A control apparatus, a camera apparatus, a flying object, a control method and a program are provided. The control apparatus is configured to control a driving of a focus lens included in a camera apparatus. The control apparatus includes a memory, storing a program; and a processor, configured to execute the program to set a drive range of the focus lens based on a height of the camera apparatus away from a reference position, and control the driving of the focus lens in the drive range."
"CONTROL APPARATUS, CAMERA APPARATUS, FLYING OBJECT, CONTROL METHOD AND PROGRAM",https://lens.org/146-588-755-059-786,2020,"A control apparatus, a camera apparatus, a flying object, a control method and a program are provided. The control apparatus is configured to control a driving of a focus lens included in a camera apparatus. The control apparatus includes a memory, storing a program; and a processor, configured to execute the program to set a drive range of the focus lens based on a height of the camera apparatus away from a reference position, and control the driving of the focus lens in the drive range."
METHOD AND APPARATUS FOR PROVIDING DRONE DATA BY MATCHING USER WITH PROVIDER,https://lens.org/131-592-337-593-086,2020,An apparatus for providing drone data provides a method of matching a user who needs drone data of a certain area with at least one provider capable of providing drone data of a part or the entirety of the certain area.
POWER SUPPLY FOR AN AIRCRAFT AND CORRESPONDING AIRCRAFT,https://lens.org/003-458-213-244-767,2020,"A power supply for an aircraft includes a drone capable of flight and including rotors, a DC-to-DC converter, a battery for driving the rotors and a locking device for securing a plug connection between the drone and the aircraft. The drone is set up to secure the plug connection by the locking device until the aircraft reaches a prescribed altitude, and the power supply is configured in such a way that the battery supplies power to the aircraft by the DC-to-DC converter as long as the plug connection exists."
Systems and methods for operating unmanned aerial vehicles,https://lens.org/046-768-031-941-960,2022,"A method of controlling an unmanned aerial vehicle includes receiving a first signal including information relating to a payload of the unmanned aerial vehicle, retrieving a predetermined value from a memory of the unmanned aerial vehicle based on the information of the first signal, and generating a second signal for changing a configuration of an arm of the unmanned aerial vehicle to change a distance of at least one of a plurality of propulsion units of the unmanned aerial vehicle corresponding to the arm from a reference point on a central body of the unmanned aerial vehicle based on the predetermined value."
SYSTEMS AND METHODS FOR OPERATING UNMANNED AERIAL VEHICLES,https://lens.org/006-438-665-426-837,2019,"A method of controlling an unmanned aerial vehicle includes receiving a first signal including information relating to a payload of the unmanned aerial vehicle, retrieving a predetermined value from a memory of the unmanned aerial vehicle based on the information of the first signal, and generating a second signal for changing a configuration of an arm of the unmanned aerial vehicle to change a distance of at least one of a plurality of propulsion units of the unmanned aerial vehicle corresponding to the arm from a reference point on a central body of the unmanned aerial vehicle based on the predetermined value."
ADAPTIVE RATE GAIN CONTROLLER,https://lens.org/126-775-723-069-54X,2022,"An aerial vehicle comprises one or more sensors to environmental data, a communication system to receive control inputs from a user, two or more actuators, with each actuator coupled to a rotary wing. The aerial vehicle also comprises a controller to determine a mode of the aerial vehicle based on the environmental data and the control inputs, each mode indicating a set of flight characteristics for the aerial vehicle, generate a gain value based on the mode, the gain value, when used to modify power signals transmitted to actuators of the aerial vehicle, causes the aerial vehicle to conform within the indicated flight characteristics of the determined mode, generate an output signal modified by the gain value based on the input signal, and transmit a power signal based on the output signal to each actuator of the aerial vehicle."
ADAPTIVE RATE GAIN CONTROLLER,https://lens.org/037-325-458-031-107,2018,"An aerial vehicle comprises one or more sensors to environmental data, a communication system to receive control inputs from a user, two or more actuators, with each actuator coupled to a rotary wing. The aerial vehicle also comprises a controller to determine a mode of the aerial vehicle based on the environmental data and the control inputs, each mode indicating a set of flight characteristics for the aerial vehicle, generate a gain value based on the mode, the gain value, when used to modify power signals transmitted to actuators of the aerial vehicle, causes the aerial vehicle to conform within the indicated flight characteristics of the determined mode, generate an output signal modified by the gain value based on the input signal, and transmit a power signal based on the output signal to each actuator of the aerial vehicle."
IN-FLIGHT DRONE STRUCTURE MODIFICATION,https://lens.org/086-850-244-390-65X,2023,"A method, computer system, and a drone for in-flight drone structure modification are provided. A first sensor of a drone may detect damage to a first arm of the drone during a flight of the drone. In response to the detecting the damage, the damaged first arm of the drone may be detached via a computer of the drone and during the flight of the drone."
DEVICE AND METHOD FOR MANAGING BIRD POPULATIONS,https://lens.org/173-290-554-419-287,2017,"The system for managing bird populations includes a drone (100); a disruptor (200) comprising an extension arm (220) having a proximal end and a distal end, the proximal end being operatively coupled with the drone (100), and the distal end comprising a tool portion (230), where the tool portion (230) comprises a piercing element constructed for engagement with one or more eggs in a nest; and a remote control system. The remote control system may comprise one or more remote control units and a monitor (430).The system can be used to manage bird populations by flying the drone (100) above a bird's nest; positioning the drone (100) above the bird's nest; and descending the drone (100) to disrupt eggs in the bird's nest with the disruptor (200)."
A REPORTER DRONE,https://lens.org/141-438-513-188-854,2015,"To provide a reporter drone (20), to approach a specific speaker in-between audience inside a big hole, a stadium, or in an open yard, or to take photos, record videos, and registers sounds from inside a narrow location where the drone's body (21) or a reporter can not approach, or can not get in. A triple camera (22) assembly, and a mike-speaker screen assembly (23), are installed and based separately at the ends of a two separate retractable motorized aerials (24), (30), installed at the ends of the bottom of the body (21) of a normal drone (20). When a drone (20) is used for reporting meetings with persons, the camera's antenna (24) is moving in the reverse direction of that moved by the antenna (30) of the mike-speaker screen (23), such that the mike-speaker screen (23) moves toward a speaker (person) while the cameras (22) are keeping a distance from him to get manage to get a photo for him."
Apparatus and method for surveying premises of a customer,https://lens.org/116-234-514-481-824,2017,"A system and method for surveying the home of a customer comprises an unmanned aerial vehicle (UAV) comprising a three dimensional scanner (i.e. laser scanner) and an image sensor, and a control circuit comprising a communication device configured to communicate with the UAV. The control circuit is configured to receive a residence location from the customer 220, instruct the UAV to travel to the premises to collect data (i.e. 3D measurements, photographs, temperature, lighting conditions, humidity) 230, form a 3D point cloud model of the property based on 3D data collected by the 3-dimensional scanner 240, identify one or more features of the premises (i.e. wall, gate, yard, door, window, roof, gutter, fence, vegetation etc.) based on the 3D model and image data collected by the image sensor 250, and generate a recommendation (i.e. product, home service, home improvement/gardening project, security improvement, lighting) to the customer based on the features 250. The system may also comprise stationary sensors (i.e. light, rain, humidity, wind, temperature, motion sensors) located at the premises, and the user may input their address via an in-store customer kiosk."
Autonomous helicopter blade end lighting device,https://lens.org/165-904-437-929-791,2000,"An autonomous helicopter blade end lighting device (20) includes a light source (22) and a power source (24) mounted in a housing (34) connectable to a helicopter rotor blade end (21), the power source (24) providing the light source (22) with power for operation when the blade is rotating."
SECURE WIRE-BASED SYSTEM FOR A DRONE,https://lens.org/076-502-555-550-581,2019,"The system according to the invention makes it possible to limit the possible drone crashing area if the drone malfunctions, and is intended in particular for operations on airports or critical populated or industrial regions."
MECHANICAL PACKAGE RELEASE SYSTEM,https://lens.org/169-945-802-765-307,2021,A package release system for delivering packages using radio controlled or autonomous vehicle like a drone. The package is carried at a first angle then released when the package changes angles such as when set on the ground.
METHOD AND SYSTEM FOR SMART ASSISTANT VOICE COMMAND REQUESTOR AUTHENTICATION,https://lens.org/029-832-490-992-959,2023,"A method, a system, and a non-transitory computer readable medium are disclosed for controlling Internet of Thing (IoT) devices using voice command requestor authentication. The method includes receiving, on a smart assistant device, a voice command from a first user; identifying, on the smart assistant device, the first user from the voice command; determining, on the smart assistant device, an authentication status of the first user to a perform one or more requests to one or more IoT devices based on the identity of the first user; and sending, from the smart assistant device, one or more instructions to the one or more IoT devices when the first user has been authorized to execute a function of the one or more IoT devices."
METHOD AND SYSTEM FOR SMART ASSISTANT VOICE COMMAND REQUESTOR AUTHENTICATION,https://lens.org/029-832-490-992-959,2023,"A method, a system, and a non-transitory computer readable medium are disclosed for controlling Internet of Thing (IoT) devices using voice command requestor authentication. The method includes receiving, on a smart assistant device, a voice command from a first user; identifying, on the smart assistant device, the first user from the voice command; determining, on the smart assistant device, an authentication status of the first user to a perform one or more requests to one or more IoT devices based on the identity of the first user; and sending, from the smart assistant device, one or more instructions to the one or more IoT devices when the first user has been authorized to execute a function of the one or more IoT devices."
"SERVO, CONTROL METHOD, AND UNMANNED AERIAL VEHICLE",https://lens.org/147-431-664-541-893,2019,"An unmanned aerial vehicle (UAV) includes a central part, a frame assembly, and a propulsion assembly mounted to the frame assembly. The UAV also includes a servo mounted to the central part. The servo includes a driving apparatus, a control apparatus operably coupled with the driving apparatus, and a sensor configured to obtain operating parameters of the driving apparatus. The operating parameters include operating positions of the driving apparatus. The control apparatus is configured to control the driving apparatus to rotate to a predetermined position and stay at the predetermined position based on the operating positions of the driving apparatus obtained by the sensor."
"Servo, control method, and unmanned aerial vehicle",https://lens.org/067-011-728-768-835,2022,"An unmanned aerial vehicle (UAV) includes a central part, a frame assembly, and a propulsion assembly mounted to the frame assembly. The UAV also includes a servo mounted to the central part. The servo includes a driving apparatus, a control apparatus operably coupled with the driving apparatus, and a sensor configured to obtain operating parameters of the driving apparatus. The operating parameters include operating positions of the driving apparatus. The control apparatus is configured to control the driving apparatus to rotate to a predetermined position and stay at the predetermined position based on the operating positions of the driving apparatus obtained by the sensor."
"Autonomous system for taking moving images from a drone, with target tracking and improved target location",https://lens.org/044-125-884-835-295,2019,"The displacements of the drone are defined by piloting commands to take moving images of a target carrying the ground station. The system comprises means for adjusting the sight angle of the camera during the displacements of the drone and of the target, so that the images are centerd to the target, and means for generating flying instructions so that the distance between drone and target fulfills determined rules, these means being based on a determination of the GPS geographical position of the target with respect to the GPS geographical position of the drone, and of the angular position of the target with respect to a main axis of the drone. These means are also based on the analysis of a non-geographical signal produced by the target and received by the drone. The system allows freeing from the uncertainty of the GPS systems equipping this type of device."
GIMBAL AND UNMANNED AERIAL VEHICLE,https://lens.org/046-294-319-607-521,2018,"The present application discloses a gimbal and an unmanned aerial vehicle. The gimbal includes a first connecting arm, a second connecting arm, a yaw axis motor, a roll axis motor, a pitch axis motor and a camera. A free end of the first connecting arm is connected to the yaw axis motor. A holding end of the first connecting arm is adjacent to the second connecting arm. Adjacent parts of the first connecting arm and the second connecting arm are connected to the roll axis motor, respectively. The two free ends of the second connecting arm are located on two sides of the camera in a embracing posture. One free end of the second connecting arm is connected to the camera, and the other free end of the second connecting arm is connected to the pitch axis motor. The pitch axis motor is further connected to the camera."
"AUTONOMOUS SYSTEM FOR TAKING MOVING IMAGES FROM A DRONE, WITH TARGET TRACKING AND IMPROVED TARGET LOCATION",https://lens.org/165-479-843-424-479,2018,"The displacements of the drone are defined by piloting commands to take moving images of a target carrying the ground station. The system comprises means for adjusting the sight angle of the camera during the displacements of the drone and of the target, so that the images are centred to the target, and means for generating flying instructions so that the distance between drone and target fulfils determined rules, these means being based on a determination of the GPS geographical position of the target with respect to the GPS geographical position of the drone, and of the angular position of the target with respect to a main axis of the drone. These means are also based on the analysis of a non-geographical signal produced by the target and received by the drone. The system allows freeing from the uncertainty of the GPS systems equipping this type of device."
Adaptive rate gain controller,https://lens.org/111-600-247-150-283,2021,"An aerial vehicle comprises one or more sensors to environmental data, a communication system to receive control inputs from a user, two or more actuators, with each actuator coupled to a rotary wing. The aerial vehicle also comprises a controller to determine a mode of the aerial vehicle based on the environmental data and the control inputs, each mode indicating a set of flight characteristics for the aerial vehicle, generate a gain value based on the mode, the gain value, when used to modify power signals transmitted to actuators of the aerial vehicle, causing the aerial vehicle to conform within the indicated flight characteristics of the determined mode, generate an output signal modified by the gain value based on the input signal, and transmit a power signal based on the output signal to each actuator of the aerial vehicle."
"LOAD DEVICE CONTROL METHOD, ADAPTER APPARATUS, UNMANNED AERIAL VEHICLE, AND CONTROL TERMINAL",https://lens.org/073-717-553-855-065,2021,"A load device control method includes an adapter apparatus receiving a control command sent by an unmanned aerial vehicle (UAV) for controlling a load device connected to the UAV via the adapter apparatus, converting a first communication protocol between the UAV and the adapter apparatus into a second communication protocol between the adapter apparatus and the load device, and sending the control command to the load device using the second communication protocol."
UNMANNED AERIAL VEHICLE,https://lens.org/148-370-359-975-791,2021,"An unmanned aerial vehicle includes a main unit having a thrust generating part for flying in air, a suction device that has a suction part and is fixed to the main unit, and a control device that controls operations of the thrust generating part and the suction device such that the suction part is configured to be suctioned to a wall surface by the operation of the suction device to allow the main unit to be attached to the wall surface, wherein a suction state detecting part that detects a suction state of the suction part, is provided, and the control device controls the operation of the thrust generating part based on a detection by the suction state detecting part in suction phase and/or departure phase of the main unit with respect to the wall surface."
LOCATING SIGNAL INTERFERENCE USING UNMANNED AERIAL VEHICLES,https://lens.org/046-297-471-126-590,2021,"An unmanned aerial vehicle (UAV) for detecting, identifying, and locating a source emitting an interfering signal is described herein. The UAV can detect wireless network site interference within a given frequency spectrum band and locate the source of the interference based on one or more signals received by one or more antennas, such as directional antennas. The one or more antennas are located on or within a main body or one or more booms of the UAV. The UAV can be flown manually (e.g., by an operator) or automatically (e.g., by a processor or preset routine)."
Locating signal interference using unmanned aerial vehicles,https://lens.org/019-481-022-435-487,2023,"An unmanned aerial vehicle (UAV) for detecting, identifying, and locating a source emitting an interfering signal is described herein. The UAV can detect wireless network site interference within a given frequency spectrum band and locate the source of the interference based on one or more signals received by one or more antennas, such as directional antennas. The one or more antennas are located on or within a main body or one or more booms of the UAV. The UAV can be flown manually (e.g., by an operator) or automatically (e.g., by a processor or preset routine)."
An armed unmanned aerial vehicle and methods of use thereof,https://lens.org/136-725-319-885-833,2022,"The present invention relates to an armed unmanned aerial vehicle (""UAV""), an armed UAV control system, and methods of use thereof. In one form, the armed UAV includes: an elongate body, a pair opposed side rotor arm assemblies extending from the sides of the body, a tail rotor arm assembly extending from a rear end of the body, a weapons system including at least one firearm associated with the body, and a flight and targeting controller operatively associated with the side rotor arm assemblies and the tail rotor arm assembly. The controller configured to: determine at least a pitch angle and yaw angle required to strike a target with the weapons system, based on target information received; and selectively control operation of each rotor arm assembly for aiming the weapons system, based on at least the pitch angle and the yaw angle determined."
Unmanned aerial vehicle perching maneuver,https://lens.org/050-628-693-526-803,2016,"A personal drone with much extended air time. A portable retractable-extendable clawed drone with automated perching function. Perching, landing on a target horizontal edge or a wire, a building trim, a lamp or sign, a shelf, almost any small horizontal edge with a little surface, for video streaming without using up power on hovering or flight, thus conserving power indefinitely. A veritable fly-on-the-wall multi-rotor drone having mechanical claws and automated perching function."
AN ARMED UNMANNED AERIAL VEHICLE AND METHODS OF USE THEREOF,https://lens.org/135-661-159-552-477,2021,"The present invention relates to an armed unmanned aerial vehicle (""UAV""), an armed UAV control system, and methods of use thereof. In one form, the armed UAV includes: an elongate body, a pair opposed side rotor arm assemblies extending from the sides of the body, a tail rotor arm assembly extending from a rear end of the body, a weapons system including at least one firearm associated with the body, and a flight and targeting controller operatively associated with the side rotor arm assemblies and the tail rotor arm assembly. The controller configured to: determine at least a pitch angle and yaw angle required to strike a target with the weapons system, based on target information received; and selectively control operation of each rotor arm assembly for aiming the weapons system, based on at least the pitch angle and the yaw angle determined."
ROOFTOP DELIVERY RECEPTACLE FOR UNMANNED AERIAL VEHICLES,https://lens.org/170-977-862-604-689,2022,"A rooftop package delivery receptacle for unmanned aerial vehicles (UAV) is transformed from a normally closed downwardly pitched transparent or translucent aesthetically acceptable rooftop aperture, appearing as an ordinary skylight, into a preferably larger substantially horizontal delivery platform providing a safe, secure, above ground location for a drone to land or tether for package delivery. Upon a wireless command signal from either an arriving UAV or a local user, the curb frame mounted receptacle containing a center pivoting platform supporting a plurality of slidably mounted panels rotates upwards and expands both longitudinally and transversely enabling a larger substantially horizontal landing area. After the package is delivered the platform contracts to its original size and continues in an upwards rotation urging the package to move inwards for collection. A pair of weatherproof accordion shaped shudders surround the openings and enclose any gaps during the operation."
ROOFTOP DELIVERY RECEPTACLE FOR UNMANNED AERIAL VEHICLES,https://lens.org/170-977-862-604-689,2022,"A rooftop package delivery receptacle for unmanned aerial vehicles (UAV) is transformed from a normally closed downwardly pitched transparent or translucent aesthetically acceptable rooftop aperture, appearing as an ordinary skylight, into a preferably larger substantially horizontal delivery platform providing a safe, secure, above ground location for a drone to land or tether for package delivery. Upon a wireless command signal from either an arriving UAV or a local user, the curb frame mounted receptacle containing a center pivoting platform supporting a plurality of slidably mounted panels rotates upwards and expands both longitudinally and transversely enabling a larger substantially horizontal landing area. After the package is delivered the platform contracts to its original size and continues in an upwards rotation urging the package to move inwards for collection. A pair of weatherproof accordion shaped shudders surround the openings and enclose any gaps during the operation."
Aerial capture platform,https://lens.org/058-607-574-107-92X,2020,"An unmanned aerial vehicle comprises a housing, a plurality of first arms, a plurality of second arms, and a landing gear. The housing includes a gimbal attachment to couple a gimbal with a camera. Each of the plurality of first arms and the plurality of second arms rotatably couple with the housing at one end and has a motor coupled with a propeller on the other end. The landing gear includes a plurality of foldable legs and releasably couples with an underside of the housing. The aerial vehicle may be programmed with aerial flight path data that corresponds with a prior traced route."
Unmanned aerial vehicle with rotating and overlapping rotor arms,https://lens.org/081-291-533-529-101,2022,"An unmanned aerial vehicle comprises a housing, a plurality of first arms, a plurality of second arms, and a landing gear. The housing includes a gimbal attachment to couple a gimbal with a camera. Each of the plurality of first arms and the plurality of second arms rotatably couple with the housing at one end and has a motor coupled with a propeller on the other end. The landing gear includes a plurality of foldable legs and releasably couples with an underside of the housing. The aerial vehicle may be programmed with aerial flight path data that corresponds with a prior traced route."
Unmanned aerial vehicle with rotating and overlapping rotor arms,https://lens.org/081-291-533-529-101,2022,"An unmanned aerial vehicle comprises a housing, a plurality of first arms, a plurality of second arms, and a landing gear. The housing includes a gimbal attachment to couple a gimbal with a camera. Each of the plurality of first arms and the plurality of second arms rotatably couple with the housing at one end and has a motor coupled with a propeller on the other end. The landing gear includes a plurality of foldable legs and releasably couples with an underside of the housing. The aerial vehicle may be programmed with aerial flight path data that corresponds with a prior traced route."
Aerial Capture Platform,https://lens.org/051-886-679-077-923,2020,"An unmanned aerial vehicle comprises a housing, a plurality of first arms, a plurality of second arms, and a landing gear. The housing includes a gimbal attachment to couple a gimbal with a camera. Each of the plurality of first arms and the plurality of second arms rotatably couple with the housing at one end and has a motor coupled with a propeller on the other end. The landing gear includes a plurality of foldable legs and releasably couples with an underside of the housing. The aerial vehicle may be programmed with aerial flight path data that corresponds with a prior traced route."
Unmanned aerial vehicle with rotating and overlapping rotor arms,https://lens.org/081-291-533-529-101,2022,"An unmanned aerial vehicle comprises a housing, a plurality of first arms, a plurality of second arms, and a landing gear. The housing includes a gimbal attachment to couple a gimbal with a camera. Each of the plurality of first arms and the plurality of second arms rotatably couple with the housing at one end and has a motor coupled with a propeller on the other end. The landing gear includes a plurality of foldable legs and releasably couples with an underside of the housing. The aerial vehicle may be programmed with aerial flight path data that corresponds with a prior traced route."
Aerial Capture Platform,https://lens.org/183-686-280-389-175,2017,"An unmanned aerial vehicle comprises a housing, a plurality of first arms, a plurality of second arms, and a landing gear. The housing includes a gimbal attachment to couple a gimbal with a camera. Each of the plurality of first arms and the plurality of second arms rotatably couple with the housing at one end and has a motor coupled with a propeller on the other end. The landing gear includes a plurality of foldable legs and releasably couples with an underside of the housing. The aerial vehicle may be programmed with aerial flight path data that corresponds with a prior traced route."
Laser weapon mounted on aerial drone,https://lens.org/123-067-851-274-779,2012,A laser weapon is mounted on an aerial drone 3 and is directed by remote control. Combatants may be targeted by live video feed through a focusing camera mounted on a moving gimbal 9. A laser weapon is mounted on a moving gimbal 8 and is synchronised with the focusing camera.
Unmanned aerial vehicle,https://lens.org/184-997-395-592-071,2015,"The invention provides an unmanned aerial vehicle, including a processing unit and an output unit. The output unit is connected to the processing unit. When the unmanned aerial vehicle satisfies preset conditions, the abovementioned output unit plays a corresponding prompt message."
DRONE NAVIGATION AND LANDING,https://lens.org/044-255-238-302-14X,2021,"Methods, systems, and apparatus for drone navigation within a property. A method includes detecting an obstacle in a navigation path of a drone, determining a classification of the obstacle, determining whether to temporarily land based on the classification of the obstacle, and temporarily landing the drone until the obstacle clears the navigation path of the drone."
DRONE RECOVERY SYSTEM,https://lens.org/009-264-437-659-307,2018,"A system for use in the secure recovery, management and storage of a drone can include a housing, at least one electromechanically operated door securing access to the housing and a retractable platform that can electromechanically extend from inside the housing to an area outside the housing when the at least one electromechanically operated door is opened. The retractable platform can serve as a landing pad for a drone and/or as a base onto which a drone can be received. The retractable platform can electromechanically move back into the housing and the door can close after receiving the drone. Communications components, alarms and cameras can also be associated with the housing to facilitate its operation for drone recovery, storage and security."
"ROBOT, ROBOT SYSTEM AND SERVER",https://lens.org/039-257-319-457-002,2016,"A robot controlled by a controller includes a recording part that records sensor information on a sensor, and a transmission part that transmits the sensor information to the controller or an external apparatus."
"Robot, robot system and server",https://lens.org/002-752-716-501-412,2019,"A robot controlled by a controller includes a recording part that records sensor information on a sensor, and a transmission part that transmits the sensor information to the controller or an external apparatus."
Loss mitigation implementing unmanned aerial vehicles (UAVS),https://lens.org/118-978-323-207-472,2021,"Unmanned aerial vehicles (UAVs) may facilitate insurance-related tasks. UAVs may actively be dispatched to an insured asset and the area surrounding an insured asset, such as with the policyholder or insured's permission and collect data related to the insured asset, such as images, video, audio, weather conditions, thermal signatures, wood and soil samples, etc., and transmit this data to a computing device. The computing device may be associated with and/or utilized by an insurance provider to perform insurance-related tasks, such as processing the data to determine an amount of risk associated with the insured asset. If the amount of risk has increased, the computing device may provide a recommendation to a mobile device of the policyholder on how to reduce the risk such that corrective action may be taken. Insurance discounts may be provided based upon following recommendations that mitigate risk."
Loss mitigation implementing unmanned aerial vehicles (UAVs),https://lens.org/043-139-059-234-175,2018,"Unmanned aerial vehicles (UAVs) may facilitate insurance-related tasks. UAVs may actively be dispatched to an insured asset and the area surrounding an insured asset, such as with the policyholder or insured's permission and collect data related to the insured asset, such as images, video, audio, weather conditions, thermal signatures, wood and soil samples, etc., and transmit this data to a computing device. The computing device may be associated with and/or utilized by an insurance provider to perform insurance-related tasks, such as processing the data to determine an amount of risk associated with the insured asset. If the amount of risk has increased, the computing device may provide a recommendation to a mobile device of the policyholder on how to reduce the risk such that corrective action may be taken. Insurance discounts may be provided based upon following recommendations that mitigate risk."
Loss mitigation implementing unmanned aerial vehicles (UAVs),https://lens.org/130-286-923-731-312,2019,"Unmanned aerial vehicles (UAVs) may facilitate insurance-related tasks. UAVs may actively be dispatched to an insured asset and the area surrounding an insured asset, such as with the policyholder or insured's permission and collect data related to the insured asset, such as images, video, audio, weather conditions, thermal signatures, wood and soil samples, etc., and transmit this data to a computing device. The computing device may be associated with and/or utilized by an insurance provider to perform insurance-related tasks, such as processing the data to determine an amount of risk associated with the insured asset. If the amount of risk has increased, the computing device may provide a recommendation to a mobile device of the policyholder on how to reduce the risk such that corrective action may be taken. Insurance discounts may be provided based upon following recommendations that mitigate risk."
Loss mitigation implementing unmanned aerial vehicles (UAVs),https://lens.org/071-970-086-548-870,2020,"Unmanned aerial vehicles (UAVs) may facilitate insurance-related tasks. UAVs may actively be dispatched to an insured asset and the area surrounding an insured asset, such as with the policyholder or insured's permission and collect data related to the insured asset, such as images, video, audio, weather conditions, thermal signatures, wood and soil samples, etc., and transmit this data to a computing device. The computing device may be associated with and/or utilized by an insurance provider to perform insurance-related tasks, such as processing the data to determine an amount of risk associated with the insured asset. If the amount of risk has increased, the computing device may provide a recommendation to a mobile device of the policyholder on how to reduce the risk such that corrective action may be taken. Insurance discounts may be provided based upon following recommendations that mitigate risk."
DRONE COORDINATION,https://lens.org/059-752-158-070-782,2017,"A system for drone coordination includes logic to detect an adverse weather condition and detect a plurality of drones operating in a region to be affected by the adverse weather condition. The logic can also transmit a request to the plurality of drones, wherein the request indicates that each of the plurality of drones is to return to an emergency landing site to be selected from a set of predetermined emergency landing sites. The emergency landing site for each drone can be based in part on the location of the drone at the time of transmittal of the request."
Drone coordination,https://lens.org/093-759-017-098-671,2018,"A system for drone coordination includes logic to detect an adverse weather condition and detect a plurality of drones operating in a region to be affected by the adverse weather condition. The logic can also transmit a request to the plurality of drones, wherein the request indicates that each of the plurality of drones is to return to an emergency landing site to be selected from a set of predetermined emergency landing sites. The emergency landing site for each drone can be based in part on the location of the drone at the time of transmittal of the request."
ACCIDENTAL VOICE TRIGGER AVOIDANCE USING THERMAL DATA,https://lens.org/098-813-356-157-310,2023,"Methods and systems for processing voice commands are disclosed. A voice controlled device may receive audio data comprising a voice command. Location information indicative of the source of the audio data may be determined. One or more devices may be caused to determine signals based on the location information. The one or more devices may receive thermal data in response to the signals. The thermal data may be analyzed to determine if the thermal data indicates the presence of a person at the expected location. If a person is detected, then the audio data may processed to cause the voice command to be executed."
ACCIDENTAL VOICE TRIGGER AVOIDANCE USING THERMAL DATA,https://lens.org/164-573-104-429-30X,2023,"Methods and systems for processing voice commands are disclosed. A voice controlled device may receive audio data comprising a voice command. Location information indicative of the source of the audio data may be determined. One or more devices may be caused to determine signals based on the location information. The one or more devices may receive thermal data in response to the signals. The thermal data may be analyzed to determine if the thermal data indicates the presence of a person at the expected location. If a person is detected, then the audio data may processed to cause the voice command to be executed."
ACCIDENTAL VOICE TRIGGER AVOIDANCE USING THERMAL DATA,https://lens.org/164-573-104-429-30X,2023,"Methods and systems for processing voice commands are disclosed. A voice controlled device may receive audio data comprising a voice command. Location information indicative of the source of the audio data may be determined. One or more devices may be caused to determine signals based on the location information. The one or more devices may receive thermal data in response to the signals. The thermal data may be analyzed to determine if the thermal data indicates the presence of a person at the expected location. If a person is detected, then the audio data may processed to cause the voice command to be executed."
ACCIDENTAL VOICE TRIGGER AVOIDANCE USING THERMAL DATA,https://lens.org/098-813-356-157-310,2023,"Methods and systems for processing voice commands are disclosed. A voice controlled device may receive audio data comprising a voice command. Location information indicative of the source of the audio data may be determined. One or more devices may be caused to determine signals based on the location information. The one or more devices may receive thermal data in response to the signals. The thermal data may be analyzed to determine if the thermal data indicates the presence of a person at the expected location. If a person is detected, then the audio data may processed to cause the voice command to be executed."
Methods and systems for data collection by drone aircraft,https://lens.org/045-571-330-632-804,2021,"A data collection method and system for a drone aircraft. The system includes a data collection device, an extension mechanism having one end connected to the drone aircraft and an opposite free end connected to the data collection device, and a control system for controlling operation of the extension mechanism. The extension mechanism is extendable from a retracted position in which the data collection device is stowed in or maintained proximate to the drone aircraft to one or more extended positions in which the data collection device is extended away from the drone aircraft, and is also retractable to bring the data collection device back to the retracted position. The control system controls operation of the extension mechanism to position the data collection device to a desired position beyond a given obstacle to enable the data collection device to capture data relating to an object or region of interest."
METHODS AND SYSTEMS FOR DATA COLLECTION BY DRONE AIRCRAFT,https://lens.org/193-034-888-813-893,2019,"A data collection method and system for a drone aircraft. The system includes a data collection device, an extension mechanism having one end connected to the drone aircraft and an opposite free end connected to the data collection device, and a control system for controlling operation of the extension mechanism. The extension mechanism is extendable from a retracted position in which the data collection device is stowed in or maintained proximate to the drone aircraft to one or more extended positions in which the data collection device is extended away from the drone aircraft, and is also retractable to bring the data collection device back to the retracted position. The control system controls operation of the extension mechanism to position the data collection device to a desired position beyond a given obstacle to enable the data collection device to capture data relating to an object or region of interest."
METHODS AND SYSTEMS FOR DATA COLLECTION BY DRONE AIRCRAFT,https://lens.org/109-792-580-153-151,2021,"A data collection method and system for a drone aircraft. The system includes a data collection device, an extension mechanism having one end connected to the drone aircraft and an opposite free end connected to the data collection device, and a control system for controlling operation of the extension mechanism. The extension mechanism is extendable from a retracted position in which the data collection device is stowed in or maintained proximate to the drone aircraft to one or more extended positions in which the data collection device is extended away from the drone aircraft, and is also retractable to bring the data collection device back to the retracted position. The control system controls operation of the extension mechanism to position the data collection device to a desired position beyond a given obstacle to enable the data collection device to capture data relating to an object or region of interest."
Capturing media moments of people using an aerial camera system,https://lens.org/053-929-827-524-183,2020,Various systems and methods for capturing media moments are described herein. An autonomous camera system for capturing media moments includes a configuration module to receive configuration parameters; a flight control module to autonomously maneuver the autonomous camera system over a crowd of people; a search module to search for a subject in the crowd of people based on the configuration parameters; and a control module to perform an action when the subject is found in the crowd of people.
CAPTURING MEDIA MOMENTS,https://lens.org/046-326-424-776-603,2016,Various systems and methods for capturing media moments are described herein. An autonomous camera system for capturing media moments includes a configuration module to receive configuration parameters; a flight control module to autonomously maneuver the autonomous camera system over a crowd of people; a search module to search for a subject in the crowd of people based on the configuration parameters; and a control module to perform an action when the subject is found in the crowd of people.
DEVICE AND METHOD OF ANTI-UNMANNED AERIAL VEHICLE BASED ON MULTI-CAMERA TRACKING AND POSITIONING,https://lens.org/132-309-089-647-478,2021,"A device and a method of anti-unmanned aerial vehicle based on multi-camera tracking and positioning, including: a bracket, defined a center, a circumference surrounding the center and a central axis passing through the center; at least three cameras, the cameras are evenly distributed and inclined outwardly on the circumference of the bracket, and center lines of view of the cameras forms an inverted cone; a directional antenna, configured to be arranged on the central axis of the bracket; an electromagnetic module, configured to be coupled to the directional antenna; a pan-tilt, connected to the center of the bracket and configured to drive the bracket to rotate; and a control unit, configured to control the pan-tilt to track a target and lock on to the target according to the video image provided by the cameras, such that the electromagnetic module is manipulated to attack the target."
Device and method of anti-unmanned aerial vehicle based on multi-camera tracking and positioning,https://lens.org/018-611-247-940-536,2023,"A device and a method of anti-unmanned aerial vehicle based on multi-camera tracking and positioning, including: a bracket, defined a center, a circumference surrounding the center and a central axis passing through the center; at least three cameras, the cameras are evenly distributed and inclined outwardly on the circumference of the bracket, and center lines of view of the cameras forms an inverted cone; a directional antenna, configured to be arranged on the central axis of the bracket; an electromagnetic module, configured to be coupled to the directional antenna; a pan-tilt, connected to the center of the bracket and configured to drive the bracket to rotate; and a control unit, configured to control the pan-tilt to track a target and lock on to the target according to the video image provided by the cameras, such that the electromagnetic module is manipulated to attack the target."
Device and method of anti-unmanned aerial vehicle based on multi-camera tracking and positioning,https://lens.org/018-611-247-940-536,2023,"A device and a method of anti-unmanned aerial vehicle based on multi-camera tracking and positioning, including: a bracket, defined a center, a circumference surrounding the center and a central axis passing through the center; at least three cameras, the cameras are evenly distributed and inclined outwardly on the circumference of the bracket, and center lines of view of the cameras forms an inverted cone; a directional antenna, configured to be arranged on the central axis of the bracket; an electromagnetic module, configured to be coupled to the directional antenna; a pan-tilt, connected to the center of the bracket and configured to drive the bracket to rotate; and a control unit, configured to control the pan-tilt to track a target and lock on to the target according to the video image provided by the cameras, such that the electromagnetic module is manipulated to attack the target."
Novel autonomous navigation four-rotor aircraft,https://lens.org/011-733-836-414-957,2015,"The utility model discloses a novel autonomous navigation four-rotor aircraft. The aircraft includes a camera, a laser sensor, a ultrasonic wave sensor, a temperature sensor, a humidity sensor, an air pressure sensor, a data collecting and processing module, a control module connected with a remote computer through a wireless transceiving module and a flight motion module whose brushless motor is connected with the control module. The camera is arranged exactly below a cabin. The sensors are mounted on the outer periphery of the cabin. The control module controls the flight motion module to command flight based on a flight path scheduled by the data collecting and processing module. The novel autonomous navigation four-rotor aircraft has advantages that autonomous navigation for the aircraft is realized and the flight path is the optimal one. Besides, environmental information and flight path of the aircraft are transmitted to the remote computer through the wireless transceiving module, so that data can be shared among different platforms. Moreover, the remote computer can control the aircraft remotely in particular cases, so that safety of the aircraft is guaranteed."
SYSTEM FOR USE WITH A DRONE DELIVERY SERVICE AND METHODS FOR USE THEREWITH,https://lens.org/094-531-763-658-066,2022,"A system can be used with a drone delivery service that facilitates a service delivery via at least one drone delivery device. The system includes a code generator configured to generate beacon data that identifies a subscriber. A beacon generator is configured to generate a wireless homing beacon that indicates the beacon data, wherein the wireless homing beacon is detectable by the at least one drone delivery device to facilitate the service delivery to the subscriber by the drone delivery device at a location selected by the subscriber and a network interface is configured to communicate via a network. The system receives delivery image data captured after the service delivery by the drone delivery device."
SYSTEM FOR USE WITH A DRONE DELIVERY SERVICE AND METHODS FOR USE THEREWITH,https://lens.org/094-531-763-658-066,2022,"A system can be used with a drone delivery service that facilitates a service delivery via at least one drone delivery device. The system includes a code generator configured to generate beacon data that identifies a subscriber. A beacon generator is configured to generate a wireless homing beacon that indicates the beacon data, wherein the wireless homing beacon is detectable by the at least one drone delivery device to facilitate the service delivery to the subscriber by the drone delivery device at a location selected by the subscriber and a network interface is configured to communicate via a network. The system receives delivery image data captured after the service delivery by the drone delivery device."
DRONE ALERTING AND REPORTING SYSTEM,https://lens.org/193-084-463-831-004,2018,"A system and method to alter pilots of the presence of drone aircraft and to document or report errant drone flight operations, in particular to alert and report drone aircraft which may present a hazard to a piloted aircraft and/or are operating outside governing regulations. In one embodiment, the system comprises a surveillance subsystem configured to identify a drone operating in an airspace adjacent the aircraft; an imaging subsystem configured to acquire at least one image of the drone; a triggering subsystem interconnected with the surveillance subsystem and configured to activate the imaging subsystem; a navigational subsystem configured to provide aircraft state data associated with the at least one image; and a communication subsystem configured to transmit the at least one image and the associated aircraft state data to a receiving station; wherein the at least one image and the associated aircraft state data are transmitted to the receiving station."
Drone alerting and reporting system,https://lens.org/135-175-009-488-613,2018,"A system and method to alter pilots of the presence of drone aircraft and to document or report errant drone flight operations, in particular to alert and report drone aircraft which may present a hazard to a piloted aircraft and/or are operating outside governing regulations. In one embodiment, the system comprises a surveillance subsystem configured to identify a drone operating in an airspace adjacent the aircraft; an imaging subsystem configured to acquire at least one image of the drone; a triggering subsystem interconnected with the surveillance subsystem and configured to activate the imaging subsystem; a navigational subsystem configured to provide aircraft state data associated with the at least one image; and a communication subsystem configured to transmit the at least one image and the associated aircraft state data to a receiving station; wherein the at least one image and the associated aircraft state data are transmitted to the receiving station."
Method and device for controlling and monitoring the surrounding areas of an unmanned aerial vehicle,https://lens.org/008-004-083-514-268,2016,The embodiments herein disclose a method and a remote control for controlling and monitoring surrounding areas of an Unmanned Aerial Vehicle (UAV) by an operator with a remote control comprising a flight display. The embodiments disclose combining the image captured by a UAV camera with a transparently overlaid positional and navigation map providing a perceptual view enabling the operator to have a complete overall view of the situation. Observation images overlaid by positional and navigation information in the way described has shown surprising and advantageous effects.
METHOD AND DEVICE FOR CONTROLLING AND MONITORING THE SURROUNDING AREAS OF AN UNMANNED AERIAL VEHICLE,https://lens.org/076-572-081-684-601,2013,The embodiments herein disclose a method and a remote control for controlling and monitoring surrounding areas of an Unmanned Aerial Vehicle (UAV) by an operator with a remote control comprising a flight display. The embodiments disclose combining the image captured by a UAV camera with a transparently overlaid positional and navigation map providing a perceptual view enabling the operator to have a complete overall view of the situation. Observation images overlaid by positional and navigation information in the way described has shown surprising and advantageous effects.
Method and device for controlling and monitoring the surrounding areas of an unmanned aerial vehicle,https://lens.org/086-316-392-236-611,2014,The embodiments herein disclose a method and a remote control for controlling and monitoring surrounding areas of an Unmanned Aerial Vehicle (UAV) by an operator with a remote control comprising a flight display. The embodiments disclose combining the image captured by a UAV camera with a transparently overlaid positional and navigation map providing a perceptual view enabling the operator to have a complete overall view of the situation. Observation images overlaid by positional and navigation information in the way described has shown surprising and advantageous effects.
DRONE FOR CLEANING OUTER WALL OF HIGH-RISE BUILDING,https://lens.org/169-920-604-685-559,2022,"A drone for cleaning an outer wall of a high-rise building is configured to float and move in the air. The drone includes a drone main body and a floating transfer unit for floating and moving the drone main body in the art. The drone main body has a camera unit provided to photograph the exterior of a building and driving wheels on one surface thereof to be guide to the exterior of the building. The drone main body further has a buffer angle member to cushion an impact with the building and a washing nozzle unit which sprays water onto and washes the exterior of the building. Accordingly, by cleaning the exterior or a window of a skyscraper using the drone, there are the effects of reducing the costs of cleaning a skyscraper, simplifying a cleaning operation, preventing human accidents due to falls, and reducing cleaning time."
DRONE FOR CLEANING OUTER WALL OF HIGH-RISE BUILDING,https://lens.org/169-920-604-685-559,2022,"A drone for cleaning an outer wall of a high-rise building is configured to float and move in the air. The drone includes a drone main body and a floating transfer unit for floating and moving the drone main body in the art. The drone main body has a camera unit provided to photograph the exterior of a building and driving wheels on one surface thereof to be guide to the exterior of the building. The drone main body further has a buffer angle member to cushion an impact with the building and a washing nozzle unit which sprays water onto and washes the exterior of the building. Accordingly, by cleaning the exterior or a window of a skyscraper using the drone, there are the effects of reducing the costs of cleaning a skyscraper, simplifying a cleaning operation, preventing human accidents due to falls, and reducing cleaning time."
POSITIONING APPARATUS FOR PHOTOGRAPHIC AND VIDEO IMAGING AND RECORDING AND SYSTEM UTILIZING SAME,https://lens.org/131-830-243-041-679,2015,"A multi-axis positioning device adapted to hold and position an electronic device such as a smart phone. A system using the positioning device and a smart phone adapted to utilize the smart phone to provide positioning commands to the positioning device. The system may provide positioning commands based upon pre-programmed instructions, or may position based upon analysis of the images being taken in real time."
Remote-control device,https://lens.org/076-803-301-434-15X,2017,"A remote-control device (10) comprises: an orientation sensor (44) that detects the flying orientation of an unmanned helicopter (1); a GPS antenna (40) and a GPS reception unit (42) for detecting velocity information of the unmanned helicopter (1); and a CPU (34a) that detects a flying distance of the unmanned helicopter (1) by integrating the velocity information. Information at a base point of the unmanned helicopter (1) is stored in a memory (34b). On the basis of the flying orientation of the unmanned helicopter (1) and the flying distance of the unmanned helicopter (1) obtained by integrating the velocity information, the CPU (34a) detects a relative position indicating the position of the unmanned helicopter (1) with respect to the base point, and controls the flying of the unmanned helicopter (1) on the basis of the relative position."
Remote control device,https://lens.org/137-153-956-981-33X,2018,"A remote-control device (10) comprises: an orientation sensor (44) that detects the flying orientation of an unmanned helicopter (1); a GPS antenna (40) and a GPS reception unit (42) for detecting velocity information of the unmanned helicopter (1); and a CPU (34a) that detects a flying distance of the unmanned helicopter (1) by integrating the velocity information. Information at a base point of the unmanned helicopter (1) is stored in a memory (34b). On the basis of the flying orientation of the unmanned helicopter (1) and the flying distance of the unmanned helicopter (1) obtained by integrating the velocity information, the CPU (34a) detects a relative position indicating the position of the unmanned helicopter (1) with respect to the base point, and controls the flying of the unmanned helicopter (1) on the basis of the relative position."
Scheduling and control system for autonomous robots,https://lens.org/152-816-137-515-798,2023,"An autonomous cleaning robot including a drive configured to move the cleaning robot across a floor surface in an area to be cleaned and a controller. The controller is configured to receive data representing an editable mission timeline including data representing a sequence of rooms to be cleaned, navigate the cleaning robot to clean the rooms following the sequence, track operational events occurring in each of the rooms, and transmit data about time spent navigating each room included in the sequence."
Scheduling and control system for autonomous robots,https://lens.org/152-816-137-515-798,2023,"An autonomous cleaning robot including a drive configured to move the cleaning robot across a floor surface in an area to be cleaned and a controller. The controller is configured to receive data representing an editable mission timeline including data representing a sequence of rooms to be cleaned, navigate the cleaning robot to clean the rooms following the sequence, track operational events occurring in each of the rooms, and transmit data about time spent navigating each room included in the sequence."
SCHEDULING AND CONTROL SYSTEM FOR AUTONOMOUS ROBOTS,https://lens.org/176-964-903-189-545,2018,"An autonomous cleaning robot including a drive configured to move the cleaning robot across a floor surface in an area to be cleaned and a controller. The controller is configured to receive data representing an editable mission timeline including data representing a sequence of rooms to be cleaned, navigate the cleaning robot to clean the rooms following the sequence, track operational events occurring in each of the rooms, and transmit data about time spent navigating each room included in the sequence."
SCHEDULING AND CONTROL SYSTEM FOR AUTONOMOUS ROBOTS,https://lens.org/072-483-641-291-209,2021,"An autonomous cleaning robot including a drive configured to move the cleaning robot across a floor surface in an area to be cleaned and a controller. The controller is configured to receive data representing an editable mission timeline including data representing a sequence of rooms to be cleaned, navigate the cleaning robot to clean the rooms following the sequence, track operational events occurring in each of the rooms, and transmit data about time spent navigating each room included in the sequence."
SCHEDULING AND CONTROL SYSTEM FOR AUTONOMOUS ROBOTS,https://lens.org/108-197-014-363-565,2023,"An autonomous cleaning robot including a drive configured to move the cleaning robot across a floor surface in an area to be cleaned and a controller. The controller is configured to receive data representing an editable mission timeline including data representing a sequence of rooms to be cleaned, navigate the cleaning robot to clean the rooms following the sequence, track operational events occurring in each of the rooms, and transmit data about time spent navigating each room included in the sequence."
UNMANNED AERIAL VEHICLES,https://lens.org/001-160-547-106-36X,2019,"An unmanned aerial vehicle 100, UAV, comprises (i) a camera 105 having a field of vision including, in use, a portion of a vehicle 200 to be cleaned, (ii) a liquid container 110 comprising waterless carwash liquid, (iii) a liquid dispenser 115 operable to cause the waterless carwash liquid comprised in the liquid container 110 to be dispensed from the liquid container 110, (iv) a cleaning implement 120, and (v) a controller 125 communicatively coupled to the camera 105, the liquid dispenser 115 and the cleaning implement 120. The controller 125 is operable (a) to cause the liquid dispenser 115 to dispense the waterless carwash liquid from the liquid container 110 onto the portion of the vehicle 200 to be cleaned and (b) to control the cleaning implement 120 to clean the portion of the vehicle 200 to be cleaned."
Autonomous action robot,https://lens.org/185-593-515-082-427,2005,"An autonomous action robot which can turn its line of sight to face a person who calls out, can recognize the face of a person, and can perform various actions in response to commands. First, a sound emitted from a person or other sound source is detected by a sound detector, and the direction of the sound source is specified based on the detected sound. Then, a robot head section is controlled, and the imaging direction of the robot head section is moved to face the specified direction of the sound source. Next, an image is captured in the direction of the sound source, and a target image of a specific shape is extracted from the captured image. Then, the imaging direction of the robot head section is controlled and moved to face in the direction of the extracted target image."
METHOD AND APPARATUS FOR CONTROLLING CONTENT RECORDING DEVICE,https://lens.org/011-907-959-009-684,2009,"A method of controlling a content recording device, by generating control commands in a uniform resource identifier (URI) format and controlling the content recording device according to the generated control command(s), is provided."
AUTOMATED DRONE CHARGING STATION,https://lens.org/124-362-347-740-222,2020,"A drone charging station configured to receive at least one drone, the docking station including an elongated docking shaft sized to engage with the at least one drone, the docking shaft having a drone entrance end and a drone exit end opposite the drone entrance end; and a drone guiding thread helically disposed along the elongated docking shaft, the drone guiding thread configured to engage with a corresponding guiding region on the at least one drone to allow the at least drone to move along the drone guiding thread from the drone entrance end to the drone exit end."
AUTOMATED DRONE CHARGING STATION,https://lens.org/073-706-564-660-091,2018,"A drone charging station configured to receive at least one drone, the docking station including an elongated docking shaft sized to engage with the at least one drone, the docking shaft having a drone entrance end and a drone exit end opposite the drone entrance end; and a drone guiding thread helically disposed along the elongated docking shaft, the drone guiding thread configured to engage with a corresponding guiding region on the at least one drone to allow the at least drone to move along the drone guiding thread from the drone entrance end to the drone exit end."
Autonomous vehicle passenger locator,https://lens.org/195-795-387-759-613,2017,"A first computer (SCU fig. 2) is programmed to send parameters describing a target passenger 18 to a mobile drone 14. The system instructs the drone to circumnavigate a search area 21 while searching said area for the target passenger with an image capturing device 15. The system receives communications 16 from the drone and confirms a match to the target passenger and instructs the drone to guide the target passenger to a destination e.g. a vehicle 10. The drone may be stored in or on the vehicle and launched from the vehicle. The target passenger parameters may include facial recognition parameters and the first computer may receive in the communication a video feed from the drone. The drone may provide a light or aural signal to the passenger. The vehicle may be autonomous and is dispatched to pick up a passenger, the drone may be a flying drone which can position itself a few meters from the vehicle and search through a crowd of people in a rendezvous area."
Method and system for controlling home assistant devices,https://lens.org/023-958-562-848-901,2020,System and method for controlling a home assistant device include: receiving an audio input; performing speaker recognition on the audio input; in accordance with a determination that the audio input includes a voice input from a first user that is authorized to control the home assistant device: performing speech-to-text conversion on the audio input to obtain a textual string; and searching for a predefined trigger word for activating the home assistant device in the textual string; and in accordance with a determination that the audio input includes a voice input from the home assistant device: forgoing performance of speech-to-text conversion on the audio input; and forgoing search for the predefined trigger word.
METHOD AND SYSTEM FOR CONTROLLING HOME ASSISTANT DEVICES,https://lens.org/009-914-856-033-941,2019,System and method for controlling a home assistant device include: receiving an audio input; performing speaker recognition on the audio input; in accordance with a determination that the audio input includes a voice input from a first user that is authorized to control the home assistant device: performing speech-to-text conversion on the audio input to obtain a textual string; and searching for a predefined trigger word for activating the home assistant device in the textual string; and in accordance with a determination that the audio input includes a voice input from the home assistant device: forgoing performance of speech-to-text conversion on the audio input; and forgoing search for the predefined trigger word.
Systems and devices to control antenna azimuth orientation in an omni-directional unmanned aerial vehicle,https://lens.org/008-791-956-993-014,2018,"An unmanned aerial vehicle (UAV) system comprises a drone 100 and a base station 170. The drone has a fixed, directional antenna 124, a rotational orientation detector, an absolute location detection system and a flight control system. The base has an RF transceiver and an absolute location detection system in wireless communication with the drone. Either the drone or the base also has an azimuth computation unit. The base is configured to receive the drones absolute location data, which may be from the drones rotational orientation detector, and calculate the drones orientation. The drone may have a yaw corrector. The claimed method includes the steps of: establishing a wireless communication link between the base and the drone; determining a location and orientation of the drone; calculating an instruction for the flight control system to change one or more of a pitch, roll and yaw of the drone in order to change the orientation of the antenna. Preferably the instruction is generated, and sent to the drone from the base, in response to the calculated drones orientation and/or location."
"AUTONOMOUS STRATOSPHERIC LIGHTER-THAN-AIR AIRCRAFT AND METHOD FOR PROVIDING RADIO AND OPTICAL COMMUNICATION, TELEVISION BROADCASTING AND MONITORING",https://lens.org/077-293-172-823-106,2012,"The invention relates to an autonomous stratospheric aircraft which is lighter than air, and to a method for providing radio and optical communication, television broadcasting and monitoring with the aid of communication equipment arranged on the aircraft. The present invention can be used for producing lighter-than-air aircraft as well as global and regional communication and television broadcasting and multi-aspect monitoring systems and networks."
Aerial delivery of chemicals for swimming pools and spas,https://lens.org/099-124-691-678-386,2023,"Airborne unmanned autonomous vehicles (UAVs) may be used to hover over swimming pools or spas and dispense chemicals (or other materials or devices) directly thereinto. UAVs alternatively or additionally may include sensors designed to identify certain characteristics of pools or spas or of the water therein. The UAVs further may hover over, or land on, pool pads or other areas adjacent or near a pool or spa to deliver or receive parts or other objects."
"DEVICE, SYSTEM AND METHOD FOR INSTALLING AN OBJECT ON A POWER LINE",https://lens.org/168-717-948-303-614,2021,"A drone is for installing an object on a power line. The drone has a connection means for connecting the drone to the object, so that the drone may carry the object. A first engagement member is for engaging a second engagement member on the object. A power source is for operating the first engagement member so as to actuate a locking means on the object, via the second engagement member, for securely locking the object to the power line. The drone further has a device for limiting one or more degrees of freedom of the object relative to the power line before engaging the locking means."
Unmanned moving vehicle piloting method and unmanned moving vehicle watching device,https://lens.org/100-486-615-002-60X,2019,"An unmanned moving vehicle piloting method and an unmanned moving vehicle watching device enabling it to pilot an unmanned moving vehicle, while keeping in visual contact with the vehicle from the vicinity of the vehicle from a third person viewpoint. In the vicinity of an unmanned moving vehicle, a watching aircraft is positioned, which is an unmanned aerial vehicle and includes a single or a plurality of rotors and image capturing means capable of capturing an image of surroundings of the watching aircraft and is able to stand still at one point in the air and piloting the unmanned moving vehicle, while viewing a third person viewpoint image captured by the watching aircraft. Moreover, the watching aircraft includes accompanying flight means for causing the watching aircraft to fly automatically, following movement of an unmanned moving vehicle. This enables the manipulator to concentrate solely on piloting the unmanned moving vehicle."
UNMANNED MOVING VEHICLE PILOTING METHOD AND UNMANNED MOVING VEHICLE WATCHING DEVICE,https://lens.org/117-167-912-739-754,2018,"An unmanned moving vehicle piloting method and an unmanned moving vehicle watching device enabling it to pilot an unmanned moving vehicle, while keeping in visual contact with the vehicle from the vicinity of the vehicle from a third person viewpoint. In the vicinity of an unmanned moving vehicle, a watching aircraft is positioned, which is an unmanned aerial vehicle and includes a single or a plurality of rotors and image capturing means capable of capturing an image of surroundings of the watching aircraft and is able to stand still at one point in the air and piloting the unmanned moving vehicle, while viewing a third person viewpoint image captured by the watching aircraft. Moreover, the watching aircraft includes accompanying flight means for causing the watching aircraft to fly automatically, following movement of an unmanned moving vehicle. This enables the manipulator to concentrate solely on piloting the unmanned moving vehicle."
INTENT BASED CONTROL OF A ROBOTIC DEVICE,https://lens.org/048-021-510-455-633,2022,"A method performed by an autonomous device includes identifying a current movement of an operator based on monitoring the operator of the autonomous device. The method also includes inferring an intended direction of travel for the autonomous device based identifying the current movement. The method further includes identifying one or more objects in a current environment and limitations of the current environment. The method still further includes determining the action to be performed based on inferring the intended direction of travel and also identifying the one or more objects and the limitations of the current environment. The method also includes performing, by the autonomous device, the action."
INTENT BASED CONTROL OF A ROBOTIC DEVICE,https://lens.org/048-021-510-455-633,2022,"A method performed by an autonomous device includes identifying a current movement of an operator based on monitoring the operator of the autonomous device. The method also includes inferring an intended direction of travel for the autonomous device based identifying the current movement. The method further includes identifying one or more objects in a current environment and limitations of the current environment. The method still further includes determining the action to be performed based on inferring the intended direction of travel and also identifying the one or more objects and the limitations of the current environment. The method also includes performing, by the autonomous device, the action."
DRONE-CARRIER BROKERING,https://lens.org/074-672-275-895-453,2018,"In an example, there is disclosed a drone operator computing apparatus having: a network interface; and one or more logic elements providing a broker agent to: communicatively couple to a drone brokerage engine via the network interface; send a carrier request comprising a request for a carrier to carry a drone through a prohibitive zone; receive a brokered carrier response comprising an engage point; and dispatch the drone to the engage point. There is also disclosed a drone having a navigation engine to proceed to the engage point and engage a carrier. There is also disclosed a brokerage engine to broker a carrier request from the drone operator, receive a carrier response from a carrier operator, and broker the carrier response."
A METHOD FOR PAIRING A REMOTE CONTROLLER WITH A DEVICE,https://lens.org/113-089-701-413-977,2022,"A method for pairing a remote controller (51) with a device (100), the method comprising: receiving (301), via a voice interface (120), an activation phrase; checking (302) whether the application phrase is received from within an allowable activation angle (12, 22, 32); if so, receiving (306), via a remote controller interface (130), a command from the remote controller (51), wherein the command includes a remote controller identifier; storing (307) the remote controller identifier as an identifier of a paired remote controller."
A METHOD FOR PAIRING A REMOTE CONTROLLER WITH A DEVICE,https://lens.org/113-089-701-413-977,2022,"A method for pairing a remote controller (51) with a device (100), the method comprising: receiving (301), via a voice interface (120), an activation phrase; checking (302) whether the application phrase is received from within an allowable activation angle (12, 22, 32); if so, receiving (306), via a remote controller interface (130), a command from the remote controller (51), wherein the command includes a remote controller identifier; storing (307) the remote controller identifier as an identifier of a paired remote controller."
Method and Apparatus for Overexposing Images Captured by Drones,https://lens.org/197-558-771-375-626,2019,"A device for nullifying images captured by drones utilizing a high power light to overexpose said images. One or more cameras installed in the device capture images of the area surrounding the device. Computer vision and deep learning are utilized to identify drones in the captured images. If a drone is identified, the location thereof is estimated. A high power light installed in the device is directed at the estimated location of the drone to overexpose any images that are being taken of the area around the device by the drone."
Method and apparatus for overexposing images captured by drones,https://lens.org/056-274-129-392-587,2020,"A device for nullifying images captured by drones utilizing a high power light to overexpose said images. One or more cameras installed in the device capture images of the area surrounding the device. Computer vision and deep learning are utilized to identify drones in the captured images. If a drone is identified, the location thereof is estimated. A high power light installed in the device is directed at the estimated location of the drone to overexpose any images that are being taken of the area around the device by the drone."
Drone captcha,https://lens.org/092-713-043-941-722,2020,"A request to determine a drone's capability may be received. A request type of the request and service context may be determined. A challenge may be generated based on the request type and the service context. The challenge may be presented to a drone and causing the drone to attempt the challenge. Information may be received from the drone, the information indicating the drone's response to the challenge attempted by the drone. The drone may be controlled to perform a given task or not perform the given task, based on the information."
DRONE CAPTCHA,https://lens.org/063-226-187-523-693,2019,"A request to determine a drone's capability may be received. A request type of the request and service context may be determined. A challenge may be generated based on the request type and the service context. The challenge may be presented to a drone and causing the drone to attempt the challenge. Information may be received from the drone, the information indicating the drone's response to the challenge attempted by the drone. The drone may be controlled to perform a given task or not perform the given task, based on the information."
"Method for specifying position, terminal device, autonomous device, and program",https://lens.org/087-005-921-094-128,2019,"A method for controlling an autonomous device that moves in two dimensions using a controller includes obtaining a first image at a first position, which is a destination of the autonomous device, calculating, from the first image, first feature values indicating certain characteristics of the first image, referring to map information indicating correspondences between coordinate information indicating coordinates of defined positions included in a movement area of the autonomous device and second feature values, which are calculated from second images and indicate certain characteristics of the second images and identifying, by referring to the map information, a second position corresponding to second feature values having at least a predetermined degree of correspondence to the feature values generating a command for moving the autonomous device to the second position on the basis of coordinate information corresponding to the second position, and transmitting the command to the autonomous device."
"METHOD FOR SPECIFYING POSITION, TERMINAL DEVICE, AUTONOMOUS DEVICE, AND PROGRAM",https://lens.org/111-913-012-248-427,2017,"A method for controlling an autonomous device that moves in two dimensions using a controller includes obtaining a first image at a first position, which is a destination of the autonomous device, calculating, from the first image, first feature values indicating certain characteristics of the first image, referring to map information indicating correspondences between coordinate information indicating coordinates of defined positions included in a movement area of the autonomous device and second feature values, which are calculated from second images and indicate certain characteristics of the second images and identifying, by referring to the map information, a second position corresponding to second feature values having at least a predetermined degree of correspondence to the feature values generating a command for moving the autonomous device to the second position on the basis of coordinate information corresponding to the second position, and transmitting the command to the autonomous device."
Augmentation of a gaming controller via projection system of an autonomous personal companion,https://lens.org/030-175-434-726-435,2019,"An autonomous personal companion executing a method of projection including tracking within a reference system a current position and orientation of a gaming controller used for controlling game play of a gaming application played by a user, wherein the personal companion is configured to provide services to the user. The method includes receiving information related to the gaming application from a gaming console supporting the game play. The method includes generating content based on the information related to the gaming application. The method includes moving the autonomous personal companion to a location having a direct line of sight to the controller. The method includes projecting the content from the autonomous personal companion to a surface of the gaming controller."
AUGMENTATION OF A GAMING CONTROLLER VIA PROJECTION SYSTEM OF AN AUTONOMOUS PERSONAL COMPANION,https://lens.org/154-868-021-473-79X,2019,"An autonomous personal companion executing a method of projection including tracking within a reference system a current position and orientation of a gaming controller used for controlling game play of a gaming application played by a user, wherein the personal companion is configured to provide services to the user. The method includes receiving information related to the gaming application from a gaming console supporting the game play. The method includes generating content based on the information related to the gaming application. The method includes moving the autonomous personal companion to a location having a direct line of sight to the controller. The method includes projecting the content from the autonomous personal companion to a surface of the gaming controller."
HYBRID VTOL FIXED-WING DRONE HAVING WING-TIP PROPELLERS,https://lens.org/042-872-212-518-277,2019,"A long-distance drone (100) and a method of improving stability, robustness, endurance and/or durability of the drone (100) and a method of controlling a roll motion of the drone (100) are provided. The drone (100) includes a main body (110), two main wings (113, 114) and two forewings(111, 112), a left linear support (120) spaced apart from said main body (110) connecting the left forewing (111) to the left main wing (113), a right linear support (121) spaced apart from said main body (110) connecting the right forewing (112) to the right main wing (114), at least two propellers (131,132,133) coupled to the left linear support (120), at least two propellers (134,135,136) coupled to the right linear support (121). Therefore, the drone (100) is sufficiently efficient to travel longer distances, and when one propeller (131,132,133,134,135,136) fails, the drone (100) may still function and continue to stay in the air."
TELEPRESENCE ROBOT WITH STABILIZATION MECHANISM,https://lens.org/050-708-238-150-162,2017,"A robot controllable by a portable device, the robot including: a support; a balancing module configured to balance the robot; and a base mounted to the support, the base including a first wheel coaxially aligned with a second wheel and a motor drivably coupled to the first and second wheel."
METHODS AND APPARATUS FOR NAVIGATING AN UNMANNED VEHICLE BASED ON A CALCULATION OF RELATIVE DISTANCE DIFFERENCES BETWEEN A START LOCATION AND A DESIGNATED DROP LOCATION,https://lens.org/016-222-760-896-925,2022,"Unmanned autonomous vehicle (UAV) selection information identifying a UAV, flight path information, and a relative elevation difference value that is a difference between a first elevation value of a start location and a second elevation value of a drop location are received. Navigation of the UAV is initiated using the UAV selection information and the flight path information. A relative altitude difference value is obtained using a first altitude value of the UAV associated with the start location and a second altitude value of the UAV associated with the drop location. In response to a difference between the relative elevation difference value and the relative altitude difference value being outside a predefined threshold, UAV is caused to adjust the second altitude value such that an updated difference between the relative elevation difference value and an updated relative altitude difference value is within the predefined threshold."
METHODS AND APPARATUS FOR NAVIGATING AN UNMANNED VEHICLE BASED ON A CALCULATION OF RELATIVE DISTANCE DIFFERENCES BETWEEN A START LOCATION AND A DESIGNATED DROP LOCATION,https://lens.org/016-222-760-896-925,2022,"Unmanned autonomous vehicle (UAV) selection information identifying a UAV, flight path information, and a relative elevation difference value that is a difference between a first elevation value of a start location and a second elevation value of a drop location are received. Navigation of the UAV is initiated using the UAV selection information and the flight path information. A relative altitude difference value is obtained using a first altitude value of the UAV associated with the start location and a second altitude value of the UAV associated with the drop location. In response to a difference between the relative elevation difference value and the relative altitude difference value being outside a predefined threshold, UAV is caused to adjust the second altitude value such that an updated difference between the relative elevation difference value and an updated relative altitude difference value is within the predefined threshold."
METHODS AND APPARATUS FOR NAVIGATING AN UNMANNED VEHICLE BASED ON A CALCULATION OF RELATIVE DISTANCE DIFFERENCES BETWEEN A START LOCATION AND A DESIGNATED DROP LOCATION,https://lens.org/016-222-760-896-925,2022,"Unmanned autonomous vehicle (UAV) selection information identifying a UAV, flight path information, and a relative elevation difference value that is a difference between a first elevation value of a start location and a second elevation value of a drop location are received. Navigation of the UAV is initiated using the UAV selection information and the flight path information. A relative altitude difference value is obtained using a first altitude value of the UAV associated with the start location and a second altitude value of the UAV associated with the drop location. In response to a difference between the relative elevation difference value and the relative altitude difference value being outside a predefined threshold, UAV is caused to adjust the second altitude value such that an updated difference between the relative elevation difference value and an updated relative altitude difference value is within the predefined threshold."
METHODS AND APPARATUS FOR NAVIGATING AN UNMANNED VEHICLE BASED ON A CALCULATION OF RELATIVE DISTANCE DIFFERENCES BETWEEN A START LOCATION AND A DESIGNATED DROP LOCATION,https://lens.org/185-819-200-600-241,2022,"Unmanned autonomous vehicle (UAV) selection information identifying a UAV, flight path information, and a relative elevation difference value that is a difference between a first elevation value of a start location and a second elevation value of a drop location are received. Navigation of the UAV is initiated using the UAV selection information and the flight path information. A relative altitude difference value is obtained using a first altitude value of the UAV associated with the start location and a second altitude value of the UAV associated with the drop location. In response to a difference between the relative elevation difference value and the relative altitude difference value being outside a predefined threshold, UAV is caused to adjust the second altitude value such that an updated difference between the relative elevation difference value and an updated relative altitude difference value is within the predefined threshold."
METHODS AND APPARATUS FOR NAVIGATING AN UNMANNED VEHICLE BASED ON A CALCULATION OF RELATIVE DISTANCE DIFFERENCES BETWEEN A START LOCATION AND A DESIGNATED DROP LOCATION,https://lens.org/041-046-026-076-873,2022,"Unmanned autonomous vehicle (UAV) selection information identifying a UAV, flight path information, and a relative elevation difference value that is a difference between a first elevation value of a start location and a second elevation value of a drop location are received. Navigation of the UAV is initiated using the UAV selection information and the flight path information. A relative altitude difference value is obtained using a first altitude value of the UAV associated with the start location and a second altitude value of the UAV associated with the drop location. In response to a difference between the relative elevation difference value and the relative altitude difference value being outside a predefined threshold, UAV is caused to adjust the second altitude value such that an updated difference between the relative elevation difference value and an updated relative altitude difference value is within the predefined threshold."
Methods and apparatus for navigating an unmanned vehicle based on a calculation of relative distance differences between a start location and a designated drop location,https://lens.org/153-239-110-585-736,2022,"Unmanned autonomous vehicle (UAV) selection information identifying a UAV, flight path information, and a relative elevation difference value that is a difference between a first elevation value of a start location and a second elevation value of a drop location are received. Navigation of the UAV is initiated using the UAV selection information and the flight path information. A relative altitude difference value is obtained using a first altitude value of the UAV associated with the start location and a second altitude value of the UAV associated with the drop location. In response to a difference between the relative elevation difference value and the relative altitude difference value being outside a predefined threshold, UAV is caused to adjust the second altitude value such that an updated difference between the relative elevation difference value and an updated relative altitude difference value is within the predefined threshold."
METHODS AND APPARATUS FOR NAVIGATING AN UNMANNED VEHICLE BASED ON A CALCULATION OF RELATIVE DISTANCE DIFFERENCES BETWEEN A START LOCATION AND A DESIGNATED DROP LOCATION,https://lens.org/041-046-026-076-873,2022,"Unmanned autonomous vehicle (UAV) selection information identifying a UAV, flight path information, and a relative elevation difference value that is a difference between a first elevation value of a start location and a second elevation value of a drop location are received. Navigation of the UAV is initiated using the UAV selection information and the flight path information. A relative altitude difference value is obtained using a first altitude value of the UAV associated with the start location and a second altitude value of the UAV associated with the drop location. In response to a difference between the relative elevation difference value and the relative altitude difference value being outside a predefined threshold, UAV is caused to adjust the second altitude value such that an updated difference between the relative elevation difference value and an updated relative altitude difference value is within the predefined threshold."
Methods and apparatus for navigating an unmanned vehicle based on a calculation of relative distance differences between a start location and a designated drop location,https://lens.org/153-239-110-585-736,2022,"Unmanned autonomous vehicle (UAV) selection information identifying a UAV, flight path information, and a relative elevation difference value that is a difference between a first elevation value of a start location and a second elevation value of a drop location are received. Navigation of the UAV is initiated using the UAV selection information and the flight path information. A relative altitude difference value is obtained using a first altitude value of the UAV associated with the start location and a second altitude value of the UAV associated with the drop location. In response to a difference between the relative elevation difference value and the relative altitude difference value being outside a predefined threshold, UAV is caused to adjust the second altitude value such that an updated difference between the relative elevation difference value and an updated relative altitude difference value is within the predefined threshold."
Apparatus and method for delivering a dry material with an unmanned aerial vehicle,https://lens.org/103-023-817-242-757,2019,A delivery device coupled to a drone can be used to distribute dry powdered materials to a target area. The powdered materials can be stored in a hopper having an auger at the lower end of the hopper. An auger motor can be actuated to transport the powdered material to an aeration chamber where the powdered material is mixed with turbulent air. The aerated powdered materials can then be emitted from the delivery device from a slinger disc onto a target area.
DRONE DESIGNED FOR VIEWING A DISTANT SCENE,https://lens.org/034-937-972-657-100,2020,"According to one aspect, the present description relates to a drone designed for viewing a distant scene, comprising a flying platform and at least one first camera mechanically secured to the platform. The first camera comprises an image sensor with a detection surface, an electro-optical system for forming images of the scene on the detection surface of the image sensor, able to give the camera a dimensional angular field of view of less than 47. According to the first aspect, the electro-optical system comprises at least one first optical group, which is fixed, comprising a plurality of optical diopters, an electro-optical device with variable optical power able to adjust the focusing of the image on the detection surface, and a control unit controlling the electro-optical device."
Control device and control method for controlling aerial vehicle,https://lens.org/003-658-731-827-790,2023,"The control device is configured to control an aerial vehicle that carries a carrying object and includes a sensor capable of measuring a ground surface temperature during flight. The control device acquires a ground surface temperature in an area where the carrying object is planned to be released, the ground surface temperature being measured by the sensor. And then, the control unit performs control regarding release of the carrying object in accordance with the ground surface temperature in the area."
CONTROL DEVICE AND CONTROL METHOD FOR CONTROLLING AERIAL VEHICLE,https://lens.org/139-979-170-879-345,2021,"The control device is configured to control an aerial vehicle that carries a carrying object and includes a sensor capable of measuring a ground surface temperature during flight. The control device acquires a ground surface temperature in an area where the carrying object is planned to be released, the ground surface temperature being measured by the sensor. And then, the control unit performs control regarding release of the carrying object in accordance with the ground surface temperature in the area."
Mobile tele-presence system with a microphone system,https://lens.org/183-194-591-932-648,2014,"A remote controlled robot system that includes a robot and a remote control station. The robot includes a binaural microphone system that is coupled to a speaker system of the remote control station. The binaural microphone system may include a pair of microphones located at opposite sides of a robot head. the location of the microphones roughly coincides with the location of ears on a human body. Such microphone location creates a mobile robot that more effectively simulates the tele-presence of an operator of the system. The robot may include two different microphone systems and the ability to switch between systems. For example, the robot may also include a zoom camera system and a directional microphone. The directional microphone may be utilized to capture sound from a direction that corresponds to an object zoomed upon by the camera system."
Mobile tele-presence system with a microphone system,https://lens.org/173-716-752-870-840,2017,"A remote controlled robot system that includes a robot and a remote control station. The robot includes a binaural microphone system that is coupled to a speaker system of the remote control station. The binaural microphone system may include a pair of microphones located at opposite sides of a robot head. the location of the microphones roughly coincides with the location of ears on a human body. Such microphone location creates a mobile robot that more effectively simulates the tele-presence of an operator of the system. The robot may include two different microphone systems and the ability to switch between systems. For example, the robot may also include a zoom camera system and a directional microphone. The directional microphone may be utilized to capture sound from a direction that corresponds to an object zoomed upon by the camera system."
MOBILE TELE-PRESENCE SYSTEM WITH A MICROPHONE SYSTEM,https://lens.org/117-225-696-050-372,2015,"A remote controlled robot system that includes a robot and a remote control station. The robot includes a binaural microphone system that is coupled to a speaker system of the remote control station. The binaural microphone system may include a pair of microphones located at opposite sides of a robot head. the location of the microphones roughly coincides with the location of ears on a human body. Such microphone location creates a mobile robot that more effectively simulates the tele-presence of an operator of the system. The robot may include two different microphone systems and the ability to switch between systems. For example, the robot may also include a zoom camera system and a directional microphone. The directional microphone may be utilized to capture sound from a direction that corresponds to an object zoomed upon by the camera system."
MOBILE TELE-PRESENCE SYSTEM WITH A MICROPHONE SYSTEM,https://lens.org/157-097-124-970-971,2012,"A remote controlled robot system that includes a robot and a remote control station. The robot includes a binaural microphone system that is coupled to a speaker system of the remote control station. The binaural microphone system may include a pair of microphones located at opposite sides of a robot head. the location of the microphones roughly coincides with the location of ears on a human body. Such microphone location creates a mobile robot that more effectively simulates the tele-presence of an operator of the system. The robot may include two different microphone systems and the ability to switch between systems. For example, the robot may also include a zoom camera system and a directional microphone. The directional microphone may be utilized to capture sound from a direction that corresponds to an object zoomed upon by the camera system."
"UNMANNED AERIAL VEHICLE, INFORMATION PROCESSING METHOD, AND PROGRAM",https://lens.org/177-412-033-547-206,2021,"An unmanned aerial vehicle (100) includes: a sensor (120) including at least a microphone (105) that generates sound data; and a processor (101). The processor (101) determines a quality of a target sound by using the sound data generated by the microphone (105), acquires a positional relationship between the unmanned aerial vehicle (100) and a sound source of the target sound by using data generated by the sensor (120), determines a destination to which the sound source is to move based on the quality of the target sound and the positional relationship, and presents target movement information that prompts the sound source to move toward the destination."
SYSTEM AND METHOD FOR ROGUE DRONE DETECTION AND INTERCEPTION,https://lens.org/134-133-295-020-98X,2022,"According to the invention there is provided a system and a method to comprehensively analyse and predict a rogue drone. It uses machine learning and artificial intelligence as a part of the system, thereby digitizing the drone detection technology. The subject invention provides a system and method consisting of a hardware and software component. The hardware components of the system automatically capture various data from multiple drone detection systems and provides the data to the artificial intelligence software. The software module interfaces with the hardware components and applies several deep learning techniques to achieve detection, recognition of rogue drones and deciding the interception technique to defect the rogue drones."
SYSTEM AND METHOD FOR ROGUE DRONE DETECTION AND INTERCEPTION,https://lens.org/134-133-295-020-98X,2022,"According to the invention there is provided a system and a method to comprehensively analyse and predict a rogue drone. It uses machine learning and artificial intelligence as a part of the system, thereby digitizing the drone detection technology. The subject invention provides a system and method consisting of a hardware and software component. The hardware components of the system automatically capture various data from multiple drone detection systems and provides the data to the artificial intelligence software. The software module interfaces with the hardware components and applies several deep learning techniques to achieve detection, recognition of rogue drones and deciding the interception technique to defect the rogue drones."
Combiner display system and method for a remote controlled system,https://lens.org/154-431-152-901-748,2017,"An apparatus and method can be used with a remote vehicle such as an unmanned aviation system (UAS) or unmanned aviation vehicle (UAV). The system can be an apparatus including a camera, electronics, and a communication unit. The electronics provide a display image on a combiner. The camera is disposed to receive the display image from the combiner and provide a camera image. The communication unit provides data associated with the camera image from the camera to a remote location."
AUGMENTED REALITY GRAPHICAL USER INTERFACE FOR NETWORK CONTROLLED LIGHTING SYSTEMS,https://lens.org/105-395-095-707-742,2015,"A mobile device having an augmented reality user interface for use in controlling networked light modules. The mobile device can detect via a camera a light module and display an identification of the light module on a user interface such as a touch screen. A user can enter a command via the user interface such as a desired intensity or color for the light module. In response, the mobile device transmits a signal to the light module in order to control the operation of the module based upon the command."
Drone capable of varying propeller arrangement shape,https://lens.org/141-315-297-020-431,2020,"A drone having a deployment device, which is configured such that the same can fly both in a folded mode and in a deployed mode. A platform 300 is arranged in the middle of the drone body 400, a deployment device 200 is arranged on the radial outer side of the platform 300, a fixed support table 230 extends outwardly from the radial outer surface of the platform 300, a rotating support table 210 is coupled to an outer free end of the fixed support table 230, and the rotating support table 210 is rotatably coupled to/supported on the outer free end of the fixed support table 230. Multiple propellers 100 are mounted on the radial outer ends of the rotating support table 210, respectively, a landing structure 600 is coupled to the body 400, and a holder 500 is mounted on the landing structure 600."
Drone Capable of Varying Propeller Arrangement Shape,https://lens.org/094-753-246-905-78X,2018,"A drone having a deployment device, which is configured such that the same can fly both in a folded mode and in a deployed mode. A platform 300 is arranged in the middle of the drone body 400, a deployment device 200 is arranged on the radial outer side of the platform 300, a fixed support table 230 extends outwardly from the radial outer surface of the platform 300, a rotating support table 210 is coupled to an outer free end of the fixed support table 230, and the rotating support table 210 is rotatably coupled to/supported on the outer free end of the fixed support table 230. Multiple propellers 100 are mounted on the radial outer ends of the rotating support table 210, respectively, a landing structure 600 is coupled to the body 400, and a holder 500 is mounted on the landing structure 600."
AUGMENTATION OF UNMANNED-VEHICLE LINE-OF-SIGHT,https://lens.org/065-864-515-343-00X,2021,"An augmented-reality head-mounted display is configured to display an indication of a location of an unmanned aerial vehicle with respect to the field-of-view of the head-mounted display, in order to assist a UAV operator to maintain line-of-sight with the UAV."
Augmentation of unmanned-vehicle line-of-sight,https://lens.org/061-564-024-484-393,2022,"An augmented-reality head-mounted display is configured to display an indication of a location of an unmanned aerial vehicle with respect to the field-of-view of the head-mounted display, in order to assist a UAV operator to maintain line-of-sight with the UAV."
AERIAL MONITORING SYSTEM FOR AGRICULTURAL EQUIPMENT,https://lens.org/170-681-069-090-261,2022,"An aerial monitoring system (12) for agricultural equipment includes an unmanned aerial vehicle (UAV) (10). A controller (120) of the UAV (10) is configured to receive a first signal indicative of a position and a velocity of a reference point (148) on a target agricultural tool, and to determine a target point relative to the reference point (148) that provides a line-of-sight to a target object on the target agricultural tool. The controller (120) is also configured to output a second signal to a movement control system (36) of the UAV (10) indicative of instructions to move the UAV (10) to the target point and to maintain the velocity of the reference point (148) in response to reaching the target point. In addition, the controller (120) is configured output a third signal to a sensor control system (40) of the UAV (10) indicative of instructions to direct a sensor assembly (38) of the UAV (10) toward the target object."
AERIAL MONITORING SYSTEM FOR AGRICULTURAL EQUIPMENT,https://lens.org/063-021-782-118-589,2020,"An aerial monitoring system (12) for agricultural equipment includes an unmanned aerial vehicle (UAV) (10). A controller (120) of the UAV (10) is configured to receive a first signal indicative of a position and a velocity of a reference point (148) on a target agricultural tool, and to determine a target point relative to the reference point (148) that provides a line-of-sight to a target object on the target agricultural tool. The controller (120) is also configured to output a second signal to a movement control system (36) of the UAV (10) indicative of instructions to move the UAV (10) to the target point and to maintain the velocity of the reference point (148) in response to reaching the target point. In addition, the controller (120) is configured output a third signal to a sensor control system (40) of the UAV (10) indicative of instructions to direct a sensor assembly (38) of the UAV (10) toward the target object."
AERIAL MONITORING SYSTEM FOR AGRICULTURAL EQUIPMENT,https://lens.org/170-681-069-090-261,2022,"An aerial monitoring system (12) for agricultural equipment includes an unmanned aerial vehicle (UAV) (10). A controller (120) of the UAV (10) is configured to receive a first signal indicative of a position and a velocity of a reference point (148) on a target agricultural tool, and to determine a target point relative to the reference point (148) that provides a line-of-sight to a target object on the target agricultural tool. The controller (120) is also configured to output a second signal to a movement control system (36) of the UAV (10) indicative of instructions to move the UAV (10) to the target point and to maintain the velocity of the reference point (148) in response to reaching the target point. In addition, the controller (120) is configured output a third signal to a sensor control system (40) of the UAV (10) indicative of instructions to direct a sensor assembly (38) of the UAV (10) toward the target object."
"METHOD OF TRANSMITTING A COMMAND FROM A REMOTE CONTROLLER TO AN AUDIO DEVICE, AND CORRESPONDING REMOTE CONTROLLER AND AUDIO DEVICE",https://lens.org/122-145-531-322-73X,2002,A remote controller transmits a command to an audio device. The audio device exchanges at least one audio signal with an audio accessory via a medium. The remote controller exchanges at least one control signal in which the command is encoded with the audio device. The control signal(s) are generated in a non-audio frequency band and superposed on the audio signal(s) on the medium. The remote controller encodes the command in the control signal(s) and the audio device decodes the command encoded in the control signal(s).
ACOUSTIC MONITORING SYSTEM,https://lens.org/076-204-982-764-626,2021,"A monitored space is monitored including the production of a first audio signal from received acoustic energy. The first audio signal is then processed against a whitelist of acoustic profiles and, based on lack of substantial correspondence with any of the acoustic profiles, a drone is navigated toward an apparent position of an apparent source. While in-flight, additional acoustic energy is received and a second audio signal is produced from the additional acoustic energy. The second audio signal is processed against the whitelist and, based on lack of substantial correspondence with any of the acoustic profiles of the whitelist, an investigate mode of the drone is initiated. The investigate mode includes notifying a remote monitor and supplying the remote monitor with an audiovisual feed. Responsive to a characterization by the remote monitor, an entry of the whitelist may be updated, added or replaced."
ACOUSTIC MONITORING SYSTEM,https://lens.org/033-118-779-420-587,2023,"A monitored space is monitored including the production of a first audio signal from received acoustic energy. The first audio signal is then processed against a whitelist of acoustic profiles and, based on lack of substantial correspondence with any of the acoustic profiles, a drone is navigated toward an apparent position of an apparent source. While in-flight, additional acoustic energy is received and a second audio signal is produced from the additional acoustic energy. The second audio signal is processed against the whitelist and, based on lack of substantial correspondence with any of the acoustic profiles of the whitelist, an investigate mode of the drone is initiated. The investigate mode includes notifying a remote monitor and supplying the remote monitor with an audiovisual feed. Responsive to a characterization by the remote monitor, an entry of the whitelist may be updated, added or replaced."
METHOD FOR OPERATING UNMANNED AERIAL VEHICLE AND ELECTRONIC DEVICE FOR SUPPORTING THE SAME,https://lens.org/185-674-033-531-642,2018,"An electronic device is provided. The electronic device includes a communication circuit configured to establish a communication channel with an aerial vehicle, a sensor configured to collect location information and orientation information, a memory configured to store an application associated with controlling the aerial vehicle, a processor electrically connected with the communication circuit, the sensor, and the memory. The processor may be configured to calculate a valid range defining a space where it is possible to operate the aerial vehicle, based on location and/or orientation information of the electronic device."
METHOD FOR OPERATING UNMANNED AERIAL VEHICLE AND ELECTRONIC DEVICE FOR SUPPORTING THE SAME,https://lens.org/028-645-665-630-010,2018,"An electronic device is provided. The electronic device includes a communication circuit configured to establish a communication channel with an aerial vehicle, a sensor configured to collect location information and orientation information, a memory configured to store an application associated with controlling the aerial vehicle, a processor electrically connected with the communication circuit, the sensor, and the memory. The processor may be configured to calculate a valid range defining a space where it is possible to operate the aerial vehicle, based on location and/or orientation information of the electronic device."
Autonomous Power Trowel,https://lens.org/029-991-885-887-086,2021,"An autonomous power trowel includes a frame supported by at least one rotor having a plurality of troweling blades, at least one power source for selectively rotating the rotor to finish an upper surface of the concrete, at least one actuator onboard the frame for selectively tilting the rotor, and a communication system onboard the frame for communicating with at least one remote communication device. Also included are a plurality of sensors onboard the frame for sensing exterior boundaries of the concrete, and at least one inspection camera for viewing the upper surface of the concrete. A controller onboard the frame is configured to selectively operate the power source, to selectively operate the actuator, to receive communications from the remote communication device, to receive signals from the sensors, and to receive signals from the inspection camera to detect any surface blemish in the concrete."
AUTONOMOUS POWER TROWEL,https://lens.org/079-836-991-024-368,2020,"An autonomous power trowel includes a frame supported by at least one rotor having a plurality of troweling blades, at least one power source for selectively rotating the rotor to finish an upper surface of the concrete, at least one actuator onboard the frame for selectively tilting the rotor, and a communication system onboard the frame for communicating with at least one remote communication device. Also included are a plurality of sensors onboard the frame for sensing exterior boundaries of the concrete, and at least one inspection camera for viewing the upper surface of the concrete. A controller onboard the frame is configured to selectively operate the power source, to selectively operate the actuator, to receive communications from the remote communication device, to receive signals from the sensors, and to receive signals from the inspection camera to detect any surface blemish in the concrete."
Autonomous power trowel,https://lens.org/064-943-606-054-202,2023,"An autonomous power trowel includes a frame supported by at least one rotor having a plurality of troweling blades, at least one power source for selectively rotating the rotor to finish an upper surface of the concrete, at least one actuator onboard the frame for selectively tilting the rotor, and a communication system onboard the frame for communicating with at least one remote communication device. Also included are a plurality of sensors onboard the frame for sensing exterior boundaries of the concrete, and at least one inspection camera for viewing the upper surface of the concrete. A controller onboard the frame is configured to selectively operate the power source, to selectively operate the actuator, to receive communications from the remote communication device, to receive signals from the sensors, and to receive signals from the inspection camera to detect any surface blemish in the concrete."
AUTONOMOUS POWER TROWEL,https://lens.org/079-836-991-024-368,2020,"An autonomous power trowel includes a frame supported by at least one rotor having a plurality of troweling blades, at least one power source for selectively rotating the rotor to finish an upper surface of the concrete, at least one actuator onboard the frame for selectively tilting the rotor, and a communication system onboard the frame for communicating with at least one remote communication device. Also included are a plurality of sensors onboard the frame for sensing exterior boundaries of the concrete, and at least one inspection camera for viewing the upper surface of the concrete. A controller onboard the frame is configured to selectively operate the power source, to selectively operate the actuator, to receive communications from the remote communication device, to receive signals from the sensors, and to receive signals from the inspection camera to detect any surface blemish in the concrete."
RUGGEDIZED AUTONOMOUS HELICOPTER PLATFORM,https://lens.org/037-433-151-542-031,2020,"An unmanned helicopter platform includes a fuselage, a tail coupled with the fuselage, a payload rail coupled with and extending along the fuselage and a main rotor assembly coupled with the fuselage. The tail includes a tail rotor and a tail rotor motor. The main rotor assembly includes a main rotor having an axis of rotation and a main rotor motor. The payload rail allows mechanical connection of payloads to the fuselage and positioning of the payloads such that a center of gravity of the payloads is alignable with the axis of rotation. A system for controlling the unmanned helicopter includes a processor and a memory for providing instructions to the processor. The processor can receive a task, dynamically determine a route for the task and autonomously perform the task including flying along at least part of the route. The route is based on the task, geography and terrain."
Ruggedized autonomous helicopter platform,https://lens.org/060-344-532-476-049,2022,"An unmanned helicopter platform includes a fuselage, a tail coupled with the fuselage, a payload rail coupled with and extending along the fuselage and a main rotor assembly coupled with the fuselage. The tail includes a tail rotor and a tail rotor motor. The main rotor assembly includes a main rotor having an axis of rotation and a main rotor motor. The payload rail allows mechanical connection of payloads to the fuselage and positioning of the payloads such that a center of gravity of the payloads is alignable with the axis of rotation. A system for controlling the unmanned helicopter includes a processor and a memory for providing instructions to the processor. The processor can receive a task, dynamically determine a route for the task and autonomously perform the task including flying along at least part of the route. The route is based on the task, geography and terrain."
Ruggedized autonomous helicopter platform,https://lens.org/060-344-532-476-049,2022,"An unmanned helicopter platform includes a fuselage, a tail coupled with the fuselage, a payload rail coupled with and extending along the fuselage and a main rotor assembly coupled with the fuselage. The tail includes a tail rotor and a tail rotor motor. The main rotor assembly includes a main rotor having an axis of rotation and a main rotor motor. The payload rail allows mechanical connection of payloads to the fuselage and positioning of the payloads such that a center of gravity of the payloads is alignable with the axis of rotation. A system for controlling the unmanned helicopter includes a processor and a memory for providing instructions to the processor. The processor can receive a task, dynamically determine a route for the task and autonomously perform the task including flying along at least part of the route. The route is based on the task, geography and terrain."
"CONTROL APPARATUS, UNINHABITED AIRBORNE VEHICLE, AND METHOD",https://lens.org/189-739-991-388-034,2022,"A control apparatus is equipped with a control unit. The control unit acquires information on a sound in at least one room arranged along an outer wall of a building. The control unit moves an uninhabited airborne vehicle along the outer wall of the building, based on the information on the sound."
Drone delivery systems and methods,https://lens.org/027-164-940-028-638,2022,"A drone delivery system for receiving a package on a roof of a structure includes a panel coupled to the roof that selectively provides access to an opening in the roof upon identification and authorization of an incoming package. Once the package is identified and authorized, the panel opens and the package is received from an aerial vehicle on a platform in the opening. The platform is lowered by a drive assembly and the panel is closed over the opening. The drive assembly then lowers the platform and package to an intended destination inside the structure."
DRONE DELIVERY SYSTEMS AND METHODS,https://lens.org/097-874-264-179-099,2022,"A drone delivery system for receiving a package on a roof of a structure includes a panel coupled to the roof that selectively provides access to an opening in the roof upon identification and authorization of an incoming package. Once the package is identified and authorized, the panel opens and the package is received from an aerial vehicle on a platform in the opening. The platform is lowered by a drive assembly and the panel is closed over the opening. The drive assembly then lowers the platform and package to an intended destination inside the structure."
DRONE DELIVERY SYSTEMS AND METHODS,https://lens.org/097-874-264-179-099,2022,"A drone delivery system for receiving a package on a roof of a structure includes a panel coupled to the roof that selectively provides access to an opening in the roof upon identification and authorization of an incoming package. Once the package is identified and authorized, the panel opens and the package is received from an aerial vehicle on a platform in the opening. The platform is lowered by a drive assembly and the panel is closed over the opening. The drive assembly then lowers the platform and package to an intended destination inside the structure."
Drone delivery systems and methods,https://lens.org/027-164-940-028-638,2022,"A drone delivery system for receiving a package on a roof of a structure includes a panel coupled to the roof that selectively provides access to an opening in the roof upon identification and authorization of an incoming package. Once the package is identified and authorized, the panel opens and the package is received from an aerial vehicle on a platform in the opening. The platform is lowered by a drive assembly and the panel is closed over the opening. The drive assembly then lowers the platform and package to an intended destination inside the structure."
"Methods, computer programs, computing devices and controllers",https://lens.org/005-788-043-082-05X,2019,"A method of controlling a mobile computing device 100 comprises receiving image data from a sensor (such as a camera 120), the received image data representing a scene including an unmanned aerial vehicle (UAV). Identification information is also received wirelessly from the UAV. Data based upon the received image data and the identification information are displayed on a display (which may be part 140 of computing device 100). The method may be used to enforce a restricted flight zone (no-fly zone). The identification and image data may be stored and/or transmitted, and additional telemetry data about the UAV may be received. The identification data may be transmitted from the UAV to a remote operator control device of the UAV, or alternatively broadcast. Map data may also be generated based upon the image data."
STABILIZING CONTROL APPARATUS FOR ROBOTIC OR REMOTELY CONTROLLED FLYING PLATFORM,https://lens.org/059-588-839-252-854,2000,"A robotic or remotely controlled flying platform with reduced drag stabilizing control apparatus constructed having an air duct with an air intake on the top and an exhaust at the bottom, containing supported therein a clockwise rotating fan and a counter-clockwise rotating fan. Directly below the perimeter of the air duct exhaust are mounted a plurality of trough shaped air deflection assemblies each including a rotatably adjustable half trough for selectively scooping a portion of the drive air, and a stationary adjacent half trough for receiving the scooped drive air and redirecting it outward and upward from the air duct. A centrally positioned plate has a plurality of rods, each pivotably connected between the plate and a corresponding lever associated with each of the adjustable half troughs so as to couple the adjustable half trough in or out of the drive air steam according to the position of the plate, thereby providing control over the pitch and roll of the flying platform. The plate is driven by first and second motors responding to input control signals. The control signals also direct the yaw of the flying platform by selectively providing independent speed control to each of the clockwise and counter clockwise fan motors resulting in duct rotation in a clockwise or counter clockwise direction accordingly."
Wireless voice activated control system for bow mounted electric trolling motor,https://lens.org/153-634-376-231-580,2017,"A wireless voice controlled system for a trolling motor assembly which enables fully automatic usage of the trolling motor assembly in different modes of operation, including automatic voice controlled storage/locking of the trolling motor assembly at the boat base, launching the trolling motor assembly from a horizontal/storage position to a vertical position for operation in water, locking the trolling motor assembly in the vertical position, and retrieving the trolling motor back to a horizontal/storage/lock position on the bow mounted base using voice commands entered by a boat operator in a microphone on a wireless command transmitter. The system enables the boat operator to control the steering of the trolling motor and speed of the propeller for the boat propulsion using voice commands transmitted wirelessly from the handheld (or stationary) wireless command transmitter to a receiver embedded in a positioning and operation control unit having a logic and mechanical drive mechanism for transitioning the trolling motor assembly into any desired mode of operation and controlling the operation of the motor."
A MULTIROTOR AIRCRAFT AND A METHOD FOR CONTROLLING THE MULTIROTOR AIRCRAFT,https://lens.org/190-154-541-010-327,2017,"A multirotor aircraft (10) and a method for controlling the multirotor aircraft (10) are disclosed. The multirotor aircraft (10) comprises a body (12), a H-shaped frame (14), a first person view camera and a servo mechanism (121), wherein, the end of each arm (142,143,144,145) of the H-shaped frame (14) far away from a lateral shaft (141) thereof is mounted with an actuator assembly (18), the lateral shaf t(141) is connected with the body (12) by the bearing (161,162), and the servo mechanism (121) is coupled with the lateral shaft (141) and is configured to control the rotation of the lateral shaft (14), in order to control the angle between the body (12) and the H-shaped frame (14). The method comprises a first mode and a second mode, wherein in the first mode, keeping the horizon within the camera view of the aircraft (10)and in the second mode, generating control command on the basis of the camera aligned axis."
DISASTER DAMAGE ANALYSIS AND LOSS MITIGATION IMPLEMENTING UNMANNED AERIAL VEHICLES (UAVS),https://lens.org/177-715-880-342-947,2021,"Various techniques are described utilizing one or more unmanned aerial vehicles (UAVs, or drones) for various disaster and/or catastrophe-related purposes. UAVs may collect data in an attempt to predict the occurrence and/or extent of a catastrophe and/or to mitigate the impact of a catastrophe before and, if not at that time, once it has occurred. The UAVs may perform various tasks such that the damage to property caused by a catastrophe (or potential catastrophe) may be eliminated or mitigated. The drone data may be transmitted by the UAVs to an external computing device, which may be associated with an insurer and used, with an insured's permission, to begin and/or facilitate an insurance claim process or other various insurance-related tasks. Damage to insured property may be estimated from the drone data, and proposed or estimated insurance claims may be generated for customer review, modification, or approval."
CELESTIAL NAVIGATION SYSTEM FOR AN AUTONOMOUS VEHICLE,https://lens.org/017-959-526-128-621,2020,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
Celestial navigation system for an autonomous vehicle,https://lens.org/142-801-186-357-744,2020,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
Celestial navigation system for an autonomous vehicle,https://lens.org/141-964-674-345-910,2022,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
CELESTIAL NAVIGATION SYSTEM FOR AN AUTONOMOUS VEHICLE,https://lens.org/137-491-211-960-43X,2021,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
CELESTIAL NAVIGATION SYSTEM FOR AN AUTONOMOUS VEHICLE,https://lens.org/174-597-460-283-086,2017,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
Celestial navigation system for an autonomous vehicle,https://lens.org/072-247-076-864-988,2022,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
CELESTIAL NAVIGATION SYSTEM FOR AN AUTONOMOUS VEHICLE,https://lens.org/043-984-556-203-140,2021,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
Celestial navigation system for an autonomous vehicle,https://lens.org/142-896-864-279-234,2021,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
Celestial navigation system for an autonomous vehicle,https://lens.org/165-503-839-091-816,2016,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
CELESTIAL NAVIGATION SYSTEM FOR AN AUTONOMOUS VEHICLE,https://lens.org/026-494-753-260-04X,2013,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
CELESTIAL NAVIGATION SYSTEM FOR AN AUTONOMOUS VEHICLE,https://lens.org/081-638-903-707-930,2010,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
CELESTIAL NAVIGATION SYSTEM FOR AN AUTONOMOUS VEHICLE,https://lens.org/104-774-897-420-536,2016,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
Celestial navigation system for an autonomous vehicle,https://lens.org/159-860-442-014-829,2015,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
Celestial navigation system for an autonomous vehicle,https://lens.org/022-402-586-379-257,2015,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
CELESTIAL NAVIGATION SYSTEM FOR AN AUTONOMOUS VEHICLE,https://lens.org/194-648-668-725-229,2021,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
Celestial navigation system for an autonomous vehicle,https://lens.org/162-536-819-446-431,2021,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
CELESTIAL NAVIGATION SYSTEM FOR AN AUTONOMOUS VEHICLE,https://lens.org/069-413-928-634-836,2017,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
Celestial navigation system for an autonomous vehicle,https://lens.org/072-247-076-864-988,2022,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
CELESTIAL NAVIGATION SYSTEM FOR AN AUTONOMOUS VEHICLE,https://lens.org/099-542-690-358-518,2020,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
Celestial navigation system for an autonomous vehicle,https://lens.org/186-230-617-201-830,2018,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
Celestial navigation system for an autonomous vehicle,https://lens.org/141-964-674-345-910,2022,"A navigation control system for an autonomous vehicle comprises a transmitter and an autonomous vehicle. The transmitter comprises an emitter for emitting at least one signal, a power source for powering the emitter, a device for capturing wireless energy to charge the power source, and a printed circuit board for converting the captured wireless energy to a form for charging the power source. The autonomous vehicle operates within a working area and comprises a receiver for detecting the at least one signal emitted by the emitter, and a processor for determining a relative location of the autonomous vehicle within the working area based on the signal emitted by the emitter."
AIRCRAFT PROVIDED WITH A SECONDARY FLIGHT ASSEMBLY,https://lens.org/193-710-338-603-120,2020,"A remote piloted aircraft comprising a secondary flight assembly adapted to intervene in case of failure or an emergency of the aircraft, said secondary flight assembly being provided with an additional control unit configured to process flight relevant data and which includes an additional receiver configured to receive commands from the remote pilot by means of a remote control unit, in case of failure or emergency said additional control unit being configured to generate, as a response, an activation command adapted to activate a first device to expel an upper wing placed in a first compartment of the aircraft and to inflate a lower wing housed in a second compartment of the aircraft, and also to generate an interdiction command of the primary propulsion unit, said upper wing being maneuverable by means of a further remote control unit."
METHODS AND SYSTEM FOR VISION-BASED LANDING,https://lens.org/135-147-460-975-223,2018,"A computer-implemented method for controlling an unmanned aerial vehicle (UAV) and an unmanned aerial vehicle UAV are provided. The method comprising: a plurality of reference images can be obtained by an imaging device carried by the UAV as the UAV take off from a target location. Subsequently, a subject image can be obtained by the UAV and compared with the reference images to determine a spatial relationship between the UAV and the target location. The UAV can then be controlled to approach the target location based on the spatial relationship."
MESH NETWORK OF UNMANNED AERIAL VEHICLES ANCHORED TO A CELL SITE OF A CELLULAR RADIO ACCESS NETWORK,https://lens.org/117-697-741-732-547,2021,"An unmanned aerial vehicle (UAV) is disclosed. The UAV includes a flight system, a communications system, and a processing system. The communications system includes a cellular radio configured to support multiple contemporaneous communications connections, including at least a first communications connection with a cellular radio access network, at least a second communications connection with a second UAV in a set of one or more UAVs, and at least a third communications connection with a user equipment (UE) in a set of one or more UEs. The processing system is configured to control the flight system and relay communications between the cellular radio access network, the set of one or more UAVs, and the set of one or more UEs, in accordance with a mesh network protocol."
Mesh network of unmanned aerial vehicles anchored to a cell site of a cellular radio access network,https://lens.org/143-797-616-836-970,2022,"An unmanned aerial vehicle (UAV) is disclosed. The UAV includes a flight system, a communications system, and a processing system. The communications system includes a cellular radio configured to support multiple contemporaneous communications connections, including at least a first communications connection with a cellular radio access network, at least a second communications connection with a second UAV in a set of one or more UAVs, and at least a third communications connection with a user equipment (UE) in a set of one or more UEs. The processing system is configured to control the flight system and relay communications between the cellular radio access network, the set of one or more UAVs, and the set of one or more UEs, in accordance with a mesh network protocol."
METHOD AND DEVICE FOR PROVIDING RESPONSE TO VOICE INPUT OF USER,https://lens.org/008-606-567-066-404,2020,"A method, performed by a device, of providing a response to a user's voice input, includes capturing, via a camera of the device, an image including at least one object; activating a microphone of the device as the image is captured; receiving, via the microphone, the user's voice input for the object; determining the intention of the user with respect to the object by analyzing the received voice input; and providing a response regarding the at least one object based on the determined intention of the user."
Method and device for providing response to voice input of user,https://lens.org/001-207-274-071-506,2022,"A method, performed by a device, of providing a response to a user's voice input, includes capturing, via a camera of the device, an image including at least one object; activating a microphone of the device as the image is captured; receiving, via the microphone, the user's voice input for the object; determining the intention of the user with respect to the object by analyzing the received voice input; and providing a response regarding the at least one object based on the determined intention of the user."
AN APPARATUS AND METHOD FOR OPERATING AN UNMANNED AERIAL VEHICLE,https://lens.org/196-314-420-876-464,2018,"Described embodiments include a method for operating an unmanned aerial vehicle (UAV) (20). The method includes receiving a signal (36) that indicates a configuration of a crane (30), computing, in response to the signal, a flight path (50) that passes under a boom (40) of the crane while circumventing the crane, and causing the UAV to follow the computed flight path, by transmitting flight instructions to the UAV. Other embodiments are also described."
ROBOT CONTROL SYSTEM AND CONTROL METHOD,https://lens.org/141-405-758-998-256,2023,"The robot control system includes a first control device and a second control device network-connected to the first control device to control a robot. The first control device includes a selection unit configured to enable any one of a plurality of sources that provide information about generation of a command instructing behavior of the robot, and a first communication unit configured to transmit a command generated according to the information from the enabled source in the plurality of sources to the second control device. The second control device includes a second communication unit configured to receive the command transmitted from the first control device, and a command value generation unit configured to sequentially generate a command value for driving each axis of the robot so as to provide the behavior instructed by the command from the first control device."
ROBOT CONTROL SYSTEM AND CONTROL METHOD,https://lens.org/141-405-758-998-256,2023,"The robot control system includes a first control device and a second control device network-connected to the first control device to control a robot. The first control device includes a selection unit configured to enable any one of a plurality of sources that provide information about generation of a command instructing behavior of the robot, and a first communication unit configured to transmit a command generated according to the information from the enabled source in the plurality of sources to the second control device. The second control device includes a second communication unit configured to receive the command transmitted from the first control device, and a command value generation unit configured to sequentially generate a command value for driving each axis of the robot so as to provide the behavior instructed by the command from the first control device."
SYSTEMS AND METHODS FOR SUPPORTING AUTOMATIC VIDEO CAPTURE AND VIDEO EDITING,https://lens.org/002-905-930-432-264,2022,"A method is performed by an unmanned aerial vehicle (UAV) (102) includes: the UAV (102) receives from a computing device (126) that is communicatively connected to the UAV (102) a first input that includes identification of a target object (106) (2006); in response to the first input, the UAV (102) determines a target type corresponding to the target object (106) (2010); the UAV (102) determines a distance between the UAV (102) and the target object (106) (2012); the UAV (102) also selects automatically, from a plurality of predefined flight routes, a flight route for the UAV (102) according to the determined target type and the distance (2014); the selected flight route includes a plurality of paths of different trajectory modes (2020); the UAV (102) sends to the computing device (126) the selected flight route for display on the computing device (126) (2032)."
SYSTEMS AND METHODS FOR SUPPORTING AUTOMATIC VIDEO CAPTURE AND VIDEO EDITING,https://lens.org/002-905-930-432-264,2022,"A method is performed by an unmanned aerial vehicle (UAV) (102) includes: the UAV (102) receives from a computing device (126) that is communicatively connected to the UAV (102) a first input that includes identification of a target object (106) (2006); in response to the first input, the UAV (102) determines a target type corresponding to the target object (106) (2010); the UAV (102) determines a distance between the UAV (102) and the target object (106) (2012); the UAV (102) also selects automatically, from a plurality of predefined flight routes, a flight route for the UAV (102) according to the determined target type and the distance (2014); the selected flight route includes a plurality of paths of different trajectory modes (2020); the UAV (102) sends to the computing device (126) the selected flight route for display on the computing device (126) (2032)."
RECONFIGURABLE BATTERY-OPERATED VEHICLE SYSTEM,https://lens.org/179-533-588-102-044,2016,"A quadrotor UAV including ruggedized, integral-battery, load-bearing body, two arms on the load-bearing body, each arm having two rotors, a control module mounted on the load-bearing body, a payload module mounted on the control module, and skids configured as landing gear. The two arms are replaceable with arms having wheels for ground vehicle use, with arms having floats and props for water-surface use, and with arms having pitch-controlled props for underwater use. The control module is configured to operate as an unmanned aerial vehicle, an unmanned ground vehicle, an unmanned (water) surface vehicle, and an unmanned underwater vehicle, depending on the type of arms that are attached."
Reconfigurable battery-operated vehicle system,https://lens.org/136-718-528-458-314,2022,"A quadrotor UAV including ruggedized, integral-battery, load-bearing body, two arms on the load-bearing body, each arm having two rotors, a control module mounted on the load-bearing body, a payload module mounted on the control module, and skids configured as landing gear. The two arms are replaceable with arms having wheels for ground vehicle use, with arms having floats and props for water-surface use, and with arms having pitch-controlled props for underwater use. The control module is configured to operate as an unmanned aerial vehicle, an unmanned ground vehicle, an unmanned (water) surface vehicle, and an unmanned underwater vehicle, depending on the type of arms that are attached."
RECONFIGURABLE BATTERY-OPERATED VEHICLE SYSTEM,https://lens.org/090-908-215-160-787,2021,"A quadrotor UAV including ruggedized, integral-battery, load-bearing body, two arms on the load-bearing body, each arm having two rotors, a control module mounted on the load-bearing body, a payload module mounted on the control module, and skids configured as landing gear. The two arms are replaceable with arms having wheels for ground vehicle use, with arms having floats and props for water-surface use, and with arms having pitch-controlled props for underwater use. The control module is configured to operate as an unmanned aerial vehicle, an unmanned ground vehicle, an unmanned (water) surface vehicle, and an unmanned underwater vehicle, depending on the type of arms that are attached."
RECONFIGURABLE BATTERY-OPERATED VEHICLE SYSTEM,https://lens.org/087-709-566-623-376,2019,"A quadrotor UAV including ruggedized, integral-battery, load-bearing body, two arms on the load-bearing body, each arm having two rotors, a control module mounted on the load-bearing body, a payload module mounted on the control module, and skids configured as landing gear. The two arms are replaceable with arms having wheels for ground vehicle use, with arms having floats and props for water-surface use, and with arms having pitch-controlled props for underwater use. The control module is configured to operate as an unmanned aerial vehicle, an unmanned ground vehicle, an unmanned (water) surface vehicle, and an unmanned underwater vehicle, depending on the type of arms that are attached."
RECONFIGURABLE BATTERY-OPERATED VEHICLE SYSTEM,https://lens.org/098-650-235-147-26X,2018,"A quadrotor UAV including ruggedized, integral-battery, load-bearing body, two arms on the load-bearing body, each arm having two rotors, a control module mounted on the load-bearing body, a payload module mounted on the control module, and skids configured as landing gear. The two arms are replaceable with arms having wheels for ground vehicle use, with arms having floats and props for water-surface use, and with arms having pitch-controlled props for underwater use. The control module is configured to operate as an unmanned aerial vehicle, an unmanned ground vehicle, an unmanned (water) surface vehicle, and an unmanned underwater vehicle, depending on the type of arms that are attached."
Reconfigurable battery-operated vehicle system,https://lens.org/153-535-476-758-546,2018,"A quadrotor UAV including ruggedized, integral-battery, load-bearing body, two arms on the load-bearing body, each arm having two rotors, a control module mounted on the load-bearing body, a payload module mounted on the control module, and skids configured as landing gear. The two arms are replaceable with arms having wheels for ground vehicle use, with arms having floats and props for water-surface use, and with arms having pitch-controlled props for underwater use. The control module is configured to operate as an unmanned aerial vehicle, an unmanned ground vehicle, an unmanned (water) surface vehicle, and an unmanned underwater vehicle, depending on the type of arms that are attached."
Reconfigurable battery-operated vehicle system,https://lens.org/061-049-669-000-839,2014,"A quadrotor UAV including ruggedized, integral-battery, load-bearing body, two arms on the load-bearing body, each arm having two rotors, a control module mounted on the load-bearing body, a payload module mounted on the control module, and skids configured as landing gear. The two arms are replaceable with arms having wheels for ground vehicle use, with arms having floats and props for water-surface use, and with arms having pitch-controlled props for underwater use. The control module is configured to operate as an unmanned aerial vehicle, an unmanned ground vehicle, an unmanned (water) surface vehicle, and an unmanned underwater vehicle, depending on the type of arms that are attached."
Method and system for controlling autonomous vehicles to affect occupant view,https://lens.org/012-191-310-338-016,2023,"A system and method for controlling an autonomous vehicle to affect a view seen by an occupant of the autonomous vehicle is described. In one embodiment, a method for controlling an autonomous vehicle to affect a view seen by an occupant of the autonomous vehicle includes determining a navigation route, determining content associated with the navigation route, monitoring current conditions of the autonomous vehicle and the occupant, determining, based on the current conditions, whether to change a position of the vehicle to affect the view seen by the occupant, and when the current conditions permit, moving the autonomous vehicle to affect the view seen by the occupant."
METHOD AND SYSTEM FOR CONTROLLING AUTONOMOUS VEHICLES TO AFFECT OCCUPANT VIEW,https://lens.org/038-253-894-922-885,2021,"A system and method for controlling an autonomous vehicle to affect a view seen by an occupant of the autonomous vehicle is described. In one embodiment, a method for controlling an autonomous vehicle to affect a view seen by an occupant of the autonomous vehicle includes determining a navigation route, determining content associated with the navigation route, monitoring current conditions of the autonomous vehicle and the occupant, determining, based on the current conditions, whether to change a position of the vehicle to affect the view seen by the occupant, and when the current conditions permit, moving the autonomous vehicle to affect the view seen by the occupant."
DRONE WITH REMOTE ID,https://lens.org/025-237-639-747-504,2022,"A global positioning satellite (GPS) receiver and a transmitter are at a base remote from a drone, and the transmitter sends GPS packets along with control packets to the drone. In turn, the drone also has a GPS receiver and a transmitter that transmits both the controller and drone GPS coordinates to the remote base."
DRONE WITH REMOTE ID,https://lens.org/025-237-639-747-504,2022,"A global positioning satellite (GPS) receiver and a transmitter are at a base remote from a drone, and the transmitter sends GPS packets along with control packets to the drone. In turn, the drone also has a GPS receiver and a transmitter that transmits both the controller and drone GPS coordinates to the remote base."
Methods and device for drone-based network management,https://lens.org/182-733-491-113-42X,2021,"An unmanned aerial vehicle (UAV) configured to operate in a management infrastructure, wherein the management infrastructure includes multiple layers that manage components of a radio communication network for a network provider, the UAV including a vehicle drive arrangement, and one or more processors configured to execute program code for a first layer of the management infrastructure to provide services to one or more first devices in a layer different from the first layer, identify a triggering condition for changing layers in the management infrastructure, identify a second layer of the management infrastructure to change to, and execute program code for the second layer to provide services to one or more second devices in a layer different from the second layer."
METHODS AND DEVICE FOR DRONE-BASED NETWORK MANAGEMENT,https://lens.org/184-012-313-095-022,2019,"An unmanned aerial vehicle (UAV) configured to operate in a management infrastructure, wherein the management infrastructure includes multiple layers that manage components of a radio communication network for a network provider, the UAV including a vehicle drive arrangement, and one or more processors configured to execute program code for a first layer of the management infrastructure to provide services to one or more first devices in a layer different from the first layer, identify a triggering condition for changing layers in the management infrastructure, identify a second layer of the management infrastructure to change to, and execute program code for the second layer to provide services to one or more second devices in a layer different from the second layer."
Radar augmentation system for airborne target,https://lens.org/052-650-656-689-009,1979,"An active radar augmentation system in a drone target aircraft, for the purpose of decreasing damage to the target. The system includes a receiving antenna in the nose, an amplifier, and a rear mounted transmitting antenna, connected by suitable cables."
INFORMATION SYSTEM HAVING A SPEECH INTERFACE,https://lens.org/071-445-669-706-193,1996,"A system for controlling a device and for controlling access to broadcast information is disclosed. The system includes a first receiver for receiving utterances of a speaker, a second receiver for receiving vocabulary data defining a vocabulary of utterances, and a processor for executing a speech recognition algorithm using the received vocabulary data to recognize the utterances of the speaker and for controlling the device and the access to the broadcast information in accordance with the recognized utterances of the speaker."
DRONE CLEANING DEVICE,https://lens.org/144-396-786-353-137,2017,"A drone cleaning device for a building exterior comprises a main frame, a plurality of branch shafts set to the main frame, a plurality of power elements respectively set to the branch shafts, a plurality of adjustable supports set to the main frame, a plurality of rotatable elements respectively set to the adjustable supports and are configured to rotate relative to the adjustable supports, and a plurality of cleaning elements respectively set to the rotatable elements."
Mobile unmanned aerial vehicle infrastructure and management system and related method,https://lens.org/058-415-840-708-28X,2016,"A mobile unmanned aerial vehicle (UAV) infrastructure and management system, and related methods to facilitate operation of one or more unmanned aerial vehicles (UAVs) in one or more areas is disclosed."
Unmanned aerial vehicle (UAV) having vertical takeoff and landing (VTOL) capability,https://lens.org/007-039-911-824-792,2018,"An unmanned aerial vehicle (UAV), or drone, includes a fuselage, left and right airfoil-shaped wings connected to the fuselage to generate lift in forward flight, a left thrust-generating device supported by the left wing, and a right thrust-generating device supported by the right wing. The UAV further includes a vertical stabilizer, a top thrust-generating device mounted to a top portion of the vertical stabilizer, and a bottom thrust-generating device mounted to a bottom portion of the vertical stabilizer. An onboard power source is provided for powering the thrust-generating devices. The left, right, top and bottom thrust-generating devices provide forward thrust during forward flight and also provide vertical thrust to enable the unmanned aerial vehicle to take-off and land vertically when the fuselage is substantially vertical and further enabling the unmanned aerial vehicle to transition between forward flight and vertical take-off and landing."
UNMANNED AERIAL VEHICLE (UAV) HAVING VERTICAL TAKEOFF AND LANDING (VTOL) CAPABILITY,https://lens.org/046-929-480-223-790,2018,"An unmanned aerial vehicle (UAV), or drone, includes a fuselage, left and right airfoil-shaped wings connected to the fuselage to generate lift in forward flight, a left thrust-generating device supported by the left wing, and a right thrust-generating device supported by the right wing. The UAV further includes a vertical stabilizer, a top thrust-generating device mounted to a top portion of the vertical stabilizer, and a bottom thrust-generating device mounted to a bottom portion of the vertical stabilizer. An onboard power source is provided for powering the thrust-generating devices. The left, right, top and bottom thrust-generating devices provide forward thrust during forward flight and also provide vertical thrust to enable the unmanned aerial vehicle to take-off and land vertically when the fuselage is substantially vertical and further enabling the unmanned aerial vehicle to transition between forward flight and vertical take-off and landing."
System and method for the unpredictable remote control of devices,https://lens.org/059-635-439-253-259,2006,"A device, means, and method for the unpredictable remote control of at least one remote device is provided. A device may include a transmitter, an aperiodic timer, and a command sequence generator to the generated command sequence as controls signal in response to a timer signal from the aperiodic timer or a trigger signal. A method is also provided, which includes the Steps of generating an aperiodic timing signal, generating or retrieving a command sequence in response the aperiodic timing signal or a trigger signal and transmitting the command sequence. The Steps for learning a command, and self-testing the device, and generating the trigger signal based on a sound pattern detected by a sound detector are also described."
"Measuring device, control device for unmanned aerial vehicle and computer program product for controlling unmanned aerial vehicle",https://lens.org/035-549-150-356-52X,2021,"Objects of the present disclosure include providing a technique which can efficiently guide an unmanned aerial vehicle to a particular part of a target object. Provided is a control device for an unmanned aerial vehicle including a camera. The control device comprises a bright spot detection unit configured to detect, from an image captured by camera, a bright spot generated by a laser pointer; a flight control unit configured to perform, based on position of the bright spot in the image, flight control over the unmanned aerial vehicle. In such structure, the camera detects the bright spot, generated by the irradiation of spot-type indicating laser beam from the total station, on a wall surface, and the flight control over the unmanned aerial vehicle is performed in a manner that the unmanned aerial vehicle follows the bright spot."
METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE AND UNMANNED AERIAL VEHICLE SUPPORTING THE SAME,https://lens.org/127-454-132-520-65X,2018,"An unmanned aerial vehicle is disclosed. The unmanned aerial vehicle includes a memory, a sensor unit, a camera, a moving unit, and a processor. The sensor unit is configured to sense the unmanned aerial vehicle or a surrounding object. The camera configured to take an image. The moving unit configured to generate power to move the unmanned aerial vehicle. The processor is configured to determine whether a user makes contact with the unmanned aerial vehicle. The processor is also configured to control the moving unit to allow the unmanned aerial vehicle to hover at a second location when the unmanned aerial vehicle is moved from a first location to the second location by an external force of a predetermined magnitude or greater while the contact is maintained."
Method for controlling unmanned aerial vehicle and unmanned aerial vehicle supporting the same,https://lens.org/061-000-818-912-35X,2020,"An unmanned aerial vehicle is disclosed. The unmanned aerial vehicle includes a memory, a sensor unit, a camera, a moving unit, and a processor. The sensor unit is configured to sense the unmanned aerial vehicle or a surrounding object. The camera configured to take an image. The moving unit configured to generate power to move the unmanned aerial vehicle. The processor is configured to determine whether a user makes contact with the unmanned aerial vehicle. The processor is also configured to control the moving unit to allow the unmanned aerial vehicle to hover at a second location when the unmanned aerial vehicle is moved from a first location to the second location by an external force of a predetermined magnitude or greater while the contact is maintained."
Gimbaled Universal Drone Controller,https://lens.org/073-842-135-371-212,2018,"Various embodiments are disclosed of a device for use on an unmanned aerial vehicle (drone) including two or more gimbals, a gimbal processor, an inertial measurement unit, and a communication connection. The two or more gimbals are pivotally coupled to rotate orthogonally relative to each other. An inner gimbal of the two or more gimbals may support an inner platform for receiving components thereon. An outer gimbal of the two or more gimbals may be pivotally coupled to the drone. The gimbal processor is mounted on the inner platform, wherein the gimbal processor is configured to control pivotal movement of the two or more gimbals. The inertial measurement unit may be fixed relative to the inner platform and coupled to the gimbal processor. The communication connection may be coupled to the gimbal processor and configured to exchange signals with the drone for controlling operations."
GIMBALED UNIVERSAL DRONE CONTROLLER,https://lens.org/047-078-916-914-028,2018,"Various embodiments are disclosed of a device for use on an unmanned aerial vehicle (drone) including two or more gimbals, a gimbal processor, an inertial measurement unit, and a communication connection. The two or more gimbals are pivotally coupled to rotate orthogonally relative to each other. An inner gimbal of the two or more gimbals may support an inner platform for receiving components thereon. An outer gimbal of the two or more gimbals may be pivotally coupled to the drone. The gimbal processor is mounted on the inner platform, wherein the gimbal processor is configured to control pivotal movement of the two or more gimbals. The inertial measurement unit may be fixed relative to the inner platform and coupled to the gimbal processor. The communication connection may be coupled to the gimbal processor and configured to exchange signals with the drone for controlling operations."
Gimbaled universal drone controller,https://lens.org/177-669-308-064-128,2019,"Various embodiments are disclosed of a device for use on an unmanned aerial vehicle (drone) including two or more gimbals, a gimbal processor, an inertial measurement unit, and a communication connection. The two or more gimbals are pivotally coupled to rotate orthogonally relative to each other. An inner gimbal of the two or more gimbals may support an inner platform for receiving components thereon. An outer gimbal of the two or more gimbals may be pivotally coupled to the drone. The gimbal processor is mounted on the inner platform, wherein the gimbal processor is configured to control pivotal movement of the two or more gimbals. The inertial measurement unit may be fixed relative to the inner platform and coupled to the gimbal processor. The communication connection may be coupled to the gimbal processor and configured to exchange signals with the drone for controlling operations."
Dynamic control of hovering drone,https://lens.org/021-081-066-043-361,2022,"Apparatus, a method and a computer program are provided. The apparatus includes circuitry for causing rendering of mediated reality content to a user, wherein the mediated reality content includes virtual visual content rendered on a display of a hovering drone. The apparatus also includes circuitry for determining a real location of the user in real space. The apparatus further includes circuitry for dynamically adjusting a real location of the hovering drone, relative to the determined real location of the user, based at least in part on at least one characteristic of the mediated reality content rendered to the user."
"CONTROL METHOD, CONTROL APPARATUS, CONTROL TERMINAL FOR UNMANNED AERIAL VEHICLE",https://lens.org/045-733-584-371-99X,2021,"A control method includes providing an image on a display device where the image is an image of an environment captured by a photographing apparatus provided at an unmanned aerial vehicle, determining a position of a selected point in the image in response to a point selection operation on the image by a user, and generating a waypoint for the unmanned aerial vehicle or marking an obstacle within the environment according to the position of the selected point in the image."
AUTHORIZING A FLIGHT OF AN UNMANNED AERIAL VEHICLE (UAV),https://lens.org/150-182-975-098-925,2019,"An example device includes one or more memories; and one or more processors, communicatively coupled to the one or more memories, to receive a request to authorize a flight of an unmanned aerial vehicle (UAV), wherein the UAV is locked by a locking mechanism until the flight is authorized and the request includes flight information that identifies a location of the flight, and a pilot identifier of a pilot of the flight; obtain a pilot certification of the pilot based on the pilot identifier; identify a first flight regulation of a flight regulation system, wherein the first flight regulation includes information identifying a threshold pilot certification to pilot the UAV at the location; determine whether the pilot certification of the pilot satisfies the threshold pilot certification to pilot the UAV at the location; and when the pilot certification of the pilot satisfies the threshold pilot certification to pilot the UAV at the location, provide a key to unlock the UAV to permit the flight of the UAV to commence."
Authorizing a flight of an unmanned aerial vehicle (UAV),https://lens.org/043-770-289-570-152,2021,"An example device includes one or more memories; and one or more processors, communicatively coupled to the one or more memories, to receive a request to authorize a flight of an unmanned aerial vehicle (UAV), wherein the UAV is locked by a locking mechanism until the flight is authorized and the request includes flight information that identifies a location of the flight, and a pilot identifier of a pilot of the flight; obtain a pilot certification of the pilot based on the pilot identifier; identify a first flight regulation of a flight regulation system, wherein the first flight regulation includes information identifying a threshold pilot certification to pilot the UAV at the location; determine whether the pilot certification of the pilot satisfies the threshold pilot certification to pilot the UAV at the location; and when the pilot certification of the pilot satisfies the threshold pilot certification to pilot the UAV at the location, provide a key to unlock the UAV to permit the flight of the UAV to commence."
Autonomous cargo delivery system,https://lens.org/029-122-126-631-990,2018,"An autonomous aerial system for delivering a payload to a waypoint. The autonomous aerial system may comprise an aerial vehicle to transport the payload to the waypoint and an onboard supervisory control system operatively coupled with the aerial vehicle. The aerial vehicle may be configured to navigate to the waypoint and to land at a designated touchdown zone within a landing zone at the waypoint. The onboard supervisory control system having a processor operatively coupled with a non-volatile memory device and a sensor package. The processor may be configured to generate flight control signal data based at least in part on data received via the sensor package, the sensor package configured to (1) dynamically sense and avoid obstacles along a flight route to the waypoint, and (2) perceive physical characteristics of the landing zone. The processor may be configured to autonomously navigate the aerial vehicle to the waypoint and to determine whether to touchdown at the designated touchdown zone based at least in part on physical characteristics of the designated touchdown zone perceived via said sensor package."
Autonomous Cargo Delivery System,https://lens.org/165-874-225-298-065,2017,"An autonomous aerial system for delivering a payload to a waypoint. The autonomous aerial system may comprise an aerial vehicle to transport the payload to the waypoint and an onboard supervisory control system operatively coupled with the aerial vehicle. The aerial vehicle may be configured to navigate to the waypoint and to land at a designated touchdown zone within a landing zone at the waypoint. The onboard supervisory control system having a processor operatively coupled with a non-volatile memory device and a sensor package. The processor may be configured to generate flight control signal data based at least in part on data received via the sensor package, the sensor package configured to (1) dynamically sense and avoid obstacles along a flight route to the waypoint, and (2) perceive physical characteristics of the landing zone. The processor may be configured to autonomously navigate the aerial vehicle to the waypoint and to determine whether to touchdown at the designated touchdown zone based at least in part on physical characteristics of the designated touchdown zone perceived via said sensor package."
Autonomous Cargo Delivery System,https://lens.org/010-240-474-668-105,2018,"An autonomous aerial system for delivering a payload to a waypoint. The autonomous aerial system may comprise an aerial vehicle to transport the payload to the waypoint and an onboard supervisory control system operatively coupled with the aerial vehicle. The aerial vehicle may be configured to navigate to the waypoint and to land at a designated touchdown zone within a landing zone at the waypoint. The onboard supervisory control system having a processor operatively coupled with a non-volatile memory device and a sensor package. The processor may be configured to generate flight control signal data based at least in part on data received via the sensor package, the sensor package configured to (1) dynamically sense and avoid obstacles along a flight route to the waypoint, and (2) perceive physical characteristics of the landing zone. The processor may be configured to autonomously navigate the aerial vehicle to the waypoint and to determine whether to touchdown at the designated touchdown zone based at least in part on physical characteristics of the designated touchdown zone perceived via said sensor package."
Autonomous cargo delivery system,https://lens.org/058-593-376-095-003,2019,"An autonomous aerial system for delivering a payload to a waypoint. The autonomous aerial system may comprise an aerial vehicle to transport the payload to the waypoint and an onboard supervisory control system operatively coupled with the aerial vehicle. The aerial vehicle may be configured to navigate to the waypoint and to land at a designated touchdown zone within a landing zone at the waypoint. The onboard supervisory control system having a processor operatively coupled with a non-volatile memory device and a sensor package. The processor may be configured to generate flight control signal data based at least in part on data received via the sensor package, the sensor package configured to (1) dynamically sense and avoid obstacles along a flight route to the waypoint, and (2) perceive physical characteristics of the landing zone. The processor may be configured to autonomously navigate the aerial vehicle to the waypoint and to determine whether to touchdown at the designated touchdown zone based at least in part on physical characteristics of the designated touchdown zone perceived via said sensor package."
Remote control having audio-visual function,https://lens.org/138-180-548-128-786,2008,"A remote control device having a tracking unit is provided. The remote control device has an audio code receiver therein and cooperated with a transmitter. When the device being used by a user, the transmitter generates an audio signal to the corresponding audio code receiver in the remote control device, so that the remote control device will generate a sound; therefore, the user can easy find the remote control device. The transmitter includes a sound signal generating unit, a sound processor, a control interface, and a speaker. The audio code receiver includes a sound controller, a signal frequency and timing detector, a received signal processor, and a sound sensor and a sound generating unit, and so on. By way of using the remote control device which includes several difference audio code receivers, the user can easily find the remote control device."
Autonomous aerial cable inspection system,https://lens.org/061-768-811-370-138,2017,"An aerial inspection system is provided, including an unmanned aerial vehicle (UAV) having an articulated arm coupled thereto. An end effector is coupled to a second end of the articulated arm, the end effector sized and shaped to extend at least partially around an aerial cable in close proximity. One or more sensors are positioned along an inner surface of the end effector, and provide feedback to a control unit. In response, the control unit adjusts a position of at least one of the UAV, the articulated arm, and the end effector such that the end effector maintains a close, non-contact position with respect to the cable."
"METHOD, DEVICE, AND UNMANNED AERIAL VEHICLE FOR CONTROLLING MOVABLE OBJECT",https://lens.org/001-028-411-067-05X,2022,"A method for controlling an unmanned aerial vehicle (UAV) includes obtaining a signal strength of a remote control signal received by the UAV, obtaining a movement path of the UAV in response to the signal strength being less than a preset strength threshold, controlling the UAV to enter a backtrack return mode to return along the movement path, and controlling the UAV to exit the backtrack return mode in response to the signal strength being greater than the preset strength threshold. The movement path of the UAV includes position information of a plurality of discrete points, and the position information of the plurality of discrete points is calculated based on at least one of sensing information obtained by a satellite positioning system disposed in the UAV or sensing information obtained by a vision positioning sensor disposed in the UAV."
"Method, device, and unmanned aerial vehicle for controlling movable object",https://lens.org/168-458-054-319-269,2023,"A method for controlling an unmanned aerial vehicle (UAV) includes obtaining a signal strength of a remote control signal received by the UAV, obtaining a movement path of the UAV in response to the signal strength being less than a preset strength threshold, controlling the UAV to enter a backtrack return mode to return along the movement path, and controlling the UAV to exit the backtrack return mode in response to the signal strength being greater than the preset strength threshold. The movement path of the UAV includes position information of a plurality of discrete points, and the position information of the plurality of discrete points is calculated based on at least one of sensing information obtained by a satellite positioning system disposed in the UAV or sensing information obtained by a vision positioning sensor disposed in the UAV."
Navigating a UAV,https://lens.org/036-486-669-623-760,2007,"Exemplary embodiments of the present invention include a method for navigating a UAV. Such embodiments include receiving in a remote control device a user's selection of a GUI map pixel that represents a waypoint for UAV navigation. The pixel has a location on the GUI. Such embodiments also include mapping the pixel's location on the GUI to Earth coordinates of the waypoint, transmitting the coordinates of the waypoint to the UAV, reading a starting position from a GPS receiver on the UAV, and piloting the UAV, under control of a navigation computer on the UAV, from the starting position to the waypoint in accordance with a navigation algorithm."
Navigating a UAV,https://lens.org/183-893-145-866-671,2005,"Exemplary embodiments of the present invention include a method for navigating a UAV. Such embodiments include receiving in a remote control device a user's selection of a GUI map pixel that represents a waypoint for UAV navigation. The pixel has a location on the GUI. Such embodiments also include mapping the pixel's location on the GUI to Earth coordinates of the waypoint, transmitting the coordinates of the waypoint to the UAV, reading a starting position from a GPS receiver on the UAV, and piloting the UAV, under control of a navigation computer on the UAV, from the starting position to the waypoint in accordance with a navigation algorithm."
UNMANNED PACKAGE STORAGE SYSTEM FOR DRONE PACKAGE DELIVERY AND SYSTEM THEREOF,https://lens.org/181-891-100-755-263,2020,An unmanned article storage box for automatically receiving an article from a drone and storing the article includes: a box main body configured to form an accommodating space for storing the article therein; an article receiver configured to slidingly be carried in and out from the box main body; a sliding unit configured to slidingly move the article receiver by having a first end that is fastened to the article receiver and a second end that is fastened to an inside of the box main body; a power unit configured to transfer a power to enable the article receiver to move along the sliding unit; and a controller configured to control the power unit.
IMAGE CAPTURING METHOD AND UNMANNED AERIAL VEHICLE,https://lens.org/177-769-897-126-144,2021,"An image capturing method is applied to an unmanned aerial vehicle (UAV). The method includes receiving a recording command sent by a control terminal; acquiring a pre-set start focal length and a pre-set end focal length; and changing from the start focal length to the end focal length, and recording an image during the process of changing focal lengths."
BASE STATIONS INCLUDING INTEGRATED SYSTEMS FOR SERVICING UAVS,https://lens.org/017-215-235-042-041,2023,A base station is disclosed for use with an unmanned aerial vehicle (UAV). The base station includes: an enclosure; a cradle that is configured to charge a power source of the UAV during docking with the base station; and a temperature control system that is connected to the cradle and which is configured to vary temperature of the power source of the UAV. The temperature control system includes: a thermoelectric conditioner (TEC); a first air circuit that is thermally connected to the TEC and which is configured to regulate temperature of the TEC; and a second air circuit that is thermally connected to the TEC such that the TEC is located between the first air circuit and the second air circuit. The second air circuit is configured to direct air across the cradle to thereby heat or cool the power source of the UAV when docked with the base station.
BASE STATIONS INCLUDING INTEGRATED SYSTEMS FOR SERVICING UAVS,https://lens.org/017-215-235-042-041,2023,A base station is disclosed for use with an unmanned aerial vehicle (UAV). The base station includes: an enclosure; a cradle that is configured to charge a power source of the UAV during docking with the base station; and a temperature control system that is connected to the cradle and which is configured to vary temperature of the power source of the UAV. The temperature control system includes: a thermoelectric conditioner (TEC); a first air circuit that is thermally connected to the TEC and which is configured to regulate temperature of the TEC; and a second air circuit that is thermally connected to the TEC such that the TEC is located between the first air circuit and the second air circuit. The second air circuit is configured to direct air across the cradle to thereby heat or cool the power source of the UAV when docked with the base station.
Autonomous unmanned aerial vehicle and method of control thereof,https://lens.org/007-500-582-162-590,2020,"An autonomous unmanned aerial vehicle (10) comprising an airframe body; at least one flight system mounted to the airframe body(12); an onboard flight controller (18) which is adapted to control the or each flight system; a memory storage unit having machine-readable flight control instructions which are implementable by the onboard flight controller; an onboard feedback system which is communicatively coupled with the or each flight system to provide real-time internal flight characteristic data to the onboard flight controller(18); and an external feedback system adapted to receive and provide to the onboard flight controller (18) real-time external flight characteristic data; wherein the onboard flight controller (18) is arranged to receive mission parameter data from an external source, determine a pre- take-off flight plan in accordance with the mission parameter data, and dynamically implement the machine-readable flight control instructions to adapt the pre-take-off flight plan to control the or each flight system based on the real-time internal flight characteristic data and real-time external flight characteristic data."
AUTONOMOUS UNMANNED AERIAL VEHICLE AND METHOD OF CONTROL THEREOF,https://lens.org/050-529-913-174-683,2019,"An autonomous unmanned aerial vehicle (10) comprising an airframe body; at least one flight system mounted to the airframe body(12); an onboard flight controller (18) which is adapted to control the or each flight system; a memory storage unit having machine-readable flight control instructions which are implementable by the onboard flight controller; an onboard feedback system which is communicatively coupled with the or each flight system to provide real-time internal flight characteristic data to the onboard flight controller(18); and an external feedback system adapted to receive and provide to the onboard flight controller (18) real-time external flight characteristic data; wherein the onboard flight controller (18) is arranged to receive mission parameter data from an external source, determine a pre- take-off flight plan in accordance with the mission parameter data, and dynamically implement the machine-readable flight control instructions to adapt the pre-take-off flight plan to control the or each flight system based on the real-time internal flight characteristic data and real-time external flight characteristic data."
DRONE-CARRIER BROKERING,https://lens.org/107-167-783-411-038,2018,"In an example, there is disclosed a drone operator computing apparatus having : a network interface; and one or more logic elements providing a broker agent to: communicatively couple to a drone brokerage engine via the network interface; send a carrier request comprising a request for a carrier to carry a drone through a prohibitive zone; receive a brokered carrier response comprising an engage point; and dispatch the drone to the engage point. There is also disclosed a drone having a navigation engine to proceed to the engage point and engage a carrier. There is also disclosed a brokerage engine to broker a carrier request from the drone operator, receive a carrier response from a carrier operator, and broker the carrier response."
RECONFIGURABLE BATTERY-OPERATED VEHICLE SYSTEM,https://lens.org/145-468-989-983-813,2011,"A quadrotor UAV including ruggedized, integral-battery, load- bearing body, two arms on the load-bearing body, each arm having two rotors, a control module mounted on the load-bearing body, a payload module mounted on the control module, and skids configured as landing gear. The two arms are replaceable with arms having wheels for ground vehicle use, with arms having floats and props for water-surface use, and with arms having pitch-controlled props for underwater use. The control module is configured to operate as an unmanned aerial vehicle, an unmanned ground vehicle, an unmanned (water) surface vehicle, and an unmanned underwater vehicle, depending on the type of arms that are attached."
Reconfigurable battery-operated vehicle system,https://lens.org/059-725-869-926-133,2013,"A quadrotor UAV including ruggedized, integral-battery, load- bearing body, two arms on the load-bearing body, each arm having two rotors, a control module mounted on the load-bearing body, a payload module mounted on the control module, and skids configured as landing gear. The two arms are replaceable with arms having wheels for ground vehicle use, with arms having floats and props for water-surface use, and with arms having pitch-controlled props for underwater use. The control module is configured to operate as an unmanned aerial vehicle, an unmanned ground vehicle, an unmanned (water) surface vehicle, and an unmanned underwater vehicle, depending on the type of arms that are attached."
RECONFIGURABLE BATTERY-OPERATED VEHICLE SYSTEM,https://lens.org/057-437-059-092-713,2013,"A quadrotor UAV including ruggedized, integral-battery, load- bearing body, two arms on the load-bearing body, each arm having two rotors, a control module mounted on the load-bearing body, a payload module mounted on the control module, and skids configured as landing gear. The two arms are replaceable with arms having wheels for ground vehicle use, with arms having floats and props for water-surface use, and with arms having pitch-controlled props for underwater use. The control module is configured to operate as an unmanned aerial vehicle, an unmanned ground vehicle, an unmanned (water) surface vehicle, and an unmanned underwater vehicle, depending on the type of arms that are attached."
APPARATUS FOR SUSTAINED SURVEILLANCE AND DETERRENCE WITH UNMANNED AERIAL VEHICLES (UAV),https://lens.org/001-292-106-533-301,2019,"An apparatus for sustained surveillance and/or deterrence of animals, such as birds, from an area, comprising one or more unmanned aerial vehicles (""UAVs"") controlled autonomously or remotely or with minimal human intervention and having a plurality of deterrence capabilities, including but not limited to flight path changes, movement changes, flight speed changes, visual projections and audio projections."
AERIAL DEVICE TO WARN OF EMERGENCIES IN AREAS WITH CRITICAL INFRASTRUCTURES,https://lens.org/032-174-771-889-84X,2019,"Aerial device for warning of emergencies in areas with critical infrastructures, a device constituted by a UAV (Unmanned Aerial Vehicle) which is equipped with control and flight means and characterised in that the device also has a (2) high power speaker for spoken warnings, an (3) acoustic siren capable of emitting a sound over 75 dBA, an (4) omnidirectional radio antenna, a (5) 4G antenna, a (6) GPS antenna, a (7) three stroboscopic lights of different colours, so that a visible colour code can be created, where each code indicates a situation, a (8) rechargeable main battery, a (9) spare battery, a (10) radio receiver/transmitter, a (11) control C.P.U. preprogramed in part, a (12) photograph and video cameras with direct signal to the emergency centre."
WIRELESS ULTRASOUND PROBE WITH VOICE CONTROL,https://lens.org/066-489-090-487-183,2008,A wireless ultrasound probe is used to conduct a diagnostic imaging procedure with voice control of the wireless probe. The user of the probe wears a wireless headset which includes a microphone and an earpiece. The user controls the probe and/or the ultrasound system by speaking commands into the microphone. The verbal commands are transmitted to the ultrasound system where they are processed to produce control signals for the control of the probe and/or the ultrasound system. Audible feedback in the form of verbal or nonverbal sounds may be transmitted back to the headset and sounded through the earpiece to provide assurance that a verbal command has be carried out.
Quad-rotor unmanned helicopter,https://lens.org/028-302-071-213-848,2015,"The utility model discloses a quad-rotor unmanned helicopter. The quad-rotor unmanned helicopter comprises four propellers, a rigid cross bracket and a main control system, wherein the four propellers are fixedly connected to the rigid cross bracket and driven by four independent motors; the main control system is arranged at the bottom of the rigid cross bracket; the quad-rotor unmanned helicopter can hover in the precision range of 1m in the air, so that target actions can be effectively observed for a long time and operation and control are flexible. Because a 10000mAh battery module is applied to the quad-rotor unmanned helicopter, the quad-rotor unmanned helicopter can fly for 10km under the cruising ability of 30 minutes; the highest speed is 10m/s and the inclusiveness of a flight altitude is in the range from 0 to 1000m; the applicable temperature range is in the range from -10 DEG C to 45 DEG C, the takeoff weight is 3kg and the greatest effective payload is 1kg; thus a camera and other equipment can be carried by the quad-rotor unmanned helicopter to carefully observe places which are difficult to observe by the human."
"Multifunction firefighting infrasound, hailstone, plant pollination drone apparatus and method",https://lens.org/050-008-674-674-117,2019,"A first drone equipped with a high energy Directional Ultrasound Parametric Speaker Array and a second drone equipped with an Acoustic Dispersion Cannon are used to fight wildfire. The first drone is distanced far from a burning flame but in close proximity to a fire target. Both drones are guided by GPS to communicate with remote operators. Once the target is locked, the first drone blasts the target with Amplitude Modulated Ultrasound. The Ultrasound is self-demodulated into a lower frequency audio sound when it encounters a hot flame of richly charged ions. The lowered frequency sound pushes and pulls the flame forward and backward rapidly away from the combustion source, causing it to be disconnected from the flame which instantly cools down and is extinguished. The second drone blasts the combustible source with powerful sonic shockwaves to disperse the still hot particulates further apart to prevent the source being reignited."
"Multifunction Firefighting Infrasound, Hailstone, Plant Pollination Drone Apparatus and Method",https://lens.org/029-509-573-847-634,2019,"A first drone equipped with a high energy Directional Ultrasound Parametric Speaker Array and a second drone equipped with an Acoustic Dispersion Cannon are used to fight wildfire. The first drone is distanced far from a burning flame but in close proximity to a fire target. Both drones are guided by GPS to communicate with remote operators. Once the target is locked, the first drone blasts the target with Amplitude Modulated Ultrasound. The Ultrasound is self-demodulated into a lower frequency audio sound when it encounters a hot flame of richly charged ions. The lowered frequency sound pushes and pulls the flame forward and backward rapidly away from the combustion source, causing it to be disconnected from the flame which instantly cools down and is extinguished. The second drone blasts the combustible source with powerful sonic shockwaves to disperse the still hot particulates further apart to prevent the source being reignited."
METHOD FOR CONTROLLING ELECTRONIC DEVICE USING IP CAMERA HAVING FUNCTION OF WIRELESS REMOTE CONTROLLER,https://lens.org/077-372-734-796-409,2016,"A networked camera for controlling electronic devices is provided. The camera includes a camera module for obtaining images, a remote control module for generating remote control signals for electronic devices, and a module for controlling orientation of the remote control module. The remote control module includes an IR (infrared) beam emitter for generating IR remote control signals. In response to a control command from a user device, the camera identifies a target electronic device, an orientation associated with the target electronic device. The camera changes orientation of a remote control module toward the target electronic device using the identified orientation and transmit an IR control signal for controlling the target electronic device."
Method and system for controlling robots within in an interactive arena and generating a virtual overlayed,https://lens.org/069-177-296-022-476,2022,"A program for operating a robot, comprising providing, a user interface for controlling a robot, wherein the user interface is from the perspective of a recording device, applying, an overlay over the robot, wherein the overlay is visible through the user interface, enabling, a user to control the position and orientation of a robot, connecting a user device with a robot, converting a request from a user to alter the position and orientation of the robot, where the request is processed based on the requested position and orientation of the robot based on a target location determined by the recording device, detecting, the updated robot position and orientation through the recording device, and altering, the robot position and orientation based on a request from the user and the preserved overlay of the robot based on the new position and orientation based on the recording device perspective of the robot."
METHOD AND SYSTEM FOR CONTROLLING ROBOTS WITHIN IN AN INTERACTIVE ARENA AND GENERATING A VIRTUAL OVERLAYED,https://lens.org/084-874-198-305-189,2020,"A program for operating a robot, comprising providing, a user interface for controlling a robot, wherein the user interface is from the perspective of a recording device, applying, an overlay over the robot, wherein the overlay is visible through the user interface, enabling, a user to control the position and orientation of a robot, connecting a user device with a robot, converting a request from a user to alter the position and orientation of the robot, where the request is processed based on the requested position and orientation of the robot based on a target location determined by the recording device, detecting, the updated robot position and orientation through the recording device, and altering, the robot position and orientation based on a request from the user and the preserved overlay of the robot based on the new position and orientation based on the recording device perspective of the robot."
Method and system for controlling robots within in an interactive arena and generating a virtual overlayed,https://lens.org/069-177-296-022-476,2022,"A program for operating a robot, comprising providing, a user interface for controlling a robot, wherein the user interface is from the perspective of a recording device, applying, an overlay over the robot, wherein the overlay is visible through the user interface, enabling, a user to control the position and orientation of a robot, connecting a user device with a robot, converting a request from a user to alter the position and orientation of the robot, where the request is processed based on the requested position and orientation of the robot based on a target location determined by the recording device, detecting, the updated robot position and orientation through the recording device, and altering, the robot position and orientation based on a request from the user and the preserved overlay of the robot based on the new position and orientation based on the recording device perspective of the robot."
Accident fault determination implementing unmanned aerial vehicles (UAVS),https://lens.org/063-073-054-068-178,2021,"Unmanned aerial vehicles (UAVs) may facilitate insurance-related tasks. UAVs may actively survey an area or be dispatched to the scene of a vehicle collision or crash, such as with an insured's permission, and collect data related to the vehicle collision or crash, such as vehicle data, insurer data, images, video, audio, weather conditions, etc., and transmit this data to a computing device. The computing device may be associated with an insurer and/or utilized by an insurer to perform insurance-related tasks, such as processing the data to assign fault to one or more parties or vehicles, such as autonomous vehicles, involved in the vehicle collision or crash, using the fault assignment to open or otherwise process an insurance claim, modifying a premium price, updating qualified discounts, etc. The drone data may also assist an insurer in opening an insurance claim by prepopulating fields associated with a submitted claim form."
Small flying environment monitoring instrument,https://lens.org/146-779-579-795-857,2015,"A small flying environment monitoring instrument comprises a small unmanned aerial vehicle body. A vehicle arm is arranged on the periphery of the small unmanned aerial vehicle body. A brushless motor is arranged at the end of the vehicle arm and is provided with a propeller. The brushless motor is connected with a battery pack which is arranged above the small unmanned aerial vehicle body. A flying control system is arranged above the small unmanned aerial vehicle body. The flying control system is connected with a GPS. The flying control system and the GPS are controlled by a ground control system. A monitoring analysis instrument pod is arranged below the small unmanned aerial vehicle body. A monitoring analyzer is arranged in the monitoring analysis instrument pod. A small unmanned aerial vehicle system, a portable type gas analysis system, a portable water quality analysis system and a radiation monitoring system are integrated, working efficiency is improved, and the safety of on-site technicians is protected. Meanwhile, a video shooting transmission system is added, and on-site and surrounding environment situations can be monitored and collected in real time."
INSURANCE UNDERWRITING AND RE-UNDERWRITING IMPLEMENTING UNMANNED AERIAL VEHICLES (UAVS),https://lens.org/190-678-178-502-50X,2022,"Unmanned aerial vehicles (UAVs) may facilitate insurance-related tasks. UAVs may actively be dispatched to an area surrounding a property, and collect data related to property. A location for an inspection of a property to be conducted by a UAV may be received, and one or more images depicting a view of the location may be displayed via a user interface. Additionally, a geofence boundary may be determined based on an area corresponding to a property boundary, where the geofence boundary represents a geospatial boundary in which to limit flight of the UAV. Furthermore, a navigation route may be determined which corresponds to the geofence boundary for inspection of the property by the UAV, the navigation route having waypoints, each waypoint indicating a location for the UAV to obtain drone data. The UAV may be directed around the property using the determined navigation route."
INSURANCE UNDERWRITING AND RE-UNDERWRITING IMPLEMENTING UNMANNED AERIAL VEHICLES (UAVS),https://lens.org/160-233-671-066-73X,2023,"Unmanned aerial vehicles (UAVs) may facilitate insurance-related tasks. UAVs may actively be dispatched to an area surrounding a property, and collect data related to property. A location for an inspection of a property to be conducted by a UAV may be received, and one or more images depicting a view of the location may be displayed via a user interface. Additionally, a geofence boundary may be determined based on an area corresponding to a property boundary, where the geofence boundary represents a geospatial boundary in which to limit flight of the UAV. Furthermore, a navigation route may be determined which corresponds to the geofence boundary for inspection of the property by the UAV, the navigation route having waypoints, each waypoint indicating a location for the UAV to obtain drone data. The UAV may be directed around the property using the determined navigation route."
INSURANCE UNDERWRITING AND RE-UNDERWRITING IMPLEMENTING UNMANNED AERIAL VEHICLES (UAVS),https://lens.org/190-678-178-502-50X,2022,"Unmanned aerial vehicles (UAVs) may facilitate insurance-related tasks. UAVs may actively be dispatched to an area surrounding a property, and collect data related to property. A location for an inspection of a property to be conducted by a UAV may be received, and one or more images depicting a view of the location may be displayed via a user interface. Additionally, a geofence boundary may be determined based on an area corresponding to a property boundary, where the geofence boundary represents a geospatial boundary in which to limit flight of the UAV. Furthermore, a navigation route may be determined which corresponds to the geofence boundary for inspection of the property by the UAV, the navigation route having waypoints, each waypoint indicating a location for the UAV to obtain drone data. The UAV may be directed around the property using the determined navigation route."
Insurance underwriting and re-underwriting implementing unmanned aerial vehicles (UAVs),https://lens.org/166-753-617-841-069,2023,"Unmanned aerial vehicles (UAVs) may facilitate insurance-related tasks. UAVs may actively be dispatched to an area surrounding a property, and collect data related to property. A location for an inspection of a property to be conducted by a UAV may be received, and one or more images depicting a view of the location may be displayed via a user interface. Additionally, a geofence boundary may be determined based on an area corresponding to a property boundary, where the geofence boundary represents a geospatial boundary in which to limit flight of the UAV. Furthermore, a navigation route may be determined which corresponds to the geofence boundary for inspection of the property by the UAV, the navigation route having waypoints, each waypoint indicating a location for the UAV to obtain drone data. The UAV may be directed around the property using the determined navigation route."
INSURANCE UNDERWRITING AND RE-UNDERWRITING IMPLEMENTING UNMANNED AERIAL VEHICLES (UAVS),https://lens.org/160-233-671-066-73X,2023,"Unmanned aerial vehicles (UAVs) may facilitate insurance-related tasks. UAVs may actively be dispatched to an area surrounding a property, and collect data related to property. A location for an inspection of a property to be conducted by a UAV may be received, and one or more images depicting a view of the location may be displayed via a user interface. Additionally, a geofence boundary may be determined based on an area corresponding to a property boundary, where the geofence boundary represents a geospatial boundary in which to limit flight of the UAV. Furthermore, a navigation route may be determined which corresponds to the geofence boundary for inspection of the property by the UAV, the navigation route having waypoints, each waypoint indicating a location for the UAV to obtain drone data. The UAV may be directed around the property using the determined navigation route."
Information system having a speech interface,https://lens.org/153-583-519-886-123,1998,"A system for controlling a device such as a television and for controlling access to broadcast information such as video, audio, and/or text information is disclosed. The system includes a first receiver for receiving utterances of a speaker, a second receiver for receiving vocabulary data defining a vocabulary of utterances, and a processor for executing a speech recognition algorithm using the received vocabulary data to recognize the utterances of the speaker and for controlling the device and the access to the broadcast information in accordance with the recognized utterances of the speaker."
Emergency route planning system,https://lens.org/109-966-585-788-153,2020,"A vehicle includes a controller, programmed to responsive to detecting, via a vehicle sensor, an obstacle blocking a route on which the vehicle is traversing, report the obstacle and blockage to a server via a wireless connection; responsive to receiving a command from the server instructing to perform an exploratory maneuver to remove the obstacle from the route, execute the command via an autonomous driving controller; and report an implementation result of the exploratory maneuver to the server."
EMERGENCY ROUTE PLANNING SYSTEM,https://lens.org/070-565-215-093-361,2020,"A vehicle includes a controller, programmed to responsive to detecting, via a vehicle sensor, an obstacle blocking a route on which the vehicle is traversing, report the obstacle and blockage to a server via a wireless connection; responsive to receiving a command from the server instructing to perform an exploratory maneuver to remove the obstacle from the route, execute the command via an autonomous driving controller; and report an implementation result of the exploratory maneuver to the server."
UNMANNED AERIAL VEHICLE SYSTEM AND METHOD WITH ENVIRONMENTAL SENSING,https://lens.org/122-635-560-555-198,2018,"An aerial system (10) and method of operating an aerial system (10) are provided. The aerial system (10) includes a body (12), a lift mechanism (14), a processing system (20), a camera (30), and a sensor module (16, 18). The lift mechanism (14) is coupled to the body (12) and configured to controllably provide lift and/or thrust. The processing system (20) is configured to control the lift mechanism (14) to provide flight to the aerial system (10). The camera (30) is coupled to the body (12) and is configured to obtain images of an environment proximate the aerial system (10). The sensor module (16, 18) is coupled to the body (12) and includes an emitter (18) and a receiver (16). The receiver (16) is configured to sense data related to an ambient environment associated with the aerial system (10). The processing system (20) controls a controllable parameter of the lift mechanism (14) or the emitter (18) as a function of the sensed data. The aerial system (10) may decrease user cognitive load resulting, and increase the reliability of autopilot application."
UNMANNED AERIAL VEHICLE SYSTEM AND METHOD WITH ENVIRONMENTAL SENSING,https://lens.org/174-830-816-387-731,2018,"An aerial system (10) and method of operating an aerial system (10) are provided. The aerial system (10) includes a body (12), a lift mechanism (14), a processing system (20), a camera (30), and a sensor module (16, 18). The lift mechanism (14) is coupled to the body (12) and configured to controllably provide lift and/or thrust. The processing system (20) is configured to control the lift mechanism (14) to provide flight to the aerial system (10). The camera (30) is coupled to the body (12) and is configured to obtain images of an environment proximate the aerial system (10). The sensor module (16, 18) is coupled to the body (12) and includes an emitter (18) and a receiver (16). The receiver (16) is configured to sense data related to an ambient environment associated with the aerial system (10). The processing system (20) controls a controllable parameter of the lift mechanism (14) or the emitter (18) as a function of the sensed data. The aerial system (10) may decrease user cognitive load resulting, and increase the reliability of autopilot application."
METHOD AND SYSTEM FOR CONTROLLING MANNED AND UNMANNED AIRCRAFT USING SPEECH RECOGNITION TOOLS,https://lens.org/101-050-978-619-165,2008,"A system and method is provided for controlling an aircraft. At least one transceiver is provided to receive a voice instruction from an air traffic controller, and transmit a voice response to the air traffic controller. A response logic unit can be provided to interpret the received voice instruction from the air traffic controller, determine a response to the interpreted voice instruction, and translate the interpreted voice instruction to a command suitable for input to at least one autopilot unit. An autopilot unit can also be provided to receive the command from the response logic unit, wherein the command is configured to guide the flight of the unmanned aircraft."
Unmanned Aerial Vehicle Search and Rescue System,https://lens.org/105-014-396-561-167,2021,"A search and rescue drone system includes a buoyant body member, a frame attached to the buoyant body member for carrying a motor and propeller, and an electronic array including a camera, GPS, an EPIRB radio distress beacon, and a transmitter/receiver for remote control flying the drone and communicating with an operator. A laser guidance system may provide coordinates for landing near a swimmer in distress. The search and rescue drone may also be programmed to simply fly to the location of an electronic wearable device, like a bracelet, that is worn by a man overboard. In another embodiment, the search and rescue drone includes pivoting motor mounts, so that it can take off and land vertically with propellers rotating in a horizontal plane, and then the propellers may pivot to rotate in a vertical plane for propulsion across water similar to a fan boat with rescued people aboard."
Unmanned Aerial Vehicle Search and Rescue System,https://lens.org/197-577-811-970-280,2023,"A search and rescue drone system includes a buoyant body member, a frame attached to the buoyant body member for carrying a motor and propeller, and an electronic array including a camera, GPS, an EPIRB radio distress beacon, and a transmitter/receiver for remote control flying the drone and communicating with an operator. A laser guidance system may provide coordinates for landing near a swimmer in distress. The search and rescue drone may also be programmed to simply fly to the location of an electronic wearable device, like a bracelet, that is worn by a man overboard. In another embodiment, the search and rescue drone includes pivoting motor mounts, so that it can take off and land vertically with propellers rotating in a horizontal plane, and then the propellers may pivot to rotate in a vertical plane for propulsion across water similar to a fan boat with rescued people aboard."
Unmanned Aerial Vehicle Search and Rescue System,https://lens.org/197-577-811-970-280,2023,"A search and rescue drone system includes a buoyant body member, a frame attached to the buoyant body member for carrying a motor and propeller, and an electronic array including a camera, GPS, an EPIRB radio distress beacon, and a transmitter/receiver for remote control flying the drone and communicating with an operator. A laser guidance system may provide coordinates for landing near a swimmer in distress. The search and rescue drone may also be programmed to simply fly to the location of an electronic wearable device, like a bracelet, that is worn by a man overboard. In another embodiment, the search and rescue drone includes pivoting motor mounts, so that it can take off and land vertically with propellers rotating in a horizontal plane, and then the propellers may pivot to rotate in a vertical plane for propulsion across water similar to a fan boat with rescued people aboard."
Unmanned aerial vehicle search and rescue system,https://lens.org/041-155-507-261-570,2021,"A search and rescue drone system includes a buoyant body member, a frame attached to the buoyant body member for carrying a motor and propeller, and an electronic array including a camera, GPS, an EPIRB radio distress beacon, and a transmitter/receiver for remote control flying the drone and communicating with an operator. A laser guidance system may provide coordinates for landing near a swimmer in distress. The search and rescue drone may also be programmed to simply fly to the location of an electronic wearable device, like a bracelet, that is worn by a man overboard. In another embodiment, the search and rescue drone includes pivoting motor mounts, so that it can take off and land vertically with propellers rotating in a horizontal plane, and then the propellers may pivot to rotate in a vertical plane for propulsion across water similar to a fan boat with rescued people aboard."
Drone Safety Mechanism,https://lens.org/024-511-051-031-591,2017,"A drone safety mechanism that prevents autonomously controlled or human-in-the-loop drones from interfering with aircraft. A signal is generated at the center of an area to be maintained free of drone activity. The signal decays with distance from the source of the signal. A sensor onboard the drone is able to measure the signal itself, as well as the strength of the signal. When the signal strength passes above some threshold level, or the signal provides some other message, an intention is sent to the drone that forces the drone to stop and/or descend. The signal may be a preexisting signal, such as an electromagnetic signal emitted from a radar system atop an air traffic control tower. To prevent drones interfering with aircraft in flight, the signal may be emitted from the aircraft itself."
NAVIGATION ELECTRONIC CARD SUPPORT FOR A ROTARY WING DRONE,https://lens.org/129-159-593-335-570,2012,"The support (300) is intended to be fixed in a housing provided in the drone, through a mechanical interface (310) made of a material absorbing the mechanical vibrations. The mechanical interface, annular in shape, is intended to be attached to a corresponding annular shoulder provided in the housing. A fastening part (301) for fixing the support in the housing carries the mechanical interface (310), with at least one connection leg (302) supporting the navigation electronic card (320) and mounted free at one end on the fastening part. A battery (400) for the power supply of the drone is further accommodated in the support. The navigation electronic card may notably include a navigation sensor (321) such as an accelerometer, placed on the card in such a manner to be positioned at the barycenter of the drone."
Navigation electronic card support for a rotary wing drone,https://lens.org/034-961-631-114-845,2014,"The support (300) is intended to be fixed in a housing provided in the drone, through a mechanical interface (310) made of a material absorbing the mechanical vibrations. The mechanical interface, annular in shape, is intended to be attached to a corresponding annular shoulder provided in the housing. A fastening part (301) for fixing the support in the housing carries the mechanical interface (310), with at least one connection leg (302) supporting the navigation electronic card (320) and mounted free at one end on the fastening part. A battery (400) for the power supply of the drone is further accommodated in the support. The navigation electronic card may notably include a navigation sensor (321) such as an accelerometer, placed on the card in such a manner to be positioned at the barycenter of the drone."
AIRBORNE DRONE TRAFFIC BROADCASTING AND ALERTING SYSTEM,https://lens.org/095-210-791-306-921,2019,"A system and method to alert pilots of the presence of drone aircraft and to document or report errant drone flight operations, in particular to alert and report drone aircraft which may present a hazard to a piloted aircraft and/or are operating outside governing regulations. In one embodiment, the system comprises a surveillance subsystem configured to identify a drone operating in an airspace adjacent the aircraft; an imaging subsystem configured to acquire at least one image of the drone; a triggering subsystem interconnected with the surveillance subsystem and configured to activate the imaging subsystem; a navigational subsystem configured to provide aircraft state data associated with the at least one image; and a communication subsystem configured to transmit the at least one image and the associated aircraft state data to a receiving station; wherein the at least one image and the associated aircraft state data are transmitted to the receiving station."
Airborne drone traffic broadcasting and alerting system,https://lens.org/116-510-447-602-371,2019,"A system and method to alert pilots of the presence of drone aircraft and to document or report errant drone flight operations, in particular to alert and report drone aircraft which may present a hazard to a piloted aircraft and/or are operating outside governing regulations. In one embodiment, the system comprises a surveillance subsystem configured to identify a drone operating in an airspace adjacent the aircraft; an imaging subsystem configured to acquire at least one image of the drone; a triggering subsystem interconnected with the surveillance subsystem and configured to activate the imaging subsystem; a navigational subsystem configured to provide aircraft state data associated with the at least one image; and a communication subsystem configured to transmit the at least one image and the associated aircraft state data to a receiving station; wherein the at least one image and the associated aircraft state data are transmitted to the receiving station."
LAUNCH DEVICE FOR REMOTELY CONTROLLED AIRCRAFT,https://lens.org/088-762-265-782-567,2016,"A device to launch a drone, comprises a rail extending along a longitudinal axis and a carriage, mobile on the rail, that can support and launch a drone by the acceleration of the carriage between a loading position and an end-of-travel position, further comprising a spring mechanism configured to exert a return force on the carriage along the longitudinal axis that is substantially constant between the two positions. The spring mechanism comprises at least one coil spring around a hub, one end of the coil spring being linked to the carriage, the return force exerted on the carriage being generated by the coiling of the spring around the hub."
Voice controlled assistant with stereo sound from two speakers,https://lens.org/056-503-370-063-68X,2017,"A voice controlled assistant has two speakers to produce high quality stereo sound. The voice controlled assistant generates a first frequency portion and a second frequency portion used to produce stereo sound. The frequency portion is filtered to remove a range of frequencies, such as the low frequency range. The second frequency portion, together with the frequency portion removed from the first frequency portion, are output as sound."
UNMANNED AERIAL VEHICLES,https://lens.org/091-327-876-793-742,2019,"A UAV comprises a camera and a controller. The controller is configured to: (a) receive image data from the camera, (b) determine, based on the received image data, whether or not a predetermined visibility condition associated with an operator of the UAV is satisfied, and (c) perform a predetermined action to attempt to operate in accordance with a predetermined visibility state with respect to the operator of the UAV based on a result of the determination."
Unmanned aerial vehicles,https://lens.org/123-917-481-754-502,2021,"A UAV comprises a camera and a controller. The controller is configured to: (a) receive image data from the camera, (b) determine, based on the received image data, whether or not a predetermined visibility condition associated with an operator of the UAV is satisfied, and (c) perform a predetermined action to attempt to operate in accordance with a predetermined visibility state with respect to the operator of the UAV based on a result of the determination."
Small rotor unmanned aerial vehicle autonomous obstacle avoidance flight control system and control method,https://lens.org/003-548-306-061-221,2015,"The invention discloses a small rotor unmanned aerial vehicle autonomous obstacle avoidance flight control system and a control method. The system comprises an autonomous flight control system, a ground station control system and a manual emergency intervention system. The autonomous flight control system comprises a flight control computer module, an obstacle detection module, a navigation and positioning module, a driving control module, an execution mechanism, an attitude reference module and a wireless communication link module. The ground station control system comprises a wireless data transmission link module and a ground control console. The manual emergency intervention system comprises a remote control receiver and a Futaba remote controller. A corresponding small rotor unmanned aerial vehicle autonomous obstacle avoidance flight control method is also provided. The autonomous obstacle avoidance flight control system is divided into three parts, a complete small rotor helicopter autonomous obstacle avoidance flight control system which integrates the autonomous flight control system, a dynamic flight path planning system and an emergency treatment mechanism as a whole is provided, and flight environment adaptability and job task universality are strong."
AUTONOMOUS VEHICLE,https://lens.org/062-504-520-517-977,2023,"An autonomous vehicle capable of executing a task corresponding to a conveyance instruction by sound is provided. The autonomous vehicle docks with a conveyance target and conveys the conveyance target. The autonomous vehicle includes a docking mechanism configured to dock with the conveyance target, an audio input device, and a controller. The controller is configured to control the docking mechanism to dock with the conveyance target that is identified based on a conveyance instruction acquired via the audio input device, and to control conveyance of the docked conveyance target to a conveyance destination position that is identified based on the conveyance instruction."
Water drone,https://lens.org/001-380-449-538-155,2018,"A water drone capable of navigating on the surface, or below the surface, of a body of water. In some embodiments such a vehicle is light-weight, electric-powered, and propeller-driven, and may be operated by remote control from the shore and guided with simple autopilot commands. The vehicle may have two actuators at the rear of the vehicle, each including a motor and a propeller, and each capable of producing forward or reverse thrust. The vehicle may be capable of travelling horizontally through the surf zone and diving vertically through the water column to the seafloor. The vehicle may monitor its own location and depth and may measure environmental conditions such as water temperature; such measurements may be communicated back to the operator using a telemetry system."
Water drone,https://lens.org/000-214-143-862-980,2019,"A water drone capable of navigating on the surface, or below the surface, of a body of water. In some embodiments such a vehicle is light-weight, electric-powered, and propeller-driven, and may be operated by remote control from the shore and guided with simple autopilot commands. The vehicle may have two actuators at the rear of the vehicle, each including a motor and a propeller, and each capable of producing forward or reverse thrust. The vehicle may be capable of travelling horizontally through the surf zone and diving vertically through the water column to the seafloor. The vehicle may monitor its own location and depth and may measure environmental conditions such as water temperature; such measurements may be communicated back to the operator using a telemetry system."
WATER DRONE,https://lens.org/004-232-996-705-308,2020,"A water drone capable of navigating on the surface, or below the surface, of a body of water. In some embodiments such a vehicle is light-weight, electric-powered, and propeller-driven, and may be operated by remote control from the shore and guided with simple autopilot commands. The vehicle may have two actuators at the rear of the vehicle, each including a motor and a propeller, and each capable of producing forward or reverse thrust. The vehicle may be capable of travelling horizontally through the surf zone and diving vertically through the water column to the seafloor. The vehicle may monitor its own location and depth and may measure environmental conditions such as water temperature; such measurements may be communicated back to the operator using a telemetry system."
WATER DRONE,https://lens.org/166-264-284-863-229,2017,"A water drone capable of navigating on the surface, or below the surface, of a body of water. In some embodiments such a vehicle is light-weight, electric-powered, and propeller-driven, and may be operated by remote control from the shore and guided with simple autopilot commands. The vehicle may have two actuators at the rear of the vehicle, each including a motor and a propeller, and each capable of producing forward or reverse thrust. The vehicle may be capable of travelling horizontally through the surf zone and diving vertically through the water column to the seafloor. The vehicle may monitor its own location and depth and may measure environmental conditions such as water temperature; such measurements may be communicated back to the operator using a telemetry system."
Water drone,https://lens.org/106-419-433-124-09X,2018,"A water drone capable of navigating on the surface, or below the surface, of a body of water. In some embodiments such a vehicle is light-weight, electric-powered, and propeller-driven, and may be operated by remote control from the shore and guided with simple autopilot commands. The vehicle may have two actuators at the rear of the vehicle, each including a motor and a propeller, and each capable of producing forward or reverse thrust. The vehicle may be capable of travelling horizontally through the surf zone and diving vertically through the water column to the seafloor. The vehicle may monitor its own location and depth and may measure environmental conditions such as water temperature; such measurements may be communicated back to the operator using a telemetry system."
HORIZONTALLY ARTICULATED ROBOT,https://lens.org/167-839-003-462-308,2017,"A horizontally articulated robot includes a base, a first arm provided at the base, and a control device controlling the first arm, in which at least a part of the control device is located inside the base."
Horizontally articulated robot,https://lens.org/020-786-902-778-309,2021,"A horizontally articulated robot includes a base, a first arm provided at the base, and a control device controlling the first arm, in which at least a part of the control device is located inside the base."
Unmanned Aerial Vehicle Control Techniques,https://lens.org/068-499-442-480-164,2018,"A method of controlling an unmanned aerial vehicle executing a mission in a defined mission area including a first observation area within a Visual Line of Sight (VLOS) of a First Observer (FO), a second observation area within a VLOS of a second observer (SO), and a transition area within the VLOS of both the FO and the SO, the method including: the vehicle moving into the transition area after completing part of the mission within the first observation area, in sight of the FO; and in response to the vehicle moving into the transition area, determining whether the vehicle is in sight of the SO. The vehicle is including multiple processing systems in wireless communication with multiple remote user interfaces and a radar sensor mounted on the vehicle using a moveable mount for moving the radar sensor between different radar orientations, the radar sensor generating a range signal."
Unmanned aerial vehicle control techniques,https://lens.org/065-166-900-733-559,2018,"A method of controlling an unmanned aerial vehicle executing a mission in a defined mission area including a first observation area within a Visual Line of Sight (VLOS) of a First Observer (FO), a second observation area within a VLOS of a second observer (SO), and a transition area within the VLOS of both the FO and the SO, the method including: the vehicle moving into the transition area after completing part of the mission within the first observation area, in sight of the FO; and in response to the vehicle moving into the transition area, determining whether the vehicle is in sight of the SO. The vehicle is including multiple processing systems in wireless communication with multiple remote user interfaces and a radar sensor mounted on the vehicle using a moveable mount for moving the radar sensor between different radar orientations, the radar sensor generating a range signal."
Aerial drone for radar calibration,https://lens.org/140-379-553-388-785,2020,"An aerial drone or unmanned aerial vehicle (UAV) is provided for radar calibration testing. The drone includes an airframe including a fuselage with nose and tail, wings and elevators. The drone includes at least one antenna attached to the airframe, as well as a signal adapter coupled to the antenna to receive impinging radar signals and transmit an electromagnetic (EM) field that effectively cancels or combines with the scattered field of the drone, depending upon the adapter's mode of operation. In the first mode of operation, the adapter transmits an EM field that has an opposite phase to the drone's scattered field thereby reducing the radar cross-section of the drone. In the second mode, the adapter transmits an EM field that is in-phase with the scattered field thereby increasing the radar cross-section of the drone."
Apparatus for controlling a remote controlled airplane,https://lens.org/191-951-948-678-685,2001,"An apparatus for operating a remote controlled airplane including a frame, a remote control unit received within the frame and having first and second joystick elements, a joystick controller cantably mounted to the frame so as to have a forward/backward movement and a side-to-side movement, a first linkage connected to the joystick controller and to the first joystick element and adapted to cause an up-and-down movement of tie first joystick element relative to the forward/backward movement of the joystick controller, and a second linkage connected to the joystick controller and to the first joystick element. The second linkage is adapted to cause a side-to-side movement of the first joystick element relative to the side-to-side movement of the joystick controller. A pedal structure is pivotally mounted to the frame so as to be pivotable about a central axis. A third linkage connects the pedal structure to the second joystick element. A throttle member is pivotally connected to the frame and has a fourth linkage connected to the second joystick element. A pair of front wheels are rotatably mounted to a forward end of the frame and a third wheel is rotatably mounted in a transverse plane to a rearward end of the frame. An actuator mounted on the joystick controller causes a motor to drive the rear wheel."
Enhanced Unmanned Aerial Vehicle Flight With Situational Awareness For Moving Vessels,https://lens.org/050-472-778-706-389,2023,"An unmanned aerial vehicle (UAV) comprises a flight control system and an electromechanical system directed by the flight control system. The flight control system is configured to track a position of a beacon that is in motion and monitor a difference between an actual position of the unmanned aerial vehicle and a desired position of the unmanned aerial vehicle relative to the position of the beacon. The flight control system configures one or more flight objectives based on one or more factors comprising whether the difference between the actual position and the desired position exceeds a threshold, wherein the flight objectives comprise a velocity objective and a position objective. The flight control system also commands the electromechanical system based at least on the one or more flight objectives."
Autonomous vehicle communication configuration system,https://lens.org/040-211-795-896-905,2017,"An autonomous vehicle (AV) can include a communication system to communicate with a backend system, a sensor system to collect sensor data representing an operational environment of the AV, and a control system that can processes the sensor data to (i) perform a localization operation to determine a location and an orientation of the AV within a given region, and (ii) autonomously operate the AV's acceleration, braking, and steering system throughout the given region. Based on the localization operation, the AV can implement a set of configuration commands to configure the communication system to transmit and receive data with the backend system using a number of specified network nodes."
XR DEVICE AND METHOD FOR CONTROLLING THE SAME,https://lens.org/114-011-671-975-798,2021,"The present disclosure relates to an XR device and a method for controlling the same, and more particularly, is applicable to a 5G communication technology field, a robot technology field, an autonomous technology field and an artificial intelligence (AI) technology field. The method for controlling an XR device of a vehicle comprises acquiring a camera view by capturing an image in front of the vehicle; acquiring position information of the vehicle by detecting a position of the vehicle, acquiring movement information of the vehicle by detecting movement of the vehicle, and providing navigation of an augmented reality (AR) mode displaying at least one virtual object for guiding a path by overlapping the at least one virtual object on the camera view based on at least the position information of the vehicle or the movement information of the vehicle, wherein the step of providing navigation further comprises performing calibration based on the camera view, a vanish point of a road and a bonnet line of the vehicle included in the camera view, or the movement information of the vehicle."
UAV Routing and Data Extraction,https://lens.org/089-209-590-299-387,2018,This invention relates to a drone based predictive system for detecting and analyzing web and drone based data in order to mitigate potential losses and enhance risk mitigation activities in commercial insurance such as for business owners policies and workers compensation. The drone is able to capture from a plurality of angles and perspective to provide data to effect a variety of insurance based actions.
UAV routing and data extraction,https://lens.org/002-263-745-228-729,2020,This invention relates to a drone based predictive system for detecting and analyzing web and drone based data in order to mitigate potential losses and enhance risk mitigation activities in commercial insurance such as for business owners policies and workers compensation. The drone is able to capture from a plurality of angles and perspective to provide data to effect a variety of insurance based actions.
Servo control system for a co-axial rotary winged aircraft,https://lens.org/002-784-645-052-344,1991,"A servo control system for a radio controlled co-axial rotor helicopter includes a receiver 4 to provide signals indicative of operator desired pitch, yaw, roll, and collective commands to an electronic mixer unit 30 which translates these command signals into six control signals 34-42 utilized by servos 50-60 to properly displace the rotor blades 256, 258."
Electronic remote control and method for control-line airplane models,https://lens.org/175-010-294-912-30X,1991,A control apparatus for model airplanes is presented which includes a remote radio transmitter which communicates with a rotatably mounted receiver positioned on a fixed pylon. The receiver has a control handle joined thereto whereby control lines are actuated for controlling the upward and downward movement of the elevators of the model airplane as the plane encircles the pylon.
Pick-up authentication via audible signals,https://lens.org/161-166-135-643-977,2022,"A method including sending a communication to a user device associated with the user and receiving, at the autonomous vehicle, an audible authentication code. The communication can include a location of the autonomous vehicle. The location can be effective to assist the user device to audibly provide guidance from a location of the mobile device to the location of the autonomous vehicle. The audible authentication code can be effective to assist an authentication process between the autonomous vehicle and the user."
PICK-UP AUTHENTICATION VIA AUDIBLE SIGNALS,https://lens.org/165-095-932-734-302,2021,"A method including sending a communication to a user device associated with the user and receiving, at the autonomous vehicle, an audible authentication code. The communication can include a location of the autonomous vehicle. The location can be effective to assist the user device to audibly provide guidance from a location of the mobile device to the location of the autonomous vehicle. The audible authentication code can be effective to assist an authentication process between the autonomous vehicle and the user."
Unmanned aerial vehicle system and method with environmental sensing,https://lens.org/092-336-072-981-722,2020,"An aerial system and method of operating an aerial system is provided. The aerial system includes a body, a lift mechanism, a processing system, a camera, and a sensor module. The lift mechanism is coupled to the body and configured to controllably provide lift and/or thrust. The processing system is configured to control the lift mechanism to provide flight to the aerial system. The camera is coupled to the body and is configured to obtain images of an environment proximate the aerial system. The sensor module is coupled to the body and includes an emitter and a receiver. The receiver is configured to sense data related to an ambient environment associated with the aerial system. The processing system controls a controllable parameter of the lift mechanism or the emitter as a function of the sensed data."
UNMANNED AERIAL VEHICLE SYSTEM AND METHOD WITH ENVIRONMENTAL SENSING,https://lens.org/137-103-735-897-139,2019,"An aerial system and method of operating an aerial system is provided. The aerial system includes a body, a lift mechanism, a processing system, a camera, and a sensor module. The lift mechanism is coupled to the body and configured to controllably provide lift and/or thrust. The processing system is configured to control the lift mechanism to provide flight to the aerial system. The camera is coupled to the body and is configured to obtain images of an environment proximate the aerial system. The sensor module is coupled to the body and includes an emitter and a receiver. The receiver is configured to sense data related to an ambient environment associated with the aerial system. The processing system controls a controllable parameter of the lift mechanism or the emitter as a function of the sensed data."
UNMANNED AERIAL VEHICLE SYSTEM AND METHOD WITH ENVIRONMENTAL SENSING,https://lens.org/116-102-952-478-508,2018,"An aerial system and method of operating an aerial system is provided. The aerial system includes a body, a lift mechanism, a processing system, a camera, and a sensor module. The lift mechanism is coupled to the body and configured to controllably provide lift and/or thrust. The processing system is configured to control the lift mechanism to provide flight to the aerial system. The camera is coupled to the body and is configured to obtain images of an environment proximate the aerial system. The sensor module is coupled to the body and includes an emitter and a receiver. The receiver is configured to sense data related to an ambient environment associated with the aerial system. The processing system controls a controllable parameter of the lift mechanism or the emitter as a function of the sensed data."
Unmanned aerial vehicle system and method with environmental sensing,https://lens.org/195-365-086-203-101,2018,"An aerial system and method of operating an aerial system is provided. The aerial system includes a body, a lift mechanism, a processing system, a camera, and a sensor module. The lift mechanism is coupled to the body and configured to controllably provide lift and/or thrust. The processing system is configured to control the lift mechanism to provide flight to the aerial system. The camera is coupled to the body and is configured to obtain images of an environment proximate the aerial system. The sensor module is coupled to the body and includes an emitter and a receiver. The receiver is configured to sense data related to an ambient environment associated with the aerial system. The processing system controls a controllable parameter of the lift mechanism or the emitter as a function of the sensed data."
A REMOTE CONTROLLED FISH FINDING SYSTEM,https://lens.org/027-588-439-091-042,2014,"There is provided a system for finding fish in a remote environment, the system comprising a remotely controllable device (200) and a control unit (100) in communication with the remotely controllable device (200)."
Stations for unmanned aerial vehicles,https://lens.org/142-623-844-616-391,2023,"Stations for a drone are described as well as a monitoring system that is configured to monitor a property using one or more drones. The drone is launched from a docking station and configured to navigate the property to perform operations to monitor the property. The docking station is located at an area of the property. The docking station includes a landing surface that is parallel to a particular area of the property that supports the docking station. A positioning surface of the docking station slopes toward the landing surface. The positioning surface, including its slope, is configured to receive the drone and guide the drone toward the landing surface."
Stations for unmanned aerial vehicles,https://lens.org/142-623-844-616-391,2023,"Stations for a drone are described as well as a monitoring system that is configured to monitor a property using one or more drones. The drone is launched from a docking station and configured to navigate the property to perform operations to monitor the property. The docking station is located at an area of the property. The docking station includes a landing surface that is parallel to a particular area of the property that supports the docking station. A positioning surface of the docking station slopes toward the landing surface. The positioning surface, including its slope, is configured to receive the drone and guide the drone toward the landing surface."
METHOD AND DEVICE FOR CONTROLLING UNMANNED AERIAL VEHICLE TO ACCESS NETWORK,https://lens.org/134-182-152-666-688,2021,"The present disclosure provides a method and device for controlling an unmanned aerial vehicle (UAV) to access a network, said method comprising: acquiring, by means of a first communication module, information to be transmitted between a UAV and a target base station; Forwarding, to a second communication module, the information to be transmitted; and by means of the second communication module, sending, to an information receiving end, the information to be transmitted, the information receiving end comprising: the UAV, or a target base station of a mobile communication network; the first communication module and the second communication module being different types of communication modules, the communication modules comprising: a cellular communication module and a wireless local area network (WLAN) communication module. The method for controlling the UAV to access the network provided by the present disclosure can be used to enable the UAV to access the mobile communication network smoothly, without increasing the manufacturing costs of the UAV."
Systems and methods for providing emergency alerts at emergency landing areas of unmanned aerial vehicles,https://lens.org/162-710-668-004-767,2019,"In some embodiments, methods and systems are provided that provide for controlling unmanned aerial vehicles (UAVs) experiencing emergency landings and providing emergency alerts to the predicted emergency landing locations of the UAV. Each UAV includes sensors configured to detect at least one status input associated with the UAV during flight along its flight route. Each UAV analyzes the status inputs while in flight in order to predict an emergency landing location where the UAV would land if unable to fly due to an emergency condition. The UAV is configured to transmit an alert signal to electronic devices proximate the predicted emergency landing location to notify users of the electronic devices that the unmanned aerial vehicle is going to experience an emergency landing at the predicted emergency landing location."
SYSTEMS AND METHODS FOR PROVIDING EMERGENCY ALERTS AT EMERGENCY LANDING AREAS OF UNMANNED AERIAL VEHICLES,https://lens.org/166-100-018-679-778,2019,"In some embodiments, methods and systems are provided that provide for controlling unmanned aerial vehicles (UAVs) experiencing emergency landings and providing emergency alerts to the predicted emergency landing locations of the UAV. Each UAV includes sensors configured to detect at least one status input associated with the UAV during flight along its flight route. Each UAV analyzes the status inputs while in flight in order to predict an emergency landing location where the UAV would land if unable to fly due to an emergency condition. The UAV is configured to transmit an alert signal to electronic devices proximate the predicted emergency landing location to notify users of the electronic devices that the unmanned aerial vehicle is going to experience an emergency landing at the predicted emergency landing location."
Systems and methods for providing emergency alerts at emergency landing areas of unmanned aerial vehicles,https://lens.org/064-600-460-852-943,2020,"In some embodiments, methods and systems are provided that provide for controlling unmanned aerial vehicles (UAVs) experiencing emergency landings and providing emergency alerts to the predicted emergency landing locations of the UAV. Each UAV includes sensors configured to detect at least one status input associated with the UAV during flight along its flight route. Each UAV analyzes the status inputs while in flight in order to predict an emergency landing location where the UAV would land if unable to fly due to an emergency condition. The UAV is configured to transmit an alert signal to electronic devices proximate the predicted emergency landing location to notify users of the electronic devices that the unmanned aerial vehicle is going to experience an emergency landing at the predicted emergency landing location."
Presenting snapshot of controlled device display on display of remote commander to facilitate control of the controlled device by user who cannot see controlled device,https://lens.org/147-152-284-807-328,2015,"A system includes a controlled device presenting on a device display an image including a native user interface (UI) and a remote commander (RC) communicating with the controlled device to receive the image and present it on an RC display, so that a user may manipulate the RC looking at the RC display to control the controlled device using the native UI even if the user cannot see the display of the controlled device."
PRESENTING SNAPSHOT OF CONTROLLED DEVICE DISPLAY ON DISPLAY OF REMOTE COMMANDER TO FACILITATE CONTROL OF THE CONTROLLED DEVICE BY USER WHO CANNOT SEE CONTROLLED DEVICE,https://lens.org/078-774-045-567-502,2014,"A system includes a controlled device presenting on a device display an image including a native user interface (UI) and a remote commander (RC) communicating with the controlled device to receive the image and present it on an RC display, so that a user may manipulate the RC looking at the RC display to control the controlled device using the native UI even if the user cannot see the display of the controlled device."
"FLIGHT DEVICE, FLIGHT METHOD THROWN BY USER AND STORAGE MEDIUM",https://lens.org/019-135-642-703-380,2017,"A flight device includes at least one propelling unit and a controller unit for flying in the air, and the flight device is thrown by a user. The controller unit drives the propelling unit after throwing is performed by the user, such that the flight device flies based on a state of the flight device at a moment when the throwing is performed."
"Flight device, flight method thrown by user and storage medium",https://lens.org/028-637-310-863-624,2018,"A flight device includes at least one propelling unit and a controller unit for flying in the air, and the flight device is thrown by a user. The controller unit drives the propelling unit after throwing is performed by the user, such that the flight device flies based on a state of the flight device at a moment when the throwing is performed."
"DYNAMIC MANAGEMENT SYSTEM, METHOD, AND RECORDING MEDIUM FOR COGNITIVE DRONE-SWARMS",https://lens.org/085-616-896-974-747,2017,"A method, system, and recording medium including a drone and pattern recruiting device configured to recruit a plurality of drones based on a mission, a flocking goal device configured to arrange the plurality of drones in the drone-swarm in a pattern to satisfy the mission, and a changing device configured to adaptively change the pattern of the drone-swarm based on a condition of the mission indicating a needed change and to cause the drone and pattern recruiting device to recruit an additional drone for the needed change."
"Dynamic management system, method, and recording medium for cognitive drone-swarms",https://lens.org/145-449-600-646-47X,2018,"A method, system, and recording medium including a drone and pattern recruiting device configured to recruit a plurality of drones based on a mission, a flocking goal device configured to arrange the plurality of drones in the drone-swarm in a pattern to satisfy the mission, and a changing device configured to adaptively change the pattern of the drone-swarm based on a condition of the mission indicating a needed change and to cause the drone and pattern recruiting device to recruit an additional drone for the needed change."
QUADCOPTER SENSOR NOISE AND CAMERA NOISE RECORDING AND SIMULATION,https://lens.org/176-289-775-341-71X,2020,A method of simulating a quadcopter includes recording camera output for one or more video cameras under constant conditions and subtracting a constant signal from the recorded camera output to obtain a camera noise recording. Simulated camera noise is generated from the camera noise recording and is added to a plurality of simulated camera outputs of a quadcopter simulator to generate noise-added simulated camera outputs. The noise-added simulated camera outputs are sent to an Artificial Intelligence (AI) controller coupled to the quadcopter simulator for the AI controller to use to pilot a simulated quadcopter of the quadcopter simulator.
Quadcopter sensor noise and camera noise recording and simulation,https://lens.org/181-273-180-105-704,2023,A method of simulating a quadcopter includes recording camera output for one or more video cameras under constant conditions and subtracting a constant signal from the recorded camera output to obtain a camera noise recording. Simulated camera noise is generated from the camera noise recording and is added to a plurality of simulated camera outputs of a quadcopter simulator to generate noise-added simulated camera outputs. The noise-added simulated camera outputs are sent to an Artificial Intelligence (AI) controller coupled to the quadcopter simulator for the AI controller to use to pilot a simulated quadcopter of the quadcopter simulator.
"UNMANNED AERIAL VEHICLE, METHOD OF PROVIDING AIRBORNE REPLENISHMENT, AERIAL PLATFORM AND CONTROL METHOD THEREOF",https://lens.org/194-906-509-742-012,2018,"An unmanned aerial vehicle (UAV) includes a detection device configured to generate a supplement demand signal in response to a need of the UAV for resource supplement, a wireless communication device configured to establish a wireless communication connection with at least one aerial platform and communicate with the at least one aerial platform in response to the supplement demand signal being generated, and a flight control device configured to determine a target aerial platform from the at least one aerial platform, generate a flight control signal based upon communication information of the target aerial platform received by the wireless communication device, and adjust a spatial distance between the UAV and the target aerial platform based upon the flight control signal to enable an airborne replenishment to the UAV by the target aerial platform."
VOICE RECOGNITION SYSTEM FOR MEDICAL DEVICES,https://lens.org/082-844-601-963-887,2010,"A system for transmitting voice commands to a medical device for carrying out those commands by the medical device. The system includes a remote control device that receives the voice commands from the caregiver and recognizes the caregiver as being authorized to give such commands. The recognized commands are then analyzed to determine the particular command, and the signals representing that command are transmitted in digital form by a wireless protocol, such as a ZigBee wireless protocol, to a receiving module incorporated into or in communication with the medical device. The receiving module decodes the wireless protocol, identifies the particular command, and interfaces that command to the patient device, whereby the command effects the operation of the patient device, such as by silencing an alarm on the medical device."
Unmanned aerial vehicle flight control system,https://lens.org/079-170-790-626-911,2018,An onboard system for controlling flight of an unmanned aerial vehicle. The system comprises: a flight management system configured for controlling flight of the unmanned aerial vehicle; a mission control module configured to send commands to the flight management system for guiding the unmanned aerial vehicle to perform a mission; a safety module configured to communicate commands to the flight management system for guiding the unmanned aerial vehicle to fly in a safe mode; a communication control component which is switchable between a mission state in which the flight management system receives commands from the mission control module and a safety state in which the flight management system receives commands from the safety module; and a monitor module configured to determine whether a trigger condition warranting a change in mode is present or not and to cause the communication control component to switch from the mission state to the safety state when the trigger condition is present.
UNMANNED AERIAL VEHICLE FLIGHT CONTROL FOR CHASING A MOVING TARGET EQUIPPED WITH A TRACKABLE BEACON,https://lens.org/119-414-922-415-735,2023,"An unmanned aerial vehicle comprises a flight control system and an electromechanical system directed by the flight control system. The flight control system is configured to track a position of a beacon that is in motion and monitor a difference between an actual position of the unmanned aerial vehicle and a desired position of the unmanned aerial vehicle relative to the position of the beacon. The flight control system configures one or more flight objectives based on one or more factors comprising whether the difference between the actual position and the desired position exceeds a threshold, wherein the flight objectives comprise a velocity objective and a position objective. The flight control system also commands the electromechanical system based at least on the one or more flight objectives."
"Wireless Network Communication Method, Network Device, and Terminal",https://lens.org/084-648-443-959-501,2021,"A wireless network communication method, a network device, and a terminal, where the method includes: An uncrewed aerial vehicle traffic management entity receives an authorization request. The uncrewed aerial vehicle traffic management entity sends an authorization response. The authorization request is used to request authorization to control an uncrewed aerial vehicle by a terminal, and the authorization response is used to indicate whether the terminal is allowed to control the uncrewed aerial vehicle. Alternatively, the authorization request is used to request authorization to pair a terminal with an uncrewed aerial vehicle controller, and the authorization response is used to indicate whether the terminal is allowed to be paired with the uncrewed aerial vehicle controller."
Insurance underwriting and re-underwriting implementing unmanned aerial vehicles (UAVS),https://lens.org/052-223-141-577-319,2019,"Unmanned aerial vehicles (UAVs) may facilitate insurance-related tasks. UAVs may actively be dispatched to an area surrounding an insured or potentially insured asset, such as with the insurance customer's permission, and collect data related to the insured or potentially insured asset, such as size, height, roof shape, materials (siding, roofing), etc. which may form a basis of the underwriting detail used to evaluate a property. The drone data may reveal site characteristics, such as slope or grade of a parcel; the proximity to other structures (and their uses); trees; rivers; coastlines; and earthquake faults. The drone data may be used by an insurance provider remote server to assess the risk associated with an insured asset, generate or modify an insurance premium or discount, etc. The drone data may also be used to mitigate risk and prevent loss by alerting policyholders of the risk such that corrective action may be taken."
"AERIAL DEVICES, ROTOR ASSEMBLIES FOR AERIAL DEVICES, AND DEVICE FRAMEWORKS AND METHODOLOGIES CONFIGURED TO ENABLE CONTROL OF AERIAL DEVICES",https://lens.org/120-524-829-996-726,2017,"The present disclosure relates to drone technology, and in particular to aerial drone technology. This includes both drone hardware/hardware configuration, and drone software/software configuration. Embodiments are described by reference to a ""selfie drone"", being an aerial drone device that is configured to take photos (and/or video) of a user (for example by positioning itself in a defined location relative to the user). However, it will be appreciated that various aspects of technology described herein have wider application."
A remote control system for a crane,https://lens.org/165-652-584-760-22X,2015,"The invention provides a remote control system for a crane. The remote control system comprises a wireless remote controller for sending an instruction, a wireless receiver mounted in the crane for receiving the instruction sent by the wireless remote controller, and a control module for controlling the crane based on a signal of the wireless receiver. The control module controls the actions of the crane for moving a motor to and fro, hoisting, steering, and lifting the motor. The remote control system of the invention has characteristics of simple structure and low cost."
Radio with frequency scanning and interference detection capability for remote controlled model aircraft,https://lens.org/076-514-635-130-809,1996,A remote control system for use with model aircraft provides a user with the capability of placing the remote control system into a scanning mode wherein a receiver scans through a plurality of channels having a predetermined frequency bandwidth and frequency interference detection circuitry is activated upon detection of interference picked up by the receiver on a channel within the selected bandwidth. Warning circuitry is provided to communicate with the frequency interference detection circuitry for providing a warning signal to a user that interference has been detected. A clear channel is then selected and tuning circuitry permits locking of the receiver and the transmitter on the clear channel so that a user can control the flight of a model aircraft by sending rf signals from the transmitter to the receiver.
Dynamically arming a safety mechanism on a delivery drone,https://lens.org/015-139-812-003-962,2022,"A system and method for dynamically operating a drone safety system of a delivery drone. The method includes: receiving at least one terrain map; receiving a delivery request, wherein the delivery request includes a destination location and a delivery time; analyzing the received at least one terrain map and the delivery request to generate a navigation plan, wherein the navigation plan include a plurality of segments, wherein each of the plurality of segments include at least source coordinates, destination coordinates, an operation instruction to operate a drone safety system in case of failure of a delivery drone; and sending the navigation plan to the delivery drone for execution of the navigation plan at least in case of failure of the delivery drone."
DYNAMICALLY ARMING A SAFETY MECHANISM ON A DELIVERY DRONE,https://lens.org/134-660-336-796-499,2020,"A system and method for dynamically operating a drone safety system of a delivery drone. The method includes: receiving at least one terrain map; receiving a delivery request, wherein the delivery request includes a destination location and a delivery time; analyzing the received at least one terrain map and the delivery request to generate a navigation plan, wherein the navigation plan include a plurality of segments, wherein each of the plurality of segments include at least source coordinates, destination coordinates, an operation instruction to operate a drone safety system in case of failure of a delivery drone; and sending the navigation plan to the delivery drone for execution of the navigation plan at least in case of failure of the delivery drone."
BUG EATER,https://lens.org/140-048-186-385-892,2017,"A drone with a high-voltage trap seeks, identifies, pursues and destroys flying insects within a patrolling area. During its passive attracting mode, the drone lands on a designated ground site and attracts insects with light, sound, and scents. Once insects are lured, the high voltage screens trap will immediately electrocute targeted insects. In its active offensive mode, the drone hovers closer to insect nests using its high- velocity propellers, producing strong downdraft jet streams to disturb the nest and force insects, such as mosquitoes and the like, to evacuate their nest. Once insects are airborne, the drone pursues fleeing insects from below or behind, making use of its propellers and vacuuming the fleeing insects. Slow flying insects that come in contact with the high- voltage electrified screens are immediately electrocuted. Insects that are vacuumed into the fast- spinning propellers blades are knocked down and killed. A rectified charging pad recharges the drone batteries."
Unmanned aerial vehicle having automatic tracking function and method of controlling the same,https://lens.org/181-601-584-791-261,2019,"The present invention relates to an unmanned aerial vehicle having an automatic tracking function and a control method thereof, the unmanned aerial vehicle comprising: an image input unit for acquiring an image of a peripheral image of a subject to be photographed; an object recognition unit for extracting a region of interest using the image acquired through the image input unit, detecting a specific region located within the region of interest to measure coordinates, and recognizing the specific region as an object to be tracked; an object tracking unit for calculating and tracking a position of the object to be tracked recognized by the object recognition unit using a tracking learning detection (TLD) learning algorithm and generating a drive command for driving the unmanned aerial vehicle corresponding to the position; a motion recognition unit for recognizing a motion of the object to be tracked and generating a driving command corresponding to a photographing mode, a moving picture photographing mode, and a return mode; and a drive control unit for driving the unmanned aerial vehicle according to the drive command. Due to this feature, the present invention has an effect of enabling autonomous flight of an unmanned aerial vehicle by recognizing and automatically tracking an object to be tracked."
UNMANNED AERIAL VEHICLE HAVING AUTOMATIC TRACKING FUNCTION AND METHOD OF CONTROLLING THE SAME,https://lens.org/019-589-546-401-901,2018,"The present invention relates to an unmanned aerial vehicle having an automatic tracking function and a control method thereof, the unmanned aerial vehicle comprising: an image input unit for acquiring an image of a peripheral image of a subject to be photographed; an object recognition unit for extracting a region of interest using the image acquired through the image input unit, detecting a specific region located within the region of interest to measure coordinates, and recognizing the specific region as an object to be tracked; an object tracking unit for calculating and tracking a position of the object to be tracked recognized by the object recognition unit using a tracking learning detection (TLD) learning algorithm and generating a drive command for driving the unmanned aerial vehicle corresponding to the position; a motion recognition unit for recognizing a motion of the object to be tracked and generating a driving command corresponding to a photographing mode, a moving picture photographing mode, and a return mode; and a drive control unit for driving the unmanned aerial vehicle according to the drive command. Due to this feature, the present invention has an effect of enabling autonomous flight of an unmanned aerial vehicle by recognizing and automatically tracking an object to be tracked."
"METHOD AND DEVICE FOR GENERATING FLIGHT RESTRICTION ZONE, AND METHOD AND DEVICE FOR CONTROLLING FLIGHT OF UNMANNED AERIAL VEHICLE",https://lens.org/041-266-730-694-899,2021,"A method for controlling flight of an unmanned aerial vehicle, includes receiving a data file indicating flight restriction level and range of an airport area in an airport generated according to a risk level of the airport, parsing the data file to obtain the flight restriction level and the range of the airport area, and controlling the unmanned aerial vehicle to execute a flight restriction strategy according to the flight restriction level and the range of the airport area."
UAV NAVIGATION OBSTACLE AVOIDANCE SYSTEM AND METHOD THEREOF,https://lens.org/128-057-480-588-383,2019,"An unmanned aerial vehicle (UAV) navigation obstacle avoidance system and method thereof are introduced. The UAV navigation obstacle avoidance system provides with functions of automatically controlling the UAV motive power sources to control the flight of UAV and avoid the obstacle. The system comprises a sensing device, a signal processing module, a communication module, a control module. The sensing device detects the relative direction, velocity and distance between a UAV and a dynamic or static obstacle. The sensing device also detects the real-time position, flight attitude and inertia signals of the UAV. The signal processing module generates a UAV flight control signal. The control module receives the UAV flight control signal and controls each of the UAV motive power sources. Therefore, the system achieves the purpose of controlling flight and obstacle avoidance and forward to the original planned follow-on flight route after the avoidance."
UAV navigation obstacle avoidance system and method thereof,https://lens.org/166-775-019-145-538,2019,"An unmanned aerial vehicle (UAV) navigation obstacle avoidance system and method thereof are introduced. The UAV navigation obstacle avoidance system provides with functions of automatically controlling the UAV motive power sources to control the flight of UAV and avoid the obstacle. The system comprises a sensing device, a signal processing module, a communication module, a control module. The sensing device detects the relative direction, velocity and distance between a UAV and a dynamic or static obstacle. The sensing device also detects the real-time position, flight attitude and inertia signals of the UAV. The signal processing module generates a UAV flight control signal. The control module receives the UAV flight control signal and controls each of the UAV motive power sources. Therefore, the system achieves the purpose of controlling flight and obstacle avoidance and forward to the original planned follow-on flight route after the avoidance."
"REMOTE CONTROL APPARATUS AND ELECTRONIC DEVICE, AND SYSTEM INCLUDING SAME",https://lens.org/012-623-576-620-357,2020,"A remote control apparatus is disclosed. The remote control apparatus comprises: a microphone; a communication unit; a storage unit for storing pattern information of a non-audible sound for identification of the locality of an external electronic device; and a processor for broadcasting, through the communication unit, information acquired on the basis of an ambient sound received through the microphone, and when a non-audible sound based on broadcasted information output from an electronic device is received through the microphone, comparing a pattern of the received non-audible sound with pattern information stored in the storage unit, and transmitting a pairing request signal to the electronic device on the basis of a comparison result."
"Remote control apparatus and electronic device, and system including same",https://lens.org/069-684-392-335-209,2021,"A remote control apparatus is disclosed. The remote control apparatus comprises: a microphone; a communication unit; a storage unit for storing pattern information of a non-audible sound for identification of the locality of an external electronic device; and a processor for broadcasting, through the communication unit, information acquired on the basis of an ambient sound received through the microphone, and when a non-audible sound based on broadcasted information output from an electronic device is received through the microphone, comparing a pattern of the received non-audible sound with pattern information stored in the storage unit, and transmitting a pairing request signal to the electronic device on the basis of a comparison result."
DRONE TAKEOFF AND LANDING SYSTEM,https://lens.org/185-767-350-881-470,2019,"A drone takeoff and landing system according to an embodiment comprises: a drone including a through-hole; and a landing pad including an extension member which can pass through the through-hole, wherein, when the extension member of the landing pad passes through the through-hole of the drone, an eddy current may occur between the through-hole and the extension member to cause magnetic braking of the drone."
Drone takeoff and landing system,https://lens.org/043-400-315-202-276,2022,"A drone takeoff and landing system according to an embodiment comprises: a drone including a through-hole; and a landing pad including an extension member which can pass through the through-hole, wherein, when the extension member of the landing pad passes through the through-hole of the drone, an eddy current may occur between the through-hole and the extension member to cause magnetic braking of the drone."
DRONE TAKEOFF AND LANDING SYSTEM,https://lens.org/130-483-015-446-594,2019,"A drone takeoff and landing system according to an embodiment comprises: a drone including a through-hole; and a landing pad including an extension member which can pass through the through-hole, wherein, when the extension member of the landing pad passes through the through-hole of the drone, an eddy current may occur between the through-hole and the extension member to cause magnetic braking of the drone."
Drone takeoff and landing system,https://lens.org/043-400-315-202-276,2022,"A drone takeoff and landing system according to an embodiment comprises: a drone including a through-hole; and a landing pad including an extension member which can pass through the through-hole, wherein, when the extension member of the landing pad passes through the through-hole of the drone, an eddy current may occur between the through-hole and the extension member to cause magnetic braking of the drone."
AUTONOMOUSLY MOTILE DEVICE WITH SPEECH COMMANDS,https://lens.org/030-020-424-003-253,2023,"An autonomously motile device may be controlled by speech received by a user device. A first speech-processing system associated with the user device may determine that audio data includes a representation of a command; a second speech-processing system associated with the autonomously motile device may determine that the command should be executed by the autonomously motile device. A network connection is established between the user device and the autonomously motile device, and a device manager authorizes execution of the command."
ADVANCED MISSION INTERACTION CONTROL YOKE FOR ADVANCED AUTOPILOTS OR AUTONOMOUS AIRCRAFT,https://lens.org/043-768-678-504-316,2021,"An aircraft and a control yoke for operating the aircraft. The control yoke includes a base, a handle for manual operation of the aircraft, and a graphical communication device centered at the base for receiving a command from an operator and autonomously operating the aircraft according to the received command."
Advanced mission interaction control yoke for advanced autopilots or autonomous aircraft,https://lens.org/123-348-804-890-297,2023,"An aircraft and a control yoke for operating the aircraft. The control yoke includes a base, a handle for manual operation of the aircraft, and a graphical communication device centered at the base for receiving a command from an operator and autonomously operating the aircraft according to the received command."
Advanced mission interaction control yoke for advanced autopilots or autonomous aircraft,https://lens.org/123-348-804-890-297,2023,"An aircraft and a control yoke for operating the aircraft. The control yoke includes a base, a handle for manual operation of the aircraft, and a graphical communication device centered at the base for receiving a command from an operator and autonomously operating the aircraft according to the received command."
SWARM CONSISTING OF A PLURALITY OF LIGHTWEIGHT DRONES,https://lens.org/157-716-343-530-159,2019,"This swarm (101) is made up of a plurality of drones (111-115), the drones being flying drones, the drones forming a communication network with one another. It is characterized in that the swarm implements, autonomously, an obstacle avoidance functionality (20) based on a collaborative observation of the environment of the swarm by each of the drones and the sharing of obstacle detection information among the drones."
AUTOMATIC CONTEXTUAL SELECTION OF A SMART DEVICE,https://lens.org/031-516-092-554-539,2021,"Systems and methods for automatically selecting a smart device based on the context of a voice command event are disclosed. In embodiments, a smart device controller receives a user voice command from a user regarding a function to be performed during a command event within a smart environment; determines context data associated with the user voice command; determines a smart device name of the user voice command; accesses a knowledge database including registered smart devices and associated context-specific names, wherein the context-specific names are associated with context parameters; matches the smart device name of the user voice command with one of the context-specific names of the knowledge database; automatically chooses a select smart device from the plurality of registered smart devices to perform the function based on the matching; and initiates the function at the select smart device."
Automatic contextual selection of a smart device,https://lens.org/129-134-553-966-06X,2022,"Systems and methods for automatically selecting a smart device based on the context of a voice command event are disclosed. In embodiments, a smart device controller receives a user voice command from a user regarding a function to be performed during a command event within a smart environment; determines context data associated with the user voice command; determines a smart device name of the user voice command; accesses a knowledge database including registered smart devices and associated context-specific names, wherein the context-specific names are associated with context parameters; matches the smart device name of the user voice command with one of the context-specific names of the knowledge database; automatically chooses a select smart device from the plurality of registered smart devices to perform the function based on the matching; and initiates the function at the select smart device."
Autonomous Robotic Aide,https://lens.org/044-227-037-290-666,2018,An autonomous robotic aide and methods of its operation are provided herein. The robotic aide can carry and lift objects around the user's environment. The robot has a lifting mechanism which lifts the objects that are placed on the robot. It can assist users with picking up objects from the ground. The use of accessories may be combined with the robot's carrying and lifting functions to further assist the user. The robot can also map the user's environment for autonomous navigation. The robot can be given voice commands and can be controlled manually by integrating with a smart device.
AUTONOMOUS ROBOTIC AIDE,https://lens.org/050-059-107-627-242,2018,An autonomous robotic aide and methods of its operation are provided herein. The robotic aide can carry and lift objects around the user's environment. The robot has a lifting mechanism which lifts the objects that are placed on the robot. It can assist users with picking up objects from the ground. The use of accessories may be combined with the robot's carrying and lifting functions to further assist the user. The robot can also map the user's environment for autonomous navigation. The robot can be given voice commands and can be controlled manually by integrating with a smart device.
"Methods, computer programs, computing devices and controllers",https://lens.org/150-936-131-606-887,2018,"Computing device 100 comprises a camera 120 and a display 140. The camera provides image data representing a scene comprising an unmanned aerial vehicle (UAV or drone). The computing device receives identification data wirelessly 130 from the UAV, associates it with the image and displays them both on the display at the same time. This may provide photographic evidence that the UAV was at a location at a particular time or allow identification of an attribute of the UAV. Based on the identification data, the computing device may determine whether the UAV is authorized to be in a restricted flight zone. In response it may prevent or allow the UAV to enter, remain in or leave the zone; notify an entity associated (or not) with the UAV; or take control of the UAV. The identification data may be a registration, equipment, contact or WLAN identifier (e.g. BSSID) and may be broadcast by the UAV or transmitted from it to its operators control device. The computing device may be a mobile device or another UAV."
Remote control audio link,https://lens.org/018-935-773-059-344,2014,"One embodiment may take the form of a voice control system. The system may include a first apparatus with a processing unit configured to execute a voice recognition module and one or more executable commands, and a receiver coupled to the processing unit and configured to receive a first audio file from a remote control device. The first audio file may include at least one voice command. The first apparatus may further include a communication component coupled to the processing unit and configured to receive programming content, and one or more storage media storing the voice recognition module. The voice recognition module may be configured to convert voice commands into text."
"APPARATUS, SYSTEM, AND METHOD FOR ACTIVE CHANNEL SWITCHING AND SPECTRUM IDENTIFICATION IN HOSTILE RADIO FREQUENCY ENVIRONMENTS",https://lens.org/086-194-484-308-19X,2023,"An unmanned aerial vehicle (UAV) has a first radio configured to operate on one of a plurality of radio frequency (RF) channels, a processing and management application program interface (API), and a controller. A system for active radio frequency (RF) channel switching includes the UAV and a head end control unit in wireless communication with the UAV. A method of RF spectrum identification and mapping includes collecting RF data by the UAV within an area of operation, determining location data within the area of operation using a global positioning system (GPS) located on the UAV, and mapping the RF data of the area of operation using the location data."
"APPARATUS, SYSTEM, AND METHOD FOR ACTIVE CHANNEL SWITCHING AND SPECTRUM IDENTIFICATION IN HOSTILE RADIO FREQUENCY ENVIRONMENTS",https://lens.org/086-194-484-308-19X,2023,"An unmanned aerial vehicle (UAV) has a first radio configured to operate on one of a plurality of radio frequency (RF) channels, a processing and management application program interface (API), and a controller. A system for active radio frequency (RF) channel switching includes the UAV and a head end control unit in wireless communication with the UAV. A method of RF spectrum identification and mapping includes collecting RF data by the UAV within an area of operation, determining location data within the area of operation using a global positioning system (GPS) located on the UAV, and mapping the RF data of the area of operation using the location data."
COMPANION DRONE TO ASSIST LOCATION DETERMINATION,https://lens.org/186-469-264-425-410,2020,"A drone positioning system includes a processor subsystem and memory comprising instructions, which when executed by the processor subsystem, cause the processor subsystem to perform the operations comprising: transmitting, from an operation drone, a request message to a plurality of companion drones; receiving a response message from each of the plurality of companion drones, each response message including: a first timestamp indicating when the response message was sent from the corresponding companion drone and a first geoposition of the corresponding companion drone; calculating a first distance to each of the plurality of companion drones using the first timestamps of respective response messages from, each of the plurality of companion drones; calculating an estimated geoposition of the operation drone from the respective first distances and the respective first geopositions of the companion drones; and assisting navigation of the operation drone using the estimated geoposition."
SYSTEM AND METHOD FOR AUTONOMOUSLY MONITORING LIGHT POLES USING AN UNMANNED AERIAL VEHICLE,https://lens.org/162-996-883-967-570,2019,"An autonomous aerial solution is disclosed to monitor the status of light pole bulbs and report its findings to the operator. The system involves the use of a smartphone and a consumer UAV to give users the ability to autonomously monitor light poles. The invention consists of three main parts: (i) autonomous path planning and flight, (ii) training a custom convolutional neural network, and (iii) classifying RGB light pole images. While following FAA regulations, the UAV avoids most obstacles. As the UAV approaches a light pole, it (i) slows down, (ii) centers itself, (iii) captures an image, and (iv) heads towards the next pole. Upon completion, the UAV returns to its takeoff position, and the program analyzes the images using a trained convolutional neural network. As the UAV descends, the data is available to the operator using an intuitive color-coded map."
Bug eater,https://lens.org/137-914-064-424-224,2017,"A drone with a high-voltage trap seeks, identifies, pursues and destroys flying insects within a patrolling area. During its passive attracting mode, the drone lands on a designated ground site and attracts insects with light, sound, and scents. Once insects are lured, the high voltage screens trap will immediately electrocute targeted insects. In its active offensive mode, the drone hovers closer to insect nests using its high-velocity propellers, producing strong downdraft jet streams to disturb the nest and force insects, such as mosquitoes and the like, to evacuate their nest. Once insects are airborne, the drone pursues fleeing insects from below or behind, making use of its propellers and vacuuming the fleeing insects. Slow flying insects that come in contact with the high-voltage electrified screens are immediately electrocuted. Insects that are vacuumed into the fast-spinning propellers blades are knocked down and killed. A rectified charging pad recharges the drone batteries."
VOICE ACTIVATED DEVICE FOR USE WITH A VOICE-BASED DIGITAL ASSISTANT,https://lens.org/081-007-650-547-578,2020,"A voice activated device for interaction with a digital assistant is provided. The device comprises a housing, one or more processors, and memory, the memory coupled to the one or more processors and comprising instructions for automatically identifying and connecting to a digital assistant server. The device further comprises a power supply, a wireless network module, and a human-machine interface. The human-machine interface consists essentially of: at least one speaker, at least one microphone, an ADC coupled to the microphone, a DAC coupled to the at least one speaker, and zero or more additional components selected from the set consisting of: a touch-sensitive surface, one or more cameras, and one or more LEDs. The device is configured to act as an interface for speech communications between the user and a digital assistant of the user on the digital assistant server."
Voice activated device for use with a voice-based digital assistant,https://lens.org/070-702-345-434-126,2020,"A voice activated device for interaction with a digital assistant is provided. The device comprises a housing, one or more processors, and memory, the memory coupled to the one or more processors and comprising instructions for automatically identifying and connecting to a digital assistant server. The device further comprises a power supply, a wireless network module, and a human-machine interface. The human-machine interface consists essentially of: at least one speaker, at least one microphone, an ADC coupled to the microphone, a DAC coupled to the at least one speaker, and zero or more additional components selected from the set consisting of: a touch-sensitive surface, one or more cameras, and one or more LEDs. The device is configured to act as an interface for speech communications between the user and a digital assistant of the user on the digital assistant server."
Healthcare systems and methods using voice inputs,https://lens.org/186-887-327-367-556,2021,"A voice-enabled digital communications assistant powered in part using tailored machine learning models and other algorithms is used to engage with and control one or more healthcare devices or instruments such that a user is able to control the devices or instruments using natural language, conversational-like, voice commands. A command processor processes the audible instructions, while a context-aware processor monitors the present states and conditions of all devices and instruments, as well as the environment, for situational awareness purposes, including situations where executing commands may be incompatible with or conflict with the present states or conditions of devices and instruments as well as their expected future states. In addition to speech responses by the digital assistant, a separate notification engine provides audible or visual feedback to the user."
Healthcare systems and methods using voice inputs,https://lens.org/113-833-479-903-109,2019,"A voice-enabled digital communications assistant powered in part using tailored machine learning models and other algorithms is used to engage with and control one or more healthcare devices or instruments such that a user is able to control the devices or instruments using natural language, conversational-like, voice commands. A command processor processes the audible instructions, while a context-aware processor monitors the present states and conditions of all devices and instruments, as well as the environment, for situational awareness purposes, including situations where executing commands may be incompatible with or conflict with the present states or conditions of devices and instruments as well as their expected future states. In addition to speech responses by the digital assistant, a separate notification engine provides audible or visual feedback to the user."
HEALTHCARE SYSTEMS AND METHODS USING VOICE INPUTS,https://lens.org/136-492-547-085-745,2019,"A voice-enabled digital communications assistant powered in part using tailored machine learning models and other algorithms is used to engage with and control one or more healthcare devices or instruments such that a user is able to control the devices or instruments using natural language, conversational-like, voice commands. A command processor processes the audible instructions, while a context-aware processor monitors the present states and conditions of all devices and instruments, as well as the environment, for situational awareness purposes, including situations where executing commands may be incompatible with or conflict with the present states or conditions of devices and instruments as well as their expected future states. In addition to speech responses by the digital assistant, a separate notification engine provides audible or visual feedback to the user."
HEALTHCARE SYSTEMS AND METHODS USING VOICE INPUTS,https://lens.org/031-425-828-235-941,2020,"A voice-enabled digital communications assistant powered in part using tailored machine learning models and other algorithms is used to engage with and control one or more healthcare devices or instruments such that a user is able to control the devices or instruments using natural language, conversational-like, voice commands. A command processor processes the audible instructions, while a context-aware processor monitors the present states and conditions of all devices and instruments, as well as the environment, for situational awareness purposes, including situations where executing commands may be incompatible with or conflict with the present states or conditions of devices and instruments as well as their expected future states. In addition to speech responses by the digital assistant, a separate notification engine provides audible or visual feedback to the user."
DELIVERY ROBOT,https://lens.org/100-854-451-396-898,2022,"Described herein is a delivery robot that can be programmed to travel from one location to another in open spaces that have few restrictions on the robot's path of travel. The delivery robot may operate in an autonomous mode, a remote controlled mode, or a combination thereof. The delivery robot can include a cargo area for transporting physical items. The robot can include exterior display devices and/or lighting devices to convey information to people that the robot may be encountering, including indications of the robot's direction of travel, current status, and/or other information."
SYSTEMS AND METHODS FOR MULTI-ORIENTATION FLIGHT,https://lens.org/081-542-919-903-42X,2022,"A method of operating an unmanned aerial vehicle (UAV) includes generating, with aid of one or more processors, a signal that causes the UAV to flip from a first orientation to a second orientation opposite to the first orientation, and effecting, with aid of one or more propulsion units, flip of the UAV from the first orientation to the second orientation in response to the signal."
SYSTEMS AND METHODS FOR MULTI-ORIENTATION FLIGHT,https://lens.org/081-542-919-903-42X,2022,"A method of operating an unmanned aerial vehicle (UAV) includes generating, with aid of one or more processors, a signal that causes the UAV to flip from a first orientation to a second orientation opposite to the first orientation, and effecting, with aid of one or more propulsion units, flip of the UAV from the first orientation to the second orientation in response to the signal."
System and method for thermal control during delivery of a medication package,https://lens.org/080-918-176-759-805,2022,"A method for controlling an autonomous unmanned aerial vehicle for delivery of a medication package includes determining a thermal control period for the medication package. The method also includes identifying a delivery location corresponding to the medication package. The method also includes identifying at least one environmental characteristic of an environment that includes a delivery three-dimensional flight path between a starting location and the delivery location, wherein the at least one environmental characteristic indicates an actual weather value at the delivery location. The method also includes determining whether to deliver the medication package based on the thermal control period and the at least one environmental characteristic, using the unmanned aerial vehicle."
System and method for thermal control during delivery of a medication package,https://lens.org/080-918-176-759-805,2022,"A method for controlling an autonomous unmanned aerial vehicle for delivery of a medication package includes determining a thermal control period for the medication package. The method also includes identifying a delivery location corresponding to the medication package. The method also includes identifying at least one environmental characteristic of an environment that includes a delivery three-dimensional flight path between a starting location and the delivery location, wherein the at least one environmental characteristic indicates an actual weather value at the delivery location. The method also includes determining whether to deliver the medication package based on the thermal control period and the at least one environmental characteristic, using the unmanned aerial vehicle."
Sound-producing remote control unit,https://lens.org/160-326-584-932-903,2015,"The invention provides a sound-producing remote control unit. The sound-producing remote control unit comprises a remote control unit, an antenna and a buzzer, wherein the antenna is mounted on the remote control unit and connected with the buzzer through a control circuit; the buzzer is mounted on the remote control unit. The sound-producing remote control unit is simple in structure, convenient to use, and high in practicability; the antenna and the buzzer are mounted on the remote control unit, starting devices can be mounted on the corresponding household appliances, and when the buzzer is started to produce sound, the position of the remote control unit can be effectively found."
Remote control system for pointing robot,https://lens.org/197-614-687-355-52X,2017,"There is provided a remote control system including a controlled device and a remote device. The controlled device has a light source and moves according to a control signal from the remote device. The remote device is adapted to be operated by a user and includes an image sensor. The remote device determines a moving direction of the controlled device according to an imaging position of the light source in the image captured by the image sensor and a pointing position of the user, and outputs the control signal."
REMOTE CONTROL SYSTEM FOR POINTING ROBOT,https://lens.org/074-814-782-852-336,2014,"There is provided a remote control system including a controlled device and a remote device. The controlled device has a light source and moves according to a control signal from the remote device. The remote device is adapted to be operated by a user and includes an image sensor. The remote device determines a moving direction of the controlled device according to an imaging position of the light source in the image captured by the image sensor and a pointing position of the user, and outputs the control signal."
REMOTE CONTROL SYSTEM FOR POINTING ROBOT,https://lens.org/024-122-896-071-529,2017,"There is provided a remote control system including a controlled device and a remote device. The controlled device has a light source and moves according to a control signal from the remote device. The remote device is adapted to be operated by a user and includes an image sensor. The remote device determines a moving direction of the controlled device according to an imaging position of the light source in the image captured by the image sensor and a pointing position of the user, and outputs the control signal."
REMOTE CONTROL SYSTEM FOR POINTING ROBOT,https://lens.org/159-641-722-684-480,2017,"There is provided a remote control system including a controlled device and a remote device. The controlled device has a light source and moves according to a control signal from the remote device. The remote device is adapted to be operated by a user and includes an image sensor. The remote device determines a moving direction of the controlled device according to an imaging position of the light source in the image captured by the image sensor and a pointing position of the user, and outputs the control signal."
Remote control system for pointing robot,https://lens.org/019-236-052-620-414,2017,"There is provided a remote control system including a controlled device and a remote device. The controlled device has a light source and moves according to a control signal from the remote device. The remote device is adapted to be operated by a user and includes an image sensor. The remote device determines a moving direction of the controlled device according to an imaging position of the light source in the image captured by the image sensor and a pointing position of the user, and outputs the control signal."
Remote control system for pointing robot,https://lens.org/096-167-945-108-692,2018,"There is provided a remote control system including a controlled device and a remote device. The controlled device has a light source and moves according to a control signal from the remote device. The remote device is adapted to be operated by a user and includes an image sensor. The remote device determines a moving direction of the controlled device according to an imaging position of the light source in the image captured by the image sensor and a pointing position of the user, and outputs the control signal."
Noise modulation for unmanned aerial vehicles,https://lens.org/164-402-168-203-047,2023,"Various mechanisms and methods for altering sound output from an unmanned aerial vehicle (UAV) are disclosed. The UAV can have a drive system comprising a motor or a plurality of motors, and a processor operatively coupled to the drive system to control operation of the drive system. The UAV can further have a plurality of propellers that are rotatably drivable by the drive system, the plurality of propellers having physical characteristics such that, when drivingly rotated to maintain the UAV in stable flight, a first of the plurality of propellers emits a first note, and a second of the plurality of propellers emits a second, different note, a combination of the first and second notes producing a consonant sound."
Location verification and secure no-fly logic for unmanned aerial vehicles,https://lens.org/093-027-826-979-432,2018,"Certain embodiments herein relate to location verification for autonomous unmanned aerial vehicles (also referred to as drones). In some embodiments, an unmanned aerial vehicle engaged in autonomous flight may determine its location using a satellite-based navigation system. The location may be evaluated against location data obtained from one or more secondary factors, such as public broadcast beacons, cellular towers, wireless network identifiers, visual markers, or any combination thereof. If the location is determined to be invalid, the unmanned aerial vehicle may be instructed to take a mitigation action. Additionally, certain embodiments also include the verification of a flight plan for the unmanned aerial vehicle using secure no-fly logic to verify a flight plan does not violate no-fly zones. If the flight plan is verified, the flight plan may be signed using a cryptographic signature and provided to a navigation module that verifies the signature and executes the flight plan."
LOCATION VERIFICATION AND SECURE NO-FLY LOGIC FOR UNMANNED AERIAL VEHICLES,https://lens.org/130-362-478-716-879,2017,"Certain embodiments herein relate to location verification for autonomous unmanned aerial vehicles (also referred to as drones). In some embodiments, an unmanned aerial vehicle engaged in autonomous flight may determine its location using a satellite-based navigation system. The location may be evaluated against location data obtained from one or more secondary factors, such as public broadcast beacons, cellular towers, wireless network identifiers, visual markers, or any combination thereof. If the location is determined to be invalid, the unmanned aerial vehicle may be instructed to take a mitigation action. Additionally, certain embodiments also include the verification of a flight plan for the unmanned aerial vehicle using secure no-fly logic to verify a flight plan does not violate no-fly zones. If the flight plan is verified, the flight plan may be signed using a cryptographic signature and provided to a navigation module that verifies the signature and executes the flight plan."
REMOTE-CONTROL DEVICE WITH DIRECTIONAL AUDIO SYSTEM,https://lens.org/112-341-917-666-776,2009,"A method of directing an audio signal to an intended user by a remote-control device coupled to an audio/video device is described. The remote-control device sends an instruction to the audio/video device to transmit an audio signal. The remote-control device receives the audio signal and process the audio signal to generate a directional audio. The directional audio is then routed to an intended user such that the directional audio signal is audible to the intended user, other recipients in the vicinity."
"UNMANNED AERIAL VEHICLE, INFORMATION PROCESSING METHOD, AND RECORDING MEDIUM",https://lens.org/009-784-459-465-844,2021,"An unmanned aerial vehicle includes: a sensor including at least a microphone that generates sound data; and a processor. The processor determines a quality of a target sound by using the sound data generated by the microphone, acquires a positional relationship between the unmanned aerial vehicle and a sound source of the target sound by using data generated by the sensor, determines a destination to which the sound source is to move based on the quality of the target sound and the positional relationship, and presents target movement information that prompts the sound source to move toward the destination."
VELOCITY CONTROL FOR AN UNMANNED AERIAL VEHICLE,https://lens.org/010-183-325-975-461,2016,"Systems and methods for controlling an unmanned aerial vehicle within an environment are provided. In one aspect, a system comprises one or more sensors carried on the unmanned aerial vehicle and configured to receive sensor data of the environment and one or more processors. The one or more processors may be individually or collectively configured to: determine, based on the sensor data, an environmental complexity factor representative of an obstacle density for the environment; determine, based on the environmental complexity factor, one or more operating rules for the unmanned aerial vehicle; receive a signal indicating a desired movement of the unmanned aerial vehicle; and cause the unmanned aerial vehicle to move in accordance with the signal while complying with the one or more operating rules."
VELOCITY CONTROL FOR AN UNMANNED AERIAL VEHICLE,https://lens.org/061-736-169-888-506,2018,"Systems and methods for controlling an unmanned aerial vehicle within an environment are provided. In one aspect, a system comprises one or more sensors carried on the unmanned aerial vehicle and configured to receive sensor data of the environment and one or more processors. The one or more processors may be individually or collectively configured to: determine, based on the sensor data, an environmental complexity factor representative of an obstacle density for the environment; determine, based on the environmental complexity factor, one or more operating rules for the unmanned aerial vehicle; receive a signal indicating a desired movement of the unmanned aerial vehicle; and cause the unmanned aerial vehicle to move in accordance with the signal while complying with the one or more operating rules."
Velocity control for an unmanned aerial vehicle,https://lens.org/087-231-766-950-013,2020,"Systems and methods for controlling an unmanned aerial vehicle within an environment are provided. In one aspect, a system comprises one or more sensors carried on the unmanned aerial vehicle and configured to receive sensor data of the environment and one or more processors. The one or more processors may be individually or collectively configured to: determine, based on the sensor data, an environmental complexity factor representative of an obstacle density for the environment; determine, based on the environmental complexity factor, one or more operating rules for the unmanned aerial vehicle; receive a signal indicating a desired movement of the unmanned aerial vehicle; and cause the unmanned aerial vehicle to move in accordance with the signal while complying with the one or more operating rules."
VELOCITY CONTROL FOR AN UNMANNED AERIAL VEHICLE,https://lens.org/151-599-700-695-042,2016,"Systems and methods for controlling an unmanned aerial vehicle within an environment are provided. In one aspect, a system comprises one or more sensors carried on the unmanned aerial vehicle and configured to receive sensor data of the environment and one or more processors. The one or more processors may be individually or collectively configured to: determine, based on the sensor data, an environmental complexity factor representative of an obstacle density for the environment; determine, based on the environmental complexity factor, one or more operating rules for the unmanned aerial vehicle; receive a signal indicating a desired movement of the unmanned aerial vehicle; and cause the unmanned aerial vehicle to move in accordance with the signal while complying with the one or more operating rules."
VELOCITY CONTROL FOR AN UNMANNED AERIAL VEHICLE,https://lens.org/143-258-234-055-762,2017,"Systems and methods for controlling an unmanned aerial vehicle within an environment are provided. In one aspect, a system comprises one or more sensors carried on the unmanned aerial vehicle and configured to receive sensor data of the environment and one or more processors. The one or more processors may be individually or collectively configured to: determine, based on the sensor data, an environmental complexity factor representative of an obstacle density for the environment; determine, based on the environmental complexity factor, one or more operating rules for the unmanned aerial vehicle; receive a signal indicating a desired movement of the unmanned aerial vehicle; and cause the unmanned aerial vehicle to move in accordance with the signal while complying with the one or more operating rules."
Velocity control for an unmanned aerial vehicle,https://lens.org/104-038-946-746-634,2016,"Systems and methods for controlling an unmanned aerial vehicle within an environment are provided. In one aspect, a system comprises one or more sensors carried on the unmanned aerial vehicle and configured to receive sensor data of the environment and one or more processors. The one or more processors may be individually or collectively configured to: determine, based on the sensor data, an environmental complexity factor representative of an obstacle density for the environment; determine, based on the environmental complexity factor, one or more operating rules for the unmanned aerial vehicle; receive a signal indicating a desired movement of the unmanned aerial vehicle; and cause the unmanned aerial vehicle to move in accordance with the signal while complying with the one or more operating rules."
Velocity control for an unmanned aerial vehicle,https://lens.org/002-726-829-206-664,2018,"Systems and methods for controlling an unmanned aerial vehicle within an environment are provided. In one aspect, a system comprises one or more sensors carried on the unmanned aerial vehicle and configured to receive sensor data of the environment and one or more processors. The one or more processors may be individually or collectively configured to: determine, based on the sensor data, an environmental complexity factor representative of an obstacle density for the environment; determine, based on the environmental complexity factor, one or more operating rules for the unmanned aerial vehicle; receive a signal indicating a desired movement of the unmanned aerial vehicle; and cause the unmanned aerial vehicle to move in accordance with the signal while complying with the one or more operating rules."
Velocity control for an unmanned aerial vehicle,https://lens.org/106-117-082-570-595,2017,"Systems and methods for controlling an unmanned aerial vehicle within an environment are provided. In one aspect, a system comprises one or more sensors carried on the unmanned aerial vehicle and configured to receive sensor data of the environment and one or more processors. The one or more processors may be individually or collectively configured to: determine, based on the sensor data, an environmental complexity factor representative of an obstacle density for the environment; determine, based on the environmental complexity factor, one or more operating rules for the unmanned aerial vehicle; receive a signal indicating a desired movement of the unmanned aerial vehicle; and cause the unmanned aerial vehicle to move in accordance with the signal while complying with the one or more operating rules."
Velocity control for an unmanned aerial vehicle,https://lens.org/104-038-946-746-634,2016,"Systems and methods for controlling an unmanned aerial vehicle within an environment are provided. In one aspect, a system comprises one or more sensors carried on the unmanned aerial vehicle and configured to receive sensor data of the environment and one or more processors. The one or more processors may be individually or collectively configured to: determine, based on the sensor data, an environmental complexity factor representative of an obstacle density for the environment; determine, based on the environmental complexity factor, one or more operating rules for the unmanned aerial vehicle; receive a signal indicating a desired movement of the unmanned aerial vehicle; and cause the unmanned aerial vehicle to move in accordance with the signal while complying with the one or more operating rules."
UNMANNED AERIAL SYSTEM DRONE SITUATIONAL AWARENESS FLIGHT SAFETY AND TRACKING SYSTEM,https://lens.org/138-632-000-864-790,2015,"The invention provides for the creation of an electromagnetic wave broadcast based locator beacon systems to allow for the tracking of drone/UAV/UAS, hereafter also referred to as drones, coupled with an alert system and display panel which can be placed in manned aircraft and other locations to let pilots and concerned parties know when they are in the vicinity of each other and or when drone aircraft are operating nearby any areas of concern utilizing this system. This system will alert pilots and others when a drone is operating in their area as well as give an indication of the drone's proximity to their aircraft while also allowing drone operators to know where manned aircraft and other operators using the system are located. This invention will allow concerned parties to maintain situational awareness and avoid operational incursions while also providing enhanced safety through increased situational awareness."
Drone detection and interception,https://lens.org/120-815-418-743-003,2020,"Embodiments disclosed herein provide for systems and methods for detecting and intercepting drones and drone operators. An example system for disrupting drone attacks comprises a drone detection system configured to detect a hostile drone, a defensive drone control system coupled to the drone detection system and configured to communicate with a first defensive drone, and a first defensive drone configured to receive first data from the defensive drone control system and to use the data to intercept the hostile drone. The system for disrupting drone attacks may further comprise a system configured to identify a control source of the hostile drone, and a second defensive drone configured to receive second data from the defensive drone control system and to use the second data to fly to a location associated with the control source of the hostile drone."
DEVICE FOR REMOTELY COMMANDING A CRANE,https://lens.org/031-980-914-990-698,2017,"A device for remotely commanding a crane comprises a transmission unit suitable for establishing a communication between the device and a control unit of the crane. The device also includes a control panel comprising a plurality of manual control members, each arranged for commanding a specific movement of a plurality of available movements of the crane and the direction of the specific movement. The device may also include a plurality of indicators of the available movements of the crane, each correlated with the specific crane movement cornmandable by a respective manual control"
UNMANNED AERIAL VEHICLE AND ANTENNA ASSEMBLY,https://lens.org/149-164-155-517-675,2019,"An unmanned aerial vehicle (UAV) includes an antenna assembly configured to communicate with a ground terminal controller, a memory storing antenna assembly configuration information, and one or more processors configured to adjust a radiation direction pattern of the antenna assembly according to the antenna assembly configuration information."
COMPANION DRONE TO ASSIST LOCATION DETERMINATION,https://lens.org/068-046-557-832-316,2019,"A drone positioning system includes a processor subsystem and memory comprising instructions, which when executed by the processor subsystem, cause the processor subsystem to perform the operations comprising: transmitting, from an operation drone, a request message to a plurality of companion drones; receiving a response message from each of the plurality of companion drones, each response message including: a first timestamp indicating when the response message was sent from the corresponding companion drone and a first geoposition of the corresponding companion drone; calculating a first distance to each of the plurality of companion drones using the first timestamps of respective response messages from each of the plurality of companion drones; calculating an estimated geoposition of the operation drone from the respective first distances and the respective first geopositions of the companion drones; and assisting navigation of the operation drone using the estimated geoposition."
UNMANNED AERIAL VEHICLES,https://lens.org/000-098-921-245-394,2017,"An unmanned aerial vehicle (UAV) includes an image capturing module disposed on the UAV, and configured to capture image data; and a controller chip coupled to the image capturing module to receive and process the image data; and the controller chip being configured to control the flight of the UAV."
Unmanned aerial vehicles,https://lens.org/196-053-329-553-207,2018,"An unmanned aerial vehicle (UAV) includes an image capturing module disposed on the UAV, and configured to capture image data; and a controller chip coupled to the image capturing module to receive and process the image data; and the controller chip being configured to control the flight of the UAV."
"SYSTEMS, METHODS, AND DEVICES FOR DRONE DETECTION USING AN OUTDOOR LIGHTING NETWORK",https://lens.org/043-929-118-956-60X,2020,"The present disclosure is directed to inventive systems, methods, and devices for use in an outdoor lighting network for drone detection. The drone detection system includes one or more lighting fixtures, one or more radar sensors to detect a moving object, and one or more controllers. The controllers receive data from the sensors, determine the velocity and velocity change rate of the object over a period of time, and analyze flight data pertaining to the moving object to determine if the object is a drone. The system can determine the starting location of the moving object, and send a signal indicating its starting location. The system can also track the position of the moving object in the outside environment."
"SYSTEMS, METHODS, AND DEVICES FOR DRONE DETECTION USING AN OUTDOOR LIGHTING NETWORK",https://lens.org/181-576-644-730-961,2022,"The present disclosure is directed to inventive systems, methods, and devices for use in an outdoor lighting network for drone detection. The drone detection system includes one or more lighting fixtures, one or more radar sensors to detect a moving object, and one or more controllers. The controllers receive data from the sensors, determine the velocity and velocity change rate of the object over a period of time, and analyze flight data pertaining to the moving object to determine if the object is a drone. The system can determine the starting location of the moving object, and send a signal indicating its starting location. The system can also track the position of the moving object in the outside environment."
METHOD AND SYSTEM FOR PERFORMING VOICE COMMAND,https://lens.org/109-607-018-796-953,2020,"Provided is a method, performed by a first device, of performing a voice command. For example, a method, performed by a first device, of performing a voice command includes receiving a packet including voice data of a user broadcast from a second device; performing authentication of the user, by using the voice data included in the packet; detecting a control command from the voice data, when the authentication of the user succeeds; and performing a control operation corresponding to the control command."
METHOD AND SYSTEM FOR PERFORMING VOICE COMMAND,https://lens.org/193-220-757-916-904,2021,"Provided is a method, performed by a first device, of performing a voice command. For example, a method, performed by a first device, of performing a voice command includes receiving a packet including voice data of a user broadcast from a second device; performing authentication of the user, by using the voice data included in the packet; detecting a control command from the voice data, when the authentication of the user succeeds; and performing a control operation corresponding to the control command."
METHOD FOR MONITORING AND CONTROLLING AUTOMOUS VEHICLE,https://lens.org/088-756-975-061-739,2021,"Disclosed herein is a method for allowing a user to monitor or control an autonomous vehicle after a drop off of the user. The method for monitoring and controlling an autonomous vehicle according to an embodiment includes receiving user alighting information for an autonomous vehicle, identifying whether a destination is set for the autonomous vehicle, determining an operating mode of a user terminal as a monitoring mode or a controlling mode on the basis of whether the destination is set, and transmitting a driving state of the autonomous vehicle to the user terminal, or transmitting a control signal corresponding to user manipulation input to the user terminal to the autonomous vehicle, on the basis of the operating mode."
ROBOT/DRONE MULTI-PROJECTILE LAUNCHER,https://lens.org/099-938-806-839-825,2018,"A multi-projectile launcher capable of firing less-lethal 40 mm rounds or high explosive 40 mm rounds (i.e., HE Grenades) can be attached to robots, drones, vehicles and stationary structures. The robot/drone multi-projectile launcher is remote controlled and capable of 360 degree horizontal rotation as well as vertical panning, and is able to quickly turn and acquire targets. A solenoid controlled firing system for each barrel includes a firing pin, trigger lever and striker, as well as a lockout bar and striker seer to prevent accidental firing (e.g., from impact or sudden jolt). Target acquisition systems include an infrared laser system, a standard red laser system, and an optic targeting system that is monitored through an onboard camera. A wireless network access device allows for remote viewing of live-feed camera images (still frame and video) and control of the optic targeting system, as well as the launcher articulation and firing."
Robot/drone multi-projectile launcher,https://lens.org/110-825-200-026-163,2019,"A multi-projectile launcher capable of firing less-lethal 40 mm rounds or high explosive 40 mm rounds (i.e., HE Grenades) can be attached to robots, drones, vehicles and stationary structures. The robot/drone multi-projectile launcher is remote controlled and capable of 360 degree horizontal rotation as well as vertical panning, and is able to quickly turn and acquire targets. A solenoid controlled firing system for each barrel includes a firing pin, trigger lever and striker, as well as a lockout bar and striker seer to prevent accidental firing (e.g., from impact or sudden jolt). Target acquisition systems include an infrared laser system, a standard red laser system, and an optic targeting system that is monitored through an onboard camera. A wireless network access device allows for remote viewing of live-feed camera images (still frame and video) and control of the optic targeting system, as well as the launcher articulation and firing."
LUMINAIRE-MOUNTED LANDING PLATFORM FOR A DRONE,https://lens.org/086-098-081-557-669,2017,"There is provided a landing platform for mounting on a luminaire, where the landing platform provides an interface to a drone. For example, there is provided a landing platform for a drone, the landing platform being adaptable to mount on a luminaire. The landing platform includes two electrically active portions and an elevated portion. The elevated portion is configured to secure the drone on the landing platform and provide electrical contact between the two electrically active portions and electrical connectors of the drone."
SYSTEMS AND METHODS FOR DETERMINING THE POSITION OF AN OBJECT USING AN UNMANNED AERIAL VEHICLE,https://lens.org/144-758-569-928-649,2022,"An unmanned aerial vehicle (UAV) has a positional sensor, an image sensor, one or more processors, and memory. The UAV receives from an electronic device a first wireless signal. The first wireless signal includes a first direction of illumination. In accordance with the first wireless signal, the UAV identifies a target object based, at least in part, on the first direction of illumination. The UAV also determines positional coordinates of the target object."
SYSTEMS AND METHODS FOR DETERMINING THE POSITION OF AN OBJECT USING AN UNMANNED AERIAL VEHICLE,https://lens.org/144-758-569-928-649,2022,"An unmanned aerial vehicle (UAV) has a positional sensor, an image sensor, one or more processors, and memory. The UAV receives from an electronic device a first wireless signal. The first wireless signal includes a first direction of illumination. In accordance with the first wireless signal, the UAV identifies a target object based, at least in part, on the first direction of illumination. The UAV also determines positional coordinates of the target object."
UNMANNED AERIAL VEHICLE CONTROL METHOD AND TERMINAL,https://lens.org/143-915-653-364-014,2020,"Embodiments of the present invention disclose an unmanned aerial vehicle (UAV) control method and a terminal. The method includes: determining, by a terminal before the terminal is connected to any UAV, location information of at least one waypoint according to a first setting operation of a user, and determining a flight path according to the location information of the at least one waypoint; storing, by the terminal, the flight path into a path record of a path database; and invoking, by the terminal after the terminal establishes a connection to a UAV, a first path record associated with the UAV from the path database, and sending the first path record to the UAV, to control the UAV to fly according to information in the first path record. The embodiments of the present invention can improve efficiency of a UAV in obtaining a flight path, and reduce power consumption of the UAV when no flight course task is executed."
ADAPTIVELY DISRUPTING UNMANNED AERIAL VEHICLES,https://lens.org/016-265-134-784-707,2018,"A technique for adaptively disrupting UAVs detects a target UAV using a camera, monitors the target UAV's communications using a directional antenna aligned with the camera, and attempts to communicate with the target UAV to request that it land, fly away, or return to launch. With the camera trained on the UAV, the directional antenna detects down-link signals from the UAV, which the UAV may employ to communicate with a ground-based controller. Control circuitry analyzes the down-link signals and generates a disrupting signal based thereon. The disrupting signal shares characteristics with the down-link signal, such as its protocol, bit rate, and/or packet length. The directional antenna transmits the disrupting signal back toward the UAV to affect the UAV's flight."
"CONTROL METHOD, CONTROL DEVICE AND ELECTRONIC DEVICE",https://lens.org/149-990-499-413-989,2019,"A control method includes receiving status information of the aerial vehicle, obtaining a flight path of the aerial vehicle based on the status information, and displaying a three-dimensional (3D) dynamic icon corresponding to the flight path."
Device for remotely commanding a crane,https://lens.org/097-953-374-395-361,2018,"A device for remotely commanding a crane comprises a transmission unit suitable for establishing a communication between the device and a control unit of the crane. The device also includes control panel comprising a plurality of manual control members, each arranged for commanding a specific movement of a plurality of available movements of the crane and the direction of the specific movement. The device may also include a plurality of indicators of the available movements of the crane, each correlated with the specific crane movement commandable by a respective manual control member."
SUBMERSIBLE DRONE SYSTEM,https://lens.org/061-412-925-215-737,2023,"Abstract A system includes a submersible drone comprising a payload, a propulsion system and a navigation system for determining the drone's position relative to a reference position. The drone comprises a magnet for attaching the drone to a submerged ferromagnetic surface of an object. A targeting system comprises a rangefinder for measuring a relative distance between the rangefinder and the object, and an orientation device for determining a relative bearing from the orientation device to the object. A wireless communication system communicatively connects the targeting system and drone together. A guidance system generates drive instructions based on telemetry data, the data including the position, reference position, relative distance and bearing, received in whole or in part via the wireless communication system. A drone control system controls the propulsion system in accordance with the drive instructions to move the drone to the object to attach the magnet to the surface. N IlL CD I, D T-I"
SUBMERSIBLE DRONE SYSTEM,https://lens.org/061-412-925-215-737,2023,"Abstract A system includes a submersible drone comprising a payload, a propulsion system and a navigation system for determining the drone's position relative to a reference position. The drone comprises a magnet for attaching the drone to a submerged ferromagnetic surface of an object. A targeting system comprises a rangefinder for measuring a relative distance between the rangefinder and the object, and an orientation device for determining a relative bearing from the orientation device to the object. A wireless communication system communicatively connects the targeting system and drone together. A guidance system generates drive instructions based on telemetry data, the data including the position, reference position, relative distance and bearing, received in whole or in part via the wireless communication system. A drone control system controls the propulsion system in accordance with the drive instructions to move the drone to the object to attach the magnet to the surface. N IlL CD I, D T-I"
DRONE LANDING SYSTEM AND ASSEMBLY,https://lens.org/039-986-617-058-018,2022,"A drone landing assembly comprising a coupling assembly comprising a first coupling and a second coupling complementary to the first coupling, a landing station having the first coupling of the coupling assembly, a drone having the second coupling of the coupling assembly. The drone is adapted to be guided to within a first predetermined vertical height and horizontal distance of the landing station via GPS, and align the first coupling with the second coupling within a predetermined tolerance level via an image processing assembly."
DRONE LANDING SYSTEM AND ASSEMBLY,https://lens.org/039-986-617-058-018,2022,"A drone landing assembly comprising a coupling assembly comprising a first coupling and a second coupling complementary to the first coupling, a landing station having the first coupling of the coupling assembly, a drone having the second coupling of the coupling assembly. The drone is adapted to be guided to within a first predetermined vertical height and horizontal distance of the landing station via GPS, and align the first coupling with the second coupling within a predetermined tolerance level via an image processing assembly."
DRONE LANDING SYSTEM AND ASSEMBLY,https://lens.org/039-986-617-058-018,2022,"A drone landing assembly comprising a coupling assembly comprising a first coupling and a second coupling complementary to the first coupling, a landing station having the first coupling of the coupling assembly, a drone having the second coupling of the coupling assembly. The drone is adapted to be guided to within a first predetermined vertical height and horizontal distance of the landing station via GPS, and align the first coupling with the second coupling within a predetermined tolerance level via an image processing assembly."
Voice activated device,https://lens.org/022-377-668-583-014,2005,"A voice activated camera is described which allows users to take remote photographs by speaking one or more keywords. In a preferred embodiment, a speech processing unit is provided which is arranged to detect extended periodic signals from a microphone of the camera. A control unit is also provided to control the taking of a photograph when such an extended periodic component is detected by the speech processing unit."
Voice activated device,https://lens.org/060-642-409-705-753,2008,"A voice activated camera is described which allows users to take remote photographs by speaking one or more keywords. In a preferred embodiment, a speech processing unit is provided which is arranged to detect extended periodic signals from a microphone of the camera. A control unit is also provided to control the taking of a photograph when such an extended periodic component is detected by the speech processing unit."
AUTONOMOUS BASE STATION AND NETWORK FOR UNMANNED VEHICLES,https://lens.org/150-156-989-324-509,2021,"An autonomous base station for unmanned aerial vehicles ('UAVs') is disclosed, which includes a landing surface for a UAV, configured with at least one power transfer bus for supplying power to a power source of a UAV thereon. The base station further includes a networking module and data processing means operably connected to, and configured to control, the power transfer bus and the networking module. The data processing means is operably connected to the UAV through the networking module, and further configured to receive, store and process data from the UAV or another. The base station further includes a power supply operably connected to the or each power transfer bus, the or each networking module and the data processing means. A network of at least two such base stations is also disclosed, for sensing, modelling and monitoring an environment with UAVs."
AUTONOMOUS BASE STATION AND NETWORK FOR UNMANNED VEHICLES,https://lens.org/100-893-653-676-830,2021,"An autonomous base station for unmanned aerial vehicles ('UAVs') is disclosed, which includes a landing surface for a UAV, configured with at least one power transfer bus for supplying power to a power source of a UAV thereon. The base station further includes a networking module and data processing means operably connected to, and configured to control, the power transfer bus and the networking module. The data processing means is operably connected to the UAV through the networking module, and further configured to receive, store and process data from the UAV or another. The base station further includes a power supply operably connected to the or each power transfer bus, the or each networking module and the data processing means. A network of at least two such base stations is also disclosed, for sensing, modelling and monitoring an environment with UAVs."
"TARGET RECOGNITION BASED ON IMAGE INFORMATION, SYSTEM FOR TARGET RECOGNITION BASED ON IMAGE INFORMATION",https://lens.org/090-769-139-118-845,2020,"A method for controlling an unmanned vehicle for target recognition includes receiving an instruction pertinent to a target zone (102), sending a first command to the unmanned vehicle for navigating around the target zone (102'), receiving image information of a plurality of target candidates within the target zone (103), identifying a first group of the plurality of target candidates by processing the image information of the plurality of target candidates (104), and receiving image information of each of the plurality of target candidates in the first group from at least two perspectives (105)."
"Control method for camera device, camera device, camera system, and storage medium",https://lens.org/093-453-914-530-370,2022,A control method of a camera device includes receiving audio data transmitted by an acoustic-electric device via Bluetooth communication and mixing the audio data with the video data to produce a video with audio. The audio data is recorded by the acoustic-electric device during a process of capturing video data by the camera device.
"CONTROL METHOD FOR CAMERA DEVICE, CAMERA DEVICE, CAMERA SYSTEM, AND STORAGE MEDIUM",https://lens.org/183-985-329-148-998,2021,A control method of a camera device includes receiving audio data transmitted by an acoustic-electric device via Bluetooth communication and mixing the audio data with the video data to produce a video with audio. The audio data is recorded by the acoustic-electric device during a process of capturing video data by the camera device.
"Control method for camera device, camera device, camera system, and storage medium",https://lens.org/093-453-914-530-370,2022,A control method of a camera device includes receiving audio data transmitted by an acoustic-electric device via Bluetooth communication and mixing the audio data with the video data to produce a video with audio. The audio data is recorded by the acoustic-electric device during a process of capturing video data by the camera device.
AUTONOMOUS BASE STATION AND NETWORK FOR UNMANNED VEHICLES,https://lens.org/018-989-073-892-101,2023,"An autonomous base station for unmanned aerial vehicles (UAVs) is disclosed, which includes a landing surface for a UAV, configured with at least one power transfer bus for supplying power to a power source of a UAV thereon. The base station further includes a networking module and data processing means operably connected to, and configured to control, the power transfer bus and the networking module. The data processing means is operably connected to the UAV through the networking module, and further configured to receive, store and process data from the UAV or another. The base station further includes a power supply operably connected to the or each power transfer bus, the or each networking module and the data processing means. A network of at least two such base stations is also disclosed, for sensing, modelling and monitoring an environment with UAVs."
AUTONOMOUS BASE STATION AND NETWORK FOR UNMANNED VEHICLES,https://lens.org/018-989-073-892-101,2023,"An autonomous base station for unmanned aerial vehicles (UAVs) is disclosed, which includes a landing surface for a UAV, configured with at least one power transfer bus for supplying power to a power source of a UAV thereon. The base station further includes a networking module and data processing means operably connected to, and configured to control, the power transfer bus and the networking module. The data processing means is operably connected to the UAV through the networking module, and further configured to receive, store and process data from the UAV or another. The base station further includes a power supply operably connected to the or each power transfer bus, the or each networking module and the data processing means. A network of at least two such base stations is also disclosed, for sensing, modelling and monitoring an environment with UAVs."
Reinforcement Learning Based System for Aerial Imagery Acquisition Using Drone Following Target Vehicle,https://lens.org/100-273-848-740-831,2021,"A method of surveying roads includes generating a dynamic flight plan for a drone using a vehicle traveling on a road as a target. The dynamic flight plan includes instructions for movement of the drone. The method includes controlling the drone as a function of position of the vehicle based on the dynamic flight plan. The method includes maintaining, based on the controlling, line of sight with the drone while the drone with an onboard camera follows the vehicle and captures images of the road being traveled by the vehicle using the onboard camera."
"FLYING DEVICE, MOVING DEVICE, SERVER AND PROGRAM",https://lens.org/010-711-183-304-756,2018,"A flying device includes: an image capturing unit that captures an image of an object that is moving; a flying unit that flies with the image capturing unit mounted thereat; and a control unit that controls at least one of the flying unit and the image capturing unit with control information based on an output from the image capturing unit so as to engage the image capturing unit, after having captured the image of the object, to capture an image of the object."
Autonomous control of a parafoil recovery system for UAVs,https://lens.org/104-661-907-495-697,2003,"A parafoil system for autonomously controlling the gliding descent of a payload/UAV from a launch point to a predetermined recovery area and manipulating the parafoil to execute a soft landing in the recovery area, a sensing means associated with the system for determining wind speed and direction, as well as altitude, heading and position of the system, a means housed within the system for processing information received from the sensing means to determine the gliding flight path from the launch point to a predetermined recovery area and the execution of a flare maneuver to achieve a soft landing, control surface means on the parafoil canopy, mechanical means coupling the information processing means with the control surface means for adjusting the control surface means to accomplish the steering to the recovery area during gliding flight and the flare maneuver during landing, and a power source in the payload/UAV."
Surveillance and Tracking Device,https://lens.org/036-129-983-844-97X,2016,"A surveillance and tracking device (10) comprises a nest (12) holding a secondary camera (20) and a drone (14) holding a primary camera (18). Both cameras provide the operator (16) with a real time video or photos. While the secondary camera (20) surveys the local field in which the nest (12) is installed, the drone (14) can fly during the active stage of the functionality of the device (10) to follow up certain events or persons using the primary camera (18). The drone (14) can also perform routine surveillance of targeted fields. This large scale capability of the presented device (10) enables the operator (16) to perform a flexible, sustainable and more effective surveillance process. And so; the device (10) can deal up with the massively elaborated danger diversity and security challenges of the current era."
Unmanned firefighting drone,https://lens.org/042-406-568-633-075,2023,"The invention discloses an unmanned, firefighting drone (100) comprising at least one propulsion unit (101), and a gyroscopic frame (200) which frame (200) carries a launching unit (300), wherein the launching unit (300) is adapted to receive fire retarding material, and is rotatable, in use, independently of the propulsion unit (101) to aim and discharge fire retarding material at an intended target."
UNMANNED FIREFIGHTING DRONE,https://lens.org/133-004-046-232-677,2022,"The invention discloses an unmanned, firefighting drone (100) comprising at least one propulsion unit (101), and a gyroscopic frame (200) which frame (200) carries a launching unit (300), wherein the launching unit (300) is adapted to receive fire retarding material, and is rotatable, in use, independently of the propulsion unit (101) to aim and discharge fire retarding material at an intended target."
Unmanned firefighting drone,https://lens.org/042-406-568-633-075,2023,"The invention discloses an unmanned, firefighting drone (100) comprising at least one propulsion unit (101), and a gyroscopic frame (200) which frame (200) carries a launching unit (300), wherein the launching unit (300) is adapted to receive fire retarding material, and is rotatable, in use, independently of the propulsion unit (101) to aim and discharge fire retarding material at an intended target."
Remote switch controller,https://lens.org/031-026-358-762-940,2016,"A wireless remote control system and method for activating a switch including a transmitter assembly and a receiver assembly. The receiver assembly attaches to and is stabilized by connecting a flex rod to an object near the switch. The receiver assembly includes a servo that connects to an object, such as a key or switch. The transmitter assembly can send differing signals to cause the servo to take alternate actions."
THEFT IDENTIFICATION AND INSURANCE CLAIM ADJUSTMENT USING DRONE DATA,https://lens.org/031-398-532-426-123,2021,"Various techniques are described utilizing unmanned aerial vehicles (UAVs, or drones) for various disaster and/or catastrophe-related purposes. An area at risk of an insurance-related event (catastrophe, hurricane, natural disaster, wild fire, etc.) that requires evacuation may be determined, as well as insured premises or assets within that area. With an insured's permission, drones may be directed to the area to collect image or other data of insured premises or assets before, during, or after the event strikes. The drone data may be received and analyzed to identify losses to insured assets that should properly be classified as theft losses for insurance purposes. Insurance claims may be prepared or adjusted for insureds based upon the theft losses in accordance with various types of insurance policies (auto, home, personal articles, etc.) or endorsements to ensure that insureds are properly and promptly reimbursed for the theft losses."
ROBOT/DRONE MULTI-PROJECTILE LAUNCHER,https://lens.org/058-078-904-790-653,2018,"A multi-projectile launcher capable of firing less-lethal 40 mm rounds or high explosive 40 mm rounds (i.e., HE Grenades) can be attached to robots, drones, vehicles and stationary structures. The robot/drone multi -projectile launcher is remote controlled and capable of 360 degree horizontal rotation as well as vertical panning, and is able to quickly turn and acquire targets. A solenoid controlled firing system for each barrel includes a firing pin, trigger lever and striker, as well as a lockout bar and striker seer to prevent accidental firing (e.g., from impact or sudden jolt). Target acquisition systems include an infrared laser system, a standard red laser system, and an optic targeting system that is monitored through an onboard camera. A wireless network access device allows for remote viewing of live-feed camera images (still frame and video) and control of the optic targeting system, as well as the launcher articulation and firing."
ROBOT/DRONE MULTI-PROJECTILE LAUNCHER,https://lens.org/045-429-298-336-513,2018,"A multi-projectile launcher capable of firing less-lethal 40 mm rounds or high explosive 40 mm rounds (i.e., HE Grenades) can be attached to robots, drones, vehicles and stationary structures. The robot/drone multi -projectile launcher is remote controlled and capable of 360 degree horizontal rotation as well as vertical panning, and is able to quickly turn and acquire targets. A solenoid controlled firing system for each barrel includes a firing pin, trigger lever and striker, as well as a lockout bar and striker seer to prevent accidental firing (e.g., from impact or sudden jolt). Target acquisition systems include an infrared laser system, a standard red laser system, and an optic targeting system that is monitored through an onboard camera. A wireless network access device allows for remote viewing of live-feed camera images (still frame and video) and control of the optic targeting system, as well as the launcher articulation and firing."
"UNMANNED AERIAL VEHICLE, CONTROLSYSTEM THEREOF AND CONTROL PROGRAM",https://lens.org/123-842-613-082-354,2021,"Being unable to restart when it collides with an object or crashes, an unmanned aerial vehicle, control system thereof and control program, for preventing damage caused by uncontrollable restarts and crashes is provided. The unmanned aerial vehicle includes a plurality of rotating bodies, a plurality of motors individually driving and rotating the plurality of rotating bodies, and a flight controller individually controlling the plurality of motors. The flight controller includes a collision/crash detection unit detecting collision or crash on the basis of a signal from a sensor, and a power cut-off command unit cutting off a power supply on the basis of a detection signal from the collision/crash detection unit."
HELICOPTER REMOTE CONTROL SYSTEM,https://lens.org/130-555-205-437-058,1992,"A remote controlled helicopter (12) having a video radio frequency link (43) to a fixed control location (10) has a video camera (14) with a field of view including the terrain forward of the helicopter (12), an airspeed display (70), a relative wind direction indicator (18, 20), and a pitch indicator (33). A video monitor (40) at the fixed location (10) displays received video signals of the terrain, airspeed, relative wind direction and pitch permitting control of the helicopter over a radio link (43) from the fixed location (10) to the helicopter (12). The system provides training, experience, and practice in operation of a helicopter (12)."
ELECTRONIC DEVICE AND CONTROL METHOD THEREOF,https://lens.org/178-522-784-637-468,2023,"An electronic device and a control method thereof are provided. The control method of an electronic device includes: acquiring first location information on a projection area of an image projected by the electronic device through a sensor; acquiring second location information on a location where a user is located, through the sensor; and performing at least one of an operation corresponding to a voice input of the user or an operation corresponding to image quality processing based on the first location information and the second location information."
Propeller sound alteration for a drone,https://lens.org/116-002-006-786-442,2018,"Techniques for using an unmanned aerial vehicle (UAV) to deliver a payload while reducing and/or altering sound generated by the UAV during delivery may be provided. For example, during delivery, the UAV may be instructed to utilize one or more sets of propellers of different sizes to reduce and/or alter the sound generated by and/or around the UAV. Intrinsic and extrinsic information associated with the UAV may be utilized to dynamically adjust the particular sets of propellers of a certain and different size to utilize during different portions of a flight path while delivering the payload."
"System, apparatus and method for controlling an aircraft",https://lens.org/047-975-850-009-606,2012,"Apparatuses, systems and methods are provided for controlling an aircraft."
UNMANNED AERIAL VEHICLE COUPLING APPARATUS FOR DRONE COUPLING WITH VEHICLES,https://lens.org/059-311-784-568-007,2017,"An unmanned aerial vehicle coupling apparatus for drone coupling. The unmanned aerial vehicle coupling apparatus includes a processor-based monitoring device to monitor values for each of a plurality of functions provided by a unmanned aerial vehicle and to detect when a value exceeds a predetermined threshold value, a vehicle selector to receive travel routes from each of a plurality of secondary vehicles and to select a secondary vehicle based on a travel route of the secondary vehicle when the value exceeds the predetermined threshold value, and a coupling mechanism to fasten and unfasten the unmanned aerial vehicle to the secondary vehicle."
Unmanned aerial vehicle coupling apparatus for drone coupling with vehicles,https://lens.org/091-769-433-499-593,2019,"An unmanned aerial vehicle coupling apparatus for drone coupling. The unmanned aerial vehicle coupling apparatus includes a processor-based monitoring device to monitor values for each of a plurality of functions provided by a unmanned aerial vehicle and to detect when a value exceeds a predetermined threshold value, a vehicle selector to receive travel routes from each of a plurality of secondary vehicles and to select a secondary vehicle based on a travel route of the secondary vehicle when the value exceeds the predetermined threshold value, and a coupling mechanism to fasten and unfasten the unmanned aerial vehicle to the secondary vehicle."
"UNCREWED AERIAL VEHICLE CONTROL METHOD, APPARATUS, AND SYSTEM",https://lens.org/189-437-142-604-552,2022,"This application provides an uncrewed aerial vehicle control method, an apparatus, and a system. An uncrewed aerial vehicle or a network device identifies a risk of a flight path, to manage the flight path of the uncrewed aerial vehicle, thereby ensuring flight safety of the uncrewed aerial vehicle."
"UNCREWED AERIAL VEHICLE CONTROL METHOD, APPARATUS, AND SYSTEM",https://lens.org/189-437-142-604-552,2022,"This application provides an uncrewed aerial vehicle control method, an apparatus, and a system. An uncrewed aerial vehicle or a network device identifies a risk of a flight path, to manage the flight path of the uncrewed aerial vehicle, thereby ensuring flight safety of the uncrewed aerial vehicle."
"UNMANNED AERIAL VEHICLE CONTROL METHOD, APPARATUS, AND SYSTEM",https://lens.org/021-386-493-726-447,2022,"This application provides an uncrewed aerial vehicle control method, an apparatus, and a system. An uncrewed aerial vehicle or a network device identifies a risk of a flight path, to manage the flight path of the uncrewed aerial vehicle, thereby ensuring flight safety of the uncrewed aerial vehicle."
"UNMANNED AERIAL VEHICLE CONTROL METHOD, APPARATUS, AND SYSTEM",https://lens.org/021-386-493-726-447,2022,"This application provides an uncrewed aerial vehicle control method, an apparatus, and a system. An uncrewed aerial vehicle or a network device identifies a risk of a flight path, to manage the flight path of the uncrewed aerial vehicle, thereby ensuring flight safety of the uncrewed aerial vehicle."
UNMANNED AUTONOMOUS VEHICLE CAMERABOT,https://lens.org/005-933-322-373-042,2022,"The disclosure relates to providing a method for video capturing by a camera- equipped drone of an activity of at least one athlete practicing in an area. The method includes the drone hovering in a pre-specified flight zoon, the camera capturing video streams of the area and the practicing athlete thereof, analyzing video streams for an analysis of operations of the athlete and for a decision on desired shooting parameters, determining desired drone maneuvering and desired camera alignment, and the drone executing navigation instructions and desired camera parameter alignment in accordance with the determining of drone maneuvering and camera alignment. The method may also include the drone issuing a signal for the attention of the athlete. Additional optional steps are detecting sports objects, playing field lines and landmarks, detecting and tracking the athlete, detecting a 3D (three dimension) pose of the athlete, recognizing sports events occurring in the area, and recognizing detailed performance parameters. The method may further include retrieving a set of rules for determining a shooting path for the drone, the athlete issuing a signal for the attention of the drone, interpreting the issued signal the drone acting accordingly."
UNMANNED AUTONOMOUS VEHICLE CAMERABOT,https://lens.org/005-933-322-373-042,2022,"The disclosure relates to providing a method for video capturing by a camera- equipped drone of an activity of at least one athlete practicing in an area. The method includes the drone hovering in a pre-specified flight zoon, the camera capturing video streams of the area and the practicing athlete thereof, analyzing video streams for an analysis of operations of the athlete and for a decision on desired shooting parameters, determining desired drone maneuvering and desired camera alignment, and the drone executing navigation instructions and desired camera parameter alignment in accordance with the determining of drone maneuvering and camera alignment. The method may also include the drone issuing a signal for the attention of the athlete. Additional optional steps are detecting sports objects, playing field lines and landmarks, detecting and tracking the athlete, detecting a 3D (three dimension) pose of the athlete, recognizing sports events occurring in the area, and recognizing detailed performance parameters. The method may further include retrieving a set of rules for determining a shooting path for the drone, the athlete issuing a signal for the attention of the drone, interpreting the issued signal the drone acting accordingly."
UNMANNED AUTONOMOUS VEHICLE CAMERABOT,https://lens.org/005-933-322-373-042,2022,"The disclosure relates to providing a method for video capturing by a camera- equipped drone of an activity of at least one athlete practicing in an area. The method includes the drone hovering in a pre-specified flight zoon, the camera capturing video streams of the area and the practicing athlete thereof, analyzing video streams for an analysis of operations of the athlete and for a decision on desired shooting parameters, determining desired drone maneuvering and desired camera alignment, and the drone executing navigation instructions and desired camera parameter alignment in accordance with the determining of drone maneuvering and camera alignment. The method may also include the drone issuing a signal for the attention of the athlete. Additional optional steps are detecting sports objects, playing field lines and landmarks, detecting and tracking the athlete, detecting a 3D (three dimension) pose of the athlete, recognizing sports events occurring in the area, and recognizing detailed performance parameters. The method may further include retrieving a set of rules for determining a shooting path for the drone, the athlete issuing a signal for the attention of the drone, interpreting the issued signal the drone acting accordingly."
Bathroom speaker,https://lens.org/116-736-775-498-413,2021,"A voice controlled device comprises a housing, a dock, a coupling mechanism, and a microphone. The dock is configured to connect the housing to a plurality of host appliances. The coupling mechanism is configured to receive an identification value indicative of docking between the voice controlled device and a currently connected host appliance of the plurality of host appliances. The microphone is configured to receive one or more voice inputs for the currently connected host appliance. A command is provided based on the one or more voice inputs and the identification value."
SINK DEVICE,https://lens.org/008-002-302-593-420,2021,"A voice controlled device comprises a housing, a dock, a coupling mechanism, and a microphone. The dock is configured to connect the housing to a plurality of host appliances. The coupling mechanism is configured to receive an identification value indicative of docking between the voice controlled device and a currently connected host appliance of the plurality of host appliances. The microphone is configured to receive one or more voice inputs for the currently connected host appliance. A command is provided based on the one or more voice inputs and the identification value."
BATHROOM SPEAKER,https://lens.org/003-734-546-518-226,2019,"A voice controlled device comprises a housing, a dock, a coupling mechanism, and a microphone. The dock is configured to connect the housing to a plurality of host appliances. The coupling mechanism is configured to receive an identification value indicative of docking between the voice controlled device and a currently connected host appliance of the plurality of host appliances. The microphone is configured to receive one or more voice inputs for the currently connected host appliance. A command is provided based on the one or more voice inputs and the identification value."
Display hub for classrooms,https://lens.org/091-738-862-596-891,2016,"An audio and video control device is disclosed. In some embodiments, the audio and video control device may include one or more of a first Wi-Fi transceiver; a second Wi-Fi transceiver; a Bluetooth transceiver; a microphone input; an HDMI input; a video output; an audio output; an IR output; an Ethernet connection; a paging input; and/or a controller. The controller may be configured to receive a video signal from at least one of the first Wi-Fi transceiver, the second Wi-Fi transceiver, and the HDMI input; output at least a portion of the video signal through the video output; output at least a portion of an audio portion of the video signal through the audio output; receive audio data from the microphone input; and/or output the audio data through the audio output."
DISPLAY HUB FOR CLASSROOMS,https://lens.org/117-760-508-081-409,2015,"An audio and video control device is disclosed. In some embodiments, the audio and video control device may include one or more of a first Wi-Fi transceiver; a second Wi-Fi transceiver; a Bluetooth transceiver; a microphone input; an HDMI input; a video output; an audio output; an IR output; an Ethernet connection; a paging input; and/or a controller. The controller may be configured to receive a video signal from at least one of the first Wi-Fi transceiver, the second Wi-Fi transceiver, and the HDMI input; output at least a portion of the video signal through the video output; output at least a portion of an audio portion of the video signal through the audio output; receive audio data from the microphone input; and/or output the audio data through the audio output."
AUTONOMOUS VEHICLE COMMUNICATION CONFIGURATION SYSTEM,https://lens.org/151-135-510-313-01X,2017,"An autonomous vehicle (AV) can include a communication system to communicate with a backend system, a sensor system to collect sensor data representing an operational environment of the AV, and a control system that can processes the sensor data to perform a localization operation to determine a location and an orientation of the AV within a given region, and autonomously operate the AV's acceleration, braking, and steering systems throughout the given region. Based on the localization operation, the AV can implement a set of configuration commands to configure the communication system to transmit and receive data with the backend system using one or more specified network nodes."
Methods and system for vision-based landing,https://lens.org/065-389-205-661-790,2023,"A computer-implemented method for controlling an unmanned aerial vehicle (UAV) includes obtaining a first image captured by an imaging device carried by the UAV during a takeoff of the UAV from a target location, obtaining a second image from the imaging device in response to an indication to return to the target location, determining a spatial relationship between the UAV and the target location by comparing the first image and the second image, and controlling the UAV to approach the target location based at least in part on the spatial relationship."
METHODS AND SYSTEM FOR VISION-BASED LANDING,https://lens.org/004-077-732-264-118,2019,"A computer-implemented method for controlling an unmanned aerial vehicle (UAV) includes obtaining a first image captured by an imaging device carried by the UAV during a takeoff of the UAV from a target location, obtaining a second image from the imaging device in response to an indication to return to the target location, determining a spatial relationship between the UAV and the target location by comparing the first image and the second image, and controlling the UAV to approach the target location based at least in part on the spatial relationship."
Methods and system for vision-based landing,https://lens.org/065-389-205-661-790,2023,"A computer-implemented method for controlling an unmanned aerial vehicle (UAV) includes obtaining a first image captured by an imaging device carried by the UAV during a takeoff of the UAV from a target location, obtaining a second image from the imaging device in response to an indication to return to the target location, determining a spatial relationship between the UAV and the target location by comparing the first image and the second image, and controlling the UAV to approach the target location based at least in part on the spatial relationship."
Small UAV (unmanned aerial vehicle) provided with rotary body,https://lens.org/059-779-998-792-411,2016,"The invention discloses a small UAV (unmanned aerial vehicle) provided with a rotary body. The small UAV comprises the body provided with a built-in power supply and a control system, wherein the body is provided with two opposite rotor propellers and two opposite hinges, rotary shafts of the rotor propellers are parallel to the horizontal plane, wings are hinged onto the hinges, a rotary shaft of each hinge forms a 7-11-degree angle with the horizontal plane and forms a 60-degree angle with an axis of the corresponding wing, and each wing is provided with a position-limit mechanism, so that the axis of the wing can keep parallel to the horizontal plane when the wing is in a stop state. The UAV combines structure characteristics of a fixed-wing UAV and a rotor UAV and has higher maneuvering characteristic and higher cruising ability."
REMOTE CONTROLLED MOBILE PLATFORM,https://lens.org/044-739-952-927-770,2008,"A self-powered mobile platform that is configured to be remotely wirelessly controlled, said platform including a base with a first face that is dimensioned and configured to allow a vertical landing aircraft to land and take off."
REMOTE CONTROLLED MOBILE PLATFORM,https://lens.org/131-156-627-106-302,2008,"A self-powered mobile platform that is configured to be remotely wirelessly controlled, said platform including a base with a first face that is dimensioned and configured to allow a vertical landing aircraft to land and take off."
Remote Controlled Mobile Platform,https://lens.org/030-440-445-978-667,2008,"A self-powered mobile platform that is configured to be remotely wirelessly controlled, said platform including a base with a first face that is dimensioned and configured to allow a vertical landing aircraft to land and take off."
"Motor control method, apparatus, and system",https://lens.org/104-746-576-773-391,2021,"An unmanned aerial vehicle includes a fuselage, a motor mounted at the fuselage, and a control apparatus configured to control the motor. The control apparatus includes one or more processors configured to obtain a present electrical parameter of a battery configured to power the motor, calculate a compensation amount of a control signal of the motor according to the present electrical parameter, and modify the control signal according to the compensation amount."
"MOTOR CONTROL METHOD, APPARATUS, AND SYSTEM",https://lens.org/074-031-227-521-780,2020,"An unmanned aerial vehicle includes a fuselage, a motor mounted at the fuselage, and a control apparatus configured to control the motor. The control apparatus includes one or more processors configured to obtain a present electrical parameter of a battery configured to power the motor, calculate a compensation amount of a control signal of the motor according to the present electrical parameter, and modify the control signal according to the compensation amount."
"METHOD AND A SYSTEM FOR REAL-TIME DATA PROCESSING, TRACKING, AND MONITORING OF AN ASSET USING UAV",https://lens.org/076-477-728-834-282,2021,The present invention discloses a novel system and a method for providing real-time long-range connectivity between a UAV and a ground controller. This technology opens the door to a range of new UAV/drone based applications that have not been possible until now. The present invention discloses a technique to control the UAV using a user device by using a high speed long distance communication techniques.
ELECTRONIC DEVICE CONTROL METHOD AND ELECTRONIC DEVICE CONTROL SYSTEM APPLYING THE ELECTRONIC DEVICE CONTROL METHOD,https://lens.org/184-306-455-659-165,2022,"An electronic device control method, for calling a first electronic device in a building, comprising: (a) receiving a call command from an user by the first electronic device; (b) acquiring map information of the building by the first electronic device corresponding to the call command; and (c) driving the first electronic device to go to a user region in which the user is located according to the map information, wherein the user region is a predetermined region of a user location of the user."
Control of image triggering for aerial image capturing in nadir alignment for an unmanned aircraft,https://lens.org/083-205-297-150-624,2019,"Method for aerial image capturing by means of an unmanned and controllable aircraft comprising a camera, more particularly a drone, during a flight maneuver of said aircraft, comprising continual determining of a camera position and alignment of an optical camera axis and acquiring of a series of aerial images. For each aerial image of said aerial image series, the capturing of the respective aerial image is triggered by flying through a respective image trigger region with said aircraft, wherein the location of said respective image trigger region is determined at least in each case by one trigger position assigned to said respective image trigger region and triggered subject to the alignment of the camera axis when flying through said respective image trigger region, with respect to fulfilling a defined, maximum angle deviation relative to a predetermined spatial alignment."
System For Generating Drone Video Feed Overlays Based On Property Monitoring System Data,https://lens.org/118-653-347-177-903,2022,"A monitoring system that is configured to monitor a property is disclosed. The monitoring system includes a sensor that is configured to generate sensor data that reflects an attribute of a property. The monitoring system further includes a drone that generates image data, location data, and orientation data. The monitoring system further includes a monitor control unit. The monitor control unit is configured to receive the sensor data, the location data, and the orientation data. The monitor control unit is configured to determine that an event has occurred at the property and a location of the event within the property. The monitor control unit is configured to generate a graphical overlay based on the event, the location data, and the orientation data. The monitor control unit is configured to generate a graphical interface. The monitor control unit is configured to output the graphical interface."
System for generating drone video feed overlays based on property monitoring system data,https://lens.org/077-907-346-370-594,2021,"A monitoring system that is configured to monitor a property is disclosed. The monitoring system includes a sensor that is configured to generate sensor data that reflects an attribute of a property. The monitoring system further includes a drone that generates image data, location data, and orientation data. The monitoring system further includes a monitor control unit. The monitor control unit is configured to receive the sensor data, the location data, and the orientation data. The monitor control unit is configured to determine that an event has occurred at the property and a location of the event within the property. The monitor control unit is configured to generate a graphical overlay based on the event, the location data, and the orientation data. The monitor control unit is configured to generate a graphical interface. The monitor control unit is configured to output the graphical interface."
METHOD FOR CONTROLLING A ROBOTIC DEVICE,https://lens.org/182-576-847-112-836,2022,"A method for controlling a robotic device. The method includes: obtaining an image, processing the image using a neural convolutional network, which generates an image in a feature space from the image, the image in the feature space, feeding the image in the feature space to a neural actor network, which generates an action parameter image, feeding the image in the feature space and the action parameter image to a neural critic network, which generates an assessment image, which defines for each pixel an assessment for the action defined by the set of action parameter values for that pixel, selecting, from multiple sets of action parameters of the action parameter image, that set of action parameter values having the highest assessment, and controlling the robot for carrying out an action according to the selected action parameter set."
METHOD FOR CONTROLLING A ROBOTIC DEVICE,https://lens.org/182-576-847-112-836,2022,"A method for controlling a robotic device. The method includes: obtaining an image, processing the image using a neural convolutional network, which generates an image in a feature space from the image, the image in the feature space, feeding the image in the feature space to a neural actor network, which generates an action parameter image, feeding the image in the feature space and the action parameter image to a neural critic network, which generates an assessment image, which defines for each pixel an assessment for the action defined by the set of action parameter values for that pixel, selecting, from multiple sets of action parameters of the action parameter image, that set of action parameter values having the highest assessment, and controlling the robot for carrying out an action according to the selected action parameter set."
AERIAL VEHICLE IMAGE CAPTURING SYSTEMS,https://lens.org/099-019-749-220-470,2019,"A method, system, apparatus, and/or device for capturing an image from an aerial vehicle. The method, system, apparatus, and/or device may include a boom, a motor, a propeller, a controller, a top plate, a bottom plate, and an image capturing device. The boom may be an arm that extends outwardly. The motor may be connected to an end of the boom. The propeller may be connected to the motor. The motor may be configured to rotate the propeller to lift the system, the apparatus, and/or the device into flight when the motor is engaged. The controller may be configured to control the motor. The top plate may be connected to a first end of the boom. The bottom plate may be connected to a second end of the boom. The image capturing device may be mounted to the top plate or the bottom plate."
Aerial vehicle image capturing systems,https://lens.org/070-714-329-939-333,2021,"A method, system, apparatus, and/or device for capturing an image from an aerial vehicle. The method, system, apparatus, and/or device may include a boom, a motor, a propeller, a controller, a top plate, a bottom plate, and an image capturing device. The boom may be an arm that extends outwardly. The motor may be connected to an end of the boom. The propeller may be connected to the motor. The motor may be configured to rotate the propeller to lift the system, the apparatus, and/or the device into flight when the motor is engaged. The controller may be configured to control the motor. The top plate may be connected to a first end of the boom. The bottom plate may be connected to a second end of the boom. The image capturing device may be mounted to the top plate or the bottom plate."
Drone with ring assembly,https://lens.org/065-801-838-450-530,2018,"Disclosed is an unmanned aerial vehicle (UAV) with a pre-defined shape to deploy one or more items. The unmanned aerial vehicle (UAV) includes an upper housing, a lower housing, and a power unit. The upper housing includes plurality of rotors to lift and propel the unmanned aerial vehicle (UAV). Further the unmanned aerial vehicle (UAV) includes various electronic components such as plurality of electronic cards, a processing unit, a Global Positioning System (GPS), a communication unit, an electronic gyroscope, a barometer, engines and flight control system, video camera, a forward looking infrared (FLIR) device, a microphone, and a laser telemeter/designator/range finder. The power unit powers the aforementioned electronic components. The lower housing includes plurality of storage units to stores one or more items. The lower housing is removably attached with the upper housing in a way to deploy the items at a predetermined location through plurality of openings."
LIGHT WEIGHT TWO OR THREE AXIS REMOTE CAMERA HEAD,https://lens.org/178-391-767-232-71X,2019,"A remotely controlled camera head has a pan frame including a first rectangular section. An upper end of a second rectangular section is joined to the left side of the first rectangular section. A pan motor in the first rectangular section of the pan frame rotates the pan frame about a pan axis co-axial with a hub when the pan motor is on. A tilt frame is rotatably attached to the lower end of the second rectangular section and movable about a tilt axis. In a two axis mode, a camera platform is attached to the tilt frame. A slide out may be used to change the length of the tilt frame. A tilt motor within the second rectangular section is connected to the tilt frame for rotating the tilt frame about a tilt axis when the tilt motor is on."
Light weight two or three axis remote camera head,https://lens.org/019-971-448-088-904,2020,"A remotely controlled camera head has a pan frame including a first rectangular section. An upper end of a second rectangular section is joined to the left side of the first rectangular section. A pan motor in the first rectangular section of the pan frame rotates the pan frame about a pan axis co-axial with a hub when the pan motor is on. A tilt frame is rotatably attached to the lower end of the second rectangular section and movable about a tilt axis. In a two axis mode, a camera platform is attached to the tilt frame. A slide out may be used to change the length of the tilt frame. A tilt motor within the second rectangular section is connected to the tilt frame for rotating the tilt frame about a tilt axis when the tilt motor is on."
Robot,https://lens.org/164-484-215-763-912,2007,"A robot for freely moving about in an environment where there is an obstacle. The robot includes a communication section transmitting by wireless an image taken by a camera to a base station, and via the base station to a communication terminal making a radio communication with the base station, and receiving by wireless movement target position information specified on the image by an operation of the communication terminal via the base station, and a motion control section that moves the robot up to a movement target position specified by the movement target position information acquired in the communication section."
A method of flying an unmanned aerial vehicle,https://lens.org/024-670-707-358-481,2017,"The invention relates to a method of flying an unmanned aerial vehicle (UAV) in response to emergency conditions A method of flying an unmanned aerial vehicle, the method including steps implemented using a controller forming part of the unmanned aerial vehicle, said steps comprising: defining a plurality of emergency conditions; associating 10 each emergency condition with a priority level; associating each emergency condition with an objective; sensing a plurality of operating parameters of the unmanned aerial vehicle to detect whether one of the plurality of emergency conditions exists; when one or more emergency condition is 15 detected: generating a trajectory for the detected emergency condition having a highest associated priority level, wherein the trajectory is generated in accordance with the objective associated with the emergency condition that has the highest associated priority level; and instructing the 20 unmanned aerial vehicle to follow the generated trajectory. - 24 -"
A method of flying an unmanned aerial vehicle,https://lens.org/005-903-716-952-605,2014,"The invention relates to a method of flying an unmanned aerial vehicle (UAV) in response to emergency conditions A method of flying an unmanned aerial vehicle, the method including steps implemented using a controller forming part of the unmanned aerial vehicle, said steps comprising: defining a plurality of emergency conditions; associating 10 each emergency condition with a priority level; associating each emergency condition with an objective; sensing a plurality of operating parameters of the unmanned aerial vehicle to detect whether one of the plurality of emergency conditions exists; when one or more emergency condition is 15 detected: generating a trajectory for the detected emergency condition having a highest associated priority level, wherein the trajectory is generated in accordance with the objective associated with the emergency condition that has the highest associated priority level; and instructing the 20 unmanned aerial vehicle to follow the generated trajectory. - 24 -"
METHOD AND APPARATUS FOR SPEECH RECOGNITION USING SMART REMOTE CONTROL,https://lens.org/088-444-399-461-36X,2015,"A speech recognition broadcasting apparatus that uses a smart remote control and a controlling method thereof, the method including receiving a runtime resource for speech recognition from a speech recognition server; receiving a speech signal from the smart remote control; recognizing the speech signal based on the received runtime resource for speech recognition; transmitting a result of recognition of the speech signal to the smart remote control; receiving at least one of EPG (Electronic Program Guide) search information or control information of the speech recognition broadcasting apparatus that are based on the result of recognition from the smart remote control; and outputting a search screen or controlling the speech recognition broadcasting apparatus based on the EPG search information or control information of the speech recognition broadcasting apparatus."
METHODS AND SYSTEMS FOR IMPROVING THE PRECISION OF AUTONOMOUS LANDINGS BY DRONE AIRCRAFT ON LANDING TARGETS,https://lens.org/176-638-740-676-635,2019,Methods and system are disclosed for guiding an autonomous drone aircraft during descent to a landing target. The method features the steps of: (a) acquiring an image using a camera on the drone aircraft of an active fiducial system at the landing target; (b) verifying the active fiducial system in the image by comparing the image to a stored model or representation of the active fiducial system; (c) determining a relative position and/or orientation of the drone aircraft to the landing target using data from the image; (d) using the relative position and/or orientation determined in step (c) to guide the drone aircraft toward the landing target; and (e) repeating steps (a) through (d) a plurality of times.
METHODS AND SYSTEMS FOR IMPROVING THE PRECISION OF AUTONOMOUS LANDINGS BY DRONE AIRCRAFT ON LANDING TARGETS,https://lens.org/180-089-067-704-071,2019,Methods and system are disclosed for guiding an autonomous drone aircraft during descent to a landing target. The method features the steps of: (a) acquiring an image using a camera on the drone aircraft of an active fiducial system at the landing target; (b) verifying the active fiducial system in the image by comparing the image to a stored model or representation of the active fiducial system; (c) determining a relative position and/or orientation of the drone aircraft to the landing target using data from the image; (d) using the relative position and/or orientation determined in step (c) to guide the drone aircraft toward the landing target; and (e) repeating steps (a) through (d) a plurality of times.
APPARATUS AND METHOD FOR CONTROLLING ELECTRONIC DEVICE,https://lens.org/005-482-455-147-970,2021,"A method for controlling, by a controller, an electronic device is provided. The method may include: sensing, by a sensor, a first radiation signal incident on the sensor; generating, by the sensor, a first output signal based on the first radiation signal; recognizing a human body based on the first output signal; determining a position of the human body as being located in one of an indoor space or an outdoor space based on the first output signal; and generating a control signal for controlling the electronic device connected via a wired or wireless network based on the position of the human body. A learning model includes a deep neural network generated through machine learning and transmission of a control signal may be performed in an Internet of Things (IoT) environment using a 5G network."
Apparatus and method for controlling electronic device,https://lens.org/118-069-024-003-164,2022,"A method for controlling, by a controller, an electronic device is provided. The method may include: sensing, by a sensor, a first radiation signal incident on the sensor; generating, by the sensor, a first output signal based on the first radiation signal; recognizing a human body based on the first output signal; determining a position of the human body as being located in one of an indoor space or an outdoor space based on the first output signal; and generating a control signal for controlling the electronic device connected via a wired or wireless network based on the position of the human body. A learning model includes a deep neural network generated through machine learning and transmission of a control signal may be performed in an Internet of Things (IoT) environment using a 5G network."
Systems and methods for dynamically masking video and images captured by a drone device camera,https://lens.org/079-685-939-640-74X,2021,"Systems and methods for dynamically masking video or images captured by a drone device camera are provided. Such systems and methods include flying the drone device proximate to a potential surveillance area while in a learning mode, capturing first video or images of the potential surveillance area, identifying first privacy masking areas in the first video or images, flying the drone device proximate to an active surveillance area while in a standard mode, capturing second video or images of the active surveillance area, identifying second privacy masking areas in the second video or images, and dynamically masking a portion of the second video or images that contains any of the first privacy masking areas or the second privacy masking areas."
Wireless remote control apparatus for camera,https://lens.org/156-350-687-803-173,1994,A wireless camera remote control apparatus comprises a transmitter unit for transmitting an activating pulse and a plurality of code pulse signals corresponding to given operations of the camera; and a receiver unit responsive to a code defined by the plurality of code pulses for causing the camera to execute a given operation. The wireless camera remote control apparatus has an immunity to disturbance noise and a reduced power consumption.
"SYSTEM, CONTROLLER AND METHOD CONTROLLING AUTONOMOUS VEHICLE FUNCTIONS",https://lens.org/136-532-529-683-956,2021,"A controller for use with autonomous vehicle functions comprises an input for receiving data regarding a set of vehicle factors, an output for controlling autonomous vehicle functions and a processor having control logic. The control logic receives data regarding the set of vehicle factors, sets the autonomous vehicle functions in a first mode when at least two of the vehicle factors meet a respective first condition and sets the autonomous vehicle functions in second mode when at least one of the vehicle factors meets a respective second condition."
"SYSTEM, CONTROLLER AND METHOD CONTROLLING AUTONOMOUS VEHICLE FUNCTIONS",https://lens.org/109-393-789-509-106,2021,"A controller for use with autonomous vehicle functions comprises an input for receiving data regarding a set of vehicle factors, an output for controlling autonomous vehicle functions and a processor having control logic. The control logic receives data regarding the set of vehicle factors, sets the autonomous vehicle functions in a first mode when at least two of the vehicle factors meet a respective first condition and sets the autonomous vehicle functions in second mode when at least one of the vehicle factors meets a respective second condition."
DRONE WITH WIND GUIDE PART,https://lens.org/166-929-709-325-623,2017,"Disclosed herein is a drone with a wind guide part, which is configured such that it can lift off or aviate using the flow of wind. The drone has a lift force by wind discharged towards the ground through a connecting duct and a wind guide part, so that the drone may lift off or aviate using the flow of the wind. Further, the drone may aviate without a propeller, thus preventing an accident due to the contact of the propeller, saving maintenance cost, and reducing weight and noise."
SECURITY SYSTEM AND SECURITY METHOD,https://lens.org/002-867-264-698-647,2022,A security system according to the present invention comprises: a wearable camera that can be worn by a person and can record a first image which has been captured; an unmanned aerial vehicle that can record a second image which has been captured by a camera mounted thereon; and a control device that acquires the position of the wearable camera and transmits a first instruction to the unmanned aerial vehicle to start recording the second image and to move toward the position of the wearable camera.
"MEASURING DEVICE, CONTROL DEVICE FOR UNMANNED AERIAL VEHICLE AND METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE",https://lens.org/030-684-796-331-858,2019,"Objects of the present disclosure include providing a technique which can efficiently guide an unmanned aerial vehicle to a particular part of a target object. Provided is a control device for an unmanned aerial vehicle (200) including a camera (201). The control device comprises a bright spot detection unit configured to detect, from an image captured by camera (201), a bright spot (301) generated by a laser pointer; a flight control unit configured to perform, based on position of the bright spot (301) in the image, flight control over the unmanned aerial vehicle (200). In such structure, the camera (201) detects the bright spot (301), generated by the irradiation of spot-type indicating laser beam from the total station (100), on a wall surface (300), and the flight control over the unmanned aerial vehicle (200) is performed in a manner that the unmanned aerial vehicle (200) follows the bright spot (301)."
Controlling and commanding an unmanned robot using natural interfaces,https://lens.org/115-212-829-543-619,2020,"The example embodiments are directed to a system and method for controlling and commanding an unmanned robot using natural interfaces. In one example, the method includes receiving a plurality of sensory inputs from a user via one or more natural interfaces, wherein each sensory input is associated with an intention of the user for an unmanned robot to perform a task, processing each of the plurality of sensory inputs using a plurality of channels of processing to produce a first recognition result and a second recognition result, combining the first recognition result and the second recognition result to determine a recognized command, and generating a task plan assignable to the unmanned robot based on the recognized command and predefined control primitives."
CONTROLLING AND COMMANDING AN UNMANNED ROBOT USING NATURAL INTERFACES,https://lens.org/074-075-164-752-075,2019,"The example embodiments are directed to a system and method for controlling and commanding an unmanned robot using natural interfaces. In one example, the method includes receiving a plurality of sensory inputs from a user via one or more natural interfaces, wherein each sensory input is associated with an intention of the user for an unmanned robot to perform a task, processing each of the plurality of sensory inputs using a plurality of channels of processing to produce a first recognition result and a second recognition result, combining the first recognition result and the second recognition result to determine a recognized command, and generating a task plan assignable to the unmanned robot based on the recognized command and predefined control primitives."
CONTROLLING AND COMMANDING AN UNMANNED ROBOT USING NATURAL INTERFACES,https://lens.org/185-010-533-293-626,2019,"The example embodiments are directed to a system and method for controlling and commanding an unmanned robot using natural interfaces. In one example, the method includes receiving a plurality of sensory inputs from a user via one or more natural interfaces, wherein each sensory input is associated with an intention of the user for an unmanned robot to perform a task, processing each of the plurality of sensory inputs using a plurality of channels of processing to produce a first recognition result and a second recognition result, combining the first recognition result and the second recognition result to determine a recognized command, and generating a task plan assignable to the unmanned robot based on the recognized command and predefined control primitives."
ACOUSTIC PARABOLIC MIRROR RING APPARATUS,https://lens.org/097-425-348-546-155,2019,An apparatus for enhancing microphone performance of a voice-controlled smart home device is disclosed. The apparatus generally comprises a lower ring having a first diameter an upper ring having a second diameter and a reflective surface. The reflective surface is disposed along the perimeter of the apparatus so as to directionally alter incoming sound waves and focus them toward an array of microphones.
Acoustic parabolic mirror ring apparatus,https://lens.org/069-988-412-077-829,2019,An apparatus for enhancing microphone performance of a voice-controlled smart home device is disclosed. The apparatus generally comprises a lower ring having a first diameter an upper ring having a second diameter and a reflective surface. The reflective surface is disposed along the perimeter of the apparatus so as to directionally alter incoming sound waves and focus them toward an array of microphones.
Orchestration in heterogeneous drone swarms,https://lens.org/140-206-715-132-323,2021,"A drone system for orchestration in heterogeneous drone swarms is configured to perform operations comprising receiving, at a lead drone of a drone swarm, from a candidate drone, a request to join the drone swarm; transmitting a swarm directive to the candidate drone; evaluating the candidate drone to determine whether the candidate drone is compatible with the swarm directive; and adjusting the swarm directive to accommodate the candidate drone when the candidate drone is compatible with the swarm directive, to add the candidate drone to the drone swarm."
ORCHESTRATION IN HETEROGENEOUS DRONE SWARMS,https://lens.org/165-499-106-887-471,2019,"A drone system for orchestration in heterogeneous drone swarms is configured to perform operations comprising receiving, at a lead drone of a drone swarm, from a candidate drone, a request to join the drone swarm; transmitting a swarm directive to the candidate drone; evaluating the candidate drone to determine whether the candidate drone is compatible with the swarm directive; and adjusting the swarm directive to accommodate the candidate drone when the candidate drone is compatible with the swarm directive, to add the candidate drone to the drone swarm."
Air Traffic Communication,https://lens.org/073-512-496-451-11X,2019,"Apparatus and methods related to autonomous aerial communications are included. A computing device can detect data associated with relevant events, determine information related to the event that should be communicated and a target aerial vehicle for that information, identify one or more operational parameters of the target aerial vehicle, and, based on those operational parameters, select a language associated with the target aerial vehicle, and generate and transmit a message expressing that information in the selected language to the target aerial vehicle. In a further aspect, a computing device can detect data associated with relevant events, determine information related to the event that should be communicated and a target recipient for that information, identify one or more operational parameters of the target recipient, and, based on those operational parameters, select a language associated with those operational parameters, and generate and transmit a message expressing that information in the selected language to the target recipient."
Air traffic communication,https://lens.org/039-620-919-233-460,2019,"Apparatus and methods related to autonomous aerial communications are included. A computing device can detect data associated with relevant events, determine information related to the event that should be communicated and a target aerial vehicle for that information, identify one or more operational parameters of the target aerial vehicle, and, based on those operational parameters, select a language associated with the target aerial vehicle, and generate and transmit a message expressing that information in the selected language to the target aerial vehicle. In a further aspect, a computing device can detect data associated with relevant events, determine information related to the event that should be communicated and a target recipient for that information, identify one or more operational parameters of the target recipient, and, based on those operational parameters, select a language associated with those operational parameters, and generate and transmit a message expressing that information in the selected language to the target recipient."
LARGE PAYLOAD UNMANNED AERIAL VEHICLE,https://lens.org/050-061-525-612-353,2019,An unmanned aerial vehicle (UAV) is provided for the lifting and carrying payloads of up to 100 kg. The UAV can include a pair of counter-rotating propellers enclosed in a cage with attitude control motors for providing directional thrust mounted on the top of the cage. One or more motors can rotate the propellers via co-axially concentric vertical output shafts. The motor can include an internal combustion motor or an electric motor.
ROBOT SYSTEM,https://lens.org/024-471-368-093-527,2018,"A robot system for performing drive control of a robot arm with respect to a target object according to information obtained by a camera, including a robot having a working section, a camera mounted in the vicinity of the working section, and a control device for controlling the driving of the robot while confirming the target object based on image data of the camera, is provided. The control device performs image-capture control, which executes image-capturing of the target object with the camera a plurality of times when moving the working section with respect to the target object according to a predetermined trajectory, and focus control, in which predetermined images within a plurality of images captured by image-capture control are in focus."
UAV launching from moving platform,https://lens.org/028-147-692-757-197,2015,"A system for launching an unmanned aerial vehicle (UAV) from a moving platform, the system including: a platform configured to carry the UAV; one or more sensors configured to measure forces acting between the platform and the UAV in one or more directions; a mooring mechanism configured to moor the UAV to the platform; and a controller configured to: transmit at least one trimming command to the UAV based on measurements of the one or more sensors, and cause the mooring mechanism to release the UAV from the platform following the transmitting of the at least one trimming command, when the measurements of the one or more sensors indicate that a lift force is sufficiently close to a weight of the UAV."
MULTIFUNCTIONAL MOTORIZED BOX AND LANDING PAD FOR AUTOMATIC DRONE PACKAGE DELIVERY,https://lens.org/112-561-516-663-237,2020,"A multifunctional motorized box and landing pad for automatic drone package delivery using an unmanned aircraft vehicle which comprises a box housing defining an enclosure and having a top edge; retractable flaps configurable between a closed configuration and an open configuration; and a motorized mechanism configured to move the retractable flaps between the closed configuration and the open configuration. Each one of the retractable flaps is connected to the box housing at the top edge thereof. In the closed configuration, the retractable flaps define a protective cover closing the enclosure of the box housing, with a landing pad surface of each one of the retractable flaps facing inwardly towards the enclosure. In the open configuration, the retractable flaps define a landing pad for the unmanned aircraft vehicle, with the landing pad surface of each one of the retractable flaps facing outwardly for receiving the unmanned aircraft vehicle thereon."
REMOTELY CONTROLLED MULTIROTOR AIRCRAFT CONTROLLED BY HUMAN VOICE,https://lens.org/102-406-533-721-766,2019,The invention relates to a multi-rotor remote control aircraft for capturing audio and/or video signals and a method for remote controlling said aircraft by means of voice commands. In particular it concerns the mitigation of the effects of the audio noise produced by motors and propellers on reception and detection of the voice commands. Audio acquisition means are provided for receiving the voice commands while noise acquisition means are devoted for capturing the environmental noise. The mitigation of the noise effects is achieved by filtering means and a cancellation technique. With the cancellation technique the noise part contained in the signal captured by the noise acquisition means is equalized to the noise part contained in an audio signal carrying the voice commands and then it is subtracted from said audio signal.
AERIAL DEVICE THAT COOPERATES WITH AN EXTERNAL PROJECTOR TO MEASURE THREE-DIMENSIONAL COORDINATES,https://lens.org/027-416-132-004-812,2017,"A three-dimensional (3D) coordinate measuring system includes an external projector that projects a pattern of light onto an object and an aerial drone attached to a 3D imaging device, the 3D imaging device and the external projector cooperating to obtain 3D coordinates of the object."
Aerial device that cooperates with an external projector to measure three-dimensional coordinates,https://lens.org/064-501-023-961-283,2018,"A three-dimensional (3D) coordinate measuring system includes an external projector that projects a pattern of light onto an object and an aerial drone attached to a 3D imaging device, the 3D imaging device and the external projector cooperating to obtain 3D coordinates of the object."
AERIAL DEVICE THAT COOPERATES WITH AN EXTERNAL PROJECTOR TO MEASURE THREE-DIMENSIONAL COORDINATES,https://lens.org/147-692-598-096-060,2017,"A three-dimensional (3D) coordinate measuring system includes an external projector that projects a pattern of light onto an object and an aerial drone attached to a 3D imaging device, the 3D imaging device and the external projector cooperating to obtain 3D coordinates of the object."
METHODS AND SYSTEMS FOR REMOTE OPERATION OF VEHICLES USING HANDS-FREE FUNCTIONALITY,https://lens.org/018-703-636-814-910,2021,"Methods and systems are provided for autonomously enabling remote operation of a vehicle such as an aircraft in response to detecting an event that may impact manual operation of the vehicle. One method autonomously detects an event with respect to manual operation of the vehicle based at least in part on output from one or more systems onboard the vehicle, identifies a hands-free functionality of a vehicle system to be activated based at least in part on a characteristic of the event, and autonomously initiates activation of the hands-free functionality of the vehicle system. A command for operating the vehicle is received from an external system via an onboard communications system and provided to the vehicle system for further implementation or execution using the hands-free functionality."
System and method for analyzing drone flight risk,https://lens.org/032-501-100-705-582,2018,"A system and method of analyzing the risk of operating a drone comprises a mobile device which determines a location of a user by accessing a location tracking system, such as GPS. The location is transmitted to a server to obtain geospatial data and temporal data for a surrounding area of the location. A risk of operating a drone for a duration of time in a given coverage area within the surrounding area using at least the geospatial data and temporal data in calculated and a quote for an insurance policy is generated. The purchase of the insurance policy is facilitated and a timer is generated indicating the remaining the policy is active for. The mobile device may monitor its location and generate a warning in the event of determining that the location is outside the given coverage area."
DEVICE FOR AUTONOMOUS TRACKING,https://lens.org/145-391-348-010-437,2022,"An autonomous tracking device, including a base, a body, the body rotatably mounted to the base, and a stand rotatably mounted to the body. The stand including a retention device configured to hold a mobile device, wherein the stand is configured to support the mobile device using the retention device. The device further including a panning motor configured to rotate the body with respect to the base. The device further comprising a camera configured to capture a scene within a field of view and create a digitized image. The device further comprising a controller containing circuitry configured to receive an object location communication as a function of the digitized image, generate a panning motor control signal, and send a panning motor control signal, wherein the panning motor control signal causes the panning motor to rotate the body such that the object remains in view of the camera."
Methods and apparatuses for detecting and neutralizing remotely activated explosives,https://lens.org/000-251-056-240-377,2012,"A system and apparatus for detecting and neutralizing remotely activated explosive devices in a combat zone, especially one of relatively limited geographic area such as an urban setting. The apparatus is configured for mounting on or within an airborne drone and includes both transmitting and receiving circuits and antennas. The apparatus detects radio transmissions by analyzing received signals using standard RF direction finding techniques and a spectrum analyzer or other signal processing circuitry. Signals may be classified as threats using predetermined criteria, and the direction of threat signals may be assessed to allow for a determination of an enemy position from which an explosive is to be detonated. The apparatus also transmits a jamming signal which may serve to detonate devices within the dynamic RF footprint of the transmitting antenna. The drone also includes a highly directional low frequency audio device which is periodically directed randomly and at suspected enemy positions."
Methods and apparatuses for detecting and neutralizing remotely activated explosives,https://lens.org/082-114-996-383-881,2010,"A system and apparatus for detecting and neutralizing remotely activated explosive devices in a combat zone, especially one of relatively limited geographic area such as an urban setting. The apparatus is configured for mounting on or within an airborne drone and includes both transmitting and receiving circuits and antennas. The apparatus detects radio transmissions by analyzing received signals using standard RF direction finding techniques and a spectrum analyzer or other signal processing circuitry. Signals may be classified as threats using predetermined criteria, and the direction of threat signals may be assessed to allow for a determination of an enemy position from which an explosive is to be detonated. The apparatus also transmits a jamming signal which may serve to detonate devices within the dynamic RF footprint of the transmitting antenna. The drone also includes a highly directional low frequency audio device which is periodically directed randomly and at suspected enemy positions."
METHODS AND APPARATUSES FOR DETECTING AND NEUTRALIZING REMOTELY ACTIVATED EXPLOSIVES,https://lens.org/138-002-620-281-960,2009,"A system and apparatus for detecting and neutralizing remotely activated explosive devices in a combat zone, especially one of relatively limited geographic area such as an urban setting. The apparatus is configured for mounting on or within an airborne drone and includes both transmitting and receiving circuits and antennas. The apparatus detects radio transmissions by analyzing received signals using standard RF direction finding techniques and a spectrum analyzer or other signal processing circuitry. Signals may be classified as threats using predetermined criteria, and the direction of threat signals may be assessed to allow for a determination of an enemy position from which an explosive is to be detonated. The apparatus also transmits a jamming signal which may serve to detonate devices within the dynamic RF footprint of the transmitting antenna. The drone also includes a highly directional low frequency audio device which is periodically directed randomly and at suspected enemy positions."
REMOTE PILOTING APPARATUS,https://lens.org/089-978-974-032-717,2020,"An apparatus for piloting a remote controlled vehicle comprising a frame for supporting a user, right and left hand mechanical controllers coupled to the frame, a position sensor and sensor conditioner to receive an electrical positioning signal from the position sensor, and a transmitter for transmitting a control signal to a remote controlled vehicle. The control system can remotely adjust at least one propulsion mechanism or control surface on the remote controlled vehicle for piloting the vehicle."
UNMANNED AERIAL VEHICLE SYSTEM AND COMMUNICATION METHOD,https://lens.org/161-673-811-940-675,2020,"An unmanned aerial vehicle includes a first communication unit to communicate via a private communication protocol, a second communication unit to communicate with a standard communication protocol, and a controller unit to control the first communication unit and the second communication unit, wherein one of the first communication unit and the second communication unit is to communicate with a second unmanned aerial vehicle, and the other one of the first communication unit and the second communication unit is to communicate with a first remote controller."
Remote control powered parafoil aircraft,https://lens.org/131-007-052-876-197,2002,"A remote-control powered parafoil aircraft has an aircraft body (1) that is engine powered and hung with lines (2) from an air-expandable wing (3, 30). The lines include control lines (15) with which air flow and aerodynamic shape of the air-expandable wing are variable selectively from a foil controller (18, 19, 20) on the aircraft body for flight-mode control. Sight from a television camera (8) on the aircraft body is televised to a control unit (9) from which control data is transmitted selectively from proximate the control unit to the foil controller (14) with a multi-axis joystick or similar control, to an engine (6) on the parafoil body from an engine controller (24) and to an item servo (29) for control of optional items (45) on the aircraft body."
DETACHABLE DRONE GUIDE FOR VEHICLE,https://lens.org/088-602-522-860-093,2020,"The disclosure provides detachable aerial unmanned vehicle (UAV) drone for a vehicle. The drone may include one or more sensors configured to scan terrain surrounding the vehicle. The vehicle may include a navigation display configured to display a topographical map generated the UAV drone. The vehicle may receive via the navigation display, an indication of a location for the UAV and transmit, to the UAV, a command including the location. The UAV drone may scan, via one or more sensors located on the detachable drone, terrain surrounding the vehicle. The UAV drone may generate a topographical map based on the scanned terrain. The UAV drone and/or the vehicle may determine a navigable route for the vehicle based on the topographical map."
SENSE AND AVOID MANEUVERING,https://lens.org/163-230-367-074-853,2018,Systems and methods for navigating an unmanned aerial vehicle are provided. The method includes detecting a possible obstacle. The method includes determining a predicted path for the possible obstacle. The method includes determining that the possible obstacle will cause a collision with the unmanned aerial vehicle based on the predicted path. The method includes determining when the possible obstacle is cooperative. The method includes controlling the unmanned aerial vehicle to perform an avoidance maneuver when the possible obstacle is not cooperative. The method includes determining whether to initiate communications with the possible obstacle when the possible obstacle is cooperative.
LARGE PAYLOAD UNMANNED AERIAL VEHICLE,https://lens.org/121-697-056-595-825,2020,"An unmanned aerial vehicle (""UAV"") is provided for the lifting and carrying payloads of up to 100 kg. The UAV can include a pair of counter-rotating propellers enclosed in a cage with attitude control motors for providing directional thrust mounted on the top of the cage. One or more motors can rotate the propellers via co-axially concentric vertical output shafts. The motor can include an internal combustion motor or an electric motor."
LARGE PAYLOAD UNMANNED AERIAL VEHICLE,https://lens.org/125-214-706-375-40X,2018,"An unmanned aerial vehicle (""UAV"") is provided for the lifting and carrying payloads of up to 100 kg. The UAV can include a pair of counter-rotating propellers enclosed in a cage with attitude control motors for providing directional thrust mounted on the top of the cage. One or more motors can rotate the propellers via co-axially concentric vertical output shafts. The motor can include an internal combustion motor or an electric motor."
Control of image triggering for aerial image capturing in nadir alignment for an unmanned aircraft,https://lens.org/041-534-718-063-937,2015,"The invention relates to control of image triggering for aerial image capturing in nadir alignment for an unmanned aircraft. A method for aerial image capturing by means of an unmanned and controllable aircraft comprising a camera, more particularly a drone, during a flight manoeuvre of said aircraft, comprises continual determining of a camera position and alignment of an optical camera axis and acquiring of a series of aerial images. For each aerial image (21a-b) of said aerial image series, the capturing of the respective aerial image (21a-b) is triggered by flying through a respective image trigger region (33) with said aircraft, wherein the location of said respective image trigger region (33) is determined at least in each case by one trigger position assigned to said respective image trigger region (33) and triggered subject to the alignment of the camera axis when flying through said respective image trigger region (33), with respect to fulfilling a defined, maximum angle deviation relative to a predetermined spatial alignment."
DEVICE AND METHOD FOR MONITORING ACTIVITY PERFORMANCE,https://lens.org/054-648-098-225-217,2020,"A control device operates a drone with an onboard camera. The control device obtains a current performance metric to be computed for an activity performed by an individual, determines, based on a positioning rule associated with the current performance metric, a selected relative position, SRP, between the individual and the onboard camera, identifies a reference plane of the individual, operates the drone to move the onboard camera from an initial relative position to attain the SRP in relation to the reference plane; operates the onboard camera, when in the SRP, to capture image(s) of the individual, and provides the image(s) for computation of the current performance metric for the activity performed by the individual. The SRP may be defined, by the positioning rule, to ensure that the orientation of the individual in the image(s) is relevant or optimal for the current performance metric."
Device and method for monitoring activity performance,https://lens.org/039-867-668-646-272,2022,"A control device operates a drone with an onboard camera. The control device obtains a current performance metric to be computed for an activity performed by an individual, determines, based on a positioning rule associated with the current performance metric, a selected relative position, SRP, between the individual and the onboard camera, identifies a reference plane of the individual, operates the drone to move the onboard camera from an initial relative position to attain the SRP in relation to the reference plane; operates the onboard camera, when in the SRP, to capture image(s) of the individual, and provides the image(s) for computation of the current performance metric for the activity performed by the individual. The SRP may be defined, by the positioning rule, to ensure that the orientation of the individual in the image(s) is relevant or optimal for the current performance metric."
Device and method for monitoring activity performance,https://lens.org/039-867-668-646-272,2022,"A control device operates a drone with an onboard camera. The control device obtains a current performance metric to be computed for an activity performed by an individual, determines, based on a positioning rule associated with the current performance metric, a selected relative position, SRP, between the individual and the onboard camera, identifies a reference plane of the individual, operates the drone to move the onboard camera from an initial relative position to attain the SRP in relation to the reference plane; operates the onboard camera, when in the SRP, to capture image(s) of the individual, and provides the image(s) for computation of the current performance metric for the activity performed by the individual. The SRP may be defined, by the positioning rule, to ensure that the orientation of the individual in the image(s) is relevant or optimal for the current performance metric."
AUTONOMOUS ROOFING REMOVAL MACHINE,https://lens.org/010-680-160-458-745,2017,An autonomous guided roofing material removal machine is provided.
Autonomous roofing removal machine,https://lens.org/160-158-464-115-28X,2018,An autonomous guided roofing material removal machine is provided.
A SYSTEM AND METHOD FOR MANAGING AND ANALYZING MULTIMEDIA INFORMATION,https://lens.org/104-760-749-422-022,2022,"An unmanned aerial vehicle (UAV) management system comprising: an origin content delivery network configured to receive at least one data stream from an encoder/broadcaster, and to deliver the at least one data stream to at least one user device; and at least one user device having a display, each said at least one user device being operated by a respective user and configured to receive the at least one data stream from the origin content delivery network, to display a map on the display and allow identification of a bookmarked area of the map by the user, wherein the origin content delivery network is configured to automatically provide alerts to the at least one user device regarding the bookmarked area."
A SYSTEM AND METHOD FOR MANAGING AND ANALYZING MULTIMEDIA INFORMATION,https://lens.org/104-760-749-422-022,2022,"An unmanned aerial vehicle (UAV) management system comprising: an origin content delivery network configured to receive at least one data stream from an encoder/broadcaster, and to deliver the at least one data stream to at least one user device; and at least one user device having a display, each said at least one user device being operated by a respective user and configured to receive the at least one data stream from the origin content delivery network, to display a map on the display and allow identification of a bookmarked area of the map by the user, wherein the origin content delivery network is configured to automatically provide alerts to the at least one user device regarding the bookmarked area."
METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE TO FOLLOW FACE ROTATION AND DEVICE THEREOF,https://lens.org/093-713-142-825-096,2017,"A method and a device for controlling an unmanned aerial vehicle (UAV) to follow face rotation are provided. The UAV is provided with a camera, the method includes: detecting a face in an image based on the Viola-Jones face detection framework; tracking the face and determining two-dimensional position of the facial feature on the face in pixel coordinates; obtaining three-dimensional position of the facial feature in world coordinates by looking up a standard three-dimensional face database; obtaining the three-dimensional position, in camera-centered coordinates, of the face on the UAV based on the two-dimensional position of the facial feature in the pixel coordinates and the three-dimensional position of the facial feature in world coordinates; and controlling, based on the three-dimensional position, in camera-centered coordinates, of the face on the UAV, the UAV to adjust its position to make the camera is aligned to the face."
MOTION CONTROL APPARATUS OF ACTION ROBOT AND MOTION GENERATION AND CONTROL SYSTEM INCLUDING THE SAME,https://lens.org/176-444-000-740-990,2020,"Disclosed herein is a motion control apparatus of an action robot including an audio playback controller configured to process sound data and control output of a speaker to play back sound corresponding to the sound data based on a result of processing, and a processor configured to acquire motion data corresponding to music, generate a motion control command based on the acquired motion data, and convert the generated motion control command according to a protocol corresponding to an action robot to be controlled."
MOTION CONTROL APPARATUS OF ACTION ROBOT AND MOTION GENERATION AND CONTROL SYSTEM INCLUDING THE SAME,https://lens.org/176-444-000-740-990,2020,"Disclosed herein is a motion control apparatus of an action robot including an audio playback controller configured to process sound data and control output of a speaker to play back sound corresponding to the sound data based on a result of processing, and a processor configured to acquire motion data corresponding to music, generate a motion control command based on the acquired motion data, and convert the generated motion control command according to a protocol corresponding to an action robot to be controlled."
SYSTEM AND METHOD FOR AUTOMATED AERIAL SYSTEM OPERATION,https://lens.org/081-002-140-175-281,2018,"A method for controlling an aerial system with a rotor enclosed by a housing, including: operating the rotor in a flight mode, detecting a grab event indicative of the aerial system being grabbed, and automatically operating the rotor in a standby mode. A method for controlling an aerial system including a central axis extending normal to a lateral plane of the aerial system, including: generating a first aerodynamic force with a set of rotors enclosed by a housing, detecting that an acute angle between the central axis and a gravity vector is greater than a threshold angle, and operating each rotor of the set of rotors to cooperatively generate a second aerodynamic force less than the first aerodynamic force with the set of rotors."
System and method for automated aerial system operation,https://lens.org/034-082-324-258-629,2020,"A method for controlling an aerial system with a rotor enclosed by a housing, including: operating the rotor in a flight mode, detecting a grab event indicative of the aerial system being grabbed, and automatically operating the rotor in a standby mode. A method for controlling an aerial system including a central axis extending normal to a lateral plane of the aerial system, including: generating a first aerodynamic force with a set of rotors enclosed by a housing, detecting that an acute angle between the central axis and a gravity vector is greater than a threshold angle, and operating each rotor of the set of rotors to cooperatively generate a second aerodynamic force less than the first aerodynamic force with the set of rotors."
SYSTEM AND METHOD FOR AUTOMATED AERIAL SYSTEM OPERATION,https://lens.org/059-623-803-453-970,2017,"A method for controlling an aerial system with a rotor enclosed by a housing, including: operating the rotor in a flight mode, detecting a grab event indicative of the aerial system being grabbed, and automatically operating the rotor in a standby mode. A method for controlling an aerial system including a central axis extending normal to a lateral plane of the aerial system, including: generating a first aerodynamic force with a set of rotors enclosed by a housing, detecting that an acute angle between the central axis and a gravity vector is greater than a threshold angle, and operating each rotor of the set of rotors to cooperatively generate a second aerodynamic force less than the first aerodynamic force with the set of rotors."
SYSTEM AND METHOD FOR AUTOMATED AERIAL SYSTEM OPERATION,https://lens.org/153-803-375-261-678,2020,"A method for controlling an aerial system with a rotor enclosed by a housing, including: operating the rotor in a flight mode, detecting a grab event indicative of the aerial system being grabbed, and automatically operating the rotor in a standby mode. A method for controlling an aerial system including a central axis extending normal to a lateral plane of the aerial system, including: generating a first aerodynamic force with a set of rotors enclosed by a housing, detecting that an acute angle between the central axis and a gravity vector is greater than a threshold angle, and operating each rotor of the set of rotors to cooperatively generate a second aerodynamic force less than the first aerodynamic force with the set of rotors."
SYSTEM AND METHOD FOR AUTOMATED AERIAL SYSTEM OPERATION,https://lens.org/175-878-142-823-187,2017,"A method for controlling an aerial system with a rotor enclosed by a housing, including: operating the rotor in a flight mode, detecting a grab event indicative of the aerial system being grabbed, and automatically operating the rotor in a standby mode. A method for controlling an aerial system including a central axis extending normal to a lateral plane of the aerial system, including: generating a first aerodynamic force with a set of rotors enclosed by a housing, detecting that an acute angle between the central axis and a gravity vector is greater than a threshold angle, and operating each rotor of the set of rotors to cooperatively generate a second aerodynamic force less than the first aerodynamic force with the set of rotors."
AN UNMANNED AUTONOMOUS VEHICLE AND METHOD FOR CONTROLLING THE SAME,https://lens.org/179-966-395-342-547,2023,"An unmanned autonomous vehicle is provided and includes at least one propulsion device, at least one image capture device, at least one adjusting member to adjust an tilt angle of the image capture device and is configured to receive, from a control device, a capturing instruction to capture at least one image, acquire angle information indicating a tilt angle of the image capture device, and control, in a case where the capturing instruction is received, the propulsion device so that the image capture device captures at least one image at an altitude which is determined based on the acquired angle information."
Device management,https://lens.org/107-983-359-716-33X,2020,"A method of operating a device in the form of an autonomous vehicle (AV) 110-1 which is configured to communicate with a wireless telecommunications network 140. The AV may comprise a UAV carrying a payload 120. The method comprises detecting a fault associated with the AV and in response to detecting said fault, causing the AV to transmit a mayday wireless network communication 135 for alerting the wireless telecommunications network of the fault. The mayday wireless network communication is in the form of a system information message. The fault may relate to a battery 130 of the AV and this may result in a recovery AV 110-2 being dispatched to retrieve the payload 120."
Robot having an imaging capability,https://lens.org/008-489-926-212-048,2007,"A robot having an imaging capability includes: an imaging device, and at least one actuator separate from the imaging device for moving at least a portion of the robot. The at least one actuator is controllable in response to a control command, the imaging device being responsive to the control command to modify characteristics of image data produced."
Robot having an imaging capability,https://lens.org/034-184-074-733-913,2004,"A robot having an imaging capability includes: an imaging device, and at least one actuator separate from the imaging device for moving at least a portion of the robot. The at least one actuator is controllable in response to a control command, the imaging device being responsive to the control command to modify characteristics of image data produced."
DRONE-BASED TRACKING,https://lens.org/069-279-222-872-205,2018,A computer is programmed to determine a trajectory of a moving target based on data from one or more vehicle sensors. The computer is programmed to deploy an aerial drone from the vehicle to track the moving target based on the determined trajectory.
DRONE-BASED TRACKING,https://lens.org/108-813-031-434-237,2020,A computer is programmed to determine a trajectory of a moving target based on data from one or more vehicle sensors. The computer is programmed to deploy an aerial drone from the vehicle to track the moving target based on the determined trajectory.
Drone-based tracking,https://lens.org/012-074-047-207-664,2022,A computer is programmed to determine a trajectory of a moving target based on data from one or more vehicle sensors. The computer is programmed to deploy an aerial drone from the vehicle to track the moving target based on the determined trajectory.
Drone-based tracking,https://lens.org/012-074-047-207-664,2022,A computer is programmed to determine a trajectory of a moving target based on data from one or more vehicle sensors. The computer is programmed to deploy an aerial drone from the vehicle to track the moving target based on the determined trajectory.
Unmanned aerial vehicle updater,https://lens.org/070-703-848-354-827,2022,"Various arrangements for updating a device utilizing an unmanned aerial vehicle (UAV) are presented. A backend system may detect a triggering event associated with a device based upon data received via a first connection. In response to detecting the first triggering event, the UAV may receive a first data set and a location associated with the device from the backend system. The UAV may deploy to the received location. A second connection between the UAV and the device can be established at the received location. The UAV may transmit the first data set to the device via the second connection at the received location."
UNMANNED AERIAL VEHICLE UPDATER,https://lens.org/150-894-945-418-268,2021,"Various arrangements for updating a device utilizing an unmanned aerial vehicle (UAV) are presented. A backend system may detect a triggering event associated with a device based upon data received via a first connection. In response to detecting the first triggering event, the UAV may receive a first data set and a location associated with the device from the backend system. The UAV may deploy to the received location. A second connection between the UAV and the device can be established at the received location. The UAV may transmit the first data set to the device via the second connection at the received location."
Autonomous vehicle operated with safety augmentation,https://lens.org/053-428-258-466-087,2021,"An autonomous vehicle is operable to follow a primary trajectory that forms a portion of a route. While controlling the autonomous vehicle, the autonomous vehicle calculates a failsafe trajectory to follow as a response to a predetermined type of event."
AUTONOMOUS VEHICLE OPERATED WITH SAFETY AUGMENTATION,https://lens.org/128-524-837-708-49X,2019,"An autonomous vehicle is operable to follow a primary trajectory that forms a portion of a route. While controlling the autonomous vehicle, the autonomous vehicle calculates a failsafe trajectory to follow as a response to a predetermined type of event."
AUTONOMOUS VEHICLE OPERATED WITH SAFETY AUGMENTATION,https://lens.org/164-862-940-465-550,2017,"An autonomous vehicle is operable to follow a primary trajectory that forms a portion of a route. While controlling the autonomous vehicle, the autonomous vehicle calculates a failsafe trajectory to follow as a response to a predetermined type of event."
Autonomous vehicle operated with safety augmentation,https://lens.org/075-857-780-677-331,2018,"An autonomous vehicle is operable to follow a primary trajectory that forms a portion of a route. While controlling the autonomous vehicle, the autonomous vehicle calculates a failsafe trajectory to follow as a response to a predetermined type of event."
Autonomous Vehicle Operated with Safety Augmentation,https://lens.org/131-006-381-454-222,2021,"An autonomous vehicle is operable to follow a primary trajectory that forms a portion of a route. While controlling the autonomous vehicle, the autonomous vehicle calculates a failsafe trajectory to follow as a response to a predetermined type of event."
Drone for industrial activities,https://lens.org/003-432-538-076-348,2022,"An industrial activity drone comprising an aerial vehicle having at least one rotor, an activity system, and a fastener device for fastening the activity system to the aerial vehicle. The activity system includes a structure, a computer, a work camera that is stationary relative to the aerial vehicle and that provides a view of a work zone, a distribution device having a plurality of compartments, and a turning motor enabling the distribution device to turn relative to the aerial vehicle. The industrial activity drone performs hovering flight so that the work camera faces a work zone and the distribution device is turned so that the compartment that is to be used faces the work zone, thereby performing one or more tasks."
DRONE FOR INDUSTRIAL ACTIVITIES,https://lens.org/042-694-811-208-001,2020,"An industrial activity drone comprising an aerial vehicle having at least one rotor, an activity system, and a fastener device for fastening the activity system to the aerial vehicle. The activity system includes a structure, a computer, a work camera that is stationary relative to the aerial vehicle and that provides a view of a work zone, a distribution device having a plurality of compartments, and a turning motor enabling the distribution device to turn relative to the aerial vehicle. The industrial activity drone performs hovering flight so that the work camera faces a work zone and the distribution device is turned so that the compartment that is to be used faces the work zone, thereby performing one or more tasks."
AUTONOMOUS AERIAL VEHICLE FOR LIGHTING INSPECTION AND REPLACEMENT AND METHODS FOR USE THEREWITH,https://lens.org/036-244-780-770-409,2020,"An autonomous aerial vehicle (AAV) includes a plurality of lightbulb changers and an actuator for controlling the plurality of lightbulb changers. A structure database stores structure data corresponding to a structure, the structure data including coordinate data corresponding to three-dimensional coordinates of a location that facilitates an unobstructed view of a plurality of exterior lights of the structure, the structure data further including schematic data that indicates positions on the structure of the plurality of exterior lights. A flight control system controls a position of the AAV, based on the coordinate data, to the location that facilitates the unobstructed view of the plurality of exterior lights of the structure. A camera captures image data corresponding to the unobstructed view of the plurality of exterior lights of the structure. A processor controls the AAV to perform a lighting inspection procedure and/or a lightbulb replacement process."
Autonomous aerial vehicle for lighting inspection and replacement and methods for use therewith,https://lens.org/137-487-485-207-216,2020,"An autonomous aerial vehicle (AAV) includes a plurality of lightbulb changers and an actuator for controlling the plurality of lightbulb changers. A structure database stores structure data corresponding to a structure, the structure data including coordinate data corresponding to three-dimensional coordinates of a location that facilitates an unobstructed view of a plurality of exterior lights of the structure, the structure data further including schematic data that indicates positions on the structure of the plurality of exterior lights. A flight control system controls a position of the AAV, based on the coordinate data, to the location that facilitates the unobstructed view of the plurality of exterior lights of the structure. A camera captures image data corresponding to the unobstructed view of the plurality of exterior lights of the structure. A processor controls the AAV to perform a lighting inspection procedure and/or a lightbulb replacement process."
AUTONOMOUS AERIAL VEHICLE FOR LIGHTING INSPECTION AND REPLACEMENT AND METHODS FOR USE THEREWITH,https://lens.org/036-428-916-918-772,2020,"An autonomous aerial vehicle (AAV) includes a plurality of lightbulb changers and an actuator for controlling the plurality of lightbulb changers. A structure database stores structure data corresponding to a structure, the structure data including coordinate data corresponding to three-dimensional coordinates of a location that facilitates an unobstructed view of a plurality of exterior lights of the structure, the structure data further including schematic data that indicates positions on the structure of the plurality of exterior lights. A flight control system controls a position of the AAV, based on the coordinate data, to the location that facilitates the unobstructed view of the plurality of exterior lights of the structure. A camera captures image data corresponding to the unobstructed view of the plurality of exterior lights of the structure. A processor controls the AAV to perform a lighting inspection procedure and/or a lightbulb replacement process."
Autonomous aerial vehicle for lighting inspection and replacement and methods for use therewith,https://lens.org/089-604-431-369-720,2020,"An autonomous aerial vehicle (AAV) includes a plurality of lightbulb changers and an actuator for controlling the plurality of lightbulb changers. A structure database stores structure data corresponding to a structure, the structure data including coordinate data corresponding to three-dimensional coordinates of a location that facilitates an unobstructed view of a plurality of exterior lights of the structure, the structure data further including schematic data that indicates positions on the structure of the plurality of exterior lights. A flight control system controls a position of the AAV, based on the coordinate data, to the location that facilitates the unobstructed view of the plurality of exterior lights of the structure. A camera captures image data corresponding to the unobstructed view of the plurality of exterior lights of the structure. A processor controls the AAV to perform a lighting inspection procedure and/or a lightbulb replacement process."
Commanding A Mobile Robot Using Glyphs,https://lens.org/057-139-917-044-078,2015,"A method of operating a robot includes receiving image data from an image capture device of the robot. The image data is representative of a glyph viewed by the image capture device on the display of a computing device within a field of view of the image capture device. The method further includes determining, at a controller, a command message based on the glyph represented in the image data and issuing a command to at least one resource or component of the robot based on the command message."
Autonomous vehicle security,https://lens.org/047-932-559-468-284,2018,"Various implementations include unmanned autonomous vehicles (UAVs) and methods for providing security for a UAV. In various implementations, a processor of the UAV may receive sensor data from a plurality of UAV sensors about an object in contact with the UAV. The processor may determine an authorization threshold based on the received sensor data. The processor may determine whether the object is authorized based on the received sensor data and the determined authorization threshold."
AUTONOMOUS VEHICLE SECURITY,https://lens.org/155-548-415-399-418,2018,"Various implementations include unmanned autonomous vehicles (UAVs) and methods for providing security for a UAV. In various implementations, a processor of the UAV may receive sensor data from a plurality of UAV sensors about an object in contact with the UAV. The processor may determine an authorization threshold based on the received sensor data. The processor may determine whether the object is authorized based on the received sensor data and the determined authorization threshold."
AUTONOMOUS VEHICLE SECURITY,https://lens.org/126-665-739-737-701,2018,"Various implementations include unmanned autonomous vehicles (UAVs) and methods for providing security for a UAV. In various implementations, a processor of the UAV may receive sensor data from a plurality of UAV sensors about an object in contact with the UAV. The processor may determine an authorization threshold based on the received sensor data. The processor may determine whether the object is authorized based on the received sensor data and the determined authorization threshold."
Autonomous Vehicle Security,https://lens.org/096-178-422-229-552,2018,"Various implementations include unmanned autonomous vehicles (UAVs) and methods for providing security for a UAV. In various implementations, a processor of the UAV may receive sensor data from a plurality of UAV sensors about an object in contact with the UAV. The processor may determine an authorization threshold based on the received sensor data. The processor may determine whether the object is authorized based on the received sensor data and the determined authorization threshold."
"SYSTEMS, METHODS AND APPARATUS FOR INTERACTING WITH A SECURITY SYSTEM USING A TELEVISION REMOTE CONTROL",https://lens.org/072-068-044-778-715,2019,"A method and apparatus is described for interacting with a security system using a television remote control. Commands sent by the remote control are received by an auxiliary interface device, which then provides the commands to a security system controller either directly, via a local-area network, or via a wide-area network and server. Status and acknowledgement messages are transmitted from the security system controller to the auxiliary device, whereupon they are provided to and displayed by a television in the form of a security dashboard"
"SYSTEMS, METHODS AND APPARATUS FOR INTERACTING WITH A SECURITY SYSTEM USING A TELEVISION REMOTE CONTROL",https://lens.org/118-360-112-674-551,2021,"A method and apparatus is described for interacting with a security system using a television remote control. Commands sent by the remote control are received by an auxiliary interface device, which then provides the commands to a security system controller either directly, via a local-area network, or via a wide-area network and server. Status and acknowledgement messages are transmitted from the security system controller to the auxiliary device, whereupon they are provided to and displayed by a television in the form of a security dashboard"
Imaging using multiple unmanned aerial vehicles,https://lens.org/052-152-299-149-431,2018,An aerial imaging system and method of aerially capturing an image including a first unmanned aerial vehicle (UAV) and a second UAV. The first UAV includes a camera and may be configured to receive input from an operator. The second UAV may be configured to dock with and deploy from the first UAV. The second UAV includes a light configured to provide remote illumination for the camera. The light on the second UAV may be activated to illuminate a target of photography by the camera while the second UAV is flown separate from the first UAV.
IMAGING USING MULTIPLE UNMANNED AERIAL VEHICLES,https://lens.org/165-218-079-653-261,2017,An aerial imaging system and method of aerially capturing an image including a first unmanned aerial vehicle (UAV) and a second UAV. The first UAV includes a camera and may be configured to receive input from an operator. The second UAV may be configured to dock with and deploy from the first UAV. The second UAV includes a light configured to provide remote illumination for the camera. The light on the second UAV may be activated to illuminate a target of photography by the camera while the second UAV is flown separate from the first UAV.
Wrist type portable accompanying flight autonomous supervision unmanned aerial vehicle,https://lens.org/004-463-082-690-97X,2016,"The invention provides a wrist type portable accompanying flight autonomous supervision unmanned aerial vehicle. A wing arm motor is arranged inside a body and controls a wing arm device to horizontally rotate by virtue of a transmission device; a rotor device is arranged at the end of the wing arm device; a controller is respectively connected with the wing arm motor, a wing propeller motor, an image acquisition device and a power supply device; and the controller comprises a central control module, a communication module, a motor drive module, an image acquisition module, a positioning module, an ultrasonic sensor and a gyro device. The product is simple in structure and high in practicality, the wing arm device can be bent, and the unmanned aerial vehicle can be suspended on the wrist and is convenient to carry; and moreover, the power supply device adopts an induced charging manner, the cruising ability is improved, a video signal returned by the unmanned aerial vehicle can be analyzed by virtue of a handheld operation control terminal, and the related information is transmitted to a guardian of an unmanned aerial vehicle carrying user or the police, so that the relevant party is informed of the information in advance."
REMOTE CONTROLLER AND METHOD FOR CONTROLLING THE SAME,https://lens.org/154-698-430-721-775,2018,"A remote controller is provided, which includes a transmitter, a microphone configured to receive from a display device an audio signal including information on a code set capable of controlling an external device connected to the display device through a predetermined carrier frequency, a signal processor configured to convert the received audio signal, and a microcomputer configured to acquire the code set capable of controlling the external device from a converted signal if the received audio signal is converted into a form that can be processed through the signal processor, and to control the transmitter to transmit a control signal for controlling the external device on the basis of the code set."
Method and apparatus for dynamically determining a destination of a drone,https://lens.org/103-679-701-238-82X,2022,"The destination for a drone is dynamically deteremined. In the context of a method, location-related data may be collected with a drone. After having collected at least some of the location-related data, a destination for the drone is determined based at least in part upon a location of the drone. The drone is then caused to travel from the location to the destination. In some instances, the drone may travel toward the destination by being carried by a vehicle that is traveling along a route toward the destination."
EMERGENCY UNMANNED AERIAL VEHICLE AND METHOD FOR DEPLOYING AN UNMANNED AERIAL VEHICLE,https://lens.org/085-330-267-550-841,2017,"An emergency unmanned aerial vehicle (UAV) and a method for employing a UAV. The method includes storing a digital elevation model (DEM) and associated data including locations of communication networks, updating the locations of communication networks in the associated data via a wireless transceiver, and storing position information determined by a global navigation satellite system (GNSS) receiver. The method includes detecting a predetermined condition using electronic sensors, determining whether the UAV is within a communications range of any communication network via the wireless transceiver, and determining a path to a communication network using the DEM and the associated data. The method also includes causing the UAV to become airborne and fly along the path, and transmitting a distress message via the wireless transceiver to the communication network, the distress message including position information corresponding to a location where the UAV detected the predetermined condition."
Emergency unmanned aerial vehicle and method for deploying an unmanned aerial vehicle,https://lens.org/152-612-706-969-18X,2017,"An emergency unmanned aerial vehicle (UAV) and a method for employing a UAV. The method includes storing a digital elevation model (DEM) and associated data including locations of communication networks, updating the locations of communication networks in the associated data via a wireless transceiver, and storing position information determined by a global navigation satellite system (GNSS) receiver. The method includes detecting a predetermined condition using electronic sensors, determining whether the UAV is within a communications range of any communication network via the wireless transceiver, and determining a path to a communication network using the DEM and the associated data. The method also includes causing the UAV to become airborne and fly along the path, and transmitting a distress message via the wireless transceiver to the communication network, the distress message including position information corresponding to a location where the UAV detected the predetermined condition."
Electronic apparatus and operating method thereof,https://lens.org/146-930-642-945-299,2020,"An unmanned photographing device and method thereof is provided which includes establishing a wireless connection with an external electronic device using a communication device, receiving a first signal at a first three-dimensional (3D) position from the external electronic device through the wireless connection, the first signal comprising data associated with a first image comprising a first object, determining a second 3D position based on at least part of the data and the first 3D position, controlling the unmanned photographing device to fly to or near the second 3D position, tracking a second object corresponding to the first object using a camera, and capturing a second image comprising the second object at or near the second 3D position such that the second image corresponds to the first image."
ELECTRONIC APPARATUS AND OPERATING METHOD THEREOF,https://lens.org/014-029-542-371-98X,2017,"An unmanned photographing device and method thereof is provided which includes establishing a wireless connection with an external electronic device using a communication device, receiving a first signal at a first three-dimensional (3D) position from the external electronic device through the wireless connection, the first signal comprising data associated with a first image comprising a first object, determining a second 3D position based on at least part of the data and the first 3D position, controlling the unmanned photographing device to fly to or near the second 3D position, tracking a second object corresponding to the first object using a camera, and capturing a second image comprising the second object at or near the second 3D position such that the second image corresponds to the first image."
Aerial beneficial insect distribution vehicle,https://lens.org/120-110-889-900-810,2015,"A remotely-piloted aircraft for distributing beneficial insects on a target area is provided. The aircraft includes an enclosure, including a top lid, one or more internal compartments, a door for each of the one or more internal compartments, and an actuator to open and close each of the doors. The aircraft also includes a circuit to control the actuators, a wireless receiver, coupled to the circuit, to receive commands to open and close the doors, and one or more power sources to power the actuators and the wireless receiver. An operator controls the aircraft and the circuit with at least one of a wireless transmitter and an uploaded program in the circuit. When the wireless receiver receives a command to open a door, the circuit controls an actuator corresponding to the door. The actuator opens the door, and the beneficial insects are distributed from internal compartments."
Aerial beneficial insect distribution vehicle,https://lens.org/124-200-183-423-092,2016,"A remotely-piloted aircraft for distributing beneficial insects on a target area is provided. The aircraft includes an enclosure, including a top lid, one or more internal compartments, a door for each of the one or more internal compartments, and an actuator to open and close each of the doors. The aircraft also includes a circuit to control the actuators, a wireless receiver, coupled to the circuit, to receive commands to open and close the doors, and one or more power sources to power the actuators and the wireless receiver. An operator controls the aircraft and the circuit with at least one of a wireless transmitter and an uploaded program in the circuit. When the wireless receiver receives a command to open a door, the circuit controls an actuator corresponding to the door. The actuator opens the door, and the beneficial insects are distributed from internal compartments."
Systems for searching for persons using autonomous vehicles,https://lens.org/051-357-895-814-840,2020,"A system includes an autonomous vehicle that has a camera for capturing an image and a GPS receiver for acquiring positional information and moves according to a specific operation command, and a controller. The controller creates an operation command sent to the autonomous vehicle, detects a human image in the image captured by the camera, and make a determination as to whether or not the human image detected in the image is an image of a searched object."
CONTROL OF IMAGE TRIGGERING FOR AERIAL IMAGE CAPTURING IN NADIR ALIGNMENT FOR AN UNMANNED AIRCRAFT,https://lens.org/124-039-772-164-799,2016,"Method for aerial image capturing by means of an unmanned and controllable aircraft comprising a camera, more particularly a drone, during a flight manoeuvre of said aircraft, comprising continual determining of a camera position and alignment of an optical camera axis and acquiring of a series of aerial images. For each aerial image of said aerial image series, the capturing of the respective aerial image is triggered by flying through a respective image trigger region with said aircraft, wherein the location of said respective image trigger region is determined at least in each case by one trigger position assigned to said respective image trigger region and triggered subject to the alignment of the camera axis when flying through said respective image trigger region, with respect to fulfilling a defined, maximum angle deviation relative to a predetermined spatial alignment."
IMAGE CAPTURE DEVICES FOR AUTONOMOUS MOBILE ROBOTS AND RELATED SYSTEMS AND METHODS,https://lens.org/158-122-489-407-178,2021,"An autonomous cleaning robot includes a drive system to support the autonomous cleaning robot above a floor surface, an image capture device positioned on the autonomous cleaning robot to capture imagery of a portion of the floor surface forward of the autonomous cleaning robot, and a controller operably connected to the drive system and the image capture device. The drive system is operable to maneuver the autonomous cleaning robot about the floor surface. The controller is configured to execute instructions to perform operations including initiating, based on a user-selected sensitivity and the imagery captured by the image capture device, an avoidance behavior to avoid an obstacle on the portion of the floor surface."
IMAGE CAPTURE DEVICES FOR AUTONOMOUS MOBILE ROBOTS AND RELATED SYSTEMS AND METHODS,https://lens.org/024-325-847-398-402,2022,"An autonomous cleaning robot includes a drive system to support the autonomous cleaning robot above a floor surface, an image capture device positioned on the autonomous cleaning robot to capture imagery of a portion of the floor surface forward of the autonomous cleaning robot, and a controller operably connected to the drive system and the image capture device. The drive system is operable to maneuver the autonomous cleaning robot about the floor surface. The controller is configured to execute instructions to perform operations including initiating, based on a user-selected sensitivity and the imagery captured by the image capture device, an avoidance behavior to avoid an obstacle on the portion of the floor surface."
Image capture devices for autonomous mobile robots and related systems and methods,https://lens.org/152-621-482-081-185,2022,"An autonomous cleaning robot includes a drive system to support the autonomous cleaning robot above a floor surface, an image capture device positioned on the autonomous cleaning robot to capture imagery of a portion of the floor surface forward of the autonomous cleaning robot, and a controller operably connected to the drive system and the image capture device. The drive system is operable to maneuver the autonomous cleaning robot about the floor surface. The controller is configured to execute instructions to perform operations including initiating, based on a user-selected sensitivity and the imagery captured by the image capture device, an avoidance behavior to avoid an obstacle on the portion of the floor surface."
IMAGE CAPTURE DEVICES FOR AUTONOMOUS MOBILE ROBOTS AND RELATED SYSTEMS AND METHODS,https://lens.org/024-325-847-398-402,2022,"An autonomous cleaning robot includes a drive system to support the autonomous cleaning robot above a floor surface, an image capture device positioned on the autonomous cleaning robot to capture imagery of a portion of the floor surface forward of the autonomous cleaning robot, and a controller operably connected to the drive system and the image capture device. The drive system is operable to maneuver the autonomous cleaning robot about the floor surface. The controller is configured to execute instructions to perform operations including initiating, based on a user-selected sensitivity and the imagery captured by the image capture device, an avoidance behavior to avoid an obstacle on the portion of the floor surface."
UNMANNED AERIAL VEHICLES WITH MULTIPLE CONFIGURATIONS,https://lens.org/093-339-790-017-305,2019,An unmanned aerial vehicle includes multiple rotor arms; a rotor disposed at an end of each of the multiple rotor arms; and an adjustment component configured to enable a first rotor arm to move relative to a second rotor arm.
Unmanned aerial vehicles with multiple configurations,https://lens.org/061-734-755-002-764,2018,An unmanned aerial vehicle includes multiple rotor arms; a rotor disposed at an end of each of the multiple rotor arms; and an adjustment component configured to enable a first rotor arm to move relative to a second rotor arm.
Aerial devices capable of controlled flight,https://lens.org/150-920-327-758-712,2020,"An aerial device (100) capable of controlled flight has a body (110), a rotor (120) arranged to rotate relative to the body; and a deployable sheet (130), the sheet having an undeployed configuration in which the sheet is folded against the body and a deployed configuration in which the sheet is at least partially unfolded away from the body."
Aerial Devices Capable of Controlled Flight,https://lens.org/134-251-098-865-470,2018,"An aerial device (100) capable of controlled flight has a body (110), a rotor (120) arranged to rotate relative to the body; and a deployable sheet (130), the sheet having an undeployed configuration in which the sheet is folded against the body and a deployed configuration in which the sheet is at least partially unfolded away from the body."
AERIAL DEVICES CAPABLE OF CONTROLLED FLIGHT,https://lens.org/071-931-232-393-896,2016,"An aerial device (100) capable of controlled flight has a body (110), a rotor (120) arranged to rotate relative to the body; and a deployable sheet (130), the sheet having an undeployed configuration in which the sheet is folded against the body and a deployed configuration in which the sheet is at least partially unfolded away from the body."
Vehicle-mounted aerial drone container,https://lens.org/111-710-129-074-678,2022,"A system comprising a computer programmed to identify a connected location of a vehicle at which a user device is connected to a first network and a disconnected location of the vehicle at which the user device is disconnected from the first network. Upon further determining that the user device has not connected to a second network within a first predetermined time, the computer is further programmed to activate an aerial drone container to an open position."
Vehicle-mounted aerial drone container,https://lens.org/111-710-129-074-678,2022,"A system comprising a computer programmed to identify a connected location of a vehicle at which a user device is connected to a first network and a disconnected location of the vehicle at which the user device is disconnected from the first network. Upon further determining that the user device has not connected to a second network within a first predetermined time, the computer is further programmed to activate an aerial drone container to an open position."
VEHICLE-MOUNTED AERIAL DRONE CONTAINER,https://lens.org/109-367-867-504-29X,2021,"A system comprising a computer programmed to identify a connected location of a vehicle at which a user device is connected to a first network and a disconnected location of the vehicle at which the user device is disconnected from the first network. Upon further determining that the user device has not connected to a second network within a first predetermined time, the computer is further programmed to activate an aerial drone container to an open position."
Auxiliary control method and system for unmanned aerial vehicle,https://lens.org/079-440-419-832-224,2020,"An auxiliary control method and an auxiliary control system for an unmanned aerial vehicle (UAV) are provided. The auxiliary control method for the UAV includes steps of: based on a flight attitude and a flight speed of the UAV, predicting a flight path of the UAV in a scheduled time; and providing information about the flight path of the UAV in the scheduled time to an operator of the UAV. The auxiliary control method and system for the UAV provided by the present invention are able to provide the information about the flight path of the UAV in the scheduled time to the operator of the UAV, so as to help the operator of the UAV make a control decision for the UAV."
SYSTEMS AND METHODS FOR DYNAMICALLY MASKING VIDEO AND IMAGES CAPTURED A DRONE DEVICE CAMERA,https://lens.org/067-863-624-262-426,2019,"Systems and methods for dynamically masking video or images captured by a drone device camera are provided. Such systems and methods include flying the drone device proximate to a potential surveillance area while in a learning mode, capturing first video or images of the potential surveillance area, identifying first privacy masking areas in the first video or images, flying the drone device proximate to an active surveillance area while in a standard mode, capturing second video or images of the active surveillance area, identifying second privacy masking areas in the the second video or images, and dynamically masking a portion of the second video or images that contains any of the first privacy masking areas or the second privacy masking"
Remote controlled aerial reconnaissance vehicle,https://lens.org/098-748-153-544-830,2016,"A remotely controlled UAV is disclosed. The UAV includes a parachute, with a cylindrical power and control module suspended vertically below the parachute. In one embodiment, a propulsion source is mounted on top of the power and control module with control lines connected to the module below the propulsion source, and in another embodiment the power and control module is suspended from a point above a propulsion source. The UAV may be flown under a parachute and guided by remote control, or the control module (fuselage) may be released from the parachute and extendable fixed wings deployed to enable the UAV to be flown as a fixed wing vehicle."
Method of controlling an autonomous device,https://lens.org/176-284-896-408-439,2012,"The invention describes a method of controlling an autonomous device (1), which autonomous device records ambient data and optionally transmits the recorded ambient data, which method comprises positioning an indicator (S1, S2, S3, S4) at a boundary (B) between a private area (P) and a non-private area (N) to optically distinguish the private area (P) from the non-private area (N) for a user of the autonomous device (1). The indicator (S1, S2, S3, S4) is detected by the autonomous device (1) and interpreted to determine whether the autonomous device (1) is in a private area (P) or a non-private area (N). Subsequently, recording or transmission of ambient data is restricted while the autonomous device (1) is within the private area (P). The invention also describes a system ( ) for controlling an autonomous device (1), an autonomous device (1), and an indicator (S3, S4) for placement at a boundary between a private area (P) and a non-private area (N), to optically distinguish the private area (P) from the non-private area (N) for a user (2), comprising a number of electronically detectable components (23, 24)."
METHOD OF CONTROLLING AN AUTONOMOUS DEVICE,https://lens.org/047-165-941-035-565,2010,"The invention describes a method of controlling an autonomous device (1), which autonomous device records ambient data and optionally transmits the recorded ambient data, which method comprises positioning an indicator (S1, S2, S3, S4) at a boundary (B) between a private area (P) and a non-private area (N) to optically distinguish the private area (P) from the non-private area (N) for a user of the autonomous device (1). The indicator (S1, S2, S3, S4) is detected by the autonomous device (1) and interpreted to determine whether the autonomous device (1) is in a private area (P) or a non-private area (N). Subsequently, recording or transmission of ambient data is restricted while the autonomous device (1) is within the private area (P). The invention also describes a system ( ) for controlling an autonomous device (1), an autonomous device (1), and an indicator (S3, S4) for placement at a boundary between a private area (P) and a non-private area (N), to optically distinguish the private area (P) from the non-private area (N) for a user (2), comprising a number of electronically detectable components (23, 24)."
FILMING AN EVENT BY AN AUTONOMOUS ROBOTIC SYSTEM,https://lens.org/078-373-978-953-491,2022,"A method for filming an event by an autonomous drone, the method may include acquiring, by the autonomous drone, a current set of images of the event; generating signatures of the current set of images to provide current signatures; searching for one or more relevant concept structures out of a group of concept structures; wherein each relevant concept structure comprises at least one signature that matches at least one of first signatures; wherein each concept structure is associated with filming parameters; and determining, at least in part, based on the filming parameters associated with at least one of the one or more relevant concept structures, next filming parameters to be applied during an acquisition of one or more next sets of images."
FILMING AN EVENT BY AN AUTONOMOUS ROBOTIC SYSTEM,https://lens.org/078-373-978-953-491,2022,"A method for filming an event by an autonomous drone, the method may include acquiring, by the autonomous drone, a current set of images of the event; generating signatures of the current set of images to provide current signatures; searching for one or more relevant concept structures out of a group of concept structures; wherein each relevant concept structure comprises at least one signature that matches at least one of first signatures; wherein each concept structure is associated with filming parameters; and determining, at least in part, based on the filming parameters associated with at least one of the one or more relevant concept structures, next filming parameters to be applied during an acquisition of one or more next sets of images."
Media playback system,https://lens.org/092-145-969-046-614,2023,"A location estimation uses data defining the intended movements of a plurality of drones 104 in three dimensions and images taken by a camera 112 (e.g. of a mobile device 110) to correlate at least part of the image with a two-dimensional projection of the plurality of drones 104, so as to estimate a location from which the image was captured and therefore estimate the location of the camera 112 or mobile phone 110."
Method for controlling camera and electronic device therefor,https://lens.org/105-300-542-922-774,2022,"A method for controlling a camera of an electronic device is provided. The method includes generating a plurality of beams using an antenna array including a plurality of antenna elements and detecting an external object using the plurality of beams, sensing a movement of the external object using a first beam corresponding to the external object among the plurality of beams, identifying a gesture corresponding to the movement based on the movement of the external object, and controlling a first camera of the electronic device based on the gesture."
METHOD FOR CONTROLLING CAMERA AND ELECTRONIC DEVICE THEREFOR,https://lens.org/103-298-696-768-121,2021,"A method for controlling a camera of an electronic device is provided. The method includes generating a plurality of beams using an antenna array including a plurality of antenna elements and detecting an external object using the plurality of beams, sensing a movement of the external object using a first beam corresponding to the external object among the plurality of beams, identifying a gesture corresponding to the movement based on the movement of the external object, and controlling a first camera of the electronic device based on the gesture."
Method for controlling camera and electronic device therefor,https://lens.org/105-300-542-922-774,2022,"A method for controlling a camera of an electronic device is provided. The method includes generating a plurality of beams using an antenna array including a plurality of antenna elements and detecting an external object using the plurality of beams, sensing a movement of the external object using a first beam corresponding to the external object among the plurality of beams, identifying a gesture corresponding to the movement based on the movement of the external object, and controlling a first camera of the electronic device based on the gesture."
Double-UAV control system with improvement of cruising ability,https://lens.org/007-502-975-527-983,2015,"The invention provides a double-UAV control system with the improvement of cruising ability, relating to the technical field of aircrafts. A GPS receiver, a compass module 1, a telemetry radio transceiver module 1, a radio control receiver module 1, and two auto-focus camera modules are connected to a mother UAV CPU main board. A fiber connection success sensor module, a planetary gearbox servo motor 1, a potentiometer position sensor are connected to a connection/releasing linear actuator motor control module. A potentiometer position sensor is connected to the planetary gearbox servo motor 1. Both an infrared reflection position sensor module and a planetary gearbox servo motor 2 are connected to a UAV directional motor control module which is connected to the mother UAV CPU main board. The system has the advantages that the degree of automation is high, the control is easy, the cruising time of a UAV system can be prolonged for 5 to 10 times, the connection and separation of two UAVs is flexibly controlled, and the purpose of a continuous and smooth work process is achieved."
VOICE RECOGNITION SYSTEM,https://lens.org/180-350-483-234-984,2019,"A voice recognition system is provided with a user interface to display content, a camera to provide a first signal indicative an image of a user viewing the content, and a microphone to provide a second signal indicative of a voice command that corresponds to a requested action. The voice recognition system is further provided with a controller that is programmed to receive the first and second signals, filter the voice command based on the image, and perform the requested action based on the filtered voice command."
VOICE RECOGNITION SYSTEM,https://lens.org/120-499-180-380-035,2018,"A voice recognition system is provided with a user interface to display content, a camera to provide a first signal indicative of an image of a user viewing the content, and a microphone to provide a second signal indicative of a voice command that corresponds to a requested action. The voice recognition system is further provided with a controller that is programmed to receive the first and second signals, filter the voice command based on the image, and perform the requested action based on the filtered voice command."
VOICE CONTROL SYSTEM,https://lens.org/045-417-618-974-509,2012,One embodiment of a voice control system includes a first electronic device communicatively coupled to a server and configured to receive a speech recognition file from the server. The speech recognition file may include a speech recognition algorithm for converting one or more voice commands into text and a database including one or more entries comprising one or more voice commands and one or more executable commands associated with the one or more voice commands.
Unmanned aerial vehicle and method for reconfiguring geofence region thereof using electronic device,https://lens.org/197-669-150-875-099,2020,"An unmanned aerial vehicle (UAV) may include: a flight body; a camera installed on the flight body; a sensor module mounted inside the flight body to sense nearby surroundings; a wireless communication module mounted inside the flight body to wirelessly communicate with an external communication device; a processor mounted inside the flight body and electrically connected with the camera, the sensor module, and the wireless communication module; and a memory electrically connected with the processor. The memory may store instructions that, when the unmanned aerial vehicle is in flight, cause the processor to: identify a first geofence region; broadcast flight information on a periodic basis; receive flight information from a second unmanned aerial vehicle in flight; determine whether there is an overlap between the first geofence region and a second geofence region of the second unmanned aerial vehicle; and if so, reset the first geofence region so that the first geofence region does not overlap with the second geofence region."
UNMANNED AERIAL VEHICLE AND METHOD FOR RECONFIGURING GEOFENCE REGION THEREOF USING ELECTRONIC DEVICE,https://lens.org/098-108-098-006-451,2018,"An unmanned aerial vehicle (UAV) may include: a flight body; a camera installed on the flight body; a sensor module mounted inside the flight body to sense nearby surroundings; a wireless communication module mounted inside the flight body to wirelessly communicate with an external communication device; a processor mounted inside the flight body and electrically connected with the camera, the sensor module, and the wireless communication module; and a memory electrically connected with the processor. The memory may store instructions that, when the unmanned aerial vehicle is in flight, cause the processor to: identify a first geofence region; broadcast flight information on a periodic basis; receive flight information from a second unmanned aerial vehicle in flight; determine whether there is an overlap between the first geofence region and a second geofence region of the second unmanned aerial vehicle; and if so, reset the first geofence region so that the first geofence region does not overlap with the second geofence region."
Proxy-based remote control method and system for a digital image capture device,https://lens.org/127-302-104-338-823,2006,"Method and system for enabling an image capture system to respond to at least one command transmitted by a foreign remote control that is associated with a first device. The image capture system is first trained to respond to at least one command that is received from the foreign remote control. A user can then use the foreign remote control to access at least one function of the trained image capture system. For example, the foreign remote control can be used to access a first predefined function of the image capture system by transmitting a first instruction to the image capture system. The image capture system, responsive to the first instruction, performs the first predefined function."
Proxy-based remote control method and system for a digital image capture device,https://lens.org/166-542-882-369-965,2003,"Method and system for enabling an image capture system to respond to at least one command transmitted by a foreign remote control that is associated with a first device. The image capture system is first trained to respond to at least one command that is received from the foreign remote control. A user can then use the foreign remote control to access at least one function of the trained image capture system. For example, the foreign remote control can be used to access a first predefined function of the image capture system by transmitting a first instruction to the image capture system. The image capture system, responsive to the first instruction, performs the first predefined function."
"INTELLIGENT VOICE RECOGNIZING METHOD, APPARATUS, AND INTELLIGENT COMPUTING DEVICE",https://lens.org/127-152-606-418-603,2019,"Provided are an intelligent voice recognition method, a voice recognition device and an intelligent computing device. In an intelligent voice recognition method, if a microphone detection signal is obtained after the size of a first voice signal is determined, the size of the microphone detection signal is adjusted based on the size of the first voice signal. A second voice signal is recognized in the adjusted microphone detection signal. Accordingly, a command included in a user's voice can be recognized accurately. At least one of the voice recognition device, the intelligent computing device and the server of the present invention may be associated with an Artificial Intelligence module, a drone (Unmanned Aerial Vehicle, UAV), robot, Augmented Reality (AR) device, virtual reality (VR) device and a device related to the 5G service."
"Intelligent voice recognizing method, apparatus, and intelligent computing device",https://lens.org/031-133-963-011-356,2022,"Provided are an intelligent voice recognition method, a voice recognition device and an intelligent computing device. In an intelligent voice recognition method, if a microphone detection signal is obtained after the size of a first voice signal is determined, the size of the microphone detection signal is adjusted based on the size of the first voice signal. A second voice signal is recognized in the adjusted microphone detection signal. Accordingly, a command included in a user's voice can be recognized accurately. At least one of the voice recognition device, the intelligent computing device and the server of the present invention may be associated with an Artificial Intelligence module, a drone (Unmanned Aerial Vehicle, UAV), robot, Augmented Reality (AR) device, virtual reality (VR) device and a device related to the 5G service."
"Mobile aerial drone early warning privacy breach detect, intercept, and defend systems and methods",https://lens.org/157-901-683-053-824,2023,"Systems and methods for aerial unmanned vehicle (for example, drone) early warning privacy breach detection, interception, and defense are disclosed. The system detects drones within a threshold distance of an individual or configurable location, notifies the individual of the drones' existence, tracks the drones, and executes countermeasures. The system can communicate with telecommunication networks or other sources (for example, FAA) to identify and filter out drones that are authorized to be in the airspace around the individual."
"MOBILE AERIAL DRONE EARLY WARNING PRIVACY BREACH DETECT, INTERCEPT, AND DEFEND SYSTEMS AND METHODS",https://lens.org/117-251-431-884-16X,2022,"Systems and methods for aerial unmanned vehicle (for example, drone) early warning privacy breach detection, interception, and defense are disclosed. The system detects drones within a threshold distance of an individual or configurable location, notifies the individual of the drones' existence, tracks the drones, and executes countermeasures. The system can communicate with telecommunication networks or other sources (for example, FAA) to identify and filter out drones that are authorized to be in the airspace around the individual."
"MOBILE AERIAL DRONE EARLY WARNING PRIVACY BREACH DETECT, INTERCEPT, AND DEFEND SYSTEMS AND METHODS",https://lens.org/075-364-486-494-846,2020,"Systems and methods for aerial unmanned vehicle (for example, drone) early warning privacy breach detection, interception, and defense are disclosed. The system detects drones within a threshold distance of an individual or configurable location, notifies the individual of the drones' existence, tracks the drones, and executes countermeasures. The system can communicate with telecommunication networks or other sources (for example, FAA) to identify and filter out drones that are authorized to be in the airspace around the individual."
"Mobile aerial drone early warning privacy breach detect, intercept, and defend systems and methods",https://lens.org/152-793-976-440-855,2021,"Systems and methods for aerial unmanned vehicle (for example, drone) early warning privacy breach detection, interception, and defense are disclosed. The system detects drones within a threshold distance of an individual or configurable location, notifies the individual of the drones' existence, tracks the drones, and executes countermeasures. The system can communicate with telecommunication networks or other sources (for example, FAA) to identify and filter out drones that are authorized to be in the airspace around the individual."
"Mobile aerial drone early warning privacy breach detect, intercept, and defend systems and methods",https://lens.org/005-789-555-686-96X,2022,"Systems and methods for aerial unmanned vehicle (for example, drone) early warning privacy breach detection, interception, and defense are disclosed. The system detects drones within a threshold distance of an individual or configurable location, notifies the individual of the drones' existence, tracks the drones, and executes countermeasures. The system can communicate with telecommunication networks or other sources (for example, FAA) to identify and filter out drones that are authorized to be in the airspace around the individual."
Perspective angle acquisition and adjustment of security camera drone,https://lens.org/080-598-207-111-527,2022,"Techniques, devices, and systems are described for determining and adjusting a perspective angle of a drone sensor such as a camera. A described drone system can include an aerial drone; a ground station; an actuator to adjust the drone camera's field of view; and a controller. The controller can be configured to receive an event associated with one or more spatial coordinates or zones, determine the camera's current perspective angle, determine a target perspective angle based on the event such that the target perspective angle will cause the camera to capture imagery from the one or more spatial coordinates or zones, and cause the actuator to adjust the camera from the current perspective angle to the target perspective angle."
Perspective angle acquisition and adjustment of security camera drone,https://lens.org/080-598-207-111-527,2022,"Techniques, devices, and systems are described for determining and adjusting a perspective angle of a drone sensor such as a camera. A described drone system can include an aerial drone; a ground station; an actuator to adjust the drone camera's field of view; and a controller. The controller can be configured to receive an event associated with one or more spatial coordinates or zones, determine the camera's current perspective angle, determine a target perspective angle based on the event such that the target perspective angle will cause the camera to capture imagery from the one or more spatial coordinates or zones, and cause the actuator to adjust the camera from the current perspective angle to the target perspective angle."
Voice controlled welding system,https://lens.org/191-969-793-383-107,1987,"Apparatus and method are provided for permitting human voice control of a welding system. A human operator, remote from a welding power supply, uses a welding torch connected by a power line to the welding power supply. The human operator is provided with an audio transmitter which permits the operator to adjust the welding power supply through verbal commands. The verbal commands are issued by the human operator, and are transmitted through a receiver, a voice recognition unit, and a computer, which is electrically connected to deliver power control signals to the welding power supply to thereby adjust the power delivered to the welding torch. The operator may also issue verbal commands to start and stop an internal combustion engine which drives the welding power supply, when such an engine is used. Additionally, when the welding process incorporates a consumable wire electrode, the operator may verbally alter the speed at which the wire electrode is fed through the welding torch. A major advantage of the system is that changes are made without interrupting the welding process."
"DRONE INCLUDING A FRONT-VIEW CAMERA WITH ATTITUDE-INDEPENDENT CONTROL PARAMETERS, IN PARTICULAR AUTO-EXPOSURE CONTROL",https://lens.org/116-189-351-803-226,2017,"The drone comprises a camera (14), an inertial unit (46) measuring the drone angles, and an extractor module (52) delivering image data of a mobile capture area of reduced size dynamically displaced in a direction opposite to that of the angle variations measured by the inertial unit. Compensator means (52) receive as an input the current drone attitude data and acting dynamically on the current value (54) of an imaging parameter such as auto-exposure, white balance or autofocus, calculated as a function of the image data contained in the capture area."
METHOD OF DESTRUCTION of remotely controlled unmanned aerial vehicles IN FLIGHT,https://lens.org/153-613-401-975-707,2015,"A method for destruction of remotely controlled unmanned aerial vehicles in flight, in which at the specified remote-controlled unmanned aerial vehicle of the enemy, which is flying, destruction mean acts, its direction of motion is directed towards the target. As the means for destruction there is used a remote-controlled drone, equipped, in addition to the regular systems and equipment with which it takes off, performs en-route flight and landing, a video surveillance system with a video camera is installed, ammunition with fragmentation or explosive action and the system for bringing into effect these weapons, and the destruction of the remotely controlled unmanned enemys aircraft in flight is carried out by means of exploding ammunition in close proximity with the target at range from 1 to 200 meters, depending on the type of ammunition."
SYSTEM AND METHOD FOR REMOTELY CONTROLLING A CAMERA,https://lens.org/094-418-903-451-485,2009,A system and method for remotely controlling a camera may include a telephony device communicatively coupled to a data network. The telephony device comprises at least one module adapted to generate a control signal in response to receiving a user command associated with dialing of an emergency telephone number. A camera may be adapted to start capturing images in response of receiving the control signal.
System and method for remotely monitoring a camera using a telephony device,https://lens.org/021-582-397-436-720,2013,A system and method for remotely controlling a camera may include a telephony device communicatively coupled to a data network. The telephony device comprises at least one module adapted to generate a control signal in response to receiving a user command associated with dialing of an emergency telephone number. A camera may be adapted to start capturing images in response of receiving the control signal.
SYSTEM AND METHOD FOR REMOTELY CONTROLLING A CAMERA,https://lens.org/131-827-005-276-002,2011,A system and method for remotely controlling a camera may include a telephony device communicatively coupled to a data network. The telephony device comprises at least one module adapted to generate a control signal in response to receiving a user command associated with dialing of an emergency telephone number. A camera may be adapted to start capturing images in response of receiving the control signal.
System and method for remotely controlling a camera,https://lens.org/134-042-474-641-462,2011,A system and method for remotely controlling a camera may include a telephony device communicatively coupled to a data network. The telephony device comprises at least one module adapted to generate a control signal in response to receiving a user command associated with dialing of an emergency telephone number. A camera may be adapted to start capturing images in response of receiving the control signal.
Unmanned aerial vehicles,https://lens.org/044-202-369-738-331,2018,"An unmanned aerial vehicle, UAV, 100 comprising a camera 110 and a controller 120, the controller is configured to: (a) receive image data from the camera, (b) determine, based on the received image data, whether or not a predetermined visibility condition associated with an operator of the UAV is satisfied, and (c) cause an alert message to be transmitted to the operator to attempt to operate in accordance with a predetermined visibility state with respect to the operator in response to determining that the predetermined visibility condition is not satisfied. The predetermined visibility state comprises a Visual Line Of Sight, VLOS, mode. The VLOS mode is associated with the operator being at most a predetermined distance from the UAV. The controller may control the direction of the camera. The controller may distinguish between different operators."
"UNMANNED AERIAL VEHICLE AND METHOD FOR DETECTING FLIGHT STATE THEREOF, AND WEARABLE DEVICE",https://lens.org/193-042-233-189-540,2020,"An unmanned aerial vehicle, a method for detecting a flight state thereof, and a wearable device (500) are disclosed. The method comprises: disposing a propeller operation state collector (302) for collecting an operation state signal of a propeller (301) on at least one support arm (303) of the UAV (S101); acquiring the operation state signal of the propeller (301) collected by the propeller operation state collector (302) (S102); processing the operation state signal to obtain an operation state of the propeller (301) (S103); and determining the flight state of the UAV according to the operation state of the propeller (301) (S104). By disposing the propeller operation state collector (302) on the support arm (303) of the UAV to collect the operation state signal of the propeller (301), and then calculating the flight state of the UAV according to the operation state signal, better flight control of the UAV can be achieved by making use of the detected flight state of the UAV, and an desired flight trajectory can be obtained, thereby improving the controllability and safety during the flight of the UAV"
LOCATION VERIFICATION AND SECURE NO-FLY LOGIC FOR UNMANNED AERIAL VEHICLES,https://lens.org/114-807-286-696-550,2017,"Certain embodiments herein relate to location verification for autonomous unmanned aerial vehicles (also referred to as ""drones""). In some embodiments, an unmanned aerial vehicle engaged in autonomous flight may determine its location using a satellite-based navigation system. The location may be evaluated against location data obtained from one or more secondary factors, such as public broadcast beacons, cellular towers, wireless network identifiers, visual markers, or any combination thereof. If the location is determined to be invalid, the unmanned aerial vehicle may be instructed to take a mitigation action. Additionally, certain embodiments also include the verification of a flight plan for the unmanned aerial vehicle using secure no-fly logic to verify a flight plan does not violate no-fly zones. If the flight plan is verified, the flight plan may be signed using a cryptographic signature and provided to a navigation module that verifies the signature and executes the flight plan."
LOCATION VERIFICATION AND SECURE NO-FLY LOGIC FOR UNMANNED AERIAL VEHICLES,https://lens.org/092-287-504-665-566,2017,"Certain embodiments herein relate to location verification for autonomous unmanned aerial vehicles (also referred to as ""drones""). In some embodiments, an unmanned aerial vehicle engaged in autonomous flight may determine its location using a satellite-based navigation system. The location may be evaluated against location data obtained from one or more secondary factors, such as public broadcast beacons, cellular towers, wireless network identifiers, visual markers, or any combination thereof. If the location is determined to be invalid, the unmanned aerial vehicle may be instructed to take a mitigation action. Additionally, certain embodiments also include the verification of a flight plan for the unmanned aerial vehicle using secure no-fly logic to verify a flight plan does not violate no-fly zones. If the flight plan is verified, the flight plan may be signed using a cryptographic signature and provided to a navigation module that verifies the signature and executes the flight plan."
METHOD TO NAVIGATE AN UNMANNED AERIAL VEHICLE TO AVOID COLLISIONS,https://lens.org/085-178-795-236-297,2022,"A method to navigate an unmanned aerial vehicle UAV (100) comprises the steps of controlling a flight path of the UAV (100) by a remote operator (5), obtaining a recognized air picture of an observation space surrounding the UAV (100), including tracking information with respect to aerial vehicles (10, 20, 30, 40) within the observation space, assigning one of a plurality of threat levels to each of the aerial vehicles (10, 20, 30, 40), the threat levels comprising a resolution advisory level and an automatic avoidance level and continuously automatically determining viable avoidance trajectories for the UAV (100). If at least one of the aerial vehicles (10, 20, 30, 40) is assigned the resolution advisory level, a message is provided to the remote operator (5) including a first proposed viable avoidance trajectory. If at least one of the aerial vehicles (10, 20, 30, 40) is assigned the automatic avoidance level, control signals are provided to an on-board flight controller (160) of the UAV (100) instructing the vehicle to follow a flight path corresponding to a second proposed viable avoidance trajectory."
"UNMANNED AIRCRAFT CONTROL SYSTEM, UNMANNED AIRCRAFT CONTROL METHOD, AND PROGRAM",https://lens.org/015-570-337-542-85X,2019,"An unmanned aerial vehicle is caused to fly by avoiding a no-fly zone, which changes as a moving object moves. Provided is an unmanned aerial vehicle control system (1), including: moving object position acquisition means (102) for acquiring moving object position information on a current position of a moving object moving above a surface of an earth; zone setting means (103) for setting a no-fly zone in which a flight of an unmanned aerial vehicle (20) is inhibited based on the moving object position information; and flight control means (105) for controlling the flight of the unmanned aerial vehicle (20) so that the unmanned aerial vehicle (20) avoids the no-fly zone set based on the moving object position information."
System and method for authenticating voice commands for a voice assistant,https://lens.org/045-498-998-536-013,2020,A system and method for authenticating voice commands for a voice assistant includes an accelerometer device for recording vibrations corresponding to speech from a user. The recorded vibrations are compared to speech signals recorded by a microphone to determine if the speech signals originated from the user.
SYSTEM AND METHOD FOR AUTHENTICATING VOICE COMMANDS FOR A VOICE ASSISTANT,https://lens.org/053-560-581-893-562,2018,A system and method for authenticating voice commands for a voice assistant includes an accelerometer device for recording vibrations corresponding to speech from a user. The recorded vibrations are compared to speech signals recorded by a microphone to determine if the speech signals originated from the user.
UNMANNED AERIAL VEHICLES AND METHODS OF OPERATING UNMANNED AERIAL VEHICLES,https://lens.org/157-977-702-867-622,2023,"A method of operating an Unmanned Aerial Vehicle, UAV is provided. The method comprises transmitting signals to a wireless communications network or to a communications device configured to communicate via the wireless communications network, the signals being transmitted via a wireless access interface between the UAV and the wireless communications network or between the UAV and the communications device, or receiving signals from the wireless communications network or from a communications device configured to communicate via the wireless communications network, the signals being received via the wireless access interface between the UAV and the wireless communications network or between the UAV and the communications device, and transmitting, by the UAV, a UAV identification transmission, wherein the UAV identification transmission comprises: an indication of a serial number assigned to the UAV or a session identifier assigned to the UAV by a remote identification Unmanned Aircraft System, UAS, service supplier; an indication of a time when the UAV identification transmission is transmitted; and an indication of an emergency status of the UAV."
PACKAGE DELIVERY BY MEANS OF AN AUTOMATED MULTI-COPTER UAS/UAV DISPATCHED FROM A CONVENTIONAL DELIVERY VEHICLE,https://lens.org/166-690-630-483-483,2016,"Methods and associated systems for autonomous package delivery utilize a UAS/UAV, an infrared positioning senor, and a docking station integrated with a package delivery vehicle. The UAS/UAV accepts a package for delivery from the docking station on the delivery vehicle and uploads the delivery destination. The UAS/UAV autonomously launches from its docked position on the delivery vehicle. The UAS/UAV autonomously flies to the delivery destination by means of GPS navigation. The UAS/UAV is guided in final delivery by means of a human supervised live video feed from the UAS/UAV. The UAS/UAV is assisted in the descent and delivery of the parcel by precision sensors and if necessary by means of remote human control. The UAS/UAV autonomously returns to the delivery vehicle by means of GPS navigation and precision sensors. The UAS/UAV autonomously docks with the delivery vehicle for recharging and preparation for the next delivery sequence."
PACKAGE DELIVERY BY MEANS OF AN AUTOMATED MULTI-COPTER UAS/UAV DISPATCHED FROM A CONVENTIONAL DELIVERY VEHICLE,https://lens.org/135-047-095-956-201,2018,"Methods and associated systems for autonomous package delivery utilize a UAS/UAV, an infrared positioning senor, and a docking station integrated with a package delivery vehicle. The UAS/UAV accepts a package for delivery from the docking station on the delivery vehicle and uploads the delivery destination. The UAS/UAV autonomously launches from its docked position on the delivery vehicle. The UAS/UAV autonomously flies to the delivery destination by means of GPS navigation. The UAS/UAV is guided in final delivery by means of a human supervised live video feed from the UAS/UAV. The UAS/UAV is assisted in the descent and delivery of the parcel by precision sensors and if necessary by means of remote human control. The UAS/UAV autonomously returns to the delivery vehicle by means of GPS navigation and precision sensors. The UAS/UAV autonomously docks with the delivery vehicle for recharging and preparation for the next delivery sequence."
Package delivery by means of an automated multi-copter UAS/UAV dispatched from a conventional delivery vehicle,https://lens.org/093-061-098-621-852,2018,"Methods and associated systems for autonomous package delivery utilize a UAS/UAV, an infrared positioning senor, and a docking station integrated with a package delivery vehicle. The UAS/UAV accepts a package for delivery from the docking station on the delivery vehicle and uploads the delivery destination. The UAS/UAV autonomously launches from its docked position on the delivery vehicle. The UAS/UAV autonomously flies to the delivery destination by means of GPS navigation. The UAS/UAV is guided in final delivery by means of a human supervised live video feed from the UAS/UAV. The UAS/UAV is assisted in the descent and delivery of the parcel by precision sensors and if necessary by means of remote human control. The UAS/UAV autonomously returns to the delivery vehicle by means of GPS navigation and precision sensors. The UAS/UAV autonomously docks with the delivery vehicle for recharging and preparation for the next delivery sequence."
PACKAGE DELIVERY BY MEANS OF AN AUTOMATED MULTI-COPTER UAS/UAV DISPATCHED FROM A CONVENTIONAL DELIVERY VEHICLE,https://lens.org/036-566-489-509-151,2021,"Methods and associated systems for autonomous package delivery utilize a UAS/UAV, an infrared positioning senor, and a docking station integrated with a package delivery vehicle. The UAS/UAV accepts a package for delivery from the docking station on the delivery vehicle and uploads the delivery destination. The UAS/UAV autonomously launches from its docked position on the delivery vehicle. The UAS/UAV autonomously flies to the delivery destination by means of GPS navigation. The UAS/UAV is guided in final delivery by means of a human supervised live video feed from the UAS/UAV. The UAS/UAV is assisted in the descent and delivery of the parcel by precision sensors and if necessary by means of remote human control. The UAS/UAV autonomously returns to the delivery vehicle by means of GPS navigation and precision sensors. The UAS/UAV autonomously docks with the delivery vehicle for recharging and preparation for the next delivery sequence."
Package delivery by means of an automated multi-copter UAS/UAV dispatched from a conventional delivery vehicle,https://lens.org/060-868-392-410-327,2021,"Methods and associated systems for autonomous package delivery utilize a UAS/UAV, an infrared positioning senor, and a docking station integrated with a package delivery vehicle. The UAS/UAV accepts a package for delivery from the docking station on the delivery vehicle and uploads the delivery destination. The UAS/UAV autonomously launches from its docked position on the delivery vehicle. The UAS/UAV autonomously flies to the delivery destination by means of GPS navigation. The UAS/UAV is guided in final delivery by means of a human supervised live video feed from the UAS/UAV. The UAS/UAV is assisted in the descent and delivery of the parcel by precision sensors and if necessary by means of remote human control. The UAS/UAV autonomously returns to the delivery vehicle by means of GPS navigation and precision sensors. The UAS/UAV autonomously docks with the delivery vehicle for recharging and preparation for the next delivery sequence."
WIRELESSLY CONTROLLING UNMANNED AIRCRAFT AND ACCESSING ASSOCIATED SURVEILLANCE DATA,https://lens.org/124-614-717-808-473,2007,"Controlling an unmanned aerial vehicle (UAV) may be accomplished by using a wireless device (e.g., cell phone) to send a control message to a receive r at the UAV via a wireless telecommunication network (e.g., an existing cel lular network configured primarily for mobile telephone communication). In a ddition, the wireless device may be used to receive communications from a tr ansmitter at the UAV, wherein the wireless device receives the communication s from the transmitter via the wireless network. Examples of such communicat ions include surveillance information and UAV monitoring information.</SDOAB >"
Voice control of an integrated room automation system,https://lens.org/093-634-135-635-707,2022,"A voice controlled room automation system that includes a speaker device situated in a guest room, a hotel automation controller operatively coupled to one or more components in the guest room, and a web service operatively coupled to the speaker device and the hotel automation controller. The web service is configured to receiving voice commands from the speaker device, process the voice command using speech recognition, interpret the voice command to determine a corresponding command for the hotel automation controller, and transmit the corresponding command to the hotel automation controller. The hotel automation controller is configured to receive the corresponding command from the web service, and to carry out the corresponding command by interacting with one or more of the components in the room. In some cases, the hotel automation controller may be configured to initiate an announcement or query on the speaker device via the web service."
Voice control of an integrated room automation system,https://lens.org/093-634-135-635-707,2022,"A voice controlled room automation system that includes a speaker device situated in a guest room, a hotel automation controller operatively coupled to one or more components in the guest room, and a web service operatively coupled to the speaker device and the hotel automation controller. The web service is configured to receiving voice commands from the speaker device, process the voice command using speech recognition, interpret the voice command to determine a corresponding command for the hotel automation controller, and transmit the corresponding command to the hotel automation controller. The hotel automation controller is configured to receive the corresponding command from the web service, and to carry out the corresponding command by interacting with one or more of the components in the room. In some cases, the hotel automation controller may be configured to initiate an announcement or query on the speaker device via the web service."
VOICE CONTROL OF AN INTEGRATED ROOM AUTOMATION SYSTEM,https://lens.org/043-554-958-896-269,2018,"A voice controlled room automation system that includes a speaker device situated in a guest room, a hotel automation controller operatively coupled to one or more components in the guest room, and a web service operatively coupled to the speaker device and the hotel automation controller. The web service is configured to receiving voice commands from the speaker device, process the voice command using speech recognition, interpret the voice command to determine a corresponding command for the hotel automation controller, and transmit the corresponding command to the hotel automation controller. The hotel automation controller is configured to receive the corresponding command from the web service, and to carry out the corresponding command by interacting with one or more of the components in the room. In some cases, the hotel automation controller may be configured to initiate an announcement or query on the speaker device via the web service."
VOICE CONTROL OF AN INTEGRATED ROOM AUTOMATION SYSTEM,https://lens.org/132-832-958-483-919,2020,"A voice controlled room automation system that includes a speaker device situated in a guest room, a hotel automation controller operatively coupled to one or more components in the guest room, and a web service operatively coupled to the speaker device and the hotel automation controller. The web service is configured to receiving voice commands from the speaker device, process the voice command using speech recognition, interpret the voice command to determine a corresponding command for the hotel automation controller, and transmit the corresponding command to the hotel automation controller. The hotel automation controller is configured to receive the corresponding command from the web service, and to carry out the corresponding command by interacting with one or more of the components in the room. In some cases, the hotel automation controller may be configured to initiate an announcement or query on the speaker device via the web service."
Voice control of integrated room automation system,https://lens.org/161-631-736-456-385,2020,"A voice controlled room automation system that includes a speaker device situated in a guest room, a hotel automation controller operatively coupled to one or more components in the guest room, and a web service operatively coupled to the speaker device and the hotel automation controller. The web service is configured to receiving voice commands from the speaker device, process the voice command using speech recognition, interpret the voice command to determine a corresponding command for the hotel automation controller, and transmit the corresponding command to the hotel automation controller. The hotel automation controller is configured to receive the corresponding command from the web service, and to carry out the corresponding command by interacting with one or more of the components in the room. In some cases, the hotel automation controller may be configured to initiate an announcement or query on the speaker device via the web service."
VOICE CONTROL OF AN INTEGRATED ROOM AUTOMATION SYSTEM,https://lens.org/107-375-961-942-648,2018,"A voice controlled room automation system that includes a speaker device situated in a guest room, a hotel automation controller operatively coupled to one or more components in the guest room, and a web service operatively coupled to the speaker device and the hotel automation controller. The web service is configured to receiving voice commands from the speaker device, process the voice command using speech recognition, interpret the voice command to determine a corresponding command for the hotel automation controller, and transmit the corresponding command to the hotel automation controller. The hotel automation controller is configured to receive the corresponding command from the web service, and to carry out the corresponding command by interacting with one or more of the components in the room. In some cases, the hotel automation controller may be configured to initiate an announcement or query on the speaker device via the web service."
VOICE CONTROL SYSTEM,https://lens.org/185-485-919-278-540,2008,A voice control system allows a user to control a device through voice commands. The voice control system includes a speech recognition unit that receives a control signal from a mobile device and a speech signal from a user. The speech recognition unit configures speech recognition settings in response to the control signal to improve speech recognition.
Voice control system,https://lens.org/082-915-592-120-188,2014,A voice control system allows a user to control a device through voice commands. The voice control system includes a speech recognition unit that receives a control signal from a mobile device and a speech signal from a user. The speech recognition unit configures speech recognition settings in response to the control signal to improve speech recognition.
SYSTEM AND METHOD FOR EXECUTING OPERATIONS ON AN OBJECT BY MEANS OF DRONES,https://lens.org/124-672-542-440-528,2019,"A system for executing an operation on an object (O) by means of a fleet of drones (20) equipped with tools for executing said operation. The system comprises: - processing means (10) adapted to receive as input information for calculating the trajectories required for bringing the fleet of drones (20) into the desired position for the execution of said operation, wherein said processing means (10) are adapted to transmit flight trajectories and instructions for executing the operation on the object (O) to said fleet of drones (20), - a local positioning system (L) comprising a plurality of anchor nodes in Ultra- Wide- Band technology (UWB-A1,UWB-A2,UWB-A3,UWB-Ax,UWB-AN) arranged around said object (O) along the sides of the surfaces of the ideal polyhedron that circumscribes the object (O). Each drone (20) of said fleet is equipped with: - a UWB transceiver (26) in communication with said anchor nodes (UWB-A1,UWB- A2,UWB-A3,UWB-Ax,UWB-AN), wherein each drone (20) is at all times in communication with at least four anchor nodes (UWB-A1,UWB-A2,UWB-A3,UWB- Ax,UWB-AN), and - a plurality of ultrasound sensors (24) for measuring the distance of each drone (20) from the other drones and from obstacles, wherein said fleet of drones (20), by following the way points (WP) of said trajectories sent by said processing means (10), executes said operation on said object (O) by means of said tools."
Vehicle-based remote control system and method,https://lens.org/119-798-492-354-092,2020,"A vehicle-based remote control system and method are provided herein. A first in-vehicle device and a second in-vehicle device are provided. The second in-vehicle device includes a user-input mechanism having at least one actuatable member, and a controller programmed to respond to input from the user-input mechanism. Upon actuation of the at least one actuatable member, the controller prompts the first in-vehicle device to transmit a pre-recorded user voice command assigned to the at least one actuatable member. The pre-recorded user voice command is transmitted to a server. The server processes the pre-recorded user voice command and generates a command for executing an action specified by the pre-recorded user voice command. The command is executed by one or more smart devices located remotely from a vehicle."
Presentation of information from the sky,https://lens.org/113-843-842-052-791,2022,"Systems, devices, and methods for presenting information in the sky using drones are disclosed. The presentation of information includes navigating one or more drones to locations in the sky where the locations are associated with an image, emitting light signals at the locations, capturing the light signals with a user device, processing the captured signals to identify the image, capturing a background image including at least one of the locations associated with the image, and presenting simultaneously, on the user device, the identified image and the background image."
PRESENTATION OF INFORMATION FROM THE SKY,https://lens.org/014-273-856-713-553,2022,"Systems, devices, and methods for presenting information in the sky using drones are disclosed. The presentation of information includes navigating one or more drones to locations in the sky where the locations are associated with an image, emitting light signals at the locations, capturing the light signals with a user device, processing the captured signals to identify the image, capturing a background image including at least one of the locations associated with the image, and presenting simultaneously, on the user device, the identified image and the background image."
Presentation of information from the sky,https://lens.org/113-843-842-052-791,2022,"Systems, devices, and methods for presenting information in the sky using drones are disclosed. The presentation of information includes navigating one or more drones to locations in the sky where the locations are associated with an image, emitting light signals at the locations, capturing the light signals with a user device, processing the captured signals to identify the image, capturing a background image including at least one of the locations associated with the image, and presenting simultaneously, on the user device, the identified image and the background image."
PRESENTATION OF INFORMATION FROM THE SKY,https://lens.org/014-273-856-713-553,2022,"Systems, devices, and methods for presenting information in the sky using drones are disclosed. The presentation of information includes navigating one or more drones to locations in the sky where the locations are associated with an image, emitting light signals at the locations, capturing the light signals with a user device, processing the captured signals to identify the image, capturing a background image including at least one of the locations associated with the image, and presenting simultaneously, on the user device, the identified image and the background image."
PRESENTATION OF INFORMATION FROM THE SKY,https://lens.org/014-273-856-713-553,2022,"Systems, devices, and methods for presenting information in the sky using drones are disclosed. The presentation of information includes navigating one or more drones to locations in the sky where the locations are associated with an image, emitting light signals at the locations, capturing the light signals with a user device, processing the captured signals to identify the image, capturing a background image including at least one of the locations associated with the image, and presenting simultaneously, on the user device, the identified image and the background image."
SYSTEM AND METHOD FOR MANAGING DRONES,https://lens.org/126-271-850-403-10X,2018,"A system and method for managing drones is provided. The system comprises a drone (102) with a first distributed register (202a). The first distributed register (202a) is configured to record information corresponding to the drone (102). The system further comprises an external system (108) with a second distributed register (202a). The external system (108) is configured to communicate with the drone (102) to receive at least a block of information from the drone (102). Further, the external system (108) is configured to update the second distributed register (202a) using the received block of information. Further, the information in the first distributed register (202a) of the drone (102) and second distributed register (202a) of the external system (108) is stored in the form of blocks, wherein each block is embedded with information of a previous block."
UNMANNED AERIAL VEHICLES,https://lens.org/176-915-812-840-186,2019,"A UAV comprises a camera arrangement configurable such that a field of view of the camera arrangement includes airspace directly above the UAV, a lighting arrangement configurable in an upwards-facing configuration, and a controller operable to cause the lighting arrangement to illuminate an object in the airspace directly above the UAV."
Unmanned aerial vehicles,https://lens.org/064-935-782-394-433,2020,"A UAV comprises a camera arrangement configurable such that a field of view of the camera arrangement includes airspace directly above the UAV, a lighting arrangement configurable in an upwards-facing configuration, and a controller operable to cause the lighting arrangement to illuminate an object in the airspace directly above the UAV."
UNMANNED AERIAL VEHICLES,https://lens.org/131-992-314-436-259,2019,"A UAV comprises a camera arrangement configurable such that a field of view of the camera arrangement includes airspace directly above the UAV, a lighting arrangement configurable in an upwards-facing configuration, and a controller operable to cause the lighting arrangement to illuminate an object in the airspace directly above the UAV."
UNMANNED AERIAL VEHICLES,https://lens.org/007-927-430-329-278,2020,"A UAV comprises a camera arrangement configurable such that a field of view of the camera arrangement includes airspace directly above the UAV, a lighting arrangement configurable in an upwards-facing configuration, and a controller operable to cause the lighting arrangement to illuminate an object in the airspace directly above the UAV."
"AUTONOMOUS VEHICLE, CONTROL SYSTEM FOR REMOTELY CONTROLLING THE SAME, AND METHOD THEREOF",https://lens.org/056-818-530-099-670,2022,"An autonomous vehicle may include a processor configured to transmit vehicle data for remote control of the autonomous vehicle to a control system when the remote control of the autonomous vehicle is required, and when receiving a remote control command for the remote control from the control system, to generate and follow a path based on the received remote control command."
"AUTONOMOUS VEHICLE, CONTROL SYSTEM FOR REMOTELY CONTROLLING THE SAME, AND METHOD THEREOF",https://lens.org/056-818-530-099-670,2022,"An autonomous vehicle may include a processor configured to transmit vehicle data for remote control of the autonomous vehicle to a control system when the remote control of the autonomous vehicle is required, and when receiving a remote control command for the remote control from the control system, to generate and follow a path based on the received remote control command."
"AUTONOMOUS VEHICLE, CONTROL SYSTEM FOR REMOTELY CONTROLLING THE SAME, AND METHOD THEREOF",https://lens.org/056-818-530-099-670,2022,"An autonomous vehicle may include a processor configured to transmit vehicle data for remote control of the autonomous vehicle to a control system when the remote control of the autonomous vehicle is required, and when receiving a remote control command for the remote control from the control system, to generate and follow a path based on the received remote control command."
Unmanned aerial vehicle (UAV) and method of using UAV to guide a target,https://lens.org/018-749-616-534-384,2020,"A method of using an unmanned aerial vehicle (UAV) to guide a target includes receiving, via the UAV, a signal indicative of a target area for guiding the target, determining an indicator based on a location of the UAV and/or a location of the target area while the target is in motion, and performing, via the UAV, an operation in response to the indicator."
SYSTEMS AND METHODS FOR WALKING PETS,https://lens.org/172-094-215-326-292,2019,"A method of using an unmanned aerial vehicle (UAV) to guide a target includes receiving, via the UAV, a signal indicative of a target area for guiding the target, determining an indicator based on a location of the UAV and/or a location of the target area while the target is in motion, and performing, via the UAV, an operation in response to the indicator."
FLYING MACHINE CAPABLE OF BLOCKING LIGHT AUTONOMOUSLY,https://lens.org/107-528-323-121-807,2016,"A flying machine capable of blocking light autonomously includes a machine body with a flight direction control module, a light sensor for detecting a sunshine angle, a position sensor for detecting the position of a moving object, and a flight movement adjuster to control the machine body to autonomously fly to a position linearly aligned with the sunlight and the moving object, so that the flying machine blocks between the sunlight and the moving object."
Flying machine capable of blocking light autonomously,https://lens.org/152-128-443-076-00X,2017,"A flying machine capable of blocking light autonomously includes a machine body with a flight direction control module, a light sensor for detecting a sunshine angle, a position sensor for detecting the position of a moving object, and a flight movement adjuster to control the machine body to autonomously fly to a position linearly aligned with the sunlight and the moving object, so that the flying machine blocks between the sunlight and the moving object."
MONITORING A CONSTRUCTION SITE USING AN UNMANNED AERIAL VEHICLE,https://lens.org/046-021-840-950-730,2017,"Described embodiments include an unmanned aerial vehicle (UAV) (20), including a receiver (26) and a processor (28). The processor is configured to receive, via the receiver, coordinates of a position sensor (34) coupled to a portion of a crane (30), a configuration of the crane changing over time due at least to movement of the portion of the crane relative to a tower (38) of the crane. The processor is further configured to compute, in response to the received coordinates, a flight path (50) that passes under a boom (40) of the crane while circumventing the crane, and to cause the UAV to follow the computed flight path. Other embodiments are also described."
Autonomous vehicle maneuver recognition,https://lens.org/057-600-344-305-236,2022,"Autonomous vehicles may include one or more onboard devices to perform various actions, such as a still image capture device. In contrast with using an auxiliary communication system to control a payload, a vehicle navigation sensor is used to monitor autonomous vehicle movements to match a predefined vehicle maneuver event, and trigger a payload event based on identification of the vehicle maneuver event. For example, this allows an autopilot system or a remote drone pilot to initiate an image capture device or send other commands based on vehicle maneuver event recognition."
Autonomous Vehicle Maneuver Recognition,https://lens.org/173-557-922-589-870,2018,"Autonomous vehicles may include one or more onboard devices to perform various actions, such as a still image capture device. In contrast with using an auxiliary communication system to control a payload, a vehicle navigation sensor is used to monitor autonomous vehicle movements to match a predefined vehicle maneuver event, and trigger a payload event based on identification of the vehicle maneuver event. For example, this allows an autopilot system or a remote drone pilot to initiate an image capture device or send other commands based on vehicle maneuver event recognition."
Autonomous vehicle maneuver recognition,https://lens.org/150-235-836-948-121,2020,"Autonomous vehicles may include one or more onboard devices to perform various actions, such as a still image capture device. In contrast with using an auxiliary communication system to control a payload, a vehicle navigation sensor is used to monitor autonomous vehicle movements to match a predefined vehicle maneuver event, and trigger a payload event based on identification of the vehicle maneuver event. For example, this allows an autopilot system or a remote drone pilot to initiate an image capture device or send other commands based on vehicle maneuver event recognition."
AUTONOMOUS VEHICLE MANEUVER RECOGNITION,https://lens.org/074-046-780-481-069,2020,"Autonomous vehicles may include one or more onboard devices to perform various actions, such as a still image capture device. In contrast with using an auxiliary communication system to control a payload, a vehicle navigation sensor is used to monitor autonomous vehicle movements to match a predefined vehicle maneuver event, and trigger a payload event based on identification of the vehicle maneuver event. For example, this allows an autopilot system or a remote drone pilot to initiate an image capture device or send other commands based on vehicle maneuver event recognition."
Precise landing automatic control method for traffic information collecting unmanned aerial vehicle,https://lens.org/169-979-926-553-774,2015,"The invention provides a precise landing automatic control method for a traffic information collecting unmanned aerial vehicle. The method comprises the following steps that S1, the unmanned aerial vehicle flies to a primary target position according to a GPS; S2, the unmanned aerial vehicle and a ground control station are in local area wireless network connection; S3, the unmanned aerial vehicle sends a secondary locating request to the ground control station, meanwhile, video locating is started, a first locating light source is started after the ground control station receives the secondary locating request, the unmanned aerial vehicle captures the position of the first locating light source through video, the position information of the first locating light source is obtained through an image processing method, and the unmanned aerial vehicle flies to a secondary target position; S4, the unmanned aerial vehicle sends a third-stage locating request to the ground control station, a second locating light source is started after the ground control station receives the three-stage locating request, the unmanned aerial vehicle captures the position of the second locating light source through video, the position information of the second locating light source is obtained through the image processing method, and the unmanned aerial vehicle lands on the ground station. According to the method, landing of the unmanned aerial vehicle can be precisely and automatically controlled."
ROOF STRUCTURE,https://lens.org/151-895-451-204-607,2022,"A roof structure that can provide a drone port where a drone can stably take off and land on a sloping roof includes a sloping roof covering the upper part of a building, a drone accommodation portion that has a size capable of accommodating a drone and is provided to cut out a part of the sloping roof so that a bottom surface is substantially horizontal, a drone port that is provided on the bottom surface of the drone accommodation portion where the drone can take off and land, a cover that covers an opening formed on the sloping roof for the drone accommodation portion, and a doorway that is provided on the drone accommodation portion and allows the drone to enter and exit, in which the cover is configured to be openable and closable, and the doorway is opened and closed by opening and closing of the cover."
Remoto-controllable automatic diaphragm control device for use with CCTV camera,https://lens.org/091-114-514-190-830,1987,"A remote-controllable automatic diaphragm control device for use with a CCTV camera permitting the diaphragm control to be changed over between an automatic diaphragm control mode in which a desired diaphragm control is achieved by utilizing a video signal supplied from a television camera and a remote diaphragm control mode in which the diaphragm is electrically adjustable to a desired diaphragm position entirely regardless of said video signal from the television camera, in a simple manner."
DRONE DETECTION USING MULTI-SENSORY ARRAYS,https://lens.org/120-368-747-697-886,2020,"A system and method for detection of an aerial drone in an environment includes a baseline of geo-mapped sensor data in a temporal and location indexed database formed by (i) using at least one sensor to receive signals from the environment and converting into digital signals for further processing; (ii)deriving time delays, object signatures, Doppler shifts, reflectivity, and/or optical characteristics from the received signals; (iii) geo-mapping the environment using GNSS and the sensor data; and (iv) logging sensor data over a time interval, for example 24 hours to 7 days. Live sensor data can be then be monitored and signature data can be derived by computing at least one parameter such as direction and signal strength. The live data is continuously or periodically compared to the baseline data to identify a variance, if any, which may be indicative of a detection event."
"Electronic Device for Determining the Distance of a Drone From an Obstacle With Filtering Adapted to the Speed of the Drone, Drone, Determination Method and Computer Program",https://lens.org/006-167-601-349-957,2018,"An electronic device for determining a distance of a drone from an obstacle, the electronic device comprising: an emission module to command the emission of an ultrasound signal toward the obstacle;a reception module to receive a signal representative of an ultrasound signal reflected by the obstacle;a calculation module to calculate the distance of the drone from the obstacle, from the received signal; anda filtering module comprising at least one filter matched to a respective Doppler offset, each matched filter generating a respective filtered signal as a function of a convolution product of the emitted ultrasound signal, to which the respective Doppler offset is applied, with the received ultrasound signal; the calculation module then calculating the distance of the drone from the obstacle, from the filtered signal(s) from the filtering module."
ROBOT AND OPERATING METHOD THEREOF,https://lens.org/026-938-835-208-098,2021,"A robot and an operating method thereof are provided. The robot includes a controller, a force sensor configured to be electrically connected to the controller, mounted in the robot, and sense an external force applied to the robot, an arm configured to be electrically connected to the controller so that an operation is controlled by the controller, an adsorber configured to adsorb a target object, and a coupler configured to couple the arm and the adsorber. The robot may transmit or receive a wireless signal on a mobile communication network constructed according to the 5G (generation) communication."
Robot and operating method thereof,https://lens.org/119-671-514-204-039,2021,"A robot and an operating method thereof are provided. The robot includes a controller, a force sensor configured to be electrically connected to the controller, mounted in the robot, and sense an external force applied to the robot, an arm configured to be electrically connected to the controller so that an operation is controlled by the controller, an adsorber configured to adsorb a target object, and a coupler configured to couple the arm and the adsorber. The robot may transmit or receive a wireless signal on a mobile communication network constructed according to the 5G (generation) communication."
INTELLIGENT DEVICE AND METHOD OF INFORMATION DISPLAYING WITH PROJECTION TYPE USING THE SAME,https://lens.org/143-541-295-259-885,2020,"According to the present invention, a method of displaying status information for a device to a user comprises receiving a control command for controlling the device to display the status information, determining the user's location, selecting other areas than where the user is located as mapping candidate areas, and selecting at least any one or more of the mapping candidate areas as a mapping area and displaying the status information in the mapping area in a projection fashion. Embodiments of the present invention may be related to artificial intelligence (AI) modules, unmanned aerial vehicles (UAVs), robots, augmented reality (AR) devices, virtual reality (VR) devices, and 5G service-related devices."
Intelligent device and method of information displaying with projection type using the same,https://lens.org/016-535-391-395-97X,2021,"According to the present invention, a method of displaying status information for a device to a user comprises receiving a control command for controlling the device to display the status information, determining the user's location, selecting other areas than where the user is located as mapping candidate areas, and selecting at least any one or more of the mapping candidate areas as a mapping area and displaying the status information in the mapping area in a projection fashion. Embodiments of the present invention may be related to artificial intelligence (AI) modules, unmanned aerial vehicles (UAVs), robots, augmented reality (AR) devices, virtual reality (VR) devices, and 5G service-related devices."
"Remote control, remote control system, and remote control method",https://lens.org/032-355-516-807-440,2018,"Provided is a remote control, including: a wireless communication unit configured to be capable of sending a control signal for controlling a device by means of wireless communication; and a determining unit configured to transmit a device detection request by means of the wireless communication unit, and to identify installation locations of a plurality of devices as one or more zones, respectively, based on responses from the plurality of devices having received the device detection request, each of the responses including measurement information reflecting an installation location."
REMOTE CONTROL FINDER,https://lens.org/037-684-934-453-883,2022,A device for locating a misplaced remote control of a media device. The device includes a transmitter unit for the media device and a receiver unit for the remote control. The receiver unit can be incorporated with the remote control and can include a buzzer. The transmitter unit can be triggered by a user for sending a signal. The receiver unit can capture the signal and upon receiving the signal triggers the buzzer. The user can follow the sound of the buzzer to locate the receiving unit and thus the remote control.
REMOTE CONTROL FINDER,https://lens.org/037-684-934-453-883,2022,A device for locating a misplaced remote control of a media device. The device includes a transmitter unit for the media device and a receiver unit for the remote control. The receiver unit can be incorporated with the remote control and can include a buzzer. The transmitter unit can be triggered by a user for sending a signal. The receiver unit can capture the signal and upon receiving the signal triggers the buzzer. The user can follow the sound of the buzzer to locate the receiving unit and thus the remote control.
UNMANNED AERIAL VEHICLE,https://lens.org/054-545-449-341-737,2021,"An unmanned aerial vehicle includes a frame, an avionics board assembly detachably mounted at a side of the frame, and a central board assembly detachably mounted at a top of the frame, spaced apart from the avionics board assembly, electrically connected to the avionics board assembly via a wire, and used to transfer at least one of a power signal or a communication signal. The avionics board assembly includes a flight controller used to control flight status of the unmanned aerial vehicle, and a positioning navigation device electrically connected to the flight controller and used to obtain current position information of the unmanned aerial vehicle."
METHOD AND APPARATUS FOR USING DRONES FOR ROAD AND TRAFFIC MONITORING,https://lens.org/029-368-086-219-300,2020,"An approach is provided for using aerial drones for road and traffic monitoring. The approach, for example, involves navigating an aerial drone to a physical marker located on a road link. The approach also involves initiating a capture of sensor data of the physical marker by a sensor of the aerial drone. The approach further involves adjusting a position, an altitude, or a combination thereof of the aerial drone to a reference position, a reference altitude, or a combination thereof over the physical marker based on the sensor data. The approach further involves initiating a capture of one or more images of the road link by the aerial drone at the reference position, the reference altitude, or a combination thereof. By way of example, the captured images can be processed for road and traffic monitoring and/or other similar applications."
Method and apparatus for using drones for road and traffic monitoring,https://lens.org/066-879-028-588-374,2021,"An approach is provided for using aerial drones for road and traffic monitoring. The approach, for example, involves navigating an aerial drone to a physical marker located on a road link. The approach also involves initiating a capture of sensor data of the physical marker by a sensor of the aerial drone. The approach further involves adjusting a position, an altitude, or a combination thereof of the aerial drone to a reference position, a reference altitude, or a combination thereof over the physical marker based on the sensor data. The approach further involves initiating a capture of one or more images of the road link by the aerial drone at the reference position, the reference altitude, or a combination thereof. By way of example, the captured images can be processed for road and traffic monitoring and/or other similar applications."
"METHOD, APPARATUS AND SYSTEM FOR USING DRONES FOR ROAD AND TRAFFIC MONITORING",https://lens.org/119-106-866-550-363,2020,"An approach is provided for using aerial drones for road and traffic monitoring. The approach, for example, involves navigating an aerial drone to a physical marker located on a road link. The approach also involves initiating a capture of sensor data of the physical marker by a sensor of the aerial drone. The approach further involves adjusting a position, an altitude, or a combination thereof of the aerial drone to a reference position, a reference altitude, or a combination thereof over the physical marker based on the sensor data. The approach further involves initiating a capture of one or more images of the road link by the aerial drone at the reference position, the reference altitude, or a combination thereof. By way of example, the captured images can be processed for road and traffic monitoring and/or other similar applications."
Unmanned vehicle civil communications systems and methods,https://lens.org/106-422-884-399-567,2015,"A mass notification push application and a civic-communication application combined into one with the primary purpose of allowing up-to-the-minute UAV aerial imagery as selected by drone ground-based commanders to be automatically transmitted to subscribed end-users via the current OS mobile operating systems for smartphones, iPads, laptops, and web-enabled devices in a manner comprised of separate technologies such as voice (voice to text, voice recognition), video stills (embedded with personalized iconographic identifiers), and with a secondary purpose of allowing the notified recipients to engage others by allowing the retransmitting of received messages along with (or without) registered user annotations so as to create a civil communications hub for wider, real-time dissemination of ongoing situational awareness data."
UNMANNED VEHICLE CIVIL COMMUNICATIONS SYSTEMS AND METHODS,https://lens.org/089-503-029-784-253,2012,"A mass notification push application and a civic-communication application combined into one with the primary purpose of allowing up-to-the-minute UAV aerial imagery as selected by drone ground-based commanders to be automatically transmitted to subscribed end-users via the current OS mobile operating systems for smartphones, iPads, laptops, and web-enabled devices in a manner comprised of separate technologies such as voice (voice to text, voice recognition), video stills (embedded with personalized iconographic identifiers), and with a secondary purpose of allowing the notified recipients to engage others by allowing the retransmitting of received messages along with (or without) registered user annotations so as to create a civil communications hub for wider, real-time dissemination of ongoing situational awareness data."
MULTI-MODAL AUDIO PROCESSING FOR VOICE-CONTROLLED DEVICES,https://lens.org/069-828-853-027-584,2021,"A voice-controlled device includes a microphone to receive a set of sound waves that includes speech uttered by a user and other sound, and to output a first audio signal that includes a contribution from the speech uttered by the user and a contribution from the other sound. The device also includes a receiver to receive an electromagnetic signal and to output a second audio signal obtained from the electromagnetic signal. An audio pre-processor of the device processes the first audio signal using the second audio signal to reduce the contribution from the other sound in a processed audio signal. The voice-controlled device then provides the processed audio signal to a speech recognition module to determine a voice command issued by the user."
MULTI-MODAL AUDIO PROCESSING FOR VOICE-CONTROLLED DEVICES,https://lens.org/057-270-569-781-365,2023,"A voice-controlled device includes a microphone to receive a set of sound waves that includes speech uttered by a user and other sound, and to output a first audio signal that includes a contribution from the speech uttered by the user and a contribution from the other sound. The device also includes a receiver to receive an electromagnetic signal and to output a second audio signal obtained from the electromagnetic signal. An audio pre-processor of the device processes the first audio signal using the second audio signal to reduce the contribution from the other sound in a processed audio signal. The voice-controlled device then provides the processed audio signal to a speech recognition module to determine a voice command issued by the user."
"REMOTE CONTROL REQUEST SYSTEM, REMOTE CONTROL REQUEST METHOD, AND NONTRANSITORY STORAGE MEDIUM",https://lens.org/022-058-619-132-606,2022,"A remote control request method has requesting, by a computer, a remote operator to perform remote control on an autonomous driving vehicle when the autonomous driving vehicle currently has or is expected to have difficulty in continuing autonomous driving, requesting remote assistance in which the remote operator makes at least a part of determination for the autonomous driving inside an autonomous driving domain, and requesting, outside the autonomous driving domain, remote driving in which the remote operator performs at least one of a steering operation and an acceleration or deceleration operation of the autonomous driving vehicle."
Method and system of recovering lost mobile devices,https://lens.org/075-538-381-100-385,2013,"An approach is provided for remotely controlling and/or tracking mobile devices. A request is received to track a mobile device. A control signal is generated, in response to the request, to remotely activate an application on the mobile device for controlling an audio interface or an imaging interface of the mobile device to capture a signal from the audio interface or the imaging interface."
METHOD AND SYSTEM OF RECOVERING LOST MOBILE DEVICES,https://lens.org/150-619-639-257-375,2011,"An approach is provided for remotely controlling and/or tracking mobile devices. A request is received to track a mobile device. A control signal is generated, in response to the request, to remotely activate an application on the mobile device for controlling an audio interface or an imaging interface of the mobile device to capture a signal from the audio interface or the imaging interface."
MULTI-PURPOSE UNMANNED AERIAL VEHICLE FOR SENSING RADIATION AND CARBON-MONOXIDE GAS WITH LIVE AERIAL VIDEO FEEDING,https://lens.org/151-183-354-833-422,2015,"A fully functional quad-rotor helicopter capable of autonomous hover and directional motion based on operator inputs is disclosed here. Total weight of the system shall be nearly a kilogram or little more. The purpose is to produce an unmanned aerial vehicle, which shall be capable of sensing radiation and carbon-monoxide gas present in the given environment. Another objective of this invention is to monitor radiation exposure in a place where nuclear activity exists, and where human life is endangered."
CIRCULAR LIGHT SOURCE FOR OBSTACLE DETECTION,https://lens.org/097-551-077-919-665,2018,"It discloses an apparatus, a drone, a system and a method. The apparatus comprises: a light source adapted to emit light; a beam-shaping element adapted to project the light to substantially surround the apparatus in a plane, the light being projected onto an object (402a) in the plane and reflected; a reception element (403) adapted to project the light reflected from the object (402a) in the plane to an image sensor (404), wherein a distortion parameter of the reception element (403) in conjunction with a difference between the emitted light and the reflected light detected at the image sensor (404) is indicative of at least one of direction and distance of the apparatus relative to the object (402a). The apparatus can detect obstacles from all directions."
"CONTROL DEVICE, PROGRAM, SYSTEM, AND METHOD",https://lens.org/148-640-192-057-792,2023,"Provided is a control device including a location information reception unit which receives, via a communication device, location information of a user terminal from the terminal in a wireless communication area, a detection device control unit which controls a detection device of a flying object to detect a state of a region including a location indicated by the location information, a detection information reception unit which receives, via the communication device, detection information indicating the state, an unmanned aerial vehicle control unit which controls an unmanned aerial vehicle to capture an image around the location by an image capturing unit of the vehicle based on the detection information, a captured image reception unit which receives a captured image captured by the image capturing unit from the vehicle, and a rescue method decision unit which decides a rescue method of rescuing a user of the terminal based on the image."
DISPERSION AIRCRAFT,https://lens.org/129-309-065-432-087,2020,"Drone for dispersing capsules containing biological active agents for combatting pests, including propulsion means ensuring movement of the aircraft in a horizontal direction parallel with the ground and a capsule distributing and jettisoning system with a vertical ejector, for in-flight ejection of the capsules toward the ground in a direction perpendicular to the horizontal direction of movement of the drone. Taking into account the movement direction of the drone, the vertical ejector is positioned in front of the propulsion means, and the capsule distribution and jettisoning system includes a capsule reservoir which is connected to an element for guiding the capsules toward a capsule counting and metering system including a plate for selecting and separating the capsules, the plate having holes calibrated for the passage of a single capsule toward the vertical jettisoning ejector and being mounted for rotation relative to the vertical ejector via a thrust generating motor."
VEHICLE-MOUNTED AERIAL DRONE CONTAINER,https://lens.org/059-665-534-847-458,2018,"A system comprising a computer programed to identify a connected location of a vehicle at which a user device is connected to a first network and a disconnected location of the vehicle at which the user device is disconnected from the first network. Upon further determining that the user device has not connected to a second network within a first predetermined time, the computer is further programmed to activate an aerial drone container to an open position."
"INFORMATION PROCESSING SYSTEM, INFORMATION PROCESSING METHOD, AND PROGRAM",https://lens.org/182-635-138-556-212,2021,"To effectively reduce an influence of an environment in flight (including taking-off and landing) of a flying object. A main drone current position information acquisition unit 131 acquires a current position of a main drone 2 from a main drone control terminal 4 through a communication unit 39, and provides the current position to the movement instruction unit 133. The sub-drone current position information acquisition unit 132 acquires a current position of the sub-drone 1 from the sub-drone 1 through the communication unit 39, and provides the current position to the movement instruction unit 133. The movement instruction unit 133 determines a movement position of the sub-drone 1 on the basis of the current position of the main drone 2. In addition, the movement instruction unit 133 generates a movement instruction for the sub-drone 1 on the basis of a difference between the current position and the movement position of the sub-drone 1, and transmits the movement instruction to the sub-drone 1 through the communication unit 39. The drive control unit 111 acquires the movement instruction transmitted from the sub-drone control terminal 3 through a communication unit 18."
Remote controlled decoy,https://lens.org/170-057-643-272-379,1995,A remotely controlled floating decoy having a buoyant body resembling a game bird and having a receiver disposed within the buoyant body. The receiver is responsive to commands from a transmitter and provides electrical control signals to a plurality of servomechanisms and associated linkages in response to the commands. The apparatus also has a propulsive device coupled to the buoyant body and electrically coupled to the receiver. The propulsive device is responsive to the electrical control signals. The apparatus also has a rudder coupled to a rear end of the buoyant body. The rudder is responsive to the electrical control signals. The propulsive device and the rudder cooperate to provide directed locomotion for the buoyant body in response to commands transmitted from the transmitter.
LINE OF SIGHT MAINTENANCE DURING OBJECT TRACKING,https://lens.org/047-522-814-793-227,2021,The presently disclosed subject matter includes a system and method that provides autonomous flight monitoring and control over an aircraft that assists in maintaining continuous object tracking by a sensing device (e.g. imaging payload such as a camera) mounted on the aircraft (e.g. UAV) and reduce the likelihood of line of sight obstruction or interception while tracking an object.
LINE OF SIGHT MAINTENANCE DURING OBJECT TRACKING,https://lens.org/136-812-069-414-785,2021,The presently disclosed subject matter includes a system and method that provides autonomous flight monitoring and control over an aircraft that assists in maintaining continuous object tracking by a sensing device (e.g. imaging payload such as a camera) mounted on the aircraft (e.g. UAV) and reduce the likelihood of line of sight obstruction or interception while tracking an object.
Flexible floating gate device of intelligence remote control,https://lens.org/064-893-694-469-279,2016,"The utility model discloses a flexible floating gate device of intelligence remote control, including control aircraft nose, the flexible door body and surface railway, the first end of controller passes through the drive shaft and links to each other with the flexible door body, the inside driving motor that is provided with of control aircraft nose, the overhead side of controller is provided with control box, be provided with a plurality ofly with the gatepost on the flexible door body, control aircraft nose and flexible men tidian connect, the flexible door body and control aircraft nose bottom are provided with the guide pulley, surface railway installs in the guide pulley below. The control aircraft nose adopts and to press that the knob is automatically controlled, one kind or A variety of control in wireless remote control, infra red ray induction and the smart card, under the state that loses the electricity, the electrically operated gate also can be under manually operation, and free and relaxed operation is adopted and has been realized different management demands according to automatically controlled, the wireless remote control of knob, infra red ray induction and smart card automatic control, and surface railway is makeed by high -quality shaped steel, and is sturdy and durable, indeformable, stand wear and tear."
System and Method For Controlling Devices in a Home-Automation Network,https://lens.org/136-135-803-384-125,2008,A home-automation system ( 108 ) and method ( 300 ) for controlling at least one device of a plurality of devices in a home-automation network ( 104 ) are disclosed. The home-automation system includes a receiver ( 202 ) configured to receive a signal indicative of location a user. The user is located beyond the proximity of the home being automated by the home-automation network. The home-automation system also includes a processor ( 208 ) adapted to control the at least one device of the plurality of devices in response to the received indicative signal.
"System for guiding a drone during the approach phase to a platform, in particular a naval platform, with a view to landing same",https://lens.org/065-822-823-779-029,2014,"The invention relates to a system for guiding a drone during the approach phase to a platform, in particular a naval platform, with a view to landing same, characterised in that the platform is provided with equipment indicating the angle of descent, emitting an array of optical guide beams onto an angular sector predetermined from the horizontal, and in that the drone is provided with a camera (6) for acquiring the beam and which is connected to an image analysis means (7) and a means (8) for computing command orders sent to an automatic flight means (9) of the drone, in order to prompt the drone to follow the guide beams."
AUTONOMOUS VEHICLE WITH AUTOMATED FOLLOWING OF PERSON OUTSIDE VEHICLE,https://lens.org/146-731-642-379-045,2023,"An autonomous vehicle operates in a Follow Mode, wherein an apparatus for controlling movement of a vehicle includes an exterior monitoring system comprising at least one sensor to monitor an exterior region and to detect a location of a target user. A controller is configured to A) interactively map an activity zone having a selected expanse in the exterior region relative to the vehicle, B) compare a monitored location of the target user to the activity zone, C) detect a relocation event when the comparison of the monitored location of the target user to the activity zone exceeds a predetermined deviation, and D) send a navigation command in response to detecting the relocation event in order to autonomously reposition the vehicle so that a relative location of the target user is restored to the activity zone."
DRONE,https://lens.org/017-140-437-242-021,2022,"A drone includes a frame and a fuselage. The fuselage is coupled to the frame extending away from the frame. The fuselage has a front panel and a bottom panel, and the front panel is positioned at an angle between the bottom surface of the frame and the bottom panel of the fuselage. A first wing is opposite a second wing and are coupled to the frame. The first and second wings extend outwardly from opposite sides of the frame. A first and second mounting member are coupled to the frame and extend outwardly from opposite sides of the frame. A plurality of power generator systems are included and each system is coupled to the first or second mounting member. Each power generator system comprises a power source coupled to a propeller."
DRONE,https://lens.org/116-279-883-397-328,2021,"A drone includes a frame and a fuselage. The fuselage is coupled to the frame extending away from the frame. The fuselage has a front panel and a bottom panel, and the front panel is positioned at an angle between the bottom surface of the frame and the bottom panel of the fuselage. A first wing is opposite a second wing and are coupled to the frame. The first and second wings extend outwardly from opposite sides of the frame. A first and second mounting member are coupled to the frame and extend outwardly from opposite sides of the frame. A plurality of power generator systems are included and each system is coupled to the first or second mounting member. Each power generator system comprises a power source coupled to a propeller."
Drone,https://lens.org/165-290-863-988-555,2022,"A drone includes a frame and a fuselage. The fuselage is coupled to the frame extending away from the frame. The fuselage has a front panel and a bottom panel, and the front panel is positioned at an angle between the bottom surface of the frame and the bottom panel of the fuselage. A first wing is opposite a second wing and are coupled to the frame. The first and second wings extend outwardly from opposite sides of the frame. A first and second mounting member are coupled to the frame and extend outwardly from opposite sides of the frame. A plurality of power generator systems are included and each system is coupled to the first or second mounting member. Each power generator system comprises a power source coupled to a propeller."
Launchable remote-control attack device,https://lens.org/000-495-857-314-365,2014,"Provided is a launchable remote-control attack device that enables an operator to remotely grasp the status of a target place and to remotely control weapons it has been equipped with to perform an attack using explosives or gas when necessary. The remote-control attack device includes a cylindrical body with a camera, drivers which are made up of two tires that are disposed on opposite sides of the body and can be driven individually, and battery units for supplying power and which are disposed in central openings of the tires of the drivers. The attack device further includes a plurality of storage units and a wireless control unit."
LAUNCHABLE REMOTE-CONTROL ATTACK DEVICE,https://lens.org/197-908-247-763-072,2012,"Provided is a launchable remote-control attack device that enables an operator to remotely grasp the status of a target place and to remotely control weapons it has been equipped with to perform an attack using explosives or gas when necessary. The remote-control attack device includes a cylindrical body with a camera, drivers which are made up of two tires that are disposed on opposite sides of the body and can be driven individually, and battery units for supplying power and which are disposed in central openings of the tires of the drivers. The attack device further includes a plurality of storage units and a wireless control unit."
Aerial vehicle delivery location,https://lens.org/077-243-080-958-737,2021,"This disclosure describes an unmanned aerial vehicle (UAV) configured to autonomously deliver items of inventory to various destinations. The UAV may receive inventory information and a destination location and autonomously retrieve the inventory from a location within a materials handling facility, compute a route from the materials handling facility to a destination and travel to the destination to deliver the inventory."
Aerial vehicle delivery of items available through an E-commerce shopping site,https://lens.org/022-382-357-998-69X,2019,"This disclosure describes an unmanned aerial vehicle (UAV) configured to autonomously deliver items of inventory to various destinations. The UAV may receive inventory information and a destination location and autonomously retrieve the inventory from a location within a materials handling facility, compute a route from the materials handling facility to a destination and travel to the destination to deliver the inventory."
Unmanned aerial vehicle delivery system,https://lens.org/080-091-311-330-372,2017,"This disclosure describes an unmanned aerial vehicle (UAV) configured to autonomously deliver items of inventory to various destinations. The UAV may receive inventory information and a destination location and autonomously retrieve the inventory from a location within a materials handling facility, compute a route from the materials handling facility to a destination and travel to the destination to deliver the inventory."
AERIAL VEHICLE DELIVERY OF ITEMS AVAILABLE THROUGH AN E-COMMERCE SHOPPING SITE,https://lens.org/019-456-307-102-155,2017,"This disclosure describes an unmanned aerial vehicle (UAV) configured to autonomously deliver items of inventory to various destinations. The UAV may receive inventory information and a destination location and autonomously retrieve the inventory from a location within a materials handling facility, compute a route from the materials handling facility to a destination and travel to the destination to deliver the inventory."
AERIAL VEHICLE DELIVERY LOCATION,https://lens.org/175-569-696-928-950,2022,"This disclosure describes an unmanned aerial vehicle (UAV) configured to autonomously deliver items of inventory to various destinations. The UAV may receive inventory information and a destination location and autonomously retrieve the inventory from a location within a materials handling facility, compute a route from the materials handling facility to a destination and travel to the destination to deliver the inventory."
AERIAL VEHICLE DELIVERY LOCATION,https://lens.org/106-832-920-123-27X,2019,"This disclosure describes an unmanned aerial vehicle (UAV) configured to autonomously deliver items of inventory to various destinations. The UAV may receive inventory information and a destination location and autonomously retrieve the inventory from a location within a materials handling facility, compute a route from the materials handling facility to a destination and travel to the destination to deliver the inventory."
Aerial vehicle delivery location,https://lens.org/069-732-842-112-269,2023,"This disclosure describes an unmanned aerial vehicle (UAV) configured to autonomously deliver items of inventory to various destinations. The UAV may receive inventory information and a destination location and autonomously retrieve the inventory from a location within a materials handling facility, compute a route from the materials handling facility to a destination and travel to the destination to deliver the inventory."
Drone detection using multi-sensory arrays,https://lens.org/133-411-283-214-331,2022,"A system and method for detection of an aerial drone in an environment includes a baseline of geo-mapped sensor data in a temporal and location indexed database formed by (i) using at least one sensor to receive signals from the environment and converting into digital signals for further processing; (ii) deriving time delays, object signatures, Doppler shifts, reflectivity, and/or optical characteristics from the received signals; (iii) geo-mapping the environment using GNSS and the sensor data; and (iv) logging sensor data over a time interval, for example 24 hours to 7 days. Live sensor data can be then be monitored and signature data can be derived by computing at least one parameter such as direction and signal strength. The live data is continuously or periodically compared to the baseline data to identify a variance, if any, which may be indicative of a detection event."
DRONE DETECTION USING MULTI-SENSORY ARRAYS,https://lens.org/019-304-317-707-948,2020,"A system and method for detection of an aerial drone in an environment includes a baseline of geo-mapped sensor data in a temporal and location indexed database formed by (i) using at least one sensor to receive signals from the environment and converting into digital signals for further processing; (ii) deriving time delays, object signatures, Doppler shifts, reflectivity, and/or optical characteristics from the received signals; (iii) geo-mapping the environment using GNSS and the sensor data; and (iv) logging sensor data over a time interval, for example 24 hours to 7 days. Live sensor data can be then be monitored and signature data can be derived by computing at least one parameter such as direction and signal strength. The live data is continuously or periodically compared to the baseline data to identify a variance, if any, which may be indicative of a detection event."
Drone detection using multi-sensory arrays,https://lens.org/133-411-283-214-331,2022,"A system and method for detection of an aerial drone in an environment includes a baseline of geo-mapped sensor data in a temporal and location indexed database formed by (i) using at least one sensor to receive signals from the environment and converting into digital signals for further processing; (ii) deriving time delays, object signatures, Doppler shifts, reflectivity, and/or optical characteristics from the received signals; (iii) geo-mapping the environment using GNSS and the sensor data; and (iv) logging sensor data over a time interval, for example 24 hours to 7 days. Live sensor data can be then be monitored and signature data can be derived by computing at least one parameter such as direction and signal strength. The live data is continuously or periodically compared to the baseline data to identify a variance, if any, which may be indicative of a detection event."
Unmanned Aerial Vehicles,https://lens.org/173-950-517-711-909,2018,"An unmanned aerial vehicle (UAV) 100, comprises: a camera 105 having a field of vision including, in use, a portion of a vehicle to be cleaned; a liquid container 110; a liquid dispenser 115 operable to cause liquid to be dispensed from the liquid container 110; a cleaning implement 120; and a controller 125 communicatively coupled to the camera 105, the liquid dispenser 115 and the cleaning implement 120. The controller 125 is operable to: cause the UAV 100 to blow air over the portion of the vehicle to be cleaned, in order to cool the portion of the vehicle to be cleaned; then cause the liquid dispenser 115 to dispense liquid from the liquid container 110 onto the portion of the vehicle to be cleaned; and then control the cleaning implement 120 to clean the portion of the vehicle to be cleaned. The liquid comprises waterless carwash liquid. The use of waterless carwash liquid may reduce the necessary capacity of the liquid container 110. The cleaning implement 120 may comprise a microfiber cloth or a terrycloth."
Remote controlled camera system,https://lens.org/005-353-629-827-909,1993,"A camera operated by a remote control device includes a zoom lens. The camera has a plurality of photographing modes. In a first mode, an object is photographed at a predetermined magnification and in a second mode, the object is photographed together with the background thereof. A desired photographing can be taken in response to a signal from the remote control device. Furthermore, the camera can rotate to upward, downward, rightward and leftward by a signal from the remote control device."
"Photographing control method, apparatus, and control device",https://lens.org/081-527-003-471-801,2023,"A method for an unmanned aerial vehicle (UAV) includes: identifying a target object in a photographed image to track the target object; determining, based on a location of the target object in the photographed image, a location of the UAV, and an altitude of a gimbal of the UAV, a location of the target object to continuously record the location of the target object; and in response to a disappearance of the target object in the photographed image, controlling, according to the recorded location of the target object prior to the disappearance of the target object, the altitude of the gimbal such that a photographing device carried by the UAV through the gimbal continues to photograph in a direction from the photographing device to the location of target object."
"Photographing control method, apparatus, and control device",https://lens.org/081-527-003-471-801,2023,"A method for an unmanned aerial vehicle (UAV) includes: identifying a target object in a photographed image to track the target object; determining, based on a location of the target object in the photographed image, a location of the UAV, and an altitude of a gimbal of the UAV, a location of the target object to continuously record the location of the target object; and in response to a disappearance of the target object in the photographed image, controlling, according to the recorded location of the target object prior to the disappearance of the target object, the altitude of the gimbal such that a photographing device carried by the UAV through the gimbal continues to photograph in a direction from the photographing device to the location of target object."
"PHOTOGRAPHING CONTROL METHOD, APPARATUS, AND CONTROL DEVICE",https://lens.org/189-150-091-402-265,2021,"A method for an unmanned aerial vehicle (UAV) includes: identifying a target object in a photographed image to track the target object; determining, based on a location of the target object in the photographed image, a location of the UAV, and an altitude of a gimbal of the UAV, a location of the target object to continuously record the location of the target object; and in response to a disappearance of the target object in the photographed image, controlling, according to the recorded location of the target object prior to the disappearance of the target object, the altitude of the gimbal such that a photographing device carried by the UAV through the gimbal continues to photograph in a direction from the photographing device to the location of target object."
Mapping and control system for an aerial vehicle,https://lens.org/106-546-338-493-470,2020,"A mapping and control system for an aerial vehicle, the system including a payload attachable to the aerial vehicle, the payload including: a range sensor that generates range data indicative of a range to an environment; a memory for storing flight plan data indicative of a desired flight plan; a communications interface; and one or more processing devices that: use the range data to generate pose data indicative of position and orientation of the payload relative to the environment; use the pose data and the flight plan data to identify manoeuvres; generate control instructions; and transfer the control instructions to a vehicle control system of the aerial vehicle via the communications interface, to cause the aerial vehicle to implement the manoeuvres and thereby fly autonomously in accordance with the desired flight plan, wherein the range data is further for use in generating a map of the environment."
Mapping and Control System for an Aerial Vehicle,https://lens.org/000-936-975-548-868,2021,"A mapping and control system for an aerial vehicle, the system including a payload attachable to the aerial vehicle, the payload including: a range sensor that generates range data indicative of a range to an environment; a memory for storing flight plan data indicative of a desired flight plan; a communications interface; and one or more processing devices that: use the range data to generate pose data indicative of position and orientation of the payload relative to the environment; use the pose data and the flight plan data to identify manoeuvres; generate control instructions; and transfer the control instructions to a vehicle control system of the aerial vehicle via the communications interface, to cause the aerial vehicle to implement the manoeuvres and thereby fly autonomously in accordance with the desired flight plan, wherein the range data is further for use in generating a map of the environment."
SAFETY DEVICE AND CRASH PREVENTING DRONE COMPRISING SAME,https://lens.org/002-452-338-576-008,2018,"A drone according to an embodiment may comprise: a support table; a main unit spaced from the support table and formed above the support table; a connecting portion for connecting the main unit and the support table; and a propulsion unit provided on the outer side of the support table so as to generate thrust. The main unit may have a through-hole formed therein, a parachute may be provided inside the through-hole, and, during a fall, the parachute may be discharged out of the through-hole by deformation of the connecting portion."
Safety device and crash preventing drone comprising same,https://lens.org/052-106-611-577-629,2020,"A drone according to an embodiment may comprise: a support table; a main unit spaced from the support table and formed above the support table; a connecting portion for connecting the main unit and the support table; and a propulsion unit provided on the outer side of the support table so as to generate thrust. The main unit may have a through-hole formed therein, a parachute may be provided inside the through-hole, and, during a fall, the parachute may be discharged out of the through-hole by deformation of the connecting portion."
SAFETY DEVICE AND CRASH PREVENTING DRONE COMPRISING SAME,https://lens.org/048-361-113-151-872,2018,"A drone according to an embodiment may comprise: a support table; a main unit spaced from the support table and formed above the support table; a connecting portion for connecting the main unit and the support table; and a propulsion unit provided on the outer side of the support table so as to generate thrust. The main unit may have a through-hole formed therein, a parachute may be provided inside the through-hole, and, during a fall, the parachute may be discharged out of the through-hole by deformation of the connecting portion."
Robot and method of controlling the same,https://lens.org/156-143-859-935-972,2010,A robot and a method for controlling the same are provided. The robot includes a first control unit to control the overall operation of the robot and a second control unit to supplement the function of the control unit in preparation for the malfunction of the first control unit such that the second control unit controls the robot to perform a predetermined safety-considered motion when the first control unit malfunctions.
Robot and method of controlling the same,https://lens.org/146-318-441-456-578,2014,A robot and a method for controlling the same are provided. The robot includes a first control unit to control the overall operation of the robot and a second control unit to supplement the function of the control unit in preparation for the malfunction of the first control unit such that the second control unit controls the robot to perform a predetermined safety-considered motion when the first control unit malfunctions.
VOICE-CONTROLLED CONFIGURATION OF AN AUTOMATION SYSTEM,https://lens.org/045-154-358-087-118,2014,"Methods and apparatus are provided for configuring control of an automation system for a home or other space, using audio input to a controller. Activation of an appliance in the automation system initiates the providing of the capabilities of the appliance to the controller and a data collection process via an audible interface. Audible user input is converted to an audio signal, and then processed by the controller to determine control input for the appliance. The audible input may also be used for user authentication. Subsequently, the controller controls the appliance based on the control input."
VOICE-CONTROLLED CONFIGURATION OF AN AUTOMATION SYSTEM,https://lens.org/014-191-219-142-349,2015,"Methods and apparatus are provided for configuring control of an automation system for a home or other space, using audio input to a controller. Activation of an appliance in the automation system initiates the providing of the capabilities of the appliance to the controller and a data collection process via an audible interface. Audible user input is converted to an audio signal, and then processed by the controller to determine control input for the appliance. The audible input may also be used for user authentication. Subsequently, the controller controls the appliance based on the control input."
UNMANNED AERIAL VEHICLE SYSTEM AND METHOD,https://lens.org/065-921-363-807-685,2020,"An unmanned aerial vehicle system includes an unmanned aerial vehicle and a remote controller, where the unmanned aerial vehicle includes a first controller unit configured to determine whether the unmanned aerial vehicle can pair via a first communication unit with the remote controller, and when the unmanned aerial vehicle cannot pair with the remote controller, to send out via a second communication unit pairing information of the unmanned aerial vehicle and version information of a first private communication protocol of the first communication unit, and the remote controller includes a second controller unit configured to determine whether the remote controller can pair via a third communication unit with the unmanned aerial vehicle, and when the remote controller cannot pair with the unmanned aerial vehicle, to send out via a first communication interface pairing information of the remote controller and version information of a second private communication protocol of the third communication unit."
Unmanned aerial vehicle system and method,https://lens.org/105-487-934-388-032,2022,"An unmanned aerial vehicle system includes an unmanned aerial vehicle and a remote controller, where the unmanned aerial vehicle includes a first controller unit configured to determine whether the unmanned aerial vehicle can pair via a first communication unit with the remote controller, and when the unmanned aerial vehicle cannot pair with the remote controller, to send out via a second communication unit pairing information of the unmanned aerial vehicle and version information of a first private communication protocol of the first communication unit, and the remote controller includes a second controller unit configured to determine whether the remote controller can pair via a third communication unit with the unmanned aerial vehicle, and when the remote controller cannot pair with the unmanned aerial vehicle, to send out via a first communication interface pairing information of the remote controller and version information of a second private communication protocol of the third communication unit."
IMAGE SENSOR SYSTEM AND AUTONOMOUS DRIVING SYSTEM USING THE SAME,https://lens.org/094-039-101-963-892,2020,"Provided are a camera, a control method thereof, and an autonomous driving system including the camera. The camera includes an active filter electrically controlled to allow light having an infrared wavelength to pass therethrough and block the light having the infrared wavelength, an image sensor converting light passing through the active filter into an electrical signal and outputting an image signal, an image analyzer analyzing the image signal obtained from the image sensor, and a filter controller selecting a wavelength of light passing through the active filter by electrically controlling an operation mode of the active filter on the basis of a result of analyzing the image signal. According to the lidar system, an autonomous vehicle, an Al device, and an external device may be linked with an artificial intelligence module, a drone, a robot, an Augmented Reality device, a Virtual Reality device, a device associated with 5G services, etc."
Air traffic communication,https://lens.org/006-306-091-233-934,2020,"Apparatus and methods related to autonomous aerial communications are included. A computing device can detect data associated with relevant events, determine information related to the event that should be communicated and a target aerial vehicle for that information, identify one or more operational parameters of the target aerial vehicle, and, based on those operational parameters, select a language associated with the target aerial vehicle, and generate and transmit a message expressing that information in the selected language to the target aerial vehicle."
AIR TRAFFIC COMMUNICATION,https://lens.org/037-985-963-617-030,2018,"Apparatus and methods related to autonomous aerial communications are included. A computing device can detect data associated with relevant events, determine information related to the event that should be communicated and a target aerial vehicle for that information, identify one or more operational parameters of the target aerial vehicle, and, based on those operational parameters, select a language associated with the target aerial vehicle, and generate and transmit a message expressing that information in the selected language to the target aerial vehicle."
Anti-drone system,https://lens.org/193-888-518-398-089,2020,An anti-drone system 10 comprises a detecting unit 12 and a defeating unit 14. The detecting unit 12 comprises at least one sensor 16 for detecting a drone. The defeating unit 14 comprises means for mitigating a threat of the detected drone. The detecting unit may comprise two or more Radio Frequency sensors. One sensor may be omnidirectional and a second may be a directional radio frequency sensor. An a lert may be generated if a drone crosses a geo-fence. The defeating unit may be a radio transmitter configured to transmit one or more frequencies within the communication bandwidth of a pilot and the drone. False location information may be transmitted to the drone.
SURVEYING AND TARGET TRACKING BY A NETWORK OF SURVEY DEVICES,https://lens.org/183-304-553-169-711,2015,"A survey device includes a dual-axis position encoder, a video camera coupled, a laser rangefinder, a wireless transceiver, and a processor. The processor is configured to autonomously orient the video camera via the dual-axis position encoder, autonomously identify other survey devices and a target that are within a line-of-sight field-of-view of the video camera, operate the laser rangefinder to determine range to the autonomously identified target and the autonomously identified other survey devices, and determining coordinates of the autonomously identified target and the autonomously identified other survey devices based on the dual-axis position encoder."
SURVEYING AND TARGET TRACKING BY A NETWORK OF SURVEY DEVICES,https://lens.org/197-747-121-343-481,2015,"A survey device includes a dual-axis position encoder, a video camera coupled, a laser rangefinder, a wireless transceiver, and a processor. The processor is configured to autonomously orient the video camera via the dual-axis position encoder, autonomously identify other survey devices and a target that are within a line-of-sight field-of-view of the video camera, operate the laser rangefinder to determine range to the autonomously identified target and the autonomously identified other survey devices, and determining coordinates of the autonomously identified target and the autonomously identified other survey devices based on the dual-axis position encoder."
Surveying and target tracking by a network of survey devices,https://lens.org/195-424-242-634-956,2016,"A survey device includes a dual-axis position encoder, a video camera coupled, a laser rangefinder, a wireless transceiver, and a processor. The processor is configured to autonomously orient the video camera via the dual-axis position encoder, autonomously identify other survey devices and a target that are within a line-of-sight field-of-view of the video camera, operate the laser rangefinder to determine range to the autonomously identified target and the autonomously identified other survey devices, and determining coordinates of the autonomously identified target and the autonomously identified other survey devices based on the dual-axis position encoder."
DEVICE AND METHOD FOR AUTOMATED POSITIONING OF AN UNMANNED AERIAL VEHICLE UPON A LANDING PLATFORM,https://lens.org/032-898-508-852-664,2018,"The purpose of the invention is to create a device and a method to allow for automated positioning of an unmanned aerial vehicle on a landing platform. The device comprises of a landing platform with a landing base and a landing surface which is connected to a vibration generating device either fully or in part. The unmanned aerial vehicle, landed on the landing base, is positioned to the desired location and position on it by vibration. Sensors of the landing base are used to detect the location and position of the unmanned aerial vehicle with respect to the desired location on the landing base."
POWERING OF DRONE CARRYING BASE STATION TRANSCEIVER,https://lens.org/087-319-975-367-437,2020,"A drone is described. The drone includes a propulsion system, a base station transceiver, a tether connector, and a power system. The power system has a battery and a chopper circuit. The chopper circuit bleeds excess charge from the battery. The power system is configured to power the propulsion system, and to power the base station transceiver through the chopper circuit. The power system is also configured to receive electrical power, through the tether connector, to charge the battery while the drone is in the air."
AERIAL MARINE DRONE SYSTEM AND METHOD,https://lens.org/181-410-043-991-007,2023,"A marine drone system utilizing an unmanned aerial vehicle to provide visual feedback for conditions including temperature, depth, and conditions which may suggest favorable fishing conditions, such as weed lines, flotsam, breaks, and objects, such as birds or fish. The system utilizes a plurality of sensors, including, but not limited to, cameras, laser, GPS, radar, and LIDAR. The visual feedback may be shown as a video fees or a map, wherein the feedback is shown as a visual backgrounds, wherein an overlay of interactive functions provides information regarding the conditions. The system also includes method steps for implementing, obtaining, and displaying the information. The system hardware includes the unmanned aerial vehicle, a base station, and a hardwired tether between the unmanned aerial vehicle and the base station providing power and bi-directional data transfer."
AERIAL MARINE DRONE SYSTEM AND METHOD,https://lens.org/181-410-043-991-007,2023,"A marine drone system utilizing an unmanned aerial vehicle to provide visual feedback for conditions including temperature, depth, and conditions which may suggest favorable fishing conditions, such as weed lines, flotsam, breaks, and objects, such as birds or fish. The system utilizes a plurality of sensors, including, but not limited to, cameras, laser, GPS, radar, and LIDAR. The visual feedback may be shown as a video fees or a map, wherein the feedback is shown as a visual backgrounds, wherein an overlay of interactive functions provides information regarding the conditions. The system also includes method steps for implementing, obtaining, and displaying the information. The system hardware includes the unmanned aerial vehicle, a base station, and a hardwired tether between the unmanned aerial vehicle and the base station providing power and bi-directional data transfer."
METHOD FOR GENERATING A TARGET TRAJECTORY OF A CAMERA EMBARKED ON A DRONE AND CORRESPONDING SYSTEM,https://lens.org/149-142-959-065-486,2016,"For generating a target trajectory of a drone equipped with a vehicle, the drone moving in an indoor or outdoor environment, the method comprises acquiring (S1) an approximate trajectory of the target trajectory by moving manually an object in the environment and capturing the movement of the object; identifying (S2), in the approximate trajectory, at least one trajectory segment corresponding substantially to at least one predefined camera movement pattern; and replacing (S3) the at least one trajectory segment by the at least one predefined camera movement pattern in order to get the target trajectory. The manual acquisition of a first trajectory which is an approximate trajectory of the target trajectory in the real environment allows taking into account obstacles in the real environment without having to describe these obstacles in software to prepare the shoot."
Method for generating a target trajectory of a camera embarked on a drone and corresponding system,https://lens.org/047-315-693-170-266,2016,"For generating a target trajectory of a drone equipped with a vehicle, the drone moving in an indoor or outdoor environment, the method comprises acquiring (S1) an approximate trajectory of the target trajectory by moving manually an object in the environment and capturing the movement of the object; identifying (S2), in the approximate trajectory, at least one trajectory segment corresponding substantially to at least one predefined camera movement pattern; and replacing (S3) the at least one trajectory segment by the at least one predefined camera movement pattern in order to get the target trajectory. The manual acquisition of a first trajectory which is an approximate trajectory of the target trajectory in the real environment allows taking into account obstacles in the real environment without having to describe these obstacles in software to prepare the shoot."
"CAMERA CALIBRATION SYSTEM, CAMERA CALIBRATION METHOD, AND NON-TRANSITORY MEDIUM",https://lens.org/168-389-649-189-970,2020,"A camera calibration system includes a server, a camera communicatively coupled to the server, a drone communicatively coupled to the server, and an identification pattern coupled to the drone. The server controls the drone to fly in front of the camera at a calibration distance according to position and orientation information of the camera and position information and a distance setting rule of the drone, controls the camera to acquire at least one image of the identification pattern at each of the plurality of positions, and obtains parameters of the camera by performing calibration on the camera according to the acquired plurality of images. The drone flies in a number of positions at the calibration distance and flies in at least one plane."
ROBOT SYSTEM AND METHOD FOR PRODUCING TO-BE-PROCESSED MATERIAL,https://lens.org/036-680-782-889-578,2014,"A robot system includes a robot, a control device, and a projection device. The control device is configured to receive area information on an area defining an operation of the robot. The projection device is configured to project the area onto an object adjacent to the robot based on the area information received by the control device."
AERIAL VEHICLE FLIGHT CONTROL METHOD AND DEVICE THEREOF,https://lens.org/070-039-445-189-238,2019,"A method for controlling an aerial vehicle includes obtaining flight indication data containing a position region associated with the flight indication data, determining whether a current position of the aerial vehicle is within the position region associated with the flight indication data, and, in response to the current position being within the position region, generating a flight control instruction according to the flight indication data, and controlling a flight of the aerial vehicle according to the flight control instruction."
Aerial vehicle flight control method and device thereof,https://lens.org/143-833-797-466-491,2021,"A method for controlling an aerial vehicle includes obtaining flight indication data containing a position region associated with the flight indication data, determining whether a current position of the aerial vehicle is within the position region associated with the flight indication data, and, in response to the current position being within the position region, generating a flight control instruction according to the flight indication data, and controlling a flight of the aerial vehicle according to the flight control instruction."
Associating identifiers with audio signals,https://lens.org/037-808-407-288-881,2019,"A voice-controlled device may receive a voice command uttered by a user, where the voice command may request that the voice-controlled device perform an operation. The voice-controlled device and/or one or more remote computing resources may process an audio signal associated with the voice command to determine text corresponding to the voice command. The resulting user utterance may be associated with a unique identifier, which may be provided to a third party and/or third party application that is to provide information responsive to the user request. The information provided by the third party/third party application may be output to the user based at least partly on the unique identifier, without disclosing user data associated with the user."
UNMANNED AERIAL VEHICLE CONTROL METHOD AND APPARATUS,https://lens.org/136-548-995-517-61X,2020,"A method and apparatus for controlling a UAV are provided. The method is applied to a base station, and includes: receiving flight path information transmitted by a UAV controller, wherein the flight path information represents a flight path set by the UAV controller for a UAV controlled by the UAV controller; determining the flight path based on the flight path information; and determining a next base station to which the UAV is to move based on the flight path, and performing a handover preparation for the next base station. Therefore, the present disclosure improves the mobility of the UAV and can also reduce the latency of handover between base stations."
Unmanned aerial vehicle control method and apparatus,https://lens.org/037-642-711-615-448,2023,"A method and apparatus for controlling a UAV are provided. The method is applied to a base station, and includes: receiving flight path information transmitted by a UAV controller, wherein the flight path information represents a flight path set by the UAV controller for a UAV controlled by the UAV controller; determining the flight path based on the flight path information; and determining a next base station to which the UAV is to move based on the flight path, and performing a handover preparation for the next base station. Therefore, the present disclosure improves the mobility of the UAV and can also reduce the latency of handover between base stations."
Unmanned aerial vehicle control method and apparatus,https://lens.org/037-642-711-615-448,2023,"A method and apparatus for controlling a UAV are provided. The method is applied to a base station, and includes: receiving flight path information transmitted by a UAV controller, wherein the flight path information represents a flight path set by the UAV controller for a UAV controlled by the UAV controller; determining the flight path based on the flight path information; and determining a next base station to which the UAV is to move based on the flight path, and performing a handover preparation for the next base station. Therefore, the present disclosure improves the mobility of the UAV and can also reduce the latency of handover between base stations."
SYSTEM FOR ACTIVATION AND CONTROL OF REMOTE NAVIGATIONAL GUIDANCE EQUIPMENT BY RADIO TRANSMITTED VOICE COMMANDS,https://lens.org/109-865-810-936-157,1998,"A system for the remote activation and operation of access control or reading of navigational guidance equipment located at a distant facility such as an aerodrome or harbour by means of radio. The invention allows the operator of a vessel or vehicle approaching the facility to initiate the activation of, and to control, access control or interrogate navigational guidance equipment such as lighting through operator-initiated, facility-specific, radio transmitted voice commands which are recognized and translated into an electronic control signal by a speech recognition device. The signal in turn actuates the equipment which the command has designated. The invention also provides means for synthesizing verbal responses to the operator to provide feedback concerning the status of the operator's command. The invention also includes interfacing means for presenting both an electronic control signal to the selected facility equipment and verbal response or acknowledgement to the operator."
Method of fishing with unmanned aerial vehicle,https://lens.org/013-011-780-183-720,2019,"The present disclosure discloses a method of using an unmanned aerial vehicle (UAV) comprising a housing, a processor, a positioning unit, a sonar unit, a launching unit and a fishhook unit in fishing. The method comprises manipulating the UAV to fly to a designated destination determined by the processor according to one of a received wireless communication and a preset program, adjusting the sonar unit to a predetermined height by the positioning unit, determining a coordinate corresponding to a signal detected by the sonar unit as a fishing region when the signal is consistent with a predetermined value, launching bait to the fishing region by the launching unit, releasing a fishhook from the fishhook unit to the fishing region, and manipulating the UAV to hover or return by the processor according to one of a received wireless communication and a preset program."
A method of fishing with unmanned aerial vehicle,https://lens.org/145-564-281-640-807,2018,"The present disclosure discloses a method of using an unmanned aerial vehicle (UAV) comprising a housing, a processor, a positioning unit, a sonar unit, a launching unit and a fishhook unit in fishing. The method comprises manipulating the UAV to fly to a designated destination determined by the processor according to one of a received wireless communication and a preset program, adjusting the sonar unit to a predetermined height by the positioning unit, determining a coordinate corresponding to a signal detected by the sonar unit as a fishing region when the signal is consistent with a predetermined value, launching bait to the fishing region by the launching unit, releasing a fishhook from the fishhook unit to the fishing region, and manipulating the UAV to hover or return by the processor according to one of a received wireless communication and a preset program."
Method of Fishing with Unmanned Aerial Vehicle,https://lens.org/177-321-098-444-052,2018,"The present disclosure discloses a method of using an unmanned aerial vehicle (UAV) comprising a housing, a processor, a positioning unit, a sonar unit, a launching unit and a fishhook unit in fishing. The method comprises manipulating the UAV to fly to a designated destination determined by the processor according to one of a received wireless communication and a preset program, adjusting the sonar unit to a predetermined height by the positioning unit, determining a coordinate corresponding to a signal detected by the sonar unit as a fishing region when the signal is consistent with a predetermined value, launching bait to the fishing region by the launching unit, releasing a fishhook from the fishhook unit to the fishing region, and manipulating the UAV to hover or return by the processor according to one of a received wireless communication and a preset program."
UNMANNED AERIAL VEHICLE AND UNMANNED AERIAL VEHICLE SYSTEM,https://lens.org/180-450-574-707-546,2021,"According to an embodiment of the present invention, an unmanned aerial vehicle (UAV) may recognize at least some of the light output from light sources of other unmanned aerial vehicles in swarm flight, and correct the location error based on the recognized light. An unmanned aerial vehicle (UAV) according to an embodiment of the present invention may be linked to an Artificial Intelligence module, a robot, a device related to a 5G service, and the like."
System and method for detecting and identifying unmanned aircraft systems,https://lens.org/090-948-544-677-37X,2019,"Systems, methods, and apparatuses are presented herein for detecting and identifying unmanned aircraft systems (UAS) or drones. The system can include one or more UAS sensor nodes distributed about an area to be monitored. Each UAS sensor node can be communicably coupled to a central server but is able to conduct detection and identification procedures separate from the central server. The UAS sensor node can include a microphone that detects an audio signal generated within the area to be monitored. The node can convert the audio signal into a digital signal, can segment the audio signal, and can pass the signal through a bandpass filter. The node can also conduct a Fourier transform and smooth filtering on the digital audio signal before comparing the signal to multiple stored sample UAS audio signals for known UAS vehicles and motor stresses to determine a likelihood of a match."
Implementations for voice assistant on devices,https://lens.org/180-700-981-323-370,2020,"A method at an electronic device with an audio input system includes: receiving a verbal input at the device; processing the verbal input; transmitting a request to a remote system, the request including information determined based on the verbal input; receiving a response to the request, wherein the response is generated by the remote system in accordance with the information based on the verbal input; and performing an operation in accordance with the response, where one or more of the receiving, processing, transmitting, receiving, and performing are performed by one or more voice processing modules of a voice assistant library executing on the electronic device, the voice processing modules providing a plurality of voice processing operations that are accessible to one or more application programs and/or operating software executing or executable on the electronic device."
METHODS AND SYSTEMS FOR LAUNCHING AN UNMANNED AERIAL VEHICLE,https://lens.org/102-886-980-742-513,2019,"The present application provides methods and systems for launching an unmanned aerial vehicle (UAV). An exemplary system for launching a UAV includes a detector configured to detect acceleration of the UAV in a launch mode. The exemplary system may also include a memory storing instructions and a processor configured to execute the instructions to cause the system to: obtain a signal configured to notify the UAV to enter the launch mode, determine whether the acceleration of the UAV satisfies a condition corresponding to threshold acceleration in the launch mode, and responsive to the determination that the acceleration of the UAV satisfies the condition, turn on a motor of the UAV."
Methods and systems for launching an unmanned aerial vehicle,https://lens.org/065-899-005-075-009,2021,"The present application provides methods and systems for launching an unmanned aerial vehicle (UAV). An exemplary system for launching a UAV includes a detector configured to detect acceleration of the UAV in a launch mode. The exemplary system may also include a memory storing instructions and a processor configured to execute the instructions to cause the system to: obtain a signal configured to notify the UAV to enter the launch mode, determine whether the acceleration of the UAV satisfies a condition corresponding to threshold acceleration in the launch mode, and responsive to the determination that the acceleration of the UAV satisfies the condition, turn on a motor of the UAV."
Determining user location with remote controller,https://lens.org/124-541-264-318-230,2016,"An audio device may be configured to work in conjunction with a handheld remote controller to receive voice commands from a user. The audio device may have multiple local microphones that are used for sound source localization, to determine the position of the user. A remote audio signal may be received from the remote controller and used in conjunction with local microphone signals generated by the local microphones to aid in determining the position of the user. The last known position of the user may be recorded whenever the user speaks into the remote controller. When the user is unable to find the remote controller, the audio device may direct the user toward the last known position of the user."
SYSTEMS FOR UNMANNED AERIAL SPRAYING APPLICATIONS,https://lens.org/113-562-828-898-36X,2021,"A UAV includes a body and rotor coupled to the body. The UAV may include a boom connected to the body, and a nozzle connected to a distal end of the boom, wherein an operational configuration of the nozzle is responsive to a second control signal. The rotor, boom, and nozzle are arranged such that the nozzle is disposed further away from the body than the rotor. The UAV may further include a sensor disposed on either the body or the boom, wherein the sensor is configured to generate a detection signal associated with a distance between the sensor and a surface disposed proximate to the sensor."
Unmanned aerial vehicle with a controller for controlling the backward and forward rotation of a spooling winch,https://lens.org/109-030-646-902-653,2022,"This unmanned aerial vehicle has: a main body; a plurality of rotary wings provided on the main body; a wire for suspending an object from the main body; a hook attached to the wire; a winch for rotatably supporting a spool on which the wire is wound in the forward and backward directions, winding the wire by rotating the spool in the forward direction and unwinding the wire by rotating the spool in the backward direction; and a controller for restricting the backward rotation of the spool when the tension of the wire becomes less than a first threshold value, and restricting the forward rotation of the spool when the tension of the wire becomes less than the first threshold value and becomes equal to or less than a second threshold value, which is less than a gravitational force acting on the hook."
Celestial navigation system for an autonomous robot,https://lens.org/037-078-396-123-405,2013,"An autonomous robot system including a transmitter disposed within a working area and a mobile robot operating within the working area. The transmitter includes an emitter for emitting at least one signal onto a remote surface above the working area. The mobile robot includes a robot body, a drive system configured to maneuver the robot over a surface within the working area, and a navigation system in communication with the drive system. The navigation system includes a receiver responsive to the emitted signal as reflected off of the remote surface and a processor connected to the receiver and configured to determine a relative location of the robot within the working area in response to the receiver responding to the reflected signal."
METHOD AND APPARATUS FOR PROVIDING VOICE ASSISTANT SERVICE,https://lens.org/079-447-406-198-027,2023,"A method, performed by an electronic device, of providing a voice assistant service may include: obtaining voice data including an input of a voice of a user; according to a performance level based on performance state information of the electronic device, identifying a processing path for obtaining a response corresponding to the voice of the user and processing a user interface (UI) corresponding to the response; and based on the identified processing path, performing control operations to process the voice data and obtain and output the processed UI."
ROBOT FACE USED IN A STERILE ENVIRONMENT,https://lens.org/033-801-484-017-519,2011,"A robot system that includes a robot face with a monitor, a camera, a speaker and a microphone. The system may include a removable handle attached to the robot face. The robot face may be controlled through a remote controller. The handle can be remove and replaced with another handle. The remote controller can be covered with a sterile drape or sterilized after each use of the system. The handle and remote controller allow the robot to be utilized in a clean environment such as an operating room without requiring the robot face to be sterilized after a medical procedure. The robot face can be attached to a boom with active joints. The robot face may include a user interface that allows a user to individually move the active joints of the boom."
ROBOT FACE USED IN A STERILE ENVIRONMENT,https://lens.org/088-181-542-081-625,2011,"A robot system that includes a robot face with a monitor, a camera, a speaker and a microphone. The system may include a removable handle attached to the robot face. The robot face may be controlled through a remote controller. The handle can be remove and replaced with another handle. The remote controller can be covered with a sterile drape or sterilized after each use of the system. The handle and remote controller allow the robot to be utilized in a clean environment such as an operating room without requiring the robot face to be sterilized after a medical procedure. The robot face can be attached to a boom with active joints. The robot face may include a user interface that allows a user to individually move the active joints of the boom."
REMOTELY CONTROLLABLE LIGHTING DEVICE,https://lens.org/127-792-280-739-030,2013,"A remotely controllable lighting device includes a control circuit, a light source, and an infrared receiver. After any remote controller is set as a designated remote controller, the designated remote controller can be used to control the remotely controllable lighting device. Alternatively, after any remote controller performs a controlled mode enabling operation, the remote controller can be used to control the remotely controllable lighting device. After one remote controller directly emits the infrared signal to the infrared receiver and the control circuit simultaneously performs a stipulated learning operation, the remote controller is set as the designated remote controller. Moreover, before the stipulated learning operation is performed, an action of announcing the stipulated learning operation is not done."
Methods of safe operation of unmanned aerial vehicles,https://lens.org/164-488-635-601-985,2020,"In various embodiments, a safety system for an unmanned aerial vehicle (UAV) enables the safe operation of the UAV within an airspace by initiating various actions based on the position of the UAV relative to one or more flight zones and/or relative to other aircraft in the airspace."
Property damage assessment system,https://lens.org/106-374-335-174-791,2023,A property damage assessment system may include a drone. The drone may include imaging equipment and a controller. The controller may include a device processor and a non-transitory computer readable medium including instructions executable by the device processor to perform the following steps: receiving imagery data of property from the imaging equipment of the drone; and automatically controlling the drone to obtain additional imagery data of the property based on the received imagery data.
Property damage assessment system,https://lens.org/106-374-335-174-791,2023,A property damage assessment system may include a drone. The drone may include imaging equipment and a controller. The controller may include a device processor and a non-transitory computer readable medium including instructions executable by the device processor to perform the following steps: receiving imagery data of property from the imaging equipment of the drone; and automatically controlling the drone to obtain additional imagery data of the property based on the received imagery data.
Natural language voice assistant,https://lens.org/162-925-905-196-351,2019,A voice assistant of a device is activated not by a key word being spoken but by recognizing speech and determining whether context of the speech indicates that audible voice assistance is appropriate.
NATURAL LANGUAGE VOICE ASSISTANT,https://lens.org/119-902-328-894-975,2018,A voice assistant of a device is activated not by a key word being spoken but by recognizing speech and determining whether context of the speech indicates that audible voice assistance is appropriate.
DETACHABLE POWER CABLE FOR UNMANNED AERIAL VEHICLE,https://lens.org/053-010-268-672-249,2020,"A surveillance drone system is provided herein generally including an UAV, a base power station, and, a tether for connecting the UAV to the base power station to provide electrical power to the UAV when airborne. The base power station may include a cable take-up assembly for releasing and taking up the tether. A plug or power module is provided at the free end of the tether configured to be detachably coupled with the UAV, to transmit electrical power to, and, possibly, data to and from, the UAV. With the plug or power module being detached, the UAV is free to fly unrestricted. This arrangement allows for the UAV to be airborne for prolonged periods to allow for monitoring a region and for release to allow the UAV to investigate anomalies in the monitored region."
Detachable power cable for unmanned aerial vehicle,https://lens.org/096-885-231-199-621,2023,"A surveillance drone system is provided herein generally including an UAV, a base power station, and, a tether for connecting the UAV to the base power station to provide electrical power to the UAV when airborne. The base power station may include a cable take-up assembly for releasing and taking up the tether. A plug or power module is provided at the free end of the tether configured to be detachably coupled with the UAV, to transmit electrical power to, and, possibly, data to and from, the UAV. With the plug or power module being detached, the UAV is free to fly unrestricted. This arrangement allows for the UAV to be airborne for prolonged periods to allow for monitoring a region and for release to allow the UAV to investigate anomalies in the monitored region."
"Re-usable intercept drone, drone engagement system and method therefor",https://lens.org/132-014-657-450-019,2023,"A re-usable intercept drone 104 comprises an elongate fuselage 200 having first and second wings 202 & 206 operably coupled thereto. First and second propulsion units 210 & 212 are operably coupled to the wings. Third and fourth propulsion units 214 & 218 are operably coupled to the fuselage. The propulsion units 210, 212, 214, 218 being circumferentially spaced about the elongate fuselage 200. The drone 104, may have a reinforced ram 238, preferably of aluminium or a titanium coating, as part of the nose cone. The drone 104 may have sensors to detect damage sustained as a result of a collision. The drone engagement system has a control system that identifies a target (106, fig 1) and attempts to collide at least one re-useable intercept drone 104 with the target. The control system may be ground based or peer-to-peer."
SYSTEMS AND METHODS FOR UNMANNED AERIAL VEHICLES,https://lens.org/079-132-302-518-990,2021,"An unmanned aerial system (UAS) may comprise an unmanned aerial vehicle (UAV) configured to search and recover persons and things, collect and produce data of an emergency situation for display on a vehicle navigation system, or explore for natural resources. The UAS may include a landing pad, and/or a sensor such as a ground penetrating sensor configured to search for a person trapped underground. The UAS may be configured to receive data from the one or more sensors. An analyzer may be used to assess surrounding environment and the status of the person or thing, and send a signal to the UAV. The components attached to the UAV may include connectors, a robotic arm, a sensor, and/or a portable power source. The UAS may be configured to, for example, detect an emergency situation and determine the nature and location of the emergency situation. The UAS may be configured to explore for oil, gas, and mineral sources, and/or excavate location using a robotic arm."
SYSTEMS AND METHODS FOR UNMANNED AERIAL VEHICLES,https://lens.org/126-614-219-892-783,2022,"An unmanned aerial system (UAS) may comprise an unmanned aerial vehicle (UAV) configured to search and recover persons and things, collect and produce data of an emergency situation for display on a vehicle navigation system, or explore for natural resources. The UAS may include a landing pad, and/or a sensor such as a ground penetrating sensor configured to search for a person trapped underground. The UAS may be configured to receive data from the one or more sensors. An analyzer may be used to assess surrounding environment and the status of the person or thing, and send a signal to the UAV. The components attached to the UAV may include connectors, a robotic arm, a sensor, and/or a portable power source. The UAS may be configured to, for example, detect an emergency situation and determine the nature and location of the emergency situation. The UAS may be configured to explore for oil, gas, and mineral sources, and/or excavate location using a robotic arm."
SYSTEMS AND METHODS FOR UNMANNED AERIAL VEHICLES,https://lens.org/013-614-996-034-903,2017,"An unmanned aerial system (UAS) may comprise an unmanned aerial vehicle (UAV) configured to search and recover persons and things, collect and produce data of an emergency situation for display on a vehicle navigation system, or explore for natural resources. The UAS may include a landing pad, and/or a sensor such as a ground penetrating sensor configured to search for a person trapped underground. The UAS may be configured to receive data from the one or more sensors. An analyzer may be used to assess surrounding environment and the status of the person or thing, and send a signal to the UAV. The components attached to the UAV may include connectors, a robotic arm, a sensor, and/or a portable power source. The UAS may be configured to, for example, detect an emergency situation and determine the nature and location of the emergency situation. The UAS may be configured to explore for oil, gas, and mineral sources, and/or excavate location using a robotic arm."
Systems and methods for unmanned aerial vehicles,https://lens.org/112-571-911-993-825,2022,"An unmanned aerial system (UAS) may comprise an unmanned aerial vehicle (UAV) configured to search and recover persons and things, collect and produce data of an emergency situation for display on a vehicle navigation system, or explore for natural resources. The UAS may include a landing pad, and/or a sensor such as a ground penetrating sensor configured to search for a person trapped underground. The UAS may be configured to receive data from the one or more sensors. An analyzer may be used to assess surrounding environment and the status of the person or thing, and send a signal to the UAV. The components attached to the UAV may include connectors, a robotic arm, a sensor, and/or a portable power source. The UAS may be configured to, for example, detect an emergency situation and determine the nature and location of the emergency situation. The UAS may be configured to explore for oil, gas, and mineral sources, and/or excavate location using a robotic arm."
SYSTEMS AND METHODS FOR UNMANNED AERIAL VEHICLES,https://lens.org/052-912-296-838-45X,2021,"An unmanned aerial system (UAS) may comprise an unmanned aerial vehicle (UAV) configured to search and recover persons and things, collect and produce data of an emergency situation for display on a vehicle navigation system, or explore for natural resources. The UAS may include a landing pad, and/or a sensor such as a ground penetrating sensor configured to search for a person trapped underground. The UAS may be configured to receive data from the one or more sensors. An analyzer may be used to assess surrounding environment and the status of the person or thing, and send a signal to the UAV. The components attached to the UAV may include connectors, a robotic arm, a sensor, and/or a portable power source. The UAS may be configured to, for example, detect an emergency situation and determine the nature and location of the emergency situation. The UAS may be configured to explore for oil, gas, and mineral sources, and/or excavate location using a robotic arm."
SYSTEMS AND METHODS FOR UNMANNED AERIAL VEHICLES,https://lens.org/126-614-219-892-783,2022,"An unmanned aerial system (UAS) may comprise an unmanned aerial vehicle (UAV) configured to search and recover persons and things, collect and produce data of an emergency situation for display on a vehicle navigation system, or explore for natural resources. The UAS may include a landing pad, and/or a sensor such as a ground penetrating sensor configured to search for a person trapped underground. The UAS may be configured to receive data from the one or more sensors. An analyzer may be used to assess surrounding environment and the status of the person or thing, and send a signal to the UAV. The components attached to the UAV may include connectors, a robotic arm, a sensor, and/or a portable power source. The UAS may be configured to, for example, detect an emergency situation and determine the nature and location of the emergency situation. The UAS may be configured to explore for oil, gas, and mineral sources, and/or excavate location using a robotic arm."
APPARATUS AND METHOD FOR BALANCING AIRCRAFT WITH ROBOTIC ARMS,https://lens.org/001-536-922-362-107,2022,"A hover-capable flying machine (100) such as a drone includes a robotic arm (120) extending from the body (110), and an instrumentality for balancing the machine in response to disturbances such as those caused by picking up and dropping of the payload by the extended robotic arm (120). In embodiments, the end of the arm (120) is equipped with a balancing rotor assembly (140) that may provide lift sufficient to counteract the weight of the payload and/or of the arm (105). In embodiments, the machine's power pack is shifted in response to the disturbances. The power pack may be moved, for example, on a rail within and/or extending beyond the machine in a direction generally opposite to the extended arm (120). The power pack may also be built into a bandolier-like device that can be rolled-in and rolled out, thus changing the center of gravity of the machine."
Control device for unmanned vehicle and control method for unmanned vehicle,https://lens.org/151-679-224-359-40X,2020,"A control device for an unmanned vehicle, said control device comprising: a temperature data acquisition unit for acquiring temperature data for operating oil supplied to a first hydraulic actuator operating a steering device of the unmanned vehicle; and a command output unit for outputting a change command for changing a travel parameter of the unmanned vehicle, on the basis of the temperature data."
Control device for unmanned vehicle and control method for unmanned vehicle,https://lens.org/031-270-841-975-908,2021,"A control device for an unmanned vehicle, said control device comprising: a temperature data acquisition unit for acquiring temperature data for operating oil supplied to a first hydraulic actuator operating a steering device of the unmanned vehicle; and a command output unit for outputting a change command for changing a travel parameter of the unmanned vehicle, on the basis of the temperature data."
Environmentally Aware Status LEDs for Use in Drones,https://lens.org/087-977-305-727-346,2018,"A lighting system for an unmanned autonomous vehicle (UAV) adapts to the environment around the UAV to ensure status notification lights are visible to an operator and/or abide by regulatory lighting requirements. A processor of the UAV may receive information from various sensors regarding environmental conditions and location of the UAV, and adjust a UAV lighting system to ensure visibility under the environmental conditions. Adjustments to the lighting system may include selection of light sources that are illuminated, the illumination intensity of particular light sources, the colors emitted by various light sources and other lighting configurations."
Environmentally aware status LEDs for use in drones,https://lens.org/180-623-738-108-412,2019,"A lighting system for an unmanned autonomous vehicle (UAV) adapts to the environment around the UAV to ensure status notification lights are visible to an operator and/or abide by regulatory lighting requirements. A processor of the UAV may receive information from various sensors regarding environmental conditions and location of the UAV, and adjust a UAV lighting system to ensure visibility under the environmental conditions. Adjustments to the lighting system may include selection of light sources that are illuminated, the illumination intensity of particular light sources, the colors emitted by various light sources and other lighting configurations."
Smart system seat controller,https://lens.org/102-207-968-332-565,2003,"A master controller and various nodes capable of performing disparate functions are configured to cause devices to manipulate an aircraft seat. The nodes operate independently and without interference of the master controller. The master controller provides programs to the nodes. A node initiates a program when commanded to do so by the master controller resulting in a device manipulating an aircraft seat or otherwise operating in conjunction with the aircraft seat. The node also monitors and provides various real time information and performs calibration, power management, diagnostic and other similar types of operations."
Smart system seat controller,https://lens.org/133-944-626-241-940,2006,"A master controller and various nodes capable of performing disparate functions are configured to cause devices to manipulate an aircraft seat. The nodes operate independently and without interference of the master controller. The master controller provides programs to the nodes. A node initiates a program when commanded to do so by the master controller resulting in a device manipulating an aircraft seat or otherwise operating in conjunction with the aircraft seat. The node also monitors and provides various real time information and performs calibration, power management, diagnostic and other similar types of operations."
SMART SYSTEM SEAT CONTROLLER,https://lens.org/093-363-503-602-238,2003,"A master controller and various nodes capable of performing disparate functions are configured to cause devices to manipulate an aircraft seat. The nodes operate independently and without interference of the master controller. The master controller provides programs to the nodes. A node initiates a program when commanded to do so by the master controller resulting in a device manipulating an aircraft seat or otherwise operating in conjunction with the aircraft seat. The node also monitors and provides various real time information and performs calibration, power management, diagnostic and other similar types of operations."
UNMANNED AERIAL VEHICLE,https://lens.org/146-005-412-468-88X,2020,An unmanned aerial vehicle (UAV) includes a fuselage and an object avoidance device connected to the fuselage. The object avoidance device includes an image sensor. An axis of the image sensor is oblique with respect to the fuselage.
Unmanned aerial vehicle having an elevated surface sensor,https://lens.org/074-931-018-670-134,2022,"A system including an unmanned aerial vehicle (UAV) or aerial robotic system (ARS) to perform at least one task to an object during flight of the UAV in a movement mode configured for maneuvering near a surface of the object. A task sensor configured to sense at least one parameter of the surface. An adjustable sensor arm attachable to the UAV and supporting the task sensor to facilitate the task performed to the surface of the object by the UAV during flight of the UAV. The sensor arm being resilient to impact forces caused by direct contact of the sensor or sensor arm with the surface to bend, spring or swivel relative to a contour of the surface."
UNMANNED AERIAL VEHICLE (UAV) FOR COLLECTING AUDIO DATA,https://lens.org/111-459-490-832-700,2018,"An unmanned aerial vehicle (UAV) with audio filtering components includes a background noise-producing component, a background microphone, and a noise emitter. The background noise-producing component is configured to produce a background noise. The background microphone is positioned within a proximity sufficiently close to collect interfering noise from the background noise producing component. The background microphone is configured to collect audio data including the background noise. The noise emitter is disposed within a proximity sufficiently close to the background noise-producing component to reduce the interfering noise. The noise emitter is configured to emit an audio signal having a reverse phase of the audio data collected by the background microphone."
Unmanned aerial vehicle (UAV) for collecting audio data,https://lens.org/165-976-770-714-375,2020,"An unmanned aerial vehicle (UAV) with audio filtering components includes a background noise-producing component, a background microphone, and a noise emitter. The background noise-producing component is configured to produce a background noise. The background microphone is positioned within a proximity sufficiently close to collect interfering noise from the background noise producing component. The background microphone is configured to collect audio data including the background noise. The noise emitter is disposed within a proximity sufficiently close to the background noise-producing component to reduce the interfering noise. The noise emitter is configured to emit an audio signal having a reverse phase of the audio data collected by the background microphone."
Apparatus and method for energy regulation and leg control for spring-mass walking machine,https://lens.org/128-755-662-764-34X,2017,A robot for legged locomotion incorporating passive dynamics with touchdown and takeoff control and method.
APPARATUS AND METHOD FOR ENERGY REGULATION AND LEG CONTROL FOR SPRING-MASS WALKING MACHINE,https://lens.org/017-216-824-513-491,2016,A robot for legged locomotion incorporating passive dynamics with touchdown and takeoff control and method.
HUMAN TRANSPORTING DRONE,https://lens.org/166-794-918-161-551,2017,"Disclosed herein is a human transporting drone including a drone core, a human receptacle for accommodating a human, the human receptacle being detachably housed in the drone core, ropes connected to the human receptacle, and rope winding mechanisms mounted on the drone core, for winding the ropes to house the human receptacle into the drone core and unwinding the ropes to release the human receptacle from the drone core."
Human transporting drone,https://lens.org/113-379-316-614-962,2019,"Disclosed herein is a human transporting drone including a drone core, a human receptacle for accommodating a human, the human receptacle being detachably housed in the drone core, ropes connected to the human receptacle, and rope winding mechanisms mounted on the drone core, for winding the ropes to house the human receptacle into the drone core and unwinding the ropes to release the human receptacle from the drone core."
HUMAN TRANSPORTING DRONE,https://lens.org/166-794-918-161-551,2017,"Disclosed herein is a human transporting drone including a drone core, a human receptacle for accommodating a human, the human receptacle being detachably housed in the drone core, ropes connected to the human receptacle, and rope winding mechanisms mounted on the drone core, for winding the ropes to house the human receptacle into the drone core and unwinding the ropes to release the human receptacle from the drone core."
AERIAL DEVICE AND METHOD FOR CONTROLLING THE AERIAL DEVICE,https://lens.org/023-205-582-922-471,2019,"An aerial device includes a body, an optical system having gimbal supporting a camera, a lift mechanism coupled to the body, a haptic sensor coupled to the body and configured to generate haptic data, and a processing system disposed in the body and in data communication with the haptic sensor. The processing system is configured to process the haptic data to understand an intended position of the aerial device and/or an intended orientation of the gimbal and convert the intended position to a target position of the aerial device and/or the intended orientation to a target orientation of the gimbal utilizing said processed data irrespective of an initial position of said aerial device and an initial orientation of said gimbal. Also disclosed is a method for controlling the aerial device."
Aerial device and method for controlling the aerial device,https://lens.org/080-655-828-464-227,2021,"An aerial device includes a body, an optical system having gimbal supporting a camera, a lift mechanism coupled to the body, a haptic sensor coupled to the body and configured to generate haptic data, and a processing system disposed in the body and in data communication with the haptic sensor. The processing system is configured to process the haptic data to understand an intended position of the aerial device and/or an intended orientation of the gimbal and convert the intended position to a target position of the aerial device and/or the intended orientation to a target orientation of the gimbal utilizing said processed data irrespective of an initial position of said aerial device and an initial orientation of said gimbal. Also disclosed is a method for controlling the aerial device."
Aerial device and method for controlling the aerial device,https://lens.org/166-194-312-931-970,2018,"An aerial device includes a body, an optical system having gimbal supporting a camera, a lift mechanism coupled to the body, a haptic sensor coupled to the body and configured to generate haptic data, and a processing system disposed in the body and in data communication with the haptic sensor. The processing system is configured to process the haptic data to understand an intended position of the aerial device and/or an intended orientation of the gimbal and convert the intended position to a target position of the aerial device and/or the intended orientation to a target orientation of the gimbal utilizing said processed data irrespective of an initial position of said aerial device and an initial orientation of said gimbal. Also disclosed is a method for controlling the aerial device."
AERIAL DEVICE AND METHOD FOR CONTROLLING THE AERIAL DEVICE,https://lens.org/074-946-622-439-985,2018,"An aerial device includes a body, an optical system having gimbal supporting a camera, a lift mechanism coupled to the body, a haptic sensor coupled to the body and configured to generate haptic data, and a processing system disposed in the body and in data communication with the haptic sensor. The processing system is configured to process the haptic data to understand an intended position of the aerial device and/or an intended orientation of the gimbal and convert the intended position to a target position of the aerial device and/or the intended orientation to a target orientation of the gimbal utilizing said processed data irrespective of an initial position of said aerial device and an initial orientation of said gimbal. Also disclosed is a method for controlling the aerial device."
AERIAL DEVICE AND METHOD FOR CONTROLLING THE AERIAL DEVICE,https://lens.org/053-644-576-546-097,2021,"An aerial device includes a body, an optical system having gimbal supporting a camera, a lift mechanism coupled to the body, a haptic sensor coupled to the body and configured to generate haptic data, and a processing system disposed in the body and in data communication with the haptic sensor. The processing system is configured to process the haptic data to understand an intended position of the aerial device and/or an intended orientation of the gimbal and convert the intended position to a target position of the aerial device and/or the intended orientation to a target orientation of the gimbal utilizing said processed data irrespective of an initial position of said aerial device and an initial orientation of said gimbal. Also disclosed is a method for controlling the aerial device."
SYSTEM AND METHOD FOR FAIL-SAFE GUIDANCE OF UAVS,https://lens.org/092-687-415-118-15X,2016,"A system, comprising: a proximity sensor to detect presence of an object within a proximity zone about an unmanned aerial vehicle (UAV) that comprises a propulsion system powered by a power source; a disconnect switch to disconnect the propulsion system from the power source; and a controller connected to the proximity sensor and the disconnect switch, wherein the controller is configured to control the disconnect switch to disconnect the propulsion system from the power source when the proximity sensor detects that the object is not present within the proximity zone so that the UAV immediately stops powered flight."
Surveillance system,https://lens.org/106-171-782-008-824,2017,"The vehicle once deployed is capable of autonomous flight paths, with basic inputs to change the circular flight paths, so as to build up surveillance for an area of interest. The vehicle comprises at least one optical sensor, which may be IR or visible range, to survey the area of interest, and feed the images back to at least one remote user."
Quadrotor moving target tracking system based on smart phone and method thereof,https://lens.org/029-855-615-063-830,2015,"The invention discloses a quadrotor moving target tracking system based on a smart phone and a method thereof. Through installing a binocular camera and an aerial smart phone on a quadrotor, a target tracking algorithm is completed in the aerial smart phone, the video information captured by the binocular camera is sent to the aerial smart phone, the video information obtained by the aerial smart phone is transmitted to a ground control smart phone through a network, the ground control smart phone selects a needed tracked moving target through a touch screen, and the quadrotor starts to track the target immediately after the targeted is selected. According to the system and the method, the accurate and effective tracking of the target by the quadrotor can be ensured, the system and the method can be applied to the fields of video recording, pedestrian tracking and the like and have good practicability."
"FLIGHT PROCESSING METHOD AND CONTROL DEVICE, UNMANNED AERIAL VEHICLE, SERVER, AND SMART TERMINAL",https://lens.org/108-569-287-385-553,2021,"The present disclosure provides a flight processing method applied to a control device of an unmanned aerial vehicle (UAV). The method includes obtaining a clearance permission file of a target flight restriction area from a server, the clearance permission file being generated by the server in response to flight clearance application information of the flight restriction removal conditions obtained from a smart terminal; and removing flight restrictions of the UAV in the target flight restriction area based on the clearance permission file."
UNMANNED AERIAL VEHICLE WITH COLLISION TOLERANT PROPULSION AND CONTROLLER,https://lens.org/136-246-732-071-536,2022,"Vertical take off and landing unmanned aerial vehicle (UAV) comprising a multi-propeller propulsion system (the system), an outer protective cage surrounding the system, an autonomous power source, a sensing system, and a control system. The sensing system has an orientation sensor and a displacement sensor. The system has at least two propellers spaced apart in a non-coaxial manner. The control system controls the flight or hovering of the UAV. The control system reverses thrust on at least one propeller distal from a point of contact with an obstacle while controlling a motor of a proximal propeller from the contact point to generate lift, the thrust of the distal and proximal propellers being controlled to exert lift on the UAV to counteract gravitational force thereon and apply a moment of rotation about said point of contact to stabilize the position of the UAV or to counteract torque resulting from inertia."
REMOTELY CONTROLLED MULTIROTOR AIRCRAFT COMPRISING AN IMPROVED FRAME,https://lens.org/179-580-226-642-846,2019,"The invention relates to a remotely controlled multirotor aircraft having a frame (1) that comprises a first and a second peripheral portions (12), to which at least one first and one second motor can be respectively coupled, and a central portion (11) comprising a first end (111) and a second end (112), to which the first peripheral portion (12) and the second peripheral portion (13 are respectively coupled, so that the first peripheral portion (12) develops in a plane that is different from that in which the second peripheral portion (13) develops; furthermore, said central portion (11) also comprises coupling means allowing the coupling between said central portion (11) and a mobile device (2) comprising video acquisition means (21)."
"ROBOT SYSTEM, TERMINAL, CONTROL METHOD FOR ROBOT SYSTEM, AND CONTROL METHOD FOR TERMINAL",https://lens.org/045-261-698-613-069,2022,"A robot system is provided and includes a robot body that performs predetermined work together with a user, and a control device that controls the robot body. The control device selects, in accordance with special information of the user, an action to be performed by the robot body during the predetermined work."
"ROBOT SYSTEM, TERMINAL, CONTROL METHOD FOR ROBOT SYSTEM, AND CONTROL METHOD FOR TERMINAL",https://lens.org/045-261-698-613-069,2022,"A robot system is provided and includes a robot body that performs predetermined work together with a user, and a control device that controls the robot body. The control device selects, in accordance with special information of the user, an action to be performed by the robot body during the predetermined work."
SYSTEM AND METHOD FOR UNMANNED TRANSPORTATION MANAGEMENT,https://lens.org/105-633-629-722-789,2022,A method includes obtaining route information at an unmanned aerial vehicle (UAV). The route information indicates a plurality of zones between an origin and a destination and a corresponding set of mobile devices for each zone. The method includes receiving first control data at the UAV from a first mobile device while in a first zone of the plurality of zones. The first mobile device is included in a first set of mobile devices corresponding to the first zone. The method further includes receiving second control data at the UAV from a second mobile device while in a second zone of the plurality of zones. The second mobile device is included in a second set of mobile devices corresponding to the second zone.
Video integration with home assistant,https://lens.org/095-760-643-781-153,2023,"Methods, devices, systems, and means for video integration with a home assistant device are described herein. The home assistant device interacts with a person in a video stream by capturing, using a network-enabled outdoor video camera, a video stream of an outdoor location of a premises at which the person is present and analyzing the person appearing in the captured video stream to determine an identity of the person. Based on determining the identity of the person, the home assistant device announces a presence of the person that is outdoors and outputs instructions to the person."
Drone terrain surveillance with camera and radar sensor fusion for collision avoidance,https://lens.org/053-963-300-296-996,2020,A drone is provided with a convolutional neural network that processes a fusion of video and radar data to identify and avoid collision threats. The drone includes a transmitter for transmitting the video data to a remote convolutional neural network for identifying structures and for further identifying threats or faults with the structures.
Drone Terrain Surveillance with Camera and Radar Sensor Fusion for Collision Avoidance,https://lens.org/131-605-317-231-336,2018,A drone is provided with a convolutional neural network that processes a fusion of video and radar data to identify and avoid collision threats. The drone includes a transmitter for transmitting the video data to a remote convolutional neural network for identifying structures and for further identifying threats or faults with the structures.
Celestial navigation system for an autonomous robot,https://lens.org/039-669-725-128-117,2014,"An autonomous robot system including a transmitter disposed within a working area and a mobile robot operating within the working area. The transmitter includes an emitter for emitting at least one signal onto a remote surface above the working area. The mobile robot includes a robot body, a drive system configured to maneuver the robot over a surface within the working area, and a navigation system in communication with the drive system. The navigation system includes a receiver responsive to the emitted signal as reflected off of the remote surface and a processor connected to the receiver and configured to determine a relative location of the robot within the working area based on input from the receiver."
Dual redundant GPS anti-jam air vehicle navigation system architecture and method,https://lens.org/036-796-229-678-278,2004,"A navigation system for an unmanned aerial vehicle, the navigation system comprising a first antenna for receiving a global positioning system signal, a first interference suppression unit coupled to the first antenna, the first interference suppression unit suppressing interference in the global positioning system signal using a first interference suppression technique, a first navigation unit for receiving signals from the first interference suppression unit, a second antenna for receiving the global positioning system signal, a second interference suppression unit coupled to the second antenna, the second interference suppression unit suppressing interference in the global positioning system signal using a second interference suppression technique, and a second navigation unit for receiving signals from the second interference suppression unit. A method for controlling the flight of an air vehicle performed by the apparatus is also included."
MULTICOPTER,https://lens.org/018-385-635-273-103,2019,"As one aspect of this multicopter, the multicopter flies on the basis of information from a flight controller and is provided with the following: a main body section; a plurality of propulsion units having rotating rotary wing, the propulsion units being attached to the main body section; motors installed in the main body section or the propulsion units; at least one first detection unit that detects motor information; and a wireless transmission unit that wirelessly transmits, to the outside, the motor information detected by the first detection unit."
Automated drone-based paint delivery system,https://lens.org/004-469-057-805-20X,2022,"An automated drone-based surface treatment material delivery system includes a drone having a body, at least one propeller rotatably supported by the body, at least one propeller motor supported by the body and configured to selectively apply motive power to the at least one propeller, and a controller supported by the body and configured to control a flight path of the drone at least by manipulating a speed of the at least one propeller. The drone also has a rotary atomizer supported by the body for movement therewith. The rotary atomizer includes a rotating dispersion structure configured to disperse a surface treatment material from a material supply."
Automated drone-based paint delivery system,https://lens.org/004-469-057-805-20X,2022,"An automated drone-based surface treatment material delivery system includes a drone having a body, at least one propeller rotatably supported by the body, at least one propeller motor supported by the body and configured to selectively apply motive power to the at least one propeller, and a controller supported by the body and configured to control a flight path of the drone at least by manipulating a speed of the at least one propeller. The drone also has a rotary atomizer supported by the body for movement therewith. The rotary atomizer includes a rotating dispersion structure configured to disperse a surface treatment material from a material supply."
AUTOMATED DRONE-BASED PAINT DELIVERY SYSTEM,https://lens.org/165-672-350-179-350,2022,"An automated drone-based surface treatment material delivery system includes a drone having a body, at least one propeller rotatably supported by the body, at least one propeller motor supported by the body and configured to selectively apply motive power to the at least one propeller, and a controller supported by the body and configured to control a flight path of the drone at least by manipulating a speed of the at least one propeller. The drone also has a rotary atomizer supported by the body for movement therewith. The rotary atomizer includes a rotating dispersion structure configured to disperse a surface treatment material from a material supply."
AUTOMATED DRONE-BASED PAINT DELIVERY SYSTEM,https://lens.org/165-672-350-179-350,2022,"An automated drone-based surface treatment material delivery system includes a drone having a body, at least one propeller rotatably supported by the body, at least one propeller motor supported by the body and configured to selectively apply motive power to the at least one propeller, and a controller supported by the body and configured to control a flight path of the drone at least by manipulating a speed of the at least one propeller. The drone also has a rotary atomizer supported by the body for movement therewith. The rotary atomizer includes a rotating dispersion structure configured to disperse a surface treatment material from a material supply."
Autonomous vehicle,https://lens.org/119-212-272-180-042,2023,"An autonomous vehicle that can perform limp home control for causing a vehicle to autonomously take refuge includes an ECU configured to perform the limp home control, limp-home usable sensors configured to detect an external environment of the autonomous vehicle, the limp-home usable sensors being used for the limp home control and being connected to the ECU, limp-home unusable sensors configured to detect the external environment of the autonomous vehicle, the limp-home unusable sensors being sensors not used for the limp home control, and a limp home battery connected to the ECU and the limp-home usable sensors but not connected to the limp-home unusable sensors."
AUTONOMOUS VEHICLE,https://lens.org/196-566-497-263-982,2021,"An autonomous vehicle that can perform limp home control for causing a vehicle to autonomously take refuge includes an ECU configured to perform the limp home control, limp-home usable sensors configured to detect an external environment of the autonomous vehicle, the limp-home usable sensors being used for the limp home control and being connected to the ECU, limp-home unusable sensors configured to detect the external environment of the autonomous vehicle, the limp-home unusable sensors being sensors not used for the limp home control, and a limp home battery connected to the ECU and the limp-home usable sensors but not connected to the limp-home unusable sensors."
Autonomous vehicle,https://lens.org/119-212-272-180-042,2023,"An autonomous vehicle that can perform limp home control for causing a vehicle to autonomously take refuge includes an ECU configured to perform the limp home control, limp-home usable sensors configured to detect an external environment of the autonomous vehicle, the limp-home usable sensors being used for the limp home control and being connected to the ECU, limp-home unusable sensors configured to detect the external environment of the autonomous vehicle, the limp-home unusable sensors being sensors not used for the limp home control, and a limp home battery connected to the ECU and the limp-home usable sensors but not connected to the limp-home unusable sensors."
UNMANNED AERIAL VEHICLE AND METHOD FOR INDICATING A LANDING ZONE,https://lens.org/130-627-262-875-169,2019,"An unmanned aerial vehicle (UAV) has: a body for carrying an article; at least one rotor; and a light source for generating a light beam to indicate the landing zone for the UAV. The UAV, in use, is flown to a desired location, that might be a site of an emergency with no defined landing zone. The UAV descends, and, while descending the light source is operated to illuminate and to define a landing zone. The UAV can be provided with lights and an audio source to warn and advise bystanders that the UAV is landing and to stand clear of the landing zone."
UNMANNED AERIAL VEHICLE AND METHOD FOR INDICATING A LANDING ZONE,https://lens.org/073-407-344-687-129,2021,"An unmanned aerial vehicle (UAV) has: a body for carrying an article; at least one rotor; and a light source for generating a light beam to indicate the landing zone for the UAV. The UAV, in use, is flown to a desired location, that might be a site of an emergency with no defined landing zone. The UAV descends, and, while descending the light source is operated to illuminate and to define a landing zone. The UAV can be provided with lights and an audio source to warn and advise bystanders that the UAV is landing and to stand clear of the landing zone."
Unmanned aerial vehicle and method for indicating a landing zone,https://lens.org/161-162-569-866-934,2021,"An unmanned aerial vehicle (UAV) has: a body for carrying an article; at least one rotor; and a light source for generating a light beam to indicate the landing zone for the UAV. The UAV, in use, is flown to a desired location, that might be a site of an emergency with no defined landing zone. The UAV descends, and, while descending the light source is operated to illuminate and to define a landing zone. The UAV can be provided with lights and an audio source to warn and advise bystanders that the UAV is landing and to stand clear of the landing zone."
Method and system for controlling an autonomous vehicle response to a fault condition,https://lens.org/080-679-778-074-170,2022,"An apparatus for an autonomous vehicle may include a controller. The controller may monitor one or more components or systems of the autonomous vehicle. The controller may determine a fault condition of the autonomous vehicle, such as for a component or a system of the autonomous vehicle. The apparatus may include a human-machine interface for a user, such as an occupant of the autonomous vehicle. The apparatus may communicate, via the human-machine interface, an alert based on the fault condition. This may be in accordance with a profile associated with the user."
SYSTEMS AND METHODS FOR AUTONOMOUS VEHICLES,https://lens.org/032-300-771-784-989,2020,"An apparatus for an autonomous vehicle may include a controller. The controller may monitor one or more components or systems of the autonomous vehicle. The controller may determine a fault condition of the autonomous vehicle, such as for a component or a system of the autonomous vehicle. The apparatus may include a human-machine interface for a user, such as an occupant of the autonomous vehicle. The apparatus may communicate, via the human-machine interface, an alert based on the fault condition. This may be in accordance with a profile associated with the user."
Remote doorbell ringer,https://lens.org/084-684-482-461-157,2005,"A remote control device when actuated by a user transmits a visually perceptible coded signal to a sensor associated with a doorbell which receives the signal and causes activation of the doorbell as desired. The sensor has multiple settings which control operation of the doorbell such that any, specified, or no remote devices may operate the doorbell depending on the setting that is selected on the sensor."
"Unmanned aerial vehicle remote identification, command and control",https://lens.org/108-351-759-982-849,2021,"A method may include receiving an identifier (ID) from a first unmanned aerial vehicle (UAV) prior to a flight, storing the ID and receiving telemetry information from the first UAV during the flight. The method may also include storing the telemetry information, receiving a request from a user device for information associated with a first location and authenticating the user device. The method may further include determining whether at least one UAV is flying in an area associated with the first location and transmitting telemetry information associated with the at least one UAV, in response to determining that at least one UAV is flying in the area associated with the first location."
"UNMANNED AERIAL VEHICLE REMOTE IDENTIFICATION, COMMAND AND CONTROL",https://lens.org/140-511-416-186-365,2021,"A method may include receiving an identifier (ID) from a first unmanned aerial vehicle (UAV) prior to a flight, storing the ID and receiving telemetry information from the first UAV during the flight. The method may also include storing the telemetry information, receiving a request from a user device for information associated with a first location and authenticating the user device. The method may further include determining whether at least one UAV is flying in an area associated with the first location and transmitting telemetry information associated with the at least one UAV, in response to determining that at least one UAV is flying in the area associated with the first location."
"Unmanned aerial vehicle remote identification, command and control",https://lens.org/149-495-048-728-65X,2023,"A method may include receiving an identifier (ID) from a first unmanned aerial vehicle (UAV) prior to a flight, storing the ID and receiving telemetry information from the first UAV during the flight. The method may also include storing the telemetry information, receiving a request from a user device for information associated with a first location and authenticating the user device. The method may further include determining whether at least one UAV is flying in an area associated with the first location and transmitting telemetry information associated with the at least one UAV, in response to determining that at least one UAV is flying in the area associated with the first location."
UNMANNED AERIAL VEHICLE DELIVERY SYSTEM,https://lens.org/077-140-489-433-248,2023,"This disclosure describes an unmanned aerial vehicle (""UAV"") configured to autonomously deliver items of inventory to various destinations. The UAV may receive inventory information and a destination location and autonomously retrieve the inventory from a location within a materials handling facility, compute a route from the materials handling facility to a destination and travel to the destination to deliver the inventory."
UNMANNED AERIAL VEHICLE DELIVERY SYSTEM,https://lens.org/150-258-046-729-495,2022,"This disclosure describes an unmanned aerial vehicle (""UAV"") configured to autonomously deliver items of inventory to various destinations. The UAV may receive inventory information and a destination location and autonomously retrieve the inventory from a location within a materials handling facility, compute a route from the materials handling facility to a destination and travel to the destination to deliver the inventory."
UNMANNED AERIAL VEHICLE DELIVERY SYSTEM,https://lens.org/061-548-134-305-093,2015,"This disclosure describes an unmanned aerial vehicle (""UAV"") configured to autonomously deliver items of inventory to various destinations. The UAV may receive inventory information and a destination location and autonomously retrieve the inventory from a location within a materials handling facility, compute a route from the materials handling facility to a destination and travel to the destination to deliver the inventory."
UNMANNED AERIAL VEHICLE DELIVERY SYSTEM,https://lens.org/152-446-441-156-974,2020,"This disclosure describes an unmanned aerial vehicle (""UAV"") configured to autonomously deliver items of inventory to various destinations. The UAV may receive inventory information and a destination location and autonomously retrieve the inventory from a location within a materials handling facility, compute a route from the materials handling facility to a destination and travel to the destination to deliver the inventory."
UNMANNED AERIAL VEHICLE DELIVERY SYSTEM,https://lens.org/077-140-489-433-248,2023,"This disclosure describes an unmanned aerial vehicle (""UAV"") configured to autonomously deliver items of inventory to various destinations. The UAV may receive inventory information and a destination location and autonomously retrieve the inventory from a location within a materials handling facility, compute a route from the materials handling facility to a destination and travel to the destination to deliver the inventory."
UNMANNED AERIAL VEHICLE DELIVERY SYSTEM,https://lens.org/150-258-046-729-495,2022,"This disclosure describes an unmanned aerial vehicle (""UAV"") configured to autonomously deliver items of inventory to various destinations. The UAV may receive inventory information and a destination location and autonomously retrieve the inventory from a location within a materials handling facility, compute a route from the materials handling facility to a destination and travel to the destination to deliver the inventory."
Unmanned aerial vehicles,https://lens.org/090-749-664-925-516,2019,"A UAV 100 comprises a camera 110 and a controller 120. The controller 120 is configured to: (a) receive image data from the camera 110, (b) determine, based on the received image data, whether or not a predetermined visibility condition associated with an operator 200 of the UAV 100 is satisfied, and (c) perform a predetermined action to attempt to operate in accordance with a predetermined visibility state with respect to the operator 200 of the UAV 100 based on a result of the determination. The controller 120 is configured to distinguish between the operator (200, fig 3) of the UAV 100 and at least one other object (500, fig 3) represented in the received image data. The controller may also be configured to distinguish between different operators. A method of using the equipment is also claimed."
Traffic stop drone,https://lens.org/043-240-594-625-916,2022,"The present invention discloses a drone or unmanned aerial vehicle (UAV) mounted on a law enforcement vehicle for the purposes of interfacing with occupants of a stopped vehicle after being pulled over for a traffic violation or routine stop. The drone is equipped with a navigation system, obstacle-avoidance sensors, a telepresence system (a camera, microphone, speaker and screen), and a robotic arm with a secure box and a device for estimating blood alcohol content. Once a suspect vehicle has been pulled over by a law enforcement officer, without leaving the safety of a law enforcement vehicle, the officer deploys the drone to perform a visual check of the interior of the suspect vehicle for dangerous items, ascertain if an occupant's face triggers any flags on a central database, administer a sobriety test, collect the necessary documents and deliver a citation to the driver via the secure box."
TRAFFIC STOP DRONE,https://lens.org/108-581-928-208-04X,2020,"The present invention discloses a drone or unmanned aerial vehicle (UAV) mounted on a law enforcement vehicle for the purposes of interfacing with occupants of a stopped vehicle after being pulled over for a traffic violation or routine stop. The drone is equipped with a navigation system, obstacle-avoidance sensors, a telepresence system (a camera, microphone, speaker and screen), and a robotic arm with a secure box and a device for estimating blood alcohol content. Once a suspect vehicle has been pulled over by a law enforcement officer, without leaving the safety of a law enforcement vehicle, the officer deploys the drone to perform a visual check of the interior of the suspect vehicle for dangerous items, ascertain if an occupant's face triggers any flags on a central database, administer a sobriety test, collect the necessary documents and deliver a citation to the driver via the secure box."
TRAFFIC STOP DRONE,https://lens.org/108-581-928-208-04X,2020,"The present invention discloses a drone or unmanned aerial vehicle (UAV) mounted on a law enforcement vehicle for the purposes of interfacing with occupants of a stopped vehicle after being pulled over for a traffic violation or routine stop. The drone is equipped with a navigation system, obstacle-avoidance sensors, a telepresence system (a camera, microphone, speaker and screen), and a robotic arm with a secure box and a device for estimating blood alcohol content. Once a suspect vehicle has been pulled over by a law enforcement officer, without leaving the safety of a law enforcement vehicle, the officer deploys the drone to perform a visual check of the interior of the suspect vehicle for dangerous items, ascertain if an occupant's face triggers any flags on a central database, administer a sobriety test, collect the necessary documents and deliver a citation to the driver via the secure box."
Power line inspection vehicle,https://lens.org/098-077-657-757-800,2023,"An exemplary unmanned aerial vehicle (UAV) mountable to a conductor of an aerial power transmission line system includes a body having a rotor system, a motivation system attached to the body to motivate the UAV along the conductor, a battery carried by the body and electrically connected to at least one of the rotor system and the motivation system, a monitoring tool mounted with the body and an inductive coil carried by the body and in electric connection with the battery, wherein the inductive coil is configured to harvest electricity from the aerial power transmission line system and charge the battery."
POWER LINE INSPECTION VEHICLE,https://lens.org/162-547-859-911-936,2023,"An exemplary unmanned aerial vehicle (UAV) mountable to a conductor of an aerial power transmission line system includes a body having a rotor system, a motivation system attached to the body to motivate the UAV along the conductor, a battery carried by the body and electrically connected to at least one of the rotor system and the motivation system, a monitoring tool mounted with the body and an inductive coil carried by the body and in electric connection with the battery, wherein the inductive coil is configured to harvest electricity from the aerial power transmission line system and charge the battery."
POWER LINE INSPECTION VEHICLE,https://lens.org/097-687-549-351-59X,2021,"An exemplary unmanned aerial vehicle (UAV) mountable to a conductor of an aerial power transmission line system includes a body having a rotor system, a motivation system attached to the body to motivate the UAV along the conductor, a battery carried by the body and electrically connected to at least one of the rotor system and the motivation system, a monitoring tool mounted with the body and an inductive coil carried by the body and in electric connection with the battery, wherein the inductive coil is configured to harvest electricity from the aerial power transmission line system and charge the battery."
POWER LINE INSPECTION VEHICLE,https://lens.org/162-547-859-911-936,2023,"An exemplary unmanned aerial vehicle (UAV) mountable to a conductor of an aerial power transmission line system includes a body having a rotor system, a motivation system attached to the body to motivate the UAV along the conductor, a battery carried by the body and electrically connected to at least one of the rotor system and the motivation system, a monitoring tool mounted with the body and an inductive coil carried by the body and in electric connection with the battery, wherein the inductive coil is configured to harvest electricity from the aerial power transmission line system and charge the battery."
Power line inspection vehicle,https://lens.org/098-077-657-757-800,2023,"An exemplary unmanned aerial vehicle (UAV) mountable to a conductor of an aerial power transmission line system includes a body having a rotor system, a motivation system attached to the body to motivate the UAV along the conductor, a battery carried by the body and electrically connected to at least one of the rotor system and the motivation system, a monitoring tool mounted with the body and an inductive coil carried by the body and in electric connection with the battery, wherein the inductive coil is configured to harvest electricity from the aerial power transmission line system and charge the battery."
"METHOD FOR CONTROLLING AN AIRCRAFT, CONTROL DEVICE FOR AN AIRCRAFT AND AIRCRAFT WITH SUCH A CONTROL DEVICE",https://lens.org/073-900-681-084-838,2021,"A method for controlling an aircraft (1), in particular a VTOL multirotor aircraft, in which flight influencing units of the aircraft a) are supplied with control commands via a first/control channel from a first computer (COM), which control commands originate or are derived from a pilot input (PE), and b) the control commands are monitored by a second/monitoring channel and a second computer (MON), which checks whether the control commands are suitable for a given physical state of the aircraft and the pilot input, c) the second computer determines whether a current navigation state of the aircraft (1) coincides with the pilot input, which has been transformed into a desired navigation state of the aircraft, preferably by the second computer, within a prescribed deviation, and d) a control signal for controlling the aircraft (1) is generated in dependence on a determination result of step c). A corresponding control device (4) and aircraft (1) with such a device are provided."
Autonomous vehicle information lighting system,https://lens.org/193-440-796-904-337,2020,"A vehicle lighting system, a system, and method for an autonomous vehicle are provided. The vehicle lighting system includes a light module and a controller. The controller is configured to control a behavior of the light module to communicate an operating status of an autonomous vehicle."
AUTONOMOUS VEHICLE INFORMATION LIGHTING SYSTEM,https://lens.org/162-488-256-684-642,2020,"A vehicle lighting system, a system, and method for an autonomous vehicle are provided. The vehicle lighting system includes a light module and a controller. The controller is configured to control a behavior of the light module to communicate an operating status of an autonomous vehicle."
FLIGHT CONTROL USING COMPUTER VISION,https://lens.org/073-870-238-879-471,2019,"A flight control operation of a reference aerial vehicle is performed. For example, an image captured by an image sensor of the reference aerial vehicle is received. A target is detected in the image. A three-dimensional relative location of the target with respect to the reference aerial vehicle is determined based on the image. The flight control operation is performed based on the three-dimensional relative location of the target with respect to the reference aerial vehicle."
FLIGHT CONTROL USING COMPUTER VISION,https://lens.org/163-758-145-632-173,2019,"A flight control operation of a reference aerial vehicle is performed. For example, an image captured by an image sensor of the reference aerial vehicle is received. A target is detected in the image. A three-dimensional relative location of the target with respect to the reference aerial vehicle is determined based on the image. The flight control operation is performed based on the three-dimensional relative location of the target with respect to the reference aerial vehicle."
Flight control using computer vision,https://lens.org/189-286-087-949-885,2019,"A flight control operation of a reference aerial vehicle is performed. For example, an image captured by an image sensor of the reference aerial vehicle is received. A target is detected in the image. A three-dimensional relative location of the target with respect to the reference aerial vehicle is determined based on the image. The flight control operation is performed based on the three-dimensional relative location of the target with respect to the reference aerial vehicle."
APPARATUS AND METHOD FOR CONTROLLING AN UNMANNED VEHICLE,https://lens.org/156-427-106-303-086,2009,"In one or more embodiments, an apparatus and method for operating an unmanned and autonomous vehicle includes a sensor management module configured to direct sensors as to what function they are to provide; a mission management module configured to provide execute function capabilities; an effects management module configured to provide launching and directing weapons to their target capabilities; a vehicle management module; a situation awareness management module configured to provide correlate sensor data of objects, threats, targets, geographic points of interest that the pilot requires in the immediate environment; a communications management module; an information management module configured to provide a database of intelligence-related data; a middleware module configured to interface with the sensor management module, the mission management module, the effects management module, the vehicle management module, the situation awareness management module, the communications management module, and the information management module."
Autonomous helicopter blade end lighting device,https://lens.org/073-215-861-475-646,1999,"An autonomous helicopter blade end lighting device (20) includes a light source (22) and a power source (24) mounted in a housing (34) connectable to a helicopter rotor blade end (21), the power source (24) providing the light source (22) with power for operation when the blade is rotating. <IMAGE>"
APPARATUS-ASSISTED SENSOR DATA COLLECTION,https://lens.org/065-404-588-737-643,2017,"The disclosure provides various methods and apparatus useful for mapping wireless nodes using a drone and aligning the body of the drone with an antenna of the wireless node. A method includes mapping, by an apparatus, a space including one or more locations of one or more wireless nodes, determining whether the apparatus is in proximity to a first wireless node of the one or more wireless nodes, determining an orientation of an antenna of the first wireless node, and in response to determining that the apparatus is in proximity to the first wireless node and determining the orientation of the antenna of the first wireless node, adjusting a six-degree-of-freedom (6DoF) orientation of the apparatus based on the determined orientation of the antenna of the first wireless node. The apparatus may be an autonomous drone."
DRONE,https://lens.org/036-057-625-464-352,2017,"Disclosed is a drone. The present invention includes a plurality of propellers creating a lift to prevent inclination and overturn of the drone due to a lift difference generated from uneven ground, a power driving unit providing a rotation power to each of a plurality of the propellers, a ground sensing unit measuring a distance to a first region of the ground and a shape of the first region, and a controller controlling the power driving unit to differentiate rotation ratios of a plurality of the propellers based on the measured distance and shape if receiving an input signal for landing at the first region."
Drone,https://lens.org/057-200-313-805-77X,2019,"Disclosed is a drone. The present invention includes a plurality of propellers creating a lift to prevent inclination and overturn of the drone due to a lift difference generated from uneven ground, a power driving unit providing a rotation power to each of a plurality of the propellers, a ground sensing unit measuring a distance to a first region of the ground and a shape of the first region, and a controller controlling the power driving unit to differentiate rotation ratios of a plurality of the propellers based on the measured distance and shape if receiving an input signal for landing at the first region."
Modular robotic platform with acoustic navigation system,https://lens.org/145-645-270-796-114,1999,"A navigation system and method for identifying a position or navigating an autonomous robotic platform within an area is provided including a moveable device having an acoustic transmitter for transmitting an acoustic signal, an electronic processor device and an RF receiver; and three or more beacons positioned proximate the area, each beacon including a signal receiving apparatus responsive to the acoustic signal and an RF transmitter, the acoustic signal and the RF signal received from each of the beacons being processed in the electronic processor device to identify the location of the platform within the area."
DRONE WITH LANDING CAPABILITY ON UNEVEN TERRAINS,https://lens.org/132-119-750-436-765,2022,"A drone configured for landing on uneven terrain, comprising a drone body comprising a plurality of propellers; a plurality of multi-sectional landing legs, each landing leg comprising at least one joint and a servo motor for operating the joint to adjust the orientation of said each landing leg; an image sensor configured on an underside of the drone; a processor configured to: analyze images of a landing area topography captured by the image sensor; extrapolate topographic information from the images; based on the topographic information, determine an appropriate landing orientation for each leg, whereby the drone body and plurality of propellers are horizontally balanced; instruct each servo motor to operate a respective joint so as to cause each leg to reach its appropriate landing orientation."
DRONE WITH LANDING CAPABILITY ON UNEVEN TERRAINS,https://lens.org/132-119-750-436-765,2022,"A drone configured for landing on uneven terrain, comprising a drone body comprising a plurality of propellers; a plurality of multi-sectional landing legs, each landing leg comprising at least one joint and a servo motor for operating the joint to adjust the orientation of said each landing leg; an image sensor configured on an underside of the drone; a processor configured to: analyze images of a landing area topography captured by the image sensor; extrapolate topographic information from the images; based on the topographic information, determine an appropriate landing orientation for each leg, whereby the drone body and plurality of propellers are horizontally balanced; instruct each servo motor to operate a respective joint so as to cause each leg to reach its appropriate landing orientation."
Stunt arenas for remote control vehicles,https://lens.org/044-432-192-327-994,2016,"A remote control vehicle, a remote control for use in controlling the vehicle, and an arena in which the vehicle can be operated, via the remote control, to engage stunts and perform acrobatic maneuvers are provided. The remote control has a charging port for receiving and charging a battery configured for use with the remote control vehicle. And, the arena includes stunts and fences disposed along part of an outer portion of the arena. The remote control vehicle is operable, via the remote control, in the arena to engage the stunts and perform acrobatic maneuvers within the arena."
STUNT ARENAS FOR REMOTE CONTROL VEHICLES,https://lens.org/059-109-150-677-35X,2014,"A remote control vehicle, a remote control for use in controlling the vehicle, and an arena in which the vehicle can be operated, via the remote control, to engage stunts and perform acrobatic maneuvers are provided. The remote control has a charging port for receiving and charging a battery configured for use with the remote control vehicle. And, the arena includes stunts and fences disposed along part of an outer portion of the arena. The remote control vehicle is operable, via the remote control, in the arena to engage the stunts and perform acrobatic maneuvers within the arena."
STUNT ARENAS FOR REMOTE CONTROL VEHICLES,https://lens.org/158-446-215-699-231,2017,"A remote control vehicle, a remote control for use in controlling the vehicle, and an arena in which the vehicle can be operated, via the remote control, to engage stunts and perform acrobatic maneuvers are provided. The remote control has a charging port for receiving and charging a battery configured for use with the remote control vehicle. And, the arena includes stunts and fences disposed along part of an outer portion of the arena. The remote control vehicle is operable, via the remote control, in the arena to engage the stunts and perform acrobatic maneuvers within the arena."
Self Regulating Power Conditioner for Energy Harvesting Applications,https://lens.org/105-331-702-837-862,2013,A monitoring system for an aircraft.
SELF REGULATING POWER CONDITIONER FOR ENERGY HARVESTING APPLICATIONS,https://lens.org/144-404-492-154-244,2010,A monitoring system for an aircraft.
Power Aware Techniques for Energy Harvesting Remote Sensor Systems,https://lens.org/038-367-682-066-613,2010,A monitoring system for an aircraft.
Methods for anti-collision and multiple access in RFID communications,https://lens.org/071-069-419-922-006,2017,"A monitoring system for an aircraft.
"
Self Regulating Power Conditioner for Energy Harvesting Applications,https://lens.org/117-525-163-929-186,2010,A monitoring system for an aircraft.
Power Aware Techniques For Energy Harvesting Remote Sensor Systems,https://lens.org/144-989-140-692-387,2019,A monitoring system for an aircraft.
METHODS FOR ANTI-COLLISION AND MULTIPLE ACCESS IN RFID COMMUNICATIONS,https://lens.org/162-507-020-666-668,2010,A monitoring system for an aircraft.
METHODS FOR ANTI-COLLISION AND MULTIPLE ACCESS IN RFID COMMUNICATIONS,https://lens.org/181-706-070-290-33X,2010,A monitoring system for an aircraft.
RF antenna supported on a drone,https://lens.org/128-625-601-583-881,2018,"A small consumer drone is used to measure RF signals, such as within the vicinity of a cell tower. The drone's frame is fitted with an antenna support device which can be in the form of two intersecting arches of dielectric material. An antenna of selected specification is secured to the antenna support. In this way, the antenna support not only provides a secure mounting for the antenna, but also provides protection from objects above the drone."
RF antenna supported on a drone,https://lens.org/025-248-164-985-042,2019,"A small consumer drone is used to measure RF signals, such as within the vicinity of a cell tower. The drone's frame is fitted with an antenna support device which can be in the form of two intersecting arches of dielectric material. An antenna of selected specification is secured to the antenna support. In this way, the antenna support not only provides a secure mounting for the antenna, but also provides protection from objects above the drone."
Systems and methods for controlling an intersection of a route of an unmanned aerial vehicle,https://lens.org/007-506-204-849-085,2023,The disclosure provides systems and methods for controlling an intersection of a route of a UAV. The systems and methods provide detection of vehicles and persons in (or predicted to enter) an area of the intersection and provide a signal to the UAV so that the UAV can avoid flying over vehicles and persons.
Systems And Methods For Controlling An Intersection Of A Route Of An Unmanned Aerial Vehicle,https://lens.org/176-702-625-737-934,2022,The disclosure provides systems and methods for controlling an intersection of a route of a UAV. The systems and methods provide detection of vehicles and persons in (or predicted to enter) an area of the intersection and provide a signal to the UAV so that the UAV can avoid flying over vehicles and persons.
Systems and methods for controlling an intersection of a route of an unmanned aerial vehicle,https://lens.org/007-506-204-849-085,2023,The disclosure provides systems and methods for controlling an intersection of a route of a UAV. The systems and methods provide detection of vehicles and persons in (or predicted to enter) an area of the intersection and provide a signal to the UAV so that the UAV can avoid flying over vehicles and persons.
Method for Exploration and Mapping Using an Aerial Vehicle,https://lens.org/185-174-760-047-194,2021,"A method for use in performing exploration and mapping of an environment, the method being performed using an aerial vehicle and a user processing system that wirelessly communicates with the aerial vehicle when the aerial vehicle is within communication range thereof, the method including: the aerial vehicle generating range data using a range sensor; whilst the aerial vehicle is within communication range, the aerial vehicle transmitting, to the user processing system, map data based on the range data; the user processing system displaying a map representation based on the map data; the user processing system obtaining user defined flight instructions; whilst the aerial vehicle is within communication range, the user processing system transmitting, to the aerial vehicle, flight instructions data based on the user defined flight instructions; and the aerial vehicle flying autonomously in accordance with the flight instructions data and the range data."
METHOD FOR EXPLORATION AND MAPPING USING AN AERIAL VEHICLE,https://lens.org/183-478-558-373-455,2020,"A method for use in performing exploration and mapping of an environment, the method being performed using an aerial vehicle and a user processing system that wirelessly communicates with the aerial vehicle when the aerial vehicle is within communication range thereof, the method including: the aerial vehicle generating range data using a range sensor; whilst the aerial vehicle is within communication range, the aerial vehicle transmitting, to the user processing system, map data based on the range data; the user processing system displaying a map representation based on the map data; the user processing system obtaining user defined flight instructions; whilst the aerial vehicle is within communication range, the user processing system transmitting, to the aerial vehicle, flight instructions data based on the user defined flight instructions; and the aerial vehicle flying autonomously in accordance with the flight instructions data and the range data."
Method for exploration and mapping using an aerial vehicle,https://lens.org/166-498-495-799-45X,2021,"A method for use in performing exploration and mapping of an environment, the method being performed using an aerial vehicle and a user processing system that wirelessly communicates with the aerial vehicle when the aerial vehicle is within communication range thereof, the method including: the aerial vehicle generating range data using a range sensor; whilst the aerial vehicle is within communication range, the aerial vehicle transmitting, to the user processing system, map data based on the range data; the user processing system displaying a map representation based on the map data; the user processing system obtaining user defined flight instructions; whilst the aerial vehicle is within communication range, the user processing system transmitting, to the aerial vehicle, flight instructions data based on the user defined flight instructions; and the aerial vehicle flying autonomously in accordance with the flight instructions data and the range data."
Robot cleaner and remote monitoring system using the same,https://lens.org/071-353-517-748-505,2014,"A robot cleaner has a camera to generate an image of a cleaning area, a controller to prepare a cleaning map based on the image and to drive a robot cleaner, and a communicator to transmit the image and cleaning map to an external device and to receive a control command from the external device. The image and map may be transmitted over a local or wide area network, and the external device may be a computer, television, smart phone, portable phone, or other type of wireless access device."
ROBOT CLEANER AND REMOTE MONITORING SYSTEM USING THE SAME,https://lens.org/058-143-882-768-92X,2011,"A robot cleaner has a camera to generate an image of a cleaning area, a controller to prepare a cleaning map based on the image and to drive a robot cleaner, and a communicator to transmit the image and cleaning map to an external device and to receive a control command from the external device. The image and map may be transmitted over a local or wide area network, and the external device may be a computer, television, smart phone, portable phone, or other type of wireless access device."
Autonomous unmanned aerial vehicle and method of control thereof,https://lens.org/117-886-364-880-597,2019,"A method of providing automated safe-fail operation for a UAV 10 has the steps of: obtaining real-time internal, and external, flight characteristic data, indicative of UAV flight system(s), and of external flight-relevant parameters, respectively; using an onboard flight controller 18 to determine a number safe-fail operations, based on the external data and determining a safe-fail condition; in the event that the condition is triggered, selecting and implementing one of the safe-fail operations in accordance with the external data the flight controllers programming. The flight system(s) may be thrust, lift, directional 14 or navigational 20 control systems or a communications system 16. The flight-relevant parameters may be air traffic control communications, and/or airspace control; environmental; mission parameter; collision prediction; safe landing; geographical and/or payload data. The flight controller may have a ranking circuit to prioritize the safe-fail operations, the safe-fail condition may be overridden by a remote user. Also claimed is a method of controlling a flight of a UAV without continuous in-flight human input, including the steps of: determining a pre-take-off flight plan in accordance with received mission parameter data; and dynamically implementing flight control instructions based on internal and external data to adapt the flight plan to control flight of the UAV."
CAMERA ASSEMBLY AND UNMANNED AERIAL VEHICLE,https://lens.org/024-899-841-691-619,2020,"A camera assembly includes a bracket and a camera device. The bracket includes a mounting surface, which is configured to be connected to a body of an unmanned aerial vehicle (UAV). The camera device is mounted at the bracket. An optical axis of the camera device tilts downward relative to the mounting surface."
Intelligent noise monitoring device and noise monitoring method using the same,https://lens.org/111-928-341-843-667,2016,"An intelligent noise monitoring device, and the corresponding method, capable of flying around an area to automatically measure noise in real time and compare and analyze the measured noise with a reference value so as to determine abnormal noise, comprises: a self-movable moving module; a noise measurement module provided coupled to the moving module configured to measure noise of a location and/or a target which is positioned within the location; a control module adapted to: control the moving module and the noise measurement module; communicate with a ground control center, predetermine a noise reference by measuring the noise of the location and/or the target at a predetermined time or a predetermined period of time, and compare the measured noise from the location or the target with the predetermined noise reference in order to determine whether or not the measured noise is in an abnormal state."
INTELLIGENT NOISE MONITORING DEVICE AND NOISE MONITORING METHOD USING THE SAME,https://lens.org/060-397-170-987-325,2016,"An intelligent noise monitoring device, and the corresponding method, capable of flying around an area to automatically measure noise in real time and compare and analyze the measured noise with a reference value so as to determine abnormal noise, comprises: a self-movable moving module; a noise measurement module provided coupled to the moving module configured to measure noise of a location and/or a target which is positioned within the location; a control module adapted to: control the moving module and the noise measurement module; communicate with a ground control center, predetermine a noise reference by measuring the noise of the location and/or the target at a predetermined time or a predetermined period of time, and compare the measured noise from the location or the target with the predetermined noise reference in order to determine whether or not the measured noise is in an abnormal state.
"
Autonomous takeoff and landing system for fixed-wing unmanned aerial vehicle (UAV),https://lens.org/072-650-158-168-53X,2015,"The utility model discloses an autonomous takeoff and landing system for a fixed-wing unmanned aerial vehicle (UAV), and the autonomous takeoff and landing system is high in automation degree, simple in manipulation, low in requirement for the skill level of manipulation personnel, suitable for UAVs of different weight classes, and low in cost without the need of a ground takeoff and landing signal guidance system. The autonomous takeoff and landing system includes a ground station hardware device and an autopilot; the ground station hardware device is provided with a ground satellite navigation reference station antenna and includes a ground satellite navigation module, a power supply and a ground link, the power supply supplying power for the ground satellite navigation module and ground link, and the ground satellite navigation module being connected to the ground link; and the autopilot is provided with an onboard satellite navigation antenna and includes an onboard satellite navigation module, an autopilot main board and an onboard link which are connected in sequence, the onboard link communicating with the ground link connected, and the autopilot main board supplying power for the onboard satellite navigation module."
"ROBOT AND ELECTRONIC DEVICE FOR ACQUIRING VIDEO, AND METHOD FOR ACQUIRING VIDEO USING ROBOT",https://lens.org/047-796-306-039-488,2020,"Disclosed herein is a robot and an electronic device for acquiring video, and a method for acquiring video using the robot. The robot includes a camera configured to rotate in the lateral direction and tilt in the vertical direction, and controls at least one of a direction of the rotation of the camera, an angle of the tilt of the camera, and a focal distance of the camera by recognizing and tracking users in a video acquired by the camera."
"RETURN FLIGHT CONTROL METHOD AND DEVICE, AND UNMANNED AERIAL VEHICLE",https://lens.org/053-439-745-547-726,2021,"The present disclosure provides a method for controlling a return flight of an unmanned aerial vehicle (UVA). The method includes controlling the UAV to fly to a predetermined cruising altitude, and controlling the UAV to return horizontally at the predetermined cruising altitude based on a first predetermined horizontal speed control value when determining that a remaining power of the UVA is less than or equal to a predetermined return flight power threshold; and controlling the UAV to perform a forced landing and the return flight based on the first predetermined horizontal speed control value and a predetermined descent speed control value when determining that the remaining power of the UAV is less than or equal to a predetermined descent power threshold in the process of the horizontal return at the predetermined cruising altitude."
Method and Apparatus For Locating A Target Using An Autonomous Unmanned Aerial Vehicle,https://lens.org/054-484-223-195-283,2016,"Described herein is an unmanned aerial vehicle (UAV) system that incorporates sensor data to statistically minimize the time to autonomously locate a target on the ground. The system uses a two-stage approach to finding the RF target: 1) randomized flight, such as Lvy fight, to search the ground space and, 2) a geo-localization process, such as a simplex minimization process, to home in on the target."
Method and apparatus for locating a target using an autonomous unmanned aerial vehicle,https://lens.org/129-564-187-463-55X,2017,"Described herein is an unmanned aerial vehicle (UAV) system that incorporates sensor data to statistically minimize the time to autonomously locate a target on the ground. The system uses a two-stage approach to finding the RF target: 1) randomized flight, such as Lvy fight, to search the ground space and, 2) a geo-localization process, such as a simplex minimization process, to home in on the target."
"METHOD OF DISPLAYING FLIGHT ROUTE OF UNMANNED AERIAL VEHICLE THAT FLIES AUTONOMOUSLY, TERMINAL, AND NON-TRANSITORY COMPUTER-READABLE RECORDING MEDIUM STORING PROGRAM",https://lens.org/051-940-685-193-925,2022,"A flight route control method of an unmanned aerial vehicle includes: accepting, by a touch panel, an input of a departure point and a waypoint that the unmanned aerial vehicle will pass; receiving a predetermined time, indicating an end of a time period in which the unmanned aerial vehicle is permitted to fly; generating a flight route passing through the departure point and the waypoint; determining whether or not an arrival time to the waypoint is later than the predetermined time; not accepting the waypoint for the generated flight route when the arrival time is later than the predetermined time; accepting the waypoint for the generated flight route when the arrival time is not later than the predetermined time; and transmitting a control command to the unmanned aerial vehicle, the control command controlling the unmanned aerial vehicle to fly according to the generated flight route."
"Control method for photographing using unmanned aerial vehicle, photographing method using unmanned aerial vehicle, mobile terminal, and unmanned aerial vehicle",https://lens.org/180-633-564-096-587,2020,"A method for operating an unmanned aerial vehicle (UAV) is performed by a mobile terminal. The mobile terminal displays an image transmission interface on a touchscreen of the mobile terminal, the image transmission interface including a picture taken by the UAV that is wirelessly connected to the mobile terminal. After detecting a touch control signal applied on the touchscreen, the mobile terminal acquires an operation gesture according to the touch control signal and generating a corresponding operation command according to the operation gesture and a current control mode of the image transmission interface. Finally, the mobile terminal sends the operation command to the UAV. The UAV then performs a predefined operation according to the operation command."
"CONTROL METHOD FOR PHOTOGRAPHING USING UNMANNED AERIAL VEHICLE, PHOTOGRAPHING METHOD USING UNMANNED AERIAL VEHICLE, MOBILE TERMINAL, AND UNMANNED AERIAL VEHICLE",https://lens.org/154-883-195-247-114,2018,"A method for operating an unmanned aerial vehicle (UAV) is performed by a mobile terminal. The mobile terminal displays an image transmission interface on a touchscreen of the mobile terminal, the image transmission interface including a picture taken by the UAV that is wirelessly connected to the mobile terminal. After detecting a touch control signal applied on the touchscreen, the mobile terminal acquires an operation gesture according to the touch control signal and generating a corresponding operation command according to the operation gesture and a current control mode of the image transmission interface. Finally, the mobile terminal sends the operation command to the UAV. The UAV then performs a predefined operation according to the operation command."
"CONTROL METHOD OF INTERNET OF THINGS DEVICE, AND ELECTRONIC DEVICE",https://lens.org/027-103-326-035-222,2023,"A control method and apparatus for of an Internet of Things device, and an electronic device (110) are provided. The method includes: sending an action call to the IoT device, wherein the action call includes a target service instance identification (siid), a target instance identification (iid), and a property parameter."
AUTONOMOUS DRONES FOR TACTILE FEEDBACK IN IMMERSIVE VIRTUAL REALITY,https://lens.org/123-897-241-665-396,2016,"A ""Tactile Autonomous Drone"" (TAD) (e.g., flying drones, mobile robots, etc.) supplies real-time tactile feedback to users immersed in virtual reality (VR) environments. TADs are not rendered into the VR environment, and are therefore not visible to users immersed in the VR environment. In various implementations, one or more TADs track users as they move through a real-world space while immersed in the VR environment. One or more TADs apply tracking information to autonomously position themselves, or one or more physical surfaces or objects carried by the TADs, in a way that enables physical contact between those surfaces or objects and one or more portions of the user's body. Further, this positioning of surfaces or objects corresponds to some real-time virtual event, virtual object, virtual character, virtual avatar of another user, etc., in the VR environment to provide real-time tactile feedback to users immersed in the VR environment."
AUTONOMOUS AERIAL VEHICLE OUTDOOR EXERCISE COMPANION,https://lens.org/190-131-887-222-923,2022,"A processing system of an autonomous aerial vehicle including at least one processor may navigate the autonomous aerial vehicle to accompany a user, project a visible personal safety zone around the user, where the visible personal safety zone comprises at least a portion of a field of view of a camera of the autonomous aerial vehicle, and project visual information for the user on at least one surface in the vicinity of the user."
AUTONOMOUS AERIAL VEHICLE OUTDOOR EXERCISE COMPANION,https://lens.org/190-131-887-222-923,2022,"A processing system of an autonomous aerial vehicle including at least one processor may navigate the autonomous aerial vehicle to accompany a user, project a visible personal safety zone around the user, where the visible personal safety zone comprises at least a portion of a field of view of a camera of the autonomous aerial vehicle, and project visual information for the user on at least one surface in the vicinity of the user."
Apparatus and method for installing and replacing light fixture devices,https://lens.org/044-185-950-854-991,2021,"an extension stick portion attached to a second end of the telescopic stick portion, and a drone-type device attached to the extension stick portion at an end opposite telescopic stick portion. The drone-type device receives power from the base portion through the telescopic stick portion and travels over and land at a top surface of the outdoor lighting fixture and perform installation or replacement of the lighting controller."
Two ways fishing line release for drone and uav,https://lens.org/171-763-734-195-975,2021,"The present disclosure discloses the fishing line release equipment and the method of the line release based on the widely used drone or UAV(Unmanned Aerial Vehicle). In order to protect the drone safely flying to the destination and facilitate fishing line release in a more convenient way, the fishing line release equipment comprises a base and a release wire, said base fixing a mechanical clip release and the electrical power controlled action that release a release wire in a clamp. A controller board and a battery are fixed on the base. A cover box covers the base and electrical part are protected by the cover box. The base is fixed on the drone or UAV, one end of the release wire clamping to a gap slot in the tube that is a part of the base, the other end of the release wire connecting to the main fishing line. The clamp force can be adjusted through the nuts in the ends of tube which adjust a spring tension acting on two ball bearings which are pressed together to form a clamp in order to hold the release wire up to a pre selected force. The release wire is clamped in the slot between the two ball bearings and the release wire is released when the pulling force coming from the fishing line excesses a threshold of a release force of the clamp.Each time a control key is pressed, an electrical motor makes a dial pad turn around, and a dial pin fixed on the dial pad pass through the gap, enforcing the two ball bearings to become separated and therefore allowing selective release of the release wire. A control signal can be supplied by a remote controller or a photoelectric switch or a signal output from the drone. Figure"
Two ways fishing line release for drone and uav,https://lens.org/150-700-743-214-963,2023,"The present disclosure discloses the fishing line release equipment and the method of the line release based on the widely used drone or UAV(Unmanned Aerial Vehicle). In order to protect the drone safely flying to the destination and facilitate fishing line release in a more convenient way, the fishing line release equipment comprises a base and a release wire, said base fixing a mechanical clip release and the electrical power controlled action that release a release wire in a clamp. A controller board and a battery are fixed on the base. A cover box covers the base and electrical part are protected by the cover box. The base is fixed on the drone or UAV, one end of the release wire clamping to a gap slot in the tube that is a part of the base, the other end of the release wire connecting to the main fishing line. The clamp force can be adjusted through the nuts in the ends of tube which adjust a spring tension acting on two ball bearings which are pressed together to form a clamp in order to hold the release wire up to a pre selected force. The release wire is clamped in the slot between the two ball bearings and the release wire is released when the pulling force coming from the fishing line excesses a threshold of a release force of the clamp.Each time a control key is pressed, an electrical motor makes a dial pad turn around, and a dial pin fixed on the dial pad pass through the gap, enforcing the two ball bearings to become separated and therefore allowing selective release of the release wire. A control signal can be supplied by a remote controller or a photoelectric switch or a signal output from the drone. Figure"
DRONE LANDING APPARATUS,https://lens.org/087-297-765-806-396,2019,"A drone landing apparatus may include: a trunk door configured to open or close a trunk of a vehicle; a drone housing contained in the trunk, and configured to provide a space in which a drone is housed; a rotator mounted on the trunk door, and configured to rotate the drone housing according to an opening angle of the trunk door; and a moving platform appearing from the drone housing or disappearing into the drone housing, and having the drone seated thereon."
Drone landing apparatus,https://lens.org/032-949-495-618-912,2021,"A drone landing apparatus may include: a trunk door configured to open or close a trunk of a vehicle; a drone housing contained in the trunk, and configured to provide a space in which a drone is housed; a rotator mounted on the trunk door, and configured to rotate the drone housing according to an opening angle of the trunk door; and a moving platform appearing from the drone housing or disappearing into the drone housing, and having the drone seated thereon."
METHOD AND APPARATUS FOR HANDLING GOODS BY UNMANNED AERIAL VEHICLE AND AUTONOMOUS VEHICLE,https://lens.org/043-768-665-426-62X,2022,"Provided is a method for an unmanned aerial vehicle to handle goods in cooperation with an autonomous vehicle. The method comprises capturing, by the unmanned aerial vehicle, an image of the autonomous vehicle having a goods storage box, recognizing, by the unmanned aerial vehicle, a marker displayed in the goods storage box by analyzing the captured image, identifying, by the unmanned aerial vehicle, a region occupied by the marker on the captured image, adjusting a relative position of the unmanned aerial vehicle and the autonomous vehicle, wherein the marker displayed in the goods storage box is covered by a lid of the goods storage box and placed in a state that cannot be captured by the unmanned aerial vehicle, and the marker is exposed in a state that can be captured by the unmanned aerial vehicle only when the lid of the storage box is opened by communication between the unmanned aerial vehicle and the autonomous vehicle."
Method and apparatus for handling goods by unmanned aerial vehicle and autonomous vehicle,https://lens.org/185-026-386-798-734,2022,"Provided is a method for an unmanned aerial vehicle to handle goods in cooperation with an autonomous vehicle. The method comprises capturing, by the unmanned aerial vehicle, an image of the autonomous vehicle having a goods storage box, recognizing, by the unmanned aerial vehicle, a marker displayed in the goods storage box by analyzing the captured image, identifying, by the unmanned aerial vehicle, a region occupied by the marker on the captured image, adjusting a relative position of the unmanned aerial vehicle and the autonomous vehicle, wherein the marker displayed in the goods storage box is covered by a lid of the goods storage box and placed in a state that cannot be captured by the unmanned aerial vehicle, and the marker is exposed in a state that can be captured by the unmanned aerial vehicle only when the lid of the storage box is opened by communication between the unmanned aerial vehicle and the autonomous vehicle."
METHOD AND APPARATUS FOR HANDLING GOODS BY UNMANNED AERIAL VEHICLE AND AUTONOMOUS VEHICLE,https://lens.org/043-768-665-426-62X,2022,"Provided is a method for an unmanned aerial vehicle to handle goods in cooperation with an autonomous vehicle. The method comprises capturing, by the unmanned aerial vehicle, an image of the autonomous vehicle having a goods storage box, recognizing, by the unmanned aerial vehicle, a marker displayed in the goods storage box by analyzing the captured image, identifying, by the unmanned aerial vehicle, a region occupied by the marker on the captured image, adjusting a relative position of the unmanned aerial vehicle and the autonomous vehicle, wherein the marker displayed in the goods storage box is covered by a lid of the goods storage box and placed in a state that cannot be captured by the unmanned aerial vehicle, and the marker is exposed in a state that can be captured by the unmanned aerial vehicle only when the lid of the storage box is opened by communication between the unmanned aerial vehicle and the autonomous vehicle."
Method and apparatus for handling goods by unmanned aerial vehicle and autonomous vehicle,https://lens.org/109-580-173-026-337,2023,"Provided is a method for an unmanned aerial vehicle to handle goods in cooperation with an autonomous vehicle. The method comprises capturing, by the unmanned aerial vehicle, an image of the autonomous vehicle having a goods storage box, recognizing, by the unmanned aerial vehicle, a marker displayed in the goods storage box by analyzing the captured image, identifying, by the unmanned aerial vehicle, a region occupied by the marker on the captured image, adjusting a relative position of the unmanned aerial vehicle and the autonomous vehicle, wherein the marker displayed in the goods storage box is covered by a lid of the goods storage box and placed in a state that cannot be captured by the unmanned aerial vehicle, and the marker is exposed in a state that can be captured by the unmanned aerial vehicle only when the lid of the storage box is opened by communication between the unmanned aerial vehicle and the autonomous vehicle."
Flight Control System For Unmanned Aerial Vehicle And Topography Measuring System,https://lens.org/190-576-809-353-161,2022,"A flight control system for an unmanned aerial vehicle comprises an unmanned aerial vehicle on which a reflector is mounted and a total station for tracking the reflector and for acquiring measurement data including three-dimensional coordinates of the reflector, wherein the total station comprises a tracking module for tracking the reflector, a data transmitting module having an optical axis parallel or approximately parallel to a tracking optical axis of the tracking module and for emitting a data transmitting light, and a TS-arithmetic control module, wherein the unmanned aerial vehicle has a photodetector for receiving the data transmitting light and for emitting a photodetecting signal and a UAV-arithmetic control module for controlling a flight of the unmanned aerial vehicle, and wherein the TS-arithmetic control module is configured to superimpose the measurement data on the data transmitting light, and the UAV-arithmetic control module is configured to separate the measurement data from the photodetecting signal and obtains a flight position of the unmanned aerial vehicle in real time."
Implementations for voice assistant on devices,https://lens.org/057-334-310-735-781,2022,"An electronic device configures a device-agnostic voice assistant library for execution on the electronic device based on the electronic device having a first device type. The electronic device also selects an implementation for the voice assistant library. After the configuring, the electronic device receives a verbal input from a user. It extracts request information from the verbal input by processing the verbal input using the voice assistant library executing on the device. It transmits a request to a remote system, the request including the extracted request information. The electronic device receives a response to the request. The response is generated by the remote system in accordance with the extracted request information. The electronic device performs an operation in accordance with the response by one or more voice processing modules of the configured voice assistant library."
Implementations for Voice Assistant on Devices,https://lens.org/043-915-104-842-460,2020,"An electronic device configures a device-agnostic voice assistant library for execution on the electronic device based on the electronic device having a first device type. The electronic device also selects an implementation for the voice assistant library. After the configuring, the electronic device receives a verbal input from a user. It extracts request information from the verbal input by processing the verbal input using the voice assistant library executing on the device. It transmits a request to a remote system, the request including the extracted request information. The electronic device receives a response to the request. The response is generated by the remote system in accordance with the extracted request information. The electronic device performs an operation in accordance with the response by one or more voice processing modules of the configured voice assistant library."
IMPLEMENTATIONS FOR VOICE ASSISTANT ON DEVICES,https://lens.org/170-410-307-098-484,2022,"An electronic device configures a device-agnostic voice assistant library for execution on the electronic device based on the electronic device having a first device type. The electronic device also selects an implementation for the voice assistant library. After the configuring, the electronic device receives a verbal input from a user. It extracts request information from the verbal input by processing the verbal input using the voice assistant library executing on the device. It transmits a request to a remote system, the request including the extracted request information. The electronic device receives a response to the request. The response is generated by the remote system in accordance with the extracted request information. The electronic device performs an operation in accordance with the response by one or more voice processing modules of the configured voice assistant library."
Implementations for voice assistant on devices,https://lens.org/057-334-310-735-781,2022,"An electronic device configures a device-agnostic voice assistant library for execution on the electronic device based on the electronic device having a first device type. The electronic device also selects an implementation for the voice assistant library. After the configuring, the electronic device receives a verbal input from a user. It extracts request information from the verbal input by processing the verbal input using the voice assistant library executing on the device. It transmits a request to a remote system, the request including the extracted request information. The electronic device receives a response to the request. The response is generated by the remote system in accordance with the extracted request information. The electronic device performs an operation in accordance with the response by one or more voice processing modules of the configured voice assistant library."
IMPLEMENTATIONS FOR VOICE ASSISTANT ON DEVICES,https://lens.org/170-410-307-098-484,2022,"An electronic device configures a device-agnostic voice assistant library for execution on the electronic device based on the electronic device having a first device type. The electronic device also selects an implementation for the voice assistant library. After the configuring, the electronic device receives a verbal input from a user. It extracts request information from the verbal input by processing the verbal input using the voice assistant library executing on the device. It transmits a request to a remote system, the request including the extracted request information. The electronic device receives a response to the request. The response is generated by the remote system in accordance with the extracted request information. The electronic device performs an operation in accordance with the response by one or more voice processing modules of the configured voice assistant library."
Method of controlling movement of graphics object and remote control device using the same,https://lens.org/154-183-758-138-310,2007,A remote control device is provided. The device includes an attitude sensing unit that senses the attitude of a device; an axis determining unit that determines one axis in space according to the attitude; a direction input unit that receives a selection command input of one of two directions that are parallel to the axis and are in opposite directions to each other; and a transmission unit that transmits a control signal to move a predetermined graphics object in a direction corresponding to the selection command.
Method of controlling movement of graphics object and remote control device using the same,https://lens.org/186-727-771-813-038,2012,A remote control device is provided. The device includes an attitude sensing unit that senses the attitude of a device; an axis determining unit that determines one axis in space according to the attitude; a direction input unit that receives a selection command input of one of two directions that are parallel to the axis and are in opposite directions to each other; and a transmission unit that transmits a control signal to move a predetermined graphics object in a direction corresponding to the selection command.
ANUNMANNED AERIAL VEHICLE-BASED RESCUE AND TRIAGE SYSTEM AND ITS METHOD THEREOF,https://lens.org/039-892-567-921-137,2022,"The system comprises a UAV with an onboard camera for carrying out online video stream for searching and detecting person lying on a ground; a navigation module for determining location of the person thereby positioning in the center of the frame of the video; a control unit for approaching and descending the UAV until positioned one meter away from the person lying on the ground and at 45-degree angle from face of the victim; a face detection module for detecting face of the victim once the drone is in position thereby the flight navigation changes to face navigation to position the camera over the region of interest (ROI); a photoplethysmography imaging technique for measuring heart and respiratory rate; and a communication module for transferring the geo positioning coordinates, heart rate, and respiratory rate information to a central processing unit. 4-4 uc < E"
Aerial material distribution method and apparatus,https://lens.org/144-155-244-397-170,2016,"A remotely-piloted aircraft for distributing a payload to a target area is provided. The aircraft includes an enclosure, which includes a top lid covering the top, an internal compartment to store the payload, a bottom surface, and a distribution apparatus to allow the payload to pass through the bottom surface. The aircraft also includes a circuit to control the distribution apparatus, a wireless receiver, to receive commands to activate and inactivate the distribution apparatus, and one or more power sources coupled to the distribution apparatus and the wireless receiver. The one or more power sources provide electrical power to the distribution apparatus and the wireless receiver. An operator controls the aircraft and the circuit with at least one of a wireless transmitter and an uploaded program in the circuit. When the wireless receiver receives a command to activate the distribution apparatus, the distribution apparatus distributes the payload from the enclosure."
SYSTEM AND METHOD FOR AUTONOMOUS VEHICLE LOCALIZATION,https://lens.org/127-961-284-857-821,2010,"An autonomous vehicle capable of determining its position in a space through improved communications with beacons is disclosed. The autonomous vehicle utilizes time of flight as well and angular information to determine position, and is capable of intelligent interaction with the beacons."
SYSTEM AND METHOD FOR AUTONOMOUS VEHICLE LOCALIZATION,https://lens.org/022-573-307-565-126,2010,"An autonomous vehicle capable of determining its position in a space through improved communications with beacons is disclosed. The autonomous vehicle utilizes time of flight as well and angular information to determine position, and is capable of intelligent interaction with the beacons."
System and method for autonomous vehicle localization,https://lens.org/156-632-121-693-580,2012,"An autonomous vehicle capable of determining its position in a space through improved communications with beacons is disclosed. The autonomous vehicle utilizes time of flight as well and angular information to determine position, and is capable of intelligent interaction with the beacons."
SYSTEM AND METHOD FOR AUTONOMOUS VEHICLE LOCALIZATION,https://lens.org/152-906-940-796-524,2010,"An autonomous vehicle capable of determining its position in a space through improved communications with beacons is disclosed. The autonomous vehicle utilizes time of flight as well and angular information to determine position, and is capable of intelligent interaction with the beacons."
DRONE DOCKING STATION FOR VEHICLE AND METHOD FOR CONTROLLING THE SAME,https://lens.org/186-188-829-744-179,2023,"A drone docking station for a vehicle includes: a transfer device configured to have a cargo loaded on a drone or to vertically move the cargo transferred by the drone; a guide device including a guide panel provided on a roof of the vehicle and connected to an upper end portion of the transfer device to have the drone accommodated on an upper portion of the guide panel, wherein the guide panel is disposed to surround the transfer device and provided to move inward or outward or to be rotated around a center portion of the transfer device; and a control unit electrically connected to the guide device and configured to rotate or move the guide panel so that the drone corresponds to the cargo positioned in the transfer device when the drone is accommodated on the guide panel."
AUTONOMOUS ROBOT,https://lens.org/045-788-052-221-518,2022,"An autonomous robot comprises: a body, that is elongated along an axis oriented transverse to a direction of movement of the robot and, connected to the elongated body, a multispectral sensor, precisely two wheels, and a stabilizing device for controlling the pitch of the elongated body when the wheels are in motion, the wheels being in the form of spoked wheels."
AUTONOMOUS ROBOT,https://lens.org/045-788-052-221-518,2022,"An autonomous robot comprises: a body, that is elongated along an axis oriented transverse to a direction of movement of the robot and, connected to the elongated body, a multispectral sensor, precisely two wheels, and a stabilizing device for controlling the pitch of the elongated body when the wheels are in motion, the wheels being in the form of spoked wheels."
AUTONOMOUS ROBOT,https://lens.org/045-788-052-221-518,2022,"An autonomous robot comprises: a body, that is elongated along an axis oriented transverse to a direction of movement of the robot and, connected to the elongated body, a multispectral sensor, precisely two wheels, and a stabilizing device for controlling the pitch of the elongated body when the wheels are in motion, the wheels being in the form of spoked wheels."
SYSTEMS AND METHODS FOR ADJUSTING FLIGHT CONTROL OF AN UNMANNED AERIAL VEHICLE,https://lens.org/000-871-346-089-713,2023,An unmanned aerial vehicle including an image sensor and one or more processors. The image sensor is carried by the unmanned aerial vehicle and is configured to generate output signals conveying visual information. The one or more processors include a distance component and a flight control component. The distance component configured to determine a distance between an object of interest and the unmanned aerial vehicle. The flight control component is configured to adjust a flight path of the unmanned aerial vehicle based on the distance between the object of interest and the unmanned aerial vehicle. The one or more processors are configured to: receive the visual information including the object of interest; and control the image sensor with a sensor control subsystem to adjust one or more parameters of the image sensor and to detect the object of interest.
UNMANNED AERIAL VEHICLE FLIGHT CONTROL SYSTEM,https://lens.org/129-317-516-720-37X,2017,An onboard system for controlling flight of an unmanned aerial vehicle (10). The system comprises: a flight management system (40) configured for controlling flight of the unmanned aerial vehicle (10); a mission control module (2) configured to send commands to the flight management system (40) for guiding the unmanned aerial vehicle (10) to perform a mission; a safety module (8) configured to communicate commands to the flight management system (40) for guiding the unmanned aerial vehicle (10) to fly in a safe mode; a communication control component (6) which is switchable between a mission state in which the flight management system (40) receives commands from the mission control module (2) and a safety state in which the flight management system (40) receives commands from the safety module (8); and a monitor module (4) configured to determine whether a trigger condition warranting a change in mode is present or not and to cause the communication control component (6) to switch from the mission state to the safety state when the trigger condition is present.
UNMANNED AERIAL VEHICLE FLIGHT CONTROL SYSTEM,https://lens.org/093-520-593-039-296,2022,An onboard system for controlling flight of an unmanned aerial vehicle (10). The system comprises: a flight management system (40) configured for controlling flight of the unmanned aerial vehicle (10); a mission control module (2) configured to send commands to the flight management system (40) for guiding the unmanned aerial vehicle (10) to perform a mission; a safety module (8) configured to communicate commands to the flight management system (40) for guiding the unmanned aerial vehicle (10) to fly in a safe mode; a communication control component (6) which is switchable between a mission state in which the flight management system (40) receives commands from the mission control module (2) and a safety state in which the flight management system (40) receives commands from the safety module (8); and a monitor module (4) configured to determine whether a trigger condition warranting a change in mode is present or not and to cause the communication control component (6) to switch from the mission state to the safety state when the trigger condition is present.
UNMANNED AERIAL VEHICLE FLIGHT CONTROL SYSTEM,https://lens.org/185-294-338-205-261,2017,"An onboard system for controlling flight of an unmanned aerial vehicle (10). The system comprises: a flight management system (40) configured for controlling flight of the unmanned aerial vehicle (10); a mission control module (2) configured to send commands to the flight management system (40) for guiding the unmanned aerial vehicle (10) to perform a mission; a safety module (8) configured to communicate commands to the flight management system (40) for guiding the unmanned aerial vehicle (10) to fly in a safe mode; a communication control component (6) which is switchable between a mission state in which the flight management system (40) receives commands from the mission control module (2) and a safety state in which the flight management system (40) receives commands from the safety module (8); and a monitor module (4) configured to determine whether a trigger condition warranting a change in mode is present or not and to cause the communication control component (6) to switch from the mission state to the safety state when the trigger condition is present.
"
Remote-control device for video camera,https://lens.org/132-700-303-331-944,2003,"A remote control device, which includes conventional remote system and wireless remote system, to control a handheld video camera without directional limitation. Generic handheld video camera controller are using IR signals which require the signal source to be pointing at the video camera IR receiver inlet lens in order for the system to facilitate the remote control functions. This device provides users a remote controlling means to control the video camera from a distance away with a physical wall or blockage in between. This device turns most of the available handheld video cameras into quality surveillance video cameras. This device makes surveillance video system much more affordable. Since this device is a universal device, it works with most generic video cameras of different brands; users can choose their favorite brand to be their surveillance camera. This device is covered with a rain shield and is suitable for both indoor and outdoor usage."
"AUTONOMOUS VEHICLE, CONTROL SYSTEM FOR REMOTELY CONTROLLING THE SAME, AND METHOD THEREOF",https://lens.org/115-589-557-697-584,2023,"An autonomous vehicle, a control system for remotely controlling the same, and a method thereof, includes an autonomous driving control apparatus including a processor that is configured for controlling remote driving for an autonomous vehicle by obtaining information related to a shaded section caused by a sensor failure according to surrounding information of the autonomous vehicle when receiving a remote driving control request and information related to the shaded section from the autonomous vehicle."
"AUTONOMOUS VEHICLE, CONTROL SYSTEM FOR REMOTELY CONTROLLING THE SAME, AND METHOD THEREOF",https://lens.org/115-589-557-697-584,2023,"An autonomous vehicle, a control system for remotely controlling the same, and a method thereof, includes an autonomous driving control apparatus including a processor that is configured for controlling remote driving for an autonomous vehicle by obtaining information related to a shaded section caused by a sensor failure according to surrounding information of the autonomous vehicle when receiving a remote driving control request and information related to the shaded section from the autonomous vehicle."
SYSTEMS AND METHODS FOR DELIVERING MERCHANDISE USING AUTONOMOUS GROUND VEHICLES AND UNMANNED AERIAL VEHICLES,https://lens.org/155-848-044-422-58X,2022,"In some embodiments, apparatuses and methods are provided herein useful to delivering merchandise using autonomous ground vehicles (AGVs) in cooperation with unmanned aerial vehicles (UAVs). In some embodiments, the system includes: an AGV having a motorized locomotion system, a storage area to hold merchandise, a sensor to detect obstacles, a transceiver, and a control circuit to operate the AGV; a UAV having a motorized flight system, a gripper mechanism to grab merchandise, a transceiver, an optical sensor to capture images; and a control circuit to operate the UAV. The system also includes a control circuit that instructs movement of the AGV along a delivery route; determines if the AGV has stopped due to an obstacle; and in certain circumstances, instructs the UAV to retrieve merchandise from the AGV, calculate a delivery route for the UAV to the delivery location, and instructs the UAV to deliver the merchandise."
Systems and methods for delivering merchandise using autonomous ground vehicles and unmanned aerial vehicles,https://lens.org/173-416-343-147-251,2023,"In some embodiments, apparatuses and methods are provided herein useful to delivering merchandise using autonomous ground vehicles (AGVs) in cooperation with unmanned aerial vehicles (UAVs). In some embodiments, the system includes: an AGV having a motorized locomotion system, a storage area to hold merchandise, a sensor to detect obstacles, a transceiver, and a control circuit to operate the AGV; a UAV having a motorized flight system, a gripper mechanism to grab merchandise, a transceiver, an optical sensor to capture images; and a control circuit to operate the UAV. The system also includes a control circuit that instructs movement of the AGV along a delivery route; determines if the AGV has stopped due to an obstacle; and in certain circumstances, instructs the UAV to retrieve merchandise from the AGV, calculate a delivery route for the UAV to the delivery location, and instructs the UAV to deliver the merchandise."
SYSTEMS AND METHODS FOR DELIVERING MERCHANDISE USING AUTONOMOUS GROUND VEHICLES AND UNMANNED AERIAL VEHICLES,https://lens.org/129-758-458-815-306,2018,"In some embodiments, apparatuses and methods are provided herein useful to delivering merchandise using autonomous ground vehicles (AGVs) in cooperation with unmanned aerial vehicles (UAVs). In some embodiments, the system includes: an AGV having a motorized locomotion system, a storage area to hold merchandise, a sensor to detect obstacles, a transceiver, and a control circuit to operate the AGV; a UAV having a motorized flight system, a gripper mechanism to grab merchandise, a transceiver, an optical sensor to capture images; and a control circuit to operate the UAV. The system also includes a control circuit that instructs movement of the AGV along a delivery route; determines if the AGV has stopped due to an obstacle; and in certain circumstances, instructs the UAV to retrieve merchandise from the AGV, calculate a delivery route for the UAV to the delivery location, and instructs the UAV to deliver the merchandise."
Systems and methods for delivering merchandise using autonomous ground vehicles and unmanned aerial vehicles,https://lens.org/173-416-343-147-251,2023,"In some embodiments, apparatuses and methods are provided herein useful to delivering merchandise using autonomous ground vehicles (AGVs) in cooperation with unmanned aerial vehicles (UAVs). In some embodiments, the system includes: an AGV having a motorized locomotion system, a storage area to hold merchandise, a sensor to detect obstacles, a transceiver, and a control circuit to operate the AGV; a UAV having a motorized flight system, a gripper mechanism to grab merchandise, a transceiver, an optical sensor to capture images; and a control circuit to operate the UAV. The system also includes a control circuit that instructs movement of the AGV along a delivery route; determines if the AGV has stopped due to an obstacle; and in certain circumstances, instructs the UAV to retrieve merchandise from the AGV, calculate a delivery route for the UAV to the delivery location, and instructs the UAV to deliver the merchandise."
SYSTEMS AND METHODS FOR DELIVERING MERCHANDISE USING AUTONOMOUS GROUND VEHICLES AND UNMANNED AERIAL VEHICLES,https://lens.org/155-848-044-422-58X,2022,"In some embodiments, apparatuses and methods are provided herein useful to delivering merchandise using autonomous ground vehicles (AGVs) in cooperation with unmanned aerial vehicles (UAVs). In some embodiments, the system includes: an AGV having a motorized locomotion system, a storage area to hold merchandise, a sensor to detect obstacles, a transceiver, and a control circuit to operate the AGV; a UAV having a motorized flight system, a gripper mechanism to grab merchandise, a transceiver, an optical sensor to capture images; and a control circuit to operate the UAV. The system also includes a control circuit that instructs movement of the AGV along a delivery route; determines if the AGV has stopped due to an obstacle; and in certain circumstances, instructs the UAV to retrieve merchandise from the AGV, calculate a delivery route for the UAV to the delivery location, and instructs the UAV to deliver the merchandise."
Device for and method of locating remote control for apparatuses,https://lens.org/168-862-033-419-070,2004,"For locating a remote control operative for controlling an operation of an apparatus, an apparatus turning element is activated by a user, and simultaneously a signal generating element is activated to send a signal to the remote control so that the remote control produces a user recognizable signal."
AUTONOMOUS SERVICING OF NETWORK DEVICES,https://lens.org/055-038-324-643-993,2021,"Various arrangements for autonomous servicing of a network device are presented. A backend server system may receive status data from various devices. The backend server system may determine, based at least in part on the received status data, a triggering event associated with a first device. In response to the determined triggering event, location information associated with the first device may be sent to an unmanned aerial vehicle (UAV). The UAV may send security information directly to the first device. The first device may be required to validate the security device, then the UAV may modify a physical component of the first device."
METHOD AND APPARATUS FOR CONTROLLING THE OPERATION OF AERIAL UEs,https://lens.org/029-922-769-444-705,2019,"The present disclosure is directed to a method and apparatus for controlling the operation of aerial UEs. An example of the method may include: determining whether an aerial UE is in an autonomous mode or in a non-autonomous mode; determining the flight path information of the aerial UE; and reporting the flight path information of the aerial UE. When the aerial UE is in the autonomous mode, the flight path information is reported when a first reporting period expires or the path deviation of the aerial UE is larger than a deviation threshold. When the aerial UE is in the non-autonomous mode, the flight path information is reported when a second reporting period less than the first reporting period expires or when at least one of the flying direction and flying speed of the aerial UE changes. Embodiments of the present disclosure solve the technical problem concerning the control of the operation of aerial UEs based on various behaviors."
Method and apparatus for controlling the operation of aerial UEs,https://lens.org/151-615-795-439-670,2022,"The present disclosure is directed to a method and apparatus for controlling the operation of aerial UEs. An example of the method may include: determining whether an aerial UE is in an autonomous mode or in a non-autonomous mode; determining the flight path information of the aerial UE; and reporting the flight path information of the aerial UE. When the aerial UE is in the autonomous mode, the flight path information is reported when a first reporting period expires or the path deviation of the aerial UE is larger than a deviation threshold. When the aerial UE is in the non-autonomous mode, the flight path information is reported when a second reporting period less than the first reporting period expires or when at least one of the flying direction and flying speed of the aerial UE changes. Embodiments of the present disclosure solve the technical problem concerning the control of the operation of aerial UEs based on various behaviors."
METHOD AND APPARATUS FOR CONTROLLING THE OPERATION OF AERIAL UEs,https://lens.org/037-680-584-406-754,2021,"The present disclosure is directed to a method and apparatus for controlling the operation of aerial UEs. An example of the method may include: determining whether an aerial UE is in an autonomous mode or in a non-autonomous mode; determining the flight path information of the aerial UE; and reporting the flight path information of the aerial UE. When the aerial UE is in the autonomous mode, the flight path information is reported when a first reporting period expires or the path deviation of the aerial UE is larger than a deviation threshold. When the aerial UE is in the non-autonomous mode, the flight path information is reported when a second reporting period less than the first reporting period expires or when at least one of the flying direction and flying speed of the aerial UE changes. Embodiments of the present disclosure solve the technical problem concerning the control of the operation of aerial UEs based on various behaviors."
Method and apparatus for controlling the operation of aerial UEs,https://lens.org/151-615-795-439-670,2022,"The present disclosure is directed to a method and apparatus for controlling the operation of aerial UEs. An example of the method may include: determining whether an aerial UE is in an autonomous mode or in a non-autonomous mode; determining the flight path information of the aerial UE; and reporting the flight path information of the aerial UE. When the aerial UE is in the autonomous mode, the flight path information is reported when a first reporting period expires or the path deviation of the aerial UE is larger than a deviation threshold. When the aerial UE is in the non-autonomous mode, the flight path information is reported when a second reporting period less than the first reporting period expires or when at least one of the flying direction and flying speed of the aerial UE changes. Embodiments of the present disclosure solve the technical problem concerning the control of the operation of aerial UEs based on various behaviors."
Self-propelled device,https://lens.org/199-165-102-080-332,2021,"A spherical, self-propelled device responds to remote controls from a user. The self-propelled device has an internal drive system and an internal vision system. The vision system remains in a constant orientation with respect to the spherical, self-propelled device. As the spherical, self-propelled device rolls along a surface, the internal vision system captures video data from an upward field of view."
Self-Propelled Device,https://lens.org/007-787-680-227-432,2019,"A spherical, self-propelled device responds to remote controls from a user. The self-propelled device has an internal drive system and an internal vision system. The vision system remains in a constant orientation with respect to the spherical, self-propelled device. As the spherical, self-propelled device rolls along a surface, the internal vision system captures video data from an upward field of view."
Interface apparatus and mobile robot equipped with the interface apparatus,https://lens.org/183-245-967-759-044,2011,A robot recording a message on a wireless tag which includes: a voice recognition unit recognizing a voice input by a voice input unit which inputs a voice of a person; a message extraction unit extracting the message from the voice recognized by the voice recognition unit based on a fixed phrase provided for obtaining a message; a recording unit recording the message extracted by the message extraction unit on the wireless tag provided on an object.
ARTIFICIAL INTELLIGENCE MOVING ROBOT AND METHOD FOR CONTROLLING THE SAME,https://lens.org/135-420-447-657-604,2020,"An artificial intelligence (AI) robot and a method for controlling the AI robot, includes detecting a target object changing its position in a travel area after determining a condition of the travel area based on an image captured by an image capturing unit while the AI robot is traveling in the travel area. The AI robot is controlled to travel based on the target object detected."
METHOD AND SYSTEM FOR PERFORMING INVASIVE MEDICAL PROCEDURES USING A SURGICAL ROBOT,https://lens.org/006-647-737-762-33X,2008,"A method and system for performing invasive procedures includes a surgical robot which is controlled by a guidance system that uses time of flight calculations from RF transmitters embedded in the robot, surgical instrument, and patient anatomy. Sensors around the room detect RF transmissions emitted by the RF transmitters and drive the robot according to a preprogrammed trajectory entered into the guidance system."
METHOD AND SYSTEM FOR PERFORMING INVASIVE MEDICAL PROCEDURES USING A SURGICAL ROBOT,https://lens.org/193-226-573-794-049,2008,"A method and system for performing invasive procedures includes a surgical robot which is controlled by a guidance system that uses time of flight calculations from RF transmitters embedded in the robot, surgical instrument, and patient anatomy. Sensors around the room detect RF transmissions emitted by the RF transmitters and drive the robot according to a preprogrammed trajectory entered into the guidance system."
OPERATING INTERNET OF THINGS DEVICES USING LiDAR METHOD AND APPARATUS,https://lens.org/021-395-678-771-986,2017,"Techniques and configurations for an apparatus(100) for controlling IoT devices(110, 112, 114) are provided. In one instance, an apparatus (100) may include a LiDAR scanner (102) having a laser (104) to scan (106) an environment(108) to obtain scan data. Scanning may include illuminating a point of the environment (108) and measuring a distance to that point based on a difference between a time of transmission of a beam to illuminate the point and a time of receipt of a beam reflected by the point. The apparatus (100) may further include a controller (130) to collect and analyze the scan data, detect a presence of a user (120, 122, 124) in the environment (108), detect and identify a gesture provided by the user (120, 122, 124 ), and provide a command to one or more IoT devices (110, 112, 114) that are responsive to commands provided by user gestures, based in part on the identified gesture."
Communication with Unmanned Underwater Vehicles,https://lens.org/014-521-820-530-915,2021,"A task such as inspection is performed at a subsea location by positioning a functional unit such as an unmanned underwater vehicle to perform the task. When positioned to perform the task, the unit is then in a shadow region where wireless control signals from a subsea control transmitter are obscured by a subsea obstacle. Consequently, control signals arre transmitted wirelessly through water from the control transmitter to an autonomous underwater vehicle (AUV) positioned outside the shadow region and are relayed from the AUV to the unit to control the unit to perform the task. The unit can be tethered to the AUV or can communicate with the AUV wirelessly. The AUV can move itself to improve wireless communication with the subsea control transmitter and optionally also with the unit."
MULTIROTOR TYPE UNMANNED AERIAL VEHICLE AVAILABLE FOR ADJUSTING DIRECTION OF THRUST,https://lens.org/037-234-390-383-89X,2016,"The multi-rotor type unmanned aerial vehicle includes: a main body including the battery module and the control module; a plurality of frames connected to a side surface of the main body and extending therefrom; a first motor connected to a distal end of each of the frames; and a drive unit connected to the first motor, wherein the drive unit includes a rotary frame and a stationary frame each having a circular shape and connected to each other in the form of a gyroscope, a second motor supported at the center of the rotatable frame, and a propeller connected to the second motor, and a vector of thrust generated by rotation of the propeller is variable according to rotation of the first and second motors."
SCISSOR ARM FOR UNMANNED ROBOTIC SYSTEM,https://lens.org/122-766-024-182-236,2019,"The present invention recites a scissor arm for an unmanned robotic system such as a UAV, also known as a drone. This arm would typically be installed on the underside of a UAV with hover capability. The arm is designed to simultaneously vertically lower and horizontally extend a payload, permitting a person to interact with the payload without risk of injury by the UAV's propellers. This aim is practical for applications such as a routine police traffic stop, wherein an officer can safely remain in their vehicle and interact with the driver via a drone equipped with communication equipment and such an arm. The drone's arm can present the driver with a box for gathering documents from the driver without risk of injuring the driver or damaging the driver's vehicle. This is accomplished by two inventive ""L""-shaped trusses that offset the arm's payload horizontally as the arm is extended downward."
SCISSOR ARM FOR UNMANNED ROBOTIC SYSTEM,https://lens.org/146-599-546-516-411,2023,"The present invention recites a scissor arm for an unmanned robotic system such as a UAV, also known as a drone. This arm would typically be installed on the underside of a UAV with hover capability. The arm is designed to simultaneously vertically lower and horizontally extend a payload, permitting a person to interact with the payload without risk of injury by the UAV's propellers. This aim is practical for applications such as a routine police traffic stop, wherein an officer can safely remain in their vehicle and interact with the driver via a drone equipped with communication equipment and such an arm. The drone's arm can present the driver with a box for gathering documents from the driver without risk of injuring the driver or damaging the driver's vehicle. This is accomplished by two inventive ""L""-shaped trusses that offset the arm's payload horizontally as the arm is extended downward."
Helicopter remote control system,https://lens.org/050-801-845-257-689,1991,"A remote controlled helicoper having a video radio frequency link to a fixed control location has a video camera with a field of view including the terrain forward of the helicopter, an airspeed display, a relative wind direction indicator, and a pitch indicator. A video monitor at the fixed location displays received video signals of the terrain, airspeed, relative wind direction and pitch permitting control of the helicopter over a radio link from the fixed location to the helicopter. The system provides training, experience, and practice in operation of the helicopter."
SELF-PROPELLED DEVICE,https://lens.org/168-766-092-752-981,2018,"A spherical, self-propelled device responds to remote controls from a user. The self- propelled device has an internal drive system and an internal vision system. The vision system remains in a constant orientation with respect to the spherical, self-propelled device. As the spherical, self-propelled device rolls along a surface, the internal vision system captures video data from an upward field of view."
SELF-PROPELLED DEVICE,https://lens.org/105-545-423-661-159,2017,"A spherical, self-propelled device responds to remote controls from a user. The self- propelled device has an internal drive system and an internal vision system. The vision system remains in a constant orientation with respect to the spherical, self-propelled device. As the spherical, self-propelled device rolls along a surface, the internal vision system captures video data from an upward field of view."
UAV LAUNCHING FROM MOVING PLATFORM,https://lens.org/179-289-910-771-069,2014,"A system for launching an unmanned aerial vehicle (UAV) from a moving platform, the system comprising: a platform configured to carry the UAV; one or more sensors configured to measure forces acting between said platform and said UAV in one or more directions; a mooring mechanism configured to moor said UAV to said platform; and a controller configured to: transmit at least one trimming command to said UAV based on measurements of said one or more sensors, and cause said mooring mechanism to release said UAV from said platform following the transmitting of the at least one trimming command, when the measurements of said one or more sensors indicate that a lift force is sufficiently close to a weight of the UAV."
ELECTRONIC DEVICE AND METHOD FOR CONTROLLING THE ELECTRONIC DEVICE THEREOF,https://lens.org/002-362-496-890-589,2022,"An artificial intelligence (AI) system utilizing a machine learning algorithm such as deep learning for controlling an electronic device when a video is reproduced and a user's voice instruction is received, to acquire a frame corresponding to the time point when the input of the user's voice instruction is received, and obtain a search result for information on objects in the frame using an AI model trained according to at least one of machine learning, a neural network or a deep learning algorithm."
ELECTRONIC DEVICE AND METHOD FOR CONTROLLING THE ELECTRONIC DEVICE THEREOF,https://lens.org/002-362-496-890-589,2022,"An artificial intelligence (AI) system utilizing a machine learning algorithm such as deep learning for controlling an electronic device when a video is reproduced and a user's voice instruction is received, to acquire a frame corresponding to the time point when the input of the user's voice instruction is received, and obtain a search result for information on objects in the frame using an AI model trained according to at least one of machine learning, a neural network or a deep learning algorithm."
ELECTRONIC DEVICE AND METHOD FOR CONTROLLING THE ELECTRONIC DEVICE THEREOF,https://lens.org/168-130-382-865-948,2019,"An artificial intelligence (AI) system utilizing a machine learning algorithm such as deep learning for controlling an electronic device when a video is reproduced and a user's voice instruction is received, to acquire a frame corresponding to the time point when the input of the user's voice instruction is received, and obtain a search result for information on objects in the frame using an AI model trained according to at least one of machine learning, a neural network or a deep learning algorithm."
AUTONOMOUS GROUND STATION INTERFACING AERIAL DELIVERY,https://lens.org/183-843-523-607-04X,2014,"To provide an autonomous ground station (20) for interfacing aerial delivery, which handles autonomously the reception of a smart parcel box (21) from a drone (22), then delivering each content in each sub-parcel to a specific person, and returning back the empty smart parcels to the drone (22). The station (20) is made of many empty coupled in-out columns (30) opened to receive boxes (21) from drones to move inside the machine (20), wherein each box (21) is made of cells (24), containing sub-parcels, to be delivered via a mini-gate (25), that is actuated after entering the sub-parcel code to the machine (20) via a data entry system (38). The boxes are moved through the station (20) from the inlet downward under gravity, and then depending on hydraulically piston supported plates (40), (41) it is pushed to the exit column (32), and then out to be collected via the drone 22)."
AUTONOMOUS GROUND STATION INTERFACING AERIAL DELIVERY,https://lens.org/035-661-268-474-791,2015,"To provide an autonomous ground station (20) for interfacing aerial delivery, which handles autonomously the reception of a smart parcel box (21) from a drone (22), then delivering each content in each sub-parcel to a specific person, and returning back the empty smart parcels to the drone (22). The station (20) is made of many empty coupled in-out columns (30) opened to receive boxes (21) from drones to move inside the machine (20), wherein each box (21) is made of cells (24), containing sub-parcels, to be delivered via a mini-gate (25), that is actuated after entering the sub-parcel code to the machine (20) via a data entry system (38). The boxes are moved through the station (20) from the inlet downward under gravity, and then depending on hydraulically piston supported plates (40), (41) it is pushed to the exit column (32), and then out to be collected via the drone 22)."
AUTONOMOUS GROUND STATION INTERFACING AERIAL DELIVERY,https://lens.org/173-014-089-616-11X,2014,"To provide an autonomous ground station (20) for interfacing aerial delivery, which handles autonomously the reception of a smart parcel box (21) from a drone (22), then delivering each content in each sub-parcel to a specific person, and returning back the empty smart parcels to the drone (22). The station (20) is made of many empty coupled in-out columns (30) opened to receive boxes (21) from drones to move inside the machine (20), wherein each box (21) is made of cells (24), containing sub-parcels, to be delivered via a mini-gate (25), that is actuated after entering the sub-parcel code to the machine (20) via a data entry system (38). The boxes are moved through the station (20) from the inlet downward under gravity, and then depending on hydraulically piston supported plates (40), (41) it is pushed to the exit column (32), and then out to be collected via the drone 22)."
"LOAD CONTROL METHOD AND DEVICE BASED ON UNMANNED AERIAL VEHICLE, AND UNMANNED AERIAL VEHICLE",https://lens.org/104-255-034-305-052,2020,"A load control method and device based on a UAV, and a UVA. The UVA includes: a UVA body, a propeller arm with a first end connected to the UVA body, a propeller blade connected to a second end of the propeller arm and a processor installed in the UVA body; a length of the propeller arm and a size of the propeller blade are adjustable. The control method includes: determining load gravity of the UVA based on a carrying object of the UVA; determining a target lift of the UVA based on the load gravity; determining a target size of the propeller blade and a target length of the propeller arm based on the target lift; and adjusting the propeller arm to the target length and the propeller blade to the target size, so that the UVA controls the propeller blade to rotate to carry the carrying object."
Remote control of ear mounted audio devices,https://lens.org/108-992-355-790-058,2023,"A remote controller for a sound delivery system such as hearing aids and headsets is shown and described. The remote controller has control buttons corresponding to control functions of the sound delivery system, a signal generator, a signal transmitter, and a power supply. The sound delivery system is worn on the head or ears, and includes speakers, sounding controlling elements, a signal receiver for communication with the remote controller, a power supply, and audible and/or visible beacons for implementing a locator function if misplaced or lost. The remote controller may be a stand alone, dedicated component physically separate from the sound delivery system, or alternatively, may be implemented as an application downloadable to a cellular telephone. The application causes manual controls corresponding to those of a hearing aid or stereophonic controls to appear on a screen of the cellular telephone."
SYSTEMS AND DEVICES FOR REMOTELY OPERATED UNMANNED AERIAL VEHICLE REPORT-SUPPRESSING LAUNCHER WITH PORTABLE RF TRANSPARENT LAUNCH TUBE,https://lens.org/092-326-738-270-929,2011,"An unmanned aerial vehicle (UAV) launch tube that comprises a tethered sabot configured to engage a UAV within a launcher volume defined by an inner wall, the tethered sabot dimensioned to provide a pressure seal at the inner wall and tethered to the inner wall, and wherein the tethered sabot is hollow having an open end oriented toward a high pressure volume and a tether attached within a hollow of the sabot and attached to the inner wall retaining the high pressure volume or attach to the inner base wall. A system comprising a communication node and a launcher comprising an unmanned aerial vehicle (UAV) in a pre-launch state configured to receive and respond to command inputs from the communication node."
Systems and devices for remotely operated unmanned aerial vehicle report-suppressing launcher with portable rf transparent launch tube,https://lens.org/126-556-362-041-612,2015,"An unmanned aerial vehicle (UAV) launch tube that comprises a tethered sabot configured to engage a UAV within a launcher volume defined by an inner wall, the tethered sabot dimensioned to provide a pressure seal at the inner wall and tethered to the inner wall, and wherein the tethered sabot is hollow having an open end oriented toward a high pressure volume and a tether attached within a hollow of the sabot and attached to the inner wall retaining the high pressure volume or attach to the inner base wall. A system comprising a communication node and a launcher comprising an unmanned aerial vehicle (UAV) in a pre-launch state configured to receive and respond to command inputs from the communication node."
SYSTEMS AND DEVICES FOR REMOTELY OPERATED UNMANNED AERIAL VEHICLE REPORT-SUPPRESSING LAUNCHER WITH PORTABLE RF TRANSPARENT LAUNCH TUBE,https://lens.org/176-340-828-676-54X,2012,"An unmanned aerial vehicle (UAV) launch tube that comprises a tethered sabot configured to engage a UAV within a launcher volume defined by an inner wall, the tethered sabot dimensioned to provide a pressure seal at the inner wall and tethered to the inner wall, and wherein the tethered sabot is hollow having an open end oriented toward a high pressure volume and a tether attached within a hollow of the sabot and attached to the inner wall retaining the high pressure volume or attach to the inner base wall. A system comprising a communication node and a launcher comprising an unmanned aerial vehicle (UAV) in a pre-launch state configured to receive and respond to command inputs from the communication node."
Systems and devices for remotely operated unmanned aerial vehicle report-suppressing launcher with portable RF transparent launch tube,https://lens.org/168-415-948-800-385,2013,"An unmanned aerial vehicle (UAV) launch tube that comprises a tethered sabot configured to engage a UAV within a launcher volume defined by an inner wall, the tethered sabot dimensioned to provide a pressure seal at the inner wall and tethered to the inner wall, and wherein the tethered sabot is hollow having an open end oriented toward a high pressure volume and a tether attached within a hollow of the sabot and attached to the inner wall retaining the high pressure volume or attach to the inner base wall. A system comprising a communication node and a launcher comprising an unmanned aerial vehicle (UAV) in a pre-launch state configured to receive and respond to command inputs from the communication node."
Virtual radar system for unmanned aerial vehicles,https://lens.org/057-390-756-466-121,2021,"In various embodiments, a safety system for an unmanned aerial vehicles (UAV) enable the safe operation of the UAV within an airspace by, for example, initiating various actions based on the position of the UAV relative to one or more flight zones and/or relative to other aircraft in the airspace."
"Following control method, control terminal, and unmanned aerial vehicle",https://lens.org/109-570-032-127-522,2022,The present disclosure provides a following control method. The method includes receiving and displaying an acquired image acquired by an imaging device of an unmanned aerial vehicle (UAV); detecting a user's selection operation on two or more objects in the image; determining a following instruction based on the detected selection operation; and controlling the UAV to follow the two or more followed objects indicated by the following instruction so that the two or more followed objects are in an imaging frame of the imaging device.
"Following control method, control terminal, and unmanned aerial vehicle",https://lens.org/109-570-032-127-522,2022,The present disclosure provides a following control method. The method includes receiving and displaying an acquired image acquired by an imaging device of an unmanned aerial vehicle (UAV); detecting a user's selection operation on two or more objects in the image; determining a following instruction based on the detected selection operation; and controlling the UAV to follow the two or more followed objects indicated by the following instruction so that the two or more followed objects are in an imaging frame of the imaging device.
"FOLLOWING CONTROL METHOD, CONTROL TERMINAL, AND UNMANNED AERIAL VEHICLE",https://lens.org/107-100-316-149-206,2020,The present disclosure provides a following control method. The method includes receiving and displaying an acquired image acquired by an imaging device of an unmanned aerial vehicle (UAV); detecting a user's selection operation on two or more objects in the image; determining a following instruction based on the detected selection operation; and controlling the UAV to follow the two or more followed objects indicated by the following instruction so that the two or more followed objects are in an imaging frame of the imaging device.
Voice-controlled remote control device,https://lens.org/013-698-245-673-190,2015,"The invention provides a voice-controlled remote control device. The voice-controlled remote control device mainly comprises an input unit, a voice recognition unit, a marching set unit, a transmitting unit and a receiving unit, wherein the voice input unit is used for converting a received voice command to a voice signal and transmitting out the voice signal; the voice recognition unit receives the voice signal, generating a coded message corresponding to the voice signal and transmitting out the coded message; the marching set unit decodes the coded message, generating a control message and transmitting out the control message; the transmitting unit receives a marching command and transmitting out the marching command; the receiving unit is used for receiving the marching command so as to drive a remote control car to perform marching movement corresponding to the marching command. Thus, the remote control device has real-time control function, and enables the remote control car to perform continuous marching movement and a series of marching movement, or can simulate the marching movement of the car actually."
Garbage searching and picking device and system for dangerous region,https://lens.org/071-154-910-123-307,2016,"The invention relates to a garbage searching and picking device and system for a dangerous region, and the device comprises a remote control helicopter which is provided with a camera and a mechanical arm. During operation, the camera is used for detecting a cleaning region, and captures a target, so the device is very convenient. The mechanical arm is used for picking the target, is very convenient, is high in automation degree, is large in cleaning region, and greatly reduces the cleaning danger."
AMPHIBIOUS DRONE,https://lens.org/138-004-625-049-035,2022,"An amphibious drone having a fuselage, a vertical tail, a wing and a take-off and landing device. The take-off and landing device is on the lower surface of the fuselage or the vertical tail or the wing. The take-off and landing device has a buoyancy unit and a power device, and the power device is capable of generating thrust to push the buoyancy unit to move. The take-off and landing device can be on the lower surface of the drone, and realizes the water support of the drone by symmetrically providing the take-off and landing device. At the same time, the take-off and landing device is further provided with a power device for pushing the drone to be started. The amphibious drone can take off and land by relying on the take-off and landing device, which can be disassembled to adapt to different usage conditions."
CONTROLLER FOR CONTROLLING PLURALITY OF LIGHT SOURCES,https://lens.org/141-860-960-691-666,2019,"A controller 102, 202 for controlling a plurality of light sources is disclosed. The controller 102, 202 comprises a receiver 106, 206 configured to receive a sound input from a plurality of microphones, the sound input being a user input from a user, a localization module 108, 208 configured to determine a user location of the user relative to the plurality of microphones based on differences between the sound input received at different microphones of the plurality of microphones, and a processor 110, 210 configured to receive location information indicative of locations of the plurality of light sources, determine which one or more light sources of the plurality of light sources are associated with the user location based on the location information, and control the one or more light sources based on the sound input."
A CONTROLLER FOR CONTROLLING A PLURALITY OF LIGHT SOURCES.,https://lens.org/035-895-779-358-161,2018,"A controller 102, 202 for controlling a plurality of light sources is disclosed. The controller 102, 202 comprises a receiver 106, 206 configured to receive a sound input from a plurality of microphones, the sound input being a user input from a user, a localization module 108, 208 configured to determine a user location of the user relative to the plurality of microphones based on differences between the sound input received at different microphones of the plurality of microphones, and a processor 110, 210 configured to receive location information indicative of locations of the plurality of light sources, determine which one or more light sources of the plurality of light sources are associated with the user location based on the location information, and control the one or more light sources based on the sound input."
Controller for controlling plurality of light sources,https://lens.org/161-366-883-083-019,2020,"A controller 102, 202 for controlling a plurality of light sources is disclosed. The controller 102, 202 comprises a receiver 106, 206 configured to receive a sound input from a plurality of microphones, the sound input being a user input from a user, a localization module 108, 208 configured to determine a user location of the user relative to the plurality of microphones based on differences between the sound input received at different microphones of the plurality of microphones, and a processor 110, 210 configured to receive location information indicative of locations of the plurality of light sources, determine which one or more light sources of the plurality of light sources are associated with the user location based on the location information, and control the one or more light sources based on the sound input."
METHOD FOR CONTROLLING SIDE MINING UNMANNED VEHICLE AND DEVICE,https://lens.org/177-872-931-872-892,2023,"A method for controlling an underground unmanned vehicle and a device are provided. The method includes measuring a traveling speed, an acceleration and a current position of the unmanned vehicle, and predicting a traveling track of the unmanned vehicle based on the traveling speed, the acceleration and the current position; detecting whether there are obstacles around the unmanned vehicle; if there is no obstacle, controlling the unmanned vehicle to travel; if there is an obstacle, determining whether the obstacle is located on the traveling track, and if the obstacle is located on the traveling track, detecting a position, a size and a speed of the obstacle, and controlling the unmanned vehicle to keep a current traveling state or decelerate to stop or determine an optimal detour route based on the position, the size and the speed of the obstacle and the traveling speed of the unmanned vehicle."
METHOD FOR CONTROLLING SIDE MINING UNMANNED VEHICLE AND DEVICE,https://lens.org/177-872-931-872-892,2023,"A method for controlling an underground unmanned vehicle and a device are provided. The method includes measuring a traveling speed, an acceleration and a current position of the unmanned vehicle, and predicting a traveling track of the unmanned vehicle based on the traveling speed, the acceleration and the current position; detecting whether there are obstacles around the unmanned vehicle; if there is no obstacle, controlling the unmanned vehicle to travel; if there is an obstacle, determining whether the obstacle is located on the traveling track, and if the obstacle is located on the traveling track, detecting a position, a size and a speed of the obstacle, and controlling the unmanned vehicle to keep a current traveling state or decelerate to stop or determine an optimal detour route based on the position, the size and the speed of the obstacle and the traveling speed of the unmanned vehicle."
"UNMANNED AERIAL VEHICLE CONTROL METHOD AND DEVICE, AND UNMANNED AERIAL VEHICLE OPERATING METHOD AND DEVICE",https://lens.org/052-537-610-371-738,2020,An unmanned aerial vehicle control method includes: reporting the flight path of an unmanned aerial vehicle to a core network by means of a base station accessed by a controller so that the base station accessed by the controller acquires from the core network a base station covered by the flight path; and sending control information to the base station accessed by the controller so that the base station accessed by the controller sends a paging signaling which carries the control information to the base station covered by the flight path.
Systems and methods for utilizing unmanned vehicles to facilitate claims processing,https://lens.org/095-233-329-447-179,2023,"This disclosure relates to utilizing unmanned vehicles for insurance claim processing. For example, a UAV may be directed to proceed to a target location, which obstructions to avoid and how to avoid them, and what data needs to be gathered about the target. Thus, one or more embodiments described herein relate to navigating to a target location based on receiving a first location of the vehicle and a second location of the target, avoiding obstructions, gathering data about a structure at the target, and initiating an insurance claim."
SYSTEM AND METHOD FOR CONFIGURING THE REMOTE CONTROL FUNCTIONALITY OF A PORTABLE DEVICE,https://lens.org/199-396-589-645-152,2016,"A system and method used to configure a smart device to command functional operations of a target appliance. The smart device retrieves from a controllable appliance, such as a settop box, data indicative of a codeset identity of the target appliance wherein the codeset identity was determined during a process used to configure a conventional universal remote control to command functional operations of the target appliance and wherein the process used to configure the conventional universal remote control is performed in cooperation with the controllable appliance. A remote control application resident on the smart device then uses the data indicative of the codeset identity retrieved from the controllable appliance to also configure the smart device to command functional operations of the target appliance."
System and method for configuring the remote control functionality of a portable device,https://lens.org/024-378-403-635-488,2016,"A system and method used to configure a smart device to command functional operations of a target appliance. The smart device retrieves from a controllable appliance, such as a settop box, data indicative of a codeset identity of the target appliance wherein the codeset identity was determined during a process used to configure a conventional universal remote control to command functional operations of the target appliance and wherein the process used to configure the conventional universal remote control is performed in cooperation with the controllable appliance. A remote control application resident on the smart device then uses the data indicative of the codeset identity retrieved from the controllable appliance to also configure the smart device to command functional operations of the target appliance."
SYSTEM AND METHOD FOR CONFIGURING THE REMOTE CONTROL FUNCTIONALITY OF A PORTABLE DEVICE,https://lens.org/160-020-360-782-617,2015,"A system and method used to configure a smart device to command functional operations of a target appliance. The smart device retrieves from a controllable appliance, such as a settop box, data indicative of a codeset identity of the target appliance wherein the codeset identity was determined during a process used to configure a conventional universal remote control to command functional operations of the target appliance and wherein the process used to configure the conventional universal remote control is performed in cooperation with the controllable appliance. A remote control application resident on the smart device then uses the data indicative of the codeset identity retrieved from the controllable appliance to also configure the smart device to command functional operations of the target appliance."
System and method for configuring the remote control functionality of a portable device,https://lens.org/183-105-973-712-109,2014,"A system and method used to configure a smart device to command functional operations of a target appliance. The smart device retrieves from a controllable appliance, such as a settop box, data indicative of a codeset identity of the target appliance wherein the codeset identity was determined during a process used to configure a conventional universal remote control to command functional operations of the target appliance and wherein the process used to configure the conventional universal remote control is performed in cooperation with the controllable appliance. A remote control application resident on the smart device then uses the data indicative of the codeset identity retrieved from the controllable appliance to also configure the smart device to command functional operations of the target appliance."
"Unmanned aerial vehicle and method for detecting flight state thereof, and wearable device",https://lens.org/001-266-529-084-609,2020,"An unmanned aerial vehicle, a method for detecting a flight state thereof, and a wearable device (500) are disclosed. The method comprises: disposing a propeller operation state collector (302) for collecting an operation state signal of a propeller (301) on at least one support arm (303) of the UAV (S101); acquiring the operation state signal of the propeller (301) collected by the propeller operation state collector (302) (S102); processing the operation state signal to obtain an operation state of the propeller (301) (S103); and determining the flight state of the UAV according to the operation state of the propeller (301) (S104). By disposing the propeller operation state collector (302) on the support arm (303) of the UAV to collect the operation state signal of the propeller (301), and then calculating the flight state of the UAV according to the operation state signal, better flight control of the UAV can be achieved by making use of the detected flight state of the UAV, and an desired flight trajectory can be obtained, thereby improving the controllability and safety during the flight of the UAV."
Receiver of camera remote control system,https://lens.org/137-598-983-002-661,1988,A camera remote control system including a transmitter arranged to transmit a control signal and a receiver arranged to receive said control signal to control an operation of the camera. The receiver of the camera remote control system is arranged to start a first stroke of operation of the camera when it has received the control signal transmitted by the transmitter and to start a second stroke of operation of the camera when a predetermined time has elapsed after starting the first stroke.
UNMANNED VEHICLE,https://lens.org/076-691-682-616-809,2017,"An unmanned vehicle is provided. The unmanned vehicle includes: a base; a driving unit including an actuator and a propeller rotating by using power of the actuator, the driving unit being provided outside the base capable of pivoting with respect to the base; and a supporter protruding from the base and supporting the base."
"METHOD, DEVICE, AND SYSTEM FOR AVALANCHE CONTROL",https://lens.org/038-719-998-555-858,2022,"A method, a device, and a system using the device, for avalanche control using an unmanned aerial vehicle to transport an explosive charge to a snow surface or snowpack. A holder of the device holds the explosive charge in a container. A receiver of the device receives a release signal. The holder releases the explosive charge in response to the release signal. A coupler couples the holder to the unmanned aerial vehicle. The explosive charge is fuzed to detonate after release from the holder to trigger an avalanche."
MANAGING NETWORK COMMUNICATION OF AN UNMANNED AUTONOMOUS VEHICLE,https://lens.org/094-443-421-856-740,2021,"Embodiments include devices and methods for managing network communication of an unmanned autonomous vehicle (UAV). A processor of the UAV may determine an altitude of the UAV. The processor may optionally also determine a speed or vector of the UAV. Based on the determined altitude and/or speed/vector of the UAV, the processor may adjust the communication parameter of the communication link between the UAV and a communication network. The processor may transmit signals based on the adjusted communication parameter, which may reduce radio frequency interference caused by the transmissions of the UAV with the communication network."
MANAGING NETWORK COMMUNICATION OF AN UNMANNED AUTONOMOUS VEHICLE,https://lens.org/096-597-335-840-202,2017,"Embodiments include devices and methods for managing network communication of an unmanned autonomous vehicle (UAV). A processor of the UAV may determine an altitude of the UAV. The processor may optionally also determine a speed or vector of the UAV. Based on the determined altitude and/or speed/vector of the UAV, the processor may adjust the communication parameter of the communication link between the UAV and a communication network. The processor may transmit signals based on the adjusted communication parameter, which may reduce radio frequency interference caused by the transmissions of the UAV with the communication network."
Managing network communication of an unmanned autonomous vehicle,https://lens.org/056-804-358-955-940,2022,"Embodiments include devices and methods for managing network communication of an unmanned autonomous vehicle (UAV). A processor of the UAV may determine an altitude of the UAV. The processor may optionally also determine a speed or vector of the UAV. Based on the determined altitude and/or speed/vector of the UAV, the processor may adjust the communication parameter of the communication link between the UAV and a communication network. The processor may transmit signals based on the adjusted communication parameter, which may reduce radio frequency interference caused by the transmissions of the UAV with the communication network."
Managing network communication of an unmanned autonomous vehicle,https://lens.org/043-907-887-143-104,2021,"Embodiments include devices and methods for managing network communication of an unmanned autonomous vehicle (UAV). A processor of the UAV may determine an altitude of the UAV. The processor may optionally also determine a speed or vector of the UAV. Based on the determined altitude and/or speed/vector of the UAV, the processor may adjust the communication parameter of the communication link between the UAV and a communication network. The processor may transmit signals based on the adjusted communication parameter, which may reduce radio frequency interference caused by the transmissions of the UAV with the communication network."
Managing network communication of an unmanned autonomous vehicle,https://lens.org/056-804-358-955-940,2022,"Embodiments include devices and methods for managing network communication of an unmanned autonomous vehicle (UAV). A processor of the UAV may determine an altitude of the UAV. The processor may optionally also determine a speed or vector of the UAV. Based on the determined altitude and/or speed/vector of the UAV, the processor may adjust the communication parameter of the communication link between the UAV and a communication network. The processor may transmit signals based on the adjusted communication parameter, which may reduce radio frequency interference caused by the transmissions of the UAV with the communication network."
Shovel and autonomous aerial vehicle flying around shovel,https://lens.org/118-734-983-904-790,2022,"A shovel includes a lower traveling body, an upper turning body mounted on the lower traveling body; and a receiver, a direction detecting device, a controller, and a display device mounted on the upper turning body, wherein the receiver is configured to receive an image captured by a camera-mounted autonomous aerial vehicle, the direction detecting device is configured to detect a direction of the shovel, the controller is configured to generate information related to a target rotation angle of the camera-mounted autonomous aerial vehicle based on the direction of the shovel, and the display device is configured to display the captured image in a same direction as a direction of an image that is captured when the camera-mounted autonomous aerial vehicle rotates by the target rotation angle."
Shovel and autonomous aerial vehicle flying around shovel,https://lens.org/143-508-558-350-572,2020,"A shovel includes a lower traveling body, an upper turning body mounted on the lower traveling body; and a receiver, a direction detecting device, a controller, and a display device mounted on the upper turning body, wherein the receiver is configured to receive an image captured by a camera-mounted autonomous aerial vehicle, the direction detecting device is configured to detect a direction of the shovel, the controller is configured to generate information related to a target rotation angle of the camera-mounted autonomous aerial vehicle based on the direction of the shovel, and the display device is configured to display the captured image in a same direction as a direction of an image that is captured when the camera-mounted autonomous aerial vehicle rotates by the target rotation angle."
SHOVEL AND AUTONOMOUS AERIAL VEHICLE FLYING AROUND SHOVEL,https://lens.org/118-906-849-946-699,2020,"A shovel includes a lower traveling body, an upper turning body mounted on the lower traveling body; and a receiver, a direction detecting device, a controller, and a display device mounted on the upper turning body, wherein the receiver is configured to receive an image captured by a camera-mounted autonomous aerial vehicle, the direction detecting device is configured to detect a direction of the shovel, the controller is configured to generate information related to a target rotation angle of the camera-mounted autonomous aerial vehicle based on the direction of the shovel, and the display device is configured to display the captured image in a same direction as a direction of an image that is captured when the camera-mounted autonomous aerial vehicle rotates by the target rotation angle."
SHOVEL AND AUTONOMOUS AERIAL VEHICLE FLYING AROUND SHOVEL,https://lens.org/194-416-588-263-527,2018,"A shovel includes a lower traveling body, an upper turning body mounted on the lower traveling body; and a receiver, a direction detecting device, a controller, and a display device mounted on the upper turning body, wherein the receiver is configured to receive an image captured by a camera-mounted autonomous aerial vehicle, the direction detecting device is configured to detect a direction of the shovel, the controller is configured to generate information related to a target rotation angle of the camera-mounted autonomous aerial vehicle based on the direction of the shovel, and the display device is configured to display the captured image in a same direction as a direction of an image that is captured when the camera-mounted autonomous aerial vehicle rotates by the target rotation angle."
Shovel and autonomous aerial vehicle flying around shovel,https://lens.org/118-734-983-904-790,2022,"A shovel includes a lower traveling body, an upper turning body mounted on the lower traveling body; and a receiver, a direction detecting device, a controller, and a display device mounted on the upper turning body, wherein the receiver is configured to receive an image captured by a camera-mounted autonomous aerial vehicle, the direction detecting device is configured to detect a direction of the shovel, the controller is configured to generate information related to a target rotation angle of the camera-mounted autonomous aerial vehicle based on the direction of the shovel, and the display device is configured to display the captured image in a same direction as a direction of an image that is captured when the camera-mounted autonomous aerial vehicle rotates by the target rotation angle."
Identifying a location of a voice-input device,https://lens.org/073-205-915-551-474,2022,"Techniques for identifying a location of a voice-controlled device within an environment. After identifying a location of the device, the device may receive a voice command from a user within the environment and may determine a response to the command based in part on the location, may determine how to output a response based in part on the location or may determine how to interact with the user based in part on the location."
Identifying a location of a voice-input device,https://lens.org/065-886-750-653-443,2020,"Techniques for identifying a location of a voice-controlled device within an environment. After identifying a location of the device, the device may receive a voice command from a user within the environment and may determine a response to the command based in part on the location, may determine how to output a response based in part on the location or may determine how to interact with the user based in part on the location."
Identifying a location of a voice-input device,https://lens.org/175-389-493-494-904,2018,"Techniques for identifying a location of a voice-controlled device within an environment. After identifying a location of the device, the device may receive a voice command from a user within the environment and may determine a response to the command based in part on the location, may determine how to output a response based in part on the location or may determine how to interact with the user based in part on the location."
Identifying a location of a voice-input device,https://lens.org/065-886-750-653-443,2020,"Techniques for identifying a location of a voice-controlled device within an environment. After identifying a location of the device, the device may receive a voice command from a user within the environment and may determine a response to the command based in part on the location, may determine how to output a response based in part on the location or may determine how to interact with the user based in part on the location."
Identifying a location of a voice-input device,https://lens.org/073-205-915-551-474,2022,"Techniques for identifying a location of a voice-controlled device within an environment. After identifying a location of the device, the device may receive a voice command from a user within the environment and may determine a response to the command based in part on the location, may determine how to output a response based in part on the location or may determine how to interact with the user based in part on the location."
Autonomous vehicle arrangement and method for controlling an autonomous vehicle,https://lens.org/058-671-917-635-027,2000,"An autonomous vehicle and method for controlling it includes an input unit to receive one or more travel orders, a route planning unit containing at least one position finding device and digital street map, a vehicle path generating a unit, an array of sensors including at least one range sensor for detecting objects and at least one range sensor for detecting the condition features of the route, a collision avoidance unit, a vehicle condition data recognition unit, a vehicle control unit and a unit for controlling the vehicle actuator system based on the signals generated by the vehicle control unit, wherein the array of sensors includes at least two essentially horizontally directed range sensors at the front of the vehicle, at least one range sensor at the rear area of the vehicle, at least one trackable range sensor on the roof of the vehicle and directed at the roadway, ultrasonic sensors and/or microwave radar sensors arranged on each side of the vehicle, and at least one camera located in each of the front and rear areas of the vehicle."
VEHICLE VISION SYSTEM USING AERIAL CAMERA,https://lens.org/193-402-386-808-644,2021,"A vehicular vision system includes a forward viewing camera disposed behind a windshield of a vehicle and viewing forward of the vehicle through the windshield. A control is disposed at the vehicle and includes an image processor operable to process image data captured by the forward viewing camera. A drone includes a drone camera that captures image data. The drone is detachably disposed at the vehicle and is detachable from the vehicle and operable to fly above the vehicle. The drone camera captures image data representative of an area viewed by the drone camera with the drone flying above the vehicle. With the drone detached from the vehicle and flying above the vehicle, the drone communicates a signal to the control. Responsive to receiving the signal communicated by the drone, the control determines a traffic condition ahead of the equipped vehicle."
High-Rise Building Escape Drone,https://lens.org/116-995-918-661-764,2021,A high rise building escape drone is shown and described. The high rise building escape drone includes of a frame. The frame has a spine secured to an upper housing. The upper housing secures a motor and a CPU operably connected to the motor. The motor is rotatably coupled to at least one propeller. A seat is secured to the spine below the upper housing. A control panel is secured to the seat. The control panel is operably coupled to the CPU and is capable to control the drone. A plurality of feet are secured to a bottom of the spine such that the feet support the drone.
BIRD SCARING DEVICE AND SYSTEM FOR USING,https://lens.org/188-789-593-214-644,2015,A device for scaring birds comprising a remote controlled aerial device having lights and sound system. Also described is a system for using the aerial device to scare birds.
REMOTE CONTROL METHOD AND SYSTEM FOR ROBOT,https://lens.org/090-795-089-095-583,2022,"A robot remote control method and system capable of remotely controlling navigation of a robot. The robot remote control method includes outputting both a map image and an ambient image to a display, the map image including location information corresponding to the ambient image, the ambient image being of surroundings of a robot, and the ambient image being received from a camera at the robot, generating a control command for controlling the robot in response to an input to the display during the outputting, and causing the robot to drive according to the control command by transmitting the control command to the robot."
UNMANNED AIR VEHICLE SYSTEM,https://lens.org/097-094-169-638-114,2007,"An unmanned air vehicle (UAV) system (10), is provided including a ground station (70), a platform (20) configured for carrying a payload (40) and having a propulsion system (30) for enabling the platform at least to selectively sustain a predetermined altitude above the ground station when in flight mode, and also including a tether (50) operatively coupling the ground station with the platform, the tether providing electrical communication between the platform and the ground station."
Unmanned aircraft with failsafe system,https://lens.org/029-981-092-549-547,2015,"An unmanned aircraft configured to fall or crash in a controlled and safe manner. The unmanned aircraft includes a drive system to thrust the unmanned aircraft during a flight, and a reverse thrust system to reverse thrust the unmanned aircraft during a landing. The unmanned aircraft further includes a controller operationally coupled to the reverse thrust system, and a detector to detect and notify to the controller that the unmanned aircraft is in an uncontrolled situation during the flight. The controller is adapted to activate the reverse thrust system in order to reverse thrust the unmanned aircraft in-flight upon notification from the detector that the unmanned aircraft is in an uncontrolled situation."
Delivery of packages by unmanned aerial vehicles,https://lens.org/014-824-643-546-876,2019,"A package delivery apparatus uses an unmanned aerial vehicle (UAV) to deliver a package containing a product to a delivery destination area. The UAV uses GPS signals to guide it to the delivery destination area and an altimeter to determine its height above the delivery destination area. The UAV then adjusts its height to a preferred drop or release height for that package and product and releases the package. An optional camera allows a human operator to view the delivery destination area. An expandable foam package surrounds the product to protect the product from impact and moisture. The package may be streamlined to reduce air resistance and increase the range of the UAV. The package characteristics, such as its thickness, are determined based one or more of the weight and fragile nature of the product, and the drop height."
Delivery of packages by unmanned aerial vehicles,https://lens.org/173-743-962-770-198,2021,"A package delivery apparatus uses an unmanned aerial vehicle (UAV) to deliver a package containing a product to a delivery destination area. The UAV uses GPS signals to guide it to the delivery destination area and an altimeter to determine its height above the delivery destination area. The UAV then adjusts its height to a preferred drop or release height for that package and product and releases the package. An optional camera allows a human operator to view the delivery destination area. An expandable foam package surrounds the product to protect the product from impact and moisture. The package may be streamlined to reduce air resistance and increase the range of the UAV. The package characteristics, such as its thickness, are determined based one or more of the weight and fragile nature of the product, and the drop height."
Delivery of packages by unmanned aerial vehicles,https://lens.org/020-937-953-296-479,2017,"A package delivery apparatus uses an unmanned aerial vehicle (UAV) to deliver a package containing a product to a delivery destination area. The UAV uses GPS signals to guide it to the delivery destination area and an altimeter to determine its height above the delivery destination area. The UAV then adjusts its height to a preferred drop or release height for that package and product and releases the package. An optional camera allows a human operator to view the delivery destination area. An expandable foam package surrounds the product to protect the product from impact and moisture. The package may be streamlined to reduce air resistance and increase the range of the UAV. The package characteristics, such as its thickness, are determined based one or more of the weight and fragile nature of the product, and the drop height."
Systems and methods for security data analysis and display,https://lens.org/182-664-953-844-379,2017,"Systems and methods are provided for improved security services. In one aspect, a method is provided for controlling an autonomous data machine situated near a monitored environment. The method comprises: obtaining security data from a plurality of data sources; analyzing the security data to generate an analysis result; determining, based on the analysis result, an action to be performed by the autonomous data machine; and transmitting a command to the autonomous data machine causing it to perform the action."
Systems and methods for security data analysis and display,https://lens.org/191-047-342-975-022,2023,"Systems and methods are provided for improved security services. In one aspect, a method is provided for controlling an autonomous data machine situated near a monitored environment. The method comprises: obtaining security data from a plurality of data sources; analyzing the security data to generate an analysis result; determining, based on the analysis result, an action to be performed by the autonomous data machine; and transmitting a command to the autonomous data machine causing it to perform the action."
Systems and methods for security data analysis and display,https://lens.org/035-494-403-341-313,2019,"Systems and methods are provided for improved security services. In one aspect, a method is provided for controlling an autonomous data machine situated near a monitored environment. The method comprises: obtaining security data from a plurality of data sources; analyzing the security data to generate an analysis result; determining, based on the analysis result, an action to be performed by the autonomous data machine; and transmitting a command to the autonomous data machine causing it to perform the action."
Systems and methods for security data analysis and display,https://lens.org/191-047-342-975-022,2023,"Systems and methods are provided for improved security services. In one aspect, a method is provided for controlling an autonomous data machine situated near a monitored environment. The method comprises: obtaining security data from a plurality of data sources; analyzing the security data to generate an analysis result; determining, based on the analysis result, an action to be performed by the autonomous data machine; and transmitting a command to the autonomous data machine causing it to perform the action."
METHOD AND APPARATUS FOR SETTING CONTROLLED EVENTS FOR NETWORK DEVICES,https://lens.org/122-653-590-837-638,2014,"A method for controlling a device during content playback commences by receiving at the device at least one user-entered command to instruct the device to take at least one action upon the occurrence of an event during content playback. The device will execute the command to take the at least one action upon occurrence of the event during content playback. The action can include providing a notification to another device, such as in the form of a URL."
Method and apparatus for setting controlled events for network devices,https://lens.org/178-263-344-485-911,2016,"A method for controlling a device during content playback commences by receiving at the device at least one user-entered command to instruct the device to take at least one action upon the occurrence of an event during content playback. The device will execute the command to take the at least one action upon occurrence of the event during content playback. The action can include providing a notification to another device, such as in the form of a URL."
Control apparatus for movable robot,https://lens.org/056-116-126-961-795,2006,"The control apparatus for a movable robot comprises: environment information acquisition means (such as video camera 3 and microphone 4 ); a current position detecting means ( 15 ); a map storage ( 7 ); a control parameter storage ( 9 ) for storing control parameters adjusted to different environments; and control means ( 11, 12 ) for determining a current position of the robot on the map data based on a signal from the current position detecting means, retrieving control parameters suitable for the current position from the parameter storage, and controlling the environment information acquisition means or actuators for moving the robot by using the retrieved control parameters."
DISPLAY DEVICE AND ROUTE DISPLAY PROGRAM,https://lens.org/197-184-112-653-078,2022,"A display device includes a display unit, and a control unit that displays a flight route of a flying object flying while photographing surroundings of a crane on the display unit. The control unit is configured to display the crane and the flight route on the display unit, and to display the flight route in a display mode viewed from at least two different directions."
DISPLAY DEVICE AND ROUTE DISPLAY PROGRAM,https://lens.org/197-184-112-653-078,2022,"A display device includes a display unit, and a control unit that displays a flight route of a flying object flying while photographing surroundings of a crane on the display unit. The control unit is configured to display the crane and the flight route on the display unit, and to display the flight route in a display mode viewed from at least two different directions."
AN UNMANNED AUTONOMOUS VEHICLE FOR INSPECTION OF FLUID TRANSPORTATION MEANS,https://lens.org/184-337-644-423-495,2014,"An unmanned autonomous vehicle, UAV, for inspection of fluid transportation means (FTM), said unmanned autonomous vehicle (1) comprising a navigation system (2) adapted to localize automatically said fluid transportation means (FTM) and to navigate said unmanned autonomous vehicle (l) along said fluid transportation means (FTM) for its inspection."
System and method for image projection mapping,https://lens.org/188-820-906-256-662,2022,"A system including a drone having a projector to project an image from a projection origin. The drone also has a navigation unit to determine location information for the drone. A processor coupled to the drone includes a memory. Execution of programming by the processor configures the system to obtain a projection surface architecture for a projection surface. The projection surface architecture includes reference points that correspond to physical locations on the projection surface. Each reference point is associated with relationship data with respect to an architecture origin. The system also receives location information for the drone, adapts the relationship data responsive to change in the location information, adjusts the image using the adapted relationship data, and projects the adjusted image onto the projection surface."
SYSTEM AND METHOD FOR IMAGE PROJECTION MAPPING,https://lens.org/104-113-097-857-790,2022,"A system including a drone having a projector to project an image from a projection origin. The drone also has a navigation unit to determine location information for the drone. A processor coupled to the drone includes a memory. Execution of programming by the processor configures the system to obtain a projection surface architecture for a projection surface. The projection surface architecture includes reference points that correspond to physical locations on the projection surface. Each reference point is associated with relationship data with respect to an architecture origin. The system also receives location information for the drone, adapts the relationship data responsive to change in the location information, adjusts the image using the adapted relationship data, and projects the adjusted image onto the projection surface."
System and method for image projection mapping,https://lens.org/188-820-906-256-662,2022,"A system including a drone having a projector to project an image from a projection origin. The drone also has a navigation unit to determine location information for the drone. A processor coupled to the drone includes a memory. Execution of programming by the processor configures the system to obtain a projection surface architecture for a projection surface. The projection surface architecture includes reference points that correspond to physical locations on the projection surface. Each reference point is associated with relationship data with respect to an architecture origin. The system also receives location information for the drone, adapts the relationship data responsive to change in the location information, adjusts the image using the adapted relationship data, and projects the adjusted image onto the projection surface."
SYSTEM AND METHOD FOR IMAGE PROJECTION MAPPING,https://lens.org/104-113-097-857-790,2022,"A system including a drone having a projector to project an image from a projection origin. The drone also has a navigation unit to determine location information for the drone. A processor coupled to the drone includes a memory. Execution of programming by the processor configures the system to obtain a projection surface architecture for a projection surface. The projection surface architecture includes reference points that correspond to physical locations on the projection surface. Each reference point is associated with relationship data with respect to an architecture origin. The system also receives location information for the drone, adapts the relationship data responsive to change in the location information, adjusts the image using the adapted relationship data, and projects the adjusted image onto the projection surface."
Systems and methods for UAV docking,https://lens.org/083-645-570-213-040,2016,Systems and methods are provided for docking an unmanned aerial vehicle (UAV) with a vehicle. The UAV may be able to distinguish a companion vehicle from other vehicles in the area and vice versa. The UAV may take off and/or land on the vehicle. The UAV may be used to capture images and stream the images live to a display within the vehicle. The vehicle may control the UAV. The UAV may be in communication with the companion vehicle while in flight.
SYSTEMS AND METHODS FOR UAV DOCKING,https://lens.org/056-349-093-572-300,2015,Systems and methods are provided for docking an unmanned aerial vehicle (UAV) with a vehicle. The UAV may be able to distinguish a companion vehicle from other vehicles in the area and vice versa. The UAV may take off and/or land on the vehicle. The UAV may be used to capture images and stream the images live to a display within the vehicle. The vehicle may control the UAV. The UAV may be in communication with the companion vehicle while in flight.
SYSTEMS AND METHODS FOR UAV DOCKING,https://lens.org/032-957-874-048-673,2021,Systems and methods are provided for docking an unmanned aerial vehicle (UAV) with a vehicle. The UAV may be able to distinguish a companion vehicle from other vehicles in the area and vice versa. The UAV may take off and/or land on the vehicle. The UAV may be used to capture images and stream the images live to a display within the vehicle. The vehicle may control the UAV. The UAV may be in communication with the companion vehicle while in flight.
Systems and methods for UAV docking,https://lens.org/145-060-428-626-411,2018,Systems and methods are provided for docking an unmanned aerial vehicle (UAV) with a vehicle. The UAV may be able to distinguish a companion vehicle from other vehicles in the area and vice versa. The UAV may take off and/or land on the vehicle. The UAV may be used to capture images and stream the images live to a display within the vehicle. The vehicle may control the UAV. The UAV may be in communication with the companion vehicle while in flight.
Systems and methods for UAV docking,https://lens.org/063-744-693-236-873,2015,Systems and methods are provided for docking an unmanned aerial vehicle (UAV) with a vehicle. The UAV may be able to distinguish a companion vehicle from other vehicles in the area and vice versa. The UAV may take off and/or land on the vehicle. The UAV may be used to capture images and stream the images live to a display within the vehicle. The vehicle may control the UAV. The UAV may be in communication with the companion vehicle while in flight.
SYSTEMS AND METHODS FOR UAV DOCKING,https://lens.org/073-107-766-527-550,2015,Systems and methods are provided for docking an unmanned aerial vehicle (UAV) with a vehicle. The UAV may be able to distinguish a companion vehicle from other vehicles in the area and vice versa. The UAV may take off and/or land on the vehicle. The UAV may be used to capture images and stream the images live to a display within the vehicle. The vehicle may control the UAV. The UAV may be in communication with the companion vehicle while in flight.
SYSTEMS AND METHODS FOR UAV DOCKING,https://lens.org/118-664-536-642-02X,2016,Systems and methods are provided for docking an unmanned aerial vehicle (UAV) with a vehicle. The UAV may be able to distinguish a companion vehicle from other vehicles in the area and vice versa. The UAV may take off and/or land on the vehicle. The UAV may be used to capture images and stream the images live to a display within the vehicle. The vehicle may control the UAV. The UAV may be in communication with the companion vehicle while in flight.
SYSTEMS AND METHODS FOR UAV DOCKING,https://lens.org/193-699-194-223-991,2016,Systems and methods are provided for docking an unmanned aerial vehicle (UAV) with a vehicle. The UAV may be able to distinguish a companion vehicle from other vehicles in the area and vice versa. The UAV may take off and/or land on the vehicle. The UAV may be used to capture images and stream the images live to a display within the vehicle. The vehicle may control the UAV. The UAV may be in communication with the companion vehicle while in flight.
Systems and methods for UAV docking,https://lens.org/150-225-350-602-148,2016,Systems and methods are provided for docking an unmanned aerial vehicle (UAV) with a vehicle. The UAV may be able to distinguish a companion vehicle from other vehicles in the area and vice versa. The UAV may take off and/or land on the vehicle. The UAV may be used to capture images and stream the images live to a display within the vehicle. The vehicle may control the UAV. The UAV may be in communication with the companion vehicle while in flight.
GROUND-AWARE UAV FLIGHT PLANNING AND OPERATION SYSTEM,https://lens.org/036-033-208-975-833,2020,"A ground-aware drone flight planning and operation system is provided. The system may comprise a semantic map, a localization system, and a perception system. The semantic map may comprise information about ground events in a geographic area where an unmanned aerial vehicle (UAV) may operate. The localization system may localize the UAV and assist in determining nearby ground events using the semantic map. The perception system may determine real-time ground events in the vicinity of the UAV. A computerized flight planner may generate a flight path based on the localization and perception data."
"REMOTE CONTROL FOR IMPLEMENTING IMAGE PROCESSING, UNMANNED AIRCRAFT SYSTEM AND IMAGE PROCESSING METHOD FOR UNMANNED AERIAL VEHICLE",https://lens.org/017-418-012-575-342,2018,"The present application discloses a remote control for implementing image processing, including a remote control controller, an image transmission unit and a data transmission unit, and further including: a system processor, connected to the remote control controller and the image transmission unit to process an image transmitted by the image transmission unit; and a display unit, connected to the system processor to display or edit the image processed by the system processor, where the remote control controller exchanges system data with the system processor, to implement function operations of the remote control, and the image transmission unit sends image data obtained from an unmanned aerial vehicle to the system processor, to display or edit the image data on the display unit connected to the system processor. The remote control completes real-time display or editing of aerial videos while operating an aerial vehicle, thereby greatly improving user's operation experience and convenience."
"System, method, and computer program for initiating actions automatically on smart devices that are in a home",https://lens.org/043-689-827-863-035,2019,"A system, method, and computer program product are provided for initiating actions automatically on smart devices that are in a home. In use, one or more smart devices connected to a common network are identified. Additionally, an alert trigger signal is sent to put the one or more smart devices on alert to be ready to perform one or more specific actions in response to an action trigger signal. Further, an event defined as an event for initiating the one or more smart devices to perform the one or more specific actions is detected. In addition, an action trigger signal is sent to the one or more smart devices to initiate the one or more specific actions associated with the one or more smart devices, the one or more specific actions including at least one of video recording or a transmission of measurements. Data resulting from the one or more specific actions is stored automatically on one or more cloud-based servers. Furthermore, a time of the detected event is logged."
Unmanned aerial vehicle (UAV) intelligent emergency voice report system and method,https://lens.org/040-274-734-030-348,2020,"An unmanned aerial vehicle intelligent emergency voice report system and method includes monitoring operational parameters of the UAV, monitoring environmental parameters within and external to the UAV, and processing the operational parameters and the environmental parameters, in a controller, to determine when the UAV is in an emergency condition. When the controller determines the UAV is in an emergency condition, the controller is used to: process the operational parameters to determine how the UAV will respond the emergency condition; automatically determine a communication transmission frequency; tune an onboard communication device to the communication transmission frequency; generate analog voice waveforms that provide information regarding the emergency condition; supply the analog voice waveforms to the onboard communication device; and command the onboard communication device to transmit the analog voice waveforms on the communication transmission frequency."
UNMANNED AERIAL VEHICLE (UAV) INTELLIGENT EMERGENCY VOICE REPORT SYSTEM AND METHOD,https://lens.org/120-207-664-955-272,2020,"An unmanned aerial vehicle intelligent emergency voice report system and method includes monitoring operational parameters of the UAV, monitoring environmental parameters within and external to the UAV, and processing the operational parameters and the environmental parameters, in a controller, to determine when the UAV is in an emergency condition. When the controller determines the UAV is in an emergency condition, the controller is used to: process the operational parameters to determine how the UAV will respond the emergency condition; automatically determine a communication transmission frequency; tune an onboard communication device to the communication transmission frequency; generate analog voice waveforms that provide information regarding the emergency condition; supply the analog voice waveforms to the onboard communication device; and command the onboard communication device to transmit the analog voice waveforms on the communication transmission frequency."
REMOTE CONTROL WITH ALERT FUNCTION,https://lens.org/154-918-722-220-886,2005,"The application provides a remote control (100) for alerting and/or reminding a user of a predefined event. The remote control is adapted for bi-directional wireless signal transmission to a base station (112) and for generating a perceptible alert in response to receiving an alert signal from a base station. The remote control is ideally suitable for applications within a telehealth system for alerting or reminding a patient of an event of a medical action plan. The remote control combines alert functionality as well as wireless entry of control commands into the base station. Moreover, the remote control can be personalized to a specific user allowing a plurality of users to share a base station of a telehealth system."
Remote control device for camera,https://lens.org/119-216-603-195-133,1981,"There is described a device for remotely controlling the shutter of a camera. The device includes a housing which incorporates a microphone for receiving an acoustic wave having a relatively high frequency in an audio frequency range, which is generated by a tone generating source, an amplifier circuit for amplifying the output of the microphone, an actuator which is caused to make one reciprocation by the output of the amplifier circuit, and an electric source for energizing the amplifier circuit and the acturator. The device further includes mounting device for fixedly securing the housing to the camera, and a release device for operating the shutter of the camera with the aid of one reciprocation of the actuator."
CONTROL METHOD AND APPARATUS FOR SMART HOME,https://lens.org/160-185-039-881-673,2019,"Provided are a control method and apparatus for a smart home. The control method includes: acquiring the weather information of a region where a terminal is located, and acquiring state information of a target smart home from a smart home application, the smart home application being installed on the terminal; synchronously displaying the state information of the target smart home and the weather information on a screen of the terminal; receiving a trigger signal generated on the basis of the state information and the weather information; and generating a control signal on the basis of the trigger signal, the control signal to control an operation state of the target smart home by means of the smart home application."
IOT DEVICES,https://lens.org/078-367-340-623-134,2021,"A method of operating an Internet of Things (loT) device, the loT device capable of communicating with a third-party system in order to perform an autonomous task subject to authorisation by an loT authorisation device, the method comprising: sending operating parameters relating to the autonomous task to a user for approval; receiving user-approved operating parameters for the autonomous task; configuring the loT device to perform the autonomous task within the user approved operating parameters; registering the user approved operating parameters with the loT device management server to enable the loT authorisation device to check that the loT device is operating within the user-approved operating parameters when it performs an autonomous task with the third-party system."
TAKE OFF AND LANDING SYSTEM FOR DRONE FOR USE WITH AN AUTONOMOUS VEHICLE,https://lens.org/062-018-533-468-146,2020,"An autonomous vehicle includes a retractable harness mounted within the vehicle and extendible through an opening in the vehicle body, such as a sun roof. The harness may include a retainer, such as an electromagnet, for engaging a docking structure on an aerial drone. On take-off, the vehicle may reach a desirable take-off speed of the aerial drone, activate the aerial drone, and release the retainer. On landing, the aerial drone and vehicle may synchronize their speeds and locations. The retractable harness may extend and align itself with the aerial drone, which descends and docks with the retractable harness."
DRONE-BASED RADIO-OVER-FIBER SYSTEM,https://lens.org/103-542-340-405-524,2019,"The drone-based radio-over-fiber system provides an unmanned aerial vehicle (AV), preferably a multi-rotor drone, connected to a base station by a tether including an optical fiber. A radio frequency-over-fiber system is used for bidirectional data communications between at least one radio frequency (RF) transmitter at the base station and at least one antenna mounted on the drone through the optical fiber in the tether. The system includes wave division multiplexers/demultiplexers that permit ultrahigh bandwidth communication over the tether. An embodiment of the system for 2x2 multiple-input, multiple-output (MIMO) signals in the 700 MHz LTE band is described."
LOCATION FOR UNMANNED AERIAL VEHICLE LANDING AND TAKING OFF,https://lens.org/174-366-275-019-509,2018,"An unmanned aerial vehicle (UAV) system, location and method, for operation with a flight management system, has a controlled access UAV zone for at least one of: UAV landing, UAV loading, and UAV take-off. A sensor can be in communication with a control panel and/or a lock to govern access to the UAV zone. The zone can have a barrier with closure secured by the lock, and controlled by a flight management system. Separate access codes can be provided for departure and destination locations, to enable personnel associated with a delivery request to access those locations, to effect delivery of an article. The codes can be generated and supplied when the flight management system receives a valid delivery request."
Location for unmanned aerial vehicle landing and taking off,https://lens.org/114-090-805-953-366,2021,"An unmanned aerial vehicle (UAV) system, location and method, for operation with a flight management system, has a controlled access UAV zone for at least one of: UAV landing, UAV loading, and UAV take-off. A sensor can be in communication with a control panel and/or a lock to govern access to the UAV zone. The zone can have a barrier with closure secured by the lock, and controlled by a flight management system. Separate access codes can be provided for departure and destination locations, to enable personnel associated with a delivery request to access those locations, to effect delivery of an article. The codes can be generated and supplied when the flight management system receives a valid delivery request."
LOCATION FOR UNMANNED AERIAL VEHICLE LANDING AND TAKING OFF,https://lens.org/002-432-074-080-886,2019,"An unmanned aerial vehicle (UAV) system, location and method, for operation with a flight management system, has a controlled access UAV zone for at least one of: UAV landing, UAV loading, and UAV take-off. A sensor can be in communication with a control panel and/or a lock to govern access to the UAV zone. The zone can have a barrier with closure secured by the lock, and controlled by a flight management system. Separate access codes can be provided for departure and destination locations, to enable personnel associated with a delivery request to access those locations, to effect delivery of an article. The codes can be generated and supplied when the flight management system receives a valid delivery request."
Location for unmanned aerial vehicle landing and taking off,https://lens.org/104-029-173-269-121,2020,"An unmanned aerial vehicle (UAV) system, location and method, for operation with a flight management system, has a controlled access UAV zone for at least one of: UAV landing, UAV loading, and UAV take-off. A sensor can be in communication with a control panel and/or a lock to govern access to the UAV zone. The zone can have a barrier with closure secured by the lock, and controlled by a flight management system. Separate access codes can be provided for departure and destination locations, to enable personnel associated with a delivery request to access those locations, to effect delivery of an article. The codes can be generated and supplied when the flight management system receives a valid delivery request."
LOCATION FOR UNMANNED AERIAL VEHICLE LANDING AND TAKING OFF,https://lens.org/184-356-226-947-089,2017,"An unmanned aerial vehicle (UAV) system, location and method, for operation with a flight management system, has a controlled access UAV zone for at least one of: UAV landing, UAV loading, and UAV take-off. A sensor can be in communication with a control panel and/or a lock to govern access to the UAV zone. The zone can have a barrier with closure secured by the lock, and controlled by a flight management system. Separate access codes can be provided for departure and destination locations, to enable personnel associated with a delivery request to access those locations, to effect delivery of an article. The codes can be generated and supplied when the flight management system receives a valid delivery request."
System and method for retrieving information while commanding operation of an appliance,https://lens.org/043-493-185-585-007,2019,"When a command key of a controlling platform is activated, the platform performs an operation to initiate a playing of media content and also initiates the retrieval of information from an information source."
SYSTEM AND METHOD FOR RETRIEVING INFORMATION WHILE COMMANDING OPERATION OF AN APPLIANCE,https://lens.org/067-427-005-985-886,2013,"When a command key of a controlling platform is activated, the platform performs an operation to initiate a playing of media content and also initiates the retrieval of information from an information source."
SYSTEM AND METHOD FOR RETRIEVING INFORMATION WHILE COMMANDING OPERATION OF AN APPLIANCE,https://lens.org/126-438-402-441-382,2014,"When a command key of a controlling platform is activated, the platform performs an operation to initiate a playing of media content and also initiates the retrieval of information from an information source."
Drone-Based Active Protection System,https://lens.org/158-176-043-125-356,2022,"A system for facilitating active protection of a target from a threat is provided. The system comprises one or more platforms configured for directing operation of the system, and one or more unmanned aerial vehicles (UAVs) configured to operate in the vicinity of the target, and to facilitate detection and/or neutralizing of the threat. The platform is configured for autonomously detecting and providing instructions for neutralizing the threat, and each of the unmanned aerial vehicles is configured for communicating with the platform."
Drone-Based Active Protection System,https://lens.org/051-654-109-292-952,2018,"A system for facilitating active protection of a target from a threat is provided. The system comprises one or more platforms configured for directing operation of the system, and one or more unmanned aerial vehicles (UAVs) configured to operate in the vicinity of the target, and to facilitate detection and/or neutralizing of the threat. The platform is configured for autonomously detecting and providing instructions for neutralizing the threat, and each of the unmanned aerial vehicles is configured for communicating with the platform."
Method and system to dynamically identify and control a UAV with emitting instruments,https://lens.org/073-811-185-934-499,2018,"A system and methodology to dynamically identify and control a UAV with a beam instrument is provided. Specifically, each UAV is provided with a telecommunication module. User equipment is provided with a beam device capable of measuring the distance, speed and location of a UAV. The user equipment is coupled to a command and control center through a command and control center network that can access a data store storing information about UAVs. Identification of the UAV is obtained through a telecommunication network that communicates with the telecommunication module to obtain location information and identity information for each telecommunication module associated with a UAV. The command and control center acquires the identity information and correlates the identity information with FAA register information from an FAA network. Identification of the target UAV is then communicated to the user equipment."
Method and System to Dynamically Identify and Control a UAV With Emitting Instruments,https://lens.org/117-950-182-958-801,2018,"A system and methodology to dynamically identify and control a UAV with a beam instrument is provided. Specifically, each UAV is provided with a telecommunication module. User equipment is provided with a beam device capable of measuring the distance, speed and location of a UAV. The user equipment is coupled to a command and control center through a command and control center network that can access a data store storing information about UAVs. Identification of the UAV is obtained through a telecommunication network that communicates with the telecommunication module to obtain location information and identity information for each telecommunication module associated with a UAV. The command and control center acquires the identity information and correlates the identity information with FAA register information from an FAA network. Identification of the target UAV is then communicated to the user equipment."
METHOD AND SYSTEM TO DYNAMICALLY IDENTIFY AND CONTROL A UAV WITH EMITTING INSTRUMENTS,https://lens.org/065-841-977-876-810,2018,"A system and methodology to dynamically identify and control a UAV with a beam instrument is provided. Specifically, each UAV is provided with a telecommunication module. User equipment is provided with a beam device capable of measuring the distance, speed and location of a UAV. The user equipment is coupled to a command and control center through a command and control center network that can access a data store storing information about UAVs. Identification of the UAV is obtained through a telecommunication network that communicates with the telecommunication module to obtain location information and identity information for each telecommunication module associated with a UAV. The command and control center acquires the identity information and correlates the identity information with FAA register information from an FAA network. Identification of the target UAV is then communicated to the user equipment."
Method and system to dynamically identify and control a UAV with emitting instruments,https://lens.org/105-403-300-247-747,2019,"A system and methodology to dynamically identify and control a UAV with a beam instrument is provided. Specifically, each UAV is provided with a telecommunication module. User equipment is provided with a beam device capable of measuring the distance, speed and location of a UAV. The user equipment is coupled to a command and control center through a command and control center network that can access a data store storing information about UAVs. Identification of the UAV is obtained through a telecommunication network that communicates with the telecommunication module to obtain location information and identity information for each telecommunication module associated with a UAV. The command and control center acquires the identity information and correlates the identity information with FAA register information from an FAA network. Identification of the target UAV is then communicated to the user equipment."
OBSTACLE CLIMBING SURVEILLANCE ROBOT AND ENERGY-ABSORBING FRAME THEREFOR,https://lens.org/155-403-530-867-005,2021,"A surveillance system includes a robot and an operator control unit (OCU) for controlling the robot. The robot includes GO a light-weight frame housing, wheels, motor compartments positioned within the light-weight frame housing, wheel motors positioned within the motor compartments and attached to the wheels, a camera for capturing surveillance images and an electronic controller that is electrically or wirelessly connected to the wheel motors and the camera and that is wirelessly connected to the OCU. The light-weight frame is made of light-weight foam that substantially surrounds, structurally supports and protects the robot wheel motors, camera and electronic controller from mechanical shock during intended use."
Device and method for detecting objects,https://lens.org/072-178-687-006-265,2022,"In order to detect flying objects, a camera configuration is used for video monitoring of a monitoring space, and a control unit is used for controlling the camera configuration and evaluating the video frames recorded by the camera configuration. The camera configuration has an infrared illuminator for the monitoring space and at least one camera with an infrared image sensor. The infrared illuminator is preferably operated in a pulsed fashion synchronously with a measurement cycle of the camera."
DEVICE AND METHOD FOR DETECTING OBJECTS,https://lens.org/139-389-295-979-403,2020,"In order to detect flying objects, a camera configuration is used for video monitoring of a monitoring space, and a control unit is used for controlling the camera configuration and evaluating the video frames recorded by the camera configuration. The camera configuration has an infrared illuminator for the monitoring space and at least one camera with an infrared image sensor. The infrared illuminator is preferably operated in a pulsed fashion synchronously with a measurement cycle of the camera."
Device and method for detecting objects,https://lens.org/072-178-687-006-265,2022,"In order to detect flying objects, a camera configuration is used for video monitoring of a monitoring space, and a control unit is used for controlling the camera configuration and evaluating the video frames recorded by the camera configuration. The camera configuration has an infrared illuminator for the monitoring space and at least one camera with an infrared image sensor. The infrared illuminator is preferably operated in a pulsed fashion synchronously with a measurement cycle of the camera."
"UAV, method and system for cleaning a wall body",https://lens.org/026-734-047-360-692,2021,"A cleaning method includes controlling an unmanned aerial vehicle (UAV) to fly to a region of a wall body according to a path to be cleaned, and, in response to detecting a cleaning prohibition identifier associated with the region, recognizing the region as a cleaning prohibition region and controlling the UAV to fly over the cleaning prohibition region without cleaning the cleaning prohibition region."
"SYSTEMS, METHODS, AND DEVICES IMPROVING SAFETY AND FUNCTIONALITY OF CRAFT HAVING ONE OR MORE ROTORS",https://lens.org/104-168-235-494-317,2018,"This application describes systems, methods, and devices to enhance the safety and functionality of unmanned rotorcraft by improving reliability, transparency, operational capabilities, and effectiveness. Embodiments include integration of rotorcraft with objects attached to the ground (including kites, balloons, or elevated structures) in order to create safe and visible sky moorings from which devices such as cameras on the craft can operate for extended periods of time while remote control can be used to move and stabilize the camera and/or the kite or balloon to which it is attached. In addition, the rotorcraft in such sky moorings can be enclosed for protection, can employ connections for systems maintenance, and can utilize changeable payload modules having supplies that the rotorcraft can dispatch or use in various contexts such as emergency situations or to provide security at venues with large gatherings of people, such as concerts."
AERIAL VEHICLE SYSTEMS AND METHODS,https://lens.org/109-393-364-939-24X,2018,"A system includes a first aerial vehicle comprising one or more sensors configured to obtain an image of a worksite. The system also includes a controller configured to receive the image of the worksite, to generate a map of the worksite by overlaying information related to the worksite on the image, and to display the map via a display."
Aerial vehicle systems and methods,https://lens.org/142-044-612-072-528,2020,"A system includes a first aerial vehicle comprising one or more sensors configured to obtain an image of a worksite. The system also includes a controller configured to receive the image of the worksite, to generate a map of the worksite by overlaying information related to the worksite on the image, and to display the map via a display."
REMOTE SYSTEM FOR AN AUTONOMOUS VEHICLE,https://lens.org/158-535-156-073-777,2020,"A remote system for an autonomous vehicle, includes a receiver, a controller, and a display device. The receiver is configured to receive road information. The controller is programmed to receive input related to the road information and create a supervision zone when the road information impacts road drivability. The display device is disposed at a control center area and configured to display a visual indication on a map of the supervision zone."
Remote system for an autonomous vehicle,https://lens.org/112-401-086-776-545,2022,"A remote system for an autonomous vehicle, includes a receiver, a controller, and a display device. The receiver is configured to receive road information. The controller is programmed to receive input related to the road information and create a supervision zone when the road information impacts road drivability. The display device is disposed at a control center area and configured to display a visual indication on a map of the supervision zone."
Remote system for an autonomous vehicle,https://lens.org/112-401-086-776-545,2022,"A remote system for an autonomous vehicle, includes a receiver, a controller, and a display device. The receiver is configured to receive road information. The controller is programmed to receive input related to the road information and create a supervision zone when the road information impacts road drivability. The display device is disposed at a control center area and configured to display a visual indication on a map of the supervision zone."
REMOTE SYSTEM FOR AN AUTONOMOUS VEHICLE,https://lens.org/068-179-722-929-103,2018,"A remote system for an autonomous vehicle, includes a receiver, a controller, and a display device. The receiver is configured to receive road information. The controller is programmed to receive input related to the road information and create a supervision zone when the road information impacts road drivability. The display device is disposed at a control center area and configured to display a visual indication on a map of the supervision zone."
Ground proximity sensor for a UAV,https://lens.org/137-651-043-408-717,2011,"An unmanned aerial vehicle comprises a housing, a rotor that is rotated to propel the housing, a pressure sensor that generates a signal indicative of an air pressure proximate a bottom surface of the housing, and a processor configured to determine, based on the signal, when an increase in air pressure proximate the bottom surface is greater than or equal to a threshold value associated with the ground effect of the rotor, wherein the processor controls the rotor to cease rotating or decrease rotational speed to land the unmanned aerial vehicle upon determining that the increase in pressure is greater than or equal to the threshold value."
GROUND PROXIMITY SENSOR,https://lens.org/071-773-614-840-267,2011,"An unmanned aerial vehicle comprises a housing, a rotor that is rotated to propel the housing, a pressure sensor that generates a signal indicative of an air pressure proximate a bottom surface of the housing, and a processor configured to determine, based on the signal, when an increase in air pressure proximate the bottom surface is greater than or equal to a threshold value associated with the ground effect of the rotor, wherein the processor controls the rotor to cease rotating or decrease rotational speed to land the unmanned aerial vehicle upon determining that the increase in pressure is greater than or equal to the threshold value."
Ground proximity sensor,https://lens.org/148-088-173-913-243,2012,"An unmanned aerial vehicle comprises a housing, a rotor that is rotated to propel the housing, a pressure sensor that generates a signal indicative of an air pressure proximate a bottom surface of the housing, and a processor configured to determine, based on the signal, when an increase in air pressure proximate the bottom surface is greater than or equal to a threshold value associated with the ground effect of the rotor, wherein the processor controls the rotor to cease rotating or decrease rotational speed to land the unmanned aerial vehicle upon determining that the increase in pressure is greater than or equal to the threshold value."
MIXED-MODE DRIVING OF A VEHICLE HAVING AUTONOMOUS DRIVING CAPABILITIES,https://lens.org/176-862-617-424-551,2023,"Among other things, a vehicle having autonomous driving capabilities is operated in a mixed driving mode."
MIXED-MODE DRIVING OF A VEHICLE HAVING AUTONOMOUS DRIVING CAPABILITIES,https://lens.org/176-862-617-424-551,2023,"Among other things, a vehicle having autonomous driving capabilities is operated in a mixed driving mode."
Mixed-mode driving of a vehicle having autonomous driving capabilities,https://lens.org/075-247-874-464-54X,2022,"Among other things, a vehicle having autonomous driving capabilities is operated in a mixed driving mode."
Mixed-mode driving of a vehicle having autonomous driving capabilities,https://lens.org/137-728-790-744-16X,2021,"Among other things, a vehicle having autonomous driving capabilities is operated in a mixed driving mode."
Mixed-mode driving of a vehicle having autonomous driving capabilities,https://lens.org/075-247-874-464-54X,2022,"Among other things, a vehicle having autonomous driving capabilities is operated in a mixed driving mode."
MIXED-MODE DRIVING OF A VEHICLE HAVING AUTONOMOUS DRIVING CAPABILITIES,https://lens.org/081-671-839-454-928,2019,"Among other things, a vehicle having autonomous driving capabilities is operated in a mixed driving mode."
Powering of drone carrying transceiver,https://lens.org/042-952-302-199-732,2022,"A drone is described. The drone includes a propulsion system, a transceiver, a tether connector, and a power system. The power system has a battery and a chopper circuit. The chopper circuit bleeds excess charge from the battery. The power system is configured to power the propulsion system, and to power the transceiver through the chopper circuit. The power system is also configured to receive electrical power, through the tether connector, to charge the battery while the drone is in the air."
ASSET MANAGEMENT MONITORING,https://lens.org/135-367-725-848-890,2022,"Techniques are described for an autonomous asset management system that integrates autonomous devices, such as drone devices and other robotic devices, with a home security system of a property to enable management, monitoring, and/or tracking of various assets located within the property. In some implementations, an indication of an asset associated with a property is obtained by an autonomous device. Sensor data collected by one or more sensors of the property is obtained by the autonomous device based on the indication of the asset. A present status of the asset is determined by the autonomous device based on the sensor data. A determination that the present status of the asset does not correspond to an expected status of the asset is made by the autonomous device. In response, the autonomous device navigates to the particular location of the property."
Asset management monitoring,https://lens.org/014-049-092-246-249,2020,"Techniques are described for an autonomous asset management system that integrates autonomous devices, such as drone devices and other robotic devices, with a home security system of a property to enable management, monitoring, and/or tracking of various assets located within the property. In some implementations, an indication of an asset associated with a property is obtained by an autonomous device. Sensor data collected by one or more sensors of the property is obtained by the autonomous device based on the indication of the asset. A present status of the asset is determined by the autonomous device based on the sensor data. A determination that the present status of the asset does not correspond to an expected status of the asset is made by the autonomous device. In response, the autonomous device navigates to the particular location of the property."
Asset management monitoring,https://lens.org/026-231-531-833-602,2022,"Techniques are described for an autonomous asset management system that integrates autonomous devices, such as drone devices and other robotic devices, with a home security system of a property to enable management, monitoring, and/or tracking of various assets located within the property. In some implementations, an indication of an asset associated with a property is obtained by an autonomous device. Sensor data collected by one or more sensors of the property is obtained by the autonomous device based on the indication of the asset. A present status of the asset is determined by the autonomous device based on the sensor data. A determination that the present status of the asset does not correspond to an expected status of the asset is made by the autonomous device. In response, the autonomous device navigates to the particular location of the property."
Asset management monitoring,https://lens.org/026-231-531-833-602,2022,"Techniques are described for an autonomous asset management system that integrates autonomous devices, such as drone devices and other robotic devices, with a home security system of a property to enable management, monitoring, and/or tracking of various assets located within the property. In some implementations, an indication of an asset associated with a property is obtained by an autonomous device. Sensor data collected by one or more sensors of the property is obtained by the autonomous device based on the indication of the asset. A present status of the asset is determined by the autonomous device based on the sensor data. A determination that the present status of the asset does not correspond to an expected status of the asset is made by the autonomous device. In response, the autonomous device navigates to the particular location of the property."
ASSET MANAGEMENT MONITORING,https://lens.org/143-039-681-136-150,2021,"Techniques are described for an autonomous asset management system that integrates autonomous devices, such as drone devices and other robotic devices, with a home security system of a property to enable management, monitoring, and/or tracking of various assets located within the property. In some implementations, an indication of an asset associated with a property is obtained by an autonomous device. Sensor data collected by one or more sensors of the property is obtained by the autonomous device based on the indication of the asset. A present status of the asset is determined by the autonomous device based on the sensor data. A determination that the present status of the asset does not correspond to an expected status of the asset is made by the autonomous device. In response, the autonomous device navigates to the particular location of the property."
Asset management monitoring,https://lens.org/047-898-388-922-30X,2020,"Techniques are described for an autonomous asset management system that integrates autonomous devices, such as drone devices and other robotic devices, with a home security system of a property to enable management, monitoring, and/or tracking of various assets located within the property. In some implementations, an indication of an asset associated with a property is obtained by an autonomous device. Sensor data collected by one or more sensors of the property is obtained by the autonomous device based on the indication of the asset. A present status of the asset is determined by the autonomous device based on the sensor data. A determination that the present status of the asset does not correspond to an expected status of the asset is made by the autonomous device. In response, the autonomous device navigates to the particular location of the property."
ASSET MANAGEMENT MONITORING,https://lens.org/135-367-725-848-890,2022,"Techniques are described for an autonomous asset management system that integrates autonomous devices, such as drone devices and other robotic devices, with a home security system of a property to enable management, monitoring, and/or tracking of various assets located within the property. In some implementations, an indication of an asset associated with a property is obtained by an autonomous device. Sensor data collected by one or more sensors of the property is obtained by the autonomous device based on the indication of the asset. A present status of the asset is determined by the autonomous device based on the sensor data. A determination that the present status of the asset does not correspond to an expected status of the asset is made by the autonomous device. In response, the autonomous device navigates to the particular location of the property."
SYSTEM AND METHOD OF ROBOT CONTROL,https://lens.org/129-642-875-740-873,2019,"A system for controlling a robotic device in an indoor environment includes: a receiving unit of a robotic device configured to wirelessly receive, from at least a portion of a mains power line, a modulated electromagnetic signal leaked by the mains power line, the mains power line carrying a modulated alternating current signal, a demodulator of the robotic device configured to demodulate the modulated electromagnetic signal and extract one or more data signals from the demodulated electromagnetic signal, a processor configured to generate control data based on the one or more data signals, and a control unit configured to control one or more actuators of a robotic device based on the control data; and a system includes: a processor configured to generate control data for controlling one or more actuators of a robotic device, and a modulator configured to modulate an alternating current signal of a mains power line using the generated control data to create a modulated alternating current signal, thereby causing the mains power line to leak a modulated electromagnetic signal comprising the control data that is wirelessly detectable by a controlled robotic device."
NAVIGATIONAL CONTROL SYSTEM FOR A ROBOTIC DEVICE,https://lens.org/074-731-280-736-278,2013,"A navigational control system for altering movement activity of a robotic device operating in a defined working area, comprising a transmitting subsystem integrated in combination with the robotic device, the transmitting subsystem comprising means for emitting a number of directed beams, each directed beam having a predetermined emission pattern, and a receiving subsystem functioning as a base station that includes a navigation control algorithm that defines a predetermined triggering event for the navigational control system and a set of detection units positioned within the defined working area in a known spaced-apart relationship, the set of detection units being configured and operative to detect one or more of the directed beams emitted by the transmitting system."
Navigational control system for a robotic device,https://lens.org/172-131-339-878-515,2014,"A navigational control system for altering movement activity of a robotic device operating in a defined working area, comprising a transmitting subsystem integrated in combination with the robotic device, the transmitting subsystem comprising means for emitting a number of directed beams, each directed beam having a predetermined emission pattern, and a receiving subsystem functioning as a base station that includes a navigation control algorithm that defines a predetermined triggering event for the navigational control system and a set of detection units positioned within the defined working area in a known spaced-apart relationship, the set of detection units being configured and operative to detect one or more of the directed beams emitted by the transmitting system."
CAMERA HAVING ADAPTIVE FUNCTIONALITY BASED ON CONNECTION WITH HOST DEVICE,https://lens.org/063-396-735-356-657,2017,"A camera configured to operate in cooperation with a host device, wherein the camera detects the host device in response to connecting the camera to the host device, and implements operational functionality associated with the host device. The camera is adapted to operate autonomously and does not require input by a user."
DRONE IMMERSION-PILOTING SYSTEM,https://lens.org/142-217-774-047-213,2016,"The system comprises a drone and a ground station with a console adapted to be directed towards the drone, and virtual reality glasses rendering images taken by a camera of the drone. The system further comprises means for modifying the framing of the images taken by the camera as a function of framing instructions received from the ground station. It further comprises relative heading determination means (302-324) for periodically elaborating an angular difference between the orientation of the glasses and the orientation of the console, and means (316) for elaborating framing instructions for the drone as a function said angular difference. The sudden changes of framing when the user simply turns the console and his whole body, head included, towards the drone to follow it in its displacements, are hence avoided."
Drone immersion-piloting system,https://lens.org/008-709-567-299-306,2017,"The system comprises a drone and a ground station with a console adapted to be directed towards the drone, and virtual reality glasses rendering images taken by a camera of the drone. The system further comprises means for modifying the framing of the images taken by the camera as a function of framing instructions received from the ground station. It further comprises relative heading determination means (302-324) for periodically elaborating an angular difference between the orientation of the glasses and the orientation of the console, and means (316) for elaborating framing instructions for the drone as a function said angular difference. The sudden changes of framing when the user simply turns the console and his whole body, head included, towards the drone to follow it in its displacements, are hence avoided."
PERSONAL MONITORING APPARATUS AND METHODS,https://lens.org/174-489-220-408-152,2023,"An apparatus, including a database which stores a travel itinerary or schedule of an individual; a processor; a global positioning system device; and a transmitter. The processor monitors a movement of the individual, compares information obtained by the global positioning system device with information contained in the travel itinerary or schedule, detects a deviation from an expected position, location, or travel route, and generates a message containing information regarding a date and time of the deviation and position or location information of the apparatus. The transmitter or apparatus transmits the message or information contained in the message to a drone. An operation of the drone is activated, the drone travels to the position or location of the apparatus, records video information of the apparatus or individual or of an area in a vicinity of the apparatus or individual, and transmits the video information to the user device or the computer."
PERSONAL MONITORING APPARATUS AND METHODS,https://lens.org/174-489-220-408-152,2023,"An apparatus, including a database which stores a travel itinerary or schedule of an individual; a processor; a global positioning system device; and a transmitter. The processor monitors a movement of the individual, compares information obtained by the global positioning system device with information contained in the travel itinerary or schedule, detects a deviation from an expected position, location, or travel route, and generates a message containing information regarding a date and time of the deviation and position or location information of the apparatus. The transmitter or apparatus transmits the message or information contained in the message to a drone. An operation of the drone is activated, the drone travels to the position or location of the apparatus, records video information of the apparatus or individual or of an area in a vicinity of the apparatus or individual, and transmits the video information to the user device or the computer."
PROPELLER CONTACT AVOIDANCE IN AN UNMANNED AERIAL VEHICLE,https://lens.org/164-928-360-139-643,2019,"An unmanned aerial vehicle comprising one or more sensors, configured to receive data from an area surrounding the unmanned aerial vehicle; one or more processors, configured to detect movement in a region surrounding the unmanned aerial vehicle using the sensor data; assess the detected movement for fulfillment of a predetermined movement threshold; and upon fulfillment of the predetermined movement threshold, switch between a first operational mode and a second operational mode."
Process for remote communication between a command transmitter and a command receiver,https://lens.org/135-215-636-748-262,2006,"A system for activating an object actuating system coupled to a movable object such as a gate or garage door includes a user command transmitter that is manipulable by a person to generate a signal representing an identification and a command. A repeater receives the signals from the command transmitter and in turn, in the presence of a valid ID, sends a command signal to the object actuating system, which in turn moves the object only if the ID from the repeater (which can be different from the ID from the command transmitter) is valid."
Process for remote communication between a command transmitter and a command receiver,https://lens.org/165-903-018-174-764,2004,"A system for activating an object actuating system coupled to a movable object such as a gate or garage door includes a user command transmitter that is manipulable by a person to generate a signal representing an identification and a command. A repeater receives the signals from the command transmitter and in turn, in the presence of a valid ID, sends a command signal to the object actuating system, which in turn moves the object only if the ID from the repeater (which can be different from the ID from the command transmitter) is valid."
UNMANNED AERIAL VEHICLE (UAV) FOR COLLECTING AUDIO DATA,https://lens.org/173-465-845-124-296,2021,"An unmanned aerial vehicle (UAV) includes an audio source collecting microphone detecting a target audio signal, background noise-producing components producing background noise different from the target audio signal, background microphones collecting the background noise, and noise emitters each configured to reduce the background noise by emitting an audio signal having a reverse phase of the collected background noise collected by the corresponding background microphone. The background microphones further collect reduced background noise. The UAV further includes a processor receiving signals which comprise the target audio signal and the reduced background noise, and generating a processed signal based on the collected reduced background noise to reduce interference by the background noise to the target audio signal."
UNMANNED AERIAL VEHICLE,https://lens.org/046-866-361-998-627,2022,"An unmanned aerial vehicle for at least one of direction finding and spectrum monitoring includes a main body including at least one electronic circuit and at least one motor. The unmanned aerial vehicle also has at least one rotor associated with the motor. The unmanned aerial vehicle includes an outer housing surrounding the rotor partially, the outer housing including at least one antenna module configured to receive a radio signal."
UNMANNED AERIAL VEHICLE,https://lens.org/046-866-361-998-627,2022,"An unmanned aerial vehicle for at least one of direction finding and spectrum monitoring includes a main body including at least one electronic circuit and at least one motor. The unmanned aerial vehicle also has at least one rotor associated with the motor. The unmanned aerial vehicle includes an outer housing surrounding the rotor partially, the outer housing including at least one antenna module configured to receive a radio signal."
Unmanned Aerial Vehicle with Electromagnetic Pulse Transmitter,https://lens.org/104-378-495-918-994,2021,"An Unmanned Aerial Vehicle is disclosed. The Unmanned Aerial Vehicle includes a body, rotors attached to the body, one or more sensors, and an electromagnetic pulse transmitter. The electromagnetic pulse transmitter is configured to transmit an EMP and the Unmanned Aerial Vehicle is configured to track a target Unmanned Aerial Vehicle using the one or more sensors and direct the electromagnetic pulse transmitter at the target Unmanned Aerial Vehicle to disrupt the target Unmanned Aerial Vehicle."
"AUTONOMOUS VIDEO-BASED AIRCRAFT DOCKING SYSTEM, APPARATUS, AND METHOD",https://lens.org/106-845-554-012-651,1996,"An autonomous video-based aircraft docking system comprises a camera arrangement, an image processing unit coupled to the camera arrangement and a communications unit coupled to the image processing unit, the camera arrangement being oriented to obtain an image of an aircraft through a designated portion of its approach for docking, the image processing unit processing the image for detecting in accordance with prestored data a location of a predetermined feature of the image and causing the communications unit to output a signal indicative of the orientation and location of the aircraft."
Guidance system for radio-controlled aircraft,https://lens.org/125-149-414-474-07X,2007,"A method and system are described for controlling the flight pattern of a remote controlled aircraft. The system includes a microcontroller that is linked to an accelerometer for determining the attitude of the aircraft and modifying signals to the aircraft's flight control system in order to prevent a crash. In addition, several preset flight patterns are stored in a memory so that upon activation, the aircraft will enter a preset flight pattern."
GUIDANCE SYSTEM FOR RADIO-CONTROLLED AIRCRAFT,https://lens.org/150-875-793-929-347,2002,"A method and system are described for controlling the flight pattern of a remote controlled aircraft. The system includes a microcontroller that is linked to an accelerometer for determining the attitude of the aircraft and modifying signals to the aircraft's flight control system in order to prevent a crash. In addition, several preset flight patterns are stored in a memory so that upon activation, the aircraft will enter a preset flight pattern."
PROGRAMMABLE ROBOTIC APPARATUS FOR CONSTRUCTION,https://lens.org/133-617-822-457-062,2008,"A robotic apparatus for use in construction that is capable of traversing a selected area autonomously. The robotic apparatus is provided in two models, a master that can record directive and ""environmental signal"" readings, or that can record received location information, to provide at least one command recorded on a machine-readable medium representing an instruction for traversing an area of interest, and a slave that lacks the recording capability. Both master and slave models can replay recorded commands, and compare the expected orientation from the command with an actual orientation sensed during autonomous operation. If an error exceeding a predetermined value is observed, a corrective action is taken. The robotic apparatus is to perform a task, such as marking locations in construction of a building for installation of services such as wiring and plumbing."
PROGRAMMABLE ROBOTIC APPARATUS FOR CONSTRUCTION,https://lens.org/021-841-576-990-608,2008,"A robotic apparatus for use in construction that is capable of traversing a selected area autonomously. The robotic apparatus is provided in two models, a master that can record directive and ""environmental signal"" readings, or that can record received location information, to provide at least one command recorded on a machine-readable medium representing an instruction for traversing an area of interest, and a slave that lacks the recording capability. Both master and slave models can replay recorded commands, and compare the expected orientation from the command with an actual orientation sensed during autonomous operation. If an error exceeding a predetermined value is observed, a corrective action is taken. The robotic apparatus is to perform a task, such as marking locations in construction of a building for installation of services such as wiring and plumbing."
INFRARED EMITTING DEVICE AND CONTROL SYSTEM FOR ELECTRONIC DEVICE,https://lens.org/163-491-174-506-096,2020,"An infrared emitting device for converting a voice command into an infrared signal and transmitting it to an electronic device to control the electronic device, including a storage module, a first collecting module, and a preprocessing a module, a voice recognition module, and an infrared transmitter. The storage module is configured to store a preset voice feature; the first collecting module is configured to collect voice data; the preprocessing module is configured to obtain a target voice; the voice recognition module is configured to extract target voice features from the target voice, and compare the obtained target voice feature with a preset voice feature. When a ratio of the target voice feature to the preset voice feature is greater than or equal to a set threshold the infrared emission generates an infrared signal and transmits the infrared signal to an electronic device to control the electronic device."
AIRCRAFT EXPLORATION SYSTEM,https://lens.org/096-794-997-745-936,2013,"An aircraft exploration system includes an unmanned aircraft, a remote control, a communication processer and a data processing terminal. The an unmanned aircraft equipped with an MCU module, an image module, a first transceiver module and a GPS module, the above-mentioned modules are electronically connected to the MCU module. The unmanned aircraft is controlled by the remote control to fly. The data processing terminal is electronically connected to the communication processer, the GPS module senses the position signals of the unmanned aircraft and sends position signals to the data processing terminal, and the data processing terminal displays a map of an environment surrounding the unmanned aircraft promptly and in real time due to the positioning signals via internet."
Robot device control based on environment and position of a movable robot,https://lens.org/147-061-369-820-456,2010,"The control apparatus for a movable robot comprises: environment information acquisition means (such as video camera 3 and microphone 4); a current position detecting means (15); a map storage (7); a control parameter storage (9) for storing control parameters adjusted to different environments; and control means (11, 12) for determining a current position of the robot on the map data based on a signal from the current position detecting means, retrieving control parameters suitable for the current position from the parameter storage, and controlling the environment information acquisition means or actuators for moving the robot by using the retrieved control parameters."
UNMANNED AERIAL VEHICLE ILLUMINATION SYSTEM,https://lens.org/027-770-261-850-523,2022,"A method of controlling camera and illumination systems may trigger a camera system to start exposing. An illumination system is also triggered to illuminate an infrared exposure of the camera system. The method also triggers multiple camera and illumination systems. In addition, a method of identification by a transmitter is provided. The method provides for modulating an infrared light source with a unique pattern to identify an unmanned aerial vehicle (UAV) and then sending the modulated light pattern to a receiver."
"INFORMATION PROCESSING DEVICE, INFORMATION PROCESSING METHOD, AND RECORDING MEDIUM",https://lens.org/100-814-695-772-232,2021,"A controller includes processor and memory. The memory stores (i) a captured image outputted from a camera in an unmanned aircraft and (ii) sound outputted from a directional microphone in the unmanned aircraft, and stores (i) a position and an orientation of the camera and (ii) a position and an orientation of the directional microphone. The processor obtains, from the memory, the captured image, the sound, the position and the orientation of the camera, and the position and the orientation of the directional microphone, calculates a sound pickup direction of the directional microphone using the position and the orientation of the camera and the position and the orientation of the directional microphone, superimposes an object indicating the sound pickup direction at a position, on the captured image, corresponding to the sound pickup direction calculated, and causes a display device to display the captured image on which the object is superimposed."
HAND HELD CONTROL APPARATUS,https://lens.org/155-819-046-478-875,1990,"A control apparatus (10) to be mounted on the arm of a user, and manipulated by the user to control a remote device such as a model aeroplane. The apparatus includes a stabilising arm (17) to be secured to the arm of the user and a pistol grip (18) attached to the stabilising arm (17). The grip (18) is manipulated by the user and is operatively connected to a hydraulic or electronic mapping convertor for converting movement of the grip (18) into a signal to be received by the remote device."
Equipment for assisting underwater exploration and underwater robot for the equipment,https://lens.org/148-236-522-356-572,2021,"The invention relates to equipment comprising an underwater robot (1) and a device (2) for the remote control of the robot, which can communicate with each other, wherein: the robot comprises means for underwater movement and an image-capturing device; and the control device comprises 3D glasses designed so that a user wearing the glasses views the underwater environment of the robot in three dimensions on the basis of the images captured by the robot, and means for remotely guiding the movement of the robot on the basis of the three-dimensional underwater environment viewed."
Autonomous mobile robot,https://lens.org/156-145-688-432-13X,2021,"An autonomous mobile robot includes a robot body, a movement unit, a detector, and a controller. The movement unit moves the robot body to a destination point. The detector detects a state of a person present around the destination point. The controller controls the movement unit so as to make the autonomous mobile robot approach the person present around the destination point along a travel route that differs depending on the state of the person detected by the detector."
AUTONOMOUS MOBILE ROBOT,https://lens.org/131-818-997-308-147,2018,"An autonomous mobile robot includes a robot body, a movement unit, a detector, and a controller. The movement unit moves the robot body to a destination point. The detector detects a state of a person present around the destination point. The controller controls the movement unit so as to make the autonomous mobile robot approach the person present around the destination point along a travel route that differs depending on the state of the person detected by the detector."
SYSTEM AND METHOD FOR SUPPORTING AUTONOMOUS VEHICLE,https://lens.org/043-248-742-632-365,2020,"A system for supporting an autonomous vehicle includes a server configured to search for and provide a driving route in response to a request of the vehicle; a controller configured to perform autonomous driving based on a road autonomous driving level included in the driving route, identify whether a change condition of a vehicle autonomous driving level is met, and adjust the vehicle autonomous driving level when the change condition of the vehicle autonomous driving level is met."
LIGHTING DEVICE AND LIGHTING SYSTEM,https://lens.org/006-350-166-490-299,2018,"A lighting device includes: a communication unit configured to wirelessly communicate with a wireless device provided externally; a command receiver that receives a command from outside; a light emitter including a light source; and a controller connected to the communication unit, the command receiver, and the light emitter. The command receiver receives a wireless device specifying command that specifies the wireless device with which the communication unit is to wirelessly communicate. The controller tests wireless communication with the wireless device via the communication unit based on the wireless device specifying command received, obtains communication reliability information regarding the reliability of the wireless communication, and causes the light emitter to perform at least one of flashing, dimming, and toning based on the communication reliability information obtained."
Lighting device and lighting system,https://lens.org/098-050-030-124-532,2019,"A lighting device includes: a communication unit configured to wirelessly communicate with a wireless device provided externally; a command receiver that receives a command from outside; a light emitter including a light source; and a controller connected to the communication unit, the command receiver, and the light emitter. The command receiver receives a wireless device specifying command that specifies the wireless device with which the communication unit is to wirelessly communicate. The controller tests wireless communication with the wireless device via the communication unit based on the wireless device specifying command received, obtains communication reliability information regarding the reliability of the wireless communication, and causes the light emitter to perform at least one of flashing, dimming, and toning based on the communication reliability information obtained."
DUAL REDUNDANT GPS ANTI-JAM AIR VEHICLE NAVIGATION SYSTEM,https://lens.org/123-276-637-291-501,2004,"A navigation system for an unmanned aerial vehicle, the navigation system comprising a first antenna for receiving a global positioning system signal, a first interference suppression unit coupled to the first antenna, the first interference suppression unit suppressing interference in the global positioning system signal using a first interference suppression technique, a first navigation unit for receiving signals from the first interference suppression unit, a second antenna for receiving the global positioning syst em signal, a second interference suppression unit coupled to the second antenna , the second interference suppression unit suppressing interference in the global positioning system signal using a second interference suppression technique, and a second navigation unit for receiving signals from the secon d interference suppression unit. A method for controlling the flight of an air vehicle performed by the apparatus is also included."
OBSTACLE CLIMBING SURVEILLANCE ROBOT AND ENERGY-ABSORBING FRAME THEREFOR,https://lens.org/172-769-885-988-36X,2018,"A surveillance system includes a robot and an operator control unit (OCU) for controlling the robot. The robot includes a light-weight frame housing, wheels, motor compartments positioned within the light-weight frame housing, wheel motors positioned within the motor compartments and attached to the wheels, a camera for capturing surveillance images and an electronic controller that is electrically or wirelessly connected to the wheel motors and the camera and that is wirelessly connected to the OCU. The light-weight frame is made of light-weight foam that substantially surrounds, structurally supports and protects the robot wheel motors, camera and electronic controller from mechanical shock during intended use."
Obstacle climbing surveillance robot and energy-absorbing frame therefor,https://lens.org/141-887-911-172-800,2022,"A surveillance system includes a robot and an operator control unit (OCU) for controlling the robot. The robot includes a light-weight frame housing, wheels, motor compartments positioned within the light-weight frame housing, wheel motors positioned within the motor compartments and attached to the wheels, a camera for capturing surveillance images and an electronic controller that is electrically or wirelessly connected to the wheel motors and the camera and that is wirelessly connected to the OCU. The light-weight frame is made of light-weight foam that substantially surrounds, structurally supports and protects the robot wheel motors, camera and electronic controller from mechanical shock during intended use."
Obstacle climbing surveillance robot and energy-absorbing frame therefor,https://lens.org/141-887-911-172-800,2022,"A surveillance system includes a robot and an operator control unit (OCU) for controlling the robot. The robot includes a light-weight frame housing, wheels, motor compartments positioned within the light-weight frame housing, wheel motors positioned within the motor compartments and attached to the wheels, a camera for capturing surveillance images and an electronic controller that is electrically or wirelessly connected to the wheel motors and the camera and that is wirelessly connected to the OCU. The light-weight frame is made of light-weight foam that substantially surrounds, structurally supports and protects the robot wheel motors, camera and electronic controller from mechanical shock during intended use."
Quad-rotor flight device,https://lens.org/068-597-849-493-468,2014,"The utility model relates to a quad-rotor flight device which is composed of a microprocessor, a three-axis gyro sensor, a GPS module, an electronic speed regulator, a brushless direct current motor, a propeller, a motor speed measuring module, a wireless data transmission module, a ground receiver and a remote control. The three-axis gyro sensor, the GPS module, the electronic speed regulator, the motor speed measuring module and the wireless data transmission module are respectively connected to the microprocessor. The electronic speed regulator, the propeller, the motor speed measuring module are respectively connected to the brushless direct current motor. The wireless data transmission module and the remote control are respectively to the ground receiver. The wireless data transmission module is connected to the remote control. A real-time wireless control can be carried out. Various types of sensors can be carried. The quad-rotor flight device can be popularized to the technical fields such as air-to-ground detection, aerial-photographed image collection and the like."
Centrifugal compressor based altitude control device with active valve system,https://lens.org/111-764-732-338-803,2022,"An altitude control system for an unmanned aerial vehicle includes a compressor assembly defining a plenum therein, a passive valve assembly coupled to a first portion of the compressor assembly and in fluid communication with the plenum, and an active valve assembly coupled to a second portion of the compressor assembly and in fluid communication with the plenum. A method of controlling an altitude of an unmanned aerial vehicle and an unmanned aerial vehicle are also provided."
Centrifugal compressor based altitude control device with active valve system,https://lens.org/111-764-732-338-803,2022,"An altitude control system for an unmanned aerial vehicle includes a compressor assembly defining a plenum therein, a passive valve assembly coupled to a first portion of the compressor assembly and in fluid communication with the plenum, and an active valve assembly coupled to a second portion of the compressor assembly and in fluid communication with the plenum. A method of controlling an altitude of an unmanned aerial vehicle and an unmanned aerial vehicle are also provided."
CENTRIFUGAL COMPRESSOR BASED ALTITUDE CONTROL DEVICE WITH ACTIVE VALVE SYSTEM,https://lens.org/187-249-736-783-251,2020,"An altitude control system for an unmanned aerial vehicle includes a compressor assembly defining a plenum therein, a passive valve assembly coupled to a first portion of the compressor assembly and in fluid communication with the plenum, and an active valve assembly coupled to a second portion of the compressor assembly and in fluid communication with the plenum. A method of controlling an altitude of an unmanned aerial vehicle and an unmanned aerial vehicle are also provided."
ARM ASSEMBLY AND UNMANNED AERIAL VEHICLE,https://lens.org/128-867-086-563-692,2020,"An unmanned aerial vehicle (UAV) includes a vehicle body and an arm assembly. The vehicle body includes a distribution board. The arm assembly includes an arm body, a lampshade, and an electric speed control (ESC) light control board. The arm body includes an accommodation space. The lampshade is mounted at the arm body. The ESC light control board is arranged in the accommodation space and electrically connected to the distribution board through a wire. The ESC light control board includes an illuminator corresponding to the lampshade and is configured to emit light out of the arm assembly through the lampshade."
SYSTEMS AND METHODS FOR UAV SENSOR PLACEMENT,https://lens.org/045-447-896-773-261,2021,"An unmanned aerial vehicle (UAV) (200, 300, 400, 700, 800, 1000, 1200, 1500) can include a central body (202, 302, 402, 702, 802, 1002, 1202, 1502), a plurality of rotors, and a plurality of arms (204, 306, 406, 706, 806, 1006, 1206, 1506) extending from the central body (202, 302, 402, 702, 802, 1002, 1202, 1502), where each arm of the plurality of arms (204, 306, 406, 706, 806, 1006, 1206, 1506) is configured to support one or more of the plurality of rotors. The UAV may include at least one sensor (208, 318, 418, 718, 818, 822, 1022, 1218, 1222, 1518) located on the UAV (200, 300, 400, 700, 800, 1000, 1200, 1500)."
SYSTEMS AND METHODS FOR A HOUSING EQUIPMENT FOR A SECURITY VEHICLE,https://lens.org/105-220-645-703-152,2019,A system for providing security functions to a vehicle may comprise a chassis and a drone. The chassis may be configured to be mounted on top of the vehicle. The chassis may include a drone port for housing a drone. The drone may include a camera. The camera of the drone may be configured to capture images of objects outside of the chassis while the drone is positioned in the drone port. A device including the chassis may be a light bar and further include lights positioned at a periphery of the device.
SYSTEMS AND METHODS FOR A HOUSING EQUIPMENT FOR A SECURITY VEHICLE,https://lens.org/125-255-751-358-44X,2020,A system for providing security functions to a vehicle may comprise a chassis and a drone. The chassis may be configured to be mounted on top of the vehicle. The chassis may include a drone port for housing a drone. The drone may include a camera. The camera of the drone may be configured to capture images of objects outside of the chassis while the drone is positioned in the drone port. A device including the chassis may be a light bar and further include lights positioned at a periphery of the device.
SYSTEMS AND METHODS FOR A HOUSING EQUIPMENT FOR A SECURITY VEHICLE,https://lens.org/062-692-832-304-365,2020,A system for providing security functions to a vehicle may comprise a chassis and a drone. The chassis may be configured to be mounted on top of the vehicle. The chassis may include a drone port for housing a drone. The drone may include a camera. The camera of the drone may be configured to capture images of objects outside of the chassis while the drone is positioned in the drone port. A device including the chassis may be a light bar and further include lights positioned at a periphery of the device.
SYSTEMS AND METHODS FOR A HOUSING EQUIPMENT FOR A SECURITY VEHICLE,https://lens.org/146-266-597-619-52X,2021,A system for providing security functions to a vehicle may comprise a chassis and a drone. The chassis may be configured to be mounted on top of the vehicle. The chassis may include a drone port for housing a drone. The drone may include a camera. The camera of the drone may be configured to capture images of objects outside of the chassis while the drone is positioned in the drone port. A device including the chassis may be a light bar and further include lights positioned at a periphery of the device.
Systems and methods for a housing equipment for a security vehicle,https://lens.org/064-324-824-364-812,2022,A system for providing security functions to a vehicle may comprise a chassis and a drone. The chassis may be configured to be mounted on top of the vehicle. The chassis may include a drone port for housing a drone. The drone may include a camera. The camera of the drone may be configured to capture images of objects outside of the chassis while the drone is positioned in the drone port. A device including the chassis may be a light bar and further include lights positioned at a periphery of the device.
Voice Assistant Devices,https://lens.org/144-555-086-425-246,2020,A voice assistant device comprises an input to receive data defining an audio command; and processing circuitry to perform an operation defined by the audio command responsive to an activation of the voice assistant device; wherein the activation comprises determining presence of an activation source within an activation region from one or more sensors.
Voice assistant devices,https://lens.org/107-528-337-916-010,2021,A voice assistant device comprises an input to receive data defining an audio command; and processing circuitry to perform an operation defined by the audio command responsive to an activation of the voice assistant device; wherein the activation comprises determining presence of an activation source within an activation region from one or more sensors.
DELIVERY SYSTEM,https://lens.org/056-161-398-123-528,2016,"The invention relates to a delivery system for use with an unmanned aerial vehicle (""UAV"") to deliver goods to a location. The delivery system includes, a first part including a carrier means for carrying the goods with the UAV and a sensor means, in communication with the controls of the UAV. The delivery system also includes a second part at the delivery location, including a receptacle for receiving the goods. In use, the UAV can be directed to deliver goods carried in the carrier means to near the delivery location and on the sensor detecting the location means, communicates with the controls of the UAV to move the UAV to be substantially aligned with the opening of the receptacle for release of the goods therein. The invention also relates to a variant thereof and a method of use."
Unmanned aerial vehicles,https://lens.org/199-776-707-912-827,2021,"Various measures (for example methods, UAVs, controllers and computer programs) are provided in relation to controlling a UAV. The UAV is caused to provide energy to and receive energy from a given vehicle. The received energy is used to provide power to at least one component of the UAV."
UNMANNED AERIAL VEHICLES,https://lens.org/108-207-634-956-464,2019,"Various measures (for example methods, UAVs, controllers and computer programs) are provided in relation to controlling a UAV. The UAV is caused to provide energy to and receive energy from a given vehicle. The received energy is used to provide power to at least one component of the UAV."
Flying vehicle navigation system and flying vehicle navigation method,https://lens.org/099-213-683-166-983,2021,"A flying vehicle navigation system includes a flying vehicle (2) and a control system (4) that controls the flight of the flying vehicle. The flying vehicle is configured to be switchable to autonomous driving when the flying vehicle is located in a first takeoff and landing section (22) set on the ground. After the flying vehicle is switched to autonomous driving, the control system guides the flying vehicle such that the flying vehicle takes off from a first takeoff and landing section, flies in a three-dimensional road as an exclusive track set in the specific region of the air, and lands on a second takeoff and landing section set on the ground. After the flying vehicle is switched to autonomous driving, operations from takeoff from the first takeoff and landing section to landing on the second takeoff and landing section are automatically carried out under control by the control system."
FLYING VEHICLE NAVIGATION SYSTEM AND FLYING VEHICLE NAVIGATION METHOD,https://lens.org/087-733-076-721-360,2019,"A flying vehicle navigation system includes a flying vehicle (2) and a control system (4) that controls the flight of the flying vehicle. The flying vehicle is configured to be switchable to autonomous driving when the flying vehicle is located in a first takeoff and landing section (22) set on the ground. After the flying vehicle is switched to autonomous driving, the control system guides the flying vehicle such that the flying vehicle takes off from a first takeoff and landing section, flies in a three-dimensional road as an exclusive track set in the specific region of the air, and lands on a second takeoff and landing section set on the ground. After the flying vehicle is switched to autonomous driving, operations from takeoff from the first takeoff and landing section to landing on the second takeoff and landing section are automatically carried out under control by the control system."
AUTONOMOUS MOBILE DEVICE AND CONTROL METHOD THEREOF,https://lens.org/117-870-704-492-130,2023,"An autonomous mobile device and a control method are disclosed. The autonomous mobile device includes a main body and an imaging device, a detecting device, a light source assembly, and a controller disposed at the main body. The imaging device is configured to acquire image information in a predetermined direction of the main body. The predetermined direction includes an upward direction of the main body. The detecting device is configured to detect obstacle information in the upward direction of the main body. A light outputting direction of the light source assembly includes the upward direction of the main body. The controller is configured to, when the detecting device detects the obstacle within a predetermined distance range in the upward direction of the main body, control the light source assembly to turn on to provide illumination for the imaging device."
AUTONOMOUS MOBILE DEVICE AND CONTROL METHOD THEREOF,https://lens.org/117-870-704-492-130,2023,"An autonomous mobile device and a control method are disclosed. The autonomous mobile device includes a main body and an imaging device, a detecting device, a light source assembly, and a controller disposed at the main body. The imaging device is configured to acquire image information in a predetermined direction of the main body. The predetermined direction includes an upward direction of the main body. The detecting device is configured to detect obstacle information in the upward direction of the main body. A light outputting direction of the light source assembly includes the upward direction of the main body. The controller is configured to, when the detecting device detects the obstacle within a predetermined distance range in the upward direction of the main body, control the light source assembly to turn on to provide illumination for the imaging device."
PROVIDING AUTOMATIC DEPENDENT SURVEILLANCE - BROADCAST DATA FOR UNMANNED AERIAL VEHICLES,https://lens.org/151-061-515-695-898,2019,"A device can be configured to receive flight data from an unmanned aerial vehicle (UAV), where the flight data indicates at least one of an identifier that identifies the UAV, a location of the UAV, an altitude of the UAV, a bearing of the UAV, or a speed of the UAV. The device can be further configured to convert at least a portion of the flight data from a first format to a second format; generate automatic dependent surveillance-broadcast (ADS-B) data based on the converted flight data; and perform an action associated with the ADS-B data."
PROVIDING AUTOMATIC DEPENDENT SURVEILLANCE - BROADCAST DATA FOR UNMANNED AERIAL VEHICLES,https://lens.org/170-419-743-065-33X,2020,"A device can be configured to receive flight data from an unmanned aerial vehicle (UAV), where the flight data indicates at least one of an identifier that identifies the UAV, a location of the UAV, an altitude of the UAV, a bearing of the UAV, or a speed of the UAV. The device can be further configured to convert at least a portion of the flight data from a first format to a second format; generate automatic dependent surveillance-broadcast (ADS-B) data based on the converted flight data; and perform an action associated with the ADS-B data."
Providing automatic dependent surveillancebroadcast data for unmanned aerial vehicles,https://lens.org/058-951-100-633-277,2022,"A device can be configured to receive flight data from an unmanned aerial vehicle (UAV), where the flight data indicates at least one of an identifier that identifies the UAV, a location of the UAV, an altitude of the UAV, a bearing of the UAV, or a speed of the UAV. The device can be further configured to convert at least a portion of the flight data from a first format to a second format; generate automatic dependent surveillance-broadcast (ADS-B) data based on the converted flight data; and perform an action associated with the ADS-B data."
PROVIDING AUTOMATIC DEPENDENT SURVEILLANCE - BROADCAST DATA FOR UNMANNED AERIAL VEHICLES,https://lens.org/022-910-237-271-409,2022,"A device can be configured to receive flight data from an unmanned aerial vehicle (UAV), where the flight data indicates at least one of an identifier that identifies the UAV, a location of the UAV, an altitude of the UAV, a bearing of the UAV, or a speed of the UAV. The device can be further configured to convert at least a portion of the flight data from a first format to a second format; generate automatic dependent surveillance-broadcast (ADS-B) data based on the converted flight data; and perform an action associated with the ADS-B data."
PROVIDING AUTOMATIC DEPENDENT SURVEILLANCE - BROADCAST DATA FOR UNMANNED AERIAL VEHICLES,https://lens.org/022-910-237-271-409,2022,"A device can be configured to receive flight data from an unmanned aerial vehicle (UAV), where the flight data indicates at least one of an identifier that identifies the UAV, a location of the UAV, an altitude of the UAV, a bearing of the UAV, or a speed of the UAV. The device can be further configured to convert at least a portion of the flight data from a first format to a second format; generate automatic dependent surveillance-broadcast (ADS-B) data based on the converted flight data; and perform an action associated with the ADS-B data."
Providing automatic dependent surveillance-broadcast data for unmanned aerial vehicles,https://lens.org/107-672-719-420-711,2020,"A device can be configured to receive flight data from an unmanned aerial vehicle (UAV), where the flight data indicates at least one of an identifier that identifies the UAV, a location of the UAV, an altitude of the UAV, a bearing of the UAV, or a speed of the UAV. The device can be further configured to convert at least a portion of the flight data from a first format to a second format; generate automatic dependent surveillance-broadcast (ADS-B) data based on the converted flight data; and perform an action associated with the ADS-B data."
DRONE-BASED RADIO-OVER-FIBER SYSTEM,https://lens.org/174-603-528-417-430,2018,"The drone-based radio-over-fiber system provides an unmanned aerial vehicle (AV), preferably a multi-rotor drone, connected to a base station by a tether including an optical fiber. A radio frequency-over-fiber system is used for bidirectional data communications between at least one radio frequency (RF) transmitter at the base station and at least one antenna mounted on the drone through the optical fiber in the tether. The system includes wave division multiplexers/demultiplexers that permit ultrahigh bandwidth communication over the tether. An embodiment of the system for 22 multiple-input, multiple-output (MIMO) signals in the 700 MHz LTE band is described."
Drone-based radio-over-fiber system,https://lens.org/121-055-001-234-980,2018,"The drone-based radio-over-fiber system provides an unmanned aerial vehicle (AV), preferably a multi-rotor drone, connected to a base station by a tether including an optical fiber. A radio frequency-over-fiber system is used for bidirectional data communications between at least one radio frequency (RF) transmitter at the base station and at least one antenna mounted on the drone through the optical fiber in the tether. The system includes wave division multiplexers/demultiplexers that permit ultrahigh bandwidth communication over the tether. An embodiment of the system for 22 multiple-input, multiple-output (MIMO) signals in the 700 MHz LTE band is described."
DRONE-BASED RADIO-OVER-FIBER SYSTEM,https://lens.org/159-516-042-459-316,2018,"The drone-based radio-over-fiber system provides an unmanned aerial vehicle (AV), preferably a multi-rotor drone, connected to a base station by a tether including an optical fiber. A radio frequency-over-fiber system is used for bidirectional data communications between at least one radio frequency (RF) transmitter at the base station and at least one antenna mounted on the drone through the optical fiber in the tether. The system includes wave division multiplexers/demultiplexers that permit ultrahigh bandwidth communication over the tether. An embodiment of the system for 22 multiple-input, multiple-output (MIMO) signals in the 700 MHz LTE band is described."
SYSTEM AND METHOD FOR DYNAMICALLY MASKING VIDEO AND IMAGES CAPTURED A DRONE DEVICE CAMERA,https://lens.org/189-557-480-098-521,2019,"Systems and methods for dynamically masking video or images captured by a drone device camera (28) are provided. Such systems and methods include flying the drone device proximate to a potential surveillance area while in a learning mode, capturing first video or images of the potential surveillance area (30), identifying first privacy masking areas in the first video or images, flying the drone device proximate to an active surveillance area (32) while in a standard mode, capturing second video or images of the active surveillance area, identifying second privacy masking areas in the the second video or images, and dynamically masking a portion of the second video or images that contains any of the first privacy masking areas or the second privacy masking areas."
REMOTE CONTROL SYSTEM FOR A CRANE,https://lens.org/129-995-508-342-666,2023,"A handheld remote control for a crane includes a wireless transceiver, an input device, a display screen, and processing circuitry. The wireless transceiver is configured to wirelessly communicate with a controller of the crane. The input device is configured to receive a user input. The display screen is configured to display information regarding deployment of a stabilizer of the crane. The processing circuitry is configured to obtain the user input via the input device, and cause at least one stabilizer of the crane to deploy or retract based on the user input."
Multi-functional robot with remote and video system,https://lens.org/105-252-491-829-495,2003,"A robot which incorporates a body, two arms, two legs, several sensors, an audio system, a light assembly, and a video device. The sensors located throughout the body of the robot combined with an edge detection sensor allows the robot to interact with objects in the room, and prevents the robot from traveling off an edge or bumping into obstacles. The audio system allows the robot to detect and transmit sounds. The video device allows a user to remotely view the area in front of the robot. Additionally, the robot may operate in a plurality of modes which allow the robot to operate autonomously. The robot may operate autonomously in an automatic mode, a security mode, a greet mode, and a monitor mode. Further, the robot can be manipulated remotely."
Managing an audio network,https://lens.org/179-450-328-010-772,2005,"A message that includes a command for an audio device is received, and the command is transmitted to the audio device."
MULTIPLE ENERGY SOURCE GUIDANCE SYSTEM AND METHOD FOR DRONES,https://lens.org/094-315-310-077-246,2018,"When a first laser beam and a second laser beam are directed to the volume of space, an aerial drone is configured to lock onto the first laser beam using a first sensor, and to utilize the first laser beam to guide the drone to an accurate landing at a landing site. The aerial drone is further configured to lock onto the second laser beam using a second sensor, to determine a relationship between the first laser beam and the second laser beam, and to utilize the relationship to adjust the tilt of the aerial drone, the orientation of the aerial drone, the speed differential between the aerial drone and the landing site, and/or the alignment of a portion of the drone with a portion of the landing site when making the landing."
Backup Navigation System for Unmanned Aerial Vehicles,https://lens.org/188-213-552-778-134,2019,"Described is a method that involves operating an unmanned aerial vehicle (UAV) to begin a flight, where the UAV relies on a navigation system to navigate to a destination. During the flight, the method involves operating a camera to capture images of the UAV's environment, and analyzing the images to detect features in the environment. The method also involves establishing a correlation between features detected in different images, and using location information from the navigation system to localize a feature detected in different images. Further, the method involves generating a flight log that includes the localized feature. Also, the method involves detecting a failure involving the navigation system, and responsively operating the camera to capture a post-failure image. The method also involves identifying one or more features in the post-failure image, and determining a location of the UAV based on a relationship between an identified feature and a localized feature."
A BACKUP NAVIGATION SYSTEM FOR UNMANNED AERIAL VEHICLES,https://lens.org/016-545-099-072-718,2019,"Described is a method that involves operating an unmanned aerial vehicle (UAV) to begin a flight, where the UAV relies on a navigation system to navigate to a destination. During the flight, the method involves operating a camera to capture images of the UAV's environment, and analyzing the images to detect features in the environment. The method also involves establishing a correlation between features detected in different images, and using location information from the navigation system to localize a feature detected in different images. Further, the method involves generating a flight log that includes the localized feature. Also, the method involves detecting a failure involving the navigation system, and responsively operating the camera to capture a post-failure image. The method also involves identifying one or more features in the post-failure image, and determining a location of the UAV based on a relationship between an identified feature and a localized feature."
Backup navigation system for unmanned aerial vehicles,https://lens.org/112-952-014-084-460,2019,"Described is a method that involves operating an unmanned aerial vehicle (UAV) to begin a flight, where the UAV relies on a navigation system to navigate to a destination. During the flight, the method involves operating a camera to capture images of the UAV's environment, and analyzing the images to detect features in the environment. The method also involves establishing a correlation between features detected in different images, and using location information from the navigation system to localize a feature detected in different images. Further, the method involves generating a flight log that includes the localized feature. Also, the method involves detecting a failure involving the navigation system, and responsively operating the camera to capture a post-failure image. The method also involves identifying one or more features in the post-failure image, and determining a location of the UAV based on a relationship between an identified feature and a localized feature."
Backup Navigation System for Unmanned Aerial Vehicles,https://lens.org/137-978-338-683-083,2023,"Described is a method that involves operating an unmanned aerial vehicle (UAV) to begin a flight, where the UAV relies on a navigation system to navigate to a destination. During the flight, the method involves operating a camera to capture images of the UAV's environment, and analyzing the images to detect features in the environment. The method also involves establishing a correlation between features detected in different images, and using location information from the navigation system to localize a feature detected in different images. Further, the method involves generating a flight log that includes the localized feature. Also, the method involves detecting a failure involving the navigation system, and responsively operating the camera to capture a post-failure image. The method also involves identifying one or more features in the post-failure image, and determining a location of the UAV based on a relationship between an identified feature and a localized feature."
Backup navigation system for unmanned aerial vehicles,https://lens.org/142-759-662-789-681,2021,"Described is a method that involves operating an unmanned aerial vehicle (UAV) to begin a flight, where the UAV relies on a navigation system to navigate to a destination. During the flight, the method involves operating a camera to capture images of the UAV's environment, and analyzing the images to detect features in the environment. The method also involves establishing a correlation between features detected in different images, and using location information from the navigation system to localize a feature detected in different images. Further, the method involves generating a flight log that includes the localized feature. Also, the method involves detecting a failure involving the navigation system, and responsively operating the camera to capture a post-failure image. The method also involves identifying one or more features in the post-failure image, and determining a location of the UAV based on a relationship between an identified feature and a localized feature."
Backup Navigation System for Unmanned Aerial Vehicles,https://lens.org/146-334-181-453-927,2020,"Described is a method that involves operating an unmanned aerial vehicle (UAV) to begin a flight, where the UAV relies on a navigation system to navigate to a destination. During the flight, the method involves operating a camera to capture images of the UAV's environment, and analyzing the images to detect features in the environment. The method also involves establishing a correlation between features detected in different images, and using location information from the navigation system to localize a feature detected in different images. Further, the method involves generating a flight log that includes the localized feature. Also, the method involves detecting a failure involving the navigation system, and responsively operating the camera to capture a post-failure image. The method also involves identifying one or more features in the post-failure image, and determining a location of the UAV based on a relationship between an identified feature and a localized feature."
SECURE ACCESS FOR DRONE PACKAGE DELIVERY,https://lens.org/137-204-762-495-664,2019,"The present invention may receive a plurality of unlock instructions based on determining a location is secured from access by the drone. The present invention may use the plurality of received unlock instructions to access the location with an access device while determining the drone is present at the drop off location. The present invention may use the plurality of received unlock instructions to re-secure the location with the access device when determining successful delivery of a package by the drone, and may monitor a security of the location."
Secure access for drone package delivery,https://lens.org/107-190-094-283-486,2021,"The present invention may receive a plurality of unlock instructions based on determining a location is secured from access by the drone. The present invention may use the plurality of received unlock instructions to access the location with an access device while determining the drone is present at the drop off location. The present invention may use the plurality of received unlock instructions to re-secure the location with the access device when determining successful delivery of a package by the drone, and may monitor a security of the location."
Wireless remotely controlled electronic equipment and the connecting devices for the same,https://lens.org/104-840-535-592-253,2005,"A wireless remotely controlled electronic equipment and its connecting devices is disclosed, it comprises an insulation box to accommodate the electronic equipment therein to protect the electric security, several connecting devices for interconnecting power supply to light load, a receiver unit for receiving wireless command signals from an external transmitter; and a function controller for performing a variety of functions according to the received wireless command signals. With this scheme, when the equipment is energized by an input from the power source, the wireless command signals received by the receiver unit are transmitted to the function controller so that the function controller is actuated to perform predetermined single or a variety of functional operations and output the resultant command signals to the connected light load so as to cause the connected light load to display a variety of blinking effects."
SPEAKER BEAM-STEERING BASED ON MICROPHONE ARRAY AND DEPTH CAMERA ASSEMBLY INPUT,https://lens.org/166-547-075-743-001,2020,"An audio device includes a speaker array and a controller for beam-steering audio output by the speaker array to localize sound in different locations in a local area around the audio device. The audio device also includes a microphone array or a set of cameras configured to detect an object, such as a human, in the local area around the audio device. From data captured by the microphone array or the set of cameras, the audio device determines a location of the object in the local area and steers the audio output by the speaker array towards the determined location of the object. As the object moves within the local area, the audio device dynamically steers the audio output to move along with the object."
Speaker beam-steering based on microphone array and depth camera assembly input,https://lens.org/049-767-511-167-462,2021,"An audio device includes a speaker array and a controller for beam-steering audio output by the speaker array to localize sound in different locations in a local area around the audio device. The audio device also includes a microphone array or a set of cameras configured to detect an object, such as a human, in the local area around the audio device. From data captured by the microphone array or the set of cameras, the audio device determines a location of the object in the local area and steers the audio output by the speaker array towards the determined location of the object. As the object moves within the local area, the audio device dynamically steers the audio output to move along with the object."
VIRTUAL RADAR SYSTEM FOR UNMANNED AERIAL VEHICLES,https://lens.org/032-672-908-425-862,2021,"In various embodiments, a safety system for an unmanned aerial vehicles (UAV) enable the safe operation of the UAV within an airspace by or exampe initiating various actions based on the position of the UAV relative to one or more flight zones and/or relative to other aircraft in the airspace."
"Mobile robot, and system and method for autonomous navigation of the same",https://lens.org/110-442-750-500-087,2004,"The robot has a communications module for transmitting a control signal to selectively control flickering of light sources e.g. LED, of a landmark array in a working space e.g. home. An image processing module calculates image coordinates of one source by detecting the controlled sources. A pose calculation module (503) calculates coordinates of the robot using the coordinates and the previously stored world coordinates of sources. The image processing module detects the light sources from an image signal obtained by a camera. The position coordinates of the robot are applied to previously stored spatial coordinates of the working space to calculate a moving path for the robot. The robot is controlled to move along the path and a main control module controls inter-operations of the modules and general operations of the robot. Independent claims are also included for the following: (a) a system for automatic navigation of a mobile robot; (b) a method for autonomous navigation of a mobile robot."
UNMANNED FOLLOWING VEHICLE,https://lens.org/067-848-456-779-729,2022,"An unmanned following vehicle includes a controller configured to control the unmanned following vehicle to move in parallel with a moving object by following the moving object on a left side or a right side of the moving object, wherein the controller is configured to control the unmanned following vehicle to move in parallel with the moving object by: adjusting a moving speed of the unmanned following vehicle according to a Y-axis coordinate difference value, which is a difference value between a position of the moving object and a position of the unmanned following vehicle in a forward direction, and adjusting a steering direction and a steering angle of the unmanned following vehicle according to an X-axis coordinate difference value, which is a difference value between the position of the moving object and the position of the unmanned following vehicle in a lateral direction."
Systems and method for unmanned aerial painting applications,https://lens.org/145-246-855-713-734,2020,"A UAV includes a body and rotor coupled to the body. The UAV may include a boom coupled to the body, and a nozzle coupled to a distal end of the boom, wherein an operational configuration of the nozzle is responsive to a second control signal. The rotor, boom, and nozzle are arranged such that the nozzle is disposed further away from the body than the rotor. The UAV may further include a sensor disposed on either the body or the boom, wherein the sensor is configured to generate a detection signal associated with a distance between the sensor and a surface disposed proximate to the sensor."
SYSTEMS AND METHOD FOR UNMANNED AERIAL PAINTING APPLICATIONS,https://lens.org/186-081-026-006-658,2018,"A UAV includes a body and rotor coupled to the body. The UAV may include a boom coupled to the body, and a nozzle coupled to a distal end of the boom, wherein an operational configuration of the nozzle is responsive to a second control signal. The rotor, boom, and nozzle are arranged such that the nozzle is disposed further away from the body than the rotor. The UAV may further include a sensor disposed on either the body or the boom, wherein the sensor is configured to generate a detection signal associated with a distance between the sensor and a surface disposed proximate to the sensor."
AGRICULTURAL DRONE HAVING IMPROVED FOOLPROOF,https://lens.org/037-756-041-412-152,2021,"A drone (an aerial vehicle), able to maintain improved safety for operation by non-specialists, is provided. A farm field data stored in a cloud at take-off is compared to an environment data read by a sensor, and a control to prohibit take-off is performed if any danger is considered. In particular, it is desirable to prohibit if there is a traffic, where people and cars may pass, between the farm field and a current location, and if a direction of the drone, installed, does not point to a direction of an intrusion pathway to the target farm field. Furthermore, it is desirable to prohibit take-off if a predetermined maintenance is not performed by referring to a maintenance history."
Plug-and-play multifunctional attachment of remote control rotorcraft,https://lens.org/061-821-219-625-63X,2018,"A plug-and-play multifunctional attachment of a remote control rotorcraft, which includes: an attachment body that includes a device board and a remote control receiver unit. The device board has a top surface to which a first coupling member is mounted. The remote control receiver unit is mounted to and electrically connected to a bottom surface of the device board. Wireless transmission of a signal is enabled between a remote control device and the remote control receiver unit. A second coupling member is mounted to a bottom of an unmanned aircraft to enable selective engagement and coupling between the second coupling member and the first coupling member."
ROOF REPAIR DRONE,https://lens.org/185-444-183-631-40X,2020,"The invention concerns an aerial drone for repairing holes or punctures in a membrane on a roof, characterized in that the aerial drone comprises at least one camera for recording a section of the membrane, an applicator adapted to apply material onto the section of the membrane, wherein the applicator is controllable wirelessly from a different altitude and/or the ground."
UNMANNED AERIAL VEHICLE AND STATION,https://lens.org/176-821-227-866-556,2021,"According to an embodiment of the present invention, an unmanned aerial vehicle (UAV) may recognize at least some of light output from light sources of a station, and determine a current location based on the recognized light. At least one of the unmanned aerial vehicle and the station according to an embodiment of the present invention may be linked to an Artificial Intelligence module, a robot, a device related to a 5G service, and the like."
Auxiliary communication system for radio controlled robots,https://lens.org/122-191-903-980-299,2012,"A system for providing autonomous capabilities to a radio-controlled robot, comprises two communication boxes, one connected to the robot and the other connected to an operator control unit (OCU). Each communication box comprises two radios that are interoperable with preexisting data radios in the robot; a microprocessor unit; and bidirectional attenuators. The system further comprises a software application that runs on the microprocessor unit of each communications box, to integrate data into existing transmission data stream between the robot and OCU, via preexisting data radios. The system enables the issuance of additional commands besides those issued by the OCU, using the original OCU."
AUTONOMOUS MULTI-ROTOR AIRPLANE,https://lens.org/076-851-889-928-527,2021,"An autonomous multi-rotor airplane comprises a body frame with a chamber. The chamber is configured to provide space for one or more skydivers or jumpers, a lifting platform having an onboard computer and an avionic system. The airplane comprises one or more propulsion systems operably coupled to the lifting platform. The airplane is configured to find and execute the optimal flight path based on given information by the operator. The airplane comprises one or more user interfaces securely positioned inside the chamber. The user interfaces are configured to enable the skydiver to view the location and the optimal flight path, and adjust the angle of the autonomous multi-rotor airplane against the wind direction. The user interface is configured to enable the skydiver to operate and land the autonomous multi-rotor airplane at a landing zone."
Animated character system with real-time control,https://lens.org/180-272-315-332-998,1994,"A system includes a control station for remotely controlling an animated character. Radio frequencies are used to transfer audio, video and other control signals to the animated character to provide speech, hearing, vision and practically any movement in real-time. A camera is used in the head of the animated character, and microphones are used in its ears to provide vision and hearing to a monitoring operator at the control station. A speaker is co-located with the animated character to generate sound from the operator. Servo control units are included within the animated character to provide a plurality of body movements. Other aspects of the animated character includes a multi-layer skin composite to make it appear more life-like, and an audio driver circuit for controlling the mouth of the animated character in proportion to the level of an audio signal generated at the control station."
Animated character system with real-time contol,https://lens.org/171-920-057-990-053,1992,"A system includes a control station for remotely controlling an animated character. Radio frequencies are used to transfer audio, video and other control signals to the animated character to provide speech, hearing, vision and practically any movement in real-time. A camera is used in the head of the animated character, and microphones are used in its ears to provide vision and hearing to a monitoring operator at the control station. A speaker is co-located with the animated character to generate sound from the operator. Servo control units are included within the animated character to provide a plurality of body movements. Other aspects of the animated character includes a multi-layer skin composite to make it appear more life-like, and an audio driver circuit for controlling the mouth of the animated character in proportion to the level of an audio signal generated at the control station."
Animated character system with real-time control,https://lens.org/034-952-372-369-004,1991,"A system includes a control station for remotely controlling an animated character. Radio frequencies are used to transfer audio, video and other control signals to the animated character to provide speech, hearing, vision and practically any movement in real-time. A camera is used in the head of the animated character, and microphones are used in its ears to provide vision and hearing to a monitoring operator at the control station. A speaker is co-located with the animated character to generate sound from the operator. Servo control units are included within the animated character to provide a plurality of body movements. Other aspects of the animated character includes a multi-layer skin composite to make it appear more life-like, and an audio driver circuit for controlling the mouth of the animated character in proportion to the level of an audio signal generated at the control station."
"FLYING DRONE FOR INSPECTING SURFACES, AND METHOD FOR INSPECTING SURFACES BY SUCH A FLYING DRONE",https://lens.org/126-048-796-615-838,2022,"A flying drone for inspecting surfaces able to reflect light has a lighting device formed of two light sources each having a shape that is elongate in a longitudinal direction of each of the light sources, two first image acquisition devices, and a second image acquisition device between the two first image acquisition devices. The two light sources are respectively between the second image acquisition device and each of the first image acquisition devices. The flying drone allows effective detection of dents in surfaces by analyzing specular reflections, by the lighting device and of the first image acquisition devices, and effective detection of superficial defects on surfaces by the second image acquisition device, with the lighting device switched off."
"FLYING DRONE FOR INSPECTING SURFACES, AND METHOD FOR INSPECTING SURFACES BY SUCH A FLYING DRONE",https://lens.org/126-048-796-615-838,2022,"A flying drone for inspecting surfaces able to reflect light has a lighting device formed of two light sources each having a shape that is elongate in a longitudinal direction of each of the light sources, two first image acquisition devices, and a second image acquisition device between the two first image acquisition devices. The two light sources are respectively between the second image acquisition device and each of the first image acquisition devices. The flying drone allows effective detection of dents in surfaces by analyzing specular reflections, by the lighting device and of the first image acquisition devices, and effective detection of superficial defects on surfaces by the second image acquisition device, with the lighting device switched off."
AUTOMATIC RELOCATION OF A VEHICLE BASED ON PROXIMITY,https://lens.org/033-105-980-822-585,2020,"A method, computer system, and computer program product for using a radio frequency trigger to move an unmanned aerial vehicle from an incoming vehicle path are provided. The embodiment may include receiving, by a processor, a radio frequency signal transmitted from a vehicle or an emergency response center. The embodiment may also include determining whether an unmanned aerial vehicle is in flight within a pre-configured threshold radius from the first responder vehicle or emergency response center. The embodiment may further include in response to determining the unmanned aerial vehicle is within the pre-configured radius, activating a return home function. The embodiment may also include commanding the unmanned aerial vehicle to fly out of the threshold radius."
Automatic relocation of a vehicle based on proximity,https://lens.org/080-436-828-097-869,2021,"A method, computer system, and computer program product for using a radio frequency trigger to move an unmanned aerial vehicle from an incoming vehicle path are provided. The embodiment may include receiving, by a processor, a radio frequency signal transmitted from a vehicle or an emergency response center. The embodiment may also include determining whether an unmanned aerial vehicle is in flight within a pre-configured threshold radius from the first responder vehicle or emergency response center. The embodiment may further include in response to determining the unmanned aerial vehicle is within the pre-configured radius, activating a return home function. The embodiment may also include commanding the unmanned aerial vehicle to fly out of the threshold radius."
Remotely-controlled emergency aerial vehicle,https://lens.org/018-856-369-856-186,2015,"Devices, systems and methods for utilizing a remotely-controlled aerial vehicle for emergency situations are disclosed. In an aspect of the present disclosure, a remotely-controlled aerial vehicle consisting of a rotor with interchangeably attached blades, a camera, an antenna for transmitting data, and rescue equipment which may be used to assist an endangered person on location is disclosed. In another aspect, the aerial vehicle further comprises a light source to assist in the use of the device at night, a pressure gun to assist in the delivery of rope or other materials in mountain side situations, an explosive device dropping mechanism, and a cable hoist."
Remotely-Controlled Emergency Aerial Vehicle,https://lens.org/057-948-649-371-40X,2014,"Devices, systems and methods for utilizing a remotely-controlled aerial vehicle for emergency situations are disclosed. In an aspect of the present disclosure, a remotely-controlled aerial vehicle consisting of a rotor with interchangeably attached blades, a camera, an antenna for transmitting data, and rescue equipment which may be used to assist an endangered person on location is disclosed. In another aspect, the aerial vehicle further comprises a light source to assist in the use of the device at night, a pressure gun to assist in the delivery of rope or other materials in mountain side situations, an explosive device dropping mechanism, and a cable hoist."
CONTROLLING ELECTRONIC DEVICES BY AERIAL VEHICLES,https://lens.org/131-421-544-071-057,2023,"An electronic device comprises a sensor arrangement, a control system operable to obtain sensor data from the sensor arrangement, and a microphone configured to provide an audio signal representing sound waves received by the microphone. The control system processes (102) the audio signal for detection of an audio characteristic feature, ACF, representing an operating parameter of a propulsion system in an aerial vehicle, and, upon said detection, performs (104) a dedicated action related to the sensor data. The dedicated action may comprise obtaining and/or transmitting at least part of the sensor data. To control the electronic device, the aerial vehicle is configured to, intermittently while on a flight path, cause its propulsion system (22) to impart a predefined and audible modification of an operating parameter of the propulsion system (22) to thereby generate sound waves that include the ACF."
CONTROLLING ELECTRONIC DEVICES BY AERIAL VEHICLES,https://lens.org/131-421-544-071-057,2023,"An electronic device comprises a sensor arrangement, a control system operable to obtain sensor data from the sensor arrangement, and a microphone configured to provide an audio signal representing sound waves received by the microphone. The control system processes (102) the audio signal for detection of an audio characteristic feature, ACF, representing an operating parameter of a propulsion system in an aerial vehicle, and, upon said detection, performs (104) a dedicated action related to the sensor data. The dedicated action may comprise obtaining and/or transmitting at least part of the sensor data. To control the electronic device, the aerial vehicle is configured to, intermittently while on a flight path, cause its propulsion system (22) to impart a predefined and audible modification of an operating parameter of the propulsion system (22) to thereby generate sound waves that include the ACF."
Unmanned aerial vehicle including an omnidirectional depth sensing and obstacle avoidance aerial system and method of operating same,https://lens.org/147-842-625-792-653,2021,"An unmanned aerial vehicle is described herein. The unmanned aerial vehicle includes a fuselage body, a lift mechanism coupled to the fuselage body, and a depth sensing and obstacle avoidance system coupled to the fuselage body. The depth sensing and obstacle avoidance system includes a platform assembly, a pair of stereovision cameras coupled to a platform assembly, and a motor assembly coupled to the fuselage body and to the platform assembly. The platform assembly includes a support member extending between a first end and an opposite second end along a longitudinal axis. The pair of stereovision cameras includes each stereovision camera positioned at an opposite end of the support member. The motor assembly is configured to rotate the platform assembly with respect to the fuselage body about a rotational axis perpendicular to the longitudinal axis of the platform assembly."
DRONE-BASED RADIO-OVER-FIBER SYSTEM,https://lens.org/143-595-933-336-704,2021,"The drone-based radio-over-fiber system provides an unmanned aerial vehicle (AV), preferably a multi-rotor drone, connected to a base station by a tether including an optical fiber. A radio frequency-over-fiber system is used for bidirectional data communications between at least one radio frequency (RF) transmitter at the base station and at least one antenna mounted on the drone through the optical fiber in the tether. The system includes wave division multiplexers/demultiplexers that permit ultrahigh bandwidth communication over the tether. An embodiment of the system for 2x2 multiple- input, multiple-output (MIMO) signals in the 700 MHz LTE band is described."
Enhanced remote control of autonomous vehicles,https://lens.org/100-508-798-345-369,2023,"Devices, systems, and methods for remote control of autonomous vehicles are disclosed herein. A method may include receiving, by a device, first data indicative of an autonomous vehicle in a parking area, and determining, based on the first data, a location of the autonomous vehicle. The method may include determining, based on a the location, first image data including a representation of an object. The method may include generating second image data based on the first data and the first image data, and presenting the second image data. The method may include receiving an input associated with controlling operation of the autonomous vehicle, and controlling, based on the input, the operation of the autonomous vehicle."
ENHANCED REMOTE CONTROL OF AUTONOMOUS VEHICLES,https://lens.org/080-769-043-221-941,2022,"Devices, systems, and methods for remote control of autonomous vehicles are disclosed herein. A method may include receiving, by a device, first data indicative of an autonomous vehicle in a parking area, and determining, based on the first data, a location of the autonomous vehicle. The method may include determining, based on a the location, first image data including a representation of an object. The method may include generating second image data based on the first data and the first image data, and presenting the second image data. The method may include receiving an input associated with controlling operation of the autonomous vehicle, and controlling, based on the input, the operation of the autonomous vehicle."
ENHANCED REMOTE CONTROL OF AUTONOMOUS VEHICLES,https://lens.org/080-769-043-221-941,2022,"Devices, systems, and methods for remote control of autonomous vehicles are disclosed herein. A method may include receiving, by a device, first data indicative of an autonomous vehicle in a parking area, and determining, based on the first data, a location of the autonomous vehicle. The method may include determining, based on a the location, first image data including a representation of an object. The method may include generating second image data based on the first data and the first image data, and presenting the second image data. The method may include receiving an input associated with controlling operation of the autonomous vehicle, and controlling, based on the input, the operation of the autonomous vehicle."
Systems and Methods for Restricting Drone Airspace Access,https://lens.org/082-016-240-181-99X,2016,"Methods, systems and devices are disclosed for providing access to a restricted area for a drone by a beacon device. Beacon signals including access information associated with access for the restricted area may be transmitted by the beacon device. The beacon device may receive one or more access parameters for the drone. The beacon device may compare the received one or more access parameters for the drone to the access information for the restricted area. The beacon device may determine clearance for the drone to access the restricted area based on comparing the one or more access parameter for the drone and the access information."
Systems and methods for restricting drone airspace access,https://lens.org/051-723-534-721-814,2017,"Methods, systems and devices are disclosed for providing access to a restricted area for a drone by a beacon device. Beacon signals including access information associated with access for the restricted area may be transmitted by the beacon device. The beacon device may receive one or more access parameters for the drone. The beacon device may compare the received one or more access parameters for the drone to the access information for the restricted area. The beacon device may determine clearance for the drone to access the restricted area based on comparing the one or more access parameter for the drone and the access information."
Trashcan system and method of use,https://lens.org/142-082-409-337-495,2022,A trashcan system includes a body forming an interior cavity; a lid engaged with the body to enclose the interior cavity; a control system secured to the body and having a speaker; the control system is to wirelessly communicate with a smart device; the control system activates playing of audio from the smart device through the speaker when the smart device is within a predetermined distance from the control system.
IMAGE STABILIZATION AND POINTING CONTROL MECHANIZATION FOR AIRCRAFT IMAGING SYSTEMS,https://lens.org/100-126-706-001-785,2018,"An imaging device can be mounted on a vehicle and used to capture images. The imaging device can include a camera assembly rotatable relative to a platform of the vehicle and about two or three camera axes. The camera assembly can include a camera and a mirror attached to the camera. The mirror can be rotatable relative to the camera and about one or two mirror axes, different from the camera axes. Users can provide input to controllers that operate the vehicle, the camera, and the mirror to control both flight and the line-of-sight of the camera. The controllers combine separate inputs as well as measured conditions, such as inertial angles, to coordinate control of vehicle, camera, and mirror parameters, such as yaw adjustments to both the camera and the mirror to achieve a desired line-of-sight."
Image stabilization and pointing control mechanization for aircraft imaging systems,https://lens.org/153-350-220-575-26X,2019,"An imaging device can be mounted on a vehicle and used to capture images. The imaging device can include a camera assembly rotatable relative to a platform of the vehicle and about two or three camera axes. The camera assembly can include a camera and a mirror attached to the camera. The mirror can be rotatable relative to the camera and about one or two mirror axes, different from the camera axes. Users can provide input to controllers that operate the vehicle, the camera, and the mirror to control both flight and the line-of-sight of the camera. The controllers combine separate inputs as well as measured conditions, such as inertial angles, to coordinate control of vehicle, camera, and mirror parameters, such as yaw adjustments to both the camera and the mirror to achieve a desired line-of-sight."
UNMANNED AERIAL VEHICLE CONTROL SYSTEM,https://lens.org/080-595-570-246-879,2017,"An unmanned aerial vehicle control (UAV) system capable of switching between a point-to-point radio frequency connection and a cellular data network connection is provided. The UAV system includes a base unit controller and a UAV. The UAV includes a processing unit, an autopilot, and a signal strength determining apparatus. The signal strength determining apparatus estimates the signal strength between the UAV and the base unit controller, and the signal strength between the UAV and the cellular data network."
INTEGRATED ENCLOSURE AND CONTROLLER FOR VIDEO SURVEILLANCE CAMERA,https://lens.org/110-830-365-910-797,2009,"A controller for a video surveillance camera enclosure including a method an d apparatus for controlling a stepper motor by decoding a command for a specific camera action, setting the state of a state machine, and instructing a position control process and a speed control process based upon the state of the state machine. A drive signal is sent from said position control process to a motor current process and a phase control process to generate the current and phase signals to control the stepper motor. The stepper motor drive current is preferably a non-linear current. The speed control signal includes ramp up and ramp down speed control for gradually increasing motor speed and gradual ly decreasing motor speed, respectively. Another aspect of the invention detect s a plurality of pan and/or tilt positions to reset the pan and/or tilt motor step count t o a known count associated with a known location without the need to pan and/or tilt past a preselected home position. Another aspect controls a dome enclosure heater to operate ov er two different thermostat ranges to provide for manual de-fogging of the dome bubble."
INTEGRATED ENCLOSURE AND CONTROLLER FOR VIDEO SURVEILLANCE CAMERA,https://lens.org/032-053-434-309-700,2002,"A controller for a video surveillance camera enclosure including a method an d apparatus for controlling a stepper motor by decoding a command for a specific camera action, setting the state of a state machine, and instructing a position control process and a speed control process based upon the state of the state machine. A drive signal is sent from said position control process to a motor current process and a phase control process to generate the current and phase signals to control the stepper motor. The stepper motor drive current is preferably a non-linear current. The speed control signal includes ramp up and ramp down speed control for gradually increasing motor speed and gradual ly decreasing motor speed, respectively. Another aspect of the invention detect s a plurality of pan and/or tilt positions to reset the pan and/or tilt motor step count t o a known count associated with a known location without the need to pan and/or tilt past a preselected home position. Another aspect controls a dome enclosure heater to operate ov er two different thermostat ranges to provide for manual de-fogging of the dome bubble."
Aerial video camera system,https://lens.org/101-871-180-025-593,2004,"An aerial video camera (1, 11) has control communication from a universal-control computer (2) and a vibration damper (6, 7, 8). The camera is rotatable circumferentially and tiltable inside of a hemispherical radome (10) that is suspended from a camera pod (9) which is attached to a wing-strut bolt (14) of an aircraft (3) with preferably an attachment bracket (13). Pan and tilt site of the camera are communicated electronically to a monitor (12) of the universal-control computer having a joystick control (20)."
SYSTEMS AND METHODS FOR THE AUTONOMOUS CONTROLLING AND MARSHALLING OF AUTONMOUS-ENABLED FLYING OBJECTS AND TRANSPORTATION OBJECTS,https://lens.org/194-927-457-709-474,2019,"The subject matter disclosed apparatuses, systems and methods for the autonomous controlling and marshalling of autonomous-enabled flying objects and autonomous-enabled transportation objects. The system includes a POD with plurality of enlarged rods parallel to each other to support a flying object. The system includes an apparatus with a camera for identifying of an at payload entering or leaving a flying object and a processor for detecting and reporting to a computing device a payload mismatch and payload manifest for pilot authorization. The system includes calculation and monitoring of restricted areas for flying objects to avoid according to the restrictions. The system calculates refueling or recharging stops for a planned route of a flying object, methods for approving routes, for scheduling docking and for operating a POD, for generating routes, for generating or canceling restricted areas, controlling the operation of transportation objects, updating routes, generating or amending guaranteed and unguaranteed routes."
"APPARATUSES, SYSTEMS AND METHODS FOR THE AUTONOMOUS CONTROLLING AND MARSHALLING OF AUTONMOUS-ENABLED FLYING OBJECTS AND AUTONMOUS-ENABLED TRANSPORTATION OBJECTS",https://lens.org/055-306-673-915-609,2019,"The subject matter disclosed apparatuses, systems and methods for the autonomous controlling and marshalling of autonomous-enabled flying objects and autonomous-enabled transportation objects. The system includes a POD with plurality of enlarged rods parallel to each other to support a flying object. The system includes an apparatus with a camera for identifying of an at payload entering or leaving a flying object and a processor for detecting and reporting to a computing device a payload mismatch and payload manifest for pilot authorization. The system includes calculation and monitoring of restricted areas for flying objects to avoid according to the restrictions. The system calculates refueling or recharging stops for a planned route of a flying object, methods for approving routes, for scheduling docking and for operating a POD, for generating routes, for generating or canceling restricted areas, controlling the operation of transportation objects, updating routes, generating or amending guaranteed and unguaranteed routes."
"Method and apparatus for controlling a crane, an excavator, a crawler-type vehicle or a similar construction machine",https://lens.org/148-753-693-255-923,2023,"The present invention generally relates to the control of material transfer machines and/or construction machines having camera assistance. The invention here in particular relates to a method and to an apparatus for controlling a material transfer machine and/or a construction machine, in particular in the form of a crane, of an excavator, or of a crawler-type vehicle, wherein an image of the piece of working equipment is provided to a machine operator and/or to a machine control by an imaging sensor. The invention furthermore also relates to the material transfer machine and/or construction machine itself, in particular to a crane, having a display apparatus for displaying an image of the piece of working equipment and/or of the environment of the piece of working equipment. It is proposed to use a remote-controlled aerial drone which is equipped with at least one imaging sensor and by means of which the desired image of the piece of working equipment and/or of the equipment environment can be provided from different directions of view."
"METHOD AND APPARATUS FOR CONTROLLING A CRANE, AN EXCAVATOR, A CRAWLER-TYPE VEHICLE OR A SIMILAR CONSTRUCTION MACHINE",https://lens.org/122-898-292-844-245,2019,"The present invention generally relates to the control of material transfer machines and/or construction machines having camera assistance. The invention here in particular relates to a method and to an apparatus for controlling a material transfer machine and/or a construction machine, in particular in the form of a crane, of an excavator, or of a crawler-type vehicle, wherein an image of the piece of working equipment is provided to a machine operator and/or to a machine control by an imaging sensor. The invention furthermore also relates to the material transfer machine and/or construction machine itself, in particular to a crane, having a display apparatus for displaying an image of the piece of working equipment and/or of the environment of the piece of working equipment. It is proposed to use a remote-controlled aerial drone which is equipped with at least one imaging sensor and by means of which the desired image of the piece of working equipment and/or of the equipment environment can be provided from different directions of view."
UAV NAVIGATION AND SENSOR SYSTEM CONFIGURATION,https://lens.org/150-680-118-901-738,2016,"Systems, methods and devices for use with unmanned aerial vehicles (UAV). A central controller is coupled to the autopilot system for a UAV. Navigation is implemented by using two GPS antennas and obtaining a difference between the locations from these two antenna to arrive at a high precision bearing or direction of travel. This single GPS derived bearing is used to trigger all the various subsystems on the UAV for imaging or mapping. Areas and locations to be mapped and imaged are determined by geolocation and mapping and imaging equipment are triggered based on the single GPS signal derived from the two GPS antennas. To reduce vibration effects on navigational and imaging or mapping equipment, these are positioned as close as possible to the vehicle's center of gravity and are deployed in a shielded box on vibration isolation mounts."
UAV NAVIGATION AND SENSOR SYSTEM CONFIGURATION,https://lens.org/132-991-441-278-996,2018,"Systems, methods and devices for use with unmanned aerial vehicles (UAV). A central controller is coupled to the autopilot system for a UAV. Navigation is implemented by using two GPS antennas and obtaining a difference between the locations from these two antenna to arrive at a high precision bearing or direction of travel. This single GPS derived bearing is used to trigger all the various subsystems on the UAV for imaging or mapping. Areas and locations to be mapped and imaged are determined by geolocation and mapping and imaging equipment are triggered based on the single GPS signal derived from the two GPS antennas. To reduce vibration effects on navigational and imaging or mapping equipment, these are positioned as close as possible to the vehicle's center of gravity and are deployed in a shielded box on vibration isolation mounts."
Altering audio to improve automatic speech recognition,https://lens.org/141-378-501-419-430,2022,"Techniques for altering audio being output by a voice-controlled device, or another device, to enable more accurate automatic speech recognition (ASR) by the voice-controlled device. For instance, a voice-controlled device may output audio within an environment using a speaker of the device. While outputting the audio, a microphone of the device may capture sound within the environment and may generate an audio signal based on the captured sound. The device may then analyze the audio signal to identify speech of a user within the signal, with the speech indicating that the user is going to provide a subsequent command to the device. Thereafter, the device may alter the output of the audio (e.g., attenuate the audio, pause the audio, switch from stereo to mono, etc.) to facilitate speech recognition of the user's subsequent command."
Altering audio to improve automatic speech recognition,https://lens.org/189-416-887-133-756,2018,"Techniques for altering audio being output by a voice-controlled device, or another device, to enable more accurate automatic speech recognition (ASR) by the voice-controlled device. For instance, a voice-controlled device may output audio within an environment using a speaker of the device. While outputting the audio, a microphone of the device may capture sound within the environment and may generate an audio signal based on the captured sound. The device may then analyze the audio signal to identify speech of a user within the signal, with the speech indicating that the user is going to provide a subsequent command to the device. Thereafter, the device may alter the output of the audio (e.g., attenuate the audio, pause the audio, switch from stereo to mono, etc.) to facilitate speech recognition of the user's subsequent command."
Altering Audio to Improve Automatic Speech Recognition,https://lens.org/197-578-782-090-851,2018,"Techniques for altering audio being output by a voice-controlled device, or another device, to enable more accurate automatic speech recognition (ASR) by the voice-controlled device. For instance, a voice-controlled device may output audio within an environment using a speaker of the device. While outputting the audio, a microphone of the device may capture sound within the environment and may generate an audio signal based on the captured sound. The device may then analyze the audio signal to identify speech of a user within the signal, with the speech indicating that the user is going to provide a subsequent command to the device. Thereafter, the device may alter the output of the audio (e.g., attenuate the audio, pause the audio, switch from stereo to mono, etc.) to facilitate speech recognition of the user's subsequent command."
Altering audio to improve automatic speech recognition,https://lens.org/012-006-033-904-448,2019,"Techniques for altering audio being output by a voice-controlled device, or another device, to enable more accurate automatic speech recognition (ASR) by the voice-controlled device. For instance, a voice-controlled device may output audio within an environment using a speaker of the device. While outputting the audio, a microphone of the device may capture sound within the environment and may generate an audio signal based on the captured sound. The device may then analyze the audio signal to identify speech of a user within the signal, with the speech indicating that the user is going to provide a subsequent command to the device. Thereafter, the device may alter the output of the audio (e.g., attenuate the audio, pause the audio, switch from stereo to mono, etc.) to facilitate speech recognition of the user's subsequent command."
Altering audio to improve automatic speech recognition,https://lens.org/121-964-432-745-131,2016,"Techniques for altering audio being output by a voice-controlled device, or another device, to enable more accurate automatic speech recognition (ASR) by the voice-controlled device. For instance, a voice-controlled device may output audio within an environment using a speaker of the device. While outputting the audio, a microphone of the device may capture sound within the environment and may generate an audio signal based on the captured sound. The device may then analyze the audio signal to identify speech of a user within the signal, with the speech indicating that the user is going to provide a subsequent command to the device. Thereafter, the device may alter the output of the audio (e.g., attenuate the audio, pause the audio, switch from stereo to mono, etc.) to facilitate speech recognition of the user's subsequent command."
Altering audio to improve automatic speech recognition,https://lens.org/141-378-501-419-430,2022,"Techniques for altering audio being output by a voice-controlled device, or another device, to enable more accurate automatic speech recognition (ASR) by the voice-controlled device. For instance, a voice-controlled device may output audio within an environment using a speaker of the device. While outputting the audio, a microphone of the device may capture sound within the environment and may generate an audio signal based on the captured sound. The device may then analyze the audio signal to identify speech of a user within the signal, with the speech indicating that the user is going to provide a subsequent command to the device. Thereafter, the device may alter the output of the audio (e.g., attenuate the audio, pause the audio, switch from stereo to mono, etc.) to facilitate speech recognition of the user's subsequent command."
UNMANNED AERIAL VEHICLE IDENTITY AND CAPABILITY VERIFICATION,https://lens.org/083-822-467-523-731,2016,"A device receives a request for a flight path for a UAV from a first location to a second location, credentials for the UAV, and component information for the UAV. The device determines, based on the credentials, whether the UAV is authenticated for utilizing the device and a network, and determines whether the UAV is capable of flight based on the component information and maintenance information. The device calculates, the flight path based on capability information for the UAV and/or other information, and determines whether the UAV is capable of traversing the flight path based on the capability information and/or the other information. The device generates flight path instructions for the flight path, and provides the flight path instructions to the UAV to permit the UAV to travel from the first location to the second location via the flight path."
Unmanned aerial vehicle identity and capability verification,https://lens.org/138-061-629-413-341,2017,"A device receives a request for a flight path for a UAV from a first location to a second location, credentials for the UAV, and component information for the UAV. The device determines, based on the credentials, whether the UAV is authenticated for utilizing the device and a network, and determines whether the UAV is capable of flight based on the component information and maintenance information. The device calculates, the flight path based on capability information for the UAV and/or other information, and determines whether the UAV is capable of traversing the flight path based on the capability information and/or the other information. The device generates flight path instructions for the flight path, and provides the flight path instructions to the UAV to permit the UAV to travel from the first location to the second location via the flight path."
Unmanned aerial vehicle which fetches objects automatically and method thereof,https://lens.org/131-246-860-192-648,2018,An unmanned aerial vehicle which fetches objects automatically and a method thereof is disclosed. The unmanned aerial vehicle is adopted to fetch objects at different altitudes. The method of fetching objects by the unmanned aerial vehicle comprises the following steps: capturing position information and identity information of the objects; determining a destination and planning a flight route; flying the unmanned aerial vehicle to the destination along the flight route; identifying and collecting a pre-set identity information on surfaces of the objects at the destination; matching the pre-set identity information with a captured identity information; targeting an object the pre-set identity information of which coincides with the captured identity; and controlling a mechanical paw settled on the unmanned aerial vehicle; capturing the object; delivering the object to a pre-set position. The present invention is able to replace human and walking robot.
Systems and methods for flight simulation,https://lens.org/176-179-030-884-202,2022,"A method includes receiving, at a display device, simulated flight data from a flight control system on-board an unmanned aerial vehicle (UAV) when the UAV is in a simulation mode; and displaying, on a visual display of the display device, simulated flight state information of the UAV in response to the simulated flight data. The display device is configured to display real flight data when the UAV is in a flight mode."
SYSTEMS AND METHODS FOR FLIGHT SIMULATION,https://lens.org/138-561-487-954-628,2019,"A method includes receiving, at a display device, simulated flight data from a flight control system on-board an unmanned aerial vehicle (UAV) when the UAV is in a simulation mode; and displaying, on a visual display of the display device, simulated flight state information of the UAV in response to the simulated flight data. The display device is configured to display real flight data when the UAV is in a flight mode."
SENSOR AND AUTONOMOUS VEHICLE,https://lens.org/135-976-781-271-022,2020,"An autonomous vehicle having a sensor and a sensor having a plurality of light transmitters and a plurality of light receivers that are arranged in a common housing, with the optical axes of the light transmitters and light receivers being arranged in parallel or in fan form in different angle directions having angular intervals, whereby a protected field is formed, and having a control and evaluation unit for monitoring and evaluating the protected field, wherein a camera is connected to the control and evaluation unit, with camera images of the camera being evaluated by the control and evaluation unit."
Sensor and autonomous vehicle,https://lens.org/079-819-417-620-216,2022,"An autonomous vehicle having a sensor and a sensor having a plurality of light transmitters and a plurality of light receivers that are arranged in a common housing, with the optical axes of the light transmitters and light receivers being arranged in parallel or in fan form in different angle directions having angular intervals, whereby a protected field is formed, and having a control and evaluation unit for monitoring and evaluating the protected field, wherein a camera is connected to the control and evaluation unit, with camera images of the camera being evaluated by the control and evaluation unit."
Sensor and autonomous vehicle,https://lens.org/079-819-417-620-216,2022,"An autonomous vehicle having a sensor and a sensor having a plurality of light transmitters and a plurality of light receivers that are arranged in a common housing, with the optical axes of the light transmitters and light receivers being arranged in parallel or in fan form in different angle directions having angular intervals, whereby a protected field is formed, and having a control and evaluation unit for monitoring and evaluating the protected field, wherein a camera is connected to the control and evaluation unit, with camera images of the camera being evaluated by the control and evaluation unit."
SYSTEM AND METHOD FOR DRONE DOCKING,https://lens.org/143-300-591-501-675,2021,"A system and a method for drone docking are provided. The method includes: setting a moving platform on a vehicle; obtaining, by the moving platform, current environmental data and historical environmental data corresponding to the moving platform; generating, by the moving platform, a recommended flight parameter according to the current environmental data and the historical environmental data, and transmitting the recommended flight parameter to a drone; and adjusting, by the drone, a flight parameter of the drone according to the recommended flight parameter to dock on the moving platform."
Autonomous vehicle and controlling method for autonomous vehicle,https://lens.org/054-003-479-589-323,1999,An autonomous vehicle has a distance measuring sensor that periodically measures the distance to an object using a prescribed period and it's movement is controlled in accordance with the distance measured by the distance measuring sensor. A controller that controls the prescribed period based on the moving speed and the measured distance so that the prescribed period is made shorter as the moving speed increases and the distance to the object becomes shorter.
FLIGHT CONTROL SYSTEM FOR UNMANNED AERIAL VEHICLE AND TOPOGRAPHY MEASURING SYSTEM,https://lens.org/194-919-223-139-026,2020,"A flight control system for an unmanned aerial vehicle comprises an unmanned aerial vehicle on which a reflector is mounted and a total station for tracking the reflector and for acquiring measurement data including three-dimensional coordinates of the reflector,wherein the total station comprises a tracking module for tracking the reflector, a data transmitting module having an optical axis parallel or approximately parallel to a tracking optical axis of the tracking module and for emitting a data transmitting light, and a TS-arithmetic control module, wherein the unmanned aerial vehicle has a photodetector for receiving the data transmitting light and for emitting a photodetecting signal and a UAV-arithmetic control module for controlling a flight of the unmanned aerial vehicle, and wherein the TS-arithmetic controlmodule is configured to superimpose the measurement data on the data transmitting light, and the UAV-arithmetic control module is configured to separate the measurement data from the photodetecting signal and obtains a flight position of the unmanned aerial vehicle in real time."
SMART SURVEILLANCE SYSTEM AND SMART SURVEILLANCE CONTROL METHOD USING UAV,https://lens.org/156-558-634-739-561,2023,"Provided is a smart surveillance system that includes one unmanned aerial vehicle (UAV), a plurality of Internet of Things (IoT) terminals distributed in a surveillance area, and a plurality of base stations distributed in the surveillance area, wherein the UAV selects any IoT terminal from among the plurality of IoT terminals using deep learning auction training, receives surveillance data from the selected IoT terminal, and transmits the surveillance data to a data center through the Internet and any one base station among the plurality of base stations."
AUV BASED SEISMIC ACQUISITION SYSTEM AND METHOD,https://lens.org/049-283-370-440-494,2016,An autonomous underwater vehicle (AUV) for guiding other AUVs during a marine seismic survey. The guiding AUV (200) includes a housing (202); a propulsion system (903) located inside the housing (202); and an acoustic positioning system (204) attached to an outside the housing (202). The acoustic positioning system (204) emits at least three chirps from three different locations.
DRONE CONTROLLING DEVICE AND METHOD,https://lens.org/109-176-612-545-514,2016,"In embodiments, apparatuses, methods and storage media (transitory and non-transitory) are described that receive sensor data from one or more sensor devices that depict a user gesture in three dimensional space, determine a flight path based at least in part on the sensor data, and store the flight path in memory for use to control operation of a drone. Other embodiments may be described and/or claimed."
Drone controlling device and method,https://lens.org/160-055-899-119-659,2019,"In embodiments, apparatuses, methods and storage media (transitory and non-transitory) are described that receive sensor data from one or more sensor devices that depict a user gesture in three dimensional space, determine a flight path based at least in part on the sensor data, and store the flight path in memory for use to control operation of a drone. Other embodiments may be described and/or claimed."
Multi-sensor environmental mapping,https://lens.org/142-281-263-286-26X,2021,"A method for controlling an unmanned aerial vehicle (UAV) includes receiving first sensor data relative to a first coordinate system and second sensor data relative to a second coordinate system from a first sensor and a second sensor, respectively. The first and second sensor data includes first and second obstacle occupancy information indicative of relative locations of a first and a second sets of obstacles in reference to the UAV in the first and second coordinate systems, respectively. The first and second sets of obstacles have at least a subset of obstacles in common. The method further includes converting the first and second sensor data into a single coordinate system using sensor calibration data to generate an obstacle occupancy grid map based on the first and second obstacle occupancy information, and effecting the UAV to navigate using the obstacle occupancy grid map to perform obstacle avoidance."
ACOUSTIC MONITORING SYSTEM,https://lens.org/057-420-353-808-670,2019,"Systems and methods for monitoring a monitored space include producing a first audio signal from received acoustic energy. The first audio signal is then processed against a whitelist of acoustic profiles and, based on lack of substantial correspondence with any of the acoustic profiles, a drone is navigated toward an apparent position of an apparent source. While in-flight, additional acoustic energy is received and a second audio signal is produced from the additional acoustic energy. The second audio signal is processed against the whitelist and, based on lack of substantial correspondence with any of the acoustic profiles of the whitelist, an investigate mode of the drone is initiated. The investigate mode includes notifying a remote monitor and supplying the remote monitor with an audiovisual feed. Responsive to a characterization by the remote monitor, an entry of the whitelist may be updated, added or replaced."
Acoustic monitoring system,https://lens.org/125-812-605-867-560,2021,"Systems and methods for monitoring a monitored space include producing a first audio signal from received acoustic energy. The first audio signal is then processed against a whitelist of acoustic profiles and, based on lack of substantial correspondence with any of the acoustic profiles, a drone is navigated toward an apparent position of an apparent source. While in-flight, additional acoustic energy is received and a second audio signal is produced from the additional acoustic energy. The second audio signal is processed against the whitelist and, based on lack of substantial correspondence with any of the acoustic profiles of the whitelist, an investigate mode of the drone is initiated. The investigate mode includes notifying a remote monitor and supplying the remote monitor with an audiovisual feed. Responsive to a characterization by the remote monitor, an entry of the whitelist may be updated, added or replaced."
ACOUSTIC MONITORING SYSTEM,https://lens.org/171-997-465-355-273,2018,"Systems and methods for monitoring a monitored space include producing a first audio signal from received acoustic energy. The first audio signal is then processed against a whitelist of acoustic profiles and, based on lack of substantial correspondence with any of the acoustic profiles, a drone is navigated toward an apparent position of an apparent source. While in-flight, additional acoustic energy is received and a second audio signal is produced from the additional acoustic energy. The second audio signal is processed against the whitelist and, based on lack of substantial correspondence with any of the acoustic profiles of the whitelist, an investigate mode of the drone is initiated. The investigate mode includes notifying a remote monitor and supplying the remote monitor with an audiovisual feed. Responsive to a characterization by the remote monitor, an entry of the whitelist may be updated, added or replaced."
Acoustic monitoring system,https://lens.org/019-291-061-411-739,2019,"Systems and methods for monitoring a monitored space include producing a first audio signal from received acoustic energy. The first audio signal is then processed against a whitelist of acoustic profiles and, based on lack of substantial correspondence with any of the acoustic profiles, a drone is navigated toward an apparent position of an apparent source. While in-flight, additional acoustic energy is received and a second audio signal is produced from the additional acoustic energy. The second audio signal is processed against the whitelist and, based on lack of substantial correspondence with any of the acoustic profiles of the whitelist, an investigate mode of the drone is initiated. The investigate mode includes notifying a remote monitor and supplying the remote monitor with an audiovisual feed. Responsive to a characterization by the remote monitor, an entry of the whitelist may be updated, added or replaced."
"System and method for mission planning, flight automation, and capturing of high-resolution images by unmanned aircraft",https://lens.org/023-759-015-956-418,2020,"A system and method for mission planning, flight automation, and capturing of high-resolution images by unmanned aircraft is provided. The system includes at least one hardware processor including a controller configured to generate and execute a flight plan that automatically detects and avoids obstacles present in a flight path for capturing the high-resolution images, requiring no (or, minimal) user involvement. The system can also predict obstacles in flight paths, and automatically calculate a flight path that avoids predicted obstacles."
"System and method for mission planning, flight automation, and capturing of high-resolution images by unmanned aircraft",https://lens.org/023-759-015-956-418,2020,"A system and method for mission planning, flight automation, and capturing of high-resolution images by unmanned aircraft is provided. The system includes at least one hardware processor including a controller configured to generate and execute a flight plan that automatically detects and avoids obstacles present in a flight path for capturing the high-resolution images, requiring no (or, minimal) user involvement. The system can also predict obstacles in flight paths, and automatically calculate a flight path that avoids predicted obstacles."
"SYSTEM AND METHOD FOR MISSION PLANNING, FLIGHT AUTOMATION, AND CAPTURING OF HIGH-RESOLUTION IMAGES BY UNMANNED AIRCRAFT",https://lens.org/058-659-464-151-529,2019,"A system and method for mission planning, flight automation, and capturing of high-resolution images by unmanned aircraft is provided. The system includes at least one hardware processor including a controller configured to generate and execute a flight plan that automatically detects and avoids obstacles present in a flight path for capturing the high-resolution images, requiring no (or, minimal) user involvement. The system can also predict obstacles in flight paths, and automatically calculate a flight path that avoids predicted obstacles."
"FLIGHT DEVICE, ELECTRONIC DEVICE AND PROGRAM",https://lens.org/067-210-916-558-124,2019,"A flying device includes a flight unit; and a flight control unit that performs, in a case where a flight position by the flight unit is out of a predetermined range, a control that is different from a control in a case where the flight position is within the predetermined range."
"FLYING DEVICE, ELECTRONIC DEVICE, AND PROGRAM",https://lens.org/058-129-144-309-827,2019,"A flying device includes a flight unit; and a flight control unit that performs, in a case where a flight position by the flight unit is out of a predetermined range, a control that is different from a control in a case where the flight position is within the predetermined range."
"AUTONOMOUS VEHICLE, CONTROL METHOD FOR REMOTELY CONTROLLING THEREOF",https://lens.org/020-710-243-010-572,2023,"The present disclosure relates to an autonomous vehicle and a remote control method therefor. An exemplary embodiment of the present disclosure provides an autonomous vehicle, including a processor configured to transmit a vehicle path to the control system to request remote control when the remote control of the autonomous vehicle is required, to receive a corrected path obtained by correcting the vehicle from the control system, and to determine errors in reference point coordinates and path data of the corrected path."
Flying camera and a system,https://lens.org/033-559-868-252-187,2019,"There is provided a control device including an image display unit configured to acquire, from a flying body, an image captured by an imaging device provided in the flying body and to display the image, and a flight instruction generation unit configured to generate a flight instruction for the flying body based on content of an operation performed with respect to the image captured by the imaging device and displayed by the image display unit."
"CONTROL DEVICE, CONTROL METHOD, AND COMPUTER PROGRAM",https://lens.org/007-313-720-586-954,2017,"There is provided a control device including an image display unit configured to acquire, from a flying body, an image captured by an imaging device provided in the flying body and to display the image, and a flight instruction generation unit configured to generate a flight instruction for the flying body based on content of an operation performed with respect to the image captured by the imaging device and displayed by the image display unit."
Flying camera and a system,https://lens.org/147-655-050-923-881,2018,"There is provided a control device including an image display unit configured to acquire, from a flying body, an image captured by an imaging device provided in the flying body and to display the image, and a flight instruction generation unit configured to generate a flight instruction for the flying body based on content of an operation performed with respect to the image captured by the imaging device and displayed by the image display unit."
Flying camera and a system,https://lens.org/015-866-433-716-12X,2022,"There is provided a control device including an image display unit configured to acquire, from a flying body, an image captured by an imaging device provided in the flying body and to display the image, and a flight instruction generation unit configured to generate a flight instruction for the flying body based on content of an operation performed with respect to the image captured by the imaging device and displayed by the image display unit."
"CONTROL DEVICE, CONTROL METHOD, AND COMPUTER PROGRAM",https://lens.org/133-490-432-795-888,2014,"There is provided a control device including an image display unit configured to acquire, from a flying body, an image captured by an imaging device provided in the flying body and to display the image, and a flight instruction generation unit configured to generate a flight instruction for the flying body based on content of an operation performed with respect to the image captured by the imaging device and displayed by the image display unit."
Flying camera and a system,https://lens.org/015-866-433-716-12X,2022,"There is provided a control device including an image display unit configured to acquire, from a flying body, an image captured by an imaging device provided in the flying body and to display the image, and a flight instruction generation unit configured to generate a flight instruction for the flying body based on content of an operation performed with respect to the image captured by the imaging device and displayed by the image display unit."
"Control device, control method, and computer program",https://lens.org/043-739-768-050-597,2017,"There is provided a control device including an image display unit configured to acquire, from a flying body, an image captured by an imaging device provided in the flying body and to display the image, and a flight instruction generation unit configured to generate a flight instruction for the flying body based on content of an operation performed with respect to the image captured by the imaging device and displayed by the image display unit."
FLYING CAMERA AND A SYSTEM,https://lens.org/065-485-266-367-659,2022,"There is provided a control device including an image display unit configured to acquire, from a flying body, an image captured by an imaging device provided in the flying body and to display the image, and a flight instruction generation unit configured to generate a flight instruction for the flying body based on content of an operation performed with respect to the image captured by the imaging device and displayed by the image display unit."
FLYING CAMERA AND A SYSTEM,https://lens.org/078-059-850-744-433,2019,"There is provided a control device including an image display unit configured to acquire, from a flying body, an image captured by an imaging device provided in the flying body and to display the image, and a flight instruction generation unit configured to generate a flight instruction for the flying body based on content of an operation performed with respect to the image captured by the imaging device and displayed by the image display unit."
FLYING CAMERA AND A SYSTEM,https://lens.org/041-206-493-857-740,2020,"There is provided a control device including an image display unit configured to acquire, from a flying body, an image captured by an imaging device provided in the flying body and to display the image, and a flight instruction generation unit configured to generate a flight instruction for the flying body based on content of an operation performed with respect to the image captured by the imaging device and displayed by the image display unit."
Flying camera and a system,https://lens.org/153-096-102-856-756,2020,"There is provided a control device including an image display unit configured to acquire, from a flying body, an image captured by an imaging device provided in the flying body and to display the image, and a flight instruction generation unit configured to generate a flight instruction for the flying body based on content of an operation performed with respect to the image captured by the imaging device and displayed by the image display unit."
Flying camera and a system,https://lens.org/079-243-223-931-949,2020,"There is provided a control device including an image display unit configured to acquire, from a flying body, an image captured by an imaging device provided in the flying body and to display the image, and a flight instruction generation unit configured to generate a flight instruction for the flying body based on content of an operation performed with respect to the image captured by the imaging device and displayed by the image display unit."
FLYING CAMERA AND A SYSTEM,https://lens.org/065-485-266-367-659,2022,"There is provided a control device including an image display unit configured to acquire, from a flying body, an image captured by an imaging device provided in the flying body and to display the image, and a flight instruction generation unit configured to generate a flight instruction for the flying body based on content of an operation performed with respect to the image captured by the imaging device and displayed by the image display unit."
FLYING CAMERA AND A SYSTEM,https://lens.org/026-942-354-429-377,2021,"There is provided a control device including an image display unit configured to acquire, from a flying body, an image captured by an imaging device provided in the flying body and to display the image, and a flight instruction generation unit configured to generate a flight instruction for the flying body based on content of an operation performed with respect to the image captured by the imaging device and displayed by the image display unit."
AUTONOMOUS AERIAL SYSTEM AND METHOD,https://lens.org/192-293-269-672-876,2022,"An indoor autonomous aerial system and method that uses micro aerial vehicle/s (MAV/s). Said system is configured to be deployable and operable in reduced GPS signal reception expansive spaces and the MAV/s is/are configured to be automatically guided and perform tasks at desired location/s, transmit/receive data, present various signs, etc. Said system and method can be used for various purposes such as, advertisement, inventory management, guidance, warning, search and rescue, etc."
AUTONOMOUS AERIAL SYSTEM AND METHOD,https://lens.org/192-293-269-672-876,2022,"An indoor autonomous aerial system and method that uses micro aerial vehicle/s (MAV/s). Said system is configured to be deployable and operable in reduced GPS signal reception expansive spaces and the MAV/s is/are configured to be automatically guided and perform tasks at desired location/s, transmit/receive data, present various signs, etc. Said system and method can be used for various purposes such as, advertisement, inventory management, guidance, warning, search and rescue, etc."
AUTONOMOUS AERIAL SYSTEM AND METHOD,https://lens.org/105-170-508-067-476,2021,"An indoor autonomous aerial system and method that uses micro aerial vehicle/s (MAV/s). Said system is configured to be deployable and operable in reduced GPS signal reception expansive spaces and the MAV/s is/are configured to be automatically guided and perform tasks at desired location/s, transmit/receive data, present various signs, etc. Said system and method can be used for various purposes such as, advertisement, inventory management, guidance, warning, search and rescue, etc."
SYSTEMS AND METHODS FOR REMOTELY CONTROLLED DEVICE POSITION AND ORIENTATION DETERMINATION,https://lens.org/015-423-845-634-961,2011,"A system for a remotely controlled device to determine its location and orientation is disclosed. The system includes a remotely controlled device, at least one sensor connected to the remotely controlled device, the at least one sensor comprising a processor, and at least one emitter, wherein the at least one sensor is configured to receive the signal from the at least one emitter and the processor is configured to determine the location and orientation of the remotely controlled device."
SYSTEMS AND METHODS FOR REMOTELY CONTROLLED DEVICE POSITION AND ORIENTATION DETERMINATION,https://lens.org/112-900-794-827-899,2021,"A system for a remotely controlled device to determine its location and orientation is disclosed. The system includes a remotely controlled device, at least one sensor connected to the remotely controlled device, the at least one sensor comprising a processor, and at least one emitter, wherein the at least one sensor is configured to receive the signal from the at least one emitter and the processor is configured to determine the location and orientation of the remotely controlled device."
Systems and methods for remotely controlled device position and orientation determination,https://lens.org/050-158-892-572-390,2021,"A system for a remotely controlled device to determine its location and orientation is disclosed. The system includes a remotely controlled device, at least one sensor connected to the remotely controlled device, the at least one sensor comprising a processor, and at least one emitter, wherein the at least one sensor is configured to receive the signal from the at least one emitter and the processor is configured to determine the location and orientation of the remotely controlled device."
METHOD AND APPARATUS FOR CREATING AERIAL PANORAMIC PHOTOGRAPHY,https://lens.org/130-078-653-212-97X,2007,"An aerial photography apparatus that comprises a remote controlled piloted aircraft, a platform, a camera, and wireless transmitter. The remote controlled piloted aircraft is attached to the top side of the platform. The camera is attached to the bottom side of the platform using a rigid member having a rotatable joint. The remote controlled piloted aircraft lifts and moves the apparatus to a desired location at a specific altitude above a particular property where the panoramic aerial photograph is to be taken. A rotatable joint enables the gravitational weight of the camera to naturally gravitate to a vertical orientation or position relative to the ground. A counterbalance weight is provided on the camera to counter the weight of the lens for maintaining the camera in a level balance while rotating through the three hundred and sixty degree rotation when creating the desired panoramic aerial photograph."
DIRECTIONAL TILES FOR AUTONOMOUS DRONES,https://lens.org/076-369-435-589-764,2021,"High strength carbon fiber tiles for autonomous drone navigation preferably are used where GPS and cellular navigation are limited or nonexistent, such as within buildings, subterranean, and non-terrestrial vehicles, in order to assist in monitoring and instructing drones to travel to predetermined locations. Tiles that are constructed out of carbon-fiber reinforced with graphene oxide nanoparticles in an epoxy resin coating provide a strong yet light-weight solution for covering areas where drone travel is desired. Contained within the tiles are navigational strips having LEDs or other lighting-emitting components, or having heating elements, which provide pathways for sensors to read and receive directional input for autonomous drone navigation. The tiles further preferably comprise 3D barcodes indicative of location in a mapped area to inform on drone location when traveling therein."
HOME ROBOT AND CONTROL METHOD THEREOF,https://lens.org/158-831-532-454-909,2016,"A home robot and control method thereof; the home robot comprises: a casing (100); a plurality of ultrasonic transmitters (200) and a plurality of ultrasonic receivers (300) provided on the casing (100) arranged at intervals; and a controller (400) connected to the plurality of ultrasonic transmitters (200) and the plurality of ultrasonic receivers (300) respectively, the controller (400) being used to control the plurality of ultrasonic transmitters (200) to transmit first ultrasonic wave signals according to a preset period and to detect a front obstacle according to signals received by the plurality of ultrasonic receivers (300). The home robot can detect the direction of an obstacle, and is not affected by a material of the obstacle, thus enabling the home robot to perform an avoidance method according to the detected direction of the obstacle, avoiding a collision between the home robot and the obstacle, increasing a cleaning coverage rate and improving a user experience."
Remote controller,https://lens.org/134-725-410-510-802,2010,"A radio remote controller includes a directional receiver 3 and a micro-controller 5, which can detect and identify external electromagnetic or optical beacons 1 or 2 situated near devices to be controlled. A radio transmitter 5 in the remote controller is then used to send different commands to a device 7 depending on which beacon is detected. The remote controller allows simple control by pointing and pushing a button and can be used to control garage doors, home appliances etc."
FLIGHT CONTROL SYSTEM FOR UNMANNED AERIAL VEHICLE AND TOPOGRAPHY MEASURING SYSTEM,https://lens.org/092-936-857-017-81X,2023,"A flight control system for an unmanned aerial vehicle comprises an unmanned aerial vehicle on which a reflector is mounted and a total station for tracking the reflector and for acquiring measurement data including three-dimensional coordinates of the reflector, wherein the total station comprises a tracking module for tracking the reflector, a TS-data transmitting module having an optical axis parallel or approximately parallel to a tracking optical axis of the tracking module and for emitting a TS-data transmitting light, and a TS-arithmetic control module, wherein the unmanned aerial vehicle has a photodetector for receiving the TS-data transmitting light and for emitting a photodetecting signal and a UAV-arithmetic control module for controlling a flight of the unmanned aerial vehicle, and wherein the TS-arithmetic control module is configured to superimpose the measurement data on the TS-data transmitting light, and the UAV-arithmetic control module is configured to separate the measurement data from the photodetecting signal and obtains a flight position of the unmanned aerial vehicle in real time."
FLIGHT CONTROL SYSTEM FOR UNMANNED AERIAL VEHICLE AND GEOGRAPHICAL-FEATURE MEASUREMENT SYSTEM,https://lens.org/004-436-453-591-097,2022,"A flight control system for an unmanned aerial vehicle comprises an unmanned aerial vehicle on which a reflector is mounted and a total station for tracking the reflector and for acquiring measurement data including three-dimensional coordinates of the reflector, wherein the total station comprises a tracking module for tracking the reflector, a TS-data transmitting module having an optical axis parallel or approximately parallel to a tracking optical axis of the tracking module and for emitting a TS-data transmitting light, and a TS-arithmetic control module, wherein the unmanned aerial vehicle has a photodetector for receiving the TS-data transmitting light and for emitting a photodetecting signal and a UAV-arithmetic control module for controlling a flight of the unmanned aerial vehicle, and wherein the TS-arithmetic control module is configured to superimpose the measurement data on the TS-data transmitting light, and the UAV-arithmetic control module is configured to separate the measurement data from the photodetecting signal and obtains a flight position of the unmanned aerial vehicle in real time."
FLIGHT CONTROL SYSTEM FOR UNMANNED AERIAL VEHICLE AND TOPOGRAPHY MEASURING SYSTEM,https://lens.org/092-936-857-017-81X,2023,"A flight control system for an unmanned aerial vehicle comprises an unmanned aerial vehicle on which a reflector is mounted and a total station for tracking the reflector and for acquiring measurement data including three-dimensional coordinates of the reflector, wherein the total station comprises a tracking module for tracking the reflector, a TS-data transmitting module having an optical axis parallel or approximately parallel to a tracking optical axis of the tracking module and for emitting a TS-data transmitting light, and a TS-arithmetic control module, wherein the unmanned aerial vehicle has a photodetector for receiving the TS-data transmitting light and for emitting a photodetecting signal and a UAV-arithmetic control module for controlling a flight of the unmanned aerial vehicle, and wherein the TS-arithmetic control module is configured to superimpose the measurement data on the TS-data transmitting light, and the UAV-arithmetic control module is configured to separate the measurement data from the photodetecting signal and obtains a flight position of the unmanned aerial vehicle in real time."
FLIGHT CONTROL SYSTEM FOR UNMANNED AERIAL VEHICLE AND GEOGRAPHICAL-FEATURE MEASUREMENT SYSTEM,https://lens.org/004-436-453-591-097,2022,"A flight control system for an unmanned aerial vehicle comprises an unmanned aerial vehicle on which a reflector is mounted and a total station for tracking the reflector and for acquiring measurement data including three-dimensional coordinates of the reflector, wherein the total station comprises a tracking module for tracking the reflector, a TS-data transmitting module having an optical axis parallel or approximately parallel to a tracking optical axis of the tracking module and for emitting a TS-data transmitting light, and a TS-arithmetic control module, wherein the unmanned aerial vehicle has a photodetector for receiving the TS-data transmitting light and for emitting a photodetecting signal and a UAV-arithmetic control module for controlling a flight of the unmanned aerial vehicle, and wherein the TS-arithmetic control module is configured to superimpose the measurement data on the TS-data transmitting light, and the UAV-arithmetic control module is configured to separate the measurement data from the photodetecting signal and obtains a flight position of the unmanned aerial vehicle in real time."
DRONE FOR COLLECTING AND PROVIDING IMAGE MATERIAL FOR BOMB DAMAGE ASSESSMENT AND AIR-TO-GROUND ARMAMENT SYSTEM HAVING SAME,https://lens.org/151-222-388-175-21X,2019,The present invention relates to a drone for collecting and providing image data for bomb damage assessment and an air-to-ground weapon system equipped with the drone. The air-to-ground weapon system includes: a hitting means moving to a bombardment target to hit the bombardment target; and a drone detachably attached to the hitting means.
SYSTEM AND METHOD FOR BROADCASTING THE LOCATION OF LOW ALTITUDE OBJECTS,https://lens.org/155-295-046-224-571,2018,"A computer-implemented method comprises detecting, by one or more sensors, at least one object in an airspace to generate a detection output; for the at least one object being registered as a drone, obtaining, by an identification friend or foe (IFF) system, information associated with the at least one object, to generate an IFF output; based on the detection output and the IFF output, determining at least one of a class and an identity of the at least one object, to generate code information; and based on the code information, generating and transmitting a high power, long distance signal configured to be received by a high power, long distance aircraft."
METHOD AND APPARATUS FOR CONTROLLING HEADLIGHTS OF AUTONOMOUS VEHICLE,https://lens.org/155-336-813-615-88X,2020,"A method of controlling headlights of an autonomous vehicle according to the present invention includes: initially driving the headlights when surrounding illumination is predetermined threshold illumination or less; detecting an object in a traveling path; sensing a light amount of the object; and adjusting brightness of the headlights in accordance with the light amount of the object, and increasing the brightness of the headlights when the light amount of the object is less than the predetermined threshold light amount. One or more of an autonomous vehicle, a user terminal, and a server of the present invention may be associated with an artificial intelligence module, a drone ((Unmanned Aerial Vehicle, UAV), a robot, an AR (Augmented Reality) device, a VR (Virtual Reality) device, a device associated with 5G services, etc."
"Flight Control Method And Apparatus, Flight Clearance Method, Flight Safety Maintenance Method And Apparatus, Server, And Aerial Vehicle",https://lens.org/011-745-197-110-460,2018,"The present disclosure includes a flight control method and apparatus. An example includes determining, when an unmanned aerial vehicle is flying, a specific flight zone to be entered by the unmanned aerial vehicle, where a flight clearance is required for the unmanned aerial vehicle to enter the specific flight zone. Application information and information about the specific flight zone is sent to a server, where the application information is used to apply for the flight clearance to enter the specific flight zone, and the information about the specific flight zone is used to indicate the specific flight zone. A flight instruction is sent when a flight clearance sent by the server is received, so that the unmanned aerial vehicle enters the specific flight zone according to the flight instruction."
"Flight control method and apparatus, flight clearance method, flight safety maintenance method and apparatus, server, and aerial vehicle",https://lens.org/120-777-764-529-849,2020,"The present disclosure includes a flight control method and apparatus. An example includes determining, when an unmanned aerial vehicle is flying, a specific flight zone to be entered by the unmanned aerial vehicle, where a flight clearance is required for the unmanned aerial vehicle to enter the specific flight zone. Application information and information about the specific flight zone is sent to a server, where the application information is used to apply for the flight clearance to enter the specific flight zone, and the information about the specific flight zone is used to indicate the specific flight zone. A flight instruction is sent when a flight clearance sent by the server is received, so that the unmanned aerial vehicle enters the specific flight zone according to the flight instruction."
REMOTE CONTROL SYSTEM,https://lens.org/053-344-539-558-414,2014,"A remote control apparatus (11) includes a moving apparatus (12) that has a control unit (41) that stores map information and a target position and controls a tracking move to the target position along a moving path, and a remote control unit (13) that transmits the target position input by a manipulating unit (32) to the moving apparatus (12), and the control unit (41) detects an input value of the manipulating unit (32) as an amount of change, and autonomously moves the moving apparatus (12) in a tracking manner while changing the target position in accordance with the amount of change."
SELF-BURYING AUTONOMOUS UNDERWATER VEHICLE AND METHOD FOR MARINE SEISMIC SURVEYS,https://lens.org/121-240-534-190-276,2014,"An autonomous underwater vehicle (AUV) (200) for recording seismic signals during a marine seismic survey. The AUV includes a body (202) having a base (204) and sides (205); a propulsion system (918) for guiding the AUV (200) to a final target on the ocean bottom; a pump-jet (210) connected to an inlet (212) and plural base outlets (214i), wherein the plural base outlets (214i) are distributed on the base (204); a processor (108) connected to the pump-jet (210) and configured to activate the pump-jet (210) when the base in on the ocean bottom; and a seismic sensor (922) configured to record seismic signals. The pump-jet (210) has a first low speed so that water jets expelled at the plural base outlets (214i) fluidize the ocean bottom underneath the base (204) and buries the AUV (200)."
PROGRAMMABLE EMERGENCY LIGHTING DEVICE INCLUDING NEAR-FIELD COMMUNICATION,https://lens.org/169-878-199-680-79X,2018,"An emergency lighting unit including a light source, a wireless communication module configured to receive a wireless communication signal, and a controller connected to the wireless communication module. The controller is configured to set a system parameter of the emergency lighting unit based on the wireless communication signal, and control the illumination of the light source based on the one system parameter."
Programmable emergency lighting device including near-field communication,https://lens.org/105-814-109-209-394,2020,"An emergency lighting unit including a light source, a wireless communication module configured to receive a wireless communication signal, and a controller connected to the wireless communication module. The controller is configured to set a system parameter of the emergency lighting unit based on the wireless communication signal, and control the illumination of the light source based on the one system parameter."
SOLAR RECHARGEABLE UNMANNED VEHICLE SYSTEMS AND METHODS TO MONITOR A GEOGRAPHIC AREA,https://lens.org/129-802-704-603-735,2018,"Some embodiments provide an aerial monitoring system to monitor a geographic area, comprising: a unmanned aerial vehicle (UAV) comprising: a plurality of lift motors to drive a propeller; a substructural support supporting the lift motors and propellers; a UAV control circuit configured to control the operation of the lift motors; a rechargeable electrical power source that supplies electrical power to the UAV control circuit and the plurality of lift motors; a recharge control circuit; and a modifiable support system cooperated with the substructural support and supporting a set of photovoltaic cells electrically coupled with the rechargeable power source and configured to supply electrical power to the rechargeable power source, wherein the recharge control circuit is configured to control a modification of the modifiable support system to cause a physical modification of at least an orientation of the modifiable support system relative to the substructural support."
Solar rechargeable unmanned vehicle systems and methods to monitor a geographic area,https://lens.org/005-538-533-324-726,2019,"Some embodiments provide an aerial monitoring system to monitor a geographic area, comprising: a unmanned aerial vehicle (UAV) comprising: a plurality of lift motors to drive a propeller; a substructural support supporting the lift motors and propellers; a UAV control circuit configured to control the operation of the lift motors; a rechargeable electrical power source that supplies electrical power to the UAV control circuit and the plurality of lift motors; a recharge control circuit; and a modifiable support system cooperated with the substructural support and supporting a set of photovoltaic cells electrically coupled with the rechargeable power source and configured to supply electrical power to the rechargeable power source, wherein the recharge control circuit is configured to control a modification of the modifiable support system to cause a physical modification of at least an orientation of the modifiable support system relative to the substructural support."
Automatic tracking mode for controlling an unmanned aerial vehicle,https://lens.org/111-095-724-413-791,2018,"Some embodiments include methods performed by a processor associated with a wireless communication device for enabling an unmanned autonomous vehicle (UAV) to operate in an automatic user tracking mode. Such embodiments may include capturing image data of surroundings by a camera while the UAV is operating in the automatic user tracking mode, calculating estimated position information for the wireless communication device based on captured image data, and transmitting estimated position information to the UAV for use in tracking a user of the wireless communication device. Some embodiments include methods performed by a processor of a UAV for enabling the UAV to automatically follow a user. Such embodiments may include calculating a current position of the UAV, receiving from a user's wireless communication device estimated position information derived from image data captured by a camera of the wireless communication device, and determining whether an update to the UAV motion is required."
Automatic Tracking Mode For Controlling An Unmanned Aerial Vehicle,https://lens.org/112-069-311-639-749,2017,"Some embodiments include methods performed by a processor associated with a wireless communication device for enabling an unmanned autonomous vehicle (UAV) to operate in an automatic user tracking mode. Such embodiments may include capturing image data of surroundings by a camera while the UAV is operating in the automatic user tracking mode, calculating estimated position information for the wireless communication device based on captured image data, and transmitting estimated position information to the UAV for use in tracking a user of the wireless communication device. Some embodiments include methods performed by a processor of a UAV for enabling the UAV to automatically follow a user. Such embodiments may include calculating a current position of the UAV, receiving from a user's wireless communication device estimated position information derived from image data captured by a camera of the wireless communication device, and determining whether an update to the UAV motion is required."
Robotic Vacuum Cleaner,https://lens.org/117-969-634-357-08X,2008,"An autonomous robot, that is for example, suitable for operations such as vacuuming and surface cleaning includes a payload configured for vacuum cleaning, a drive system including a steering system, a navigation system, and a control system for integrating operations of the aforementioned systems."
Robotic vacuum cleaner,https://lens.org/183-324-574-115-411,2008,"An autonomous robot, that is for example, suitable for operations such as vacuuming and surface cleaning includes a payload configured for vacuum cleaning, a drive system including a steering system, a navigation system, and a control system for integrating operations of the aforementioned systems."
Robotic vacuum cleaner,https://lens.org/194-661-378-182-162,2007,"An autonomous robot, that is for example, suitable for operations such as vacuuming and surface cleaning includes a payload configured for vacuum cleaning, a drive system including a steering system, a navigation system, and a control system for integrating operations of the aforementioned systems."
Robotic vacuum cleaner,https://lens.org/016-637-814-820-77X,2003,"An autonomous robot, that is for example, suitable for operations such as vacuuming and surface cleaning includes a payload configured for vacuum cleaning, a drive system including a steering system, a navigation system, and a control system for integrating operations of the aforementioned systems."
ROBOTIC VACUUM CLEANER,https://lens.org/006-079-387-969-310,2003,"An autonomous robot, that is for example, suitable for operations such as vacuuming and surface cleaning includes a payload configured for vacuum cleaning, a drive system including a steering system, a navigation system, and a control system for integrating operations of the aforementioned systems."
Robotic vacuum cleaner,https://lens.org/156-080-814-461-202,2007,"An autonomous robot, that is for example, suitable for operations such as vacuuming and surface cleaning includes a payload configured for vacuum cleaning, a drive system including a steering system, a navigation system, and a control system for integrating operations of the aforementioned systems."
ROBOTIC VACUUM CLEANER,https://lens.org/026-411-656-907-079,2003,"An autonomous robot, that is for example, suitable for operations such as vacuuming and surface cleaning includes a payload configured for vacuum cleaning, a drive system including a steering system, a navigation system, and a control system for integrating operations of the aforementioned systems."
Robotic vacuum cleaner,https://lens.org/078-413-554-303-376,2010,"An autonomous robot, that is for example, suitable for operations such as vacuuming and surface cleaning includes a payload configured for vacuum cleaning, a drive system including a steering system, a navigation system, and a control system for integrating operations of the aforementioned systems."
Robotic vacuum cleaner,https://lens.org/098-938-540-442-989,2006,"An autonomous robot, that is for example, suitable for operations such as vacuuming and surface cleaning includes a payload configured for vacuum cleaning, a drive system including a steering system, a navigation system, and a control system for integrating operations of the aforementioned systems."
HYBRID MULTICOPTER AND FIXED WING AERIAL VEHICLE,https://lens.org/173-585-435-323-512,2017,An aerial vehicle is disclosed which includes a body and a multicopter. The body has at least one wing. The multicopter is rotatably mounted to the body about a multicopter axis. The multicopter includes a plurality of rotors positioned and controllable to rotate the multicopter about the multicopter axis.
HYBRID MULTICOPTER AND FIXED WING AERIAL VEHICLE,https://lens.org/173-585-435-323-512,2017,An aerial vehicle is disclosed which includes a body and a multicopter. The body has at least one wing. The multicopter is rotatably mounted to the body about a multicopter axis. The multicopter includes a plurality of rotors positioned and controllable to rotate the multicopter about the multicopter axis.
UNMANNED AERIAL VEHICLE (UAV)-ASSISTED HANGING RING ROBOT FOR LIVE INSTALLATION AND GROUNDING,https://lens.org/019-624-328-026-50X,2022,"An unmanned aerial vehicle (UAV)-assisted hanging ring robot for live installation and grounding includes a hanging tray, a wire hanging bracket, a hanging wire, an overturning stay wire, an overturning frame, a support, an electric lock, a walking wheel, a driving motor, a workbench, a clamp seat, a puncture clamp, a tightening mechanism, a remote controller, and a controller. The hanging tray is installed at the bottom of a UAV, one end of the overturning stay wire is connected to the overturning frame, the other end thereof hangs on ground, the driving motor is installed on the overturning frame, the walking wheel is connected to the driving motor, the puncture clamp is installed on the clamp seat, the tightening mechanism is installed on the workbench, and connected to the puncture clamp, and the electric lock, tightening mechanism, driving motor, and remote controller are connected to the controller."
UNMANNED AERIAL VEHICLE (UAV)-ASSISTED HANGING RING ROBOT FOR LIVE INSTALLATION AND GROUNDING,https://lens.org/019-624-328-026-50X,2022,"An unmanned aerial vehicle (UAV)-assisted hanging ring robot for live installation and grounding includes a hanging tray, a wire hanging bracket, a hanging wire, an overturning stay wire, an overturning frame, a support, an electric lock, a walking wheel, a driving motor, a workbench, a clamp seat, a puncture clamp, a tightening mechanism, a remote controller, and a controller. The hanging tray is installed at the bottom of a UAV, one end of the overturning stay wire is connected to the overturning frame, the other end thereof hangs on ground, the driving motor is installed on the overturning frame, the walking wheel is connected to the driving motor, the puncture clamp is installed on the clamp seat, the tightening mechanism is installed on the workbench, and connected to the puncture clamp, and the electric lock, tightening mechanism, driving motor, and remote controller are connected to the controller."
Remote control device,https://lens.org/057-522-765-035-392,2007,"A remote control device is provided that functions as a device for controlling equipment of which image is picked up. The remote control device includes a camera, a drive circuit receiving an input of a signal output from the camera, an operation portion externally receiving an input of an instruction, a light-receiving portion receiving an input of an optical signal, a control circuit generating a signal for the remote control device to perform a predetermined process based on externally input data or command, a memory for reading and writing data, a display displaying an image based on the signal generated by the control circuit, and a signal output portion outputting the signal generated by the control circuit."
DRONE-BASED RADIO-OVER-FIBER SYSTEM,https://lens.org/032-609-601-467-29X,2022,"The drone-based radio-over-fiber system (10) provides an unmanned aerial vehicle, AV, preferably a multi-rotor drone (12), connected to a base station (14) by a tether (18) including an optical fiber. A radio frequency-over-fiber system is used for bidirectional data communications between at least one radio frequency, RF transmitter at the base station (14) and at least one antenna (48A, 48B) mounted on the drone through the optical fiber in the tether (18). The system includes wave division multiplexers/demultiplexers that permit ultrahigh bandwidth communication over the tether (18). An embodiment of the system for 2x2 multiple-input, multiple-output, MIMO signals in the 700 MHz LTE band is described."
DRONE-BASED RADIO-OVER-FIBER SYSTEM,https://lens.org/032-609-601-467-29X,2022,"The drone-based radio-over-fiber system (10) provides an unmanned aerial vehicle, AV, preferably a multi-rotor drone (12), connected to a base station (14) by a tether (18) including an optical fiber. A radio frequency-over-fiber system is used for bidirectional data communications between at least one radio frequency, RF transmitter at the base station (14) and at least one antenna (48A, 48B) mounted on the drone through the optical fiber in the tether (18). The system includes wave division multiplexers/demultiplexers that permit ultrahigh bandwidth communication over the tether (18). An embodiment of the system for 2x2 multiple-input, multiple-output, MIMO signals in the 700 MHz LTE band is described."
APPARATUS FOR COLLECTING ITEM AND CONTROL METHOD THEREOF,https://lens.org/178-888-420-946-987,2021,"At least one of an autonomous vehicle, a user terminal, and a server may be connected or converged with an artificial intelligence (AI) module, an unmanned aerial vehicle (UAV), a robot, an augmented reality (AR) device, a virtual reality (VR) device, a device associated with a 5G service, and the like. A method for a collecting device may include identifying a user and an item associated with the user, identifying image information associated with the user, verifying whether the item is to be collected based on the image information, moving to a position corresponding to the user when the item is to be collected, and providing information associated with item collection to the user."
PRECISION GUIDED MANNEQUIN ARIAL UNIT,https://lens.org/003-263-484-908-174,2023,"Disclosed is a guided mannequin aerial unit. The mannequin includes a control unit having a central processing unit (CPU), memory for storing a computer software instruction set for execution by the CPU, a high-resolution camera for taking and providing to the CPU real time images of the drop area and a second memory unit for pre-storing images of the mannequin drop area and the drop target. Under the control of the software instruction set, the CPU compares the real time images to the pre- stored images to guide the mannequin to the drop target."
SYSTEMS AND METHODS FOR MARKER INCLUSION IN A WELLBORE,https://lens.org/056-005-491-768-529,2019,"A system and a method for determining a location of an untethered drone (125) in a wellbore are described herein. The system includes one or more markers (120) to be placed within a wellbore casing (110) where each of the one or more markers is configured to transmit a continuous or periodic signal. The system further includes a first sensor (130, 135) to be transported by the untethered drone where the first sensor is configured to sense an existence of the one or more markers."
UNMANNED AIRCRAFT SYSTEMS AND METHODS TO INTERACT WITH SPECIFICALLY INTENDED OBJECTS,https://lens.org/198-667-706-175-897,2017,"In some embodiments, systems, apparatuses, methods, and processes are provided to control and allocate UASs. In some embodiments, a system to control unmanned aircraft systems (UAS), comprises: one or more wireless transceivers configured to communicate with the UAS; a control circuit coupled with the transceiver(s); and a memory coupled to the control circuit and storing computer instructions that when executed by the control circuit cause the control circuit to perform the steps of: receive sensor data captured by at least one sensor of a UAS; determine, from the sensor data, unique identification of an object at a predefined location; and confirm, from the sensor data, that the identified object is an expected object expected at the predefined location."
UNMANNED AIRCRAFT SYSTEMS AND METHODS TO INTERACT WITH SPECIFICALLY INTENDED OBJECTS,https://lens.org/167-441-532-814-778,2018,"In some embodiments, systems, apparatuses, methods, and processes are provided to control and allocate UASs. In some embodiments, a system to control unmanned aircraft systems (UAS), comprises: one or more wireless transceivers configured to communicate with the UAS; a control circuit coupled with the transceiver(s); and a memory coupled to the control circuit and storing computer instructions that when executed by the control circuit cause the control circuit to perform the steps of: receive sensor data captured by at least one sensor of a UAS; determine, from the sensor data, unique identification of an object at a predefined location; and confirm, from the sensor data, that the identified object is an expected object expected at the predefined location."
UNMANNED AIRCRAFT SYSTEMS AND METHODS TO INTERACT WITH SPECIFICALLY INTENDED OBJECTS,https://lens.org/087-551-507-582-95X,2019,"In some embodiments, systems, apparatuses, methods, and processes are provided to control and allocate UASs. In some embodiments, a system to control unmanned aircraft systems (UAS), comprises: one or more wireless transceivers configured to communicate with the UAS; a control circuit coupled with the transceiver(s); and a memory coupled to the control circuit and storing computer instructions that when executed by the control circuit cause the control circuit to perform the steps of: receive sensor data captured by at least one sensor of a UAS; determine, from the sensor data, unique identification of an object at a predefined location; and confirm, from the sensor data, that the identified object is an expected object expected at the predefined location."
UNMANNED AIRCRAFT SYSTEMS AND METHODS TO INTERACT WITH SPECIFICALLY INTENDED OBJECTS,https://lens.org/031-050-033-139-595,2017,"In some embodiments, systems, apparatuses, methods, and processes are provided to control and allocate UASs. In some embodiments, a system to control unmanned aircraft systems (UAS), comprises: one or more wireless transceivers configured to communicate with the UAS; a control circuit coupled with the transceiver(s); and a memory coupled to the control circuit and storing computer instructions that when executed by the control circuit cause the control circuit to perform the steps of: receive sensor data captured by at least one sensor of a UAS; determine, from the sensor data, unique identification of an object at a predefined location; and confirm, from the sensor data, that the identified object is an expected object expected at the predefined location."
Unmanned aircraft systems and methods to interact with specifically intended objects,https://lens.org/014-465-973-581-752,2018,"In some embodiments, systems, apparatuses, methods, and processes are provided to control and allocate UASs. In some embodiments, a system to control unmanned aircraft systems (UAS), comprises: one or more wireless transceivers configured to communicate with the UAS; a control circuit coupled with the transceiver(s); and a memory coupled to the control circuit and storing computer instructions that when executed by the control circuit cause the control circuit to perform the steps of: receive sensor data captured by at least one sensor of a UAS; determine, from the sensor data, unique identification of an object at a predefined location; and confirm, from the sensor data, that the identified object is an expected object expected at the predefined location."
Unmanned aircraft systems and methods to interact with specifically intended objects,https://lens.org/127-351-972-010-554,2018,"In some embodiments, systems, apparatuses, methods, and processes are provided to control and allocate UASs. In some embodiments, a system to control unmanned aircraft systems (UAS), comprises: one or more wireless transceivers configured to communicate with the UAS; a control circuit coupled with the transceiver(s); and a memory coupled to the control circuit and storing computer instructions that when executed by the control circuit cause the control circuit to perform the steps of: receive sensor data captured by at least one sensor of a UAS; determine, from the sensor data, unique identification of an object at a predefined location; and confirm, from the sensor data, that the identified object is an expected object expected at the predefined location."
"METHOD, APPARATUS, AND SYSTEM FOR CONTROLLING SMART HOME ENVIRONMENT USING LED LIGHTING DEVICE",https://lens.org/195-513-544-655-829,2016,"A smart home control system including at least one LED lighting device (1), a smart home control server (2) and at least one smart terminal (3). The LED lighting device (1) includes an LED light-emitting module (21), a power supply module (22), a video acquisition module (23), a processing module (24) and a communication module (25). The video acquisition module (23) may be configured to collect video data within a camera detection range, and send the video data to the processing module (24). The processing module (24) controls the communication module (25) to send the video data to the smart home control server (2). The smart home control server (2) parses and recognizes the video data to detect behavioral information, generates control instructions according to the behavioral information, and sends the control instructions to the smart terminal (3). The system consistent with the present disclosure enables timely detection and prevention of illegal activities and/or unsafe behaviors, as well as recognition and execution of specified user instructions."
"Sound output system or internet appliance that supports voice activated commands, and that plays audio data received from a service over a network",https://lens.org/188-975-826-003-979,2018,"An output system, such as a wireless speaker or an Internet appliance, that supports voice activated commands is herein disclosed and enabled. The output system is wirelessly connectable to a service operated over a network (e.g., Internet) for receiving output data (e.g., music) from the service for outputting at the output system. The setup of the output system includes: (1) wirelessly discovering the output system using a smart phone, (2) establishing a wireless communication link between the smart phone and the output system (e.g., via Bluetooth or IEEE 802.11), and (3) providing information, such as security and/or authentication information, from the smart phone to the output system over the wireless communication link. Thereafter, the output system accesses the service operated over the network, and the outpt system is operabke to receive voice activated commands from a user while the output system is connected to the service."
"ROBOT, CONTROL UNIT, AND CONTROL METHOD",https://lens.org/192-807-383-216-095,2016,"A robot includes: an arm; and a controller that operates the arm, the controller generating a pathway according to a relative position and a relative orientation of: a first object that moves together with the arm; and a second object and according to a first position of the first object."
"Robot, control unit, and control method",https://lens.org/120-748-487-930-016,2018,"A robot includes: an arm; and a controller that operates the arm, the controller generating a pathway according to a relative position and a relative orientation of: a first object that moves together with the arm; and a second object and according to a first position of the first object."
COATING REPAIR APPLICATION SYSTEM USING REMOTELY PILOTED AIRCRAFT,https://lens.org/182-015-368-956-652,2023,"The present invention provides the use of a drone, or remotely piloted aircraft, equipped with a system for applying paint or industrial coating with epoxy paint and/or polyurethane.Coating repair application system using remotely piloted aircraft, characterized by comprising remotely piloted aircraft (9), a portable painting system (2), (5), (7) and (8), linear guide (4), distance sensors (10), camera (11), remote control (12), battery (1), lattice structure (3)."
UNMANNED AERIAL VEHICLE SUPERVISION METHOD AND DEVICE,https://lens.org/159-239-840-615-747,2021,"An unmanned aerial vehicle supervision method is provided. The method includes: An access network device receives a second broadcast request from a core network element, where the second broadcast request includes third management and control information and fourth management and control information for managing and controlling an unmanned aerial vehicle, and the fourth management and control information includes second area information; the access network device determines, based on the second area information, a target area for broadcasting, and broadcasts the third management and control information to the unmanned aerial vehicle in the target area, where the third management and control information is used to indicate the unmanned aerial vehicle to perform a corresponding operation."
AUTHORIZING AND CONFIGURING PAIRING OF UNMANNED AERIAL SYSTEM,https://lens.org/111-897-278-286-626,2022,"Apparatuses, methods, and systems are disclosed for authorizing and configuring pairing of unmanned aerial system. An apparatus includes a transceiver (625) that receives, at a first network function of a mobile wireless communication network, a first authorization of unmanned aerial vehicle (""UAV"") operations and a second authorization for associating a UAV-controller with the UAV, the first and second authorizations associated with a first identifier. An apparatus includes a processor (605) that creates a 5G local area network (""LAN"") group within the mobile wireless communication for facilitating communications between the UAV and the UAV-controller and associating a second identifier with the 5G LAN group, configures the 5G LAN group based on at least at least one parameter associated with the UAV and updates a third network function with information for the 5G LAN group for establishing a protocol data unit (""PDU"") session between the UAV and the UAV controller."
DRONE-CARRIED PROBE STABILIZATION VIA ELECTROMAGNETIC ATTACHMENT,https://lens.org/193-067-190-212-528,2019,A drone may be flown into proximity of a structure to measure one or more parameters of the structure. An electromagnet of the drone may be activated to electromagnetically attach the drone to the structure for inspection. A probe may be activated to inspect the structure by measuring one or more parameters of the structure.
"FLYING OBJECT, MOVING APPARATUS, CONTROL METHOD, AND STORAGE MEDIUM",https://lens.org/013-881-765-387-994,2019,There is provided a flying object including an image capturing apparatus. The flying object comprises a light emitting apparatus that includes a light source and is configured to cause the light source to emit light to indicate a status of the flying object. A light emission control unit controls the light emitting apparatus according to an exposure setting of the image capturing apparatus.
"APPARATUS, SYSTEM, AND METHOD FOR CONTROLLED INFRARED ILLUMINATOR",https://lens.org/000-603-297-511-680,2013,"An apparatus for a controlled infrared illuminator includes an unmanned aerial system capable of sustained flight and an infrared light source coupled to the unmanned aerial system by attachment means. The infrared light source includes a plurality of laser diodes arranged in a pattern. The apparatus also includes a remote control that controls either the movements of the unmanned aerial system, the position of the infrared light source, or both."
Interactive animated charater immediately after the title,https://lens.org/126-417-488-713-226,1993,"A system includes a control station for remotely controlling an animated character. Radio frequencies are used to transfer audio, video and other control signals to the animated character to provide speech, hearing, vision and practically any movement in real-time. A camera is used in the head of the animated character, and microphones are used in its ears to provide vision and hearing to a monitoring operator at the control station. A speaker is co-located with the animated character to generate sound from the operator. Servo control units are includes within the animated character to provide a plurality of body movements. Other aspects of the animated character includes a multi-layer skin composite to make it appear more life-like, and an audio driver circuit for controlling the mouth of the animated character in proportion to the level of an audio signal generated at the control station."
BIRD CONTROL DEVICE,https://lens.org/110-409-294-387-249,2003,"A bird control device, which has the appearance of a bird of prey, is disclosed. The device has various moveable parts and a synthetic bird call which can be remotely activated to animate the device and to simulate the behaviour of a real bird. In a preferred arrangement remote activation of the bird, as well as remote monitoring, is performed using a WAP enabled mobile phone."
Emergency deployable GPS antenna,https://lens.org/096-992-667-155-13X,2006,"The electronic device is for at least one of transmitting and receiving signals, has a housing 500 and at least a GPS (Global Positioning System) antenna 510 that is operatively connected to the housing 500 . A control system 708 automatically moves the GPS antenna 510 from a docked position relative to the housing 500 to a deployed position relative to the housing 500 in response to an occurrence of at least one predetermined event."
CONTROL SYSTEM FOR PROVIDING CLOUD BASED COMMANDS FOR CONTROLLING OPERATION OF A MOVEABLE BARRIER,https://lens.org/143-872-315-549-30X,2017,A control system for providing Cloud based commands to a garage door includes one or more Cloud servers for receiving commands from at least one mobile web enabled user device. A load balancer is used for receiving communication from a server for distributing commands from at least one web enabled device to the Cloud. A server based garage door opener is used for receiving commands and controlling operation of a garage door from the server. The status of the garage door is determined by measuring a distance of the garage door to the garage floor using a distance measuring device such that distance measuring information is communicated to the server for determining the open or closed status of the garage door before movement.
CONTROL SYSTEM FOR PROVIDING CLOUD BASED COMMANDS FOR CONTROLLING OPERATION OF A MOVEABLE BARRIER,https://lens.org/118-975-951-905-948,2016,A control system for providing Cloud based commands to a garage door includes one or more Cloud servers for receiving commands from at least one mobile web enabled user device. A load balancer is used for receiving communication from a server for distributing commands from at least one web enabled device to the Cloud. A server based garage door opener is used for receiving commands and controlling operation of a garage door from the server. The status of the garage door is determined by measuring a distance of the garage door to the garage floor using a distance measuring device such that distance measuring information is communicated to the server for determining the open or closed status of the garage door before movement.
Control system for providing cloud based commands for controlling operation of a moveable barrier,https://lens.org/150-555-549-973-642,2018,A control system for providing Cloud based commands to a garage door includes one or more Cloud servers for receiving commands from at least one mobile web enabled user device. A load balancer is used for receiving communication from a server for distributing commands from at least one web enabled device to the Cloud. A server based garage door opener is used for receiving commands and controlling operation of a garage door from the server. The status of the garage door is determined by measuring a distance of the garage door to the garage floor using a distance measuring device such that distance measuring information is communicated to the server for determining the open or closed status of the garage door before movement.
Control system for providing cloud based commands for controlling operation of a moveable barrier,https://lens.org/188-886-059-853-192,2017,A control system for providing Cloud based commands to a garage door includes one or more Cloud servers for receiving commands from at least one mobile web enabled user device. A load balancer is used for receiving communication from a server for distributing commands from at least one web enabled device to the Cloud. A server based garage door opener is used for receiving commands and controlling operation of a garage door from the server. The status of the garage door is determined by measuring a distance of the garage door to the garage floor using a distance measuring device such that distance measuring information is communicated to the server for determining the open or closed status of the garage door before movement.
Systems and methods for creating wireless aerial traffic corridors,https://lens.org/046-274-730-442-263,2021,A device may receive information indicating one or more parameters associated with one or more antenna arrays in a radio access network. The device may receive a flight request that indicates one or more conditions for a flight path of an unmanned aerial vehicle (UAV) seeking network access to the radio access network. The device may determine waypoints for the flight path based on analyzing the one or more parameters associated with the one or more antenna arrays and the one or more conditions for the flight path of the UAV. The device may transmit information identifying the waypoints for the flight path. The device may send control information to cause the one or more antenna arrays to form a corresponding one or more beams along the flight path to enable the UAV to traverse the flight path with the network access to the radio access network.
SYSTEMS AND METHODS FOR CREATING WIRELESS AERIAL TRAFFIC CORRIDORS,https://lens.org/024-619-334-838-154,2021,A device may receive information indicating one or more parameters associated with one or more antenna arrays in a radio access network. The device may receive a flight request that indicates one or more conditions for a flight path of an unmanned aerial vehicle (UAV) seeking network access to the radio access network. The device may determine waypoints for the flight path based on analyzing the one or more parameters associated with the one or more antenna arrays and the one or more conditions for the flight path of the UAV. The device may transmit information identifying the waypoints for the flight path. The device may send control information to cause the one or more antenna arrays to form a corresponding one or more beams along the flight path to enable the UAV to traverse the flight path with the network access to the radio access network.
Two ways fishing line release equipment for uav,https://lens.org/038-493-565-795-689,2020,"The present disclosure discloses the fishing line release equipment and the method of the line release based on the widely used drone or UAV(Unmanned Aerial Vehicle). In order to protect the drone safely flying to the destination and facilitate fishing line release in a more convenient way, the fishing line release equipment comprises a base and a release wire, said base fixing a mechanical clip release and the electrical power controlled action that release a release wire in a clamp. A controller board and a battery are fixed on the base. A cover box covers the base and electrical part are protected by the cover box. The base is fixed on the drone or UAV, one end of the release wire clamping to a gap slot in the tube that is a part of the base, the other end of the release wire connecting to the main fishing line. The clamp force can be adjusted through the nuts in the ends of tube which adjust a spring tension acting on two ball bearings which are pressed together to form a clamp in order to hold the release wire up to a pre-selected force. The release wire is clamped in the slot between the two ball bearings and the release wire is released when the pulling force coming from the fishing line excesses a threshold of a release force of the clamp.Each time a control key is pressed, an electrical motor makes a dial pad turn around, and a dial pin fixed on the dial pad pass through the gap, enforcing the two ball bearings to become separated and therefore allowing selective release of the release wire. A control signal can be supplied by a remote controller or a photoelectric switch or a signal output from the drone."
A backup navigation system for unmanned aerial vehicles,https://lens.org/064-187-271-259-490,2021,"Described is a method that involves operating an unmanned aerial vehicle (UAV) (300) to begin a flight, where the UAV (300) relies on a navigation system to navigate to a destination. During the flight, the method involves operating a camera (304) to capture images (420) of the UAV's environment, and analyzing the images to detect features in the environment. The method also involves establishing a correlation between features detected in different images, and using location information from the navigation system to localize a feature detected in different images. Further, the method involves generating a flight log that includes the localized feature. Also, the method involves detecting a failure involving the navigation system, and responsively operating the camera (304) to capture a post-failure image. The method also involves identifying one or more features in the post-failure image, and determining a location of the UAV (300) based on a relationship between an identified feature and a localized feature."
A BACKUP NAVIGATION SYSTEM FOR UNMANNED AERIAL VEHICLES,https://lens.org/058-558-166-923-014,2019,"Described is a method that involves operating an unmanned aerial vehicle (UAV) (300) to begin a flight, where the UAV (300) relies on a navigation system to navigate to a destination. During the flight, the method involves operating a camera (304) to capture images (420) of the UAV's environment, and analyzing the images to detect features in the environment. The method also involves establishing a correlation between features detected in different images, and using location information from the navigation system to localize a feature detected in different images. Further, the method involves generating a flight log that includes the localized feature. Also, the method involves detecting a failure involving the navigation system, and responsively operating the camera (304) to capture a post-failure image. The method also involves identifying one or more features in the post-failure image, and determining a location of the UAV (300) based on a relationship between an identified feature and a localized feature."
A backup navigation system for unmanned aerial vehicles,https://lens.org/176-503-062-561-792,2020,"Described is a method that involves operating an unmanned aerial vehicle (UAV) (300) to begin a flight, where the UAV (300) relies on a navigation system to navigate to a destination. During the flight, the method involves operating a camera (304) to capture images (420) of the UAV's environment, and analyzing the images to detect features in the environment. The method also involves establishing a correlation between features detected in different images, and using location information from the navigation system to localize a feature detected in different images. Further, the method involves generating a flight log that includes the localized feature. Also, the method involves detecting a failure involving the navigation system, and responsively operating the camera (304) to capture a post-failure image. The method also involves identifying one or more features in the post-failure image, and determining a location of the UAV (300) based on a relationship between an identified feature and a localized feature."
Aquatic sports target drone,https://lens.org/050-927-684-645-165,2015,"The utility model discloses an aquatic sports target drone, including raft, target plate and target drone master control system, this target drone master control system includes propulsion system, and this propulsion system includes stroke detection module, a drive circuit and screw motor, and this stroke detection module electricity is connected system master control circuit's input, drive circuit electricity is connected system master control circuit's output, screw motor electricity is connected a drive circuit's control end, the transmission is connected with the screw on the output shaft of this screw motor. This novel aquatic sports target drone realizes the target function of establishing wantonly on water to this has broken away from the backward mode that need carry and adjust in the past the target drone position by ship, more saves a large amount of manpowers, material resources and time, reduces the support personnel of gunnery training, improves firing practice's security."
SYSTEMS AND METHODS FOR DETERMINING THE POSITION OF AN OBJECT USING AN UNMANNED AERIAL VEHICLE,https://lens.org/037-474-736-665-37X,2023,"An unmanned aerial vehicle (UAV) may have a positional sensor and an image sensor. The UAV may receive from an electronic structure a first wireless signal. The first wireless signal may include a first direction of illumination. In accordance with the first wireless signal, the UAV may identify a target object based, at least in part, on the first direction of illumination. The UAV may also determine positional coordinates of the target object."
Apparatus and method for the automatic control of an aerial photographic camera,https://lens.org/058-268-592-622-737,1986,"Method and apparatus for automatically controlling aerial photographic cameras. An exact and reliable control device of low electronic and optical cost, which unburdens the operator, is realized by means of two photoreceiver lines positioned parallel to each other and perpendicular to the flight direction. At least the first line is connected to a data memory, which as well as the second line is connected to a correlator. The correlator is connected, via units for calculating the vg/hg ratio and/or the drift, to setting mechanisms of the aerial camera. A third photoreceiver line can also be provided, coupled subsequently to a data memory. The invention is utilizable in photogrammetry."
DRONE-HOSTED CONSTRUCTION DEFECT MARKING,https://lens.org/066-263-887-671-04X,2022,"A system includes processing circuitry and a drone that includes a marking mount that receives a marking device, a motion guide that provides a sliding framework for a reciprocating motion of the marking mount, and a shock absorption sub-assembly positioned between the marking mount and the motion guide. Control logic of the drone is configured to navigate, based on navigation instructions received from the processing circuitry, the drone to an area associated with a misapplication of a tape as applied to a substrate or a substrate defect, such that a distal tip of the marking device makes contact with the area associated with the tape misapplication or the substrate defect, while activating the shock absorption sub-assembly to at least partially absorb a shock caused by the contact between the distal tip of the marking device and the area associated with the tape misapplication or the substrate defect."
DRONE-HOSTED CONSTRUCTION DEFECT MARKING,https://lens.org/066-263-887-671-04X,2022,"A system includes processing circuitry and a drone that includes a marking mount that receives a marking device, a motion guide that provides a sliding framework for a reciprocating motion of the marking mount, and a shock absorption sub-assembly positioned between the marking mount and the motion guide. Control logic of the drone is configured to navigate, based on navigation instructions received from the processing circuitry, the drone to an area associated with a misapplication of a tape as applied to a substrate or a substrate defect, such that a distal tip of the marking device makes contact with the area associated with the tape misapplication or the substrate defect, while activating the shock absorption sub-assembly to at least partially absorb a shock caused by the contact between the distal tip of the marking device and the area associated with the tape misapplication or the substrate defect."
"SOUND OUTPUT SYSTEM OR INTERNET APPLIANCE THAT SUPPORTS VOICE ACTIVATED COMMANDS, AND THAT PLAYS AUDIO DATA RECEIVED FROM A SERVICE OVER A NETWORK",https://lens.org/174-552-968-535-097,2017,"An output system, such as a wireless speaker or an Internet appliance, that supports voice activated commands is herein disclosed and enabled. The output system is wirelessly connectable to a service operated over a network (e.g., Internet) for receiving output data from the service. The setup of the output system includes: (1) wirelessly discovering the output system using a smart phone, (2) establishing a wireless communication link between the smart phone and the output system (e.g., via Bluetooth); (4) provide information, such as security and/or authentication information, from the smart phone to the output system via the wireless communication link. Thereafter, the output system, using the information received from the smart phone, establishes a wireless local area network connection and also connects itself to the service over the network. The output system is operable to receive voice activated commands from the user when connected to the service."
Unmanned aerial vehicle system and method of use,https://lens.org/146-761-865-053-664,2018,"An unmanned aerial vehicle (UAV) system includes a command center having a computing device an unmanned aerial vehicle (UAV) with a body, the UAV to communicate wirelessly with the command center via a network, the UAV having a control system with a power source, a geospatial tracking device, and a multi-channel communication portal; a camera secured to the body and in communication with the control system; and one or more equipment attachment sites; site assessment tools to attach to or within the one or more equipment attachment sites, each of the site assessment tools to record a data associated with an emergency site, such as weather conditions, road conditions, traffic, visibility, radiation, and chemical exposure; the UAV is to receive commands from the command center to deploy to the emergency site; and the UAV is to receive the data and transmit the data to the command center via the multi-channel communication portal."
"Robot, robot control method, and recording medium",https://lens.org/148-892-346-019-715,2022,"A robot is equipped with a processor. The processor detects external appearance or audio of a living being, and by controlling the robot, causes the robot to execute an operation in accordance with liking data indicating preferences of the robot regarding external appearance or audio and the detected external appearance or audio of the living being."
"ROBOT, ROBOT CONTROL METHOD, AND RECORDING MEDIUM",https://lens.org/096-129-249-885-44X,2023,"A robot is equipped with a processor. The processor detects external appearance or audio of a living being, and by controlling the robot, causes the robot to execute an operation in accordance with liking data indicating preferences of the robot regarding external appearance or audio and the detected external appearance or audio of the living being."
"ROBOT, ROBOT CONTROL METHOD, AND RECORDING MEDIUM",https://lens.org/172-239-419-074-933,2019,"A robot is equipped with a processor. The processor detects external appearance or audio of a living being, and by controlling the robot, causes the robot to execute an operation in accordance with liking data indicating preferences of the robot regarding external appearance or audio and the detected external appearance or audio of the living being."
"Robot, robot control method, and recording medium",https://lens.org/148-892-346-019-715,2022,"A robot is equipped with a processor. The processor detects external appearance or audio of a living being, and by controlling the robot, causes the robot to execute an operation in accordance with liking data indicating preferences of the robot regarding external appearance or audio and the detected external appearance or audio of the living being."
"ROBOT, ROBOT CONTROL METHOD, AND RECORDING MEDIUM",https://lens.org/096-129-249-885-44X,2023,"A robot is equipped with a processor. The processor detects external appearance or audio of a living being, and by controlling the robot, causes the robot to execute an operation in accordance with liking data indicating preferences of the robot regarding external appearance or audio and the detected external appearance or audio of the living being."
Systems And Methods For Assisting A Delivery Robot,https://lens.org/089-553-254-325-569,2022,"This disclosure is generally directed to using a building security system to provide assistance to a delivery robot. In one example implementation, a communication system provided in the delivery robot communicates with the building security system to obtain information pertaining to a terrain between the autonomous vehicle and a package drop-off spot at the building. The information may be provided in the form of an image captured by a camera located on the premises of the building. In one case, the delivery robot may identify a landmark in the image and use the landmark to navigate to the package drop-off spot. In another case, the delivery robot may use the image to generate a route map for traveling to the drop-off spot. In yet another case, the delivery robot may match and/or compare the image to a reference image or a topographical map to navigate to the package drop-off spot."
Robot system having augmented reality-compatible display,https://lens.org/111-917-426-624-603,2018,"A robot system using an augmented reality-compatible display, capable of providing information on the status and/or an operation guide of a robot added to an actual image or actual environment, to a user of the robot, so as to improve the efficiency of operations carried out by the user. The robot system includes an actual robot, a controller which controls the actual robot, and an image capturing-displaying device connected to the controller by a wire or by radio. The image capturing-displaying device has a function for capturing an image of a scene including the actual robot and a function for displaying the captured image in real-time. The user can obtain a scene including the actual robot in real-time by directing a camera arranged on the image capturing-displaying device toward the actual robot, and can monitor an augmented reality image."
ROBOT SYSTEM HAVING AUGMENTED REALITY-COMPATIBLE DISPLAY,https://lens.org/167-261-519-649-597,2016,"A robot system using an augmented reality-compatible display, capable of providing information on the status and/or an operation guide of a robot added to an actual image or actual environment, to a user of the robot, so as to improve the efficiency of operations carried out by the user. The robot system includes an actual robot, a controller which controls the actual robot, and an image capturing-displaying device connected to the controller by a wire or by radio. The image capturing-displaying device has a function for capturing an image of a scene including the actual robot and a function for displaying the captured image in real-time. The user can obtain a scene including the actual robot in real-time by directing a camera arranged on the image capturing-displaying device toward the actual robot, and can monitor an augmented reality image."
Lock apparatus and related methods for use with drones,https://lens.org/153-604-464-432-035,2023,"Lock apparatus and related methods for use with drones are disclosed. A disclosed drone assembly includes a wing, a keel-beam, an adapter positioned on an end of the keel-beam, and a lock configured to receive the adapter. The lock includes a first lock portion coupled to the wing and a second lock portion rotatable relative to the first lock portion between a first position and a second position. The lock is configured to (a) couple the keel-beam to the wing when the second lock portion is in the second position and (b) decouple the keel-beam from the wing when the second lock portion is in the first position."
Lock apparatus and related methods for use with drones,https://lens.org/153-604-464-432-035,2023,"Lock apparatus and related methods for use with drones are disclosed. A disclosed drone assembly includes a wing, a keel-beam, an adapter positioned on an end of the keel-beam, and a lock configured to receive the adapter. The lock includes a first lock portion coupled to the wing and a second lock portion rotatable relative to the first lock portion between a first position and a second position. The lock is configured to (a) couple the keel-beam to the wing when the second lock portion is in the second position and (b) decouple the keel-beam from the wing when the second lock portion is in the first position."
LOCK APPARATUS AND RELATED METHODS FOR USE WITH DRONES,https://lens.org/167-965-874-031-068,2021,"Lock apparatus and related methods for use with drones are disclosed. A disclosed drone assembly includes a wing, a keel-beam, an adapter positioned on an end of the keel-beam, and a lock configured to receive the adapter. The lock includes a first lock portion coupled to the wing and a second lock portion rotatable relative to the first lock portion between a first position and a second position. The lock is configured to (a) couple the keel-beam to the wing when the second lock portion is in the second position and (b) decouple the keel-beam from the wing when the second lock portion is in the first position."
FLYING CAMERA AND A SYSTEM,https://lens.org/069-292-018-039-765,2020,"There is provided a control device including an image display unit configured to acquire, from a flying body, an image captured by an imaging device provided in the flying body and to display the, image, and a flight instruction generation unit configured to generate a flight instruction for the flying body based on content of an operation performed with respect to the image captured by the imaging device and displayed by the image display unit."
Jet-pump operated autonomous underwater vehicle and method for coupling to ocean bottom during marine seismic survey,https://lens.org/197-823-882-930-762,2015,"An autonomous underwater vehicle (AUV) for recording seismic signals during a marine seismic survey. The AUV includes a body having a head part and a tail part); a propulsion system for guiding the AUV to a final target on the ocean bottom; a jet pump group connected to the body and including plural jet pumps; a control device connected to the jet pumps; and a seismic sensor configured to record seismic signals. The jet pump group controls a steering of the AUV by generating water jets according to a given sequence, for proper contact with the bottom."
JET-PUMP OPERATED AUTONOMOUS UNDERWATER VEHICLE AND METHOD FOR COUPLING TO OCEAN BOTTOM DURING MARINE SEISMIC SURVEY,https://lens.org/054-661-580-936-128,2014,"An autonomous underwater vehicle (AUV) for recording seismic signals during a marine seismic survey. The AUV includes a body having a head part and a tail part); a propulsion system for guiding the AUV to a final target on the ocean bottom; a jet pump group connected to the body and including plural jet pumps; a control device connected to the jet pumps; and a seismic sensor configured to record seismic signals. The jet pump group controls a steering of the AUV by generating water jets according to a given sequence, for proper contact with the bottom."
OMNIDIRECTIONAL FLYING VISUAL APPARATUS,https://lens.org/085-183-460-050-251,2018,"An omnidirectional flying apparatus for displaying video content and static signage to grab attention, interact with people, and convey messages. A flight system including an unmanned aerial vehicle having a plurality of individually rotatable propellers configured to provide thrust and enable the apparatus to fly is mounted on a structural assembly. The structural assembly is configured to hold an array of signage providing a 360 degree visual display. The apparatus provides lightweight screens utilizing at least one projector to display the video content. At least one input/output device is configured to enable a user to program a flight path of the unmanned aerial vehicle and select video content to be displayed."
"Method and Apparatus for Controlling Device, Smart Home Device, System, and Storage Medium",https://lens.org/081-833-783-516-526,2022,"The present application relates to a method and an apparatus for controlling a device, a smart home device and system and a storage medium the device may be a lighting device. The method for controlling a device comprises: receiving a data stream including data for playing audio; acquiring reference data corresponding to a device control command controlling the device to perform one or more functions; determining whether at least a portion of the data in the data stream matches the reference data; and controlling, in case at least a portion of the data in the data stream matches the reference data, the device to perform one or more of the functions according to the corresponding device control command."
"Method and Apparatus for Controlling Device, Smart Home Device, System, and Storage Medium",https://lens.org/081-833-783-516-526,2022,"The present application relates to a method and an apparatus for controlling a device, a smart home device and system and a storage medium the device may be a lighting device. The method for controlling a device comprises: receiving a data stream including data for playing audio; acquiring reference data corresponding to a device control command controlling the device to perform one or more functions; determining whether at least a portion of the data in the data stream matches the reference data; and controlling, in case at least a portion of the data in the data stream matches the reference data, the device to perform one or more of the functions according to the corresponding device control command."
"Method and apparatus for controlling device, smart home device, system, and storage medium",https://lens.org/177-802-042-968-719,2023,"The present application relates to a method and an apparatus for controlling a device, a smart home device and system and a storage medium the device may be a lighting device. The method for controlling a device comprises: receiving a data stream including data for playing audio; acquiring reference data corresponding to a device control command controlling the device to perform one or more functions; determining whether at least a portion of the data in the data stream matches the reference data; and controlling, in case at least a portion of the data in the data stream matches the reference data, the device to perform one or more of the functions according to the corresponding device control command."
"METHOD AND APPARATUS FOR CONTROLLING DEVICE, SMART PHONE DEVICE, SYSTEM, AND STORAGE MEDIUM",https://lens.org/189-684-807-766-029,2022,"The present application relates to a method and an apparatus for controlling a device, a smart home device and system and a storage medium the device may be a lighting device. The method for controlling a device comprises: receiving a data stream including data for playing audio; acquiring reference data corresponding to a device control command controlling the device to perform one or more functions; determining whether at least a portion of the data in the data stream matches the reference data; and controlling, in case at least a portion of the data in the data stream matches the reference data, the device to perform one or more of the functions according to the corresponding device control command."
"Agent device, method for controlling agent device, and storage medium",https://lens.org/085-451-234-348-568,2022,"An agent device is equipped with a plurality of agent controllers which provide a service including causing an output device to output a response of voice in accordance with an utterance of an occupant of a vehicle, in which a first agent controller included in the plurality of agent controllers provides an agent controller different from the first agent controller with first service information on the service to be provided to the occupant."
"AGENT DEVICE, METHOD FOR CONTROLLING AGENT DEVICE, AND STORAGE MEDIUM",https://lens.org/066-366-537-490-494,2020,"An agent device is equipped with a plurality of agent controllers which provide a service including causing an output device to output a response of voice in accordance with an utterance of an occupant of a vehicle, in which a first agent controller included in the plurality of agent controllers provides an agent controller different from the first agent controller with first service information on the service to be provided to the occupant."
"Agent device, method for controlling agent device, and storage medium",https://lens.org/085-451-234-348-568,2022,"An agent device is equipped with a plurality of agent controllers which provide a service including causing an output device to output a response of voice in accordance with an utterance of an occupant of a vehicle, in which a first agent controller included in the plurality of agent controllers provides an agent controller different from the first agent controller with first service information on the service to be provided to the occupant."
Surveying System,https://lens.org/018-835-388-144-667,2022,"Provided is a surveying system comprising a flying vehicle system which is configured to perform a remote control and include a flying vehicle and a measuring instrument, a position measuring instrument configured to measure a position of the flying vehicle system, and a remote controller configured to control the flying of the flying vehicle system and to wirelessly communicate with the flying vehicle system and the position measuring instrument, in which the remote controller is configured to fly the flying vehicle system to a desired structure, measure an object surface by the measuring instrument, and convert a measurement result of the object surface into a measurement result with reference to the position measuring instrument."
Surveying System,https://lens.org/018-835-388-144-667,2022,"Provided is a surveying system comprising a flying vehicle system which is configured to perform a remote control and include a flying vehicle and a measuring instrument, a position measuring instrument configured to measure a position of the flying vehicle system, and a remote controller configured to control the flying of the flying vehicle system and to wirelessly communicate with the flying vehicle system and the position measuring instrument, in which the remote controller is configured to fly the flying vehicle system to a desired structure, measure an object surface by the measuring instrument, and convert a measurement result of the object surface into a measurement result with reference to the position measuring instrument."
Marine surface drone and method for characterising an underwater environment implemented by such a drone,https://lens.org/189-281-350-443-767,2020,"The invention relates to a marine surface drone (1) comprising: - an on-board multi-beam sonar (10); - a system (41) for controlling the sonar, configured to command, for a given position of the drone, a plurality of consecutive emissions of acoustic waves, the control system controlling the sonar emitters (12) so as to vary the characteristics of the emitted acoustic waves, from one of said emissions to the next, and - an acquisition unit (42) configured to determine, from echo signals acquired in response to said plurality of emissions, a three-dimensional image representing the content of a given observation volume. The invention also relates to a method for characterising an underwater environment, implemented by such a drone. Figure"
"CONTROL DEVICE, CONTROL METHOD, AND STREETLIGHT",https://lens.org/073-400-824-573-583,2022,A control device includes a control unit configured to acquire an image of a subject which is captured by a terminal device and to control at least one streetlight which is provided near the terminal device based on the acquired image.
"AUTOROTATING AERIAL DEVICE, METHOD OF FORMING THE AUTOROTATING AERIAL DEVICE AND AN AUTOROTATING AERIAL SYSTEM",https://lens.org/058-298-877-449-189,2021,"There is provided an autorotating aerial device which includes a housing member having disposed thereon an actuator and a controller configured to control the actuator; and a wing member coupled to the actuator, the wing member including a main wing portion and a flap portion adjustable with respect to the main wing portion. The controller is configured to control the actuator to switch the autorotating aerial device between a diving mode of operation and an autorotating mode of operation based on adjusting an angle of attack of the flap portion, the angle of attack being with respect to a lateral axis along the main wing portion. There is also provided a method of forming the autorotating aerial device and an autorotating aerial system including two or more autorotating aerial devices."
Apparatus for recognizing and approaching a three-dimensional target,https://lens.org/082-744-706-826-40X,1990,An apparatus for recognizing and approaching a target in a space not directly visible within the maximum range of an industrial robot with camera on the end of a boom. The camera is used to observe an environment of the space including the target and to send images to a monitor at a remote control station. The apparatus includes an industrial robot with a plurality of axes having degrees of freedom and a camera with a lens having an optical axis which can be selectively rotated 360 degrees around a first axis and selectively pivoted 180 degrees around a second axis that is perpendicular to the first axis. The rotating and pivoting motions are used to move the camera and the optical axis until the target can be seen in the monitor. A system is used to control various movements of the robot while sensing and maintaining the camera position and the target direction during movement of the end of the boom from the robot to the target.
"UAVS, INCLUDING MULTI-PROCESSOR UAVS WITH SECURED PARAMETERS, AND ASSOCIATED SYSTEMS, DEVICES, AND METHODS",https://lens.org/181-514-028-416-465,2021,"Unmanned aerial vehicles (UAVs), including multi-processor UAVs with secured parameters, and associated systems, devices, and methods are disclosed herein. In one embodiment, a UAV includes a flight controller configured to control flight operations of the UAV based at least in part on system parameters provided to the UAV. The UAV can additionally include an oversight processor configured to (i) monitor operations of the flight controller and (ii) intercede when the oversight processor determines the flight controller is operating in violation of the system parameters. In some embodiments, the system parameters are secured (e.g., digitally signed and/or encrypted) and provided to the UAV. In these and other embodiments, the UAV is configured to verify the secure systems parameters and/or to autonomously execute a flight plan after verifying the system parameters. In some embodiments, the system parameters define an operational envelope specifying airspace to which autonomous flight of the UAV is constrained."
SYSTEM AND METHOD FOR THE AUTONOMOUS TRANSITION OF AN ELECTRIC VERTICAL TAKEOFF AND LANDING AIRCRAFT,https://lens.org/091-083-594-182-005,2023,"A system for autonomous flight of an electric vertical takeoff and landing (eVTOL) aircraft. The system may include a pusher component, a lift component, a flight controller, and a pilot override switch. The pusher component is mechanically coupled to the eVTOL aircraft. The lift component is mechanically coupled to the eVTOL aircraft. The flight controller is communicatively connected to the pilot override switch. The flight controller is configured to identify a transition point, initiate operation of the pusher component, and terminate operation of the lift component. A method for flight control of an eVTOL aircraft is also provided."
SYSTEM AND METHOD FOR THE AUTONOMOUS TRANSITION OF AN ELECTRIC VERTICAL TAKEOFF AND LANDING AIRCRAFT,https://lens.org/091-083-594-182-005,2023,"A system for autonomous flight of an electric vertical takeoff and landing (eVTOL) aircraft. The system may include a pusher component, a lift component, a flight controller, and a pilot override switch. The pusher component is mechanically coupled to the eVTOL aircraft. The lift component is mechanically coupled to the eVTOL aircraft. The flight controller is communicatively connected to the pilot override switch. The flight controller is configured to identify a transition point, initiate operation of the pusher component, and terminate operation of the lift component. A method for flight control of an eVTOL aircraft is also provided."
System and method for the autonomous transition of an electric vertical takeoff and landing aircraft,https://lens.org/121-213-221-739-754,2022,"A system for autonomous flight of an electric vertical takeoff and landing (eVTOL) aircraft. The system may include a pusher component, a lift component, a flight controller, and a pilot override switch. The pusher component is mechanically coupled to the eVTOL aircraft. The lift component is mechanically coupled to the eVTOL aircraft. The flight controller is communicatively connected to the pilot override switch. The flight controller is configured to identify a transition point, initiate operation of the pusher component, and terminate operation of the lift component. A method for flight control of an eVTOL aircraft is also provided."
System and method for the autonomous transition of an electric vertical takeoff and landing aircraft,https://lens.org/121-213-221-739-754,2022,"A system for autonomous flight of an electric vertical takeoff and landing (eVTOL) aircraft. The system may include a pusher component, a lift component, a flight controller, and a pilot override switch. The pusher component is mechanically coupled to the eVTOL aircraft. The lift component is mechanically coupled to the eVTOL aircraft. The flight controller is communicatively connected to the pilot override switch. The flight controller is configured to identify a transition point, initiate operation of the pusher component, and terminate operation of the lift component. A method for flight control of an eVTOL aircraft is also provided."
REMOTELY MANAGING HEALTHCARE UTILIZING PERSONAL ASSISTANT DEVICES,https://lens.org/058-593-073-286-494,2020,"Systems and methods for utilizing personal assistant devices to remotely manage healthcare are presented. In some aspects a personal assistant device associated with a patient (e.g., an AMAZON ECHO or a GOOGLE HOME device) is utilized to audibly output at least one instruction to be performed by the patient. In aspects, the instruction is to be performed by the user utilizing a connected health marker monitoring device. Upon the patient performing the instruction, for instance, upon a measurement being received from the connected health marker monitoring device, the result of the instruction (e.g., the measurement) is transmitted to one or more of an electronic health information system for association with the patient's healthcare records, a device associated with a member of a care team associated with the patient, a data store, and a control component for further evaluation."
"ROBOT, CONTROL APPARATUS AND ROBOT SYSTEM",https://lens.org/075-550-926-018-456,2016,"A robot includes a casing, a first arm unit and a second arm unit provided on the casing, a first board that outputs a current command signal, a second board that controls an actuator for driving the first arm unit based on the current command signal, and a third board that controls an actuator for driving the second arm unit based on the current command signal. The second board and the third board are provided inside of the casing."
APPARATUS AND METHOD FOR INSTALLING AND REPLACING LIGHT FIXTURE DEVICES,https://lens.org/127-377-448-891-303,2020,"Provided is a method and an apparatus for installing and replacing a lighting controller of an outdoor lighting fixture that includes a base portion supplying power, a telescopic stick portion attached to the base portion at a first end thereof, an extension stick portion attached to a second end of the telescopic stick portion, and a drone-type device attached to the extension stick portion at an end opposite telescopic stick portion. The drone-type device receives power from the base portion through the telescopic stick portion and travels over and land at a top surface of the outdoor lighting fixture and perform installation or replacement of the lighting controller."
APPARATUS AND METHOD FOR INSTALLING AND REPLACING LIGHT FIXTURE DEVICES,https://lens.org/030-938-375-648-213,2020,"Provided is a method and an apparatus for installing and replacing a lighting controller of an outdoor lighting fixture that includes a base portion supplying power, a telescopic stick portion attached to the base portion at a first end thereof, an extension stick portion attached to a second end of the telescopic stick portion, and a drone-type device attached to the extension stick portion at an end opposite telescopic stick portion. The drone-type device receives power from the base portion through the telescopic stick portion and travels over and land at a top surface of the outdoor lighting fixture and perform installation or replacement of the lighting controller."
APPARATUS AND METHOD FOR INSTALLING AND REPLACING LIGHT FIXTURE DEVICES,https://lens.org/071-331-307-079-844,2020,"Provided is a method and an apparatus for installing and replacing a lighting controller of an outdoor lighting fixture that includes a base portion supplying power, a telescopic stick portion attached to the base portion at a first end thereof, an extension stick portion attached to a second end of the telescopic stick portion, and a drone-type device attached to the extension stick portion at an end opposite telescopic stick portion. The drone-type device receives power from the base portion through the telescopic stick portion and travels over and land at a top surface of the outdoor lighting fixture and perform installation or replacement of the lighting controller."
Voice-controlled tractor-mounted loader,https://lens.org/081-249-089-849-694,2002,A tractor is equipped with a front end loader including a boom mounted for being raised and lowered through the operation of a pair of hydraulic boom motors having a bucket attached to the arms thereof for being rocked about an axis of connection by a hydraulic bucket motor. A control system includes manual controls for controlling operation of the boom and bucket motors. The control system also includes a speech recognition device that is programmed for recognizing the speech of authorized operators and for sending signals responsive to certain command words for effecting desired control of the boom and bucket motors.
Speaker system,https://lens.org/052-431-403-994-881,1978,"A speaker system comprising a speaker unit, a drone cone driven by the speaker unit; and a removable weight loaded on the front of the drone cone which can be exchanged from the front of the drone cone."
DROPPING MECHANISM WITH UNIVERSAL MOUNTING POINTS,https://lens.org/142-671-483-216-232,2018,"A dropping mechanism with universal mounting points includes a device for securing a payload to a drone, mechanically releasing it and mounting additional accessories that can be used during flight. The dropping mechanism can be attached to either the landing gear or body of the drone, in an orientation that allows contact between the release trigger and the drone's camera. A notch and groove system holds a sliding restraint in place, keeping the payload secure during flight. Once the release trigger is pushed, an energized member pulls the sliding restraint allowing the payload to drop. Since the camera is pointed down to actuate the trigger, the user can watch as the payload falls to the ground. The use of a mechanical dropping system makes this device compatible with drones that only have an electrical connection for the camera. Universal mounting points allow attachment of a wide variety of accessories."
Air straight flow type drone,https://lens.org/014-569-404-259-348,2015,"The utility model discloses an air straight flow type drone, comprising a drone body, a rotor wing spindle and a propeller clip pin shaft; the drone also comprises an engine fixed in the drone body; the engine comprises at least one cylinder provided with an exhaust port in one side, a cylinder body detachably connected with the cylinder, an air inlet valve detachably connected with the cylinder body, and an air filter fixed at the bottom of the drone body; the air filter comprises a venting slot fixed in the bottom of the drone body, a filter net fixed in the venting slot and a rectifying shield of which one end is fixedly connected with the air inlet valve and the other end is fixedly connected with the venting slot in order that air flows into the air inlet valve by the filter net and the rectifying shield in sequence."
METHOD AND APPARATUS FOR POWER CONSERVATION FOR AN ELECTRONIC DEVICE,https://lens.org/021-335-778-674-767,2010,"An apparatus comprises a first interface module configured to wirelessly interface with one or more user devices; a second interface module configured to interface with a wireless communication network; and a controller. The controller is configured to detect a signal received through the second interface module, the signal including a command; and execute the command. Executing the command causes one or more components of the apparatus to exit a power conservation mode and enter a full operation mode."
AUTONOMOUS UNDERWATER VEHICLE FOR MARINE SEISMIC SURVEYS,https://lens.org/177-314-587-392-198,2014,"An autonomous underwater vehicle (AUV) for recording seismic signals during a marine seismic survey. The AUV (200) includes a body (204) having a flush shape; a buoyancy system (202) located inside the body and configured to control a buoyancy of the AUV while traveling underwater; a processor (108) connected to the buoyancy system and configured to select one of plural phases for the buoyancy system at different times of the seismic survey, wherein the plural phases include a neutral buoyancy, a positive buoyancy and a negative buoyancy; and a seismic sensor (110) for recording seismic signals."
REMOTELY OPERABLE USER CONTROLLED PET ENTERTAINMENT DEVICE,https://lens.org/120-060-370-702-348,2009,"A pet entertainment device that is also capable of exercising a pet, such as a cat, via user interaction with the device using a remote control that enables user control of motion of a pet plaything/attractant in or along two degrees of freedom. The device includes a base that rests on a floor that carries a housing rotatable relative thereto enabling corresponding plaything/attractant movement in response to a first user manipulable control of the remote. The housing includes a plaything/attractant carrier, such as a wand, that is movable relative to the housing, the base, and the floor in response to a second user manipulable control of the remote. The device includes a housing rotation drive and a wand drive connected to an electrical power supply and onboard controller that receives wireless control signals from the user-manipulable remote control and carries out user- initiated movement commands inputted into the remote."
Autonomous all-terrain vehicle (ATV),https://lens.org/031-946-791-267-571,2020,"According to one aspect, an autonomous all-terrain vehicle (ATV) includes a controller, a location unit, a navigation module, and a drive controller. The controller receives a remember path command and in response, the location unit determines a location associated with the autonomous ATV and a path being travelled by a leader device. The navigation module determines a first route for the autonomous ATV based on the path being travelled by the leader device and stores the first route for the autonomous ATV as a first preset route based on the received remember path command. The navigation module determines a second route for the autonomous ATV based on the received recall path command and the stored first preset route. The controller controls a drive controller of the autonomous ATV based on the determined second route."
AUTONOMOUS ALL-TERRAIN VEHICLE (ATV),https://lens.org/145-601-346-645-044,2019,"According to one aspect, an autonomous all-terrain vehicle (ATV) includes a controller, a location unit, a navigation module, and a drive controller. The controller receives a remember path command and in response, the location unit determines a location associated with the autonomous ATV and a path being travelled by a leader device. The navigation module determines a first route for the autonomous ATV based on the path being travelled by the leader device and stores the first route for the autonomous ATV as a first preset route based on the received remember path command. The navigation module determines a second route for the autonomous ATV based on the received recall path command and the stored first preset route. The controller controls a drive controller of the autonomous ATV based on the determined second route."
"ELECTRONIC APPARATUS, CONTROL METHOD THEREOF, COMPUTER PROGRAM, AND COMPUTER-READABLE RECORDING MEDIUM",https://lens.org/118-239-900-423-927,2016,Disclosed herein is a control method of an electronic apparatus. The control method of an electronic apparatus includes: detecting a crosswalk from an image data photographed in a camera during a period in which a vehicle is operated; generating an object indicating the detected crosswalk; and outputting the generated object through augmented reality.
"Electronic apparatus, control method thereof, computer program, and computer-readable recording medium",https://lens.org/078-957-816-172-915,2017,Disclosed herein is a control method of an electronic apparatus. The control method of an electronic apparatus includes: detecting a crosswalk from an image data photographed in a camera during a period in which a vehicle is operated; generating an object indicating the detected crosswalk; and outputting the generated object through augmented reality.
Method and a device for identifying and neutralizing an undersea mine,https://lens.org/054-671-423-542-562,2012,"A method of identifying and optionally neutralizing an undersea object (1, 1) that might be an undersea mine and that is of known geographical position, in which an undersea intervention robot (4, 4) is used suspended under an aircraft capable of stationary flight, such as a helicopter (7) or a drone, serving to bring the robot (4, 4) into register with the object (1, 1) for identification and possibly for being neutralized, the object is identified, and optionally it is neutralized."
Vehicle and method for detecting a parking space via a drone,https://lens.org/171-841-923-568-233,2020,"A vehicle includes processors, a display, and a drone comprising a camera and sensors. The processors receive an input indicating a destination, generate a zone including the destination, cause the drone to capture images of the zone, identify an unoccupied parking spot from the images of the zone, and present the unoccupied parking spot on the display."
Unmanned aerial system targeting,https://lens.org/165-850-055-922-69X,2019,An unmanned aerial system (UAS) includes a body and a lift and propulsion system coupled to the body. The UAS includes a weapon coupled to the body. The weapon has an aiming axis oriented in a fixed direction relative to the body. The UAS includes a control system operatively coupled to the lift and propulsion system and the weapon. The control system is configured to determine a roll angle and a flight path such that the aiming axis is directed at a target when the UAS moves according to at least a portion of the flight path at the roll angle. The control system is further configured to control the lift and propulsion system such that the UAS moves according to the at least the portion of the flight path at the roll angle.
UNMANNED AERIAL SYSTEM TARGETING,https://lens.org/031-049-688-503-951,2018,An unmanned aerial system (UAS) includes a body and a lift and propulsion system coupled to the body. The UAS includes a weapon coupled to the body. The weapon has an aiming axis oriented in a fixed direction relative to the body. The UAS includes a control system operatively coupled to the lift and propulsion system and the weapon. The control system is configured to determine a roll angle and a flight path such that the aiming axis is directed at a target when the UAS moves according to at least a portion of the flight path at the roll angle. The control system is further configured to control the lift and propulsion system such that the UAS moves according to the at least the portion of the flight path at the roll angle.
UNMANNED AERIAL SYSTEMS,https://lens.org/124-538-512-763-097,2018,"Apparatus for configuring a mission automation and decision support system for an unmanned aerial vehicle, the apparatus comprising a user interface and a computer-implemented module configured to: -receive data representative of at least one task to be performed by said unmanned aerial vehicle in use during a mission, said task being defined by one or more decision points, each corresponding to one or more system actions or responses that could result from respective specified mission information; -for the or each of a plurality of decision point(s), request, via said user interface, respective user inputs in response to specified questions, said specified questions being designed to determine at least an extent to which each relevant system action or response can be automated and a respective level of mandated operator approval therefor; and -allocate to the or each decision point, using said respective user inputs, a set of one or more corresponding automation levels, each automation level comprising data representative of a measure of automation to be applied at a respective decision point."
Surveying and mapping method and device,https://lens.org/025-836-709-312-157,2023,"A surveying and mapping system. Said system comprises: a control terminal and an unmanned aerial vehicle (UAV) for surveying and mapping; the control terminal is configured to: determine surveying and mapping parameters matching a surveying and mapping area, and send the surveying and mapping parameters to the UAV for surveying and mapping, the surveying and mapping parameters including: a plurality of surveying and mapping sampling points surveyed and mapped by the UAV for surveying and mapping in the surveying and mapping area; and the UAV for surveying and mapping is configured to: receive the surveying and mapping parameters, and perform flight photographing in the surveying and mapping area according to the surveying and mapping parameters, so as to obtain a surveying and mapping photo collection corresponding to the plurality of surveying and mapping sampling points, and enable a plurality of photos in the surveying and mapping photo collection to be subjected to at least one of: photo combination and photo splicing, thereby obtaining a map corresponding to the surveying and mapping area."
Surveying and mapping method and device,https://lens.org/025-836-709-312-157,2023,"A surveying and mapping system. Said system comprises: a control terminal and an unmanned aerial vehicle (UAV) for surveying and mapping; the control terminal is configured to: determine surveying and mapping parameters matching a surveying and mapping area, and send the surveying and mapping parameters to the UAV for surveying and mapping, the surveying and mapping parameters including: a plurality of surveying and mapping sampling points surveyed and mapped by the UAV for surveying and mapping in the surveying and mapping area; and the UAV for surveying and mapping is configured to: receive the surveying and mapping parameters, and perform flight photographing in the surveying and mapping area according to the surveying and mapping parameters, so as to obtain a surveying and mapping photo collection corresponding to the plurality of surveying and mapping sampling points, and enable a plurality of photos in the surveying and mapping photo collection to be subjected to at least one of: photo combination and photo splicing, thereby obtaining a map corresponding to the surveying and mapping area."
"SURVEYING AND MAPPING SYSTEM, SURVEYING AND MAPPING METHOD AND DEVICE, APPARATUS AND MEDIUM",https://lens.org/047-139-595-752-086,2020,"A surveying and mapping system. Said system comprises: a control terminal and an unmanned aerial vehicle (UAV) for surveying and mapping; the control terminal is configured to: determine surveying and mapping parameters matching a surveying and mapping area, and send the surveying and mapping parameters to the UAV for surveying and mapping, the surveying and mapping parameters including: a plurality of surveying and mapping sampling points surveyed and mapped by the UAV for surveying and mapping in the surveying and mapping area; and the UAV for surveying and mapping is configured to: receive the surveying and mapping parameters, and perform flight photographing in the surveying and mapping area according to the surveying and mapping parameters, so as to obtain a surveying and mapping photo collection corresponding to the plurality of surveying and mapping sampling points, and enable a plurality of photos in the surveying and mapping photo collection to be subjected to at least one of: photo combination and photo splicing, thereby obtaining a map corresponding to the surveying and mapping area."
"SURVEYING AND MAPPING SYSTEM, SURVEYING AND MAPPING METHOD AND DEVICE, APPARATUS AND MEDIUM",https://lens.org/047-139-595-752-086,2020,"A surveying and mapping system. Said system comprises: a control terminal and an unmanned aerial vehicle (UAV) for surveying and mapping; the control terminal is configured to: determine surveying and mapping parameters matching a surveying and mapping area, and send the surveying and mapping parameters to the UAV for surveying and mapping, the surveying and mapping parameters including: a plurality of surveying and mapping sampling points surveyed and mapped by the UAV for surveying and mapping in the surveying and mapping area; and the UAV for surveying and mapping is configured to: receive the surveying and mapping parameters, and perform flight photographing in the surveying and mapping area according to the surveying and mapping parameters, so as to obtain a surveying and mapping photo collection corresponding to the plurality of surveying and mapping sampling points, and enable a plurality of photos in the surveying and mapping photo collection to be subjected to at least one of: photo combination and photo splicing, thereby obtaining a map corresponding to the surveying and mapping area."
"Surveying and mapping system, surveying and mapping method, apparatus, device and medium",https://lens.org/014-388-097-991-033,2021,"A surveying and mapping system. Said system comprises: a control terminal and an unmanned aerial vehicle (UAV) for surveying and mapping; the control terminal is configured to: determine surveying and mapping parameters matching a surveying and mapping area, and send the surveying and mapping parameters to the UAV for surveying and mapping, the surveying and mapping parameters including: a plurality of surveying and mapping sampling points surveyed and mapped by the UAV for surveying and mapping in the surveying and mapping area; and the UAV for surveying and mapping is configured to: receive the surveying and mapping parameters, and perform flight photographing in the surveying and mapping area according to the surveying and mapping parameters, so as to obtain a surveying and mapping photo collection corresponding to the plurality of surveying and mapping sampling points, and enable a plurality of photos in the surveying and mapping photo collection to be subjected to at least one of: photo combination and photo splicing, thereby obtaining a map corresponding to the surveying and mapping area."
Internet-of-things devices and related methods for performing in-call interactions,https://lens.org/039-693-819-690-493,2021,"A miniaturized multiprotocol audio/voice internet-of-things device (MAVID) initiates a wireless call in response to a command received from a first user. The MAVID carries out the wireless call between the first user and a second user. The wireless call utilizes wireless protocols such as WiFi, Bluetooth, third generation mobile technology (3G), fourth generation mobile technology (4G), and Digital Enhanced Cordless Telecommunications (DECT). The MAVID performs an in-call interaction, such as connecting to and utilizing an internet-based application or controlling a consumer electronic device, in response to a voice command from either the first user or the second user, while carrying out the wireless call."
Internet-Of-Things Devices and Related Methods for Performing In-Call Interactions,https://lens.org/027-710-873-792-796,2019,"A miniaturized multiprotocol audio/voice internet-of-things device (MAVID) initiates a wireless call in response to a command received from a first user. The MAVID carries out the wireless call between the first user and a second user. The wireless call utilizes wireless protocols such as WiFi, Bluetooth, third generation mobile technology (3G), fourth generation mobile technology (4G), and Digital Enhanced Cordless Telecommunications (DECT). The MAVID performs an in-call interaction, such as connecting to and utilizing an internet-based application or controlling a consumer electronic device, in response to a voice command from either the first user or the second user, while carrying out the wireless call."
Internet-of-things devices and related methods for performing in-call interactions,https://lens.org/059-361-139-062-48X,2020,"A miniaturized multiprotocol audio/voice internet-of-things device (MAVID) initiates a wireless call in response to a command received from a first user. The MAVID carries out the wireless call between the first user and a second user. The wireless call utilizes wireless protocols such as WiFi, Bluetooth, third generation mobile technology (3G), fourth generation mobile technology (4G), and Digital Enhanced Cordless Telecommunications (DECT). The MAVID performs an in-call interaction, such as connecting to and utilizing an internet-based application or controlling a consumer electronic device, in response to a voice command from either the first user or the second user, while carrying out the wireless call."
Aircraft control device and remote control aircraft,https://lens.org/171-991-726-490-864,2018,An aircraft control device and a remote controller aircraft are disclosed. The aircraft control device includes a first channel configured to receive first control information outputted by a remote controller and transmit the first control information to an aircraft; a second channel configured to receive second control information outputted by the remote controller and transmit the second control information to a camera and/or a gimbal; and a switch unit configured to switch that the first control information is received by the second channel and transmitted to the aircraft when the first channel is disturbed or a distance between the remote controller and the aircraft is larger than a distance threshold. The present invention is able to switch the transmission route of the first control information between the first channel and the second channel in accordance with situations of the first channel and the second channel.
Aircraft control device and remote control aircraft,https://lens.org/167-877-715-076-47X,2019,An aircraft control device and a remote controller aircraft are disclosed. The aircraft control device includes a first channel configured to receive first control information outputted by a remote controller and transmit the first control information to an aircraft; a second channel configured to receive second control information outputted by the remote controller and transmit the second control information to a camera and/or a gimbal; and a switch unit configured to switch that the first control information is received by the second channel and transmitted to the aircraft when the first channel is disturbed or a distance between the remote controller and the aircraft is larger than a distance threshold. The present invention is able to switch the transmission route of the first control information between the first channel and the second channel in accordance with situations of the first channel and the second channel.
Autonomous mobile robot system,https://lens.org/027-211-991-449-52X,2016,A navigational control system for an autonomous robot includes a transmitter subsystem having a stationary emitter for emitting at least one signal. An autonomous robot operating within a working area utilizes a receiving subsystem to detect the emitted signal. The receiver subsystem has a receiver for detecting the emitted signal emitted by the emitter and a processor for determining a relative location of the robot within the working area upon the receiver detecting the signal.
Celestial navigation system for an autonomous robot,https://lens.org/156-028-701-207-015,2010,A navigational control system for an autonomous robot includes a transmitter subsystem having a stationary emitter for emitting at least one signal. An autonomous robot operating within a working area utilizes a receiving subsystem to detect the emitted signal. The receiver subsystem has a receiver for detecting the emitted signal emitted by the emitter and a processor for determining a relative location of the robot within the working area upon the receiver detecting the signal.
Celestial navigation system for an autonomous robot,https://lens.org/171-455-197-553-647,2014,A navigational control system for an autonomous robot includes a transmitter subsystem having a stationary emitter for emitting at least one signal. An autonomous robot operating within a working area utilizes a receiving subsystem to detect the emitted signal. The receiver subsystem has a receiver for detecting the emitted signal emitted by the emitter and a processor for determining a relative location of the robot within the working area upon the receiver detecting the signal.
METHOD FOR FLIGHT DATA RECORDING OF UNMANNED AERIAL VEHICLE USING BLOCKCHAIN TECHNOLOGY AND APPARATUS FOR THE SAME,https://lens.org/113-521-605-559-060,2021,"Disclosed herein is a method for recording flight data of an unmanned aerial vehicle (UAV) using blockchain technology. The method includes collecting sensor data from a sensor installed in the UAV, collecting location information of the UAV from a GPS installed therein, estimating the flight status of the UAV based on a control signal, the sensor data, and the location information, detecting an abnormal condition by comparing the flight status with the flight plan of the UAV, generating signature information corresponding to surroundings at a corresponding time based on peripheral signals collected from a receiver installed in the UAV, generating a transmission data block capable of being registered in a blockchain based on the flight status, the abnormal condition, and the signature information, transmitting the transmission data block to a flight data registration apparatus, and registering the transmission data block, received by the flight data registration apparatus, in the blockchain."
SYSTEMS AND METHODS FOR REMOTELY CONTROLLED DEVICE POSITION AND ORIENTATION DETERMINATION,https://lens.org/080-218-984-078-066,2011,"A system, for a remotely controlled device to determine its location, and orientation is disclosed. The system includes a remotely controlled, device, at least one sensor connected to the remotely controlled device, fee at least one sensor comprising a processor, and at least one emitter, wherein the al least one sensor is configured to receive the signal from the at least one emitter and the processor is configured to determine the location and orientation of the remotely controlled device."
CONTROL OF THE HEIGHT OF GUIDABLE FLYING BODIES,https://lens.org/105-359-336-702-101,1999,"A method and an apparatus for controlling the height of a guidable flying body are provided. The body is of the type in which a pitch control signal from a station remote from the flying body is received by the flying body to control the pitch of the flying body. Height sensing the sense, from the flying body, the height of the flying body. Control means are connected to the height sensing means and receive the pitch control signal. As the flying body approaches a predetermined minimum height, the pitch control signal is modified by the control means so that the flying body is controlled to maintain at least the predetermined minimum height."
Flight control system for flying object,https://lens.org/001-940-419-425-566,2014,"A flight control system for a flying object comprises a flying object, a navigating means provided in the flying object, a position measuring unit 17, a flight control unit 18 for controlling the navigating means, and a main arithmetic control unit 19 for controlling the position measuring unit and the flight control unit, and in the flight control system for a flying object, the position measuring unit has a GPS device 23 for measuring a ground coordinate of the flying object and a vertical camera 13 for taking a digital image below the flying object and measures an altitude of the flying object based on images at two points taken by the vertical camera, on ground coordinates of the two points measured by the GPS device, and on a focal length of the vertical camera, and the main arithmetic control unit controls the navigating means via the flight control unit based on the measured altitude and makes the flying object fly at a predetermined altitude."
Flight Control System For Flying Object,https://lens.org/142-931-386-107-163,2012,"A flight control system for a flying object comprises a flying object, a navigating means provided in the flying object, a position measuring unit 17, a flight control unit 18 for controlling the navigating means, and a main arithmetic control unit 19 for controlling the position measuring unit and the flight control unit, and in the flight control system for a flying object, the position measuring unit has a GPS device 23 for measuring a ground coordinate of the flying object and a vertical camera 13 for taking a digital image below the flying object and measures an altitude of the flying object based on images at two points taken by the vertical camera, on ground coordinates of the two points measured by the GPS device, and on a focal length of the vertical camera, and the main arithmetic control unit controls the navigating means via the flight control unit based on the measured altitude and makes the flying object fly at a predetermined altitude."
Portable smart speaker power control,https://lens.org/069-366-426-794-101,2022,"Various aspects include a speaker including: an acoustic transducer for providing an audio output; a set of microphones for detecting a user voice command; and a controller coupled with the acoustic transducer and the set of microphones, wherein the controller is configured to: in response to detecting a power down command, switch the set of microphones from an active listening mode to a standby mode for a parking period, in response to detecting a power up command during the parking period, switch the set of microphones from the standby mode to the active listening mode after a first time period, and in response to detecting the power up command after expiration of the parking period switch the set of microphones from the standby mode to the active listening mode after a second time period that is greater than the first time period."
PORTABLE SMART SPEAKER POWER CONTROL,https://lens.org/079-893-514-762-879,2021,"Various aspects include a speaker including: an acoustic transducer for providing an audio output; a set of microphones for detecting a user voice command; and a controller coupled with the acoustic transducer and the set of microphones, wherein the controller is configured to: in response to detecting a power down command, switch the set of microphones from an active listening mode to a standby mode for a parking period, in response to detecting a power up command during the parking period, switch the set of microphones from the standby mode to the active listening mode after a first time period, and in response to detecting the power up command after expiration of the parking period switch the set of microphones from the standby mode to the active listening mode after a second time period that is greater than the first time period."
METHOD AND APPARATUS FOR LAUNCHING UNMANNED AERIAL VEHICLE AND UNMANNED AERIAL VEHICLE INCORPORATING THE SAME,https://lens.org/008-153-689-410-374,2018,"A method for launching an unmanned aerial vehicle (UAV) comprises: receiving a pre-launching signal; detecting, via at least one sensor of the UAV, at least one status parameter of the UAV in response to receiving the pre-launching signal; determining a launching mode of the UAV according to the at least one detected status parameter of the UAV; and launching the UAV according to the determined launching mode of the UAV."
Method and apparatus for launching unmanned aerial vehicle and unmanned aerial vehicle incorporating the same,https://lens.org/013-205-023-425-046,2019,"A method for launching an unmanned aerial vehicle (UAV) comprises: receiving a pre-launching signal; detecting, via at least one sensor of the UAV, at least one status parameter of the UAV in response to receiving the pre-launching signal; determining a launching mode of the UAV according to the at least one detected status parameter of the UAV; and launching the UAV according to the determined launching mode of the UAV."
METHOD AND APPARATUS FOR PERFORMING WATER SAMPLING WITH AN UNMANNED AERIAL VEHICLE,https://lens.org/082-367-007-179-177,2020,"A UAV capable of sampling a hazardous body of water and a method of using the same is disclosed. The method includes receiving, by an electronic controller of the attached apparatus, a first instruction to lower a sampling device at a specified rate into the body of water. The sampling device is connected to the apparatus via a line, and the sampling device is lowered by unspooling the line from a reel. The method also includes lowering the sampling device at the specified rate into the body of water based on the instruction. The method also includes retrieving the sampling device from the body of water. A line-cutting device can cut the line should the sampling device get caught up in an obstruction."
MEASURING METHOD USING UNMANNED AERIAL ROBOT AND DEVICE FOR SUPPORTING SAME IN UNMANNED AERIAL SYSTEM,https://lens.org/096-999-132-051-803,2021,"An altitude measuring method of an unmanned aerial robot is provided. The robot adjusts a level of the unmanned aerial robot so that the robot is at a horizontal state with respect the ground to measure the altitude. The robot generates a plurality of laser beams to the ground, and photographs the ground through the camera. The robot calculates a vertical distance from the ground to the robot based on the photographed image of the ground and the plurality of laser beams."
DISTRIBUTED DRONE SYSTEM AND DRONE,https://lens.org/154-465-881-353-126,2016,"In order to enable an improved and cost-efficient way for at least one of spotting, tagging, localizing, registering and inventorying Objects located inside large Outdoor Areas (ODA), in particular Layout Areas (LOA) of Plant Grounds (PLG), it is proposed a ""Unmanned Aerial Vehicle"" (UAV) commonly known as a Drone, which is constructed or designed to a multi-component Front-End (FRE, UAV) of a corresponding Distributed Drone System (DDS) being supported by a multi-component Back-End (BAE, S-BAE, M-BAE) of the corresponding Distributed Drone System (DDS), flying at very low altitude over a Layout Area (LOA) of an Outdoor Area (ODA), reading information of ""Ultra High Frequency (UHF) Radio Frequency Identification (RFID) ""-Transponder (URTP) located on Objects (OBT) for least one of spotting, tagging, localizing, registering and inventorying purposes. The corresponding Distributed Drone System (DDS) including the Front-End (FRE, UAV) and the Back-End (BAE, S-BAE, M-BAE) is a combination of several components in the Front-End (FRE, UAV) and the Back-End (BAE, S-BAE, M-BAE)."
UNMANNED AERIAL VEHICLES,https://lens.org/068-679-180-118-111,2021,"A system comprises an unmanned aerial vehicle, UAV. The UAV comprises a camera having one or more camera properties. The system is configured to provide privacy in relation to the camera when the UAV is below a predetermined altitude. The system is configured such that said privacy in relation to the camera is not provided when the UAV is above said predetermined altitude."
SYSTEMS AND METHODS FOR DUAL OPERATION OF UNMANNED AERIAL VEHICLES,https://lens.org/079-860-232-332-60X,2017,"An unmanned aerial vehicle (UAV) dual operation system and method is described. Certain embodiments include a dual operation system that receives and processes control signals from two controllers, e.g., a first controller and a second controller, and outputs a control signal to a UAV on-board pilot system to operate the UAV. In some embodiments, the dual operation system may override control signals from the first controller with the control signals received from the second controller. Further, the dual operation system may respond to various conditions when control signals from one of the controllers are lost or unstable, enabling an on-board pilot system to take over control of the UAV."
A WIRELESS EVENT NOTIFICATION SYSTEM WITH VOICE-BASED INTERACTION,https://lens.org/043-438-261-105-780,2018,"A wireless event notification system includes a microphone, a controller, a voice authentication engine, a speech recognition engine, and a wireless device. The microphone is configured to transmit an audible command initiated by a user. The controller is located in a cloud and is configured to receive the audible command. The voice authentication engine is configured to receive the audible command for authenticating the user, and send an authentication signal to the controller. The speech recognition engine is configured to receive the audible command for recognition of the audible command, and send a command text indicative of the audible command to the controller. The wireless device is configured to receive the command text if the controller has received both the authentication signal from the voice authentication engine and the command text from the speech recognition engine."
A WIRELESS EVENT NOTIFICATION SYSTEM WITH VOICE-BASED INTERACTION,https://lens.org/155-958-491-292-278,2020,"A wireless event notification system includes a microphone, a controller, a voice authentication engine, a speech recognition engine, and a wireless device. The microphone is configured to transmit an audible command initiated by a user. The controller is located in a cloud and is configured to receive the audible command. The voice authentication engine is configured to receive the audible command for authenticating the user, and send an authentication signal to the controller. The speech recognition engine is configured to receive the audible command for recognition of the audible command, and send a command text indicative of the audible command to the controller. The wireless device is configured to receive the command text if the controller has received both the authentication signal from the voice authentication engine and the command text from the speech recognition engine."
Surface cleaning unmanned aerial vehicle,https://lens.org/198-890-980-939-548,2018,Described embodiments include an unmanned aerial vehicle and a method. The unmanned aerial vehicle includes an airframe and a rotary wing system coupled with the airframe and configured to aerodynamically lift the vehicle in the air. The unmanned aerial vehicle includes a flight controller configured to control a movement of the vehicle while airborne. The unmanned aerial vehicle includes a cleansing controller configured to manage a removal of a surface contaminant from a selected portion of a surface of an external object using an airflow generated by the rotary wing system.
Surface cleaning unmanned aerial vehicle,https://lens.org/165-475-108-062-952,2016,Described embodiments include an unmanned aerial vehicle and a method. The unmanned aerial vehicle includes an airframe and a rotary wing system coupled with the airframe and configured to aerodynamically lift the vehicle in the air. The unmanned aerial vehicle includes a flight controller configured to control a movement of the vehicle while airborne. The unmanned aerial vehicle includes a cleansing controller configured to manage a removal of a surface contaminant from a selected portion of a surface of an external object using an airflow generated by the rotary wing system.
SURFACE CLEANING UNMANNED AERIAL VEHICLE,https://lens.org/022-522-508-439-353,2016,Described embodiments include an unmanned aerial vehicle and a method. The unmanned aerial vehicle includes an airframe and a rotary wing system coupled with the airframe and configured to aerodynamically lift the vehicle in the air. The unmanned aerial vehicle includes a flight controller configured to control a movement of the vehicle while airborne. The unmanned aerial vehicle includes a cleansing controller configured to manage a removal of a surface contaminant from a selected portion of a surface of an external object using an airflow generated by the rotary wing system.
METHODS AND SYSTEMS FOR USING AN UNMANNED AERIAL VEHICLE (UAV) FLIGHT PATH TO COORDINATE AN ENHANCED HANDOVER IN 3RD GENERATION PARTNERSHIP PROJECT (3GPP) NETWORKS,https://lens.org/102-177-459-858-492,2018,"A method for managing an unmanned aerial vehicle (UAV) is described. The method may include receiving flight plan information describing a flight path of the UAV; generating one or more cell lists based on the flight plan information; and transmitting the one or more cell lists to a source cell in a wireless network in which the UAV is currently operating, wherein the one or more cell lists are used in a handover procedure between the source cell that the UAV is currently connected to and a target cell that the UAV will connect to after completing the handover procedure."
Methods and systems for using an unmanned aerial vehicle (UAV) flight path to coordinate an enhanced handover in 3rd generation partnership project (3GPP) networks,https://lens.org/149-935-515-885-854,2021,"A method for managing an unmanned aerial vehicle (UAV) is described. The method may include receiving flight plan information describing a flight path of the UAV; generating one or more cell lists based on the flight plan information; and transmitting the one or more cell lists to a source cell in a wireless network in which the UAV is currently operating, wherein the one or more cell lists are used in a handover procedure between the source cell that the UAV is currently connected to and a target cell that the UAV will connect to after completing the handover procedure."
METHODS AND SYSTEMS FOR USING AN UNMANNED AERIAL VEHICLE (UAV) FLIGHT PATH TO COORDINATE AN ENHANCED HANDOVER IN 3RD GENERATION PARTNERSHIP PROJECT (3GPP) NETWORKS,https://lens.org/093-595-577-889-166,2020,"A method for managing an unmanned aerial vehicle (UAV) is described. The method may include receiving flight plan information describing a flight path of the UAV; generating one or more cell lists based on the flight plan information; and transmitting the one or more cell lists to a source cell in a wireless network in which the UAV is currently operating, wherein the one or more cell lists are used in a handover procedure between the source cell that the UAV is currently connected to and a target cell that the UAV will connect to after completing the handover procedure."
UNMANNED AERIAL VEHICLE DETECTOR,https://lens.org/003-431-109-145-136,2023,"Method of detecting and tracking an unmanned aerial vehicle, the method comprising, at a detector unit (300a) comprising a first microphone and a second microphone: monitoring for a sound associated with the presence of the unmanned aerial vehicle (505) in the vicinity of the detector unit; in response to the monitoring indicating the presence of the unmanned aerial vehicle, determining, at the detector unit, a phase delay between the sound as received at the first microphone and the sound as received at the second microphone; on the basis of the determined phase delay and a known separation of the first microphone and the second microphone, determining, at the detector unit, an azimuth angle (507a) to the unmanned aerial vehicle from the detector unit; and transmitting, to a computing node (501), the determined azimuth angle for use in determining a location of the unmanned aerial vehicle."
UNMANNED AERIAL VEHICLE DETECTOR,https://lens.org/003-431-109-145-136,2023,"Method of detecting and tracking an unmanned aerial vehicle, the method comprising, at a detector unit (300a) comprising a first microphone and a second microphone: monitoring for a sound associated with the presence of the unmanned aerial vehicle (505) in the vicinity of the detector unit; in response to the monitoring indicating the presence of the unmanned aerial vehicle, determining, at the detector unit, a phase delay between the sound as received at the first microphone and the sound as received at the second microphone; on the basis of the determined phase delay and a known separation of the first microphone and the second microphone, determining, at the detector unit, an azimuth angle (507a) to the unmanned aerial vehicle from the detector unit; and transmitting, to a computing node (501), the determined azimuth angle for use in determining a location of the unmanned aerial vehicle."
SYSTEM AND METHOD FOR AUTHORING AND VIEWING AUGMENTED REALITY CONTENT WITH A DRONE,https://lens.org/069-385-701-859-074,2019,"A display device receives video data, location data, position data from a remotely controlled unmanned aerial vehicle (UAV). The display device converts a first set of coordinates from the location and position data to a second set of coordinates of a virtual world model. A user of the display device provides a selection of an AR object at the display device that is also used to control the remotely controlled UAV. The display device associates the selected AR object with the second set of coordinates and providing information of the selected AR object and the second set of coordinates to a server."
Unmanned aerial vehicle based security system,https://lens.org/135-456-804-335-676,2019,"A method includes defining a flight plan of an unmanned aerial vehicle from a rest location thereof to a destination location within a memory of the unmanned aerial vehicle, and capturing, through one or more sensor(s) communicatively coupled to the unmanned aerial vehicle and a server through a computer network, data related to an environment of a specific location covered by the one or more sensor(s). The method also includes detecting, through a processor associated with the one or more sensor(s) and/or the server, a security breach and/or a security threat at the specific location based on analyzing the captured data, and automatically activating, through the one or more sensor(s) or the server, the flight plan on the unmanned aerial vehicle in response to the detection of the security breach and/or the security threat to dispatch the unmanned aerial vehicle to perform additional surveillance of the specific location."
UNMANNED AERIAL VEHICLE BASED SECURITY SYSTEM,https://lens.org/028-319-756-953-524,2017,"A method includes defining a flight plan of an unmanned aerial vehicle from a rest location thereof to a destination location within a memory of the unmanned aerial vehicle, and capturing, through one or more sensor(s) communicatively coupled to the unmanned aerial vehicle and a server through a computer network, data related to an environment of a specific location covered by the one or more sensor(s). The method also includes detecting, through a processor associated with the one or more sensor(s) and/or the server, a security breach and/or a security threat at the specific location based on analyzing the captured data, and automatically activating, through the one or more sensor(s) or the server, the flight plan on the unmanned aerial vehicle in response to the detection of the security breach and/or the security threat to dispatch the unmanned aerial vehicle to perform additional surveillance of the specific location."
SYSTEM AND METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE,https://lens.org/079-601-746-399-928,2012,"An unmanned aerial vehicle (UAV) includes a driving unit and a control unit. The control unit detects a human figure in an image of a scene of a monitored area, determines coordinate differences between the scene image's center and the figure image's center, and determines a tilt direction and a tilt angle of a lens of the image capture unit based on the coordinate differences. If the tilt angle falls within an allowable rotation range of the lens, the control unit controls the driving unit to directly rotate the lens by the tilt angle along the tilt direction. Otherwise, the control unit controls the driving unit to rotate the lens by a threshold angle along the tilt direction, and further controls the driving unit to adjust a flight orientation and a flight height of the UAV until the figure image's center superposes the scene image's center."
Systems and methods for UAV docking,https://lens.org/009-138-539-710-620,2020,"A vehicle is configured to couple with an unmanned aerial vehicle (UAV) and includes a landing connection component configured to form a connection between the UAV and the vehicle and to prevent detachment of the UAV from the vehicle, a cover configured to at least partially enclose the UAV when the UAV is connected to the landing connection component, and one or more processors configured to generate one or more commands to (1) vary a position of the cover depending on a status of the UAV and (2) control an operation of the UAV."
UAV GUIDANCE SYSTEM AND HAND CONTROL UNIT,https://lens.org/058-269-968-514-836,2022,"The present invention provides a system for control and guidance of an unmanned aerial vehicle (UAV) using modulated laser light in radio frequency (RF) contested environments. The system enables the user to send light signal communications to the UAV from a handheld device. In one embodiment, where the handheld device is capable of being incorporated into a firearm fore-grip with built-in controls that allow for control of the UAV by a user in a shooting/aiming position. The UAV includes an optical array for detecting and receiving the light signal communications, as well as filtering systems for filtering out unnecessary image data for better control in different weather and time conditions, as well as an avoidance system to avoid objects and other UAVs when used in a swarm of UAVs."
UAV GUIDANCE SYSTEM AND HAND CONTROL UNIT,https://lens.org/058-269-968-514-836,2022,"The present invention provides a system for control and guidance of an unmanned aerial vehicle (UAV) using modulated laser light in radio frequency (RF) contested environments. The system enables the user to send light signal communications to the UAV from a handheld device. In one embodiment, where the handheld device is capable of being incorporated into a firearm fore-grip with built-in controls that allow for control of the UAV by a user in a shooting/aiming position. The UAV includes an optical array for detecting and receiving the light signal communications, as well as filtering systems for filtering out unnecessary image data for better control in different weather and time conditions, as well as an avoidance system to avoid objects and other UAVs when used in a swarm of UAVs."
Apparatus for notifying a parcel is delivered,https://lens.org/142-716-851-223-572,2020,"An apparatus for notifying of parcel delivery comprising an aerial parcel delivery apparatus, landing gear, a processor, a number of visual sensors, and an articulated robotic arm. The robotic arm may comprise an end effector comprising one or more simulated fingers or digits of a human hand, a protruding member, and a wireless communication adapter. The end effector may have the ability to grasp an object or actuate a doorbell, key pay, or an alarm system. The articulated robotic arm including a protruding member is extended to ring a doorbell."
Apparatus for Notifying a Parcel is Delivered,https://lens.org/065-978-663-758-106,2018,"An apparatus for notifying of parcel delivery comprising an aerial parcel delivery apparatus, landing gear, a processor, a number of visual sensors, and an articulated robotic arm. The robotic arm may comprise an end effector comprising one or more simulated fingers or digits of a human hand, a protruding member, and a wireless communication adapter. The end effector may have the ability to grasp an object or actuate a doorbell, key pay, or an alarm system. The articulated robotic arm including a protruding member is extended to ring a doorbell."
Remote assistance for an autonomous vehicle in low confidence situations,https://lens.org/096-944-859-696-874,2016,"Example systems and methods enable an autonomous vehicle to request assistance from a remote operator when the vehicle's confidence in operation is low. One example method includes operating an autonomous vehicle in a first autonomous mode. The method may also include identifying a situation where a level of confidence of an autonomous operation in the first autonomous mode is below a threshold level. The method may further include sending a request for assistance to a remote assistor, the request including sensor data representative of a portion of an environment of the autonomous vehicle. The method may additionally include receiving a response from the remote assistor, the response indicating a second autonomous mode of operation. The method may also include causing the autonomous vehicle to operate in the second autonomous mode of operation in accordance with the response from the remote assistor."
Remote assistance for an autonomous vehicle in low confidence situations,https://lens.org/016-625-228-922-804,2019,"Example systems and methods enable an autonomous vehicle to request assistance from a remote operator when the vehicle's confidence in operation is low. One example method includes operating an autonomous vehicle in a first autonomous mode. The method may also include identifying a situation where a level of confidence of an autonomous operation in the first autonomous mode is below a threshold level. The method may further include sending a request for assistance to a remote assistor, the request including sensor data representative of a portion of an environment of the autonomous vehicle. The method may additionally include receiving a response from the remote assistor, the response indicating a second autonomous mode of operation. The method may also include causing the autonomous vehicle to operate in the second autonomous mode of operation in accordance with the response from the remote assistor."
Remote Assistance for an Autonomous Vehicle in Low Confidence Situations,https://lens.org/137-158-962-148-70X,2016,"Example systems and methods enable an autonomous vehicle to request assistance from a remote operator when the vehicle's confidence in operation is low. One example method includes operating an autonomous vehicle in a first autonomous mode. The method may also include identifying a situation where a level of confidence of an autonomous operation in the first autonomous mode is below a threshold level. The method may further include sending a request for assistance to a remote assistor, the request including sensor data representative of a portion of an environment of the autonomous vehicle. The method may additionally include receiving a response from the remote assistor, the response indicating a second autonomous mode of operation. The method may also include causing the autonomous vehicle to operate in the second autonomous mode of operation in accordance with the response from the remote assistor."
REMOTE ASSISTANCE FOR AN AUTONOMOUS VEHICLE IN LOW CONFIDENCE SITUATIONS,https://lens.org/035-566-533-321-505,2020,"Example systems and methods enable an autonomous vehicle to request assistance from a remote operator when the vehicle's confidence in operation is low. One example method includes operating an autonomous vehicle in a first autonomous mode. The method may also include identifying a situation where a level of confidence of an autonomous operation in the first autonomous mode is below a threshold level. The method may further include sending a request for assistance to a remote assistor, the request including sensor data representative of a portion of an environment of the autonomous vehicle. The method may additionally include receiving a response from the remote assistor, the response indicating a second autonomous mode of operation. The method may also include causing the autonomous vehicle to operate in the second autonomous mode of operation in accordance with the response from the remote assistor."
"METHOD, SYSTEM, AND NON-TRANSITORY COMPUTER-READABLE RECORDING MEDIUM FOR CONTROLLING A ROBOT",https://lens.org/176-883-953-158-320,2022,A method for controlling a robot is provided. The method includes the steps of: acquiring at least one of sound information and action information for a robot from a user in a serving place; determining identification information on the user on the basis of at least one of the sound information and the action information; and determining an operation to be performed by the robot on the basis of the identification information.
"METHOD, SYSTEM, AND NON-TRANSITORY COMPUTER-READABLE RECORDING MEDIUM FOR CONTROLLING A ROBOT",https://lens.org/035-042-724-983-694,2022,A method for controlling a robot is provided. The method includes the steps of: acquiring at least one of sound information and action information for a robot from a user in a serving place; determining identification information on the user on the basis of at least one of the sound information and the action information; and determining an operation to be performed by the robot on the basis of the identification information.
"METHOD, SYSTEM, AND NON-TRANSITORY COMPUTER-READABLE RECORDING MEDIUM FOR CONTROLLING A ROBOT",https://lens.org/176-883-953-158-320,2022,A method for controlling a robot is provided. The method includes the steps of: acquiring at least one of sound information and action information for a robot from a user in a serving place; determining identification information on the user on the basis of at least one of the sound information and the action information; and determining an operation to be performed by the robot on the basis of the identification information.
"METHOD, SYSTEM, AND NON-TRANSITORY COMPUTER-READABLE RECORDING MEDIUM FOR CONTROLLING A ROBOT",https://lens.org/035-042-724-983-694,2022,A method for controlling a robot is provided. The method includes the steps of: acquiring at least one of sound information and action information for a robot from a user in a serving place; determining identification information on the user on the basis of at least one of the sound information and the action information; and determining an operation to be performed by the robot on the basis of the identification information.
Autonomous behavior robot recognizing direction of sound source,https://lens.org/058-643-059-406-333,2019,"This robot uses a microphone array to detect a sound and identify the direction of a sound source. The robot faces a head portion in the direction of the sound source. If an object having a characteristic of an uttering body is detected in an image capturing region 420 in the direction of the sound source identified by the microphone array, the uttering body is identified as an utterance source. Upon identifying the uttering body as the utterance source, the robot faces a body thereof toward the sound source (utterance source). The robot executes a predetermined motion if a particular environmental sound is detected."
"UAV HAVING RADAR-GUIDED LANDING FUNCTION, SYSTEM AND METHOD THEREOF",https://lens.org/026-024-644-051-832,2018,"A UAV having a radar-guided landing function that helps the UAV to land on a landing station is disclosed. The UAV uses a GPS transceiving unit's positioning, and receives a flight path from an external source through a control unit to advance toward the landing station. When the UAV approaches a landing station, the control unit receives an activation signal and activates a landing radar to continuously transmit a frequency sweeping radar wave. When the frequency sweeping radar wave reaches the landing station, a reflected radar wave is generated, so that the landing radar receives the reflected radar wave and transmits it to the control unit. The control unit performs computation based on data related to the reflected radar wave and accordingly controls the UAV to land on the landing station."
"DRONE DETERRENCE SYSTEM, METHOD, AND ASSEMBLY",https://lens.org/083-441-401-452-53X,2020,A drone deterrence system and method include a housing configured to be secured to a stationary or moving structure. A tracker is configured to track motion of a drone within a predetermined range. A laser is configured to emit laser energy to a position of the drone that is tracked by the tracker while the drone is within the predetermined range. A gimbal assembly is secured to the housing. One or both of the tracker or the laser is mounted to the gimbal assembly.
Drone structure for the transport of temperature-controlled material,https://lens.org/037-530-844-707-948,2022,"A system for carrying a load at a controlled temperature includes a drone structure having a motor that handles the drone structure, an energy unit that delivers electric energy, and a control unit. The drone structure also includes a thermal container having an insulating casing with at least one layer of heat-insulating material, an inner temperature sensor that measures a value of temperature Tint internal to the insulating casing, an outer temperature sensor configured to measure a value of temperature Text external to the insulating casing, and a thermal unit arranged to adjust or keep constant the value of temperature Tint. The control unit is adapted to carry out an acquisition of a flight mission comprising a landing position of the drone structure, a time limit tmax to reach the landing position and a condition on the values of the temperature Tint to keep during the flight mission."
DRONE STRUCTURE FOR THE TRANSPORT OF TEMPERATURE-CONTROLLED MATERIAL,https://lens.org/121-398-082-807-932,2020,"A system for carrying a load at a controlled temperature includes a drone structure having a motor that handles the drone structure, an energy unit that delivers electric energy, and a control unit. The drone structure also includes a thermal container having an insulating casing with at least one layer of heat-insulating material, an inner temperature sensor that measures a value of temperature Tint internal to the insulating casing, an outer temperature sensor configured to measure a value of temperature Text external to the insulating casing, and a thermal unit arranged to adjust or keep constant the value of temperature Tint. The control unit is adapted to carry out an acquisition of a flight mission comprising a landing position of the drone structure, a time limit tmax to reach the landing position and a condition on the values of the temperature Tint to keep during the flight mission."
Video surveillance system with aerial camera device,https://lens.org/169-591-592-758-305,2019,"A video surveillance system having a plurality of aerial camera devices such as cameras on drones operable from a plurality of docking stations. Each station having a dock for receiving, charging, and controlling the aerial camera devices."
VIDEO SURVEILLANCE SYSTEM WITH AERIAL CAMERA DEVICE,https://lens.org/008-246-155-586-116,2018,"A video surveillance system having a plurality of aerial camera devices such as cameras on drones operable from a plurality of docking stations. Each station having a dock for receiving, charging, and controlling the aerial camera devices."
Automatic unmanned aerial vehicle of flight is dodged and passes through in three dimensions range finding,https://lens.org/182-880-306-565-345,2016,"The utility model provides an automatic unmanned aerial vehicle of flight is dodged and passes through in three dimensions range finding, it includes: an unmanned aerial vehicle main part, a flight controller, set up in the inside of unmanned aerial vehicle main part, a protective bracket fixes in the unmanned aerial vehicle main part, a plurality of distance measuring sensor, four at least distance measuring sensor equidistance looping -in respectively are in protective bracket's the outside, two at least distance measuring sensor install below in the unmanned aerial vehicle main part respectively, measure the distance of horizontal direction and vertical direction respectively, distance measuring sensor will give flight controller apart from data transmission at any time, the analysis is apart from data, wireless transmission gives the operator simultaneously, make the operator can be in time change unmanned aerial vehicle's flight path according to the direction of obstacle, unmanned aerial vehicle accepts long -range remote sensing signal again and comes control flight, under guarantee unmanned aerial vehicle's the complete prerequisite of safety, more be favorable to passing through the cubical space in clearance between various building door and window or animals and plants."
GIMBAL REMOTE CONTROLLER AND HANDHELD GIMBAL USING THE GIMBAL REMOTE CONTROLLER,https://lens.org/155-398-307-420-709,2017,"A gimbal remote controller includes a press key, a sensor disposed below the press key for acquiring an operation state of the press key, and a controller electrically coupled to the sensor and configured to send a gimbal control signal in accordance with the operation state of the press key."
Gimbal remote controller and handheld gimbal using the gimbal remote controller,https://lens.org/163-381-526-160-395,2019,"A gimbal remote controller includes a press key, a sensor disposed below the press key for acquiring an operation state of the press key, and a controller electrically coupled to the sensor and configured to send a gimbal control signal in accordance with the operation state of the press key."
VISUAL OBSERVER FOR UNMANNED AERIAL VEHICLES,https://lens.org/145-301-100-719-416,2021,"In some examples, a device may receive, from a first camera, a plurality of images of an airspace corresponding to an area of operation of an unmanned aerial vehicle (UAV). The device may detect, based on the plurality of images from the first camera, a candidate object approaching or within the airspace. Based on detecting the candidate object, the device may control a second camera to direct a field of view of the second camera toward the candidate object. Further, based on images from the second camera captured at a first location and images from at least one other camera captured at a second location, the candidate object may be determined to be an object of interest. In addition, at least one action may be taken based on determining that the candidate object is the object of interest."
Wildfire Surveillance UAV and Fire Surveillance System,https://lens.org/075-278-069-818-968,2021,"An unmanned aerial vehicle (UAV) includes a propulsion system, a camera system, a processor, and communications circuitry. The camera system includes an image channel with a band pass filter centered near a spectral line of a material associated with wildfires, and the camera system captures a spectral line emission image within a region of a potential wildfire. The processor uses the captured spectral line emission image to identify an emission event indicative of a wildfire. The communications circuitry transmits, to a dispatch system, data describing a location of an identified emission event. The dispatch system may dispatch firefighting resources to the location of the wildfire."
Wildfire surveillance UAV and fire surveillance system,https://lens.org/020-438-951-276-339,2022,"An unmanned aerial vehicle (UAV) includes a propulsion system, a camera system, a processor, and communications circuitry. The camera system includes an image channel with a band pass filter centered near a spectral line of a material associated with wildfires, and the camera system captures a spectral line emission image within a region of a potential wildfire. The processor uses the captured spectral line emission image to identify an emission event indicative of a wildfire. The communications circuitry transmits, to a dispatch system, data describing a location of an identified emission event. The dispatch system may dispatch firefighting resources to the location of the wildfire."
AUTONOMOUS VEHICLE AND METHOD OF CONTROLLING THE SAME,https://lens.org/116-394-126-816-883,2019,"An autonomous vehicle include an object detection device configured to detect external information about the autonomous vehicle, a communication device configured to receive user information from a remote device, and one or more processors. The one or more processors are configured to: determine internal information about the autonomous vehicle; change control of the autonomous vehicle based on at least one of the external information, the user information, or the internal information; and transmit, to the remote device, monitoring information corresponding to the changed control of the autonomous vehicle."
AUTONOMOUS VEHICLE AND METHOD OF CONTROLLING THE SAME,https://lens.org/117-454-274-356-274,2019,"An autonomous vehicle include an object detection device configured to detect external information about the autonomous vehicle, a communication device configured to receive user information from a remote device, and one or more processors. The one or more processors are configured to: determine internal information about the autonomous vehicle; change control of the autonomous vehicle based on at least one of the external information, the user information, or the internal information; and transmit, to the remote device, monitoring information corresponding to the changed control of the autonomous vehicle."
Autonomous vehicle and method of controlling the same,https://lens.org/185-049-267-282-120,2021,"An autonomous vehicle include an object detection device configured to detect external information about the autonomous vehicle, a communication device configured to receive user information from a remote device, and one or more processors. The one or more processors are configured to: determine internal information about the autonomous vehicle; change control of the autonomous vehicle based on at least one of the external information, the user information, or the internal information; and transmit, to the remote device, monitoring information corresponding to the changed control of the autonomous vehicle."
AUTONOMOUS VEHICLE AND METHOD OF CONTROLLING THE SAME,https://lens.org/182-055-972-046-918,2019,"An autonomous vehicle include an object detection device configured to detect external information about the autonomous vehicle, a communication device configured to receive user information from a remote device, and one or more processors. The one or more processors are configured to: determine internal information about the autonomous vehicle; change control of the autonomous vehicle based on at least one of the external information, the user information, or the internal information; and transmit, to the remote device, monitoring information corresponding to the changed control of the autonomous vehicle."
"ROBOT CONTROL DEVICE, AND METHOD AND NON-TRANSITORY COMPUTER-READABLE STORAGE MEDIUM FOR CONTROLLING THE SAME",https://lens.org/191-720-889-249-136,2021,"This invention provides a robot control device for controlling a robot configured to perform a predetermined operation, where the robot control device comprises an acquisition unit configured to acquire a plurality of images captured by a plurality of image capturing devices including a first image capturing device and a second image capturing device different from the first image capturing device; and a specification unit configured to use the plurality of captured images acquired by the acquisition unit as inputs to a neural network, and configured to specify a control instruction for the robot based on an output as a result from the neural network."
CHARTING AND SURVEILLANCE RADAR,https://lens.org/038-370-876-557-952,2022,"A millimeter wavelength charting synthetic aperture radar having small dimensions and light weight, carried by an UAV (unmanned aerial vehicle), also referred to as a drone."
UNMANNED AERIAL VEHICLE PROTECTIVE FRAME CONGIGURATION,https://lens.org/121-952-771-929-535,2016,"An unmanned aerial vehicle (UAV) configured to facilitate extended flight duration is disclosed. The UAV comprises a frame configured to provide structural support for the UAV and to provide protection from foreign objects that may come into contact with the UAV. In an embodiment, the frame is formed as a monolithic uni-body to increase the structural integrity of the UAV. The frame comprises a hub, a plurality of motor arms, a plurality of motor mounts, a plurality of support arms and a perimeter protective barrier. Any number of lifting motors and at least one pushing motor are coupled to the monolithic uni-body frame to provide vertical lift and horizontal movement. A plurality of propellers coupled to any number of lifting motors are encompassed by the perimeter protective barrier of the monolithic uni-body frame."
Combination ceiling fan with light and sound generator,https://lens.org/059-258-948-041-472,2007,"A ceiling fan with a light and sound generator is disclosed where the blades of the ceiling fan resemble the rotor blades of a helicopter. Under the blades of the ceiling fan a fixed or replaceable body of a helicopter is located or locatable. The blades of the helicopter may also be changeable to simulate different types of rotors for different helicopters. Control chains extend down from the body of the helicopter to resemble lanyards for repelling from the helicopter. The control chains provide control for fan speed, rotation direction, lighting, and may further include control of sounds that can be generated from the ceiling fan that may simulate commands from the pilot of a helicopter. A remote control can be provided to control the fan light and sound functions. A sensor for detecting the presence of a person in the room may also activate the sound generation."
Combination ceiling fan with light and sound generator,https://lens.org/054-864-503-542-416,2008,"A ceiling fan with a light and sound generator is disclosed where the blades of the ceiling fan resemble the rotor blades of a helicopter. Under the blades of the ceiling fan a fixed or replaceable body of a helicopter is located or locatable. The blades of the helicopter may also be changeable to simulate different types of rotors for different helicopters. Control chains extend down from the body of the helicopter to resemble lanyards for repelling from the helicopter. The control chains provide control for fan speed, rotation direction, lighting, and may further include control of sounds that can be generated from the ceiling fan that may simulate commands from the pilot of a helicopter. A remote control can be provided to control the fan light and sound functions. A sensor for detecting the presence of a person in the room may also activate the sound generation."
LINK ROTOR HEAD AND UNMANNED AERIAL VEHICLE,https://lens.org/034-651-890-344-828,2023,"A link rotor head and an unmanned aerial vehicle are disclosed. The link rotor head includes a main shaft, a rotor hub arranged at an upper end of the main shaft, a rotor assembly rotatably arranged on the rotor hub, a swashplate assembly movably arranged around the main shaft, and a link assembly. The swashplate assembly drives the rotor assembly to rotate via the link assembly. The link assembly includes a phase link, a phase rocker and a pitch link. The phase rocker is rotatably arranged on the rotor hub, with one end of the phase rocker movably connected with the swashplate assembly via the phase link and with an other end of the phase rocker movably connected with the rotor assembly via the pitch link."
LINK ROTOR HEAD AND UNMANNED AERIAL VEHICLE,https://lens.org/034-651-890-344-828,2023,"A link rotor head and an unmanned aerial vehicle are disclosed. The link rotor head includes a main shaft, a rotor hub arranged at an upper end of the main shaft, a rotor assembly rotatably arranged on the rotor hub, a swashplate assembly movably arranged around the main shaft, and a link assembly. The swashplate assembly drives the rotor assembly to rotate via the link assembly. The link assembly includes a phase link, a phase rocker and a pitch link. The phase rocker is rotatably arranged on the rotor hub, with one end of the phase rocker movably connected with the swashplate assembly via the phase link and with an other end of the phase rocker movably connected with the rotor assembly via the pitch link."
Four-rotor aircraft and control device thereof,https://lens.org/089-960-536-461-903,2015,"The invention provides a four-rotor aircraft and a control device thereof. The four-rotor aircraft comprises a four-rotor body, a photographic device and a controller, wherein the body is connected with the photographic device through a photographic base; the controller realizes both-way connection with the four-rotor body through a wireless information transmission module. Compared with the prior art, the four-rotor aircraft disclosed by the invention has the following benefits that when the four-rotor aircraft approaches to an object or a human, a warning lamp on the controller and a warning horn on the controller can automatically send out warnings so as to warn a user; when the four-rotor aircraft has a fault, and the four-rotor aircraft urgently falls or cannot fly due to other problems, the user can restart the four-rotor aircraft by a restart button or restore factory settings by a restoration button, so that the four-rotor aircraft is protected; when the user needs to find the controller, the user can adopt specific intelligent mobile equipment or application software on a computer to send out a finding instruction, and then the warning lamp on the controller and the warning horn on the computer can automatically send out warnings so as to warn the user where the controller is."
SYSTEMS AND METHODS FOR OUTDOOR EVACUATION GUIDANCE USING AN UAV,https://lens.org/128-787-228-387-162,2018,"Systems and methods for outdoor evacuation guidance using an UAV are provided. Some methods can include a UAV receiving a signal from a central station device, and responsive to the signal, the UAV flying over an outdoor environment while emitting one or more messages to direct humans within the outdoor environment to evacuate the outdoor environment."
METHODS AND ENTITIES FOR ALERTING ABOUT FAILURE OF AN UNMANNED AERIAL VEHICLE,https://lens.org/142-982-053-361-569,2023,"A method (20) performed in an unmanned aerial vehicle (2) is provided for alerting about a malfunctioning. The method (20) comprises identifying (51) a malfunctioning in the unmanned aerial vehicle about low battery or fuel, and transmit (52) to a network node (4, 10, 12) a failure report (2) comprising malfunctioning and/or position of the unmanned aerial vehicle (2). Methods in a network node and computer program products are also provided."
METHODS AND ENTITIES FOR ALERTING ABOUT FAILURE OF AN UNMANNED AERIAL VEHICLE,https://lens.org/142-982-053-361-569,2023,"A method (20) performed in an unmanned aerial vehicle (2) is provided for alerting about a malfunctioning. The method (20) comprises identifying (51) a malfunctioning in the unmanned aerial vehicle about low battery or fuel, and transmit (52) to a network node (4, 10, 12) a failure report (2) comprising malfunctioning and/or position of the unmanned aerial vehicle (2). Methods in a network node and computer program products are also provided."
ROBOTIC VACUUM CLEANER,https://lens.org/134-609-180-404-757,2003,"An autonomous robot, that is for example, suitable for operations such as vacuuming and surface cleaning includes a payload configured for vacuum cleaning, a drive system (1004) including a steering system (1030) , a navigation system, and a control system (1000) for integrating operations of the aforementioned systems."
Drone Tours In Security Systems,https://lens.org/127-200-256-037-360,2016,"An unmanned aerial vehicle is described and includes a computer carried by the unmanned aerial vehicle to control flight of the unmanned aerial vehicle and at least one sensor. The unmanned aerial vehicle is caused to fly a specific pattern within a facility, receive sensor data from a sensor carried by the vehicle, apply processing to the sensor data to detect an unacceptable level of detected feature differences in features contained in the sensor data, determine a new flight instruction for the vehicle based on the processing; and send the new flight instruction for the vehicle to a system for controlling flight of the vehicle."
Drone tours in security systems,https://lens.org/110-822-513-856-527,2021,"An unmanned aerial vehicle is described and includes a computer carried by the unmanned aerial vehicle to control flight of the unmanned aerial vehicle and at least one sensor. The unmanned aerial vehicle is caused to fly a specific pattern within a facility, receive sensor data from a sensor carried by the vehicle, apply processing to the sensor data to detect an unacceptable level of detected feature differences in features contained in the sensor data, determine a new flight instruction for the vehicle based on the processing; and send the new flight instruction for the vehicle to a system for controlling flight of the vehicle."
ROBUST AND AUTONOMOUS DOCKING AND RECHARGING OF QUADROTORS,https://lens.org/010-411-316-113-781,2016,"A method of docking and recharging using a base station and a station-mating frame on the multicopter. The base station includes an upward-facing camera that is used by a docking controller to detect the presence, position, and orientation of a frame, with infrared light-emitting diodes arranged in a predefined pattern. The controller of the base station acts to emit wireless signals to the multicopter to guide the multicopter with its station-mating frame to a predefined position above the base station. The controller transmits a wireless signal to the multicopter to reduce thrust, and the multicopter lowers itself onto a sloped receiving surface that may be arranged in a crown pattern to provide passive gravity-driven centering, which causes the station-mating frame to slide to a lowest vertical point of the receiving assembly. A locking mechanism engages to lock the frame in place and provide electrical contact for recharging."
Robust and autonomous docking and recharging of quadrotors,https://lens.org/054-723-547-555-228,2017,"A method of docking and recharging using a base station and a station-mating frame on the multicopter. The base station includes an upward-facing camera that is used by a docking controller to detect the presence, position, and orientation of a frame, with infrared light-emitting diodes arranged in a predefined pattern. The controller of the base station acts to emit wireless signals to the multicopter to guide the multicopter with its station-mating frame to a predefined position above the base station. The controller transmits a wireless signal to the multicopter to reduce thrust, and the multicopter lowers itself onto a sloped receiving surface that may be arranged in a crown pattern to provide passive gravity-driven centering, which causes the station-mating frame to slide to a lowest vertical point of the receiving assembly. A locking mechanism engages to lock the frame in place and provide electrical contact for recharging."
WILDLIFE TRACKING SYSTEM,https://lens.org/077-129-124-876-698,2022,"The present disclosure relates to a system for tracking wildlife such as game animals. The tracking system includes a drone that has a camera and a dart dispenser that dispenses a dart with a location transmitter. The drone sends images from the camera to a remote controller, where a user pilots the drone and observes animals for disease or other behaviors, and sends instructions to dispense the dart. The real-time location of the dart is then provided to a mobile application for use in tracking or hunting the animal."
Scissor arm for unmanned robotic system,https://lens.org/055-654-113-708-581,2021,"The present invention recites a scissor arm for an unmanned robotic system such as a UAV, also known as a drone. This arm would typically be installed on the underside of a UAV with hover capability. The arm is designed to simultaneously vertically lower and horizontally extend a payload, permitting a person to interact with the payload without risk of injury by the UAV's propellers. This arm is practical for applications such as a routine police traffic stop, wherein an officer can safely remain in their vehicle and interact with the driver via a drone equipped with communication equipment and such an arm. The drone's arm can present the driver with a box for gathering documents from the driver without risk of injuring the driver or damaging the driver's vehicle. This is accomplished by two inventive L-shaped trusses that offset the arm's payload horizontally as the arm is extended downward."
JET-PUMP-BASED AUTONOMOUS UNDERWATER VEHICLE AND METHOD FOR COUPLING TO OCEAN BOTTOM DURING MARINE SEISMIC SURVEY,https://lens.org/010-327-194-488-400,2014,An autonomous underwater vehicle (AUV) for recording seismic signals during a marine seismic survey. The AUV includes a body having a head part and a tail part); a propulsion system for guiding the AUV to a final target on the ocean bottom; a jet pump group connected to the body and including plural jet pumps; a control device connected to the jet pumps; and a seismic sensor configured to record seismic signals. The jet pump group controls a steering of the AUV by generating water jets according to a given sequence.
Electronic device supporting improved speech recognition,https://lens.org/187-210-155-475-957,2023,"An electronic device is provided. The electronic device includes a microphone, a processor operatively connected to the microphone, and a memory operatively connected to the processor, wherein the memory, when executed, stores instructions for causing the processor to receive first speech data through the microphone, recognize a user input to call a voice assistant from the first speech data, convert the user input into a first wakeup score, determine the electronic device as a first reference device at least based on the first wakeup score that exceeds a designated threshold value, configure a first noise reduction space based on location information of the first reference device, determine at least one of one or more electronic devices, located in the first noise reduction space, as a first noise reduction device to perform a noise reduction operation, and control the noise reduction operation of the first noise reduction device."
ELECTRONIC DEVICE SUPPORTING IMPROVED SPEECH RECOGNITION,https://lens.org/088-352-600-612-222,2021,"An electronic device is provided. The electronic device includes a microphone, a processor operatively connected to the microphone, and a memory operatively connected to the processor, wherein the memory, when executed, stores instructions for causing the processor to receive first speech data through the microphone, recognize a user input to call a voice assistant from the first speech data, convert the user input into a first wakeup score, determine the electronic device as a first reference device at least based on the first wakeup score that exceeds a designated threshold value, configure a first noise reduction space based on location information of the first reference device, determine at least one of one or more electronic devices, located in the first noise reduction space, as a first noise reduction device to perform a noise reduction operation, and control the noise reduction operation of the first noise reduction device."
ELECTRONIC DEVICE SUPPORTING IMPROVED SPEECH RECOGNITION,https://lens.org/091-675-079-663-671,2021,"An electronic device is provided. The electronic device includes a microphone, a processor operatively connected to the microphone, and a memory operatively connected to the processor, wherein the memory, when executed, stores instructions for causing the processor to receive first speech data through the microphone, recognize a user input to call a voice assistant from the first speech data, convert the user input into a first wakeup score, determine the electronic device as a first reference device at least based on the first wakeup score that exceeds a designated threshold value, configure a first noise reduction space based on location information of the first reference device, determine at least one of one or more electronic devices, located in the first noise reduction space, as a first noise reduction device to perform a noise reduction operation, and control the noise reduction operation of the first noise reduction device."
Electronic device supporting improved speech recognition,https://lens.org/187-210-155-475-957,2023,"An electronic device is provided. The electronic device includes a microphone, a processor operatively connected to the microphone, and a memory operatively connected to the processor, wherein the memory, when executed, stores instructions for causing the processor to receive first speech data through the microphone, recognize a user input to call a voice assistant from the first speech data, convert the user input into a first wakeup score, determine the electronic device as a first reference device at least based on the first wakeup score that exceeds a designated threshold value, configure a first noise reduction space based on location information of the first reference device, determine at least one of one or more electronic devices, located in the first noise reduction space, as a first noise reduction device to perform a noise reduction operation, and control the noise reduction operation of the first noise reduction device."
Method and system for detecting water depth and piloting vessels,https://lens.org/153-879-963-424-753,1988,The depth of water ahead of a vessel is detected by sonar means carried aboard a drone stationed by radio control ahead of the vessel. Detected depth information is transmitted from the drone to the vessel where it is displayed for use by the vessel pilot in navigating shallow waters.
SYSTEMS AND STRUCTURES OF UNMANNED AERIAL VEHICLES,https://lens.org/150-708-999-980-780,2022,"A system of an unmanned aerial vehicle (UAV) includes a first body of the UAV capable of flying, a second body detachably attached to the first body and capable of being a stabilizer, and a power storage system capable of powering the first body and the second body. The system further includes one or more sensors, at least one processor, and at least one storage medium storing instructions. When executed, the instructions in the at least one storage medium configure the processor to receive sensor data from the one or more sensors."
SYSTEMS AND STRUCTURES OF UNMANNED AERIAL VEHICLES,https://lens.org/150-708-999-980-780,2022,"A system of an unmanned aerial vehicle (UAV) includes a first body of the UAV capable of flying, a second body detachably attached to the first body and capable of being a stabilizer, and a power storage system capable of powering the first body and the second body. The system further includes one or more sensors, at least one processor, and at least one storage medium storing instructions. When executed, the instructions in the at least one storage medium configure the processor to receive sensor data from the one or more sensors."
SYSTEM FOR CONTROLLING UNMANNED AERIAL VEHICLE AND METHOD THEREOF,https://lens.org/113-310-534-011-072,2022,"A system for controlling an unmanned aerial vehicle may control to receive a departure point and a destination from a vehicle, and transmit information related to a shadow area between the departure point and the destination to the unmanned aerial vehicle to control the unmanned aerial vehicle to measure a communication sensitivity for each altitude in the shadow area."
ROBOTIC DEVICE,https://lens.org/140-863-163-352-01X,2008,"A robotic device in accordance with a plurality of embodiments is provided. The robotic device generally includes a plurality of groups of sensing devices for sensing environmental events; a plurality of controllers for recognizing the environmental events and generating corresponding commands; a plurality of driving devices for driving the robotic device to respond to the environmental events under control of the commands; at least one communication line for communication between the controllers; at least one power line for transmitting power to the sensing devices, the controllers and the driving devices; a plurality of ground lines; a plurality of branches extending out from the communication line, the power line and the ground lines; and a plurality of connectors for connecting the controllers to the branches."
Systems and methods for utilizing unmanned aerial vehicles to monitor hazards for users,https://lens.org/121-956-342-854-844,2019,"Various methods for utilizing an unmanned aerial vehicle (UAV) to monitor hazards for a user may include maintaining the UAV at a monitoring position relative to the user, monitoring an area surrounding the user for approaching objects, detecting an approaching object, determining whether the approaching object poses a danger to the user, and performing one or more actions to mitigate the danger of the approaching object in response to determining that the approaching object poses a danger to the user."
Systems and Methods for Utilizing Unmanned Aerial Vehicles to Monitor Hazards for Users,https://lens.org/073-055-957-497-014,2018,"Various methods for utilizing an unmanned aerial vehicle (UAV) to monitor hazards for a user may include maintaining the UAV at a monitoring position relative to the user, monitoring an area surrounding the user for approaching objects, detecting an approaching object, determining whether the approaching object poses a danger to the user, and performing one or more actions to mitigate the danger of the approaching object in response to determining that the approaching object poses a danger to the user."
Ballast control mechanisms for aerial vehicles,https://lens.org/046-740-690-397-562,2018,"An automated aerial vehicle (AAV) and systems, devices, and techniques pertaining to moveable ballast that is movable onboard the AAV during operation and/or flight. The AAV may include a frame or support structure that includes the movable ballast. A ballast controller may be used to cause movement of the ballast based on one or more factors, such as a type of flight, a type of operation of the AAV, a speed of the AAV, a triggering event, and/or other factors. The ballast may be moved using mechanical, electrical, electromagnetic, pneumatic, hydraulic and/or other devices/techniques described herein. In some embodiments, the ballast may be moved or located in or toward a centralized position in the AAV to enable more agile control of the AAV. The ballast may be moved outward from the centralized location of the AAV to enable more stable control of the AAV."
"Unmanned Aerial Vehicle, Unmanned Aerial Vehicle Flight Control Device, Unmanned Aerial Vehicle Flight Control Method and Program",https://lens.org/103-704-227-953-00X,2022,"Provided are a flight control device, a flight control method, and the like for measuring the distance between the body of an aircraft and a target element during flight and controlling the distance in accordance with the measured value. This unmanned aircraft flight control device comprises: a distance sensor for measuring the distance between a target element and an unmanned aircraft that flies by control using an external input signal and/or pre-generated flight plan information, the distance sensor comprising an imaging camera that captures the target element, and a measured value determination circuit that determines a measured value of the distance using the captured image information; and a control signal generation circuit that generates a control signal for controlling the distance between the target element and the unmanned aircraft during flight, in accordance with the distance measurement value measured by the distance sensor."
Fixed-wing VTOL aerial vehicle,https://lens.org/021-926-548-624-355,2022,"A long-distance drone is disclosed having a canard wing configuration with a cabin attached to a left main wing and a right main wing. There is a left forewing and a right forewing connected together to form a single-piece forewing. There is a left linear support connecting the left forewing to the left main wing, and a right linear support connecting the right forewing to the right main wing. A plurality of propellers is disposed on the left and the right linear supports."
Fixed-Wing VTOL Aerial Vehicle,https://lens.org/131-412-412-629-528,2022,"A long-distance drone is disclosed having a canard wing configuration with a cabin attached to a left main wing and a right main wing. There is a left forewing and a right forewing connected together to form a single-piece forewing. There is a left linear support connecting the left forewing to the left main wing, and a right linear support connecting the right forewing to the right main wing. A plurality of propellers is disposed on the left and the right linear supports."
Digital interconnect of entertainment equipment,https://lens.org/158-371-226-201-917,2008,"A remote control for communicating commands to a target device having first data that specifies a function supported by the target device. The remote control includes a set of command key indicias, stored within the universal remote control prior to any communications with the target device, each command key indicia being assigned a function identifier. The remote control is adapted to receive the first data from the target device and select a command key indicia from the set of command key indicias that has a function identifier that corresponds to the function specified by the first data. The selected command key indicia is displayable on a display of the universal remote control in association with a command key actuatable to communicate one or more commands to the target device to control the function supported by the target device that is represented by the first data."
Digital interconnect of entertainment equipment,https://lens.org/095-918-820-435-428,2005,"A remote control for communicating commands to a target device having first data that specifies a function supported by the target device. The remote control includes a set of command key indicias, stored within the universal remote control prior to any communications with the target device, each command key indicia being assigned a function identifier. The remote control is adapted to receive the first data from the target device and select a command key indicia from the set of command key indicias that has a function identifier that corresponds to the function specified by the first data. The selected command key indicia is displayable on a display of the universal remote control in association with a command key actuatable to communicate one or more commands to the target device to control the function supported by the target device that is represented by the first data."
Digital interconnect of entertainment equipment,https://lens.org/042-494-379-230-229,2005,"A remote control for communicating commands to a target device having first data that specifies a function supported by the target device. The remote control includes a set of command key indicias, stored within the universal remote control prior to any communications with the target device, each command key indicia being assigned a function identifier. The remote control is adapted to receive the first data from the target device and select a command key indicia from the set of command key indicias that has a function identifier that corresponds to the function specified by the first data. The selected command key indicia is displayable on a display of the universal remote control in association with a command key actuatable to communicate one or more commands to the target device to control the function supported by the target device that is represented by the first data."
Digital interconnect of entertainment equipment,https://lens.org/163-276-303-839-611,2006,"A remote control for communicating commands to a target device having first data that specifies a function supported by the target device. The remote control includes a set of command key indicias, stored within the universal remote control prior to any communications with the target device, each command key indicia being assigned a function identifier. The remote control is adapted to receive the first data from the target device and select a command key indicia from the set of command key indicias that has a function identifier that corresponds to the function specified by the first data. The selected command key indicia is displayable on a display of the universal remote control in association with a command key actuatable to communicate one or more commands to the target device to control the function supported by the target device that is represented by the first data."
ROBOT SYSTEM AND METHOD FOR CREATING ARTICLES USING SAME,https://lens.org/159-136-344-524-473,2020,"The robot system of the present disclosure includes a robot (10) having a robot body (1) and a robot controller (3) configured to control operation of the robot body (1), and an unmanned aerial vehicle (4) capable of autonomous flight. The unmanned aerial vehicle (4) acquires at least one of image pick-up data of a work of the robot body (1) and positional information of a work object of the robot body (1), and transmits at least one of the image pick-up data and the positional information to the robot controller (3). The robot controller (3) receives at least one of the image pick-up data and the positional information of the work object, and controls the operation of the robot body (1) by using at least one of the image pick-up data and the positional information of the work object."
UNMANNED AERIAL VEHICLE LAUNCHING CAPSULE,https://lens.org/145-563-119-017-529,2020,"A system for releasing an Unmanned Aerial Vehicle (UAV), comprising: a capsule comprising: a UAV comprising a controller; and a release actuator configured to release the UAV from the capsule; wherein the capsule is configured to be at least one of launched and deployed; the system further comprises: at least one sensor; a release condition evaluation module, connected with the at least one sensor; and a release command module, connected with the release condition evaluation module, and configured to activate the release actuator upon at least one release condition being met; wherein the process of deploying the capsule and/or launching the capsule is a separate process from the process of releasing the UAV from the capsule."
"UNMANNED AIRCRAFT, INFORMATION PROCESSING METHOD, AND PROGRAM",https://lens.org/052-644-375-241-610,2021,"An unmanned aircraft (100) includes: a sensor that includes at least a microphone (105) that generates sound data; and a processor (101). The processor (101) determines quality of a target sound using the sound data generated by the microphone (105), obtains a positional relationship between the unmanned aircraft (100) and a sound source (400) of the target sound using data generated by the sensor, and controls movement of the unmanned aircraft (100) to control a distance between the unmanned aircraft (100) and the sound source (400) of the target sound, in accordance with the quality of the target sound and the positional relationship."
Invertible drone for selective power capture,https://lens.org/036-604-804-902-610,2018,Various embodiments include methods for operating a photovoltaic-powered drone having a photovoltaic surface on one side of at least one of wing or fuselage body of the drone. The method may include determining a flight attitude for the drone based on a first drone attitude for optimizing light energy harvesting by the photovoltaic surface and a second drone attitude for minimizing power expenditure by an onboard propulsion system of the drone to reach a designated destination. The method may include flying the drone in the determined flight attitude while converting light into electricity en route to the designated destination.
System and methods for preventing the unauthorized use of aircraft,https://lens.org/045-491-370-117-807,2006,An aircraft having a memory loaded with geolocation data corresponding to restricted airspace boundaries and an autonomous system for rerouting the aircraft outside of the restricted airspace boundaries as the aircraft approaches to within a predetermined distance of the restricted airspace.
Unmanned aerial vehicle system for taking close-up picture of facility and photography method using the same,https://lens.org/118-849-669-513-505,2018,"Provided are an unmanned aerial vehicle system for taking a close-up picture of a facility and a photography method using the same. The unmanned aerial vehicle system can safely bring a drone, which is an unmanned aerial vehicle, close to a facility surface, which is a subject, using supports and settling members to precisely photograph damage, deterioration, and defects on the facility surface and can safely bring the unmanned aerial vehicle close to the facility and fix the unmanned aerial vehicle on the facility in a perpendicular direction with respect to the subject surface of the facility to improve the quality of an image captured by a camera when the unmanned aerial vehicle is remotely controlled or autonomously navigates."
UNMANNED AERIAL VEHICLE SYSTEM FOR TAKING CLOSE-UP PICTURE OF FACILITY AND PHOTOGRAPHY METHOD USING THE SAME,https://lens.org/037-310-428-778-136,2018,"Provided are an unmanned aerial vehicle system for taking a close-up picture of a facility and a photography method using the same. The unmanned aerial vehicle system can safely bring a drone, which is an unmanned aerial vehicle, close to a facility surface, which is a subject, using supports and settling members to precisely photograph damage, deterioration, and defects on the facility surface and can safely bring the unmanned aerial vehicle close to the facility and fix the unmanned aerial vehicle on the facility in a perpendicular direction with respect to the subject surface of the facility to improve the quality of an image captured by a camera when the unmanned aerial vehicle is remotely controlled or autonomously navigates."
Aerial support structure for capturing an image of a target,https://lens.org/161-547-666-234-389,2012,"An aerial support structure for capturing an image of a target via a camera mounted thereon includes a support platform, a frame mounted to the support platform and a beam movably attached to the frame. A camera platform suspends and is axially spaced from the support platform by a plurality of support cables. An actuator is mounted to one of the support platform and the frame, and the actuator is associated with each of the plurality of support cables. Operation of the actuator causes the beam to move with respect to the frame, thereby moving the camera platform relative to the support platform."
AERIAL SUPPORT STRUCTURE FOR CAPTURING AN IMAGE OF A TARGET,https://lens.org/062-662-564-388-138,2011,"An aerial support structure for capturing an image of a target via a camera mounted thereon includes a support platform, a frame mounted to the support platform and a beam movably attached to the frame. A camera platform suspends and is axially spaced from the support platform by a plurality of support cables. An actuator is mounted to one of the support platform and the frame, and the actuator is associated with each of the plurality of support cables. Operation of the actuator causes the beam to move with respect to the frame, thereby moving the camera platform relative to the support platform."
AUTOMATED ALERT SYSTEM USING UNMANNED AERIAL VEHICLES,https://lens.org/135-346-892-953-265,2021,An automated alert system using unmanned aerial vehicles is described where the system is configured to monitor a selected area via one or more sensors configured to monitor the selected area for an anomaly. A processor in communication with the one or more sensors may be programmed to create or alter a flight path of an unmanned aerial vehicle upon receiving an alert from the one or more sensors for investigating or verifying the anomaly.
FLYING SENSOR,https://lens.org/138-486-945-989-67X,2018,"A flying sensor comprising an unmanned aerial vehicle (UAV) and at least one profiler mounted on the UAV, the profiler comprising a base, a scanning unit for providing (LiDAR) data, the scanning unit mounted on the base and comprising a shaft carrying a deflector and being mounted in the scanning unit and rotatable, a transmitter transmitting a transmission beam, a first receiver configured for receiving a first reception beam reflected from the setting via the deflector, and an electric port configured for connecting the profiler to the UAV, and comprising a data interface and a power interface, and wherein the UAV comprises a visual sensor providing visual data, and comprising one or more cameras, a pose sensor for providing pose data, and a computer to compute a 3D point cloud based on the LiDar data and a Simultaneous Localisation and Mapping (SLAM) algorithm using the visual and pose data."
Target sensing and homing system,https://lens.org/179-241-224-829-918,1979,"A low cost system using passive radiometry or active radar for the detection of a target and providing discrimination between desired targets and false targets. The device may be mounted on a drone aircraft or other vehicle and comprises a detecting sensor having a fixed antenna system whose function is to detect the presence and direction to a target in airframe coordinates. The sensor provides means for generating a broad fan beam containing a plurality of closely spaced interference lobes spaced so as to encompass a predetermined target size. The interference lobes are continuously swept across the line of travel and the receiving circuitry provides means for detecting a desired target within the interference lobes. The system also provides a pre-programmed means, initiated by the target sensor, designed to aim the aircraft at the target and a target tracker or homing means having a fixed antenna directed along the heading axis of the drone aircraft and used to ""home"" the aircraft into the target."
UAV CELLULAR COMMUNICATION SERVICE DELIVERY,https://lens.org/044-896-189-102-474,2018,"The use of UAV network cells may enable a wireless communication carrier to provide supplemental cellular network communication coverage to geographical areas. Geolocations of multiple user devices in a geographical area that is serviced by an unmanned aerial vehicle (UAV) network cell may be determined. Subsequently, operation condition data for the geographical area that affect at least one of UAV flight or UAV communication signal transmission or reception for the UAV network cell may be received. Accordingly, a flight trajectory that provides network coverage to one or more specific user devices in the geographical area may be generated based on the geolocations of the multiple user devices and the operation condition data. A control command is then sent to the UAV network cell to direct the UAV network cell to travel according to the flight trajectory."
UAV cellular communication service delivery,https://lens.org/142-800-196-483-539,2018,"The use of UAV network cells may enable a wireless communication carrier to provide supplemental cellular network communication coverage to geographical areas. Geolocations of multiple user devices in a geographical area that is serviced by an unmanned aerial vehicle (UAV) network cell may be determined. Subsequently, operation condition data for the geographical area that affect at least one of UAV flight or UAV communication signal transmission or reception for the UAV network cell may be received. Accordingly, a flight trajectory that provides network coverage to one or more specific user devices in the geographical area may be generated based on the geolocations of the multiple user devices and the operation condition data. A control command is then sent to the UAV network cell to direct the UAV network cell to travel according to the flight trajectory."
UAV cellular communication service delivery,https://lens.org/083-251-539-613-036,2017,"The use of UAV network cells may enable a wireless communication carrier to provide supplemental cellular network communication coverage to geographical areas. Geolocations of multiple user devices in a geographical area that is serviced by an unmanned aerial vehicle (UAV) network cell may be determined. Subsequently, operation condition data for the geographical area that affect at least one of UAV flight or UAV communication signal transmission or reception for the UAV network cell may be received. Accordingly, a flight trajectory that provides network coverage to one or more specific user devices in the geographical area may be generated based on the geolocations of the multiple user devices and the operation condition data. A control command is then sent to the UAV network cell to direct the UAV network cell to travel according to the flight trajectory."
"POWER SYSTEM, POWER SYSTEM CONTROL METHOD, UAV AND UAV CONTROL METHOD",https://lens.org/180-280-200-437-730,2023,"A power system, a power system control method, an unmanned aerial vehicle (UAV) and a UAV control method are disclosed. The power system includes an engine, a motor, and a battery. The engine includes an engine body and an engine output shaft. The motor includes a stator, a rotor, and a stator connector for connecting the stator and the rotor. The stator connector is arranged on the engine body, and the rotor is coaxially arranged on the engine output shaft. The rotor is used for coaxial connection with the external power receiver. The battery is connected to the motor, and the battery can be discharged to provide electric energy to the motor, or receive the electric energy output by the motor for charging."
"POWER SYSTEM, POWER SYSTEM CONTROL METHOD, UAV AND UAV CONTROL METHOD",https://lens.org/180-280-200-437-730,2023,"A power system, a power system control method, an unmanned aerial vehicle (UAV) and a UAV control method are disclosed. The power system includes an engine, a motor, and a battery. The engine includes an engine body and an engine output shaft. The motor includes a stator, a rotor, and a stator connector for connecting the stator and the rotor. The stator connector is arranged on the engine body, and the rotor is coaxially arranged on the engine output shaft. The rotor is used for coaxial connection with the external power receiver. The battery is connected to the motor, and the battery can be discharged to provide electric energy to the motor, or receive the electric energy output by the motor for charging."
Operation system for working machine,https://lens.org/014-272-762-567-204,2020,"An operating system for a working machine includes drones having GNSS receivers, and working machines having take-off and landing ports and is configured so that positional information on the working machines is acquired by the GNSS receivers of the drones to be placed on the take-off and landing ports."
OPERATION SYSTEM FOR WORKING MACHINE,https://lens.org/077-386-541-381-917,2020,"An operating system for a working machine includes drones having GNSS receivers, and working machines having take-off and landing ports and is configured so that positional information on the working machines is acquired by the GNSS receivers of the drones to be placed on the take-off and landing ports."
Avionics framework,https://lens.org/101-007-024-325-330,2007,A modular avionics system for an Unmanned Aerial Vehicle (UAV) has a control module that executes flight control and vertical and lateral guidance algorithms to generate control commands. A data link module communicates with a remote control station and receives control commands from the remote control station. A data acquisition module communicates with the control module and the data link module. The data acquisition module is configured to receive and process data from one or more onboard sensors and to actuate a plurality of servo motors in response to control commands. A switching module selectively couples the data acquisition module to the control module or to the data link module responsive to an input from the remote control station to respectively switch between a fully autonomous mode of UAV operation and a manual mode of UAV operation. Power may be provided by a power module.
Avionics framework,https://lens.org/067-879-925-976-592,2010,A modular avionics system for an Unmanned Aerial Vehicle (UAV) has a control module that executes flight control and vertical and lateral guidance algorithms to generate control commands. A data link module communicates with a remote control station and receives control commands from the remote control station. A data acquisition module communicates with the control module and the data link module. The data acquisition module is configured to receive and process data from one or more onboard sensors and to actuate a plurality of servo motors in response to control commands. A switching module selectively couples the data acquisition module to the control module or to the data link module responsive to an input from the remote control station to respectively switch between a fully autonomous mode of UAV operation and a manual mode of UAV operation. Power may be provided by a power module.
MANAGING AUTONOMOUS VEHICLES,https://lens.org/178-802-077-803-03X,2021,"Some embodiments include a method for providing control information to autonomous vehicles. The method may include receiving a video content stream over an electronic communication interface. The method may include identifying objects represented in the video content stream; determining information about the objects. The method may include transmitting, to one or more autonomous vehicles, one or more data streams including the information about the objects."
Autonomous action robot,https://lens.org/019-551-651-375-414,2003,"The present invention provides an autonomous action robot which can turn its line of sight to face a person who calls out, can recognize the face of a person, and can perform various actions in response to commands. First, a sound emitted from a person or other sound source is detected by a sound detector, and the direction of the sound source is specified based on the detected sound. Then, a robot head section is controlled, and the imaging direction of the robot head section is moved to face the specified direction of the sound source. Next, an image is captured in the direction of the sound source, and a target image of a specific shape is extracted from the captured image. Then, the imaging direction of the robot head section is controlled and moved to face in the direction of the extracted target image."
Antenna system for unmanned aerial vehicle,https://lens.org/110-213-325-935-128,2020,"An antenna system for an unmanned aerial vehicle (UAV) includes an antenna and a self-leveling antenna mount configured to mount the antenna to the UAV. The antenna is configured to receive commands for the UAV via a network and to transmit data from the UAV via the network. The antenna has a transmit-receive pattern with a peak strength in a first direction aligned with an axis of the antenna. The transmit-receive pattern falls off in directions away from the axis of the antenna. The self-leveling antenna mount is configured to adjust an orientation of the antenna to maintain substantial alignment between the first direction and a straight downward direction relative to the UAV despite a change in roll, pitch, or bank of the UAV. In some embodiments, the axis of the antenna is a downward vertical axis of the antenna."
ANTENNA SYSTEM FOR UNMANNED AERIAL VEHICLE,https://lens.org/078-014-985-715-155,2019,"An antenna system for an unmanned aerial vehicle (UAV) includes an antenna and a self-leveling antenna mount configured to mount the antenna to the UAV. The antenna is configured to receive commands for the UAV via a network and to transmit data from the UAV via the network. The antenna has a transmit-receive pattern with a peak strength in a first direction aligned with an axis of the antenna. The transmit-receive pattern falls off in directions away from the axis of the antenna. The self-leveling antenna mount is configured to adjust an orientation of the antenna to maintain substantial alignment between the first direction and a straight downward direction relative to the UAV despite a change in roll, pitch, or bank of the UAV. In some embodiments, the axis of the antenna is a downward vertical axis of the antenna."
ANTENNA SYSTEM FOR UNMANNED AERIAL VEHICLE,https://lens.org/171-934-519-042-937,2021,"An antenna system for an unmanned aerial vehicle (UAV) includes an antenna and a self-leveling antenna mount configured to mount the antenna to the UAV. The antenna is configured to receive commands for the UAV via a network and to transmit data from the UAV via the network. The antenna has a transmit-receive pattern with a peak strength in a first direction aligned with an axis of the antenna. The transmit-receive pattern falls off in directions away from the axis of the antenna. The self-leveling antenna mount is configured to adjust an orientation of the antenna to maintain substantial alignment between the first direction and a straight downward direction relative to the UAV despite a change in roll, pitch, or bank of the UAV. In some embodiments, the axis of the antenna is a downward vertical axis of the antenna."
ANTENNA SYSTEM FOR UNMANNED AERIAL VEHICLE,https://lens.org/133-306-879-491-79X,2021,"An antenna system for an unmanned aerial vehicle (UAV) includes an antenna and a self-leveling antenna mount configured to mount the antenna to the UAV. The antenna is configured to receive commands for the UAV via a network and to transmit data from the UAV via the network. The antenna has a transmit-receive pattern with a peak strength in a first direction aligned with an axis of the antenna. The transmit-receive pattern falls off in directions away from the axis of the antenna. The self-leveling antenna mount is configured to adjust an orientation of the antenna to maintain substantial alignment between the first direction and a straight downward direction relative to the UAV despite a change in roll, pitch, or bank of the UAV. In some embodiments, the axis of the antenna is a downward vertical axis of the antenna."
RADAR-BASED SMART DEVICE CONTROL,https://lens.org/163-194-841-661-110,2021,"Systems and methods for smart device control using radar are disclosed. According to some aspects, a machine receives, using a millimeter-wave multiple antenna array, a radar signal. The machine preprocesses the radar signal to generate radar metadata. The machine determines, using a trained machine learning engine and based on at least the radar metadata, a moving entity and a movement type. The machine identifies, based on at least the determined moving entity and the determined movement type, a smart device and an action for the smart device to take in response to the movement type by the moving entity. The machine transmits, to the smart device, a control signal for the identified action."
SYSTEM AND METHOD FOR SMART DEVICE CONTROL USING RADAR,https://lens.org/116-213-844-938-361,2021,"Systems and methods for smart device control using radar are disclosed. According to some aspects, a machine receives, using a millimeter-wave multiple antenna array, a radar signal. The machine preprocesses the radar signal to generate radar metadata. The machine determines, using a trained machine learning engine and based on at least the radar metadata, a moving entity and a movement type. The machine identifies, based on at least the determined moving entity and the determined movement type, a smart device and an action for the smart device to take in response to the movement type by the moving entity. The machine transmits, to the smart device, a control signal for the identified action."
"Emergency incident detection, response, and mitigation using autonomous drones",https://lens.org/014-795-465-812-43X,2020,"A system may be configured to detect an emergency condition at a premises; dispatch one or more autonomous drones to a location associated with the emergency condition; receive from the one or more autonomous drones, sensor data associated with the emergency condition; generate, based on the sensor data, a plan identifying an evacuation route for safely evacuating the premises; and transmit an instruction that causes the one or more autonomous drones to indicate, to one or more persons in a vicinity of the emergency condition, the evacuation route. The system may further detect, based on the sensor data, one or more safe areas in the premises, and the evacuation route may pass through at least one of the one or more safe areas."
"EMERGENCY INCIDENT DETECTION, RESPONSE, AND MITIGATION USING AUTONOMOUS DRONES",https://lens.org/174-286-339-160-000,2023,"A system may be configured to detect an emergency condition at a premises; dispatch one or more autonomous drones to a location associated with the emergency condition; receive from the one or more autonomous drones, sensor data associated with the emergency condition; generate, based on the sensor data, a plan identifying an evacuation route for safely evacuating the premises; and transmit an instruction that causes the one or more autonomous drones to indicate, to one or more persons in a vicinity of the emergency condition, the evacuation route. The system may further detect, based on the sensor data, one or more safe areas in the premises, and the evacuation route may pass through at least one of the one or more safe areas."
"Emergency incident detection, response, and mitigation using autonomous drones",https://lens.org/006-177-157-322-780,2022,"A system may be configured to detect an emergency condition at a premises; dispatch one or more autonomous drones to a location associated with the emergency condition; receive from the one or more autonomous drones, sensor data associated with the emergency condition; generate, based on the sensor data, a plan identifying an evacuation route for safely evacuating the premises; and transmit an instruction that causes the one or more autonomous drones to indicate, to one or more persons in a vicinity of the emergency condition, the evacuation route. The system may further detect, based on the sensor data, one or more safe areas in the premises, and the evacuation route may pass through at least one of the one or more safe areas."
"EMERGENCY INCIDENT DETECTION, RESPONSE, AND MITIGATION USING AUTONOMOUS DRONES",https://lens.org/174-286-339-160-000,2023,"A system may be configured to detect an emergency condition at a premises; dispatch one or more autonomous drones to a location associated with the emergency condition; receive from the one or more autonomous drones, sensor data associated with the emergency condition; generate, based on the sensor data, a plan identifying an evacuation route for safely evacuating the premises; and transmit an instruction that causes the one or more autonomous drones to indicate, to one or more persons in a vicinity of the emergency condition, the evacuation route. The system may further detect, based on the sensor data, one or more safe areas in the premises, and the evacuation route may pass through at least one of the one or more safe areas."
Unmanned aerial vehicle with wireless stereo function,https://lens.org/065-746-833-387-035,2015,"The invention relates to an unmanned aerial vehicle with the wireless stereo function. The unmanned aerial vehicle comprises an aerial vehicle body, a power supply module, rotor wing arms, motors, an undercarriage, an unmanned aerial vehicle controller and a wireless stereo system, wherein the power supply module is formed by mutually connecting a charging circuit and a battery capable of being charged repeatedly, the rotor wing arms are fixedly connected with the aerial vehicle body, each motor with one impeller blade is arranged on the corresponding rotor wing arm, the undercarriage is arranged at the bottom of the aerial vehicle body and fixedly connected with the aerial vehicle body, the unmanned aerial vehicle controller is arranged in the body and connected with the motors on the rotor wing arms, and the wireless stereo system is combined with the unmanned aerial vehicle. The unmanned aerial vehicle with the wireless stereo function can fast fly to a certain broadcast height when used, broadcast information in real time to the position below a flight region within the distance range from 300 meters to the farthest voyage of the unmanned aerial vehicle generally according to the used wireless audio transmission mode, and fast and clearly transmit the information and has an excellent information broadcast effect."
AUV based seismic acquisition system and method,https://lens.org/009-586-556-244-667,2020,An autonomous underwater vehicle (AUV) for guiding other AUVs during a marine seismic survey. The guiding AUV includes a housing; a propulsion system located inside the housing; and an acoustic positioning system attached to an outside the housing. The acoustic positioning system emits at least three chirps from three different locations.
AUV BASED SEISMIC ACQUISITION SYSTEM AND METHOD,https://lens.org/130-112-093-425-307,2017,An autonomous underwater vehicle (AUV) for guiding other AUVs during a marine seismic survey. The guiding AUV includes a housing; a propulsion system located inside the housing; and an acoustic positioning system attached to an outside the housing. The acoustic positioning system emits at least three chirps from three different locations.
VTOL FIXED-WING FLYING PLATFORM SYSTEM,https://lens.org/069-263-991-873-791,2020,"An aerial drone having a flying platform (101) and has detachable and interchangeable cabins (130; 140). Each cabin can have an energy storage unit (155) that supplies energy to the flying platform (101) so the when cabins (130; 140) are exchanged, a fresh supply of energy is made available to the flying platform (101). The flying platform (101) and the cabins (130; 140) can have motorized wheels (148) as well as floatation devices (160) for water landing."
Radio controlled toy with remote accessory activation,https://lens.org/008-831-990-682-15X,1998,"A remotely controlled vehicle that mechanically activates an action accessory. The vehicle contains a remotely controlled plunger that engages a trigger of the action accessory. Engaging the trigger activates a mechanism within the action accessory. Activation of the mechanism induces a mechanical action such as ejecting a projectile or loading items onto the vehicle. The plunger and vehicle are remotely controlled by a transmitter which emits command signals to a receiver located within the vehicle. In operation, the end user skillfully manipulates the vehicle over the trigger and then transmits a command to extend the plunger and activate the mechanism of the action accessory."
"Device for the automated vertical take-off, vertical landing, and/or handling of an aerial vehicle with the aid of a robot, aerial vehicle, and end effector",https://lens.org/119-483-705-161-117,2023,"A device for the automated vertical take-off, vertical landing, and/or handling of an aerial vehicle with the aid of a robot, the device including a first connection module and a second connection module, each including a capture and/or release section that is active in a capture and/or release phase and a guide section that is active in a guide phase, and the first connection module and the second connection module being lockable in a holding position. An aerial vehicle capable of automatedly vertically taking off, vertically landing, or being handled with the aid of a robot, the aerial vehicle including a first connection module or a second connection module of such a device. An end effector for a robot for the automated vertical take-off, vertical landing, and/or handling of an aerial vehicle, the end effector including a second connection module or a first connection module of such a device."
"Device for the automated vertical take-off, vertical landing, and/or handling of an aerial vehicle with the aid of a robot, aerial vehicle, and end effector",https://lens.org/119-483-705-161-117,2023,"A device for the automated vertical take-off, vertical landing, and/or handling of an aerial vehicle with the aid of a robot, the device including a first connection module and a second connection module, each including a capture and/or release section that is active in a capture and/or release phase and a guide section that is active in a guide phase, and the first connection module and the second connection module being lockable in a holding position. An aerial vehicle capable of automatedly vertically taking off, vertically landing, or being handled with the aid of a robot, the aerial vehicle including a first connection module or a second connection module of such a device. An end effector for a robot for the automated vertical take-off, vertical landing, and/or handling of an aerial vehicle, the end effector including a second connection module or a first connection module of such a device."
Wireless video and audio broadcasting device,https://lens.org/008-081-366-730-322,2009,"A broadcasting device includes a video and audio transmitter, several video and audio receivers to wirelessly receive signals from the video and audio transmitter, and a remote control; the video and audio transmitter is connected to a computer/multimedia broadcasting device; the video and audio receivers are each connected to a respective broadcasting device so that video and audio information from the computer/multimedia broadcasting device can be transmitted through the transmitter, received with the receivers, and broadcasted through the broadcasting devices connected to the receivers; the remote control is used to give orders to the transmitter and the receivers so as to control video and audio information broadcasted through the broadcasting devices; the transmitter has a wireless signal communication module, and can be connected to internet to serve as a router with signals being received and transmitted through the wireless signal communication module."
CONTROL SYSTEM FOR AUTONOMOUS ALL-TERRAIN VEHICLE (ATV),https://lens.org/177-744-819-035-465,2019,"According to one aspect, an autonomous all-terrain vehicle (ATV) may include a controller receiving a command associated with autonomous driving and monitoring components of the autonomous ATV, a location unit determining a current location associated with the autonomous ATV and a destination location associated with the command, a navigation module determining one or more driving parameters based on map data associated with a path from the current location to the destination location, and a safety logic implementing an emergency stop based on an error determined by the controller. The controller may monitor the location unit and the navigation module for the error."
Control system for autonomous all-terrain vehicle (ATV),https://lens.org/029-604-864-135-333,2021,"According to one aspect, an autonomous all-terrain vehicle (ATV) may include a controller receiving a command associated with autonomous driving and monitoring components of the autonomous ATV, a location unit determining a current location associated with the autonomous ATV and a destination location associated with the command, a navigation module determining one or more driving parameters based on map data associated with a path from the current location to the destination location, and a safety logic implementing an emergency stop based on an error determined by the controller. The controller may monitor the location unit and the navigation module for the error."
"REMOTE CONTROLLER, DISPLAY APPARATUS AND CONTROLLING METHOD THEREOF",https://lens.org/195-422-608-375-380,2018,A remote controller is provided. The remote controller includes a transmitter; a microphone configured to receive an audio signal output from an audio output apparatus; a communicator comprising communication circuitry configured to perform communication with a display apparatus connected to the audio output apparatus and to transmit the audio signal received through the microphone to the display apparatus; and a processor configured to control the transmitter to transmit to the audio output apparatus a signal for controlling a power of the audio output apparatus based on information indicating whether there is a test tone in an audio signal received by the microphone and received from the display apparatus.
"Remote controller, display apparatus and controlling method thereof",https://lens.org/137-298-614-968-618,2020,A remote controller is provided. The remote controller includes a transmitter; a microphone configured to receive an audio signal output from an audio output apparatus; a communicator comprising communication circuitry configured to perform communication with a display apparatus connected to the audio output apparatus and to transmit the audio signal received through the microphone to the display apparatus; and a processor configured to control the transmitter to transmit to the audio output apparatus a signal for controlling a power of the audio output apparatus based on information indicating whether there is a test tone in an audio signal received by the microphone and received from the display apparatus.
"Use of drones to assist with insurance, financial and underwriting related activities",https://lens.org/147-271-816-259-361,2020,"An unmanned insurance drone can include a drone body and a sensor unit disposed on the drone body to collect sensor data. An on-board data processor converts the sensor data into insurance related information, and a wireless communication unit in communication with the data processor to transmit the insurance related information. In another example, the data processor may not be on the drone but remotely located. The location can be with the pilot or a control collection location. If the insurance related information is separate from the drone, than the wireless communication unit can transmit the raw sensor data to the processor."
"USE OF DRONES TO ASSIST WITH INSURANCE, FINANCIAL AND UNDERWRITING RELATED ACTIVITIES",https://lens.org/194-550-816-792-023,2016,"An unmanned insurance drone can include a drone body and a sensor unit disposed on the drone body to collect sensor data. An on-board data processor converts the sensor data into insurance related information, and a wireless communication unit in communication with the data processor to transmit the insurance related information. In another example, the data processor may not be on the drone but remotely located. The location can be with the pilot or a control collection location. If the insurance related information is separate from the drone, than the wireless communication unit can transmit the raw sensor data to the processor."
UNMANNED AERIAL VEHICLE AND BODY THEREOF AND PAN-TILT-ZOOM CAMERA,https://lens.org/140-504-036-936-683,2021,"An unmanned aerial vehicle (UAV) and body thereof, and a gimbal camera. The UAV includes a body (100) that includes a housing (110) provided with an inwardly recessed mounting groove (111) with a notch on one side, and a protective cover (130) arranged at the housing (110) and configured to open and cover the notch, and a gimbal camera (200) including a mounting frame (210) arranged in the mounting groove (111) and detachably connected to the housing (110), a gimbal (230) arranged at the mounting frame (210), and a camera (220) arranged at the gimbal (230). Because the housing is provided with the mounting groove, the size of the UAV having the detachable gimbal can be reduced."
DEVICES AND SYSTEMS FOR REMOTE CONTROL,https://lens.org/077-202-000-920-034,2009,"Remote controllers and systems thereof are disclosed. The remote controller remotely operates a receiving host, in which the receiving host provides voice input and voice recognition functions. The remote controller comprises a first input unit and a second input unit for generating a voice input request and a voice recognition request. The generated voice input and voice recognition requests are then sent to the receiving host, thereby forcing the receiving host to perform the voice input and voice recognition functions."
AERIAL DELIVERY SYSTEM AND METHOD,https://lens.org/128-855-913-370-416,2018,"An aerial delivery system includes an elongate member, a cover, a sensor, and a motorized actuator. The elongate member has both a top end and a bottom end, and is configured to receive items, particularly mail and packages, from a delivery means, particularly an aerial drone. The cover is removably attached to the top end of the elongate member, and is configured to allow entry of mail and packages into the elongate member. The sensor is also removably attached to the top end of the elongate member, and is configured to identify the delivery means."
An unmanned aerial vehicle,https://lens.org/046-211-895-221-68X,2020,"An unmanned aerial vehicle, having a main body comprising at least an elongate backbone (140) with a forward end piece (130) and a rearward end piece (150). The end pieces are wider than the backbone and comprise coupling facilities for respective rotor arms (200), each said rotor arm configured for supporting motor and propeller assemblies. The unmanned aerial vehicle further comprises a pair of elongated batteries (500). The end pieces and at least a portion of the backbone form receptacles on both sides of the backbone for releasably receiving respective electric batteries (500), wherein the batteries, backbone and end pieces form an elongate and substantially rectangular body assembly."
AN UNMANNED AERIAL VEHICLE,https://lens.org/095-742-127-820-92X,2019,"An unmanned aerial vehicle, having a main body comprising at least an elongate backbone (140) with a forward end piece (130) and a rearward end piece (150). The end pieces are wider than the backbone and comprise coupling facilities for respective rotor arms (200), each said rotor arm configured for supporting motor and propeller assemblies. The unmanned aerial vehicle further comprises a pair of elongated batteries (500). The end pieces and at least a portion of the backbone form receptacles on both sides of the backbone for releasably receiving respective electric batteries (500), wherein the batteries, backbone and end pieces form an elongate and substantially rectangular body assembly."
SERVICE FOR TARGETED CROWD SOURCED AUDIO FOR VIRTUAL INTERACTION,https://lens.org/060-099-352-989-078,2020,"An audio generation system is provided to enable coordinated control of multiple IoT devices for audio collection and distribution of one or more audio sources according to location and user preference. The audio generation system enables a location sensitive acoustic control of sound, both as a shaped envelope for a particular source, and as an individualized experience. The audio generation system also facilitates an interactive visual system for visualization and manipulation of the audio environment including via the use of augmented reality and/or virtual reality to depict soundscapes. The audio generation system can also facilitate a system for improving and achieving an audio environment (sound influence zone) and an intuitive way to understand where sounds will be heard."
Service for targeted crowd sourced audio for virtual interaction,https://lens.org/032-592-437-984-376,2022,"An audio generation system is provided to enable coordinated control of multiple IoT devices for audio collection and distribution of one or more audio sources according to location and user preference. The audio generation system enables a location sensitive acoustic control of sound, both as a shaped envelope for a particular source, and as an individualized experience. The audio generation system also facilitates an interactive visual system for visualization and manipulation of the audio environment including via the use of augmented reality and/or virtual reality to depict soundscapes. The audio generation system can also facilitate a system for improving and achieving an audio environment (sound influence zone) and an intuitive way to understand where sounds will be heard."
SERVICE FOR TARGETED CROWD SOURCED AUDIO FOR VIRTUAL INTERACTION,https://lens.org/152-440-262-596-336,2023,"An audio generation system is provided to enable coordinated control of multiple IoT devices for audio collection and distribution of one or more audio sources according to location and user preference. The audio generation system enables a location sensitive acoustic control of sound, both as a shaped envelope for a particular source, and as an individualized experience. The audio generation system also facilitates an interactive visual system for visualization and manipulation of the audio environment including via the use of augmented reality and/or virtual reality to depict soundscapes. The audio generation system can also facilitate a system for improving and achieving an audio environment (sound influence zone) and an intuitive way to understand where sounds will be heard."
SERVICE FOR TARGETED CROWD SOURCED AUDIO FOR VIRTUAL INTERACTION,https://lens.org/152-440-262-596-336,2023,"An audio generation system is provided to enable coordinated control of multiple IoT devices for audio collection and distribution of one or more audio sources according to location and user preference. The audio generation system enables a location sensitive acoustic control of sound, both as a shaped envelope for a particular source, and as an individualized experience. The audio generation system also facilitates an interactive visual system for visualization and manipulation of the audio environment including via the use of augmented reality and/or virtual reality to depict soundscapes. The audio generation system can also facilitate a system for improving and achieving an audio environment (sound influence zone) and an intuitive way to understand where sounds will be heard."
Service for targeted crowd sourced audio for virtual interaction,https://lens.org/032-592-437-984-376,2022,"An audio generation system is provided to enable coordinated control of multiple IoT devices for audio collection and distribution of one or more audio sources according to location and user preference. The audio generation system enables a location sensitive acoustic control of sound, both as a shaped envelope for a particular source, and as an individualized experience. The audio generation system also facilitates an interactive visual system for visualization and manipulation of the audio environment including via the use of augmented reality and/or virtual reality to depict soundscapes. The audio generation system can also facilitate a system for improving and achieving an audio environment (sound influence zone) and an intuitive way to understand where sounds will be heard."
Navigating a mobile robot,https://lens.org/060-252-582-584-314,2022,A method for controlling a robot includes receiving image data from at least one image sensor. The image data corresponds to an environment about the robot. The method also includes executing a graphical user interface configured to display a scene of the environment based on the image data and receive an input indication indicating selection of a pixel location within the scene. The method also includes determining a pointing vector based on the selection of the pixel location. The pointing vector represents a direction of travel for navigating the robot in the environment. The method also includes transmitting a waypoint command to the robot. The waypoint command when received by the robot causes the robot to navigate to a target location. The target location is based on an intersection between the pointing vector and a terrain estimate of the robot.
Navigating a Mobile Robot,https://lens.org/052-570-013-853-290,2021,A method for controlling a robot includes receiving image data from at least one image sensor. The image data corresponds to an environment about the robot. The method also includes executing a graphical user interface configured to display a scene of the environment based on the image data and receive an input indication indicating selection of a pixel location within the scene. The method also includes determining a pointing vector based on the selection of the pixel location. The pointing vector represents a direction of travel for navigating the robot in the environment. The method also includes transmitting a waypoint command to the robot. The waypoint command when received by the robot causes the robot to navigate to a target location. The target location is based on an intersection between the pointing vector and a terrain estimate of the robot.
VERIFYING AUTHORIZED PERSONNEL FOR INTERACTION WITH AUTONOMOUS VEHICLES,https://lens.org/017-425-074-798-627,2023,"An autonomous vehicle (AV) uses an authentication system to verify that a person on the street attempting to control behavior of the AV is authorized to do so. An authorized person (e.g., a construction worker or a police officer) has an associated beacon that provides a beacon signal, such as a visual symbol or wireless signal. The AV perceives the beacon signal and transmits it to the authentication system. The authentication system looks up the beacon signal in a database and retrieves conditions associated with the beacon signal. If the authentication system and/or AV confirms that the beacon signal is in the database, and the conditions under which the person associated with the beacon signal is authorized to control the AV are met, the AV follows instructions from the person."
VERIFYING AUTHORIZED PERSONNEL FOR INTERACTION WITH AUTONOMOUS VEHICLES,https://lens.org/017-425-074-798-627,2023,"An autonomous vehicle (AV) uses an authentication system to verify that a person on the street attempting to control behavior of the AV is authorized to do so. An authorized person (e.g., a construction worker or a police officer) has an associated beacon that provides a beacon signal, such as a visual symbol or wireless signal. The AV perceives the beacon signal and transmits it to the authentication system. The authentication system looks up the beacon signal in a database and retrieves conditions associated with the beacon signal. If the authentication system and/or AV confirms that the beacon signal is in the database, and the conditions under which the person associated with the beacon signal is authorized to control the AV are met, the AV follows instructions from the person."
Precision landing system for unmanned aerial vehicles and utilization thereof,https://lens.org/060-572-971-351-509,2021,"A precision landing system including an unmanned aerial vehicle (UAV) and a beacon is provided. A processor of the UAV controls a flight system of the UAV to fly the UAV. The processor detects, via a sensor of the UAV, a signal emitted by a beacon. The processor controls the flight system of the UAV to land on or near the beacon. The processor also energizes one or more electromagnets on a cradle of the UAV to retrieve the beacon."
PRECISION LANDING SYSTEM FOR UNMANNED AERIAL VEHICLES AND UTILIZATION THEREOF,https://lens.org/075-469-567-999-521,2020,"A precision landing system including an unmanned aerial vehicle (UAV) and a beacon is provided. A processor of the UAV controls a flight system of the UAV to fly the UAV. The processor detects, via a sensor of the UAV, a signal emitted by a beacon. The processor controls the flight system of the UAV to land on or near the beacon. The processor also energizes one or more electromagnets on a cradle of the UAV to retrieve the beacon."
SMART HOME APPLIANCE AND AUDIO CONTROL METHOD THEREOF,https://lens.org/084-364-787-148-804,2022,"The present invention relates to a smart home appliance (1) for playing audio content and an audio control method for the smart home appliance (1). The smart home appliance (1) comprises: a far-field module (2) for picking up played audio content sound and ambient sound, and detecting presence of speech in ambient sound; a sound analysis unit (3) for analysing picked-up sounds and determining audio modification parameters according to the analysis; a real-time sound processor (4) for processing audio content according to said audio modification parameters; and at least one loudspeaker (5) for outputting processed audio content."
SMART HOME APPLIANCE AND AUDIO CONTROL METHOD THEREOF,https://lens.org/084-364-787-148-804,2022,"The present invention relates to a smart home appliance (1) for playing audio content and an audio control method for the smart home appliance (1). The smart home appliance (1) comprises: a far-field module (2) for picking up played audio content sound and ambient sound, and detecting presence of speech in ambient sound; a sound analysis unit (3) for analysing picked-up sounds and determining audio modification parameters according to the analysis; a real-time sound processor (4) for processing audio content according to said audio modification parameters; and at least one loudspeaker (5) for outputting processed audio content."
THREE-LEVEL MOTION DETECTOR USING ACCELEROMETER DEVICE IN KEY FOB APPLICATION,https://lens.org/186-352-462-856-191,2021,"A remote access device and methods of operation thereof are provided for accessing a physical object or location. The remote access device includes an accelerometer, a wireless transmitter, and control circuitry. The control circuitry causes the wireless transmitter to transition between a first operating mode and a second operating mode in response to receiving signals from the accelerometer indicating a first change in motion states of the remote access device. The control circuitry causes the wireless transmitter to transition between a first operating mode and a second operating mode in response to receiving signals from the accelerometer indicating a second change in motion states of the remote access device. The control circuitry further causes the wireless transmitter to transition between the first operating mode and the second operating mode in response to receiving signals from the accelerometer indicating a third change in motion states of the remote access device."
Three-level motion detector using accelerometer device in key fob application,https://lens.org/103-367-938-952-439,2023,"A remote access device and methods of operation thereof are provided for accessing a physical object or location. The remote access device includes an accelerometer, a wireless transmitter, and control circuitry. The control circuitry causes the wireless transmitter to transition between a first operating mode and a second operating mode in response to receiving signals from the accelerometer indicating a first change in motion states of the remote access device. The control circuitry causes the wireless transmitter to transition between a first operating mode and a second operating mode in response to receiving signals from the accelerometer indicating a second change in motion states of the remote access device. The control circuitry further causes the wireless transmitter to transition between the first operating mode and the second operating mode in response to receiving signals from the accelerometer indicating a third change in motion states of the remote access device."
Helicopter with an improved vibration control device,https://lens.org/040-778-605-260-218,2010,"A helicopter having a rotor, a fuselage connected to the rotor by connecting means, and a control device for controlling vibration of the fuselage; the control device including generating means for generating signals associated with vibration of the fuselage, and actuating means for producing a force on the fuselage associated with the signals to reduce vibration; and the actuating means being carried by the connecting means."
HELICOPTER WITH AN IMPROVED VIBRATION CONTROL DEVICE,https://lens.org/023-104-278-104-201,2014,"A helicopter having a rotor, a fuselage connected to the rotor by connecting means, and a control device for controlling vibration of the fuselage; the control device including generating means for generating signals associated with vibration of the fuselage, and actuating means for producing a force on the fuselage associated with the signals to reduce vibration; and the actuating means being carried by the connecting means."
Helicopter with an improved vibration control device,https://lens.org/084-760-882-993-752,2009,"A helicopter having a rotor, a fuselage connected to the rotor by connecting means, and a control device for controlling vibration of the fuselage; the control device including generating means for generating signals associated with vibration of the fuselage, and actuating means for producing a force on the fuselage associated with the signals to reduce vibration; and the actuating means being carried by the connecting means."
HOME AUTOMATION WEATHER DETECTION,https://lens.org/024-693-761-005-507,2016,"Systems and methods for controlling a device in a home automation network based on detection of a weather event include receiving image data from a camera in operative communication with a host system, where the image data is representative of an outdoor weather event that is captured by the camera, and analyzing the image data to identify the outdoor weather event. Systems and methods may include determining a home automation rule based on the identified outdoor weather event, where the home automation rule includes an operational setting of a home automation device, and instructing the home automation device based on the determined home automation rule via a home automation network."
Home automation weather detection,https://lens.org/197-085-852-898-456,2018,"Systems and methods for controlling a device in a home automation network based on detection of a weather event include receiving image data from a camera in operative communication with a host system, where the image data is representative of an outdoor weather event that is captured by the camera, and analyzing the image data to identify the outdoor weather event. Systems and methods may include determining a home automation rule based on the identified outdoor weather event, where the home automation rule includes an operational setting of a home automation device, and instructing the home automation device based on the determined home automation rule via a home automation network."
COLLISION PREVENTION FLIGHT CONTROL MODE,https://lens.org/109-824-584-203-48X,2023,"Systems (100, 110) and methods for controlling an aerial vehicle to avoid obstacles are disclosed. A system (100,110) can detect, based on a world model (145) generated from sensor data captured by one or more sensors (125) positioned on the aerial vehicle (105) during flight, an obstacle (140) for the aerial vehicle, and trigger an augmented manual control mode responsive to a speed of the aerial vehicle (105) being less than a predetermined threshold and detecting the obstacle (140). The system (100, 110) can set, responsive to triggering the augmented manual control mode, a speed constraint for the aerial vehicle in a direction of the obstacle based on a distance between the aerial vehicle and the obstacle. The system (100, 110) can receive an instruction to navigate the aerial vehicle (105) in the direction at a second speed, and adjust the instruction to replace the second speed with the speed constraint, causing the aerial vehicle (105) to navigate at the speed constraint."
"SITUATIONAL AWARENESS, NAVIGATION AND COMMUNICATION FOR LOW-COST, GUN-LAUNCHED UAVS",https://lens.org/133-910-123-215-606,2019,"An unmanned aerial vehicle (UAV), comprising: a projectile body; a propulsion system foldably deployable from the projectile body; a synthetic aperture radar (SAR) system comprising a SAR antenna fixedly and non-rotatably arranged on the projectile body; and a control system connected to the propulsion system and the SAR system, wherein the control system is configured to control: orientation of the projectile body and thus orientation of the SAR antenna; and operation of the SAR system so that the SAR system is selectively operable in one or more of: a situational awareness mode; a navigation mode; and a communication mode."
Active alignment of stereo cameras,https://lens.org/127-476-075-350-881,2019,"In some examples, an unmanned aerial vehicle (UAV) may include a stereo camera including two cameras. To maintain proper alignment of the stereo camera as the UAV moves about, a management device may access calibration information for the stereo camera and receive sensing information indicating movement of the two cameras relative to each other. Based at least in part on the calibration information and the sensing information, the management device may instruct an actuator to move one of the two cameras to the proper alignment or may rectify frames captured by the two cameras to return to the proper alignment."
"Server and method for controlling laser irradiation of movement path of robot, and robot that moves based thereon",https://lens.org/137-586-661-924-550,2022,"A main server for controlling laser irradiation of a movement path of a robot, the main server including a communication unit configured to communicate with a camera module and a laser irradiation module; and a controller configured to: receive, via the communication unit, an image of a robot captured by the camera module, identify a location of the robot in the image captured by the camera module, generate a movement path of the robot based on sensing information, and transmit, via the communication unit, movement path information to the laser irradiation module for outputting the movement path to a vicinity of the robot with a laser for the robot to follow, in which the sensing information includes first information about an obstacle sensed by the camera module or second information about the obstacle sensed by the laser irradiation module."
"Server and method for controlling laser irradiation of movement path of robot, and robot that moves based thereon",https://lens.org/137-586-661-924-550,2022,"A main server for controlling laser irradiation of a movement path of a robot, the main server including a communication unit configured to communicate with a camera module and a laser irradiation module; and a controller configured to: receive, via the communication unit, an image of a robot captured by the camera module, identify a location of the robot in the image captured by the camera module, generate a movement path of the robot based on sensing information, and transmit, via the communication unit, movement path information to the laser irradiation module for outputting the movement path to a vicinity of the robot with a laser for the robot to follow, in which the sensing information includes first information about an obstacle sensed by the camera module or second information about the obstacle sensed by the laser irradiation module."
"SERVER AND METHOD FOR CONTROLLING LASER IRRADIATION OF MOVEMENT PATH OF ROBOT, AND ROBOT THAT MOVES BASED THEREON",https://lens.org/179-316-304-263-68X,2020,"A main server for controlling laser irradiation of a movement path of a robot, the main server including a communication unit configured to communicate with a camera module and a laser irradiation module; and a controller configured to: receive, via the communication unit, an image of a robot captured by the camera module, identify a location of the robot in the image captured by the camera module, generate a movement path of the robot based on sensing information, and transmit, via the communication unit, movement path information to the laser irradiation module for outputting the movement path to a vicinity of the robot with a laser for the robot to follow, in which the sensing information includes first information about an obstacle sensed by the camera module or second information about the obstacle sensed by the laser irradiation module."
Flying Device With Improved Movement on The Ground,https://lens.org/174-557-497-675-060,2008,"The invention relates to a flying device which can efficiently move in the air by aerodynamic forces and by direct force transmission on the ground, without the need for independent drive and thrust generation systems for the two modes of movement. The rotors ( 1 ) of the flying device are provided on the outside thereof with an annular rotating covering ( 4 ), connected directly to the rotor blade tips, which, when the flying device is on the ground and the rotor rotational axes ( 2 ) are correspondingly pitched about an axis ( 3 ), come into contact with the ground. The covering ( 4 ) hence permits a movement of the flying device on the ground by rolling, which is based on a direct force transfer to the ground. A further rotor pitching axis ( 5 ) permits the flying device to be controlled in the air and on the ground by means of the same actuator system. The above flying principle permits, for example, remote controlled reconnaissance drones for close or remote espionage, to independently enter inaccessible regions, or in the context of police or military application in buildings presenting danger for personnel, to gain access to upper floors."
Systems and methods for secure transportation and safe deployment of unmanned aerial vehicles,https://lens.org/088-395-355-840-482,2022,"Systems and methods for secure transportation and safe deployment of unmanned aerial vehicles are disclosed herein. An example method includes performing a UAV preflight procedure that includes determining UAV startup sounds from sound signals received from a microphone positioned within a housing that houses the UAV, determining synchronized rotation of propellers of the UAV, determining that no obstructions are present above the housing based on range finder signals; and releasing the UAV after completion of the UAV preflight procedure."
SYSTEMS AND METHODS FOR SECURE TRANSPORTATION AND SAFE DEPLOYMENT OF UNMANNED AERIAL VEHICLES,https://lens.org/033-563-458-771-912,2020,"Systems and methods for secure transportation and safe deployment of unmanned aerial vehicles are disclosed herein. An example method includes performing a UAV preflight procedure that includes determining UAV startup sounds from sound signals received from a microphone positioned within a housing that houses the UAV, determining synchronized rotation of propellers of the UAV, determining that no obstructions are present above the housing based on range finder signals; and releasing the UAV after completion of the UAV preflight procedure."
UNMANNED FLYING OBJECT AND FLIGHT CONTROL METHOD THEREOF,https://lens.org/144-722-429-025-961,2017,"A flight control method of an unmanned flying object includes acquiring first positional information indicating a position of the unmanned flying object using a position sensor, receiving a position reset command and second positional information that indicates a position of an operation device from the operation device used to operate the unmanned flying object, determining a rotation angle needed to orient a movement direction of the unmanned flying object in a predetermined direction in accordance with the first positional information and the second positional information, and performing control to orient the movement direction of the unmanned flying object in the predetermined direction in accordance with the rotation angle."
Unmanned flying object and flight control method thereof,https://lens.org/146-396-517-014-658,2018,"A flight control method of an unmanned flying object includes acquiring first positional information indicating a position of the unmanned flying object using a position sensor, receiving a position reset command and second positional information that indicates a position of an operation device from the operation device used to operate the unmanned flying object, determining a rotation angle needed to orient a movement direction of the unmanned flying object in a predetermined direction in accordance with the first positional information and the second positional information, and performing control to orient the movement direction of the unmanned flying object in the predetermined direction in accordance with the rotation angle."
AUTHORIZING AND CONFIGURING PAIRING OF UNMANNED AERIAL SYSTEM,https://lens.org/022-885-785-112-394,2023,"Apparatuses, methods, and systems are disclosed for authorizing and configuring pairing of unmanned aerial system. An apparatus includes a transceiver that receives, at a first network function of a mobile wireless communication network, a first authorization of unmanned aerial vehicle (UAV) operations and a second authorization for associating a UAV-controller with the UAV, the first and second authorizations associated with a first identifier. An apparatus includes a processor that creates a 5G local area network (LAN) group within the mobile wireless communication for facilitating communications between the UAV and the UAV-controller and associating a second identifier with the 5G LAN group, configures the 5G LAN group based on at least at least one parameter associated with the UAV and updates a third network function with information for the 5G LAN group for establishing a protocol data unit (PDU) session between the UAV and the UAV controller."
Working device and working method,https://lens.org/006-833-562-603-642,2014,"A working device and a working method wherein an articulated robot controls vertical movement of a balancer arm by commanding vertical movement for a balancer, and moves the balancer arm horizontally by applying an external force to the balancer arm in the horizontal direction by means of a robot arm."
WORKING DEVICE AND WORKING METHOD,https://lens.org/068-518-544-641-88X,2011,"A working device and a working method wherein an articulated robot controls vertical movement of a balancer arm by commanding vertical movement for a balancer, and moves the balancer arm horizontally by applying an external force to the balancer arm in the horizontal direction by means of a robot arm."
PERFORMING SPEECH RECOGNITION USING A LOCAL LANGUAGE CONTEXT INCLUDING A SET OF WORDS WITH DESCRIPTIONS IN TERMS OF COMPONENTS SMALLER THAN THE WORDS,https://lens.org/029-957-682-952-037,2020,"A method of a local recognition system controlling a host device to perform one or more operations is provided. The method includes receiving, by the local recognition system, a query, performing speech recognition on the received query by implementing, by the local recognition system, a local language context comprising a set of words comprising descriptions in terms of components smaller than the words, and performing speech recognition, using the local language context, to create a transcribed query. Further, the method includes controlling the host device in dependence upon the speech recognition performed on the transcribed query."
UNMANNED AERIAL VEHICLE FOR DELIVERING CARGO,https://lens.org/021-598-753-884-308,2020,"Disclosed herein are aspects of an unmanned aerial vehicle (UAV). In one embodiment, the UAV includes a container body having a cargo bay configured to hold cargo, and a plurality of rotor assemblies coupled to the container body. Each rotor assembly is configured to provide the container body with propulsion. A control system may be held by the container body and operatively connected to the rotor assemblies. The control system may be configured to fly the container body to a destination. The rotor assemblies may be moveable between a flight configuration and a shipping configuration. In the flight configuration, the rotor assemblies may extend outward from the container body such that the rotor assemblies are positioned to propel the container body through the air. In the shipping configuration, the rotor assemblies may be folded to the container body such that the container body is configured to be shipped to a destination."
UNMANNED AERIAL VEHICLE FOR DELIVERING CARGO,https://lens.org/040-835-058-036-425,2020,"Disclosed herein are aspects of an unmanned aerial vehicle (UAV). In one embodiment, the UAV includes a container body having a cargo bay configured to hold cargo, and a plurality of rotor assemblies coupled to the container body. Each rotor assembly is configured to provide the container body with propulsion. A control system may be held by the container body and operatively connected to the rotor assemblies. The control system may be configured to fly the container body to a destination. The rotor assemblies may be moveable between a flight configuration and a shipping configuration. In the flight configuration, the rotor assemblies may extend outward from the container body such that the rotor assemblies are positioned to propel the container body through the air. In the shipping configuration, the rotor assemblies may be folded to the container body such that the container body is configured to be shipped to a destination."
Robotic control using deep learning,https://lens.org/083-745-270-707-506,2021,"A method of controlling one or more robotic devices, such as autonomous vehicles using neural networks, to perform a task. A first neural network determines information about environmental conditions relating to the task. Second neural network 206 and the information about the environmental conditions are used to help control the one or more robotic devices when carrying out the task. The information may include a logical state describing the environmental conditions. The second neural network may determine actions to help control the devices when carried out. The environmental conditions may include unexpected events. The neural networks may generate one or more loss values using which they are trained. The environmental conditions may be determined based on sensor data obtained by environmental sensors 214 such as cameras, navigation sensors, GPS sensors, RADAR sensors, LIDAR sensors, or inertial sensors."
Multi-rotor unmanned aerial vehicle automatic flight control system,https://lens.org/126-735-176-739-359,2015,"A multi-rotor unmanned aerial vehicle automatic flight control system comprises a flight control calculation unit, a full manual control unit, a wireless signal transmission unit and a motor drive unit. An output end of the flight control calculation unit is connected with an input end of the full manual control unit. An output end of the full manual control unit is connected with an input end of the motor drive unit. The flight control calculation unit is formed by a flight attitude derivation device, an attitude controller, a flight speed detection and correction device, a speed controller, a flight location detection and correction unit, a flight location controller, a GPS navigation sensor, an inertia measurement sensor and an air pressure sensor. The full manual control unit is formed by a three-axis gyroscope sensor and an angular rate control unit. The wireless signal transmission unit is formed by a ground station signal transceiver unit and a remote control signal receiving unit. According to the utility model, multi-point automatic flight of a multi-rotor unmanned aerial vehicle can be achieved, and the automatic flight controller can be switched into full manual control to avoid air crash when a fault occurs."
UAV (unmanned aerial vehicle) for panoramic surveillance,https://lens.org/168-200-625-008-934,2015,"The invention discloses a UAV (unmanned aerial vehicle) for panoramic surveillance, comprising a frame body and a camera part, wherein the frame body is formed by plastic steel for one time molding; the frame body comprises a frame circular ring, rotor poles and a centre plate used for installing a circuit control system and the camera part; the frame circular ring is equally divided into six parts; the rotor poles are located at sixe equal diversion points of the frame circular ring and extend outwards; the ends of the rotor poles are provided with fixed wings; the frame circular ring is connected to the center plate by a support rod; the camera part is installed below the centre plate; the camera part comprises wide angle camera modules, telephoto local camera modules, and an optical transceiver transmitting module, and the wide angle camera modules concretely are small type wide angle cameras; the UAV for panoramic surveillance disclosed by the invention realizes the efficient real-time surveillance under the condition of multi-objective differentiation surveillance demand, and is capable of mainly and locally performing surveillance on a sensitive surveillance area, thus efficient real-time surveillance of a complex object is realized."
AUTHORISATION MANAGEMENT AND FLIGHT COMPLIANCE SYSTEM AND METHOD FOR UNMANNED AERIAL VEHICLES,https://lens.org/171-310-423-362-105,2019,"An authorisation management and flight compliance system for a plurality of Unmanned Aerial Vehicles (UAV) operating in a region, said system configured to assess a flight command request for a UAV submitted by an authorised controller for approval, the assessment based on constraints for the flight and a level of authority assigned to the controller; and cryptographically sign an approved command request and return the signed command request to the controller for sending to the UAV."
AUTHORISATION MANAGEMENT AND FLIGHT COMPLIANCE SYSTEM AND METHOD FOR UNMANNED AERIAL VEHICLES,https://lens.org/175-433-604-992-267,2017,"An authorisation management and flight compliance system for a plurality of Unmanned Aerial Vehicles (UAV) operating in a region, said system configured to assess a flight command request for a UAV submitted by an authorised controller for approval, the assessment based on constraints for the flight and a level of authority assigned to the controller; and cryptographically sign an approved command request and return the signed command request to the controller for sending to the UAV."
Authorisation management and flight compliance system and method for unmanned aerial vehicles,https://lens.org/098-421-132-391-762,2018,"An authorisation management and flight compliance system for a plurality of Unmanned Aerial Vehicles (UAV) operating in a region, said system configured to assess a flight command request for a UAV submitted by an authorised controller for approval, the assessment based on constraints for the flight and a level of authority assigned to the controller; and cryptographically sign an approved command request and return the signed command request to the controller for sending to the UAV."
DRONE NOISE REDUCTION VIA SIMULTANEOUS PROPELLER MODULATION,https://lens.org/105-025-157-170-111,2018,"Techniques for using an unmanned aerial vehicle (UAV) to deliver a payload while generating an expected sound by the UAV during delivery may be provided. For example, during delivery or while in flight, propellers of different sizes that are associated with the UAV may be instructed to modulate at different rotational speeds to thereby generate an expected sound."
Operation method in which autonomous underwater vehicle is used,https://lens.org/184-923-566-264-936,2020,"This operation method in which an autonomous underwater vehicle (AUV) is used has: a step for operating an object to be operated using an operation device provided to an AUV while the AUV is driven along the object to be operated; a step for dropping a transponder and submerging the same to the sea floor; a step for driving the AUV toward a return destination; and a step for driving the AUV, on the basis of information obtained by acoustic positioning in which the transponder submerged to the sea floor is used, from the return destination to a location near an operation suspension position at which operation of the object to be operated is suspended, and restarting the operation of the object to be operated."
Working method using autonomous underwater vehicle,https://lens.org/123-737-212-297-894,2021,"This operation method in which an autonomous underwater vehicle (AUV) is used has: a step for operating an object to be operated using an operation device provided to an AUV while the AUV is driven along the object to be operated; a step for dropping a transponder and submerging the same to the sea floor; a step for driving the AUV toward a return destination; and a step for driving the AUV, on the basis of information obtained by acoustic positioning in which the transponder submerged to the sea floor is used, from the return destination to a location near an operation suspension position at which operation of the object to be operated is suspended, and restarting the operation of the object to be operated."
Operation method in which autonomous underwater vehicle is used,https://lens.org/097-477-938-207-545,2020,"This operation method in which an autonomous underwater vehicle (AUV) is used has: a step for operating an object to be operated using an operation device provided to an AUV while the AUV is driven along the object to be operated; a step for dropping a transponder and submerging the same to the sea floor; a step for driving the AUV toward a return destination; and a step for driving the AUV, on the basis of information obtained by acoustic positioning in which the transponder submerged to the sea floor is used, from the return destination to a location near an operation suspension position at which operation of the object to be operated is suspended, and restarting the operation of the object to be operated."
"IMAGE CAPTURING SYSTEM, CONTROL DEVICE, CONTROL METHOD, AND STORAGE MEDIUM",https://lens.org/189-458-764-762-718,2022,An image capturing system comprises: an unmanned aerial vehicle including an image capturing unit capable of capturing an image of a subject in a flight state; and a control device capable of communicating with a terminal of the subject and the unmanned aerial vehicle. The control device includes: a storage unit configured to register subject information in which the subject is set as a target to be captured; a determination unit configured to determine whether the subject is present in a predetermined image capturing area; a signal generation unit configured to generate a control signal that controls the image capturing unit; and a communication control unit configured to transmit the subject information and the control signal to the unmanned aerial vehicle.
"IMAGE CAPTURING SYSTEM, CONTROL DEVICE, CONTROL METHOD, AND STORAGE MEDIUM",https://lens.org/189-458-764-762-718,2022,An image capturing system comprises: an unmanned aerial vehicle including an image capturing unit capable of capturing an image of a subject in a flight state; and a control device capable of communicating with a terminal of the subject and the unmanned aerial vehicle. The control device includes: a storage unit configured to register subject information in which the subject is set as a target to be captured; a determination unit configured to determine whether the subject is present in a predetermined image capturing area; a signal generation unit configured to generate a control signal that controls the image capturing unit; and a communication control unit configured to transmit the subject information and the control signal to the unmanned aerial vehicle.
System for Use in Remote Controlling Controlled Device,https://lens.org/010-950-393-894-975,2015,"An objective of the present invention is to provide a system for remotely controlling a controlled device. The system comprises 1) emitting means comprising a light-emission source for sending a control signal; 2) detecting means comprising a camera unit for acquiring imaging information of the control signal in the camera unit; 3) computing means for determining location information of the emitting means based on the imaging information acquired by the detecting means; 4) controlling means for determining a control instruction corresponding to the location information so as to control a controlled device connected to the system. Compared with the prior art, a receiving end of the system according to the present invention comprises a computing means for computing location information of the emitting means, and a controlling means that determines a corresponding control instruction based on the location information, which implements remote control of the controlled device and improves the control accuracy, thereby further enhancing the control efficiency and improving the user's control experience."
XR device and method for controlling the same,https://lens.org/137-824-576-027-75X,2022,"A XR device and a method for controlling the XR device are discussed. The method includes accessing to a public DB (Database), generating a private DB based on key information of the public DB, where the public DB includes public AR (Artificial Intelligence) information, and the private DB includes private AR information and a whitelist, and acquiring the public AR information or the private AR information."
XR DEVICE AND METHOD FOR CONTROLLING THE SAME,https://lens.org/084-022-832-247-263,2019,"A XR device and a method for controlling the XR device are discussed. The method includes accessing to a public DB (Database), generating a private DB based on key information of the public DB, where the public DB includes public AR (Artificial Intelligence) information, and the private DB includes private AR information and a whitelist, and acquiring the public AR information or the private AR information."
XR device and method for controlling the same,https://lens.org/137-824-576-027-75X,2022,"A XR device and a method for controlling the XR device are discussed. The method includes accessing to a public DB (Database), generating a private DB based on key information of the public DB, where the public DB includes public AR (Artificial Intelligence) information, and the private DB includes private AR information and a whitelist, and acquiring the public AR information or the private AR information."
"Configurability options for information, airspace, and property utilized by an unmanned aerial vehicle platform",https://lens.org/172-069-797-504-196,2016,"A device receives aviation information associated with aviation in a geographical region, and receives configurability options associated with the aviation information. The device analyzes the aviation information based on the configurability options to generate analyzed information, and receives a request for a flight path for a UAV to travel from a first location to a second location in the geographical region. The device calculates the flight path from the first location to the second location based on the analyzed information and capability information associated with the UAV, and generates flight path instructions for the flight path. The device provides the flight path instructions to the UAV to permit the UAV to travel from the first location to the second location via the flight path."
METHOD FOR PERFORMING COOPERATIVE FUNCTION AUTOMATICALLY AND DEVICE USING THE SAME,https://lens.org/124-896-391-825-107,2017,"A device for performing a cooperative function with another device is provided. The device includes a communication unit, and a controller that determines whether the other device is in a surrounding area of the device based a signal received through the communication unit, selects one cooperative function from among a plurality of cooperative functions according to a relative position of the device with respect to the other device and performs the selected cooperative function with the other device."
Method for performing cooperative function automatically and device using the same,https://lens.org/107-092-072-921-046,2018,"A device for performing a cooperative function with another device is provided. The device includes a communication unit, and a controller that determines whether the other device is in a surrounding area of the device based a signal received through the communication unit, selects one cooperative function from among a plurality of cooperative functions according to a relative position of the device with respect to the other device and performs the selected cooperative function with the other device."
Autonomous fleet management,https://lens.org/116-257-752-117-421,2021,"An autonomous vehicle includes a display interface. The vehicle includes a controller configured to execute commands to transport a passenger from a pickup location to a destination and display a brand name or logo associated with a brand identifier during at least a portion of the transport. The execution is responsive to a request for transportation service including the brand identifier, the pickup location, and the destination."
Antenna system using a motion sensor and method for operating the antenna system using a motion sensor,https://lens.org/151-471-909-969-566,2019,"An antenna system using a motion sensor includes an antenna having a plurality of axes within a smart device, whereby motion sensor sensing axis information is generated by movement or rotation of the plurality of axes of the antenna, and a controller for controlling the information sensed by the motion sensor and a strength of a signal of the antenna having the plurality of axes received in real time."
ANTENNA SYSTEM USING A MOTION SENSOR AND METHOD FOR OPERATING THE ANTENNA SYSTEM USING A MOTION SENSOR,https://lens.org/120-105-584-393-145,2017,"An antenna system using a motion sensor includes an antenna having a plurality of axes within a smart device, whereby motion sensor sensing axis information is generated by movement or rotation of the plurality of axes of the antenna, and a controller for controlling the information sensed by the motion sensor and a strength of a signal of the antenna having the plurality of axes received in real time."
ELECTRONIC DEVICE AND METHOD FOR MANAGING TRAFFIC FLOW,https://lens.org/098-758-913-220-169,2013,"A system for managing traffic flow is used in an electronic device in communication with an unmanned aerial vehicle (UAV) and traffic signals. The UAV captures a real-time image of each road, and detects position and direction of the real-time image when the UAV captures the real-time image. The UAV transmits the real-time image of each road, the position, and the direction to the electronic device. The system analyzes the real-time image to gather a number of the vehicles and a number of people in the real-time image. The electronic device marks the number of the vehicles and the number of people on the position of an electronic map corresponding to the position and the direction of the real-time image, and dynamically manages statuses of traffic signals according to the number of the vehicles and the number of people marked on the electronic map."
"SHOVEL COMMUNICATIONS SYSTEM, MULTICOPTER, AND SHOVEL",https://lens.org/164-208-057-652-668,2018,"A shovel communications system includes a multicopter, an operation apparatus, and a shovel. The multicopter is configured to fly in response to an operation command. The operation apparatus is configured to transmit a radio signal corresponding to the operation command when the operation command is input to the multicopter, and to output information when receiving the information from the multicopter. The shovel includes a relay configured to relay a radio signal communicated between the operation apparatus and the multicopter."
FRICTION ACTUATOR,https://lens.org/071-364-386-695-768,1993,"An actuator suitable for autopilot control of a helicopter tail rotor comprises a direct current motor, a non-reversible gearbox, a speed reducer driving an output shaft, a friction device disposed between the non-reversible gearbox and the speed reducer and a friction exceeded sensing device adapted to cut off the supply of power to the motor."
METHODS AND SYSTEMS FOR DYNAMIC FLEET PRIORITIZATION MANAGEMENT,https://lens.org/019-542-066-294-766,2023,"Systems and method are provided for requesting remote control of an autonomous vehicle by a remote transportation system. In one embodiment, a method includes: receiving, by a processor of the autonomous vehicle, experience data associated with the autonomous vehicle, wherein the experience data includes a location of the autonomous vehicle, a time of day, a pose of the autonomous vehicle, detected freespace in an environment of the autonomous vehicle, detected congestion in the environment, a planned maneuver type, and an associated maneuver graph; determining, by the processor, one or more features of a planned maneuver based on the experience data; determining, by the processor, a risk value associated with the planned mission by processing the one or more features with a machine learning model; and selectively generating, by the processor, request data to the remote transportation system based on the risk value, wherein the request data includes the risk value."
METHODS AND SYSTEMS FOR DYNAMIC FLEET PRIORITIZATION MANAGEMENT,https://lens.org/019-542-066-294-766,2023,"Systems and method are provided for requesting remote control of an autonomous vehicle by a remote transportation system. In one embodiment, a method includes: receiving, by a processor of the autonomous vehicle, experience data associated with the autonomous vehicle, wherein the experience data includes a location of the autonomous vehicle, a time of day, a pose of the autonomous vehicle, detected freespace in an environment of the autonomous vehicle, detected congestion in the environment, a planned maneuver type, and an associated maneuver graph; determining, by the processor, one or more features of a planned maneuver based on the experience data; determining, by the processor, a risk value associated with the planned mission by processing the one or more features with a machine learning model; and selectively generating, by the processor, request data to the remote transportation system based on the risk value, wherein the request data includes the risk value."
SOLAR POWERED DRONE,https://lens.org/059-888-180-132-743,2018,"A solar power system for a drone. The system including a shell with at least one solar cell adapted for placement on an exterior surface of a drone. The system coupled to a controller, the controller distributing collected solar energy to the various systems of the drone including the power systems containing batteries and the motor systems adapted to propel the drone."
Safe powering of tethered drone,https://lens.org/034-681-619-708-062,2022,"A drone includes a propulsion system, a processing unit, and a power system having a battery and a power connection port. The power system is configured to receive packetized electrical power over a tether including an air-to-ground power feed attachable to the power connection port. The power system is also configured to supply electrical power to the processing unit, the battery, and the propulsion system. The processing unit is configured to acknowledge receipt of the packetized electrical power. A power delivery system includes a packetized electrical power transmitter and a processing unit. The processing unit is configured to operate the packetized electrical power transmitter to transmit packets of electrical power over a power feed within a tether attached to a drone. The processing unit is also configured to monitor a communication channel within the tether for acknowledgements indicating the drone has received the transmitted packets of electrical power."
SAFE POWERING OF TETHERED DRONE,https://lens.org/115-377-665-284-58X,2020,"A drone includes a propulsion system, a processing unit, and a power system having a battery and a power connection port. The power system is configured to receive packetized electrical power over a tether including an air-to-ground power feed attachable to the power connection port. The power system is also configured to supply electrical power to the processing unit, the battery, and the propulsion system. The processing unit is configured to acknowledge receipt of the packetized electrical power. A power delivery system includes a packetized electrical power transmitter and a processing unit. The processing unit is configured to operate the packetized electrical power transmitter to transmit packets of electrical power over a power feed within a tether attached to a drone. The processing unit is also configured to monitor a communication channel within the tether for acknowledgements indicating the drone has received the transmitted packets of electrical power."
Safe powering of tethered drone,https://lens.org/034-681-619-708-062,2022,"A drone includes a propulsion system, a processing unit, and a power system having a battery and a power connection port. The power system is configured to receive packetized electrical power over a tether including an air-to-ground power feed attachable to the power connection port. The power system is also configured to supply electrical power to the processing unit, the battery, and the propulsion system. The processing unit is configured to acknowledge receipt of the packetized electrical power. A power delivery system includes a packetized electrical power transmitter and a processing unit. The processing unit is configured to operate the packetized electrical power transmitter to transmit packets of electrical power over a power feed within a tether attached to a drone. The processing unit is also configured to monitor a communication channel within the tether for acknowledgements indicating the drone has received the transmitted packets of electrical power."
Drone for Agriculture,https://lens.org/119-515-948-749-787,2018,"The present invention is a drone for spraying liquid such as pesticides, fungicides, herbicides, plant growth regulators, plant defoliators, and fertilizers over field crop. The drone comprises: a frame with a slender rigid beam in the middle and two base structures at the two ends, a rigid tube with an array of nozzles on elongated stems and the rigid tube is suspended below the beam structure with retractable wires, at least three propellers on motors with arms that are rotatably mounted to each of the two base structures of the frame, a power source positioned in one of the bases, at least one distance detector for measuring height of the drone above the ground, an antenna for sending and receiving communication signals, an electronic control system to operate motors and sensors, a container for a liquid material with a caped opening for refilling and an air pump to maintain a positive pressure in the container and electronic valve to allow liquid in the container under pressure to be released through a transfer line to be sprayed from the nozzles, and a remote controller for operating the drone. The invention provides a specialized drone that is able to spray liquid solutions over a wide strip of the field at a height close to crop canopy to achieve high efficiency and precision and reduced drift of sprays while the drone flies at a relatively high above the crop canopy for safe operation and avoid damage to crop by air turbulence."
UNMANNED AERIAL VEHICLE FOR PAINTING STRUCTURES,https://lens.org/136-635-175-936-689,2023,"An unmanned aerial vehicle (UAV) includes a sprayer configured to generate a pressurized fluid flow and a nozzle configured to receive the pressurized fluid from the sprayer and to generate a spray fan to apply the fluid to a surface. The UAV includes sensors and a control unit to control both flight of the UAV and spraying by the sprayer. The fluid can be stored onboard the UAV in a reservoir or can be remotely stored and pumped to the UAV. The UAV control unit can be preloaded with a spray plan and a flight plan, or the UAV can be controlled by a user."
Cleaning robot and remote controller included therein,https://lens.org/025-395-537-010-054,2020,"A cleaning robot includes a navigator to move a main body, a remote controller to output a modulated infrared ray in accordance with a control command of a user and to form a light spot, a light receiver to receive the infrared ray from the remote controller, and a controller to control the navigator such that the main body tracks the light spot when the modulated infrared ray is received in accordance with the control command. Because the cleaning robot tracks a position indicated by the remote controller, a user may conveniently move the cleaning robot."
UNMANNED AERIAL VEHICLE FOR PAINTING STRUCTURES,https://lens.org/136-635-175-936-689,2023,"An unmanned aerial vehicle (UAV) includes a sprayer configured to generate a pressurized fluid flow and a nozzle configured to receive the pressurized fluid from the sprayer and to generate a spray fan to apply the fluid to a surface. The UAV includes sensors and a control unit to control both flight of the UAV and spraying by the sprayer. The fluid can be stored onboard the UAV in a reservoir or can be remotely stored and pumped to the UAV. The UAV control unit can be preloaded with a spray plan and a flight plan, or the UAV can be controlled by a user."
Unmanned aerial vehicle for painting structures,https://lens.org/048-927-240-148-609,2022,"An unmanned aerial vehicle (UAV) includes a sprayer configured to generate a pressurized fluid flow and a nozzle configured to receive the pressurized fluid from the sprayer and to generate a spray fan to apply the fluid to a surface. The UAV includes sensors and a control unit to control both flight of the UAV and spraying by the sprayer. The fluid can be stored onboard the UAV in a reservoir or can be remotely stored and pumped to the UAV. The UAV control unit can be preloaded with a spray plan and a flight plan, or the UAV can be controlled by a user."
Unmanned aerial vehicle for painting structures,https://lens.org/048-927-240-148-609,2022,"An unmanned aerial vehicle (UAV) includes a sprayer configured to generate a pressurized fluid flow and a nozzle configured to receive the pressurized fluid from the sprayer and to generate a spray fan to apply the fluid to a surface. The UAV includes sensors and a control unit to control both flight of the UAV and spraying by the sprayer. The fluid can be stored onboard the UAV in a reservoir or can be remotely stored and pumped to the UAV. The UAV control unit can be preloaded with a spray plan and a flight plan, or the UAV can be controlled by a user."
"Control system, controller, control method, and recording medium",https://lens.org/133-767-648-087-45X,2020,"A control system, a controller, a control method and a recording medium capable of preventing damage to a cable occurring during an operation under control of a scara robot are provided. A control system includes a scara robot 300 and a controller configured to control the scara robot 300. The controller includes an acquisition unit configured to acquire a target position of a control object in the scara robot 300 and a decision unit configured to decide a rotational direction of an operation tool 332 so that a cable 333 does not collide with a component of the scara robot 300 when the control object moves to the target position."
"CONTROL SYSTEM, CONTROLLER, CONTROL METHOD, AND RECORDING MEDIUM",https://lens.org/084-086-711-943-150,2018,"A control system, a controller, a control method and a recording medium capable of preventing damage to a cable occurring during an operation under control of a scara robot are provided. A control system includes a scara robot 300 and a controller configured to control the scara robot 300. The controller includes an acquisition unit configured to acquire a target position of a control object in the scara robot 300 and a decision unit configured to decide a rotational direction of an operation tool 332 so that a cable 333 does not collide with a component of the scara robot 300 when the control object moves to the target position."
CONTROL AND SYSTEMS FOR AUTONOMOUSLY DRIVEN VEHICLES,https://lens.org/139-811-805-968-730,2012,"An autonomous controller for a vehicle. The controller has a processor configured to receive position signals from position sensors and to generate operation control signals defining an updated travel path for the vehicle. The controller has a programmable interface providing communication among the position sensors, the operation control mechanisms, and the processor. The controller is configured to normalize inputs to the processor from the position sensors and to generate compatible operation control signals applied as the inputs to the operation control mechanisms. The processor and the programmable interface define a self-contained unit configurable for operation with a variety of different remote sensors and different remote operation control mechanisms."
Control and systems for autonomously driven vehicles,https://lens.org/093-863-723-846-198,2014,"An autonomous controller for a vehicle. The controller has a processor configured to receive position signals from position sensors and to generate operation control signals defining an updated travel path for the vehicle. The controller has a programmable interface providing communication among the position sensors, the operation control mechanisms, and the processor. The controller is configured to normalize inputs to the processor from the position sensors and to generate compatible operation control signals applied as the inputs to the operation control mechanisms. The processor and the programmable interface define a self-contained unit configurable for operation with a variety of different remote sensors and different remote operation control mechanisms."
Control and systems for autonomously driven vehicles,https://lens.org/034-192-081-951-644,2013,"An autonomous controller for a vehicle. The controller has a processor configured to receive position signals from position sensors and to generate operation control signals defining an updated travel path for the vehicle. The controller has a programmable interface providing communication among the position sensors, the operation control mechanisms, and the processor. The controller is configured to normalize inputs to the processor from the position sensors and to generate compatible operation control signals applied as the inputs to the operation control mechanisms. The processor and the programmable interface define a self-contained unit configurable for operation with a variety of different remote sensors and different remote operation control mechanisms."
CONTROL AND SYSTEMS FOR AUTONOMOUSLY DRIVEN VEHICLES,https://lens.org/014-172-164-128-094,2015,"An autonomous controller for a vehicle. The controller has a processor configured to receive position signals from position sensors and to generate operation control signals defining an updated travel path for the vehicle. The controller has a programmable interface providing communication among the position sensors, the operation control mechanisms, and the processor. The controller is configured to normalize inputs to the processor from the position sensors and to generate compatible operation control signals applied as the inputs to the operation control mechanisms. The processor and the programmable interface define a self-contained unit configurable for operation with a variety of different remote sensors and different remote operation control mechanisms."
Control and systems for autonomously driven vehicles,https://lens.org/032-345-375-763-501,2012,"An autonomous controller for a vehicle. The controller has a processor configured to receive position signals from position sensors and to generate operation control signals defining an updated travel path for the vehicle. The controller has a programmable interface providing communication among the position sensors, the operation control mechanisms, and the processor. The controller is configured to normalize inputs to the processor from the position sensors and to generate compatible operation control signals applied as the inputs to the operation control mechanisms. The processor and the programmable interface define a self-contained unit configurable for operation with a variety of different remote sensors and different remote operation control mechanisms."
CONTROL AND SYSTEMS FOR AUTONOMOUSLY DRIVEN VEHICLES,https://lens.org/135-581-082-113-600,2013,"An autonomous controller for a vehicle. The controller has a processor configured to receive position signals from position sensors and to generate operation control signals defining an updated travel path for the vehicle. The controller has a programmable interface providing communication among the position sensors, the operation control mechanisms, and the processor. The controller is configured to normalize inputs to the processor from the position sensors and to generate compatible operation control signals applied as the inputs to the operation control mechanisms. The processor and the programmable interface define a self-contained unit configurable for operation with a variety of different remote sensors and different remote operation control mechanisms."
CONTROL AND SYSTEMS FOR AUTONOMOUSLY DRIVEN VEHICLES,https://lens.org/017-726-443-133-436,2012,"An autonomous controller for a vehicle. The controller has a processor configured to receive position signals from position sensors and to generate operation control signals defining an updated travel path for the vehicle. The controller has a programmable interface providing communication among the position sensors, the operation control mechanisms, and the processor. The controller is configured to normalize inputs to the processor from the position sensors and to generate compatible operation control signals applied as the inputs to the operation control mechanisms. The processor and the programmable interface define a self-contained unit configurable for operation with a variety of different remote sensors and different remote operation control mechanisms."
CONTROL AND SYSTEMS FOR AUTONOMOUSLY DRIVEN VEHICLES,https://lens.org/033-503-004-331-176,2014,"An autonomous controller for a vehicle. The controller has a processor configured to receive position signals from position sensors and to generate operation control signals defining an updated travel path for the vehicle. The controller has a programmable interface providing communication among the position sensors, the operation control mechanisms, and the processor. The controller is configured to normalize inputs to the processor from the position sensors and to generate compatible operation control signals applied as the inputs to the operation control mechanisms. The processor and the programmable interface define a self-contained unit configurable for operation with a variety of different remote sensors and different remote operation control mechanisms."
"System, Device, and Method of Secure Location-Aware Garage Door Actuation for Efficient Delivery of Packages",https://lens.org/153-830-989-414-599,2019,"System, device, and method of secure and location-aware garage door actuation for efficient delivery of packages. For example, a delivery vehicle or a courier carries or has a device able to determine its geographic location. Based on the geographic location, the device receives wirelessly, from a remote server or a cloud-based platform or from a nearby Home Automation System, an incoming wireless message indicating to the device how to construct and transmit an outgoing wireless message that would cause actuation of the particular garage door of a particular venue at which the device is located or for which a package delivery is required. Accordingly, a single device is dynamically configured on-the-fly, to selectively open a variety of garage doors of various houses or venues."
Autonomous infrastructure element survey systems and methods using UAV fleet deployment,https://lens.org/147-233-959-315-634,2017,"An unmanned aerial vehicle (UAV) survey system and methods for surveying an area of interest are disclosed. The system can include a plurality of docking stations positioned at predetermined locations within the area of interest, each docking station comprising a platform to support a UAV while docked at the docking station; a battery charger; and a communications interface; a plurality of UAVs distributed among the plurality of docking stations, each UAV comprising a communications interface; and a system controller comprising a processor and transmitter communicatively coupled to the plurality of UAVs."
Combination UAV,https://lens.org/180-072-126-255-421,2022,"A combination unmanned aerial vehicle (UAV) having a fixed wing UAV, a plurality of rotor UAVs, a first communication component and a plurality of second communication components. The first communication component is arranged on the fixed wing UAV, and the plurality of second communication components are correspondingly arranged on the plurality of rotor UAVs. The first communication component can communicate with the plurality of second communication components. When operating in long-distance and complex surrounding areas, it can fly to a designated position through the fixed wing UAV, and then release the plurality of rotor UAVs, which may carry out reconnaissance operations on one or more targets in one area at the same time, or operate on multiple targets in multiple areas, and transmit signal commands in real time through the first communication component and the second communication component."
Combination UAV,https://lens.org/180-072-126-255-421,2022,"A combination unmanned aerial vehicle (UAV) having a fixed wing UAV, a plurality of rotor UAVs, a first communication component and a plurality of second communication components. The first communication component is arranged on the fixed wing UAV, and the plurality of second communication components are correspondingly arranged on the plurality of rotor UAVs. The first communication component can communicate with the plurality of second communication components. When operating in long-distance and complex surrounding areas, it can fly to a designated position through the fixed wing UAV, and then release the plurality of rotor UAVs, which may carry out reconnaissance operations on one or more targets in one area at the same time, or operate on multiple targets in multiple areas, and transmit signal commands in real time through the first communication component and the second communication component."
SYSTEMS AND METHODS FOR PAIRING A REMOTE CONTROL TO VIDEO OR AUDIO COMPONENTS USING ULTRASOUND SIGNALS,https://lens.org/152-581-521-944-219,2013,"Methods and systems for pairing remote controls to video or audio components are provided. The remote control, for example, may include, but is not limited to, an ultrasound receiver and a controller coupled to the ultrasound receiver. The controller may be configured to receive an ultrasound signal from the ultrasound receiver, extract pairing data from the ultrasound signal, and configure the remote control based upon the pairing data."
Unmanned aerial vehicle management,https://lens.org/089-548-852-225-529,2022,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
Unmanned aerial vehicle power management,https://lens.org/169-143-652-387-560,2022,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
UNMANNED AERIAL VEHICLE MANAGEMENT,https://lens.org/193-645-573-763-601,2016,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
UAV POWER MANAGEMENT,https://lens.org/150-135-378-451-514,2020,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
UNMANNED AERIAL VEHICLE MANAGEMENT,https://lens.org/152-020-923-671-452,2023,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
UNMANNED AERIAL VEHICLE MANAGEMENT,https://lens.org/070-811-487-801-983,2016,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
Unmanned aerial vehicle management,https://lens.org/040-426-301-745-671,2022,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
UNMANNED AERIAL VEHICLE MANAGEMENT,https://lens.org/044-973-329-562-103,2020,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
Unmanned aerial vehicle management,https://lens.org/089-548-852-225-529,2022,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
Unmanned aerial vehicle management,https://lens.org/092-540-349-861-474,2022,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
UNMANNED AERIAL VEHICLE MANAGEMENT,https://lens.org/111-214-998-710-565,2020,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
Unmanned aerial vehicle management,https://lens.org/040-426-301-745-671,2022,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
Unmanned aerial vehicle power management,https://lens.org/169-143-652-387-560,2022,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
UNMANNED AERIAL VEHICLE MANAGEMENT,https://lens.org/044-973-329-562-103,2020,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
UNMANNED AERIAL VEHICLE MANAGEMENT,https://lens.org/191-297-885-068-922,2020,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
Unmanned aerial vehicle management,https://lens.org/178-309-741-705-878,2019,"A base module may be used to receive and house one or more unmanned aerial vehicles (UAVs) via one or more cavities. The base module receives commands from a manager device and identifies a flight plan that allows a UAV to execute the received commands. The base module transfers the flight plan to the UAV and frees the UAV. Once the UAV returns, the base module once again receives it. The base module then receives sensor data from the UAV from one or more sensors onboard the UAV, and optionally receives additional information describing its flight and identifying success or failure of the flight plan. The base module transmits the sensor data and optionally the additional information to a storage medium locally or remotely accessible by the manager device."
Drone air to ground transition system,https://lens.org/135-398-826-302-530,2023,"An unmanned aerial vehicle (UAV) having a plurality of arms and a land/air drive assembly attached to each arm. The land/air drive assembly includes (i) a multi-speed motor assembly; (ii) a propeller having a first diameter and driven by the motor assembly at a first speed; and (iii) a ground drive wheel having a second diameter greater than the first diameter and driven by the motor assembly at a second speed slower than the first speed. A drive assembly orientation actuator is positioned between each arm and each drive assembly, wherein the orientation actuator is configured to, on command, rotate the drive assembly between a flight position and ground drive position approximately perpendicular to the flight position."
Manual remote control device especially a fluid distributor,https://lens.org/094-877-947-636-281,1999,"Manually operated remote control device comprising a body (1) enclosing at least one movable member generating a signal associated with an axially movable pushrod (2) projecting upwards from the body (1); a fixing plate (3) closing the top of the body and provided with at least one drilling (5) through which the abovementioned pushrod passes; a rocking cam (6) fixed to the top of the body (1) so as to cooperate with the projecting end of the pushrod (2) and control the movement of the latter; a grip (9, 10) secured to the cam (6) and incorporating at least one electric control member (11) to which is connected an electrical cable (12) passing through the abovementioned fixing plate (3) via an opening (13) in the latter; the opening (13) is elongate and runs transversely from one edge of the plate (3), opening out into the said edge, by virtue of which the electrical cable, preassembled and pre-equipped, can be put in place in the device by being inserted into the opening transversely from the edge of the plate."
Unmanned Aerial Vehicle Sensor Activation and Correlation System,https://lens.org/089-975-500-614-244,2023,"An unmanned aerial vehicle (UAV) logs first UAV information at a first frequency. The UAV triggers a camera associated with the UAV to capture an image. In response to triggering the camera to capture the image, the UAV logs second UAV information at a second frequency that is higher than the first frequency. A device that is separate from the UAV identifies a location of the UAV corresponding to the image based on a capture timestamp of the image received from the camera, the first UAV information, and the second UAV information. The device generates a geo-rectified imagery based on the image and the location of the UAV."
DEFAULT IN-DETENT VERTICAL SPEED/ALTITUDE HOLD,https://lens.org/075-256-118-641-525,2018,"A rotorcraft including a flight control computer (FCC) providing a vertical speed hold for the rotorcraft, a collective control, and a collective trim motor connected to the collective control. The collective trim motor moves the collective control according to a collective set command generated by the FCC according to a target vertical speed and when the FCC determines the collective control is in-detent. A collective position sensor is connected to the collective control. The collective position sensor generates, and sends to the FCC, a collective position signal indicating the position of the collective control. A flight control device controls a flight parameter of the rotorcraft in response to a flight control device control signal received from the FCC. The FCC generates the flight control device control signal according to the collective position signal, and sends the flight control device control signal to a flight control device."
Default in-detent vertical speed/altitude hold,https://lens.org/132-178-539-677-336,2019,"A rotorcraft including a flight control computer (FCC) providing a vertical speed hold for the rotorcraft, a collective control, and a collective trim motor connected to the collective control. The collective trim motor moves the collective control according to a collective set command generated by the FCC according to a target vertical speed and when the FCC determines the collective control is in-detent. A collective position sensor is connected to the collective control. The collective position sensor generates, and sends to the FCC, a collective position signal indicating the position of the collective control. A flight control device controls a flight parameter of the rotorcraft in response to a flight control device control signal received from the FCC. The FCC generates the flight control device control signal according to the collective position signal, and sends the flight control device control signal to a flight control device."
SECURED INTEGRATED BUILDING ACCESS,https://lens.org/029-799-153-950-764,2018,"An integrated secured building access system is presented that allows an authorized person to remotely grant or deny a visitor building access. The system provides audiovisual communication between a visitor and the access controller via a cloud service operating with the internet or a cellular network and remote devices such as smart phones, personal computers, and/or tablets. The access controller can remotely grant or deny the visitor entry to the building."
Robot and method for controlling the same,https://lens.org/101-265-287-158-505,2023,"A robot according to the present disclosure comprises: a microphone; a camera disposed to face a predetermined direction; and a processor configured to: inactivate driving of the camera and activate driving of the microphone, if a driving mode of the robot is set to a user monitoring mode; acquire a sound signal through the microphone; activate the driving of the camera based on an event estimated from the acquired sound signal; confirm the event from the image acquired through the camera; and control at least one constituent included in the robot to perform an operation based on the confirmed event."
Robot and method for controlling the same,https://lens.org/101-265-287-158-505,2023,"A robot according to the present disclosure comprises: a microphone; a camera disposed to face a predetermined direction; and a processor configured to: inactivate driving of the camera and activate driving of the microphone, if a driving mode of the robot is set to a user monitoring mode; acquire a sound signal through the microphone; activate the driving of the camera based on an event estimated from the acquired sound signal; confirm the event from the image acquired through the camera; and control at least one constituent included in the robot to perform an operation based on the confirmed event."
ROBOT AND METHOD FOR CONTROLLING THE SAME,https://lens.org/106-919-446-101-998,2021,"A robot according to the present disclosure comprises: a microphone; a camera disposed to face a predetermined direction; and a processor configured to: inactivate driving of the camera and activate driving of the microphone, if a driving mode of the robot is set to a user monitoring mode; acquire a sound signal through the microphone; activate the driving of the camera based on an event estimated from the acquired sound signal; confirm the event from the image acquired through the camera; and control at least one constituent included in the robot to perform an operation based on the confirmed event."
Control circuit board,https://lens.org/057-011-067-936-156,2015,"The invention provides a control circuit board which is used in a multi-rotor-wing unmanned aerial vehicle. The control circuit board comprises a first surface and a second surface which is reverse to the first surface, the first surface at least comprises a flight control system chip, a camera interface, an image transmission interface and a battery interface, and the second surface at least comprises multiple electronic speed controller elements."
Autonomous Mobile Robot And Method For Controlling An Autonomous Mobile Robot,https://lens.org/051-776-438-162-177,2021,"An autonomous mobile robot, comprising: a drive unit which is designed to receive control signals and to move the robot in accordance with the control signals, a navigation sensor for capturing navigation features, and a navigation unit coupled to the navigation sensor. The navigation unit is designed to receive information from the navigation sensor and to plan a movement for the robot. The robot also has a control unit, which is designed to receive movement information representing the movement planned by the navigation unit and to generate the control signals based on the movement information. The robot has further sensors which are coupled to the control unit such that the control unit can receive further sensor information from the further sensors. The control unit is designed to pre-process this further sensor information and to supply the pre-processed sensor information in a pre-defined format to the navigation unit."
CONTROL METHOD,https://lens.org/034-274-922-651-048,2019,"A mobile device control method includes receiving a photographing command, turning off, in response to the photographing command, a light source affecting a photographing effect, and performing a photographing operation according to the photographing command."
Control method and apparatus for turning off a light source affecting a photographing effect,https://lens.org/138-452-826-638-417,2021,"A mobile device control method includes receiving a photographing command, turning off, in response to the photographing command, a light source affecting a photographing effect, and performing a photographing operation according to the photographing command."
UNMANNED AERIAL SYSTEM,https://lens.org/181-758-600-751-733,2017,"A multi-propeller unmanned aerial system (UAS) with a wind-resistant software platform that allows for motor support arm rotation, thereby allowing two propellers to move the drone forward and backward, or rotate it, through thrust vectoring, while the other propellers maintain hover. Horizontal movement is possible without losing the level stability necessary for a number of drone-related functions such as aerial photography. The software platform of the UAS provides for the rotational movement of the motor support arm and motors to engage and disengage to allow for tiltrotor control, specifically two motors rotate to advance the UAS forward or reverse while the remaining propellers maintain hover. Propeller guards are provided for safety which do not affect the maximum thrust or flight maneuverability of the drone."
Voice and connection platform,https://lens.org/175-591-991-916-988,2019,"A system and method for providing a voice assistant including receiving, at a first device, a first audio input from a user requesting a first action; performing automatic speech recognition on the first audio input; obtaining a context of user; performing natural language understanding based on the speech recognition of the first audio input; and taking the first action based on the context of the user and the natural language understanding."
VOICE AND CONNECTION PLATFORM,https://lens.org/182-930-804-669-043,2016,"A system and method for providing a voice assistant including receiving, at a first device, a first audio input from a user requesting a first action; performing automatic speech recognition on the first audio input; obtaining a context of user; performing natural language understanding based on the speech recognition of the first audio input; and taking the first action based on the context of the user and the natural language understanding."
Voice and Connection Platform,https://lens.org/049-171-594-410-909,2019,"A system and method for providing a voice assistant including receiving, at a first device, a first audio input from a user requesting a first action; performing automatic speech recognition on the first audio input; obtaining a context of user; performing natural language understanding based on the speech recognition of the first audio input; and taking the first action based on the context of the user and the natural language understanding."
Voice and connection platform,https://lens.org/139-235-400-500-774,2020,"A system and method for providing a voice assistant including receiving, at a first device, a first audio input from a user requesting a first action; performing automatic speech recognition on the first audio input; obtaining a context of user; performing natural language understanding based on the speech recognition of the first audio input; and taking the first action based on the context of the user and the natural language understanding."
ROBOT FOR PROVIDING GUIDANCE SERVICE USING ARTIFICIAL INTELLIGENCE AND METHOD OF OPERATING THE SAME,https://lens.org/036-876-378-392-695,2021,"A robot for providing a guidance service in a first language using artificial intelligence includes a microphone configured to receive voice data, a camera configured to acquire image data, an output unit, and a processor configured to determine a second language used to provide the guidance service based on one or more of the voice data or the image data, change the language used to provide the guidance service from the first language to the second language when the determined second language is different from the first language and output the guidance service through the output unit in the changed second language."
Method and apparatus for total control handle,https://lens.org/000-243-982-147-665,2015,"By using the intelligent ski handle capable of communicating with a tow boat, a towed user can control functions such as raising a warning flag, changing the speed and direction of the boat, sounding a horn, etc. thus promoting safety of the rider. When the towed user is separated by a prespecified distance from the ski handle, the handle can sense a fallen rider and wirelessly transmit a control signal to a receiver on the towing boat."
"COMMERCIAL AND GENERAL AIRCRAFT AVOIDANCE USING LIGHT, SOUND, AND/OR MULTI-SPECTRAL PATTERN DETECTION",https://lens.org/149-650-271-397-360,2019,"Methods and apparatus for executing the methods, wherein the method comprises generating signals, by one or more sensors of an unmanned aerial vehicle (UAV), from waves generated by propulsion of a flying object, determining one or more characteristic features of the signals, identifying the flying object based at least in part on a comparison of the one or more characteristic features to a database of known signals, associating performance parameters with the flying object using a database that includes performance parameters for at least one of a plurality of flying objects or class of flying objects, determining a location and an airspeed associated with the flying object based at least in part on the signals, determining a trajectory envelope for the flying object based at least in part on the location, the airspeed, and the associated performance parameters, and updating a flight plan for the UAV based at least in part on the trajectory envelope of the flying object, wherein the updated flight plan does not interact with the trajectory envelope of the flying object."
Object detection and analysis via unmanned aerial vehicle,https://lens.org/080-828-240-138-853,2018,"An unmanned aerial vehicle (UAV) can include one or more cameras for capturing image data within a field of view that depends in part upon the location and orientation of the UAV. At least a portion of the image data can be processed on the UAV to locate objects of interest, such as people or cars, and use that information to determine where to fly the drone in order to capture higher quality image data of those or other such objects. Once identified, the objects of interest can be counted, and the density, movement, location, and behavior of those objects identified. This can help to determine occurrences such as traffic congestion or unusual patterns of pedestrian movement, as well as to locate persons, fires, or other such objects. The data can also be analyzed by a remote system or service that has additional resources to provide more accurate results."
OBJECT DETECTION AND ANALYSIS VIA UNMANNED AERIAL VEHICLE,https://lens.org/142-487-444-962-056,2017,"An unmanned aerial vehicle (UAV) can include one or more cameras for capturing image data within a field of view that depends in part upon the location and orientation of the UAV. At least a portion of the image data can be processed on the UAV to locate objects of interest, such as people or cars, and use that information to determine where to fly the drone in order to capture higher quality image data of those or other such objects. Once identified, the objects of interest can be counted, and the density, movement, location, and behavior of those objects identified. This can help to determine occurrences such as traffic congestion or unusual patterns of pedestrian movement, as well as to locate persons, fires, or other such objects. The data can also be analyzed by a remote system or service that has additional resources to provide more accurate results."
OBJECT DETECTION AND ANALYSIS VIA UNMANNED AERIAL VEHICLE,https://lens.org/108-145-628-874-912,2018,"An unmanned aerial vehicle (UAV) can include one or more cameras for capturing image data within a field of view that depends in part upon the location and orientation of the UAV. At least a portion of the image data can be processed on the UAV to locate objects of interest, such as people or cars, and use that information to determine where to fly the drone in order to capture higher quality image data of those or other such objects. Once identified, the objects of interest can be counted, and the density, movement, location, and behavior of those objects identified. This can help to determine occurrences such as traffic congestion or unusual patterns of pedestrian movement, as well as to locate persons, fires, or other such objects. The data can also be analyzed by a remote system or service that has additional resources to provide more accurate results."
Hybrid remotely/autonomously operated underwater vehicle,https://lens.org/087-154-106-113-82X,2008,"Disclosed is an underwater vehicle that can be operated as a remotely operated vehicle (ROV) or as an autonomous vehicle (AUV). The underwater vehicle has a tether, which may be a fiberoptic cable, that connects the vehicle to a control console. The underwater vehicle has vertical and lateral thrusters, pitch and yaw control fins, and a propulsor, all of which may be used in an ROV-mode when the underwater vehicle is operating at slow speeds. The underwater vehicle may also be operated in a AUV-mode when operating at higher speeds. The operator may switch the vehicle between ROV-mode and AUV-mode. The underwater vehicle also has a fail-safe mode, in which the vehicle may navigate according to a pre-loaded mission plan if the tether is severed."
DRONE CLEANING APPARATUS AND METHOD FOR ELEVATED STRUCTURES AND CEILINGS,https://lens.org/088-156-065-678-482,2020,"A cleaning method and apparatus for elevated structures and ceilings, such as open girder truss systems, utilizes a multi-rotor blade helicopter/drone together with a contaminant entrainment system. More specifically, the drone includes a contaminant entrainment system including a vacuum and filter for entraining the contaminants dislodged from the elevated structures, a cleaning head to engage the surface to be cleaned, a system to guide the drone's flight path proximate the elevated structures to be cleaned, and optionally a power tether to reduce battery weight and increase the flight time of the drone."
Portable countermeasure device against unmanned systems,https://lens.org/090-455-927-598-999,2018,"A portable countermeasure device is provided comprising one or more directional antennae, one or more disruption components and at least one activator. The portable countermeasure device further comprises a body, with the directional antennae are affixed to a front portion of the body. The one or more disruption components may be externally or internally mounted to the device body. The portable countermeasure device is aimed at a specific drone, the activator is engaged, and disruptive signals are directed toward the drone, disrupting the control, navigation, and other signals to and from the drone."
PORTABLE COUNTERMEASURE DEVICE AGAINST UNMANNED SYSTEMS,https://lens.org/076-089-983-466-689,2021,"A portable countermeasure device is provided comprising one or more directional antennae, one or more disruption components and at least one activator. The portable countermeasure device further comprises a body, with the directional antennae are affixed to a front portion of the body. The one or more disruption components may be externally or internally mounted to the device body. The portable countermeasure device is aimed at a specific drone, the activator is engaged, and disruptive signals are directed toward the drone, disrupting the control, navigation, and other signals to and from the drone."
PORTABLE COUNTERMEASURE DEVICE AGAINST UNMANNED SYSTEMS,https://lens.org/121-426-787-892-968,2019,"A portable countermeasure device is provided comprising one or more directional antennae, one or more disruption components and at least one activator. The portable countermeasure device further comprises a body, with the directional antennae are affixed to a front portion of the body. The one or more disruption components may be externally or internally mounted to the device body. The portable countermeasure device is aimed at a specific drone, the activator is engaged, and disruptive signals are directed toward the drone, disrupting the control, navigation, and other signals to and from the drone."
Portable countermeasure device against unmanned systems,https://lens.org/089-561-641-720-083,2019,"A portable countermeasure device is provided comprising one or more directional antennae, one or more disruption components and at least one activator. The portable countermeasure device further comprises a body, with the directional antennae are affixed to a front portion of the body. The one or more disruption components may be externally or internally mounted to the device body. The portable countermeasure device is aimed at a specific drone, the activator is engaged, and disruptive signals are directed toward the drone, disrupting the control, navigation, and other signals to and from the drone."
Portable countermeasure device against unmanned systems,https://lens.org/042-215-433-861-01X,2018,"A portable countermeasure device is provided comprising one or more directional antennae, one or more disruption components and at least one activator. The portable countermeasure device further comprises a body, with the directional antennae are affixed to a front portion of the body. The one or more disruption components may be externally or internally mounted to the device body. The portable countermeasure device is aimed at a specific drone, the activator is engaged, and disruptive signals are directed toward the drone, disrupting the control, navigation, and other signals to and from the drone."
PORTABLE COUNTERMEASURE DEVICE AGAINST UNMANNED SYSTEMS,https://lens.org/163-406-667-049-98X,2017,"A portable countermeasure device is provided comprising one or more directional antennae, one or more disruption components and at least one activator. The portable countermeasure device further comprises a body, with the directional antennae are affixed to a front portion of the body. The one or more disruption components may be externally or internally mounted to the device body. The portable countermeasure device is aimed at a specific drone, the activator is engaged, and disruptive signals are directed toward the drone, disrupting the control, navigation, and other signals to and from the drone."
Portable countermeasure device against unmanned systems,https://lens.org/107-192-102-853-063,2019,"A portable countermeasure device is provided comprising one or more directional antennae, one or more disruption components and at least one activator. The portable countermeasure device further comprises a body, with the directional antennae are affixed to a front portion of the body. The one or more disruption components may be externally or internally mounted to the device body. The portable countermeasure device is aimed at a specific drone, the activator is engaged, and disruptive signals are directed toward the drone, disrupting the control, navigation, and other signals to and from the drone."
PORTABLE COUNTERMEASURE DEVICE AGAINST UNMANNED SYSTEMS,https://lens.org/078-042-435-470-016,2018,"A portable countermeasure device is provided comprising one or more directional antennae, one or more disruption components and at least one activator. The portable countermeasure device further comprises a body, with the directional antennae are affixed to a front portion of the body. The one or more disruption components may be externally or internally mounted to the device body. The portable countermeasure device is aimed at a specific drone, the activator is engaged, and disruptive signals are directed toward the drone, disrupting the control, navigation, and other signals to and from the drone."
Method and apparatus to locate a device in a dwelling or other enclosed space,https://lens.org/052-251-287-073-39X,2006,"A device is presented including a processor. A user interface is connected to the processor. A receiver is connected to the processor for receiving current location information from an external source. Also, a transmitter is connected to the processor for transmitting the current location information and command data to an external receiver. The current location information is a specific room or a specific area."
Method and apparatus to locate a device in a dwelling or other enclosed space,https://lens.org/195-971-058-164-918,2005,"A device is presented including a processor. A user interface is connected to the processor. A receiver is connected to the processor for receiving current location information from an external source. Also, a transmitter is connected to the processor for transmitting the current location information and command data to an external receiver. The current location information is a specific room or a specific area."
BEYOND LINE OF SIGHT FLYING DRONE SURFACE CLEANER,https://lens.org/088-479-495-681-610,2016,"A flying propeller driven vehicle controlled remotely by operator with Radio Frequency Transceiver with additional Radio Frequency Transceiver Video Link on board Colour Camera, power by batteries or fuel, on board cleaning and rinsing fluid reservoir, scrubbing brush, fluid dispense nozzle, actuator and monitoring electronics Drawcng 1 Page 1"
AUTONOMOUS VEHICLE SECURITY,https://lens.org/071-093-002-350-102,2022,"In accordance with embodiments of this disclosure, a method of securing an autonomous vehicle is presented. The method includes receiving a request for an action at the autonomous vehicle; requesting permission from a user device that has been paired with the autonomous vehicle; and performing the action if permission is received from the user device."
"Robot controller, robot system, robot, robot control method, and program",https://lens.org/189-942-312-340-156,2015,"A robot includes a control unit that controls a movable unit of the robot to move an end point of the movable unit closer to a target position, and an image acquisition unit that acquires a target image as an image containing the end point when the end point is in the target position, and a current image as an image containing the end point when the end point is in a current position. The control unit controls movement of the movable unit based on the current image and the target image and output from a force detection unit that detects a force acting on the movable unit.
"
"Unmanned aerial vehicle, flight control method, non-transitory computer-readable recording medium, and control device",https://lens.org/095-100-582-158-101,2019,"A controller in an unmanned aerial vehicle determines whether the unmanned aerial vehicle is beyond a visual range within which the unmanned aerial vehicle is visible to an operator. When the unmanned aerial vehicle is determined to be beyond the visual range, the controller determines whether the operator is controlling the unmanned aerial vehicle using the control device while viewing video on a head-mounted display. When the operator is determined to be controlling the unmanned aerial vehicle using the control device while viewing video on the head-mounted display, the controller controls flight of the unmanned aerial vehicle in accordance with control information for controlling the unmanned aerial vehicle. When the operator is determined not to be controlling the unmanned aerial vehicle using the control device while viewing video on the head-mounted display, the controller does not control flight of the unmanned aerial vehicle in accordance with the control information."
"UNMANNED AERIAL VEHICLE, FLIGHT CONTROL METHOD, NON-TRANSITORY COMPUTER-READABLE RECORDING MEDIUM, AND CONTROL DEVICE",https://lens.org/162-875-733-682-579,2018,"A controller in an unmanned aerial vehicle determines whether the unmanned aerial vehicle is beyond a visual range within which the unmanned aerial vehicle is visible to an operator. When the unmanned aerial vehicle is determined to be beyond the visual range, the controller determines whether the operator is controlling the unmanned aerial vehicle using the control device while viewing video on a head-mounted display. When the operator is determined to be controlling the unmanned aerial vehicle using the control device while viewing video on the head-mounted display, the controller controls flight of the unmanned aerial vehicle in accordance with control information for controlling the unmanned aerial vehicle. When the operator is determined not to be controlling the unmanned aerial vehicle using the control device while viewing video on the head-mounted display, the controller does not control flight of the unmanned aerial vehicle in accordance with the control information."
Remote controller and ornamental device arrangement,https://lens.org/013-442-079-840-707,2006,"A remote controller and ornamental device arrangement is constructed to include a remote controller, which has a casing holding a circuit board and a keypad, and an ornamental device, which has a transparent watertight shell mounted in the remote controller and partially extended out of the top cover shell of the casing for decoration and a floating ornament floating on a liquid inside the transparent watertight shell."
UN-MANNED AERIAL VEHICLE,https://lens.org/084-287-435-418-042,2017,An un-manned aerial vehicle including a powered chassis having a top side and a bottom side. The powered chassis includes a fuel powered electricity generator. The vehicle includes a flight system functionally coupled to the powered chassis. The vehicle includes a flood light system functionally coupled to a bottom side of the powered chassis and oriented to project light downward therefrom. The flood light system includes a plurality of modular lights that are able to selectably couple to the bottom side of the powered chassis. The flood light system includes a programmable light control module that controls lighting. The vehicle includes an automated flight control system functionally coupled to the flight system that automatically directs light from the flood light system to a desired region.
Drone with target tracking and signal output,https://lens.org/197-807-330-780-524,2021,"An unmanned aircraft is described. The unmanned aircraft includes a signal output unit and a control unit. The control unit receives at least one signal to be output by the signal output unit. The control unit transmits at least a first signal to the signal output unit, so that the signal output unit outputs the first signal. The unmanned aircraft may be used stand-alone or autonomous as a movable signal output device, but it may also be coupled with a carrier vehicle to meet the function of a signal output device at the carrier vehicle."
DRONE WITH TARGET TRACKING AND SIGNAL OUTPUT,https://lens.org/127-529-990-224-113,2018,"An unmanned aircraft is described. The unmanned aircraft includes a signal output unit and a control unit. The control unit receives at least one signal to be output by the signal output unit. The control unit transmits at least a first signal to the signal output unit, so that the signal output unit outputs the first signal. The unmanned aircraft may be used stand-alone or autonomous as a movable signal output device, but it may also be coupled with a carrier vehicle to meet the function of a signal output device at the carrier vehicle."
"Electronic device, control method, and control program",https://lens.org/179-644-325-008-082,2018,"According to one of aspects, an electronic device includes a speaker and a controller. The controller is configured to acquire information and output an acquired information from the speaker upon sounding an alarm."
"ELECTRONIC DEVICE, CONTROL METHOD, AND CONTROL PROGRAM",https://lens.org/090-539-993-488-649,2015,"According to one of aspects, an electronic device includes a speaker and a controller. The controller is configured to acquire information and output an acquired information from the speaker upon sounding an alarm."
Aircraft (drone),https://lens.org/022-410-451-850-400,2023,"The present invention relates to the field of heavier-than-air aircraft, such as airplanes and unmanned aerial vehicles (UAV) and, in particular, to emergency rescue systems. The technical objective is accomplished by providing an aircraft, such as a drone, including a powerplant, a parachute, and a body. In particular, the parachute has a fixed shape, it is permanently in an opened state and is connected to the body by rigid braces, while the aircraft center of gravity is located below the aircraft aerodynamic center."
AIRCRAFT (DRONE),https://lens.org/028-545-231-966-870,2022,"The present invention relates to the field of heavier-than-air aircraft, such as airplanes and unmanned aerial vehicles (UAV) and, in particular, to emergency rescue systems. The technical objective is accomplished by providing an aircraft, such as a drone, including a powerplant, a parachute, and a body. In particular, the parachute has a fixed shape, it is permanently in an opened state and is connected to the body by rigid braces, while the aircraft center of gravity is located below the aircraft aerodynamic center."
Dispatching UAVs for Wildfire Surveillance,https://lens.org/127-382-915-194-635,2021,"A dispatch system includes an unmanned aerial vehicle (UAV) interface for interfacing with one or more UAVs for wildfire detection. The UAV interface transmits an instruction for a UAV to navigate to a location of a potential wildfire, and receives data captured by at least one sensor of the UAV. The dispatch system further includes a fire detection engine to process the received data to identify the presence of a wildfire, and a web server to provide a user interface that includes an alert regarding the wildfire. The alert may include the location of the wildfire."
Dispatching UAVs for wildfire surveillance,https://lens.org/112-378-567-086-382,2022,"A dispatch system includes an unmanned aerial vehicle (UAV) interface for interfacing with one or more UAVs for wildfire detection. The UAV interface transmits an instruction for a UAV to navigate to a location of a potential wildfire, and receives data captured by at least one sensor of the UAV. The dispatch system further includes a fire detection engine to process the received data to identify the presence of a wildfire, and a web server to provide a user interface that includes an alert regarding the wildfire. The alert may include the location of the wildfire."
METHOD AND DEVICE FOR DETERMINING OPERATION OF AN AUTONOMOUS DEVICE,https://lens.org/001-568-028-312-283,2020,"A method and device for determining operation of an autonomous device is disclosed. The method includes receiving pixel data and sound data associated with an environment at an instance of time, wherein the pixel data is received from least an image sensor associated with the autonomous device, and wherein the sound data is received from at least four sound sensors placed in a quadrilateral configuration on the autonomous device. Each quadrant of the pixel data is associated with each of the at least four sound sensors. The sound data received is mapped the to the matrix to identify one or more pixels in the matrix corresponding to the sound data based on a difference in amplitude between a first sound sensor of the at least four sound sensors recording maximum sound amplitude with a plurality of second sound sensors of the at least four sound sensors."
Method and device for determining operation of an autonomous device,https://lens.org/136-309-858-010-494,2022,"A method and device for determining operation of an autonomous device is disclosed. The method includes receiving pixel data and sound data associated with an environment at an instance of time, wherein the pixel data is received from least an image sensor associated with the autonomous device, and wherein the sound data is received from at least four sound sensors placed in a quadrilateral configuration on the autonomous device. Each quadrant of the pixel data is associated with each of the at least four sound sensors. The sound data received is mapped the to the matrix to identify one or more pixels in the matrix corresponding to the sound data based on a difference in amplitude between a first sound sensor of the at least four sound sensors recording maximum sound amplitude with a plurality of second sound sensors of the at least four sound sensors."
GESTURE RECOGNITION SYSTEM FOR AUTONOMOUS VEHICLE TRAFFIC CONTROL,https://lens.org/088-680-447-245-341,2023,"An autonomous vehicle (an AV, or manual vehicle in an autonomous or semi-autonomous mode) includes the ability to sense a command from a source external to the vehicle and modify the behavior of the vehicle in accordance with the command. For example, the vehicle may visualize a police officer or other person associated with traffic control and interpret gestures made by the person causing the vehicle to stop, slow down, pull over, change lanes, back up or take a different route due to unplanned traffic patterns such as accidents, harsh weather, road closings or other situations. The system and method may also be used for non-emergency purposes, including external guidance for load pick-up/placement, hailing a vehicle used as a cab, and so forth. The command may further be spoken or may include a radio frequency (RF) light or other energy component."
AUTONOMOUS PLACEMENT OF AN AERIALLY-MOUNTABLE ELECTRONIC DEVICE,https://lens.org/129-868-570-517-488,2022,"An autonomous placement device for securing an electronic device to and/or removing an electronic device from an object (such as, for example, a utility pole or a streetlight luminaire optionally forming a part thereof) includes a repository and a remove-and-place system. The repository is arranged to store at least one electronic device. The remove-and-place system is operable, in one embodiment, to retrieve an electronic device from the repository and, after the autonomous placement device has been positioned proximate an aerial placement position, secure the electronic device to the object at the aerial placement position. The autonomous placement device may further include a guidance system operable to locate the aerial placement position prior to aerial positioning. The autonomous placement device may form part of a system, which also includes an unmanned aerial vehicle (UAV) and a payload coupling system that mechanically couples the autonomous placement device to the UAV."
AUTONOMOUS PLACEMENT OF AN AERIALLY-MOUNTABLE ELECTRONIC DEVICE,https://lens.org/129-868-570-517-488,2022,"An autonomous placement device for securing an electronic device to and/or removing an electronic device from an object (such as, for example, a utility pole or a streetlight luminaire optionally forming a part thereof) includes a repository and a remove-and-place system. The repository is arranged to store at least one electronic device. The remove-and-place system is operable, in one embodiment, to retrieve an electronic device from the repository and, after the autonomous placement device has been positioned proximate an aerial placement position, secure the electronic device to the object at the aerial placement position. The autonomous placement device may further include a guidance system operable to locate the aerial placement position prior to aerial positioning. The autonomous placement device may form part of a system, which also includes an unmanned aerial vehicle (UAV) and a payload coupling system that mechanically couples the autonomous placement device to the UAV."
AUTONOMOUS PLACEMENT OF AN AERIALLY-MOUNTABLE ELECTRONIC DEVICE,https://lens.org/082-423-657-795-573,2023,"An autonomous placement device for securing an electronic device to and/or removing an electronic device from an object (such as, for example, a utility pole or a streetlight luminaire optionally forming a part thereof) includes a repository and a remove-and-place system. The repository is arranged to store at least one electronic device. The remove-and-place system is operable, in one embodiment, to retrieve an electronic device from the repository and, after the autonomous placement device has been positioned proximate an aerial placement position, secure the electronic device to the object at the aerial placement position. The autonomous placement device may further include a guidance system operable to locate the aerial placement position prior to aerial positioning. The autonomous placement device may form part of a system, which also includes an unmanned aerial vehicle (UAV) and a payload coupling system that mechanically couples the autonomous placement device to the UAV."
"UNMANNED AERIAL VEHICLE, UNMANNED AERIAL VEHICLE SYSTEM, AND BATTERY SYSTEM",https://lens.org/192-610-028-103-978,2020,"An unmanned aerial vehicle includes a main body, a propulsion assembly including a rotary blade and a motor to rotate the rotary blade about a rotation axis. The propulsion assembly is attached to the main body and further includes a rechargeable battery to supply electric power to the propulsion assembly, a frame portion surrounding an outside of the rotary blade in a radial direction, and a power receiving coil to provide non-contact power feeding. The power receiving coil is electrically connected to the battery, has a frame shape along the frame portion, and is provided in the frame portion."
AUTONOMOUS UNDERWATER VEHICLE FOR MARINE SEISMIC SURVEYS,https://lens.org/147-978-067-633-377,2014,"An autonomous underwater vehicle (AUV) for recording seismic signals during a marine seismic survey. The AUV includes a body having a flush shape; a buoyancy system located inside the body and configured to control a buoyancy of the AUV while travelingunderwater; a processor connected to the buoyancy system and configured to select one of plural phases for the buoyancy system at different times of the seismic survey, wherein the plural phases include a neutral buoyancy, a positive buoyancy and a negative buoyancy; and a seismic sensor for recording seismic signals."
"Robot controller, robot system, robot, robot control method, and program",https://lens.org/069-095-547-752-272,2016,"A robot includes a control unit that controls a movable unit of the robot to move an endpoint of the movable unit closer to a target position, and an image acquisition unit that acquires a target image as an image containing the end point when the end point is in the target position, and a current image as an image containing the end point when the end point is in a current position. The control unit controls movement of the movable unit based on the current image and the target image and output from a force detection unit that detects a force acting on the movable unit."
"ROBOT CONTROLLER, ROBOT SYSTEM, ROBOT, ROBOT CONTROL METHOD, AND PROGRAM",https://lens.org/010-209-368-492-497,2015,"A robot includes a control unit that controls a movable unit of the robot to move an endpoint of the movable unit closer to a target position, and an image acquisition unit that acquires a target image as an image containing the end point when the end point is in the target position, and a current image as an image containing the end point when the end point is in a current position. The control unit controls movement of the movable unit based on the current image and the target image and output from a force detection unit that detects a force acting on the movable unit."
"Robot controller, robot system, robot, robot control method, and program",https://lens.org/069-095-547-752-272,2016,"A robot includes a control unit that controls a movable unit of the robot to move an endpoint of the movable unit closer to a target position, and an image acquisition unit that acquires a target image as an image containing the end point when the end point is in the target position, and a current image as an image containing the end point when the end point is in a current position. The control unit controls movement of the movable unit based on the current image and the target image and output from a force detection unit that detects a force acting on the movable unit."
METHOD AND APPARATUS FOR POSITIONING AN INSPECTION DRONE WITH RESPECT TO A STRUCTURE,https://lens.org/010-932-987-084-831,2023,"A method (700) for use in positioning a drone (102) with respect to a structure (101). The drone comprises a camera (103) having an optical system and an image sensor configured to produce an image (190) having a height and a width. The method includes obtaining (s702) a height value, HT, indicating an estimated height of the structure, a set of parameters associated with the camera, the set of parameters includes a focal length parameter, f, indicating a focal length of the optical system of the camera and a height parameter, Hj, indicating said height of the image. The method includes determining (s706), based on HT, f, and HJ, at least one of: i) a first distance value indicating a horizontal or vertical distance, dl, or ii) an angle value indicating an angle for the camera, "
METHOD AND APPARATUS FOR POSITIONING AN INSPECTION DRONE WITH RESPECT TO A STRUCTURE,https://lens.org/010-932-987-084-831,2023,"A method (700) for use in positioning a drone (102) with respect to a structure (101). The drone comprises a camera (103) having an optical system and an image sensor configured to produce an image (190) having a height and a width. The method includes obtaining (s702) a height value, HT, indicating an estimated height of the structure, a set of parameters associated with the camera, the set of parameters includes a focal length parameter, f, indicating a focal length of the optical system of the camera and a height parameter, Hj, indicating said height of the image. The method includes determining (s706), based on HT, f, and HJ, at least one of: i) a first distance value indicating a horizontal or vertical distance, dl, or ii) an angle value indicating an angle for the camera, "
Mobile robot hybrid communication link,https://lens.org/043-039-454-416-894,2008,"A mobile robot communication system includes a remote unit, a repeater module and a control station. A cable connects the repeater module to the control station. The remote unit has a wireless receiver/transmitter for sending and receiving commands. The repeater module has a wireless receiver/transmitter for sending and receiving commands from the mobile unit. The control station is operable in communication with the repeater module for remotely sending and receiving signals. The cable is attached between the repeater module and control station for transmitting signals therebetween."
MOBILE ROBOT HYDRID COMMUNICATION LINK,https://lens.org/163-430-146-211-478,2004,"A mobile robot communication system includes a remote unit, a repeater module and a control station. A cable connects the repeater module to the control station. The remote unit has a wireless receiver/transmitter for sending and receiving commands. The repeater module has a wireless receiver/transmitter for sending and receiving commands from the mobile unit. The control station is operable in communication with the repeater module for remotely sending and receiving signals. The cable is attached between the repeater module and control station for transmitting signals therebetween."
Mobile robot hybrid communication link,https://lens.org/166-666-015-839-791,2005,"A mobile robot communication system includes a remote unit, a repeater module and a control station. A cable connects the repeater module to the control station. The remote unit has a wireless receiver/transmitter for sending and receiving commands. The repeater module has a wireless receiver/transmitter for sending and receiving commands from the mobile unit. The control station is operable in communication with the repeater module for remotely sending and receiving signals. The cable is attached between the repeater module and control station for transmitting signals therebetween."
THREE-DIMENSIONAL PATHWAY TRACKING SYSTEM,https://lens.org/129-756-480-700-59X,2019,"Techniques are described for tracking and determining a three dimensional path travelled by controlled unmanned aircraft, i.e. drones, (601) or other moving objects. By monitoring the strength of communication signals transmitted by an object, the strength of control signals received by the object, and altitude data generated by the object, its three dimensional path is determined. For example, these techniques can be applied to racing drones to determine their positions on a course. An end gate structure for such a course that can automatically transmit disable signals to the drones upon completing the course is also described."
Unmanned aerial vehicle platform,https://lens.org/044-055-425-133-285,2020,"A device receives a request for a flight path of UAV from a first location to a second location in a region, and determines, based on credentials associated with the UAV, whether the UAV is authenticated for utilizing the device and a network. The device determines, when the UAV is authenticated, capability information for the UAV based on the request and component information associated with the UAV. The device calculates the flight path from the first location to the second location based on the capability information and one or more of weather information, air traffic information, obstacle information, or regulatory information associated with the region. The device generates flight path instructions for the flight path based on one or more of the weather information, the air traffic information, the obstacle information, or the regulatory information associated with the region, and provides the flight path instructions to the UAV."
Unmanned aerial vehicle platform,https://lens.org/085-461-544-546-809,2017,"A device receives a request for a flight path of UAV from a first location to a second location in a region, and determines, based on credentials associated with the UAV, whether the UAV is authenticated for utilizing the device and a network. The device determines, when the UAV is authenticated, capability information for the UAV based on the request and component information associated with the UAV. The device calculates the flight path from the first location to the second location based on the capability information and one or more of weather information, air traffic information, obstacle information, or regulatory information associated with the region. The device generates flight path instructions for the flight path based on one or more of the weather information, the air traffic information, the obstacle information, or the regulatory information associated with the region, and provides the flight path instructions to the UAV."
UNMANNED AERIAL VEHICLE PLATFORM,https://lens.org/115-389-457-199-40X,2018,"A device receives a request for a flight path of UAV from a first location to a second location in a region, and determines, based on credentials associated with the UAV, whether the UAV is authenticated for utilizing the device and a network. The device determines, when the UAV is authenticated, capability information for the UAV based on the request and component information associated with the UAV. The device calculates the flight path from the first location to the second location based on the capability information and one or more of weather information, air traffic information, obstacle information, or regulatory information associated with the region. The device generates flight path instructions for the flight path based on one or more of the weather information, the air traffic information, the obstacle information, or the regulatory information associated with the region, and provides the flight path instructions to the UAV."
Unmanned aerial vehicle platform,https://lens.org/098-721-465-291-043,2022,"A device receives a request for a flight path of UAV from a first location to a second location in a region, and determines, based on credentials associated with the UAV, whether the UAV is authenticated for utilizing the device and a network. The device determines, when the UAV is authenticated, capability information for the UAV based on the request and component information associated with the UAV. The device calculates the flight path from the first location to the second location based on the capability information and one or more of weather information, air traffic information, obstacle information, or regulatory information associated with the region. The device generates flight path instructions for the flight path based on one or more of the weather information, the air traffic information, the obstacle information, or the regulatory information associated with the region, and provides the flight path instructions to the UAV."
UNMANNED AERIAL VEHICLE PLATFORM,https://lens.org/046-150-586-197-042,2020,"A device receives a request for a flight path of UAV from a first location to a second location in a region, and determines, based on credentials associated with the UAV, whether the UAV is authenticated for utilizing the device and a network. The device determines, when the UAV is authenticated, capability information for the UAV based on the request and component information associated with the UAV. The device calculates the flight path from the first location to the second location based on the capability information and one or more of weather information, air traffic information, obstacle information, or regulatory information associated with the region. The device generates flight path instructions for the flight path based on one or more of the weather information, the air traffic information, the obstacle information, or the regulatory information associated with the region, and provides the flight path instructions to the UAV."
Autonomous insect carrier,https://lens.org/063-570-306-726-681,2020,"Unmanned autonomous vehicles UAV (e.g., drones) are described that include an insect carrier for transporting and/or capturing mosquitoes or other insects and/or their larvae. The insect carrier may include a programmable opening for delivering the insects/larvae to a select location and/or capture the insects from the select location. Target locations include underground sewers, and the UAV includes sonar sensors to assess spatial surroundings and adjust positioning to avoid any collisions."
FLIGHT CONTROL METHOD AND AIRCRAFT,https://lens.org/036-869-400-337-081,2021,"The present disclosure provides a flight control method. The method includes controlling an imaging device on an aircraft to record a target object at a first frame rate on a first trajectory to obtain a first video, a flight speed of the aircraft on the first trajectory is not lower than a predetermined speed threshold. The method further includes converting the first video into a second video with a second frame rate."
UNMANNED AERIAL VEHICLE,https://lens.org/183-596-522-430-806,2023,"The present invention relates to an unmanned aerial vehicle (UAV) for agricultural weed management. The UAV comprises a control and processing unit (20), and a camera (30). The control and processing unit is configured to control the UAV to fly to a location inside the canopy of a crop and below the vertical height of the crop and/or between a row of a plurality of crops and below the vertical height of the plurality of crops. The control and processing unit is configured to control the camera to acquire at least one image relating to the ground at the location inside the canopy of a crop and below the vertical height of the crop and/or between a row of a plurality of crops and below the vertical height of the plurality of crops. The control and processing unit is configured to analyse the at least one image to determine the presence of at least one weed and its location on the ground."
UNMANNED AERIAL VEHICLE,https://lens.org/156-299-037-579-009,2021,"The present invention relates to an unmanned aerial vehicle (UAV) for agricultural weed management. The UAV comprises a control and processing unit (20), and a camera (30). The control and processing unit is configured to control the UAV to fly to a location inside the canopy of a crop and below the vertical height of the crop and/or between a row of a plurality of crops and below the vertical height of the plurality of crops. The control and processing unit is configured to control the camera to acquire at least one image relating to the ground at the location inside the canopy of a crop and below the vertical height of the crop and/or between a row of a plurality of crops and below the vertical height of the plurality of crops. The control and processing unit is configured to analyse the at least one image to determine the presence of at least one weed and its location on the ground."
UNMANNED AERIAL VEHICLE,https://lens.org/183-596-522-430-806,2023,"The present invention relates to an unmanned aerial vehicle (UAV) for agricultural weed management. The UAV comprises a control and processing unit (20), and a camera (30). The control and processing unit is configured to control the UAV to fly to a location inside the canopy of a crop and below the vertical height of the crop and/or between a row of a plurality of crops and below the vertical height of the plurality of crops. The control and processing unit is configured to control the camera to acquire at least one image relating to the ground at the location inside the canopy of a crop and below the vertical height of the crop and/or between a row of a plurality of crops and below the vertical height of the plurality of crops. The control and processing unit is configured to analyse the at least one image to determine the presence of at least one weed and its location on the ground."
"AUTONOMOUS CAMERA TRACKING APPARATUS, SYSTEM AND METHOD",https://lens.org/174-022-709-471-799,2012,"An autonomous camera tracking system. The system can include a tracking apparatus, and a beacon. The tracking apparatus can include an infrared sensor, a camera, a processor, and a panning stepper motor. The beacon can include an infrared emitter. The infrared sensor can receive an infrared signal from the beacon and, upon detection of a shift in the position of the infrared signal, the stepper motor can pan the camera and the infrared sensor so as to place the beacon in the field of view of the camera. The tracking apparatus can further include a tilting stepper motor, and, upon detection of a shift in the position of the infrared signal, the stepper motor can tilt the camera and the infrared sensor so as to place the beacon in the field of view of the camera."
WEAPON ROBOT WITH SITUATIONAL AWARENESS,https://lens.org/018-503-916-475-515,2009,"A mobile, remotely controlled robot includes a turret subsystem, a robot controller subsystem configured to control the robot, control the turret, and fire the weapon, a robot navigation subsystem configured to determine the position of the robot, a turret orientation determination subsystem, and a robot communications subsystem for receiving commands and for transmitting robot position data and turret orientation data. An operator control unit communications subsystem transmits commands to the robot and receives robot position data and turret orientation data from the robot. An operator control unit navigation subsystem is configured to determine the position of the operator control unit. An operator control unit controller subsystem is responsive to the robot position data, the turret onentation data, and the operator control unit position and is configured to determine if the weapon is aimed at the operator control unit within a predetermined fan angle."
METHODS AND APPARATUS FOR REDUCING ENERGY CONSUMED BY DRONES DURING FLIGHT,https://lens.org/106-782-667-059-354,2018,"Methods and apparatus for reducing energy consumed by drones during flight are disclosed. A drone includes a housing, a motor, and a route manager to generate a route for a flight of the drone based on wind data. The wind data includes turbine-generated wind data provided by turbines that detect airflows received at the turbines. The turbines are located in an area within which a segment of the flight of the drone is to occur. The route is to be followed by the drone during the flight to reduce energy consumed by the drone during the flight."
Methods and apparatus for reducing energy consumed by drones during flight,https://lens.org/174-120-502-025-782,2019,"Methods and apparatus for reducing energy consumed by drones during flight are disclosed. A drone includes a housing, a motor, and a route manager to generate a route for a flight of the drone based on wind data. The wind data includes turbine-generated wind data provided by turbines that detect airflows received at the turbines. The turbines are located in an area within which a segment of the flight of the drone is to occur. The route is to be followed by the drone during the flight to reduce energy consumed by the drone during the flight."
METHODS AND APPARATUS FOR REDUCING ENERGY CONSUMED BY DRONES DURING FLIGHT,https://lens.org/107-192-383-027-058,2018,"Methods and apparatus for reducing energy consumed by drones during flight are disclosed. A drone includes a housing, a motor, and a route manager to generate a route for a flight of the drone based on wind data. The wind data includes turbine-generated wind data provided by turbines that detect airflows received at the turbines. The turbines are located in an area within which a segment of the flight of the drone is to occur. The route is to be followed by the drone during the flight to reduce energy consumed by the drone during the flight."
Audio-visual interaction with user devices,https://lens.org/165-025-294-738-531,2018,"A user device is enabled by an audio-visual assistant for audio-visual interaction with a user. The audio-visual assistant enables the user device to track the user's eyes and face to determine objects on the screen that the user is currently observing. Various tasks can be executed on the objects based on further input provided by the user. The user can provide further inputs via facial gestures, voice or combinations thereof for executing the various tasks."
Audio-visual interaction with user devices,https://lens.org/182-044-518-942-954,2019,"A user device is enabled by an audio-visual assistant for audio-visual interaction with a user. The audio-visual assistant enables the user device to track the user's eyes and face to determine objects on the screen that the user is currently observing. Various tasks can be executed on the objects based on further input provided by the user. The user can provide further inputs via facial gestures, voice or combinations thereof for executing the various tasks."
AUDIO-VISUAL INTERACTION WITH USER DEVICES,https://lens.org/121-920-989-960-862,2015,"A user device is enabled by an audio-visual assistant for audio-visual interaction with a user. The audio-visual assistant enables the user device to track the user's eyes and face to determine objects on the screen that the user is currently observing. Various tasks can be executed on the objects based on further input provided by the user. The user can provide further inputs via facial gestures, voice or combinations thereof for executing the various tasks."
AUDIO-VISUAL INTERACTION WITH USER DEVICES,https://lens.org/108-779-817-261-933,2018,"A user device is enabled by an audio-visual assistant for audio-visual interaction with a user. The audio-visual assistant enables the user device to track the user's eyes and face to determine objects on the screen that the user is currently observing. Various tasks can be executed on the objects based on further input provided by the user. The user can provide further inputs via facial gestures, voice or combinations thereof for executing the various tasks."
"SYSTEMS, METHODS, AND DEVICES FOR PROVIDING ASSISTANCE TO AN UNMANNED AERIAL VEHICLE",https://lens.org/162-543-845-354-165,2016,"A service unmanned aerial vehicle (UAV) includes a flight system, a status component, a navigation system, and a surveillance component. The flight system is for flying the service UAV. The status component is configured to determine that a first UAV is disabled. The navigation system is configured to fly the service UAV to a landing location of the first UAV in response to the status component determining that the first UAV is disabled. The surveillance component is configured to observe the first UAV and an area surrounding the first UAV."
"Systems, methods, and devices for providing assistance to an unmanned aerial vehicle",https://lens.org/017-787-874-849-160,2016,"A service unmanned aerial vehicle (UAV) includes a flight system, a status component, a navigation system, and a surveillance component. The flight system is for flying the service UAV. The status component is configured to determine that a first UAV is disabled. The navigation system is configured to fly the service UAV to a landing location of the first UAV in response to the status component determining that the first UAV is disabled. The surveillance component is configured to observe the first UAV and an area surrounding the first UAV."
Moving robot and method for controlling the same,https://lens.org/010-281-285-877-056,2018,"A robot that moves to a position indicated by a remote device, and a method for controlling the moving robot. The moving robot according to an embodiment includes a traveling unit that moves a main body, a light reception unit that receives light, and a control unit that determines a traveling direction of the moving robot by filtering the light received from the light reception unit in accordance with a probability-based filtering method, and controls the traveling unit so that the main body travels in the traveling direction."
MOVING ROBOT AND METHOD FOR CONTROLLING THE SAME,https://lens.org/077-038-997-338-211,2016,"A robot that moves to a position indicated by a remote device, and a method for controlling the moving robot. The moving robot according to an embodiment includes a traveling unit that moves a main body, a light reception unit that receives light, and a control unit that determines a traveling direction of the moving robot by filtering the light received from the light reception unit in accordance with a probability-based filtering method, and controls the traveling unit so that the main body travels in the traveling direction."
Signaling voice-controlled devices,https://lens.org/033-363-253-090-586,2017,"Techniques for indicating to a voice-controlled device that a user is going to provide a voice command to the device. In response to receiving such an indication, the device may prepare to process an audio signal based on sound captured by a microphone of the device for the purpose of identifying the voice command from the audio signal. For instance, a user may utilize a signaling device that includes a button that, when actuated, sends a signal that is received by the voice-controlled device. In response to receiving the signal, a microphone of the voice-controlled device may capture sound that is proximate to the voice-controlled device and may create an audio signal based on the sound. The voice-controlled device may then analyze the audio signal for a voice command of the user or may provide the audio signal to a remote service for identifying the command."
Signaling voice-controlled devices,https://lens.org/079-672-001-851-412,2018,"Techniques for indicating to a voice-controlled device that a user is going to provide a voice command to the device. In response to receiving such an indication, the device may prepare to process an audio signal based on sound captured by a microphone of the device for the purpose of identifying the voice command from the audio signal. For instance, a user may utilize a signaling device that includes a button that, when actuated, sends a signal that is received by the voice-controlled device. In response to receiving the signal, a microphone of the voice-controlled device may capture sound that is proximate to the voice-controlled device and may create an audio signal based on the sound. The voice-controlled device may then analyze the audio signal for a voice command of the user or may provide the audio signal to a remote service for identifying the command."
METHOD AND DEVICE FOR RESCUE MISSION ASSISTANCE,https://lens.org/067-266-967-993-073,2021,"A method at a Unmanned Aerial Vehicle (UAV), and a UAV, adapted therefore, is adapted for enabling assisting in a rescue mission, where the method comprise: initiating a first localization of at least one body or object; initiating an analysis, for determining, at least partly based on the first localization of the at least one body or object, a need for activities, and initiating the determined activities, comprising applying floatable foam to an area on or in close proximity to the at least one body or object, while applying, to the floatable foam, a recognizable means capable of assisting in a second localization of the at least one body or object."
Device and system for the automatic control of a helicopter,https://lens.org/196-390-580-850-022,2003,"Device and system for the automatic control of a helicopter. The automatic control device (6) comprises a vertical objective law (A) in respect of the pitching axis, which automatically determines a control command (UT1) for operating the tilting of the disk of main rotor of the helicopter, a speed limitation law (B) for limiting the airspeed of the helicopter with respect to at least one limit value, detection means (10) for automatically detecting whether the airspeed reaches the limit value, and toggling means (11) for, in order to select the objective law (A, B) whose control command (UT1, UT2) is used for the pitching axis, automatically toggling from the first law (A) to the second law (B), when the detection means (10) detect that the airspeed has reached the limit value."
TETHERED COLLABORATIVE ROBOT WITH SMART TORCH,https://lens.org/031-796-770-656-454,2022,"A torch (220) for use by a robot. The torch has a body (226) that can be connected to an arm of the robot. A first actuator (222) on the body can be activated by a user to initiate a recording cycle at a starting point of a desired welding or cutting path and to terminate the recording cycle at an ending point of the path. A second actuator (224) on the body can be activated by the user to indicate way points (227, 228, 229) from the starting point (227) to the ending point (229) as the user moves the torch along the path. The first actuator sends first information to a robot controller, operatively connected to and located remotely from the robot, to initiate and to terminate the recording cycle at the controller. The second actuator device sends the way points as second information to the controller to be recorded at the controller during the recording cycle."
TETHERED COLLABORATIVE ROBOT WITH SMART TORCH,https://lens.org/031-796-770-656-454,2022,"A torch (220) for use by a robot. The torch has a body (226) that can be connected to an arm of the robot. A first actuator (222) on the body can be activated by a user to initiate a recording cycle at a starting point of a desired welding or cutting path and to terminate the recording cycle at an ending point of the path. A second actuator (224) on the body can be activated by the user to indicate way points (227, 228, 229) from the starting point (227) to the ending point (229) as the user moves the torch along the path. The first actuator sends first information to a robot controller, operatively connected to and located remotely from the robot, to initiate and to terminate the recording cycle at the controller. The second actuator device sends the way points as second information to the controller to be recorded at the controller during the recording cycle."
SPECIAL EFFECTS TECHNIQUES,https://lens.org/176-147-020-601-700,2016,A system in accordance with present embodiments includes a ground controller and an unmanned aerial vehicle including communications circuitry configured to transmit signals to and receive signals from the ground controller. The system may also include a vehicle controller configured to execute a flight plan and at least one special effects module. The system may also include a special effects module controller configured to cause the special effect to be activated in response to an activation signal from the ground controller.
Special effects techniques,https://lens.org/109-266-822-296-711,2018,A system in accordance with present embodiments includes a ground controller and an unmanned aerial vehicle including communications circuitry configured to transmit signals to and receive signals from the ground controller. The system may also include a vehicle controller configured to execute a flight plan and at least one special effects module. The system may also include a special effects module controller configured to cause the special effect to be activated in response to an activation signal from the ground controller.
SPECIAL EFFECTS TECHNIQUES,https://lens.org/042-269-384-934-051,2017,A system in accordance with present embodiments includes a ground controller and an unmanned aerial vehicle including communications circuitry configured to transmit signals to and receive signals from the ground controller. The system may also include a vehicle controller configured to execute a flight plan and at least one special effects module. The system may also include a special effects module controller configured to cause the special effect to be activated in response to an activation signal from the ground controller.
Special effects techniques,https://lens.org/142-987-866-246-456,2016,A system in accordance with present embodiments includes a ground controller and an unmanned aerial vehicle including communications circuitry configured to transmit signals to and receive signals from the ground controller. The system may also include a vehicle controller configured to execute a flight plan and at least one special effects module. The system may also include a special effects module controller configured to cause the special effect to be activated in response to an activation signal from the ground controller.
SPECIAL EFFECTS TECHNIQUES,https://lens.org/114-601-242-381-30X,2018,A system in accordance with present embodiments includes a ground controller and an unmanned aerial vehicle including communications circuitry configured to transmit signals to and receive signals from the ground controller. The system may also include a vehicle controller configured to execute a flight plan and at least one special effects module. The system may also include a special effects module controller configured to cause the special effect to be activated in response to an activation signal from the ground controller.
Apparatus and method for remote control using camera-based virtual touch,https://lens.org/094-599-190-861-083,2019,"A remote control apparatus comprises an image acquisition unit for acquiring an image of the body of a user by photographing the image, a location calculation unit for calculating coordinate data representing the locations of a first coordinate (eye) and a second coordinate (a finger or a pointer) of the body of the user by means of the image received from the image acquisition unit, and a match confirmation unit for checking whether the locations of the first and second coordinates of the body of the user match the extended connecting straight line, the coordinates having been confirmed on the basis of the camera lens-based coordinate data calculated in the location calculation unit, and if the match is confirmed, then concluding the setup intention of the user to be an affirmative."
APPARATUS AND METHOD FOR REMOTE CONTROL USING CAMERA-BASED VIRTUAL TOUCH,https://lens.org/182-924-663-670-321,2017,"A remote control apparatus comprises an image acquisition unit for acquiring an image of the body of a user by photographing the image, a location calculation unit for calculating coordinate data representing the locations of a first coordinate (eye) and a second coordinate (a finger or a pointer) of the body of the user by means of the image received from the image acquisition unit, and a match confirmation unit for checking whether the locations of the first and second coordinates of the body of the user match the extended connecting straight line, the coordinates having been confirmed on the basis of the camera lens-based coordinate data calculated in the location calculation unit, and if the match is confirmed, then concluding the setup intention of the user to be an affirmative."
APPARATUS AND METHOD FOR REMOTE CONTROL USING CAMERA-BASED VIRTUAL TOUCH,https://lens.org/024-572-973-988-604,2019,"A remote control apparatus comprises an image acquisition unit for acquiring an image of the body of a user by photographing the image, a location calculation unit for calculating coordinate data representing the locations of a first coordinate (eye) and a second coordinate (a finger or a pointer) of the body of the user by means of the image received from the image acquisition unit, and a match confirmation unit for checking whether the locations of the first and second coordinates of the body of the user match the extended connecting straight line, the coordinates having been confirmed on the basis of the camera lens-based coordinate data calculated in the location calculation unit, and if the match is confirmed, then concluding the setup intention of the user to be an affirmative."
UNMANNED AERIAL VEHICLE,https://lens.org/142-228-885-080-626,2018,"The present invention provides an unmanned aerial vehicle, comprising a main body, a fixed wing mounted on both sides of the main body, a plurality of rotors securingly connected to both sides of the fixed wing through respective rotor supporting parts, an airborne sensor system used for gathering flying data of the unmanned aerial vehicle, and a flight control system connected to the airborne sensor system, for adjusting states of the fixed wing and/or the rotors and further flying state of the unmanned aerial vehicle according to the flying data. According to the unmanned aerial vehicle, it is unnecessary for the rotor shaft thereof to rotate relative to the fixed wing, and thus complex mechanical components for controlling rotation of the rotor shaft are no longer necessary. Compared with the existing tilted-rotor aircraft, the aircraft provided herein has a simpler structure and lighter weight. At the same time, the unmanned aerial vehicle adopts one power system to perform vertical taking-off and landing and cruising. Therefore, it can provide much more capacity for meeting the requirements of loading and flying range and time compared with existing aircrafts."
INTEGRATED INTELLIGENT SPRINKLER IRRIGATION ROBOT FOR OPEN SPACE,https://lens.org/029-277-235-504-452,2023,"Described is an integrated intelligent sprinkler irrigation robot for open space, which can be used in cooperation with a UAV, comprising: a walking system, a balance system, an irrigation system and a control system. In the present invention, through wireless connection between the controller and the UAV, a specific dry area in a certain region can be accurately obtained through the advantage of broad field of vision of the UAV, and a signal can be transmitted to the controller, which is convenient for the controller to control the water-saving irrigation device for accurate irrigation of key areas. Two lower photoelectric sensors are installed on both sides of the front end of the traveling direction of a bottom plate, and electric control lifting devices are installed on both sides of a middle plate; the two photoelectric sensors can detect whether the ground on both sides of the traveling direction of the bottom plate is level, and transmit the signal to the controller; and the controller regulates the lifting of the two electric control lifting devices according to the transmitted ground information, to ensure that the irrigation system installed on a top plate remains level and the accuracy of sprinkler irrigation is improved."
APPARATUS FOR REMOTE OPERATION ON A ROOFTOP,https://lens.org/082-926-456-495-19X,2014,"An apparatus for remotely performing an operation on a roof including a frame assembly configured to be positioned on the roof, a pivot assembly configured to couple to an external anchor point such that the frame assembly is positioned between the pivot assembly and an operating position, and a flexible control line including a first segment having a first end coupled to the frame assembly and extending in substantially a first direction to a second end disposed at the operating position, and a second segment having a first end coupled to the frame assembly and extending in a second direction substantially opposite the first direction through the pivot assembly, which redirects the second segment to the first direction, to a second end at the operating position, wherein pulling the second ends of the first and second segments controls movement of the frame assembly on the roof."
Apparatus for remote operation on a rooftop,https://lens.org/015-860-805-251-988,2016,"An apparatus for remotely performing an operation on a roof including a frame assembly configured to be positioned on the roof, a pivot assembly configured to couple to an external anchor point such that the frame assembly is positioned between the pivot assembly and an operating position, and a flexible control line including a first segment having a first end coupled to the frame assembly and extending in substantially a first direction to a second end disposed at the operating position, and a second segment having a first end coupled to the frame assembly and extending in a second direction substantially opposite the first direction through the pivot assembly, which redirects the second segment to the first direction, to a second end at the operating position, wherein pulling the second ends of the first and second segments controls movement of the frame assembly on the roof."
SYSTEM AND METHOD FOR CONTROLLING UNMANNED VEHICLES,https://lens.org/087-715-392-121-587,2016,"A system for controlling an unmanned vehicle is disclosed to facilitate remote-control operation of the unmanned vehicle from long distances. The system includes at least one ground control communication device having a transceiver configured for operation in a cellular communication network. The system also includes an unmanned vehicle comprising another transceiver configured for operation in the cellular communication network. The unmanned vehicle is further configured to be responsive to communications received via the transceiver from the communication device, wherein the communications received from the communication device includes operation commands. Additionally, the unmanned vehicle is configured to transmit video surveillance data and other monitoring data to the communication device via the cellular network."
Robot having an obstacle detection unit and method of controlling the same,https://lens.org/096-821-282-960-609,2009,"A robot having an obstacle detection unit and a method of controlling the robot. The robot includes a main body, a driving unit, an auxiliary body, and a control unit. The driving unit drives the main body along a given surface. The auxiliary body projects from the main body and detecting an obstacle around the main body. The control unit controls the driving unit according to results of the detection so that the main body and the obstacle are maintained at a predetermined distance from each other."
ROBOT CONTROLLER,https://lens.org/007-325-392-544-111,1988,A robot controller according to this invention is designed to use a given speed command to drive a servo motor (4) which forms a drive mechanism for robot axes. A filter circuit (1) comprising a plurality of load filter stages each having a given acceleration pattern of input/output characteristic is employed to perform smooth positioning control in a required range with a reasonable tracking accuracy maintained.
Remote keyless entry system for a vehicle and a method of controlling a vehicle function by the same,https://lens.org/028-145-855-586-283,2010,A remote unit for a keyless entry system for a vehicle. The remote unit comprising a controller configured to generate a command signal in response to a user input. The command signal comprising a first command message and a substantially similar second command message. The first command message comprises a first low data rate portion and the second command message comprises a high data rate portion. The remote unit further comprising a transmitter configured to transmit the command.
REMOTE KEYLESS ENTRY SYSTEM FOR A VEHICLE AND A METHOD OF CONTROLLING A VEHICLE FUNCTION BY THE SAME,https://lens.org/106-634-393-272-785,2008,A remote unit for a keyless entry system for a vehicle. The remote unit comprising a controller configured to generate a command signal in response to a user input. The command signal comprising a first command message and a substantially similar second command message. The first command message comprises a first low data rate portion and the second command message comprises a high data rate portion. The remote unit further comprising a transmitter configured to transmit the command.
UNMANNED AERIAL VEHICLE,https://lens.org/021-052-942-901-387,2022,"An unmanned aerial vehicle (10) for at least one of direction finding and spectrum monitoring comprises a main body (12) including at least one electronic circuit (14) and at least one motor (16). The unmanned aerial vehicle (10) also has at least one rotor (18) associated with the motor (16). The unmanned aerial vehicle (10) comprises an outer housing (24) surrounding the rotor (18) partially, the outer housing (24) comprising at least one antenna module (26) configured to receive a radio signal."
UNMANNED AERIAL VEHICLE,https://lens.org/021-052-942-901-387,2022,"An unmanned aerial vehicle (10) for at least one of direction finding and spectrum monitoring comprises a main body (12) including at least one electronic circuit (14) and at least one motor (16). The unmanned aerial vehicle (10) also has at least one rotor (18) associated with the motor (16). The unmanned aerial vehicle (10) comprises an outer housing (24) surrounding the rotor (18) partially, the outer housing (24) comprising at least one antenna module (26) configured to receive a radio signal."
PORTABLE LANDING AND TAKE-OFF PAD FOR AN UNMANNED AIR AERIAL VEHICLE,https://lens.org/161-172-103-103-301,2021,"A portable landing pad (100) for landing of a drone (200) includes a platform (105) having a flat surface for receiving the drone, and multiple global positioning system (GPS) guided lasers (125) positioned at near edges of the platform and configured for guiding the drone to land and take off from the platform."
"AUTONOMOUS TAKING OFF, POSITIONING AND LANDING OF UNMANNED AERIAL VEHICLES (UAV) ON A MOBILE PLATFORM",https://lens.org/066-022-233-286-647,2019,"A method for autonomously tracking a landing surface by a UAV to enable repeated autonomous take off and landings without the need for GPS data or any other satellite positioning techniques. The landing surface may be on an autonomous and/or moving ground vehicle, and comprises two or more markers on the landing surface. The markers may be of different sizes. The drone comprises two or more downward looking cameras, with at least one camera having a different focal length to the other, to form a dual monocular system which captures images of the markers on the landing surface. The images are analysed to estimate the pose of the markers and thus determine the location of the UAV with respect to the landing surface, which is then provided to a flight controller of the UAV."
"AUTONOMOUS TAKING OFF, POSITIONING AND LANDING OF UNMANNED AERIAL VEHICLES (UAV) ON A MOBILE PLATFORM",https://lens.org/033-491-343-696-190,2021,"A method for autonomously tracking a landing surface by a UAV to enable repeated autonomous take off and landings without the need for GPS data or any other satellite positioning techniques. The landing surface may be on an autonomous and/or moving ground vehicle, and comprises two or more markers on the landing surface. The markers may be of different sizes. The drone comprises two or more downward looking cameras, with at least one camera having a different focal length to the other, to form a dual monocular system which captures images of the markers on the landing surface. The images are analysed to estimate the pose of the markers and thus determine the location of the UAV with respect to the landing surface, which is then provided to a flight controller of the UAV."
LIGHTING DEVICE ALIGNMENT CALIBRATION SYSTEM,https://lens.org/041-299-086-330-138,2019,"A system for detecting misalignment of a light fixture uses a gateway controller device to receive images captured by an aerial drone. The gateway controller will select a group of the images and, for each image in the group: identify a segment of an illuminated surface that is contained in the image; identify a light fixture that is configured to direct light to the segment; and determine whether the image contains content indicating that the light fixture improperly aligned. For any image that indicating that the light fixture is improperly aligned, the system will output a signal indicating that the light fixture requires recalibration."
Lighting device alignment calibration system,https://lens.org/082-415-615-103-989,2020,"A system for detecting misalignment of a light fixture uses a gateway controller device to receive images captured by an aerial drone. The gateway controller will select a group of the images and, for each image in the group: identify a segment of an illuminated surface that is contained in the image; identify a light fixture that is configured to direct light to the segment; and determine whether the image contains content indicating that the light fixture improperly aligned. For any image that indicating that the light fixture is improperly aligned, the system will output a signal indicating that the light fixture requires recalibration."
Snow/Ice Melting Drone Device,https://lens.org/192-294-255-417-262,2018,"An unmanned aerial vehicle (UAV) melting device, including an unmanned aerial vehicle (UAV), a melting apparatus to melt snow or ice in an area around the UAV melting device; and one or more connecting attachments to couple the UAV to the melting apparatus. The UAV melting device comprises a wireless transceiver, the wireless transceiver to receive operational commands from a user to determine direction of operation and area of coverage of the UAV melting device. The melting apparatus further comprises one or more power sources and one or more heating assemblies."
METHOD AND APPARATUS FOR PRIVACY-SENSITIVE ROUTING OF AN AERIAL DRONE,https://lens.org/105-499-958-103-060,2022,"There is provided a computer-implemented method comprising: receiving a routing request for an aerial drone to travel to a target location (603) located in or near a structure (103); accessing map data comprising line-of-sight data for one or more privacy-sensitive features of the structure, the one or more privacy-sensitive features including one or more windows (201, 505), one or more openings, or a combination thereof; calculating a privacy-sensitive route for the aerial drone to the target location (603) based on the map data; and providing the privacy-sensitive route in response to the routing request."
MANAGING AN UNMANNED AERIAL VEHICLE IDENTITY,https://lens.org/051-786-256-451-292,2022,"In embodiments of systems and methods for managing an unmanned aerial vehicle (UAV) identity, a processor of a network computing device may generate an anonymity token that is associated with a digital certificate of a UAV, provide the anonymity token to the UAV for use in operations, receive a request to authenticate the UAV, wherein the request includes the anonymity token, determine whether the anonymity token included in the request is associated with the digital certificate, and send an indication that the UAV is authenticated responsive to the request in response to determining that the anonymity token included in the request is associated with the digital certificate."
MANAGING AN UNMANNED AERIAL VEHICLE IDENTITY,https://lens.org/051-786-256-451-292,2022,"In embodiments of systems and methods for managing an unmanned aerial vehicle (UAV) identity, a processor of a network computing device may generate an anonymity token that is associated with a digital certificate of a UAV, provide the anonymity token to the UAV for use in operations, receive a request to authenticate the UAV, wherein the request includes the anonymity token, determine whether the anonymity token included in the request is associated with the digital certificate, and send an indication that the UAV is authenticated responsive to the request in response to determining that the anonymity token included in the request is associated with the digital certificate."
Managing An Unmanned Aerial Vehicle Identity,https://lens.org/055-931-818-737-81X,2022,"In embodiments of systems and methods for managing an unmanned aerial vehicle (UAV) identity, a processor of a network computing device may generate an anonymity token that is associated with a digital certificate of a UAV, provide the anonymity token to the UAV for use in operations, receive a request to authenticate the UAV, wherein the request includes the anonymity token, determine whether the anonymity token included in the request is associated with the digital certificate, and send an indication that the UAV is authenticated responsive to the request in response to determining that the anonymity token included in the request is associated with the digital certificate."
Managing An Unmanned Aerial Vehicle Identity,https://lens.org/055-931-818-737-81X,2022,"In embodiments of systems and methods for managing an unmanned aerial vehicle (UAV) identity, a processor of a network computing device may generate an anonymity token that is associated with a digital certificate of a UAV, provide the anonymity token to the UAV for use in operations, receive a request to authenticate the UAV, wherein the request includes the anonymity token, determine whether the anonymity token included in the request is associated with the digital certificate, and send an indication that the UAV is authenticated responsive to the request in response to determining that the anonymity token included in the request is associated with the digital certificate."
LIGHTING CONTROL,https://lens.org/151-856-162-417-663,2016,"Apparatus comprising: a transmitter for controlling one or more luminaires which illuminate at least part of an environment occupied by a user; and a controller configured to provide control functionality for controlling the luminaires via the transmitter; wherein the controller is configured to receive an altitude measurement from an altimeter disposed about the user's person, and based thereon to provide said control functionality in dependence on an altitude of the user relative to an altitude of each of the luminaires."
Lighting control,https://lens.org/141-298-318-149-436,2019,"Apparatus comprising: a transmitter for controlling one or more luminaires which illuminate at least part of an environment occupied by a user; and a controller configured to provide control functionality for controlling the luminaires via the transmitter; wherein the controller is configured to receive an altitude measurement from an altimeter disposed about the user's person, and based thereon to provide said control functionality in dependence on an altitude of the user relative to an altitude of each of the luminaires."
LIGHTING CONTROL,https://lens.org/165-539-328-066-39X,2016,"Apparatus comprising: a transmitter for controlling one or more luminaires which illuminate at least part of an environment occupied by a user; and a controller configured to provide control functionality for controlling the luminaires via the transmitter; wherein the controller is configured to receive an altitude measurement from an altimeter disposed about the user's person, and based thereon to provide said control functionality in dependence on an altitude of the user relative to an altitude of each of the luminaires."
SYSTEMS AND METHODS FOR COMMUNICATING WITH THIRD PARTIES EXTERNAL TO AUTONOMOUS VEHICLES,https://lens.org/015-561-776-133-180,2023,"An apparatus and method for communicating with third parties external to autonomous vehicles are disclosed. In one aspect, the apparatus may be configured to receive a signal from a first user interface mounted to an exterior of an autonomous vehicle, establish a two way communication between the first user interface and a remote system, authenticate a third party, and in response to the third party being authenticated, establish a connection with a second user interface."
Unmanned vehicle control system and apparatus,https://lens.org/068-585-302-702-395,2017,"A system for controlling an unmanned aerial vehicle may include a GNSS receiver, a transponder, one or more flight controls, a UAV operation module, a UAV mission module, and a UAV chassis. The system may include an operating area defined within an airspace and an airspace controller, and a transponder key issued to the UAV by the airspace controller. The airspace controller and the UAV may communicate to unlock UAV access of the operating area, including transmitting a transponder ID code for verification to the airspace controller; receiving a read certificate from the airspace controller; transmitting a mission plan to the airspace controller; receiving a mission key from the airspace controller; verifying the mission key via read back transmission to the airspace controller; and receiving a mission plan from the airspace controller in the form of the transponder key, the mission plan unlocking access to the operating area."
Managing dynamic obstructions in air traffic control systems for unmanned aerial vehicles,https://lens.org/069-410-905-970-497,2020,"An Unmanned Aerial Vehicle (UAV) includes flight components attached or disposed to a base; one or more cameras; radar; one or more wireless interfaces; a processing device communicatively coupled to the flight components, the one or more cameras, the radar, and the wireless interfaces; and memory storing instructions that, when executed, cause the processing device to monitor proximate airspace with one or more of the one or more cameras and the radar; detect an obstruction based on the monitor; identify characteristics of the obstruction; alter a flight plan, through the flight components, if required based on the characteristics; and communicate the obstruction to an air traffic control system via the one or more wireless interfaces."
"Control system for a flying object, control device therefor, and marker thereof",https://lens.org/092-436-818-435-153,2022,"A control system 2 for a flying object includes at least one marker 6, which corresponds to control information related to the control of the flying object, a reading unit 12 for reading the control information, and a flight information transmitting unit 14 for transmitting flight information to the flying object based on the control information read by the reading unit."
"UNMANNED AIRCRAFT, INFORMATION PROCESSING METHOD, AND RECORDING MEDIUM",https://lens.org/062-103-935-601-989,2021,"An unmanned aircraft includes: a sensor that includes at least a microphone that generates sound data; and a processor. The processor determines quality of a target sound using the sound data generated by the microphone, obtains a positional relationship between the unmanned aircraft and a sound source of the target sound using data generated by the sensor, and controls movement of the unmanned aircraft to control a distance between the unmanned aircraft and the sound source of the target sound, in accordance with the quality of the target sound and the positional relationship."
Apparatus and method for monitoring premises,https://lens.org/154-086-394-276-530,2018,"A system for monitoring premises comprises; an unmanned aerial vehicle (UAV) 320 having a three dimensional (3D) scanner 327, a baseline model database 330, and a control circuit 314 having a communication device 312. The control circuit instructs the UAV to travel to a monitored premises and perform a 3D scan with the 3D scanner. The control circuit then compares a current state of at least one feature of in the 3D scan with a baseline state of the at least one feature in a baseline state model retrieved from the database. The control circuit is further configured to identify a deviation of the current state of the feature from the baseline state. The feature may be a door, gate, window, electrical box or security camera. The baseline state may be a gap width between: door panels, window panels, a door and door frame or a window and window frame. The UAV may further comprise a colour or thermal image sensor 328. The control circuit may also trigger an alert to a user based on a detected deviation of the current state of a feature. A corresponding method and apparatus are also disclosed."
System and method for providing real time audio content to flying camera video,https://lens.org/104-529-586-312-926,2022,"An apparatus includes a transceiver circuit and a first controller circuit. The transceiver circuit may be configured to receive an uplink channel and transmit a downlink channel. The first controller circuit configured to (i) control operation of an unmanned aerial vehicle and a camera in response to commands received via the uplink channel, (ii) capture video data from the camera, (iii) generate a first encoded video stream having a first resolution and a second encoded video stream having a second resolution, (iv) store the first encoded video stream with time stamp information on a storage medium, (v) transmit the second encoded video stream and the time stamp information via the downlink channel, (vi) receive encoded audio information associated with previously transmitted time stamp information via the uplink channel, and (vii) combine the encoded audio information with the first encoded video stream stored on the storage medium using the associated time stamp information."
System and method for providing real time audio content to flying camera video,https://lens.org/104-529-586-312-926,2022,"An apparatus includes a transceiver circuit and a first controller circuit. The transceiver circuit may be configured to receive an uplink channel and transmit a downlink channel. The first controller circuit configured to (i) control operation of an unmanned aerial vehicle and a camera in response to commands received via the uplink channel, (ii) capture video data from the camera, (iii) generate a first encoded video stream having a first resolution and a second encoded video stream having a second resolution, (iv) store the first encoded video stream with time stamp information on a storage medium, (v) transmit the second encoded video stream and the time stamp information via the downlink channel, (vi) receive encoded audio information associated with previously transmitted time stamp information via the uplink channel, and (vii) combine the encoded audio information with the first encoded video stream stored on the storage medium using the associated time stamp information."
"METHOD FOR INDICATING INFORMATION OF UNMANNED AERIAL VEHICLE, UNMANNED AERIAL VEHICLE, AND GROUND EQUIPMENT",https://lens.org/003-289-706-630-370,2020,"A method for prompting information of an unmanned aerial vehicle, an unmanned aerial vehicle, and a ground terminal device are provided. The method includes: acquiring status information of the unmanned aerial vehicle; and transmitting the status information of the unmanned aerial vehicle to a ground terminal device, such that the ground terminal device acquires audio prompt information corresponding to the status information according to the status information of the unmanned aerial vehicle and performs an audio prompt according to the audio prompt information."
"Method, device and system for processing a flight task",https://lens.org/035-386-015-154-665,2021,"A method, a device and a system for processing a flight task are provided. The method comprises receiving a loading request for flight data, searching for corresponding flight data according to the loading request, processing located flight data in response to the loading request, and loading the located flight data to control a corresponding aerial vehicle to perform a corresponding flight task."
"METHOD, DEVICE AND SYSTEM FOR PROCESSING A FLIGHT TASK",https://lens.org/058-234-361-469-776,2017,"A method, a device and a system for processing a flight task are provided. The method comprises receiving a loading request for flight data, searching for corresponding flight data according to the loading request, processing located flight data in response to the loading request, and loading the located flight data to control a corresponding aerial vehicle to perform a corresponding flight task."
"Systems, apparatus, and methods for drone audio noise reduction",https://lens.org/176-715-009-872-916,2019,"Methods, systems, and apparatus for audio noise reduction from a drone are disclosed. An example apparatus includes a first sensor to gather acoustic data and a second sensor to gather rotational motion data of a rotor. The example apparatus also includes an analyzer to match the rotational motion data to a filter and filter the acoustic data using the filter. The analyzer also is to generate an audio signal based on the filtered acoustic data."
"SYSTEMS, APPARATUS, AND METHODS FOR DRONE AUDIO NOISE REDUCTION",https://lens.org/151-089-742-908-712,2019,"Methods, systems, and apparatus for audio noise reduction from a drone are disclosed. An example apparatus includes a first sensor to gather acoustic data and a second sensor to gather rotational motion data of a rotor. The example apparatus also includes an analyzer to match the rotational motion data to a filter and filter the acoustic data using the filter. The analyzer also is to generate an audio signal based on the filtered acoustic data."
Unmanned following vehicle,https://lens.org/199-957-985-298-794,2023,"An unmanned following vehicle includes a controller that controls the unmanned following vehicle to move in parallel with a moving object by following the moving object on a left side or a right side of the moving object. For example, the controller adjusts a moving speed of the unmanned following vehicle according to a Y-axis coordinate difference value, which is a difference value between a position of the moving object and a position of the unmanned following vehicle in a forward direction. The controller also adjusts a steering direction and a steering angle of the unmanned following vehicle according to an X-axis coordinate difference value, which is a difference value between the position of the moving object and the position of the unmanned following vehicle in a lateral direction."
"Unmanned aerial vehicle control system, unmanned aerial vehicle control method, and program",https://lens.org/012-757-251-763-193,2023,"An unmanned aerial vehicle is caused to fly by avoiding a no-fly zone, which changes as a moving object moves. Provided is an unmanned aerial vehicle control system, including: moving object position acquisition means for acquiring moving object position information on a current position of a moving object moving above a surface of an earth; zone setting means for setting a no-fly zone in which a flight of an unmanned aerial vehicle is inhibited based on the moving object position information; and flight control means for controlling the flight of the unmanned aerial vehicle so that the unmanned aerial vehicle avoids the no-fly zone set based on the moving object position information."
"UNMANNED AERIAL VEHICLE CONTROL SYSTEM, UNMANNED AERIAL VEHICLE CONTROL METHOD, AND PROGRAM",https://lens.org/004-505-067-036-286,2021,"An unmanned aerial vehicle is caused to fly by avoiding a no-fly zone, which changes as a moving object moves. Provided is an unmanned aerial vehicle control system, including: moving object position acquisition means for acquiring moving object position information on a current position of a moving object moving above a surface of an earth; zone setting means for setting a no-fly zone in which a flight of an unmanned aerial vehicle is inhibited based on the moving object position information; and flight control means for controlling the flight of the unmanned aerial vehicle so that the unmanned aerial vehicle avoids the no-fly zone set based on the moving object position information."
"Unmanned aerial vehicle control system, unmanned aerial vehicle control method, and program",https://lens.org/012-757-251-763-193,2023,"An unmanned aerial vehicle is caused to fly by avoiding a no-fly zone, which changes as a moving object moves. Provided is an unmanned aerial vehicle control system, including: moving object position acquisition means for acquiring moving object position information on a current position of a moving object moving above a surface of an earth; zone setting means for setting a no-fly zone in which a flight of an unmanned aerial vehicle is inhibited based on the moving object position information; and flight control means for controlling the flight of the unmanned aerial vehicle so that the unmanned aerial vehicle avoids the no-fly zone set based on the moving object position information."
"UNMANNED AERIAL VEHICLE CONTROL SYSTEM, UNMANNED AERIAL VEHICLE CONTROL METHOD, AND PROGRAM",https://lens.org/158-983-557-132-511,2019,"An unmanned aerial vehicle is caused to fly by avoiding a no-fly zone, which changes as a moving object moves. Provided is an unmanned aerial vehicle control system, including: moving object position acquisition means for acquiring moving object position information on a current position of a moving object moving above a surface of an earth; zone setting means for setting a no-fly zone in which a flight of an unmanned aerial vehicle is inhibited based on the moving object position information; and flight control means for controlling the flight of the unmanned aerial vehicle so that the unmanned aerial vehicle avoids the no-fly zone set based on the moving object position information."
"Unmanned aerial vehicle control system, unmanned aerial vehicle control method, and program",https://lens.org/054-831-149-451-456,2021,"An unmanned aerial vehicle is caused to fly by avoiding a no-fly zone, which changes as a moving object moves. Provided is an unmanned aerial vehicle control system, including: moving object position acquisition means for acquiring moving object position information on a current position of a moving object moving above a surface of an earth; zone setting means for setting a no-fly zone in which a flight of an unmanned aerial vehicle is inhibited based on the moving object position information; and flight control means for controlling the flight of the unmanned aerial vehicle so that the unmanned aerial vehicle avoids the no-fly zone set based on the moving object position information."
Remotely controllable aeronautical ordnance,https://lens.org/171-811-703-669-246,2022,"REMOTELY CONTROLLABLE AERONAUTICAL ORDNANCE An ordnance for air-borne delivery to a target under remotely controlled in-flight navigation. In one embodiment, self - powered aerial ordnance includes upper and lower cases. A plurality of co axial, deployable blades is powered by a motor positioned in the upper case. When deployed, the blades are rotatable about the upper case to impart thrust and bring the vehicle to a first altitude above a target position. An explosive material and a camera are positioned in a lower case which is attached to the upper case. The camera generates a view along the ground plane and above the target when the ordinance is in flight. When the vehicle is deployed it is remotely controllable to deliver the vehicle to the target to detonate the explosive at the target. The ordnance may drop directly on a target as a bomb does. 24635109_1"
Remotely controllable aeronautical ordnance,https://lens.org/171-811-703-669-246,2022,"REMOTELY CONTROLLABLE AERONAUTICAL ORDNANCE An ordnance for air-borne delivery to a target under remotely controlled in-flight navigation. In one embodiment, self - powered aerial ordnance includes upper and lower cases. A plurality of co axial, deployable blades is powered by a motor positioned in the upper case. When deployed, the blades are rotatable about the upper case to impart thrust and bring the vehicle to a first altitude above a target position. An explosive material and a camera are positioned in a lower case which is attached to the upper case. The camera generates a view along the ground plane and above the target when the ordinance is in flight. When the vehicle is deployed it is remotely controllable to deliver the vehicle to the target to detonate the explosive at the target. The ordnance may drop directly on a target as a bomb does. 24635109_1"
TELEVISION SYSTEM MODULE WITH REMOTE CONTROL CODE DETERMINATION,https://lens.org/169-682-773-320-074,1994,"A video recorder (22), adapted for use in conjunction with a remotely controllable unit associated with television recording and/or viewing, contains a remote control signal transmitter (108) to transmit control codes to the associated unit, and means to analyze the operation of the associated unit in response to the control codes. An electronic controller causes the transmitter to transmit test codes to the associated unit, then analyzes the resulting operation of the associated unit to determine its control codes, which it stores in a memory for later use."
Communication assembly,https://lens.org/199-173-236-196-250,2016,A communication assembly includes a crane structured to elevate a platform coupled to the crane. A remote unit is held by a first user in the platform of the crane. A remote processor is coupled to the remote unit. A remote transceiver is coupled to the remote unit. A pair of sticks is coupled to the remote unit. The sticks are manipulated by the first user to issue a selected one of a plurality of movement commands with respect to the platform of the crane. A base unit is positioned within a cab of the crane. A base processor is coupled to the base unit. A base transceiver receives the movement commands from the pair of sticks. A display is coupled to the base unit and displays indicia relating to the movement commands. The second user manipulates the platform of the crane to correspond to the movement commands.
Communication Assembly,https://lens.org/008-052-516-579-451,2016,A communication assembly includes a crane structured to elevate a platform coupled to the crane. A remote unit is held by a first user in the platform of the crane. A remote processor is coupled to the remote unit. A remote transceiver is coupled to the remote unit. A pair of sticks is coupled to the remote unit. The sticks are manipulated by the first user to issue a selected one of a plurality of movement commands with respect to the platform of the crane. A base unit is positioned within a cab of the crane. A base processor is coupled to the base unit. A base transceiver receives the movement commands from the pair of sticks. A display is coupled to the base unit and displays indicia relating to the movement commands. The second user manipulates the platform of the crane to correspond to the movement commands.
INFORMATION PROCESSING SYSTEM,https://lens.org/182-903-563-201-541,2020,"The purpose of the present invention is to find a more meaningful method of use of an information processing system that includes a moving body such an unmanned aerial vehicle, by providing the moving body with new functions. One or more transceivers 2 in an information processing system to which the present invention is applied are provided with a communication unit 35 for transmitting transmission information. A drone 1 is provided with a third communication unit 204 for executing control to receive the transmission information transmitted from each of the one or more transceivers 2."
Autonomous operation control system,https://lens.org/035-386-776-476-095,2006,"A monitoring apparatus including a loudspeaker, a photographic camera that photographs image information on a photographic subject, a proximity sensor, and a monitoring control unit is disposed at a first remote location. An autonomous operation controller including an autonomous operation control unit is disposed at a second remote location remote from the first remote location. Under remote control of this autonomous remote controller, the monitoring apparatus performs photographing of the image information on the photographic subject and acquires the image information."
Autonomous operation control system,https://lens.org/025-821-940-171-260,2008,"A monitoring apparatus including a loudspeaker, a photographic camera that photographs image information on a photographic subject, a proximity sensor, and a monitoring control unit is disposed at a first remote location. An autonomous operation controller including an autonomous operation control unit is disposed at a second remote location remote from the first remote location. Under remote control of this autonomous remote controller, the monitoring apparatus performs photographing of the image information on the photographic subject and acquires the image information."
SYSTEMS AND METHODS FOR ASSISTING A MANEUVER OF A MOVING OBJECT,https://lens.org/156-761-276-978-856,2021,"A system for assisting a maneuver of a moving object is provided. The system includes a plurality of unmanned aerial vehicles, and a computing device comprising a controller configured to: identify a maneuver location of the moving object based on location information associated with the moving object, determine one or more unmanned aerial vehicles among the plurality of unmanned aerial vehicles based on a proximity of the maneuver location and the plurality of unmanned aerial vehicles, dispatch the one or more unmanned aerial vehicles to the maneuver location, and transmit an instruction signal to the one or more unmanned aerial vehicles, wherein the instruction signal causes the one or more unmanned aerial vehicles to generate an indication configured to assist one or more vehicles approaching the maneuver location."
SYSTEM AND METHOD FOR PROVIDING CONTEXTUAL FEEDBACK IN RESPONSE TO A COMMAND,https://lens.org/033-738-909-607-09X,2022,"A voice recognition system in an aircraft is provided. The voice recognition system includes: a voice recognition controller configured to receive a voice command from a flight crew member voice interface, convert the voice command to an avionics system command, and forward the avionics system command to an avionics system for execution. The voice recognition system further includes an application controller configured to: receive the avionics system command that has been converted from the voice command; determine whether the avionics system command can be performed; cause the avionics system command to be performed when it is determined that the avionics system command can be performed; and when it is determined that the avionics system command cannot be performed, generate a message that provides a reason why the avionics system command cannot be performed and cause the message to be displayed on a display device and/or annunciated on an aural device."
Adaptative wind turbine,https://lens.org/055-473-247-684-973,2020,"A drone with a horizontal rotor includes one or more rotor(s) (115, 116) which rotate in a horizontal plane, each rotor (115, 116) being equipped with one or more rigid or non-rigid blades (120, 121), the blade end being mounted on an electric motor (110, 111) with a propeller."
A DRONE,https://lens.org/147-518-789-218-856,2017,"A drone with a horizontal rotor includes one or more rotor(s) (115, 116) which rotate in a horizontal plane, each rotor (115, 116) being equipped with one or more rigid or non-rigid blades (120, 121), the blade end being mounted on an electric motor (110, 111) with a propeller."
Wireless device with remote control function,https://lens.org/105-483-317-906-49X,2004,"A wireless device with a remote control function. The wireless device comprises a wired I/O port, a switching circuit, a storage device, and a remote control circuit. The switching circuit, coupled with the wired I/O port, selectively operating in an audio mode or a data mode for inputing/outputing from the wired port. A set of control codes of an external electronic device is input into the storage device for storage through the wired I/O port in the data mode. When the wireless device is in a remote control mode, the remote control circuit reads out the set of control codes from the storage device and converts the set of control codes into a wireless signal to be transmitted through an antenna, and thereby the wireless device remotely controls the external electronic device in the remote control mode."
Methods and systems for utilizing voice commands onboard an aircraft,https://lens.org/145-611-329-846-871,2015,"Methods and systems are provided for utilizing audio commands onboard an aircraft. A method comprises identifying a flight phase for the aircraft, resulting in an identified flight phase, receiving an audio input, resulting in received audio input, filtering the received audio input in a manner that is influenced by the identified flight phase for the aircraft, resulting in filtered audio input, and validating the filtered audio input as a first voice command of a first plurality of possible voice commands."
METHODS AND SYSTEMS FOR UTILIZING VOICE COMMANDS ONBOARD AN AIRCRAFT,https://lens.org/100-446-512-965-01X,2013,"Methods and systems are provided for utilizing audio commands onboard an aircraft. A method comprises identifying a flight phase for the aircraft, resulting in an identified flight phase, receiving an audio input, resulting in received audio input, filtering the received audio input in a manner that is influenced by the identified flight phase for the aircraft, resulting in filtered audio input, and validating the filtered audio input as a first voice command of a first plurality of possible voice commands."
Methods and systems for utilizing voice commands onboard an aircraft,https://lens.org/152-965-207-700-104,2013,"Methods and systems are provided for utilizing audio commands onboard an aircraft. A method comprises identifying a flight phase for the aircraft, resulting in an identified flight phase, receiving an audio input, resulting in received audio input, filtering the received audio input in a manner that is influenced by the identified flight phase for the aircraft, resulting in filtered audio input, and validating the filtered audio input as a first voice command of a first plurality of possible voice commands."
METHODS AND SYSTEMS FOR UTILIZING VOICE COMMANDS ONBOARD AN AIRCRAFT,https://lens.org/124-147-280-265-428,2011,"Methods and systems are provided for utilizing audio commands onboard an aircraft. A method comprises identifying a flight phase for the aircraft, resulting in an identified flight phase, receiving an audio input, resulting in received audio input, filtering the received audio input in a manner that is influenced by the identified flight phase for the aircraft, resulting in filtered audio input, and validating the filtered audio input as a first voice command of a first plurality of possible voice commands."
"METHOD FOR CONTROLLING AIRCRAFT, DEVICE, AND AIRCRAFT",https://lens.org/037-258-855-661-922,2020,"A method for controlling an aircraft includes determining photographing information related to a photographing object, the photographing information indicating an occupying scope of the photographing object in an image to be captured. The method also includes controlling the aircraft to fly to a photographing location based on the photographing information."
"Method for controlling aircraft, device, and aircraft",https://lens.org/037-132-347-926-126,2021,"A method for controlling an aircraft includes determining photographing information related to a photographing object, the photographing information indicating an occupying scope of the photographing object in an image to be captured. The method also includes controlling the aircraft to fly to a photographing location based on the photographing information."
VIDEO SURVEILLANCE SYSTEM WITH AERIAL CAMERA DEVICE,https://lens.org/184-038-154-719-971,2019,"A video surveillance system having a plurality of aerial camera devices such as cameras on drones operable from a plurality of docking stations. Each station has a dock for receiving, charging, and controlling the aerial camera devices."
Video surveillance system with aerial camera device,https://lens.org/089-738-501-471-901,2020,"A video surveillance system having a plurality of aerial camera devices such as cameras on drones operable from a plurality of docking stations. Each station has a dock for receiving, charging, and controlling the aerial camera devices."
COMPUTER-ASSISTED CAMERA AND CONTROL SYSTEM,https://lens.org/183-241-226-085-793,2021,"A lightweight portable microprocessor-assisted remote control camera system provides precise repeatable camera movement through the improved stability of a 3-axis gimbal design, which allows a lightweight large sensor camera to be placed almost anywhere and smoothly controlled remotely via a simple touchscreen interface. The computer control module provides a wide range of control options including remote adjustment of all camera, lens and gimbal parameters, which can be programmed, set and recalled, including stabilization and motion smoothing, via the touchscreen interface."
Systems and methods for tuning propeller noise,https://lens.org/072-356-042-185-533,2022,"The present disclosure relates to devices, systems, and methods for controlling and/or augmenting acoustic sounds emitted from flight vehicles, such as unmanned aerial vehicles (UAVs). For example, while in flight, a UAV may emit a characteristic sound or tone (or a plurality of such tones), which may be a result of propeller and/or motor noise. To mitigate such noise from UAVs, disclosed embodiments may include acoustic resonators that may provide additional tones to complement the sounds or tones emitted from the UAV. Namely, the acoustic resonators may be shaped, adjusted, or otherwise controlled to emit additional tones that form pleasing intervals in combination with the characteristic tone(s) from the UAV."
Systems and Methods for Tuning Propeller Noise,https://lens.org/113-880-643-758-84X,2020,"The present disclosure relates to devices, systems, and methods for controlling and/or augmenting acoustic sounds emitted from flight vehicles, such as unmanned aerial vehicles (UAVs). For example, while in flight, a UAV may emit a characteristic sound or tone (or a plurality of such tones), which may be a result of propeller and/or motor noise. To mitigate such noise from UAVs, disclosed embodiments may include acoustic resonators that may provide additional tones to complement the sounds or tones emitted from the UAV. Namely, the acoustic resonators may be shaped, adjusted, or otherwise controlled to emit additional tones that form pleasing intervals in combination with the characteristic tone(s) from the UAV."
Systems and methods for tuning propeller noise,https://lens.org/026-688-502-463-323,2020,"The present disclosure relates to devices, systems, and methods for controlling and/or augmenting acoustic sounds emitted from flight vehicles, such as unmanned aerial vehicles (UAVs). For example, while in flight, a UAV may emit a characteristic sound or tone (or a plurality of such tones), which may be a result of propeller and/or motor noise. To mitigate such noise from UAVs, disclosed embodiments may include acoustic resonators that may provide additional tones to complement the sounds or tones emitted from the UAV. Namely, the acoustic resonators may be shaped, adjusted, or otherwise controlled to emit additional tones that form pleasing intervals in combination with the characteristic tone(s) from the UAV."
"SERVER FOR DETERMINING TARGET DEVICE BASED ON SPEECH INPUT OF USER AND CONTROLLING TARGET DEVICE, AND OPERATION METHOD OF THE SERVER",https://lens.org/037-813-976-123-960,2020,"A server for controlling a device based on a speech input of a user and an operation method of the server are provided. The server is configured to determine a type of a target device related to a speech input of a user received from a client device in a network environment including a plurality of devices, determine the target device based on the determined type and device information of the plurality of devices, and obtain operation information for the determined target device to perform an operation."
Flying device with improved movement on the ground,https://lens.org/027-529-273-525-516,2011,"The invention relates to a flying device which can efficiently move in the air by aerodynamic forces and by direct force transmission on the ground, without the need for independent drive and thrust generation systems for the two modes of movement. The rotors (1) of the flying device are provided on the outside thereof with an annular rotating covering (4), connected directly to the rotor blade tips, which, when the flying device is on the ground and the rotor rotational axes (2) are correspondingly pitched about an axis (3), come into contact with the ground. The covering (4) hence permits a movement of the flying device on the ground by rolling, which is based on a direct force transfer to the ground. A further rotor pitching axis (5) permits the flying device to be controlled in the air and on the ground by means of the same actuator system. The above flying principle permits, for example, remote controlled reconnaissance drones for close or remote espionage, to independently enter inaccessible regions, or in the context of police or military application in buildings presenting danger for personnel, to gain access to upper floors."
UNMANNED AERIAL VEHICLE CONTROL METHOD AND UNMANNED AERIAL VEHICLE,https://lens.org/099-835-894-237-231,2022,"A method for controlling an unmanned aerial vehicle includes obtaining flight status information of a target aircraft, determining a relative direction of the target aircraft relative to the unmanned aerial vehicle according to the flight status information of the target aircraft, and communicatively connecting an automatic dependent surveillance broadcast (ADS-B) device of the unmanned aerial vehicle to a target antenna selected from a plurality of antennas of the unmanned aerial vehicle according to the relative direction and radiation patterns of the plurality of antennas, so that the ADS-B device obtains and analyzes an ADS-B signal from the target aircraft received by the target antenna. The radiation patterns of the plurality of antennas are different from each other."
UNMANNED AERIAL VEHICLE CONTROL METHOD AND UNMANNED AERIAL VEHICLE,https://lens.org/099-835-894-237-231,2022,"A method for controlling an unmanned aerial vehicle includes obtaining flight status information of a target aircraft, determining a relative direction of the target aircraft relative to the unmanned aerial vehicle according to the flight status information of the target aircraft, and communicatively connecting an automatic dependent surveillance broadcast (ADS-B) device of the unmanned aerial vehicle to a target antenna selected from a plurality of antennas of the unmanned aerial vehicle according to the relative direction and radiation patterns of the plurality of antennas, so that the ADS-B device obtains and analyzes an ADS-B signal from the target aircraft received by the target antenna. The radiation patterns of the plurality of antennas are different from each other."
Universal camera tripod head adapter having pan and tilt encoders,https://lens.org/071-463-901-797-309,2020,"A direct drive servo motor is provided and may include a quadrature encoder and a silicone rubber sleeve affixed to the encoder's shaft that is attached to the rotor hub and may also include an axle fixed to the rotor hub, inner and outer bearings, front and rear bearing plates, an outer stator, and an inner rotor rare earth magnet ring. A computer-controlled camera system is also provided and includes a direct drive camera gimbal; a pan-bar system; a robotic control system; a master interconnect unit; custom control software; and a track and gantry system. A universal camera tripod head adapter is also provided and includes front and rear clamps, a clamp handle, side and rear brackets and a silicone rubber sleeve affixed to the shaft of each encoder that rides on the pan and tilt axis lips of a camera tripod head."
ROBOTIC CAMERA SYSTEMS,https://lens.org/164-064-668-155-089,2019,"A direct drive servo motor is provided and may include a quadrature encoder and a silicone rubber sleeve affixed to the encoder's shaft that is attached to the rotor hub and may also include an axle fixed to the rotor hub, inner and outer bearings, front and rear bearing plates, an outer stator, and an inner rotor rare earth magnet ring. A computer-controlled camera system is also provided and includes a direct drive camera gimbal; a pan-bar system; a robotic control system; a master interconnect unit; custom control software; and a track and gantry system. A universal camera tripod head adapter is also provided and includes front and rear clamps, a clamp handle, side and rear brackets and a silicone rubber sleeve affixed to the shaft of each encoder that rides on the pan and tilt axis lips of a camera tripod head."
ROBOTIC CAMERA SYSTEMS,https://lens.org/134-885-069-358-95X,2017,"A direct drive servo motor is provided and may include a quadrature encoder and a silicone rubber sleeve affixed to the encoder's shaft that is attached to the rotor hub and may also include an axle fixed to the rotor hub, inner and outer bearings, front and rear bearing plates, an outer stator, and an inner rotor rare earth magnet ring. A computer-controlled camera system is also provided and includes a direct drive camera gimbal; a pan-bar system; a robotic control system; a master interconnect unit; custom control software; and a track and gantry system. A universal camera tripod head adapter is also provided and includes front and rear clamps, a clamp handle, side and rear brackets and a silicone rubber sleeve affixed to the shaft of each encoder that rides on the pan and tilt axis lips of a camera tripod head."
Motor with encoder for robotic camera systems,https://lens.org/136-850-761-640-030,2019,"A direct drive servo motor is provided and may include a quadrature encoder and a silicone rubber sleeve affixed to the encoder's shaft that is attached to the rotor hub and may also include an axle fixed to the rotor hub, inner and outer bearings, front and rear bearing plates, an outer stator, and an inner rotor rare earth magnet ring. A computer-controlled camera system is also provided and includes a direct drive camera gimbal; a pan-bar system; a robotic control system; a master interconnect unit; custom control software; and a track and gantry system. A universal camera tripod head adapter is also provided and includes front and rear clamps, a clamp handle, side and rear brackets and a silicone rubber sleeve affixed to the shaft of each encoder that rides on the pan and tilt axis lips of a camera tripod head."
Guidance and control for an autonomous soaring UAV,https://lens.org/100-555-355-993-748,2008,"The present invention provides a practical method for UAVs to take advantage of thermals in a manner similar to piloted aircrafts and soaring birds. In general, the invention is a method for a UAV to autonomously locate a thermal and be guided to the thermal to greatly improve range and endurance of the aircraft."
UNMANNED AERIAL VEHICLE WITH PROTECTIVE OUTER CAGE,https://lens.org/100-431-213-618-032,2019,"Unmanned aerial vehicle (UAV) (1) including an inner frame (2), an inner flight propulsion system (4) mounted on the inner frame (2), an outer frame (8), a gimbal system (6) comprising at least two rotational couplings (26, 30) coupling the inner propulsion system to the outer frame, a control system (14), a power source (12), and an outer frame actuation system (10) configured to actively orient the outer frame with respect to the inner frame."
METHODS AND SYSTEM FOR AUTONOMOUS LANDING,https://lens.org/106-927-452-147-810,2018,Techniques are provided for autonomously landing an unmanned aerial vehicle (UAV). A target marker can be detected based on a plurality of images captured by an imaging devices carried by the UAV. A spatial relationship can be determined between the UAV and the target marker based on the plurality of images. The UAV can be controlled to approach the target marker based on the spatial relationship while the imaging device is controlled to track the target marker.
METHODS AND SYSTEM FOR AUTONOMOUS LANDING,https://lens.org/120-042-377-376-611,2021,Techniques are provided for autonomously landing an unmanned aerial vehicle (UAV). A target marker can be detected based on a plurality of images captured by an imaging devices carried by the UAV. A spatial relationship can be determined between the UAV and the target marker based on the plurality of images. The UAV can be controlled to approach the target marker based on the spatial relationship while the imaging device is controlled to track the target marker.
SYSTEMS AND METHODS TO ENABLE OR DISABLE AUTONOMOUS DRIVING,https://lens.org/032-895-502-184-438,2017,"An autonomous driving system for a vehicle is provided. The system includes a location unit configured to determine a current location of the vehicle; a database storing mapping information; and a control unit coupled to the location unit and the database, the control unit configured to selectively generate autonomous driving commands for the current location in view of the mapping information."
Systems and methods to enable or disable autonomous driving,https://lens.org/029-998-431-200-923,2018,"An autonomous driving system for a vehicle is provided. The system includes a location unit configured to determine a current location of the vehicle; a database storing mapping information; and a control unit coupled to the location unit and the database, the control unit configured to selectively generate autonomous driving commands for the current location in view of the mapping information."
UNMANNED AIRCRAFT WITH FAILSAFE SYSTEM,https://lens.org/036-826-533-789-954,2015,An unmanned aircraft comprises: a drive system to thrust the unmanned aircraft during a flight; a reverse thrust system to reverse thrust the unmanned aircraft during a landing; a controller operationally coupled to the reverse thrust system; and a detector to detect and notify to the controller that the unmanned aircraft is in an uncontrolled situation during the flight. The controller is then adapted to activate the reverse thrust system in order to reverse thrust the unmanned aircraft in-flight upon notification from the detector that the unmanned aircraft is in an uncontrolled situation.
ROBOTIC NAVIGATION SYSTEM AND METHOD,https://lens.org/173-486-304-349-727,2017,A robotic navigation system includes a handheld navigation unit associated with a frame of reference. The handheld navigation unit is moveable with respect to a plurality of axes and is configured to send movement signals based on movement of the handheld navigation unit. A controller is configured to receive the movement signals from the handheld navigation unit and determine control signals for the robot. The control signals are configured to incrementally move the robot with respect to a point of interest removed from the robot. The point of interest is removed from a fixed point on the robot as defined by assigned coordinates. The controller is further configured to reassign the assigned coordinates following each incremental movement of the robot.
ROBOTIC NAVIGATION SYSTEM AND METHOD,https://lens.org/125-651-355-973-867,2021,A robotic navigation system includes a handheld navigation unit associated with a frame of reference. The handheld navigation unit is moveable with respect to a plurality of axes and is configured to send movement signals based on movement of the handheld navigation unit. A controller is configured to receive the movement signals from the handheld navigation unit and determine control signals for the robot. The control signals are configured to incrementally move the robot with respect to a point of interest removed from the robot. The point of interest is removed from a fixed point on the robot as defined by assigned coordinates. The controller is further configured to reassign the assigned coordinates following each incremental movement of the robot.
ROBOTIC NAVIGATION SYSTEM AND METHOD,https://lens.org/094-083-611-172-749,2020,A robotic navigation system includes a handheld navigation unit associated with a frame of reference. The handheld navigation unit is moveable with respect to a plurality of axes and is configured to send movement signals based on movement of the handheld navigation unit. A controller is configured to receive the movement signals from the handheld navigation unit and determine control signals for the robot. The control signals are configured to incrementally move the robot with respect to a point of interest removed from the robot. The point of interest is removed from a fixed point on the robot as defined by assigned coordinates. The controller is further configured to reassign the assigned coordinates following each incremental movement of the robot.
ROBOTIC NAVIGATION SYSTEM AND METHOD,https://lens.org/094-083-611-172-749,2020,A robotic navigation system includes a handheld navigation unit associated with a frame of reference. The handheld navigation unit is moveable with respect to a plurality of axes and is configured to send movement signals based on movement of the handheld navigation unit. A controller is configured to receive the movement signals from the handheld navigation unit and determine control signals for the robot. The control signals are configured to incrementally move the robot with respect to a point of interest removed from the robot. The point of interest is removed from a fixed point on the robot as defined by assigned coordinates. The controller is further configured to reassign the assigned coordinates following each incremental movement of the robot.
ROBOTIC NAVIGATION SYSTEM AND METHOD,https://lens.org/144-850-927-400-820,2018,A robotic navigation system includes a handheld navigation unit associated with a frame of reference. The handheld navigation unit is moveable with respect to a plurality of axes and is configured to send movement signals based on movement of the handheld navigation unit. A controller is configured to receive the movement signals from the handheld navigation unit and determine control signals for the robot. The control signals are configured to incrementally move the robot with respect to a point of interest removed from the robot. The point of interest is removed from a fixed point on the robot as defined by assigned coordinates. The controller is further configured to reassign the assigned coordinates following each incremental movement of the robot.
ROBOT,https://lens.org/164-447-885-756-452,2022,"A robot includes: a communication unit that receives a remote operation instruction by a user terminal of a user; a body unit capable of traveling; a head unit attached to the body unit and capable of changing a direction; a camera; a control unit that controls the body unit, the head unit, and the camera, based on the operation instruction; and an operation switching input unit that switches between the operation instruction by the user terminal of the user and an operation instruction by a facility terminal of a facility user, and when switching the operation instruction, the operation switching input unit requests the user for whether to approve user switching, and when the user approves the user switching of the operation instruction via the user terminal, the operation switching input unit switches the operation instruction by the user terminal to the operation instruction by the facility terminal."
REMOTE WORKSITE MONITORING SYSTEM,https://lens.org/110-430-830-158-594,2017,"A remote worksite monitoring system is provided. The remote worksite monitoring system includes a machine operating at a worksite, The remote worksite monitoring system also includes an Unmanned Aerial Vehicle (UAV) associated with the machine. The UAV includes a control module and a sensor module. The UAV is adapted to fly to a location proximate to an area at which the machine is present. The UAV is adapted to directly communicate with the machine over a first communication network to at least one of receive machine data from the machine and transfer data to the machine when direct communication between the machine and a remote control station cannot be established. Further, the UAV is adapted to transmit the machine data received from the machine to the remote control station over a second communication network."
Appliance Remote Control,https://lens.org/021-662-343-951-612,2022,"An apparatus embodiment includes a remote control interface unit configured to accept an appliance control code carried in a radio frequency signal transmitted from a smart phone, extract the appliance control code from the radio frequency signal, send the extracted appliance control code to an optical frequency interface, and initiate transmission of an optical frequency signal including the appliance control code to an appliance configured to receive signals from an optical remote control."
Methods and entities for alerting about failure of an unmanned aerial vehicle,https://lens.org/193-737-902-385-380,2023,"A method performed in an unmanned aerial vehicle is provided for alerting about failure of the unmanned aerial vehicle. The method comprises identifying a malfunctioning in the unmanned aerial vehicle, and transmitting to a network node, a failure report comprising the malfunctioning and/or position of the unmanned aerial vehicle. Methods in a network node, and an unmanned aerial vehicle are also provided."
Unmanned aerial vehicle,https://lens.org/165-726-105-599-846,2020,"An unmanned aerial vehicle (UAV) is provided, which includes a main body; a plurality of frames each extending from the main body; and a plurality of thrust generating devices respectively mounted on the plurality of frames, each of the thrust generating devices including a propeller. The propeller includes a hub that provides a rotation axis of the propeller, and rotates according to an operation of the thrust generating device, and a pair of blades, each of which is pivotably mounted on the hub, and generates a thrust or lift while rotating around the rotation axis as the hub is rotated. The blades are pivotably interlocked with each other such that the blades are aligned to a folded position in which the blades are parallel with each other on the hub in a first arrangement or aligned to an expanded position in a diametric direction of a rotating region of the propeller in a second arrangement."
Unmanned aerial vehicle,https://lens.org/165-726-105-599-846,2020,"An unmanned aerial vehicle (UAV) is provided, which includes a main body; a plurality of frames each extending from the main body; and a plurality of thrust generating devices respectively mounted on the plurality of frames, each of the thrust generating devices including a propeller. The propeller includes a hub that provides a rotation axis of the propeller, and rotates according to an operation of the thrust generating device, and a pair of blades, each of which is pivotably mounted on the hub, and generates a thrust or lift while rotating around the rotation axis as the hub is rotated. The blades are pivotably interlocked with each other such that the blades are aligned to a folded position in which the blades are parallel with each other on the hub in a first arrangement or aligned to an expanded position in a diametric direction of a rotating region of the propeller in a second arrangement."
UNMANNED AERIAL VEHICLE,https://lens.org/011-385-979-839-356,2017,"An unmanned aerial vehicle (UAV) is provided, which includes a main body; a plurality of frames each extending from the main body; and a plurality of thrust generating devices respectively mounted on the plurality of frames, each of the thrust generating devices including a propeller. The propeller includes a hub that provides a rotation axis of the propeller, and rotates according to an operation of the thrust generating device, and a pair of blades, each of which is pivotably mounted on the hub, and generates a thrust or lift while rotating around the rotation axis as the hub is rotated. The blades are pivotably interlocked with each other such that the blades are aligned to a folded position in which the blades are parallel with each other on the hub in a first arrangement or aligned to an expanded position in a diametric direction of a rotating region of the propeller in a second arrangement."
A REMOTE CONTROLLED DEVICE AND A REMOTE CONTROL FOR CONTROLLING MULTPLE REMOTE CONTROLLED DEVICES,https://lens.org/137-462-641-616-644,2018,"By transmitting a remote controlled device identifier through an optical signal emitted by a remote controlled device to a remote control pointed at the remote controlled device, the remote control is able to address the remote controlled device via a communication network and be paired with the remote controlled device. As the remote control just has to be pointed at the remote controlled device that is to be paired the pairing is intuitive. A verification unit can be added to the remote controlled device that transmits a challenge via the optical signal to the remote control. The remote control creates a response and transmits the response to the remote controlled device for verification by the verification unit. If the verification is successful the pairing is allowed. As the challenge can only be extracted from the optical signal, access to the room in which the remote controlled device is locate dis required in order to gain control over the remote controlled device. A hack solely over the communication network is prevented as the challenge is not available on the communication network."
A REMOTE CONTROLLED DEVICE AND A REMOTE CONTROL FOR CONTROLLING MULTIPLE REMOTE CONTROLLED DEVICES,https://lens.org/008-576-194-238-052,2016,"By transmitting a remote controlled device identifier through an optical signal emitted by a remote controlled device to a remote control pointed at the remote controlled device, the remote control is able to address the remote controlled device via a communication network and be paired with the remote controlled device. As the remote control just has to be pointed at the remote controlled device that is to be paired the pairing is intuitive. A verification unit can be added to the remote controlled device that transmits a challenge via the optical signal to the remote control. The remote control creates a response and transmits the response to the remote controlled device for verification by the verification unit. If the verification is successful the pairing is allowed. As the challenge can only be extracted from the optical signal, access to the room in which the remote controlled device is locate dis required in order to gain control over the remote controlled device. A hack solely over the communication network is prevented as the challenge is not available on the communication network."
Remote controlled device and a remote control for controlling multiple remote controlled devices,https://lens.org/088-314-160-644-118,2018,"By transmitting a remote controlled device identifier through an optical signal emitted by a remote controlled device to a remote control pointed at the remote controlled device, the remote control is able to address the remote controlled device via a communication network and be paired with the remote controlled device. As the remote control just has to be pointed at the remote controlled device that is to be paired the pairing is intuitive. A verification unit can be added to the remote controlled device that transmits a challenge via the optical signal to the remote control. The remote control creates a response and transmits the response to the remote controlled device for verification by the verification unit. If the verification is successful the pairing is allowed. As the challenge can only be extracted from the optical signal, access to the room in which the remote controlled device is locate dis required in order to gain control over the remote controlled device. A hack solely over the communication network is prevented as the challenge is not available on the communication network."
TEMPORARY CONTROL OF COMPONENTS USING LOCATION BASED GRANTS,https://lens.org/129-341-013-106-28X,2017,"A device, system, and method gives temporary control of a user device using location based grants. The method performed by a control server of a third party is performed when the user device is in a predetermined area. The method includes transmitting authentication data to the user device, the authentication data configured to authenticate the third party to the user device, the predetermined area being associated with the third party. The method includes receiving a request from the user device for command data, the command data configured to be executed on the user device to provide the third party with a limited control over the user device while the user device remains in the predetermined area. The method includes transmitting the command data to the user device."
Temporary control of components using location based grants,https://lens.org/166-046-609-822-471,2022,"A device, system, and method gives temporary control of a user device using location based grants. The method performed by a control server of a third party is performed when the user device is in a predetermined area. The method includes transmitting authentication data to the user device, the authentication data configured to authenticate the third party to the user device, the predetermined area being associated with the third party. The method includes receiving a request from the user device for command data, the command data configured to be executed on the user device to provide the third party with a limited control over the user device while the user device remains in the predetermined area. The method includes transmitting the command data to the user device."
ALARM AND MONITORING SYSTEM AND METHOD OF OPERATION THEROF,https://lens.org/103-077-055-026-540,2016,"An alarm and monitoring system including a primary device and at least one secondary device, the alarm and monitoring system including at least one controller configured to: determine whether at least one alarm event is set; establish a wireless communication between a primary device and the secondary device, when it is determined that the alarm event has been set; transmit an alarm event signal including alarm information from the primary device to the secondary device in accordance with the alarm event that is determined to have been set; generate an alarm signal by the secondary device in accordance with at least the alarm information; and render the generated alarm signal on a rendering device. The controller being configured to generate and send an actuator control signal to an actuator to adjust a condition to a predetermined state."
Alarm and monitoring system and method of operation thereof,https://lens.org/072-954-248-056-622,2018,"An alarm and monitoring system including a primary device and at least one secondary device, the alarm and monitoring system including at least one controller configured to: determine whether at least one alarm event is set; establish a wireless communication between a primary device and the secondary device, when it is determined that the alarm event has been set; transmit an alarm event signal including alarm information from the primary device to the secondary device in accordance with the alarm event that is determined to have been set; generate an alarm signal by the secondary device in accordance with at least the alarm information; and render the generated alarm signal on a rendering device. The controller being configured to generate and send an actuator control signal to an actuator to adjust a condition to a predetermined state."
PORTABLE COUNTERMEASURE DEVICE AGAINST UNMANNED SYSTEMS,https://lens.org/011-111-051-372-551,2018,"A portable countermeasure device is provided comprising one or more directional antennae, one or more disruption components and at least one activator. The portable countermeasure device further comprises a body, with the directional antennae are affixed to a front portion of the body. The one or more disruption components may be externally mounted to the device body. The portable countermeasure device is aimed at a specific drone, the activator is engaged, and disruptive signals are directed toward the drone, disrupting the control, navigation, and other signals to and from the drone. FIG. 2 for publication (NI 0 (N V (N 0 (N nun nun 04 U (9 (N - - i."
Autonomous takeoff and landing with open loop mode and closed loop mode,https://lens.org/170-025-882-134-874,2019,"Autonomous flight is performed in an open loop mode over a first range of altitudes, wherein a plurality altitude-related data from a plurality of altitude-related sensors is ignored while performing the autonomous flight in the open loop mode. The autonomous flight is performed in a closed loop mode over a second range of altitudes, wherein: the plurality of altitude-related data from the plurality of altitude-related sensors is used while performing the autonomous flight in the closed loop mode, and the first range of altitudes is a non-overlapping, lower range of altitudes compared to the second range of altitudes. The altitude-related data may include, among other things, a radar signal or a phase associated with a radar signal."
Systems and methods for autonomous landing using a three dimensional evidence grid,https://lens.org/000-683-505-125-032,2015,"A method for autonomous landing of an unmanned aerial vehicle (UAV) comprising: obtaining sensor data corresponding to one or more objects outside of the aircraft using at least one onboard sensor; using the sensor data to create a three dimensional evidence grid, wherein a three dimensional evidence grid is a three dimensional world model based on the sensor data; combining a priori data with the three dimensional evidence grid; locating a landing zone based on the combined three dimensional evidence grid and a priori data; validating an open spots in the landing zone, wherein validating includes performing surface condition assessment of a surface of the open spots; generating landing zone motion characterization, wherein landing zone motion characterization includes characterizing real time landing zone pitching, heaving, rolling or forward motion; processing the three dimensional evidence grid data to generate flight controls to land the aircraft in one of the open spots; and controlling the aircraft according to the flight controls to land the aircraft."
System and method for UAV landing,https://lens.org/080-724-176-122-120,2014,"A method for autonomous landing of an unmanned aerial vehicle (UAV) comprising: obtaining sensor data corresponding to one or more objects outside of the aircraft using at least one onboard sensor; using the sensor data to create a three dimensional evidence grid, wherein a three dimensional evidence grid is a three dimensional world model based on the sensor data; combining a priori data with the three dimensional evidence grid; locating a landing zone based on the combined three dimensional evidence grid and a priori data; validating an open spots in the landing zone, wherein validating includes performing surface condition assessment of a surface of the open spots; generating landing zone motion characterization, wherein landing zone motion characterization includes characterizing real time landing zone pitching, heaving, rolling or forward motion; processing the three dimensional evidence grid data to generate flight controls to land the aircraft in one of the open spots; and controlling the aircraft according to the flight controls to land the aircraft."
UNMANNED AERIAL SYSTEM COMMUNICATION,https://lens.org/189-355-880-050-02X,2021,An unmanned aerial vehicle and control method thereof are provided. A position of the unmanned aerial vehicle is determined. One or more airspace rules corresponding to the position of the unmanned aerial vehicle are identified. An operator of the unmanned aerial vehicle is notified of a potential violation of the one or more airspace rules.
METHOD FOR USING A REMOTE CONTROL FOR A PAYMENT TRANSACTION AND ASSOCIATED DEVICE,https://lens.org/015-779-017-299-499,2013,"Remote control device of a data receiver, the data being representative of an audiovisual content, the data receiver receiving information relating to payment of an object and data representative of the object, the remote control device comprising means of configuring the data receiver useful for processing data representative of an audiovisual content, remote control device being characterised in that it comprises a user interface for initialising a payment transaction, a first wireless interface for receiving information useful for payment of the object and a second wireless interface for transmitting payment information with a remote payment unit."
ENTERTAINMENT ENVIRONMENT REMOTE CONTROL AND AUDIO/VIDEO STREAMING METHOD AND SYSTEM,https://lens.org/023-996-142-208-673,2015,"A remote control and streaming interface for an entertainment environment. The system includes an infrared (IR) transmitter panel holding a plurality of IR LEDs formed in an LED array. The system also includes at least one transceiver configured to maintain a bidirectional administration link with a smart handheld device and configured to maintain a separate streaming link with the smart handheld device. The system includes a processor configured to identify remote control (RC) commands received over the administration link, the processor configured to direct the LED array to generate an IR signal having a select IR pulse sequence based on the RC commands."
Portable system including motorized base controller and transmitter for tracking a moving target,https://lens.org/108-185-831-081-893,2023,"A system including a motorized base unit with a smart device mount for automatically orienting the smart device camera toward a moving target to track the moving target and take pictures or video. The target (e.g., a child playing soccer) wears a tracking tag comprising a GPS chip and transmitter packaged inside an athletic pad. The base unit includes a motorized mast for mounting a smart device. The base unit receives the transmitted GPS data, calculates updated pointing angle and angular velocity for the smart phone based on update location information from the remote tag sensor, calculates the correct angle that the smart phone should be pointed at, translates the new pointing directions to a control signal that turns the mast, which in turn causes the smart device camera to follow or track the target."
PORTABLE SYSTEM INCLUDING MOTORIZED BASE CONTROLLER AND TRANSMITTER FOR TRACKING A MOVING TARGET,https://lens.org/159-829-434-080-02X,2021,"A system including a motorized base unit with a smart device mount for automatically orienting the smart device camera toward a moving target to track the moving target and take pictures or video. The target (e.g., a child playing soccer) wears a tracking tag comprising a GPS chip and transmitter packaged inside an athletic pad. The base unit includes a motorized mast for mounting a smart device. The base unit receives the transmitted GPS data, calculates updated pointing angle and angular velocity for the smart phone based on update location information from the remote tag sensor, calculates the correct angle that the smart phone should be pointed at, translates the new pointing directions to a control signal that turns the mast, which in turn causes the smart device camera to follow or track the target."
Payload module for stratospheric drone,https://lens.org/146-153-627-687-339,2021,"A payload module (1) of a stratospheric drone including: a casing (10), and a piece of optical equipment (20) comprising an optical axis, mounted in the casing, wherein the module being includes a mirror (40) positioned on the optical axis facing the optical equipment, the mirror being swivelable about at least one axis, within an angular range, wherein the casing has a through-opening (11) shaped so that any light ray received or emitted by the optical equipment parallel to the optical axis and reflected by the mirror passes through the through-opening, over the entire angular range of the mirror."
PAYLOAD MODULE FOR STRATOSPHERIC DRONE,https://lens.org/087-844-936-131-697,2020,"A payload module (1) of a stratospheric drone including: a casing (10), and a piece of optical equipment (20) comprising an optical axis, mounted in the casing, wherein the module being includes a mirror (40) positioned on the optical axis facing the optical equipment, the mirror being swivelable about at least one axis, within an angular range, wherein the casing has a through-opening (11) shaped so that any light ray received or emitted by the optical equipment parallel to the optical axis and reflected by the mirror passes through the through-opening, over the entire angular range of the mirror."
Shape-shifting control surface for an autonomous vehicle,https://lens.org/102-392-332-638-566,2023,"A system for interactions with an autonomous vehicle includes a proprioceptive device; and a controller. The controller is configured to: detect a first condition external to the autonomous vehicle; generate a first proprioceptive output in response to the first condition, the first proprioceptive output changing a shape of the proprioceptive device; receive a first input force from the proprioceptive device; determine a first user input based on the first input force; and, based on the first user input, cause the autonomous vehicle to perform a navigation action."
SHAPE-SHIFTING CONTROL SURFACE FOR AN AUTONOMOUS VEHICLE,https://lens.org/095-326-411-159-398,2020,"A system for interactions with an autonomous vehicle includes a proprioceptive device; and a controller. The controller is configured to: detect a first condition external to the autonomous vehicle; generate a first proprioceptive output in response to the first condition, the first proprioceptive output changing a shape of the proprioceptive device; receive a first input force from the proprioceptive device; determine a first user input based on the first input force; and, based on the first user input, cause the autonomous vehicle to perform a navigation action."
SHAPE-SHIFTING CONTROL SURFACE FOR AN AUTONOMOUS VEHICLE,https://lens.org/187-996-340-578-306,2020,"A system for interactions with an autonomous vehicle includes a proprioceptive device; and a controller. The controller is configured to: detect a first condition external to the autonomous vehicle; generate a first proprioceptive output in response to the first condition, the first proprioceptive output changing a shape of the proprioceptive device; receive a first input force from the proprioceptive device; determine a first user input based on the first input force; and, based on the first user input, cause the autonomous vehicle to perform a navigation action."
VOLUME ADJUSTMENT MODEL DEVELOPMENT,https://lens.org/153-037-113-760-717,2020,"Controlling the volume of a Virtual Personal Assistant (VPA) by receiving radio frequency (RF) data associated with a user, identifying a location of a user relative to the VPA, creating a volume adjustment model using the data and VPA data, tracking movement of the user based on the data, and adjusting a volume of the VPA according to the volume adjustment model."
Volume adjustment model development,https://lens.org/052-500-995-307-833,2021,"Controlling the volume of a Virtual Personal Assistant (VPA) by receiving radio frequency (RF) data associated with a user, identifying a location of a user relative to the VPA, creating a volume adjustment model using the data and VPA data, tracking movement of the user based on the data, and adjusting a volume of the VPA according to the volume adjustment model."
AN UNMANNED AERIAL VEHICLE (UAV) FOR COLLECTING AUDIO DATA,https://lens.org/108-201-722-972-985,2016,"A UAV (110) is provided to cancel background noise from audio data collected by the UAV (110). The UAV (110) is provided with one or more background microphones (140) in proximity of one or more background noise-producing components (150a, 150b, 150c, 150d). The UAV (110) is also provided with one or more audio source collecting microphones (140). The audio data collected by the background microphones (140) may be used to reduce or cancel interfering background noise from the audio signal detected by the audio source collecting microphone (140). The target audio may be captured or recorded with little or no background noise."
SYSTEM FOR PERFORMING MULTIPLE POSSIBLE COMPLEX TASKS ON WORK SITES USING UNMANNED AERIAL DEVICES,https://lens.org/126-670-220-954-212,2021,"The present disclosure relates to a system that comprises: a control station intended to be operated; an unmanned aerial vehicle for multiple tasks (UAM) which is supported, by unmanned aerial devices (UAV), unmanned ground vehicle (UGV), and by a centralised mobile reel unit which feeds cables and hoses for supplying multiple additive and subtractive fluids (e.g. paint, air suction, etc.) and for charging power; wherein the cables and hoses comprise a device that makes it possible to predict trajectories, without interfering with flight maneuvers or the environment. The UAM comprises a robotic arm with specific tools that make it possible, for example, to paint fences, as well as a device that allows it to be attached to various surfaces."
"METHOD, APPARATUS, AND SYSTEM FOR DRONE DELIVERY USING BEACON POSITIONING",https://lens.org/014-692-415-353-712,2022,"An approach is provided for drone delivery using beacon positioning. The approach, for example, involves determining, at a drone, a cell where a target beacon associated with a domain is located. The approach also involves, upon reaching the cell, transmitting a destination identifier associated with the target beacon from the drone to a domain beacon of the domain in the cell. The approach further involves receiving, by the drone, a guiding signal from the domain beacon to reach the target beacon."
"METHOD, APPARATUS, AND SYSTEM FOR DRONE DELIVERY USING BEACON POSITIONING",https://lens.org/014-692-415-353-712,2022,"An approach is provided for drone delivery using beacon positioning. The approach, for example, involves determining, at a drone, a cell where a target beacon associated with a domain is located. The approach also involves, upon reaching the cell, transmitting a destination identifier associated with the target beacon from the drone to a domain beacon of the domain in the cell. The approach further involves receiving, by the drone, a guiding signal from the domain beacon to reach the target beacon."
INTELLIGENT DEVICE SELECTION USING HISTORICAL INTERACTIONS,https://lens.org/010-262-040-705-746,2022,"This relates generally to intelligent automated assistants and, more specifically, to provide intelligent device selections by the intelligent automated assistants for performing requested actions. An example method includes, at an electronic device receiving a user request from a user, identifying the user, a domain type of the user request, and one or more electronic devices available for handling the user request; retrieving one or more historical interactions involving at least one of the identified user, the domain type, and the one or more electronic devices, generating metadata based on the one or more historical interactions, location information of the one or more electronic devices, and context information associated with the one or more electronic devices; identifying a delivery device by interpreting the metadata using a preference model; and transmitting a response command to the delivery device for providing the result output."
INTELLIGENT DEVICE SELECTION USING HISTORICAL INTERACTIONS,https://lens.org/010-262-040-705-746,2022,"This relates generally to intelligent automated assistants and, more specifically, to provide intelligent device selections by the intelligent automated assistants for performing requested actions. An example method includes, at an electronic device receiving a user request from a user, identifying the user, a domain type of the user request, and one or more electronic devices available for handling the user request; retrieving one or more historical interactions involving at least one of the identified user, the domain type, and the one or more electronic devices, generating metadata based on the one or more historical interactions, location information of the one or more electronic devices, and context information associated with the one or more electronic devices; identifying a delivery device by interpreting the metadata using a preference model; and transmitting a response command to the delivery device for providing the result output."
Programmable universal remote control unit,https://lens.org/083-944-872-730-393,2006,"A programmable universal remote control unit, settable in one of either a single device mode of operation or a multi-device mode of operation."
Programmable universal remote control unit,https://lens.org/039-286-349-738-799,2006,"A programmable universal remote control unit, settable in one of either a single device mode of operation or a multi-device mode of operation."
Delivery sound masking and sound emission,https://lens.org/079-595-920-446-497,2018,"An unmanned aerial vehicle (UAV) may emit masking sounds during operation of the UAV to mask other sounds generated by the UAV during operation. The UAV may be used to deliver items to a residence or other location associated with a customer. The UAV may emit sounds that mask the conventional sounds generated by the propellers and/or motors to cause the UAV to emit sounds that are pleasing to bystanders or do not annoy the bystanders. The UAV may emit sounds using speakers or other sound generating devices, such as fins, reeds, whistles, or other devices which may cause sound to be emitted from the UAV. Noise canceling algorithms may be used to cancel at least some of the conventional noise generated by operation of the UAV using inverted sounds, while additional sound may be emitted by the UAV, which may not be subject to noise cancellation."
UNMANNED AERIAL VEHICLE HAVING A PROJECTOR AND BEING TRACKED BY A LASER TRACKER,https://lens.org/136-084-815-630-576,2019,"An unmanned aerial vehicle (UAV) such as a drone, quadcopter or octocopter having a projector on board for projecting information into physical space such as onto objects or locations while the UAV is in flight, and further with the position and orientation (i.e., the six degrees of freedom) of the UAV in flight being accurately tracked and controlled from the ground, e.g., by a laser tracker or a camera bar, thereby leading to a relatively more stable flight of the UAV."
UNMANNED AERIAL VEHICLE HAVING A PROJECTOR AND BEING TRACKED BY A LASER TRACKER,https://lens.org/157-292-928-062-93X,2016,"An unmanned aerial vehicle (UAV) such as a drone, quadcopter or octocopter having a projector on board for projecting information into physical space such as onto objects or locations while the UAV is in flight, and further with the position and orientation (i.e., the six degrees of freedom) of the UAV in flight being accurately tracked and controlled from the ground, e.g., by a laser tracker or a camera bar, thereby leading to a relatively more stable flight of the UAV."
Method and apparatus to locate a device in a dwelling or other enclosed space,https://lens.org/115-459-924-536-366,2003,"A device is presented including a processor. A user interface is connected to the processor. A receiver is connected to the processor for receiving current location information from an external source. Also, a transmitter is connected to the processor for transmitting the current location information and command data to an external receiver. Also presented is a system including a processor connected to a transmission medium. A first receiver is connected to the processor. A first transmitter is also connected to the processor. A second transmitter transmits location data. A remote control (RC) including a RC receiver and a RC transmitter is included. The RC receives location data and sends command data and the location data to the first receiver. The first transmitter sends control information for at least one device located in a specific location according to the location data received by the RC."
Method and apparatus to locate a device in a dwelling or other enclosed space,https://lens.org/108-720-760-868-817,2005,"A device is presented including a processor. A user interface is connected to the processor. A receiver is connected to the processor for receiving current location information from an external source. Also, a transmitter is connected to the processor for transmitting the current location information and command data to an external receiver. Also presented is a system including a processor connected to a transmission medium. A first receiver is connected to the processor. A first transmitter is also connected to the processor. A second transmitter transmits location data. A remote control (RC) including a RC receiver and a RC transmitter is included. The RC receives location data and sends command data and the location data to the first receiver. The first transmitter sends control information for at least one device located in a specific location according to the location data received by the RC."
Interactive voice responsive radio tuning system,https://lens.org/173-131-411-456-349,2001,A system for automatically tuning the radio equipment of an aircraft in response to a verbal communication to the system.
SECURE COMMUNICATIONS WITH UNMANNED AERIAL VEHICLES,https://lens.org/188-290-709-578-456,2016,"A device receives a request for a flight path for a UAV to travel from a first location to a second location, and determines, based on credentials of the UAV, whether the UAV is authenticated for utilizing the device. The device determines, when the UAV is authenticated, capability information for the UAV based on component information of the UAV, and calculates the flight path. The device determines whether the UAV is capable of traversing the flight path based on the capability information, and generates, when the UAV is capable of traversing the flight path, flight path instructions for the flight path. The device provides the flight path instructions and credentials of the device to the UAV to permit the UAV to travel from the first location to the second location when the UAV authenticates the device based on the credentials of the device."
Secure communications with unmanned aerial vehicles,https://lens.org/156-772-080-940-737,2017,"A device receives a request for a flight path for a UAV to travel from a first location to a second location, and determines, based on credentials of the UAV, whether the UAV is authenticated for utilizing the device. The device determines, when the UAV is authenticated, capability information for the UAV based on component information of the UAV, and calculates the flight path. The device determines whether the UAV is capable of traversing the flight path based on the capability information, and generates, when the UAV is capable of traversing the flight path, flight path instructions for the flight path. The device provides the flight path instructions and credentials of the device to the UAV to permit the UAV to travel from the first location to the second location when the UAV authenticates the device based on the credentials of the device."
END GATE STRUCTURE WITH AUTOMATIC POWER DOWN,https://lens.org/098-903-512-453-066,2019,"Techniques are described for tracking and determining a three dimensional path traveled by controlled unmanned aircraft (i.e. drones) or other moving objects. By monitoring the strength of communication signals transmitted by an object, the strength of control signals received by the object, and altitude data generated by the object, its three dimensional path is determined. For example, these techniques can be applied to racing drones to determine their positions on a course. An end gate structure for such a course that can automatically transmit disable signals to the drones upon completing the course is also described."
Closed-Loop Adaptive Two-Way Remote Controller,https://lens.org/161-964-232-712-141,2012,"An adaptive remote control unit that automatically reads the changing real-time physical orientation of its remote controlled object, or other of its momentary features, and henceforth transmits commands to the remote controlled object that are a function of such reading as well as a function of user's own input control, for the purpose of achieving a unique pre-defined movement pattern, or otherwise adjust the behavior of the object in relations to its real time situation."
ELECTRONIC DEVICE AND CONTROLLING METHOD THEREOF,https://lens.org/075-325-994-848-944,2017,"An electronic device and a controlling method thereof are provided. The controlling method of the electronic device includes acquiring an image, extracting a search formula from the acquired image, generating a search result based on the extracted search formula, and outputting the generated search result."
"CONTROL DEVICE, OPTICAL DEVICE, AND CONTROL METHOD FOR TRACKING UNMANNED AERIAL VEHICLE, AND SYSTEM AND PROGRAM THEREFOR",https://lens.org/009-475-326-032-165,2018,"A technique enables easy recapture of an unmanned aerial vehicle (UAV) that an optical device has lost sight of. A control device controls tracking of the unmanned aerial vehicle. When failing to capture the unmanned aerial vehicle during tracking of the unmanned aerial vehicle, the control device controls processing to transmit a lost signal and controls processing to search for the unmanned aerial vehicle by targeting an airspace containing a location at which the unmanned aerial vehicle was previously captured by the control device."
"Control device, optical device, and control method for tracking unmanned aerial vehicle, and system and program therefor",https://lens.org/161-768-385-582-239,2018,"A technique enables easy recapture of an unmanned aerial vehicle (UAV) that an optical device has lost sight of. A control device controls tracking of the unmanned aerial vehicle. When failing to capture the unmanned aerial vehicle during tracking of the unmanned aerial vehicle, the control device controls processing to transmit a lost signal and controls processing to search for the unmanned aerial vehicle by targeting an airspace containing a location at which the unmanned aerial vehicle was previously captured by the control device."
Self-burying autonomous underwater vehicle and method for marine seismic surveys,https://lens.org/122-240-205-228-807,2016,"An autonomous underwater vehicle (AUV) for recording seismic signals during a marine seismic survey. The AUV includes a body having a base and sides; a propulsion system for guiding the AUV to a final target on the ocean bottom; a pump-jet connected to an inlet and plural base outlets, wherein the plural base outlets are distributed on the base; a processor connected to the pump-jet and configured to activate the pump-jet when the base in on the ocean bottom; and a seismic sensor configured to record seismic signals. The pump-jet has a first low speed so that water jets expelled at the plural base outlets fluidize the ocean bottom underneath the base and buries the AUV."
SELF-BURYING AUTONOMOUS UNDERWATER VEHICLE AND METHOD FOR MARINE SEISMIC SURVEYS,https://lens.org/156-959-676-264-645,2014,"An autonomous underwater vehicle (AUV) for recording seismic signals during a marine seismic survey. The AUV includes a body having a base and sides; a propulsion system for guiding the AUV to a final target on the ocean bottom; a pump-jet connected to an inlet and plural base outlets, wherein the plural base outlets are distributed on the base; a processor connected to the pump-jet and configured to activate the pump-jet when the base in on the ocean bottom; and a seismic sensor configured to record seismic signals. The pump-jet has a first low speed so that water jets expelled at the plural base outlets fluidize the ocean bottom underneath the base and buries the AUV."
Helicopter navigation and location system.,https://lens.org/168-277-652-968-370,1985,"The disclosure relates to a helicopter (5) having a flight path computer to provide signals for pilot or automatic flying in accordance with a predetermined flight path, a forward looking infra-red camera (6) for scanning ahead and to either side of the flight for an object such as a person in the sea, a screen display for the camera and a control to be operated when the helicopter over-flies the person to cause the flight path computer to provide control signals to take the helicopter through a circuit downwind of the person and then back into-wind at pre-selected heights and speed towards the location of the person and then to hover over the person."
DEVICE AND METHOD FOR COLLECTING AERIAL IMAGES AND DATA FROM A LIGHT TRANSPORTABLE MANNED AERIAL VEHICLE,https://lens.org/181-758-146-498-626,2010,"A method and device for collecting aerial images and data. There is: an aircraft device, configured to fly through the air, including: a retractable mounting member, configured to extend and retract; and a pan tilt mounting member, configured to pan in a horizontal axis and tilt in a vertical axis, coupled to the retractable mounting member opposite the aircraft device. There is also: a data collecting device housing, coupled to the pan tilt mounting member opposite the retractable mounting member, configured to house a data collecting device; and a data collecting device, configured to collect images and data, disposed within the data collecting device housing. The data collecting device includes a remote control system in wireless communication with the data collecting device."
LOCAL AI INFERENCE,https://lens.org/013-582-518-002-284,2023,"Artificial Intelligence (AI) is used to infer information from a live video/audio feed from a doorbell camera, surveillance camera, and the like. Moving such capability from the Cloud or the Edge may provide a cost advantage, greater assurance of privacy concerning a surveilled location, and less latency than other methods employing Al inference."
ELECTRONIC DEVICE AND VEHICLE,https://lens.org/061-569-064-699-56X,2019,"A electronic device is disclosed. The electronic device includes a communication device configured to receive traveling control data from another autonomous driving vehicle, and a processor configured to determine traveling speed based on the traveling control data and to provide a control signal to allow a vehicle to travel to track the other autonomous driving vehicle within a predetermined distance according to the traveling speed."
ELECTRONIC DEVICE AND VEHICLE,https://lens.org/092-659-285-973-204,2019,"A electronic device is disclosed. The electronic device includes a communication device configured to receive traveling control data from another autonomous driving vehicle, and a processor configured to determine traveling speed based on the traveling control data and to provide a control signal to allow a vehicle to travel to track the other autonomous driving vehicle within a predetermined distance according to the traveling speed."
"UNMANNED AERIAL VEHICLE, CONTROL METHOD, AND PROGRAM",https://lens.org/133-537-010-518-288,2021,"An unmanned aircraft (1) includes: a sensor (person detection sensor (100) and so forth) that performs sensing of an external environment of the unmanned aircraft (l); a detector (suspicious person identifier (110)) that detects a moving object based on a result of the sensing performed by the sensor; an obtainer (movement prohibition position determiner (113)) that obtains area information indicating an area, entry to which by the moving object is undesirable; and a flight controller (114) that causes the unmanned aircraft (1) to move to a position between the moving object and the area indicated by the area information, based on a positional relation between the moving object and the area, and fly at the position that is a destination position."
NATURAL LANGUAGE USER INTERFACE,https://lens.org/048-665-914-919-75X,2015,"A mobile device is configured to wirelessly authenticate with a reader device. The mobile device may receive an acoustic signal from a user, and a command may be determined based on the acoustic signal. The mobile device may transmit the command to the reader device if the mobile device and the reader device are authenticated. The reader device may receive the command, and may analyze the command to determine an action to be performed. The reader device may then perform the action if the mobile device is authorized to request the command to be performed."
NATURAL LANGUAGE USER INTERFACE,https://lens.org/104-174-414-088-382,2023,"A mobile device is configured to wirelessly authenticate with a reader device. The mobile device may receive an acoustic signal from a user, and a command may be determined based on the acoustic signal. The mobile device may transmit the command to the reader device if the mobile device and the reader device are authenticated. The reader device may receive the command, and may analyze the command to determine an action to be performed. The reader device may then perform the action if the mobile device is authorized to request the command to be performed."
Natural language user interface,https://lens.org/004-368-954-389-91X,2018,"A mobile device is configured to wirelessly authenticate with a reader device. The mobile device may receive an acoustic signal from a user, and a command may be determined based on the acoustic signal. The mobile device may transmit the command to the reader device if the mobile device and the reader device are authenticated. The reader device may receive the command, and may analyze the command to determine an action to be performed. The reader device may then perform the action if the mobile device is authorized to request the command to be performed."
NATURAL LANGUAGE USER INTERFACE,https://lens.org/081-430-476-296-619,2015,"A mobile device is configured to wirelessly authenticate with a reader device. The mobile device may receive an acoustic signal from a user, and a command may be determined based on the acoustic signal. The mobile device may transmit the command to the reader device if the mobile device and the reader device are authenticated. The reader device may receive the command, and may analyze the command to determine an action to be performed. The reader device may then perform the action if the mobile device is authorized to request the command to be performed."
Natural language user interface,https://lens.org/117-671-436-055-580,2017,"A mobile device is configured to wirelessly authenticate with a reader device. The mobile device may receive an acoustic signal from a user, and a command may be determined based on the acoustic signal. The mobile device may transmit the command to the reader device if the mobile device and the reader device are authenticated. The reader device may receive the command, and may analyze the command to determine an action to be performed. The reader device may then perform the action if the mobile device is authorized to request the command to be performed."
NATURAL LANGUAGE USER INTERFACE,https://lens.org/193-367-218-314-433,2019,"A mobile device is configured to wirelessly authenticate with a reader device. The mobile device may receive an acoustic signal from a user, and a command may be determined based on the acoustic signal. The mobile device may transmit the command to the reader device if the mobile device and the reader device are authenticated. The reader device may receive the command, and may analyze the command to determine an action to be performed. The reader device may then perform the action if the mobile device is authorized to request the command to be performed."
Natural language user interface,https://lens.org/136-764-548-931-161,2023,"A mobile device is configured to wirelessly authenticate with a reader device. The mobile device may receive an acoustic signal from a user, and a command may be determined based on the acoustic signal. The mobile device may transmit the command to the reader device if the mobile device and the reader device are authenticated. The reader device may receive the command, and may analyze the command to determine an action to be performed. The reader device may then perform the action if the mobile device is authorized to request the command to be performed."
NATURAL LANGUAGE USER INTERFACE,https://lens.org/062-299-590-752-657,2021,"A mobile device is configured to wirelessly authenticate with a reader device. The mobile device may receive an acoustic signal from a user, and a command may be determined based on the acoustic signal. The mobile device may transmit the command to the reader device if the mobile device and the reader device are authenticated. The reader device may receive the command, and may analyze the command to determine an action to be performed. The reader device may then perform the action if the mobile device is authorized to request the command to be performed."
NATURAL LANGUAGE USER INTERFACE,https://lens.org/104-174-414-088-382,2023,"A mobile device is configured to wirelessly authenticate with a reader device. The mobile device may receive an acoustic signal from a user, and a command may be determined based on the acoustic signal. The mobile device may transmit the command to the reader device if the mobile device and the reader device are authenticated. The reader device may receive the command, and may analyze the command to determine an action to be performed. The reader device may then perform the action if the mobile device is authorized to request the command to be performed."
Natural language user interface,https://lens.org/017-652-473-942-657,2018,"A mobile device is configured to wirelessly authenticate with a reader device. The mobile device may receive an acoustic signal from a user, and a command may be determined based on the acoustic signal. The mobile device may transmit the command to the reader device if the mobile device and the reader device are authenticated. The reader device may receive the command, and may analyze the command to determine an action to be performed. The reader device may then perform the action if the mobile device is authorized to request the command to be performed."
Natural language user interface,https://lens.org/136-764-548-931-161,2023,"A mobile device is configured to wirelessly authenticate with a reader device. The mobile device may receive an acoustic signal from a user, and a command may be determined based on the acoustic signal. The mobile device may transmit the command to the reader device if the mobile device and the reader device are authenticated. The reader device may receive the command, and may analyze the command to determine an action to be performed. The reader device may then perform the action if the mobile device is authorized to request the command to be performed."
Collaborative unmanned aerial vehicle for an inventory system,https://lens.org/024-478-143-849-065,2018,"The disclosed unmanned aerial vehicle (UAV) includes a buoyant airbag, a drive unit, a retention feature, and an onboard control module that can be configured to cause the drive unit to displace the UAV, cause the retention feature to retain one or more items for transport, and receive instructions to transfer items from one location to another. For example, a UAV can be controlled to obtain an item at one location in a warehouse such as a first floor, lift said item to a second location in the warehouse such as a second floor, and deposit the item at the second location."
UNMANNED AERIAL VEHICLES CAPABLE OF ENVIRONMENTAL INTERACTION,https://lens.org/025-773-149-858-841,2019,"An unmanned aerial vehicle (UAV) system is disclosed. The UAV system includes a chassis, a plurality of propeller assemblies configured to provide vertical take-off and landing (VTOL) for the chassis with propulsion in 6 degrees of freedom including along a cartesian coordinate system (X, Y, Z) and provide yaw, pitch, and roll, the plurality of propeller assemblies are selected from the group consisting of (i) two fixed propeller assemblies and a tiltable propeller assembly, and (ii) four fixed propeller assemblies, a boom having a boom propeller assembly, configured to selectively provide positive and negative rectilinear thrust vectors, and an end-effector coupled to a distal end of the boom, the end-effector having a force sensor configured to provide contact force between the end-effector and an object."
UNMANNED VEHICLES CAPABLE OF ENVIRONMENTAL INTERACTION,https://lens.org/008-360-038-394-894,2021,"An unmanned aerial vehicle (UAV) system is disclosed. The UAV system includes a chassis, a plurality of propeller assemblies configured to provide vertical take-off and landing (VTOL) for the chassis with propulsion in 6 degrees of freedom including along a cartesian coordinate system (X, Y, Z) and provide yaw, pitch, and roll, the plurality of propeller assemblies are selected from the group consisting of (i) two fixed propeller assemblies and a tiltable propeller assembly, and (ii) four fixed propeller assemblies, a boom having a boom propeller assembly, configured to selectively provide positive and negative rectilinear thrust vectors, and an end-effector coupled to a distal end of the boom, the end-effector having a force sensor configured to provide contact force between the end-effector and an object."
Unmanned aerial vehicles capable of environmental interaction,https://lens.org/104-550-472-741-155,2021,"An unmanned aerial vehicle (UAV) system is disclosed. The UAV system includes a chassis, a plurality of propeller assemblies configured to provide vertical take-off and landing (VTOL) for the chassis with propulsion in 6 degrees of freedom including along a cartesian coordinate system (X, Y, Z) and provide yaw, pitch, and roll, the plurality of propeller assemblies are selected from the group consisting of (i) two fixed propeller assemblies and a tiltable propeller assembly, and (ii) four fixed propeller assemblies, a boom having a boom propeller assembly, configured to selectively provide positive and negative rectilinear thrust vectors, and an end-effector coupled to a distal end of the boom, the end-effector having a force sensor configured to provide contact force between the end-effector and an object."
Moving robot and method of controlling the same,https://lens.org/167-269-143-412-853,2020,"A autonomous robot includes a main body, a driving unit to move the main body within an operation region, a battery to supply power to the driving unit, and a controller to control the driving unit in a manner that the main body travels along a wall of the operation region to move to a charging stand when a remaining power level of the battery drops below a reference power level, wherein the controller controls the driving unit in a manner that the main body escape from one region corresponding to a closed curve when a movement path of the main body forms the closed curve while the driving unit performs wall following."
MOVING ROBOT AND METHOD OF CONTROLLING THE SAME,https://lens.org/181-424-250-222-785,2018,"A autonomous robot includes a main body, a driving unit to move the main body within an operation region, a battery to supply power to the driving unit, and a controller to control the driving unit in a manner that the main body travels along a wall of the operation region to move to a charging stand when a remaining power level of the battery drops below a reference power level, wherein the controller controls the driving unit in a manner that the main body escape from one region corresponding to a closed curve when a movement path of the main body forms the closed curve while the driving unit performs wall following."
AIRCRAFT,https://lens.org/028-928-948-365-034,2009,"An unmanned aerial vehicle (UAV) (1) in the form of a ""tail sitter"" flying wing (1) adapted for vertical take off and landing and transitions between flight as a helicopter and wing-borne flight. The vehicle is electrically powered from onboard batteries and equipped with rotors (7) on miniature helicopter rotor heads (8) at the tips of the wing for both lift, during take off and landing, and forward thrust. In planform the wing (1) comprises, to each side of its longitudinal axis, an inner section (2) with swept back leading and trailing edges, and an outer section (3) with a leading edge more perpendicular to the longitudinal axis, being only mildly swept back or substantially unswept, and a swept forward trailing edge."
Control of an alert mechanism by communication of an event-associated command,https://lens.org/167-989-853-219-228,2003,"A method and apparatus for associating a command with an event at a first device, communicating the command to a second device when the event occurs and causing an action at the second device depending on the command."
Control of an alert mechanism by communication of an event-associated command,https://lens.org/194-542-832-793-798,2006,"A method and apparatus for associating a command with an event at a first device, communicating the command to a second device when the event occurs and causing an action at the second device depending on the command."
AN UNMANNED AERIAL VEHICLE,https://lens.org/070-255-666-140-258,2022,"An unmanned aerial vehicle comprising: a housing comprising an outer surface and an inner surface that forms a cavity, at least one propulsion device adapted to move the chassis in three dimensions, one or more first electrical components configured to provide a controller that generates and/or receives flight control signals indicating a position of the unmanned aerial vehicle in air space and wherein the flight controller controls the flight propulsion device to move the UAV to locations in the space indicated by the flight control signals, wherein the housing comprises a thermal conductor, having an inner surface and an outer surface, where the outer surface faces the surrounding environment, and the inner surface is in thermal communication with at one or more of the electrical components."
AN UNMANNED AERIAL VEHICLE,https://lens.org/070-255-666-140-258,2022,"An unmanned aerial vehicle comprising: a housing comprising an outer surface and an inner surface that forms a cavity, at least one propulsion device adapted to move the chassis in three dimensions, one or more first electrical components configured to provide a controller that generates and/or receives flight control signals indicating a position of the unmanned aerial vehicle in air space and wherein the flight controller controls the flight propulsion device to move the UAV to locations in the space indicated by the flight control signals, wherein the housing comprises a thermal conductor, having an inner surface and an outer surface, where the outer surface faces the surrounding environment, and the inner surface is in thermal communication with at one or more of the electrical components."
Integration of vehicle systems into a home security system,https://lens.org/008-579-383-570-541,2022,"A method of responding to an event (e.g. intruder) detected by a security system securing a building environment comprising, at the security system, receiving and processing sensor device data to detect the event, based on detecting the event, determining a control action to be performed by a vehicle located in the environment vicinity, and transmitting a notification specifying the control action to a control system of the vehicle to trigger the control action by the vehicle. Sensor devices (e.g. motion, camera) may be installed in the building environment or vehicle. Image processing or face detection may be performed on camera image data. Control actions may comprise activating vehicle interior or exterior vehicle lights, an audible alert, an audio playback system, engine, cameras (e.g. reverse, traffic, cabin), transmitting image data to the security system, autonomously moving the vehicle. Also provided is a method controlling a smart home control system of a smart home environment to provide a home security function, comprising, receiving and processing sensor data from one or more sensor devices of a vehicle associated with the smart home, detecting a security event based on the sensor data, and in response to detecting the security event, generating a security alert."
UNMANNED AERIAL VEHICLE AND OPERATIONS THEREOF,https://lens.org/084-667-895-687-213,2022,"A multi-rotor unmanned aerial vehicle (UAV) includes a central body including an outer surface and an inner surface, a plurality of branch members connected to the central body, each branch member configured to support a corresponding actuator assembly, one or more receiving structures positioned on the outer surface of the central body and configured to receive one or more electrical components, the one or more electrical components comprising at least a battery of the UAV, and an indicator light disposed at an opening or a window on one of the plurality of branch members, wherein the opening or the window is made of a transparent or semi-transparent material."
UNMANNED AERIAL VEHICLE AND OPERATIONS THEREOF,https://lens.org/084-667-895-687-213,2022,"A multi-rotor unmanned aerial vehicle (UAV) includes a central body including an outer surface and an inner surface, a plurality of branch members connected to the central body, each branch member configured to support a corresponding actuator assembly, one or more receiving structures positioned on the outer surface of the central body and configured to receive one or more electrical components, the one or more electrical components comprising at least a battery of the UAV, and an indicator light disposed at an opening or a window on one of the plurality of branch members, wherein the opening or the window is made of a transparent or semi-transparent material."
UNMANNED AERIAL VEHICLE DEPLOYMENT SYSTEM,https://lens.org/168-119-486-902-304,2017,"A system for enabling a UAV to respond to an alert on a premises that has an alert generator configured to output event type data and event location data in response to one or more alerts on the premises, a flight plan database configured to store a plurality 5 of predetermined flight plans operable to direct a UAV to one or more locations on the premises, an event database configured to store a plurality of event types predetermined as suitable for a UAV response, and a controller. The controller is configured to receive the event type data and event location data, determine a match between the received event type and one or more event types in the event database, determine one or more .0 UAV flight plans in the flight plan database has a destination proximate the event location, and output the selected flight plan to a UAV flight control system operable to allow a UAV to navigate to the alert location. m Z! < ITw CDj Nw. 0"
UNMANNED AERIAL VEHICLES,https://lens.org/004-135-465-141-895,2019,"Various measures (for example methods, UAVs, controllers and computer programs) are provided in relation to controlling a UAV 110. The UAV 110 is caused to provide energy to and receive energy from a given vehicle 120. The received energy is used to provide power to at least one component of the UAV 110."
FAILSAFE POWERLINE ENGAGEMENT SYSTEM FOR A DRONE OR FOR AN AERIAL ROBOT,https://lens.org/178-565-832-109-636,2021,"A powerline engagement system (300) for mounting on a drone (200) or configured to form part of a drone to be engaged with a powerline (100) is disclosed. The system comprises a split core gripper (301), which may be a split core current transformer, having a first part (302) and at least one second part (303) movably connected to the first part. The at least one second part is movable, by use of an actuator (308), between a closed configuration in which a closed circuit is formed, and an open configuration in which there is an upwardly facing gap (305) for letting a powerline pass there through to allow for the engagement. During faulty operation conditions, the at least one second part can be automatically moved from the closed configuration to the open configuration in order to disengage the powerline engagement system from the powerline. Thus, the drone can fall down by gravity so that there is no need for a person to come up to the powerline to release it."
RIFLE LAUNCHER FOR SMALL UNMANNED AERIAL VEHICLES (UAVS),https://lens.org/175-095-305-803-295,2010,"A launcher system and method for an unmanned aerial vehicle (UAV), wherein the launcher system comprises a barrel comprising a prepackaged internal pusher cup configured behind the UAV housed within the barrel; an expansion chamber operatively connected around the barrel, wherein the barrel extends out of a first end of the expansion chamber; a muzzle adapter operatively connected to a second end of the expansion chamber, wherein the first end of the expansion chamber is positioned opposite to the second end of the expansion chamber; a rifle slip-fitted to the muzzle adapter; and a stand operatively connected to the expansion chamber, wherein a triggering of the rifle causes the internal pusher cup to push the UAV out of the barrel at a predetermined launch velocity in order to attain a predetermined self-propelled flight trajectory."
Rifle launcher for small unmanned aerial vehicles (UAVs),https://lens.org/051-373-016-091-456,2010,"A launcher system and method for an unmanned aerial vehicle (UAV), wherein the launcher system comprises a barrel comprising a prepackaged internal pusher cup configured behind the UAV housed within the barrel; an expansion chamber operatively connected around the barrel, wherein the barrel extends out of a first end of the expansion chamber; a muzzle adapter operatively connected to a second end of the expansion chamber, wherein the first end of the expansion chamber is positioned opposite to the second end of the expansion chamber; a rifle slip-fitted to the muzzle adapter; and a stand operatively connected to the expansion chamber, wherein a triggering of the rifle causes the internal pusher cup to push the UAV out of the barrel at a predetermined launch velocity in order to attain a predetermined self-propelled flight trajectory."
Navigation system for position self control robot and floor materials for providing absolute coordinates used thereof,https://lens.org/144-139-347-004-931,2007,"A navigation system for a position self control robot including a main body having a locomotion unit is provided. The navigation system includes two-dimensional (2D) barcodes, a barcode reader, and a control unit. The 2D barcodes are formed at predetermined intervals on a floor having a predetermined size and respectively have different unique coordinate values. The barcode reader is installed at a predetermined position in a lower portion of the main body to read a 2D barcode on the floor. The control unit is installed at the main body to be electrically connected with the barcode reader, recognizes absolute coordinates within a predetermined area, which are stored in memory, based on a unique coordinate value of the 2D barcode read by the barcode reader, applies the absolute coordinates to a programmed locomotion algorithm, and controls the locomotion unit to move the main body."
NAVIGATION SYSTEM FOR POSITION SELF CONTROL ROBOT AND FLOOR MATERIALS FOR PROVIDING ABSOLUTE COORDINATES USED THEREOF,https://lens.org/070-037-360-356-093,2005,"A navigation system for a position self control robot including a main body having a locomotion unit is provided. The navigation system includes two-dimensional (2D) barcodes, a barcode reader, and a control unit. The 2D barcodes are formed at predetermined intervals on a floor having a predetermined size and respectively have different unique coordinate values. The barcode reader is installed at a predetermined position in a lower portion of the main body to read a 2D barcode on the floor. The control unit is installed at the main body to be electrically connected with the barcode reader, recognizes absolute coordinates within a predetermined area, which are stored in memory, based on a unique coordinate value of the 2D barcode read by the barcode reader, applies the absolute coordinates to a programmed locomotion algorithm, and controls the locomotion unit to move the main body."
EVENT ATTENDANCE MONITORING USING A VIRTUAL ASSISTANT,https://lens.org/021-960-522-229-102,2023,"A function of a user-controlled virtual assistant (UCVA) device, such as a smart speaker, can be augmented using video or image information about an environment. In an example, a system for augmenting an UCVA device includes an image sensor configured to monitor an environment, a processor circuit configured to receive image information from the image sensor and use artificial intelligence to discern a presence of one or more known individuals in the environment from one or more other features in the environment. The system can include an interface coupled to the processor circuit and configured to provide identification information to the UCVA device about the one or more known human beings in the environment. The UCVA device can be configured by the identification information to update an operating mode of the UCVA device."
Audio-visual monitoring using a virtual assistant,https://lens.org/003-585-048-511-519,2020,"A function of a user-controlled virtual assistant (UCVA) device, such as a smart speaker, can be augmented using video or image information about an environment. In an example, a system for augmenting an UCVA device includes an image sensor configured to monitor an environment, a processor circuit configured to receive image information from the image sensor and use artificial intelligence to discern a presence of one or more known individuals in the environment from one or more other features in the environment. The system can include an interface coupled to the processor circuit and configured to provide identification information to the UCVA device about the one or more known human beings in the environment. The UCVA device can be configured by the identification information to update an operating mode of the UCVA device."
EVENT ATTENDANCE MONITORING USING A VIRTUAL ASSISTANT,https://lens.org/021-960-522-229-102,2023,"A function of a user-controlled virtual assistant (UCVA) device, such as a smart speaker, can be augmented using video or image information about an environment. In an example, a system for augmenting an UCVA device includes an image sensor configured to monitor an environment, a processor circuit configured to receive image information from the image sensor and use artificial intelligence to discern a presence of one or more known individuals in the environment from one or more other features in the environment. The system can include an interface coupled to the processor circuit and configured to provide identification information to the UCVA device about the one or more known human beings in the environment. The UCVA device can be configured by the identification information to update an operating mode of the UCVA device."
AUDIO-VISUAL MONITORING USING A VIRTUAL ASSISTANT,https://lens.org/091-512-439-003-751,2021,"A function of a user-controlled virtual assistant (UCVA) device, such as a smart speaker, can be augmented using video or image information about an environment. In an example, a system for augmenting an UCVA device includes an image sensor configured to monitor an environment, a processor circuit configured to receive image information from the image sensor and use artificial intelligence to discern a presence of one or more known individuals in the environment from one or more other features in the environment. The system can include an interface coupled to the processor circuit and configured to provide identification information to the UCVA device about the one or more known human beings in the environment. The UCVA device can be configured by the identification information to update an operating mode of the UCVA device."
AUDIO-VISUAL MONITORING USING A VIRTUAL ASSISTANT,https://lens.org/043-194-041-315-673,2019,"A function of a user-controlled virtual assistant (UCVA) device, such as a smart speaker, can be augmented using video or image information about an environment. In an example, a system for augmenting an UCVA device includes an image sensor configured to monitor an environment, a processor circuit configured to receive image information from the image sensor and use artificial intelligence to discern a presence of one or more known individuals in the environment from one or more other features in the environment. The system can include an interface coupled to the processor circuit and configured to provide identification information to the UCVA device about the one or more known human beings in the environment. The UCVA device can be configured by the identification information to update an operating mode of the UCVA device."
"A SYSTEM, METHOD, COMPUTER PROGRAM AND DATA SIGNAL FOR THE REGISTRATION, MONITORING AND CONTROL OF MACHINES AND DEVICES",https://lens.org/080-731-215-545-843,2019,"Abstract: 5 The present invention provides a method for controlling a robotic device, comprising the steps of, receiving at a computing device at least one command arranged to effect an operation on the robotic device, reviewing the command to determine whether the command is suitable for execution, wherein the command is provided to the device only if the command is suitable for io execution."
ARTIFICIAL INTELLIGENCE MOVING ROBOT AND METHOD FOR CONTROLLING THE SAME,https://lens.org/036-696-400-622-322,2020,"The present disclosure relates to an artificial intelligence (AI) moving robot and a method for controlling the AI moving robot in which a target monitoring area is set based on recording information received from a monitoring element configured to monitor the travel area, and at least one of traveling of a main body and image capturing of an image capturing unit is controlled to monitor the target monitoring area for monitoring the travel area."
ARTIFICIAL INTELLIGENCE MOVING ROBOT AND METHOD FOR CONTROLLING THE SAME,https://lens.org/173-477-532-179-382,2022,"The present disclosure relates to an artificial intelligence (AI) moving robot and a method for controlling the AI moving robot in which a target monitoring area is set based on recording information received from a monitoring element configured to monitor the travel area, and at least one of traveling of a main body and image capturing of an image capturing unit is controlled to monitor the target monitoring area for monitoring the travel area."
Tile laying machine and a method of use,https://lens.org/112-359-837-418-321,2015,A robotic tile laying machine and a method of use.
A TILE LAYING MACHINE AND A METHOD OF USE,https://lens.org/052-225-132-904-284,2015,A robotic tile laying machine and a method of use.
AUTONOMOUS VEHICLE FOR HANDLING GOODS IN COOPERATION WITH UNMANNED AERIAL VEHICLE AND METHOD THEREOF,https://lens.org/169-827-957-751-48X,2022,"Provided is a method for an autonomous vehicle to handle goods in collaboration with an unmanned aerial vehicle. The method comprises recognizing an unmanned aerial vehicle loading goods by the autonomous vehicle, capturing an image of the recognized unmanned aerial vehicle by the autonomous vehicle, analyzing the captured image to recognize a marker by the autonomous vehicle, adjusting a relative position of the autonomous vehicle and the unmanned aerial vehicle by moving the autonomous vehicle based on a recognition result of the marker, and taking over the goods from the unmanned aerial vehicle by the autonomous vehicle after position adjustment is completed."
Autonomous vehicle for handling goods in cooperation with unmanned aerial vehicle and method thereof,https://lens.org/124-887-965-550-938,2022,"Provided is a method for an autonomous vehicle to handle goods in collaboration with an unmanned aerial vehicle. The method comprises recognizing an unmanned aerial vehicle loading goods by the autonomous vehicle, capturing an image of the recognized unmanned aerial vehicle by the autonomous vehicle, analyzing the captured image to recognize a marker by the autonomous vehicle, adjusting a relative position of the autonomous vehicle and the unmanned aerial vehicle by moving the autonomous vehicle based on a recognition result of the marker, and taking over the goods from the unmanned aerial vehicle by the autonomous vehicle after position adjustment is completed."
Autonomous vehicle for handling goods in cooperation with unmanned aerial vehicle and method thereof,https://lens.org/124-887-965-550-938,2022,"Provided is a method for an autonomous vehicle to handle goods in collaboration with an unmanned aerial vehicle. The method comprises recognizing an unmanned aerial vehicle loading goods by the autonomous vehicle, capturing an image of the recognized unmanned aerial vehicle by the autonomous vehicle, analyzing the captured image to recognize a marker by the autonomous vehicle, adjusting a relative position of the autonomous vehicle and the unmanned aerial vehicle by moving the autonomous vehicle based on a recognition result of the marker, and taking over the goods from the unmanned aerial vehicle by the autonomous vehicle after position adjustment is completed."
AUTONOMOUS VEHICLE FOR HANDLING GOODS IN COOPERATION WITH UNMANNED AERIAL VEHICLE AND METHOD THEREOF,https://lens.org/169-827-957-751-48X,2022,"Provided is a method for an autonomous vehicle to handle goods in collaboration with an unmanned aerial vehicle. The method comprises recognizing an unmanned aerial vehicle loading goods by the autonomous vehicle, capturing an image of the recognized unmanned aerial vehicle by the autonomous vehicle, analyzing the captured image to recognize a marker by the autonomous vehicle, adjusting a relative position of the autonomous vehicle and the unmanned aerial vehicle by moving the autonomous vehicle based on a recognition result of the marker, and taking over the goods from the unmanned aerial vehicle by the autonomous vehicle after position adjustment is completed."
VARIABLE-HEIGHT PROXIMITY SENSORS ON AUTONOMOUS VEHICLES,https://lens.org/011-859-215-293-105,2018,An autonomous vehicle is configured to move across a floor surface in an environment. The autonomous vehicle includes a proximity sensor that is positionable at different heights on the autonomous vehicle. A location of the autonomous vehicle within the environment is determined. A proximity sensor height is determined based on the location of the autonomous vehicle within the environment. The proximity sensor is positioned at a height on the autonomous vehicle based on the proximity sensor height. A signal is received from the proximity sensor where the signal is indicative of a distance to an object within the environment at the height of the proximity sensor on the autonomous vehicle. An operation of the autonomous vehicle can be controlled based on the signal indicative of the distance to the object.
VARIABLE-HEIGHT PROXIMITY SENSORS ON AUTONOMOUS VEHICLES,https://lens.org/133-770-213-702-844,2021,An autonomous vehicle is configured to move across a floor surface in an environment. The autonomous vehicle includes a proximity sensor that is positionable at different heights on the autonomous vehicle. A location of the autonomous vehicle within the environment is determined. A proximity sensor height is determined based on the location of the autonomous vehicle within the environment. The proximity sensor is positioned at a height on the autonomous vehicle based on the proximity sensor height. A signal is received from the proximity sensor where the signal is indicative of a distance to an object within the environment at the height of the proximity sensor on the autonomous vehicle. An operation of the autonomous vehicle can be controlled based on the signal indicative of the distance to the object.
Advanced unmanned aerial vehicle system,https://lens.org/134-876-795-446-319,2008,"An Unmanned Aerial Vehicle (UAV) system that couples the speed and responsiveness of a shoulder-launched rocket with the stable, slow-moving aerial platform of a parafoil is disclosed. The unique use of an over-damped rocket automatically positions the parafoil upwind of its target and overcomes the inherent inability of the parafoil to make headway in adverse wind conditions. This marriage of a rocket and a parafoil creates a valuable new synergy that allows the rocket to very quickly position a payload at altitude and defeat any adverse winds, while the parafoil provides an inexpensive and easy-to-fly vehicle for reconnaissance or accurately placing a payload on a target. The system is suitable for aerial videography, thermal imagery, target designation, sensor placement or precision munitions delivery; and can perform these functions at a small fraction of the cost of any other UAV. Unlike other UAV's, no flying skills are required of the operator. The system is so simple to use that no special training is required even for flying at night, and the intrinsic stability of the parafoil eliminates the need for avionic control systems."
SMART DEVICE AND CONTROLLING METHOD THEREOF,https://lens.org/025-172-814-855-728,2017,"A smart device (100) comprising a camera(121) comprising a including a lens (221, 223) and an iris (225) positioned over the lens, the iris including a single layer film (310); and a controller (180) configured to cause the iris to adjust a size of an aperture formed in the film to adjust quantity of light incident on the lens, and a method for controlling the smart device including the steps of obtaining a video of a subject consecutively via the camera, using preset conditions; detecting a relative movement between the subject and the smart device; and adjusting at least one of the conditions based on the detected movement."
System and method to monitor a person in a residence with use of a set-top box device,https://lens.org/037-455-061-005-82X,2016,"A particular method includes receiving, at a set-top box device, an activation request from a monitoring service associated with activation of a video camera coupled to the set-top box device. The activation request is received when one or more alert conditions are satisfied. The method further includes activating the video camera based on a response to a prompt."
System and Method to Monitor a Person in a Residence with Use of a Set-Top Box Device,https://lens.org/098-015-408-874-965,2013,"A particular method includes receiving, at a set-top box device, an activation request from a monitoring service associated with activation of a video camera coupled to the set-top box device. The activation request is received when one or more alert conditions are satisfied. The method further includes activating the video camera based on a response to a prompt."
"Remote control helmet with observing, aiming and guiding functions",https://lens.org/139-264-494-138-640,2015,"The utility model provides a remote control helmet with observing, aiming and guiding functions which is composed of a helmet, a near-eye display and an electrical box. The near-eye display is composed of a screen and two convex lenses which are arranged in front of the helmet; a circuit board and batteries are arranged in the electrical box; a gyroscope sensor and a control circuit are arranged on the circuit board, a turning angle of the head of a user is acquired by the gyroscope sensor and is converted into a control signal by virtue of a signal processing device, the control signal is transmitted to an unmanned aerial vehicle by virtue of a multi-channel remote control transmitter, and flight direction of the unmanned aerial vehicle is controlled; a camera on the unmanned aerial vehicle acquires a battlefield image, the battlefield image is transmitted back to the helmet by virtue of a wireless image transmitter, a wireless image receiver circuit is arranged in the electrical box of the helmet, and the battlefield image is displayed on the near-eye display; and the user can observe an image shot by the unmanned aerial vehicle in real time, turn the head to control flight of the unmanned aerial vehicle, search an enemy tank and attack top of the enemy tank."
WELDING APPARATUS,https://lens.org/121-499-311-782-744,2017,A welding apparatus (1) comprises a multi-axis robotic arm (2) having a first end (2a); a welding tool (5) attached to the first end (2a); an image acquisition device (4) attached to the first end (2a) and having a light filtering system (7); the image acquisition device (4) is configured to monitor a welding target (6) and to provide an image of the welding target (6) to an operator; a control unit (8) is configured to control the robotic arm (2) and the welding tool (5); an input interface (9) for a human operator is associated to the control unit (8) and is configured to provide an input signal (SI) to the control unit (8) and to control the robotic arm (2) and welding tool (5) substantially in real time.
"Information processor, information processing method, and program",https://lens.org/013-214-050-010-836,2022,"An information processor including: an operation control unit that controls a motion of an autonomous mobile body acting on the basis of recognition processing, in a case where a target sound that is a target voice for voice recognition processing is detected, the operation control unit moving the autonomous mobile body to a position, around an approach target, where an input level of a non-target sound that is not the target voice becomes lower, the approach target being determined on the basis of the target sound."
"Information processor, information processing method, and program",https://lens.org/013-214-050-010-836,2022,"An information processor including: an operation control unit that controls a motion of an autonomous mobile body acting on the basis of recognition processing, in a case where a target sound that is a target voice for voice recognition processing is detected, the operation control unit moving the autonomous mobile body to a position, around an approach target, where an input level of a non-target sound that is not the target voice becomes lower, the approach target being determined on the basis of the target sound."
"INFORMATION PROCESSOR, INFORMATION PROCESSING METHOD, AND PROGRAM",https://lens.org/109-074-740-241-665,2023,"An information processor including: an operation control unit that controls a motion of an autonomous mobile body acting on the basis of recognition processing, in a case where a target sound that is a target voice for voice recognition processing is detected, the operation control unit moving the autonomous mobile body to a position, around an approach target, where an input level of a non-target sound that is not the target voice becomes lower, the approach target being determined on the basis of the target sound."
"INFORMATION PROCESSOR, INFORMATION PROCESSING METHOD, AND PROGRAM",https://lens.org/109-074-740-241-665,2023,"An information processor including: an operation control unit that controls a motion of an autonomous mobile body acting on the basis of recognition processing, in a case where a target sound that is a target voice for voice recognition processing is detected, the operation control unit moving the autonomous mobile body to a position, around an approach target, where an input level of a non-target sound that is not the target voice becomes lower, the approach target being determined on the basis of the target sound."
Automaton intelligent robot protector for cars and transportations,https://lens.org/091-622-454-423-33X,2006,"An automaton intelligent robot device use to watch cars and transportation for possible theft, crime activities, and automatic make calls to seek medical aid for passenger if serious accident occurs, that built in and attached as parts and accessory of cars and transportations. The robot device has computer control center and adapters to connect and control with server modules that can attach sensors, video cameras, Global Position System, and video cell phone communication channels. Using micro controllers to control sensors' input, output signals, the robot will consistently monitor and watch our cars and transportation, when robot detect any suspicious signals of theft, crime activities, serious accident, the intelligent robot will able to decide what actions base on its programming list making decision to make video cell phone calls to who should call for the issue, and transfer video in real time and brief situation report to the owner and who is concern the issue such as police, 911, medical department. The robot device has built with authenticate encryption process security hardware, the security unit has listening ability for specific assigned activate signals of radio wave and digital signals, once the robot receive the correct encryption password, it will perform secure activate robot steps in the transportation."
ARTIFICIAL INTELLIGENCE DEVICE AND METHOD FOR OPERATING THE SAME,https://lens.org/099-903-393-203-57X,2021,"Provided is an artificial intelligence device which identifies a plurality of objects contained in the video, acquires one or more objects, which are capable of outputting an audio, of the plurality of identified objects, displays one or more volume adjustment items for adjusting a volume of the audio output from each of the one or more acquired objects on a display, and adjusts the volume of the audio output from the corresponding object according to an operation command of each of the volume adjustment items."
SYSTEMS AND METHODS FOR OPERATING UNMANNED AERIAL VEHICLE,https://lens.org/197-511-079-571-788,2020,"An unmanned aerial vehicle (UAV) includes one or more propulsion units configured to generate lift to effect flight of the UAV, one or more receivers configured to receive user input from a remote controller, and one or more processors configured to: 1) permit the UAV to fly autonomously along a planned trajectory when no user input is received by the one or more receivers and 2) permit the UAV to fly completely based on the user input when the user input is received by the one or more receivers."
Remote controlled object macro and autopilot system,https://lens.org/055-362-208-519-615,2019,"A flight path management system manages flight paths for an unmanned aerial vehicle (UAV). The flight path management system receives a sequence of controller inputs for the UAV, and stores the sequence of controller inputs in a memory. The flight path management system accesses the memory and selects a selected section of the sequence of controller inputs corresponding to a time period. The flight management system outputs the selected section to a playback device in real time over a length of the time period."
REMOTE CONTROLLED OBJECT MACRO AND AUTOPILOT SYSTEM,https://lens.org/170-426-724-574-265,2018,"A flight path management system manages flight paths for an unmanned aerial vehicle (UAV). The flight path management system receives a sequence of controller inputs for the UAV, and stores the sequence of controller inputs in a memory. The flight path management system accesses the memory and selects a selected section of the sequence of controller inputs corresponding to a time period. The flight management system outputs the selected section to a playback device in real time over a length of the time period."
Apparatus for remotely controlling a camera,https://lens.org/058-314-015-344-882,1990,A wireless remote control apparatus for a camera comprises a transmitter unit which is detachably mounted on the camera body and a receiver unit disposed in the camera. The wireless remote control apparatus determines if the remote control operation is possible prior to initiating a photographing operation of the camera.
Method and apparatus for notifying users of interactive functions using a remote device,https://lens.org/019-186-107-747-090,2010,"A method and apparatus for notifying a user of an interactive event using a remote control device. In one embodiment, a remote control device contains either a display or a bright light, or both, which can create a visual alert to let a user know that an interactive function is available. The nature of the function may be displayed on a screen attached to the remote control device."
Notifying Users of Interactive Functions,https://lens.org/086-095-803-026-402,2010,"A method and apparatus for notifying a user of an interactive event using a remote control device. In one embodiment, a remote control device contains either a display or a bright light, or both, which can create a visual alert to let a user know that an interactive function is available. The nature of the function may be displayed on a screen attached to the remote control device."
Method and apparatus for notifying users of interactive functions,https://lens.org/067-983-307-496-540,2002,"A method and apparatus for notifying a user of an interactive event using a remote control device. In one embodiment, a remote control device contains either a display or a bright light, or both, which can create a visual alert to let a user know that an interactive function is available. The nature of the function may be displayed on a screen attached to the remote control device."
UNMANNED AERIAL VEHICLE SENSOR ACTIVATION AND CORRELATION SYSTEM,https://lens.org/079-675-606-659-697,2018,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for a sensor activation and correlation system. One of the methods includes obtaining information describing a flight plan for implementation. A trigger associated with activating a camera included in an unmanned aerial vehicle (UAV) is determined to be satisfied. Information indicating that the camera is to capture an image is provided to the camera. A first timestamp associated with the image is obtained and stored. Information indicating that the image was captured is received and associated with the obtained first timestamp. Information indicating that the camera captured the image is provided to a user device in communication with the UAV."
Unmanned aerial vehicle sensor activation and correlation system,https://lens.org/063-647-574-273-503,2023,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for a sensor activation and correlation system. One of the methods includes obtaining information describing a flight plan for implementation. A trigger associated with activating a camera included in an unmanned aerial vehicle (UAV) is determined to be satisfied. Information indicating that the camera is to capture an image is provided to the camera. A first timestamp associated with the image is obtained and stored. Information indicating that the image was captured is received and associated with the obtained first timestamp. Information indicating that the camera captured the image is provided to a user device in communication with the UAV."
STIRLING POWERED UNMANNED AERIAL VEHICLE,https://lens.org/071-058-761-846-797,2023,"An unmanned aerial vehicle (UAV) (103) is provided which includes a radioactive fuel source (111), and an external combustion engine (107) powered by said radioactive fuel source."
STIRLING POWERED UNMANNED AERIAL VEHICLE,https://lens.org/071-058-761-846-797,2023,"An unmanned aerial vehicle (UAV) (103) is provided which includes a radioactive fuel source (111), and an external combustion engine (107) powered by said radioactive fuel source."
STIRLING POWERED UNMANNED AERIAL VEHICLE,https://lens.org/177-779-988-401-243,2021,"An unmanned aerial vehicle (UAV) (103) is provided which includes a radioactive fuel source (111), and an external combustion engine (107) powered by said radioactive fuel source."
SYSTEMS AND METHODS FOR DEPLOYMENT AND OPERATION OF VERTICAL TAKE-OFF AND LANDING (VTOL) UNMANNED AERIAL VEHICLES,https://lens.org/012-876-425-162-243,2016,"An unmanned aerial vehicle (UAV) system provides for UAV deployment and remote, unattended operation with reduced logistics requirements. The system includes a launcher that can include one or more containers, or hangars, configured to house vertical take-off and landing (VTOL) UAVs. The system can further include a VTOL UAV orientation and charging module configured to mechanically position a UAV within a container and facilitate electrical mating and charging of a battery in the UAV. These operations, and others, can be performed by remote command that can initiate a series of pre-programmed steps. The UAV system can further include a power generation and storage subsystem, a security subsystem, a command and control subsystem and a communications subsystem. Command, control and communications can be provided between a remote station and the UAV."
MONITORING SYSTEM USING UNMANNED AIR VEHICLE WITH WIMAX COMMUNICATION,https://lens.org/189-241-509-633-938,2009,"Provided is a monitoring system using an unmanned air vehicle communicated based on a WiMAX communication scheme. The monitoring system includes an air vehicle and a relay unit. The air vehicle includes a photographing unit for capturing on-scene image information of a current flying area, and a global positioning system (GPS) receiver for receiving GPS information of the current flying area. The air vehicle transmits the on-scene image information and the GPS information, wirelessly. The relay unit remotely controls the air vehicle by receiving a travel command signal having information on a destination of the air vehicle, wirelessly transmits the travel command signal to the air vehicle based on the WiMAX communication scheme, and wirelessly receives the on-scene image information and the GPS information from the air vehicle based on the WiMAX communication scheme."
METHOD AND SYSTEM FOR FACILITATING AUTONOMOUS LANDING OF AERIAL VEHICLES ON A SURFACE,https://lens.org/084-008-594-148-225,2012,A system for facilitating autonomous landing of aerial vehicles on a surface. A beam emitter is directed downwards. A control module is configured to govern the vehicle. A processor processes image data. The beam emitter is arranged to emit simultaneously at least four beams directed towards the surface in order to project a pattern thereon. One beam emitter of the at least four beam emitters is placed in the center. An image capturing module captures subsequent images of the pattern.
Method and system for facilitating autonomous landing of aerial vehicles on a surface,https://lens.org/186-014-056-972-240,2013,A system for facilitating autonomous landing of aerial vehicles on a surface. A beam emitter is directed downwards. A control module is configured to govern the vehicle. A processor processes image data. The beam emitter is arranged to emit simultaneously at least four beams directed towards the surface in order to project a pattern thereon. One beam emitter of the at least four beam emitters is placed in the center. An image capturing module captures subsequent images of the pattern.
Delivery sound masking and sound emission,https://lens.org/058-807-673-534-747,2017,"An unmanned aerial vehicle (UAV) may emit masking sounds during operation of the UAV to mask other sounds generated by the UAV during operation. The UAV may be used to deliver items to a residence or other location associated with a customer. The UAV may emit sounds that mask the conventional sounds generated by the propellers and/or motors to cause the UAV to emit sounds that are pleasing to bystanders or do not annoy the bystanders. The UAV may emit sounds using speakers or other sound generating devices, such as fins, reeds, whistles, or other devices which may cause sound to be emitted from the UAV. Noise canceling algorithms may be used to cancel at least some of the conventional noise generated by operation of the UAV using inverted sounds, while additional sound may be emitted by the UAV, which may not be subject to noise cancelation."
Delivery sound masking and sound emission,https://lens.org/126-685-259-060-138,2022,"An unmanned aerial vehicle (UAV) may emit masking sounds during operation of the UAV to mask other sounds generated by the UAV during operation. The UAV may be used to deliver items to a residence or other location associated with a customer. The UAV may emit sounds that mask the conventional sounds generated by the propellers and/or motors to cause the UAV to emit sounds that are pleasing to bystanders or do not annoy the bystanders. The UAV may emit sounds using speakers or other sound generating devices, such as fins, reeds, whistles, or other devices which may cause sound to be emitted from the UAV. Noise canceling algorithms may be used to cancel at least some of the conventional noise generated by operation of the UAV using inverted sounds, while additional sound may be emitted by the UAV, which may not be subject to noise cancelation."
ADDRESSABLE SMART SPEAKER,https://lens.org/196-410-759-781-421,2006,"An addressable smart speaker for use in a fire alarm system connects to and receives messages over a network, has plural taps for selecting audio power. In response to a command, a selector in an addressed smart speaker selects a tap to select a particular audio power."
Addressable smart speaker,https://lens.org/130-936-038-270-711,2007,"An addressable smart speaker for use in a fire alarm system connects to and receives messages over a network, has plural taps for selecting audio power. In response to a command, a selector in an addressed smart speaker selects a tap to select a particular audio power."
Addressable smart speaker,https://lens.org/115-560-813-382-09X,2005,"An addressable smart speaker for use in a fire alarm system connects to and receives messages over a network, has plural taps for selecting audio power. In response to a command, a selector in an addressed smart speaker selects a tap to select a particular audio power."
Maintaining consistent sensor output,https://lens.org/178-610-605-345-807,2022,"An example autonomous vehicle includes a body configured for movement along a surface, a sensor on the body to output a signal in a plane and to obtain information about an environment based on the signal, and a control system to use the information to determine a location of the autonomous vehicle in the environment. The sensor is configured to keep constant the plane of the signal for different positions of the body."
MAINTAINING CONSISTENT SENSOR OUTPUT,https://lens.org/008-890-662-078-340,2021,"An example autonomous vehicle includes a body configured for movement along a surface, a sensor on the body to output a signal in a plane and to obtain information about an environment based on the signal, and a control system to use the information to determine a location of the autonomous vehicle in the environment. The sensor is configured to keep constant the plane of the signal for different positions of the body."
Voice controlled appliance,https://lens.org/124-490-655-983-564,2021,"An Internet of Thing (IoT) device checks user authentication using a combination of voice, image, and mobile devices."
Voice Appliance,https://lens.org/099-251-440-331-099,2021,"An Internet of Thing (IoT) device checks user authentication using a combination of voice, image, and mobile devices."
Remote control terminal and information processing apparatus,https://lens.org/161-377-445-581-425,2014,"Provided is a remote control terminal, including: a first terminal-side wireless-communication unit configured to interactively communicate with a control-target information processing apparatus by using a first wireless communication system, to control the information processing apparatus; a second terminal-side wireless-communication unit configured to interactively communicate with the information processing apparatus by using a second wireless communication system, the second wireless communication system being higher in speed than the first wireless communication system; a camera unit configured to obtain video data; and a first controller configured to control the second terminal-side wireless-communication unit to transmit the video data obtained by the camera unit to the information processing apparatus by using the second wireless communication system."
Remote control terminal and information processing apparatus,https://lens.org/037-254-041-147-934,2013,"Provided is a remote control terminal, including: a first terminal-side wireless-communication unit configured to interactively communicate with a control-target information processing apparatus by using a first wireless communication system, to control the information processing apparatus; a second terminal-side wireless-communication unit configured to interactively communicate with the information processing apparatus by using a second wireless communication system, the second wireless communication system being higher in speed than the first wireless communication system; a camera unit configured to obtain video data; and a first controller configured to control the second terminal-side wireless-communication unit to transmit the video data obtained by the camera unit to the information processing apparatus by using the second wireless communication system.
"
REMOTE CONTROL TERMINAL AND INFORMATION PROCESSING APPARATUS,https://lens.org/179-504-025-646-918,2014,"Provided is a remote control terminal, including: a first terminal-side wireless-communication unit configured to interactively communicate with a control-target information processing apparatus by using a first wireless communication system, to control the information processing apparatus; a second terminal-side wireless-communication unit configured to interactively communicate with the information processing apparatus by using a second wireless communication system, the second wireless communication system being higher in speed than the first wireless communication system; a camera unit configured to obtain video data; and a first controller configured to control the second terminal-side wireless-communication unit to transmit the video data obtained by the camera unit to the information processing apparatus by using the second wireless communication system."
Remote control terminal and information processing apparatus,https://lens.org/114-435-514-677-083,2014,"Provided is a remote control terminal, including: a first terminal-side wireless-communication unit configured to interactively communicate with a control-target information processing apparatus by using a first wireless communication system, to control the information processing apparatus; a second terminal-side wireless-communication unit configured to interactively communicate with the information processing apparatus by using a second wireless communication system, the second wireless communication system being higher in speed than the first wireless communication system; a camera unit configured to obtain video data; and a first controller configured to control the second terminal-side wireless-communication unit to transmit the video data obtained by the camera unit to the information processing apparatus by using the second wireless communication system."
REMOTE CONTROL TERMINAL AND INFORMATION PROCESSING APPARATUS,https://lens.org/112-378-274-907-634,2012,"Provided is a remote control terminal, including: a first terminal-side wireless-communication unit configured to interactively communicate with a control-target information processing apparatus by using a first wireless communication system, to control the information processing apparatus; a second terminal-side wireless-communication unit configured to interactively communicate with the information processing apparatus by using a second wireless communication system, the second wireless communication system being higher in speed than the first wireless communication system; a camera unit configured to obtain video data; and a first controller configured to control the second terminal-side wireless-communication unit to transmit the video data obtained by the camera unit to the information processing apparatus by using the second wireless communication system."
Gaming method with award provided based on determination of player presence at defined location,https://lens.org/020-059-732-138-366,2022,A display that responds to a smart device in response to the GPS location of the smart device being in a predefined location.
CONTROLLING A ROBOT IN THE PRESENCE OF A MOVING OBJECT,https://lens.org/071-108-044-589-313,2015,"A method, system, and one or more computer-readable storage media for controlling a robot in the presence of a moving object are provided herein. The method includes capturing a number of frames from a three-dimensional camera system and analyzing a frame to identify a connected object. The frame is compared to a previous frame to identify a moving connected object (MCO). If an unexpected MCO is in the frame a determination is made if the unexpected MCO is in an actionable region. If so, the robot is instructed to take an action."
CONTROLLING A ROBOT IN THE PRESENCE OF A MOVING OBJECT,https://lens.org/193-517-130-387-970,2016,"A method, system, and one or more computer-readable storage media for controlling a robot in the presence of a moving object are provided herein. The method includes capturing a number of frames from a three-dimensional camera system and analyzing a frame to identify a connected object. The frame is compared to a previous frame to identify a moving connected object (MCO). If an unexpected MCO is in the frame a determination is made if the unexpected MCO is in an actionable region. If so, the robot is instructed to take an action."
"PHOTOGRAPHY SYSTEM, CONTROL DEVICE, CONTROL METHOD, PROGRAM, AND STORAGE MEDIUM",https://lens.org/144-495-720-002-709,2022,"An image capturing system comprises: an unmanned aerial vehicle including an image capturing unit capable of capturing an image of a subject in a flight state; and a control device capable of communicating with a terminal of the subject and the unmanned aerial vehicle. The control device includes: a storage unit configured to register subject information in which the subject is set as a target to be captured; a determination unit configured to determine whether the subject is present in a predetermined image capturing area, on the basis of location information of the subject acquired by communicating with the terminal and map information; a signal generation unit configured to generate a control signal that controls the image capturing unit on the basis of determination of the determination unit; and a communication control unit configured to transmit the subject information and the control signal to the unmanned aerial vehicle. The unmanned aerial vehicle further includes: an identification unit configured to identify the subject on the basis of subject information distributed from the terminal of the subject and the subject information transmitted from the communication control unit; and an image capturing control unit configured to control the image capturing unit on the basis of the control signal to control image capturing of the subject identified by the identification unit."
"PHOTOGRAPHY SYSTEM, CONTROL DEVICE, CONTROL METHOD, PROGRAM, AND STORAGE MEDIUM",https://lens.org/144-495-720-002-709,2022,"An image capturing system comprises: an unmanned aerial vehicle including an image capturing unit capable of capturing an image of a subject in a flight state; and a control device capable of communicating with a terminal of the subject and the unmanned aerial vehicle. The control device includes: a storage unit configured to register subject information in which the subject is set as a target to be captured; a determination unit configured to determine whether the subject is present in a predetermined image capturing area, on the basis of location information of the subject acquired by communicating with the terminal and map information; a signal generation unit configured to generate a control signal that controls the image capturing unit on the basis of determination of the determination unit; and a communication control unit configured to transmit the subject information and the control signal to the unmanned aerial vehicle. The unmanned aerial vehicle further includes: an identification unit configured to identify the subject on the basis of subject information distributed from the terminal of the subject and the subject information transmitted from the communication control unit; and an image capturing control unit configured to control the image capturing unit on the basis of the control signal to control image capturing of the subject identified by the identification unit."
ROBOT CONTROL SYSTEM,https://lens.org/106-819-774-572-934,2016,"Provided is a robot control system and a method thereof. The robot control system includes: a mobile robot comprising at least one camera; and a controller, wherein the controller is configured to transmit, to the mobile robot, a signal for adjusting a resolution of a next image to be transmitted from the at least one camera to the controller, based on a data transmission rate of a current image captured by the at least one camera and output to the controller, and wherein the mobile robot is configured to adjust the resolution of the next image, based on the signal for adjusting the resolution of the next image."
Robot control system,https://lens.org/045-574-117-813-60X,2018,"Provided is a robot control system and a method thereof. The robot control system includes: a mobile robot comprising at least one camera; and a controller, wherein the controller is configured to transmit, to the mobile robot, a signal for adjusting a resolution of a next image to be transmitted from the at least one camera to the controller, based on a data transmission rate of a current image captured by the at least one camera and output to the controller, and wherein the mobile robot is configured to adjust the resolution of the next image, based on the signal for adjusting the resolution of the next image."
SYSTEM AND METHOD FOR ONBOARD VISION PROCESSING,https://lens.org/139-766-919-372-660,2007,"An unmanned aerial vehicle with a camera and conventional sensors, where the processor navigates the vehicle based at least in part on the image data and the sensor data. A method for navigating an unmanned aerial vehicle where a processor navigates the vehicle based at least in part on image data corrected by traditional sensor data."
SYSTEM AND METHOD FOR ONBOARD VISION PROCESSING,https://lens.org/197-773-814-388-171,2007,"An unmanned aerial vehicle with a camera and conventional sensors, where the processor navigates the vehicle based at least in part on the image data and the sensor data. A method for navigating an unmanned aerial vehicle where a processor navigates the vehicle based at least in part on image data corrected by traditional sensor data."
System and method for onboard vision processing,https://lens.org/010-802-662-807-258,2014,"An unmanned aerial vehicle with a camera and conventional sensors, where the processor navigates the vehicle based at least in part on the image data and the sensor data. A method for navigating an unmanned aerial vehicle where a processor navigates the vehicle based at least in part on image data corrected by traditional sensor data."
METHOD AND A SYSTEM FOR ENABLING USER/S TO TRIGGER AN ALARM,https://lens.org/077-684-813-551-293,2021,"A system and method for enabling a user to trigger an alarm. A method includes receiving a command from a user to trigger an alarm, the user provides the command through an interface of a user device and converting the command to an alarm signal. The method further includes determining a location of the user device and transmitting the location and the alarm signal to one or more devices, wherein the one or more devices transmit the location and the alarm signal to a control panel for notifying a facility regarding the alarm."
Method and a system for enabling user/s to trigger an alarm,https://lens.org/048-908-093-702-361,2021,"A system and method for enabling a user to trigger an alarm. A method includes receiving a command from a user to trigger an alarm, the user provides the command through an interface of a user device and converting the command to an alarm signal. The method further includes determining a location of the user device and transmitting the location and the alarm signal to one or more devices, wherein the one or more devices transmit the location and the alarm signal to a control panel for notifying a facility regarding the alarm."
OUTSIDE SURVEILLANCE APPARATUS IN WHICH INTERPHONE AND TV ARE INTERLINKED AND CONTROL METHOD USING THE SAME,https://lens.org/104-151-682-458-392,2015,"An outside surveillance apparatus and a control method using the same. A door lock is disposed on a door so as to be locked or unlocked. An interphone disposed on an outer wall includes a button which a visitor can press and a camera which takes an image of the visitor. A TV is interlinked with the interphone, and displays the image taken using the camera on a screen in response to the button being pressed. A set-top box has an announcement display section, which is configured to display a number of announcements in response to the button being pressed. A remote control remotely controls the TV in order to select a broadcast channel and select one of the number of announcements. The remote control has a select button to select one of the number of announcements and an unlock button to unlock the door lock."
Electronic device for controlling unmanned aerial vehicle and method of operating the same,https://lens.org/180-006-283-453-047,2019,"A system, devices and method are disclosed herein. The system may include a network interface, a memory, the two devices and a processor, which implements the method. The method may include receiving by a first device a location of a second device through the network interface, retrieving by the second device a plurality of media related to the received location, transmitting by the second device the plurality of media to the first device through the network interface, in response to receiving a selection of one of the plurality of media, transmit, through the network interface, transmitting by the first device control information for controlling a particular UAV selected from the plurality of UAVs based on corresponding with the selected one of the plurality of media to the second device."
ELECTRONIC DEVICE FOR CONTROLLING UNMANNED AERIAL VEHICLE AND METHOD OF OPERATING THE SAME,https://lens.org/134-467-145-749-521,2018,"A system, devices and method are disclosed herein. The system may include a network interface, a memory, the two devices and a processor, which implements the method. The method may include receiving by a first device a location of a second device through the network interface, retrieving by the second device a plurality of media related to the received location, transmitting by the second device the plurality of media to the first device through the network interface, in response to receiving a selection of one of the plurality of media, transmit, through the network interface, transmitting by the first device control information for controlling a particular UAV selected from the plurality of UAVs based on corresponding with the selected one of the plurality of media to the second device."
AUTONOMOUS VEHICLE SERVICE SYSTEM,https://lens.org/098-178-676-477-436,2019,"An autonomous vehicle service system having a display device, a receiver, and a controller. The receiver is configured to receive transmitted data from an autonomous vehicle related to status of the autonomous vehicle and information from a third party related to road conditions. The controller is programmed to monitor the transmitted data related to the status of the autonomous vehicle and the road conditions, determine when the autonomous vehicle requires assistance based on the transmitted data, and, when the autonomous vehicle requires assistance, cause information related to the autonomous vehicle to be displayed on the display device."
Autonomous vehicle service system,https://lens.org/155-019-760-112-71X,2022,"An autonomous vehicle service system having a display device, a receiver, and a controller. The receiver is configured to receive transmitted data from an autonomous vehicle related to status of the autonomous vehicle and information from a third party related to road conditions. The controller is programmed to monitor the transmitted data related to the status of the autonomous vehicle and the road conditions, determine when the autonomous vehicle requires assistance based on the transmitted data, and, when the autonomous vehicle requires assistance, cause information related to the autonomous vehicle to be displayed on the display device."
AUTONOMOUS VEHICLE SERVICE SYSTEM,https://lens.org/046-682-873-898-316,2018,"An autonomous vehicle service system having a display device, a receiver, and a controller. The receiver is configured to receive transmitted data from an autonomous vehicle related to status of the autonomous vehicle and information from a third party related to road conditions. The controller is programmed to monitor the transmitted data related to the status of the autonomous vehicle and the road conditions, determine when the autonomous vehicle requires assistance based on the transmitted data, and, when the autonomous vehicle requires assistance, cause information related to the autonomous vehicle to be displayed on the display device."
"RAPIDLY-DEPLOYABLE, DRONE-BASED WIRELESS COMMUNICATIONS SYSTEMS AND METHODS FOR THE OPERATION THEREOF",https://lens.org/023-870-139-203-675,2019,"Drone-based wireless communications systems are provided, as are methods carried-out by such wireless communications systems. In one embodiment, the wireless communications system includes a Satellite Signal Transformation (SST) unit and a plurality of aerial network drones, which can be deployed over a designated geographical area to form a multi-drone network thereover. During operation, the SST unit transmits a network source signal, which contains content extracted from a satellite signal. The multi-drone network receives the network source signal, disseminates drone relay signals containing the content through the multi-drone network, and broadcastings user device signals containing the content over the designated geographical area. In embodiments, the multi-drone network may broadcast multiple different types of user device signals for reception by various different types of user devices located within the designated geographical area, such as an arear containing communication infrastructure disabled by a natural disaster, a hostile attack, or other catastrophic event."
"RAPIDLY-DEPLOYABLE, DRONE-BASED WIRELESS COMMUNICATIONS SYSTEMS AND METHODS FOR THE OPERATION THEREOF",https://lens.org/005-248-802-065-000,2018,"Drone-based wireless communications systems are provided, as are methods carried-out by such wireless communications systems. In one embodiment, the wireless communications system includes a Satellite Signal Transformation (SST) unit and a plurality of aerial network drones, which can be deployed over a designated geographical area to form a multi-drone network thereover. During operation, the SST unit transmits a network source signal, which contains content extracted from a satellite signal. The multi-drone network receives the network source signal, disseminates drone relay signals containing the content through the multi-drone network, and broadcastings user device signals containing the content over the designated geographical area. In embodiments, the multi-drone network may broadcast multiple different types of user device signals for reception by various different types of user devices located within the designated geographical area, such as an arear containing communication infrastructure disabled by a natural disaster, a hostile attack, or other catastrophic event."
"Rapidly-deployable, drone-based wireless communications systems and methods for the operation thereof",https://lens.org/158-567-376-440-790,2019,"Drone-based wireless communications systems are provided, as are methods carried-out by such wireless communications systems. In one embodiment, the wireless communications system includes a Satellite Signal Transformation (SST) unit and a plurality of aerial network drones, which can be deployed over a designated geographical area to form a multi-drone network thereover. During operation, the SST unit transmits a network source signal, which contains content extracted from a satellite signal. The multi-drone network receives the network source signal, disseminates drone relay signals containing the content through the multi-drone network, and broadcastings user device signals containing the content over the designated geographical area. In embodiments, the multi-drone network may broadcast multiple different types of user device signals for reception by various different types of user devices located within the designated geographical area, such as an arear containing communication infrastructure disabled by a natural disaster, a hostile attack, or other catastrophic event."
"Rapidly-deployable, drone-based wireless communications systems and methods for the operation thereof",https://lens.org/169-565-621-593-089,2020,"Drone-based wireless communications systems are provided, as are methods carried-out by such wireless communications systems. In one embodiment, the wireless communications system includes a Satellite Signal Transformation (SST) unit and a plurality of aerial network drones, which can be deployed over a designated geographical area to form a multi-drone network thereover. During operation, the SST unit transmits a network source signal, which contains content extracted from a satellite signal. The multi-drone network receives the network source signal, disseminates drone relay signals containing the content through the multi-drone network, and broadcastings user device signals containing the content over the designated geographical area. In embodiments, the multi-drone network may broadcast multiple different types of user device signals for reception by various different types of user devices located within the designated geographical area, such as an arear containing communication infrastructure disabled by a natural disaster, a hostile attack, or other catastrophic event."
AUGMENTED REALITY SYSTEMS AND METHODS USED TO IDENTIFY TOYS AND TRIGGER VIDEO AND GRAPHICS,https://lens.org/130-898-730-073-971,2014,"An augmented reality system, used to identify toys and trigger video and graphics, includes an input device, one or more toy markers, a computer database, and a controller. Both the input device and the database are coupled to a network. The input device is configured to capture images and playback video, while the toy target marker is configured for image capture and video playback. The controller is coupled to the input device for manipulation of video and graphics such that when one or more toys contained in a real world environment, are manipulated, the toys are augmented, using computer-generated sensory input and a manipulated toy image is created."
AUGMENTED REALITY SYSTEMS AND METHODS USED TO IDENTIFY TOYS AND TRIGGER VIDEO AND GRAPHICS,https://lens.org/182-236-547-770-764,2016,"An augmented reality system, used to identify toys and trigger video and graphics, includes an input device, one or more toy markers, a computer database, and a controller. Both the input device and the database are coupled to a network. The input device is configured to capture images and playback video, while the toy target marker is configured for image capture and video playback. The controller is coupled to the input device for manipulation of video and graphics such that when one or more toys contained in a real world environment, are manipulated, the toys are augmented, using computer-generated sensory input and a manipulated toy image is created."
AERIAL ILLUMINATION SYSTEM,https://lens.org/128-074-983-031-645,2022,"An aerial illumination system running a program thereon, the aerial illumination system including at least one illuminating unmanned aerial vehicle, including a main body, and a media unit disposed on at least a portion of the main body to illuminate a target area, and at least one control device connected to the at least one illuminating unmanned aerial vehicle to control operations of the at least one illuminating unmanned aerial vehicle based on the program."
AERIAL ILLUMINATION SYSTEM,https://lens.org/128-074-983-031-645,2022,"An aerial illumination system running a program thereon, the aerial illumination system including at least one illuminating unmanned aerial vehicle, including a main body, and a media unit disposed on at least a portion of the main body to illuminate a target area, and at least one control device connected to the at least one illuminating unmanned aerial vehicle to control operations of the at least one illuminating unmanned aerial vehicle based on the program."
NEURAL NETWORK-BASED IMAGE TARGET TRACKING BY AERIAL VEHICLE,https://lens.org/081-238-782-108-567,2020,"A method for controlling an unmanned vehicle includes sensing a trigger event for updating a set of parameters of a remote neural network trained for a respective vehicle context of the unmanned vehicle, receiving from a remote server a set of updated parameters of the remote neural network that at least includes updated connection weights of the remote neural network, and transmitting the updated connection weights to the unmanned vehicle for the unmanned vehicle to operate according to a vehicle-based neural network applying the updated connection weights."
Aerial surveillance for premises security systems,https://lens.org/014-638-713-497-063,2023,"A method implemented by a system for security comprising an unmanned aerial vehicle (UAV) and an analytics device configured to communicate with a remote monitoring system and the UAV is provided. Media data from the UAV is received at an analytics device, where the media data includes surveillance information corresponding to a premises under surveillance. Security attributes associated with the premises are detected based at least in part on a first level of machine learning (ML) analysis performed on the media data. The media data are transmitted by the analytics device to the remote monitoring system for a second level of ML analysis based at least in part on the security attribute, where the first level of ML analysis is less computationally expensive compared to the second level of ML analysis, and the second level of ML analysis is performed at the remote monitoring system on the media data."
Deployable delivery guidance,https://lens.org/091-941-833-980-193,2019,"Delivery area guidance may be provided to an unmanned aerial vehicle (UAV) via one or more delivery area guidance vehicles. For example, a UAV may be programmed to fly to a delivery area (e.g., a neighborhood, a block, a large residential or commercial property, and/or another area associated with landing and/or a delivery). Approaching the delivery area, the UAV may deploy one or more delivery area guidance vehicles. A guidance vehicle may be configured to maneuver a distance from the UAV, and to assist in guiding the UAV into the delivery area to the UAV."
Method for delivering a device to a target location,https://lens.org/181-480-725-954-290,2010,"An autonomous device that may include for example a camera, a transmitter for transmitting a signal from the camera and a storage compartment for retaining a substance in the device. A method of delivering a medicament to a patient including imaging a gastro intestinal tract with an autonomous device, identifying a target location in such tract, and releasing a medicament from the device at the target location."
ROBOT CONTROL DEVICE,https://lens.org/090-203-247-920-322,2021,"This control device for controlling the operation of a robot comprises a first control unit and a command unit. The first control unit receives inputs of a first state of the robot and a second state to which the robot transitions from the first state, and outputs: at least one basic operation selected from a plurality of basic operations the robot is instructed to perform for transitioning from the first state to the second state; and the order in which the basic operations are to be performed. Prescribed operating parameters are set for each of the basic operations. The command unit executes operation commands for the robot on the basis of the output from the first control unit."
Traffic offloading for a communication drone,https://lens.org/167-397-789-866-64X,2018,"Various embodiments include methods of offloading user equipment communication traffic between communications drones. The methods may include receiving, at a candidate communication drone, a replacement request from a requesting communication drone. Radio frequency (RF) communication parameters may be set for the candidate communication drone to take over communications of the requesting communication drone. The RF communication parameters may be determined based on the replacement request and may distinguish the candidate communication drone from the requesting communication drone and at least one neighboring communication drone. The candidate communication drone may move toward a target position adjacent a position of the requesting communication drone without radiating RF communications for taking over communications of the requesting communication drone. In addition, the candidate communication drone may radiate RF communications using the set RF communication parameters to begin taking over communication services from the requesting communication drone upon arriving at the target position."
TRAFFIC OFFLOADING FOR A COMMUNICATION DRONE,https://lens.org/131-330-840-300-754,2018,"Various embodiments include methods of offloading user equipment communication traffic between communications drones. The methods may include receiving, at a candidate communication drone, a replacement request from a requesting communication drone. Radio frequency (RF) communication parameters may be set for the candidate communication drone to take over communications of the requesting communication drone. The RF communication parameters may be determined based on the replacement request and may distinguish the candidate communication drone from the requesting communication drone and at least one neighboring communication drone. The candidate communication drone may move toward a target position adjacent a position of the requesting communication drone without radiating RF communications for taking over communications of the requesting communication drone. In addition, the candidate communication drone may radiate RF communications using the set RF communication parameters to begin taking over communication services from the requesting communication drone upon arriving at the target position."
Microphone attached remote controller,https://lens.org/023-165-562-352-949,2004,"A microphone attached remote controller mainly comprises a coupling unit, a switch unit, a first control unit, a sensor, a second control unit, an amplifier, and a wireless emitter. When the switch unit is triggered, the first control unit will forward a signal to disable the second control unit and enter a remote control mode, or the first control unit is supposed to have its scanning function temporarily paused and enter a microphone mode for input, amplification, and reproduction of audio signals."
Method for inspecting and/or manipulating a beam using an unmanned aerial vehicle and unmanned aerial vehicle suitable therefor,https://lens.org/009-353-982-039-140,2020,"Method for inspecting and/or manipulating a beam at a lower side of a roof or deck, the beam including a strip, the method comprising the steps of: providing an unmanned aerial vehicle, UAV, wherein the UAV comprises a body, a number of rotors, a first arm; and an inspection and/or manipulation tool; - while the first arm is in the first position, flying the UAV towards the beam; - when the UAV contacts the beam, moving the first arm from the first position to the second position such that the end of the first arm is moved to a position vertically above the strip; - reduce the propulsion force until the UAV hangs from the beam with the end of the arm in contact with and supported by the strip; and - inspecting and/or manipulating the beam, using the inspection and/or manipulation tool, while the UAV hangs from the beam."
A SYSTEM AND A METHOD FOR FACILITATING TESTING OF PLURALITY OF DEVICES USING A DRONE,https://lens.org/187-248-854-995-162,2015,"The present disclosure discloses system 102 and a method for facilitating testing of a plurality of devices 136 using a drone 130. At first, locating module 116 locates position of the drone 130 relative to the plurality of devices 136. Further, receiving module 118 receives an image, of a device of the plurality of devices 136, from image capturing unit 132 of the drone 130. Then, the comparing module 120 compares the image with a reference image corresponding to the device. Based on the comparison, the determining module 122 determines an action to be performed for testing the device. Further, facilitating module 124 facilitates the testing by enabling a snout associated with the drone to perform the action on the device."
"AUTOMATICALLY CONTROLLED DIRECTIONAL SPEAKER, AND LAMP THEREOF",https://lens.org/026-308-548-932-554,2017,"An automatically controlled directional speaker includes a sound amplifying device, an image capture device, a computing device, an azimuth control motor and an amplitude control unit. The image capture device is provided for detecting the status of surrounding environment to generate image information, and the computing device is communicatively coupled to the image capture device for determining whether there is at least one face information in the image information, and the azimuth control motor is coupled to the sound amplifying device for controlling the azimuth of an output sound of the sound amplifying device according to the face information, and the amplitude control unit is communicatively coupled to the sound amplifying device for controlling the volume of the output sound of the sound amplifying device according to the face information. The speaker may be combined with a lamp to form an LED lamp with broadcasting and illumination functions."
"Automatically controlled directional speaker, and lamp thereof",https://lens.org/103-986-418-833-201,2017,"An automatically controlled directional speaker includes a sound amplifying device, an image capture device, a computing device, an azimuth control motor and an amplitude control unit. The image capture device is provided for detecting the status of surrounding environment to generate image information, and the computing device is communicatively coupled to the image capture device for determining whether there is at least one face information in the image information, and the azimuth control motor is coupled to the sound amplifying device for controlling the azimuth of an output sound of the sound amplifying device according to the face information, and the amplitude control unit is communicatively coupled to the sound amplifying device for controlling the volume of the output sound of the sound amplifying device according to the face information. The speaker may be combined with a lamp to form an LED lamp with broadcasting and illumination functions."
FIRE EXTINGUISHING FIREFIGHTING DRONE,https://lens.org/162-800-830-250-034,2018,"The present invention relates to a fire extinguishing firefighting drone which, in case of a fire in a house, a structure, a building, or the like, can be rapidly introduced and extinguish a fire in an early stage of the fire, and can be remotely operated in an unmanned manner through connection with a central control system. The fire extinguishing firefighting drone includes a flight unit configured to include propeller units, a disaster prevention turret unit configured to spray a fire-extinguishing chemical, a plurality of movement units configured to move a body unit, and a disaster prevention means unit configured to be provided with items adapted to spray a fire-extinguishing chemical, to launch a fire-extinguishing bomb, or to save lives."
Fire extinguishing firefighting drone,https://lens.org/021-652-276-299-089,2019,"The present invention relates to a fire extinguishing firefighting drone which, in case of a fire in a house, a structure, a building, or the like, can be rapidly introduced and extinguish a fire in an early stage of the fire, and can be remotely operated in an unmanned manner through connection with a central control system. The fire extinguishing firefighting drone includes a flight unit configured to include propeller units, a disaster prevention turret unit configured to spray a fire-extinguishing chemical, a plurality of movement units configured to move a body unit, and a disaster prevention means unit configured to be provided with items adapted to spray a fire-extinguishing chemical, to launch a fire-extinguishing bomb, or to save lives."
FIRE EXTINGUISHING FIREFIGHTING DRONE,https://lens.org/177-630-934-275-717,2018,"The present invention relates to a fire extinguishing firefighting drone which, in case of a fire in a house, a structure, a building, or the like, can be rapidly introduced and extinguish a fire in an early stage of the fire, and can be remotely operated in an unmanned manner through connection with a central control system. The fire extinguishing firefighting drone includes a flight unit configured to include propeller units, a disaster prevention turret unit configured to spray a fire-extinguishing chemical, a plurality of movement units configured to move a body unit, and a disaster prevention means unit configured to be provided with items adapted to spray a fire-extinguishing chemical, to launch a fire-extinguishing bomb, or to save lives."
AN UNMANNED AERIAL VEHICLE,https://lens.org/167-138-851-443-984,2021,"An unmanned aerial vehicle, having a main body comprising at least an elongate backbone with a forward end piece and a rearward end piece. The end pieces are wider than the backbone and comprise coupling facilities for respective rotor arms, each said rotor arm configured for supporting motor and propeller assemblies. The unmanned aerial vehicle further comprises a pair of elongated batteries. The end pieces and at least a portion of the backbone form receptacles on both sides of the backbone for releasably receiving respective electric batteries, wherein the batteries, backbone and end pieces form an elongate and substantially rectangular body assembly."
Home automation system,https://lens.org/114-472-505-251-104,2003,"Home automation system (31) comprising an array of functional devices (37), a plurality of input devices (38) associated with the array of functional devices and a control unit (49), interconnected via radio link and constituting a home automation system (32). The system (31) is employed in combination with an autonomous safety/security system (33) having input sensors (41), local and/or remote signalling devices (42) and a control unit (43) between the sensors and the signalling devices. The system also comprises connecting means between the control unit (43) of the safety/security system and the control unit (49) of the automation system (32) for activation of the safety/security system by the automation system and/or for activation of the automation system by the safety/security system."
METHOD AND DEVICE FOR RESCUE MISSION ASSISTANCE,https://lens.org/138-935-590-649-983,2020,"A method at a Unmanned Aerial Vehicle (UAV), and a UAV, adapted therefore, is adapted for enabling assisting in a rescue mission, where the method comprise: initiating a first localization of at least one body or object (300); initiating an analysis, for determining, at least partly based on the first localization of the at least one body or object, a need for activities (305), and initiating the determined activities (310), comprising applying floatable foam to an area on or in close proximity to the at least one body or object, while applying, to the floatable foam, a recognizable means capable of assisting in a second localization of the at least one body or object."
Jet-pump-based autonomous underwater vehicle and method for coupling to ocean bottom during marine seismic survey,https://lens.org/024-304-708-437-413,2016,"An autonomous underwater vehicle (AUV) is configured to record seismic signals during a marine seismic survey. The AUV includes a body having a base (B) and first and second sides (A, C), the body having a head part and a tail part; a propulsion system for guiding the AUV to a final target on the ocean bottom; jet pumps connected to corresponding nozzles on the first and second sides (A, C); a control device connected to the jet pumps; and a seismic sensor configured to record seismic signals. The jet pumps are actuated by the control device in a given sequence so that the base (B) penetrates into the ocean bottom."
JET-PUMP-BASED AUTONOMOUS UNDERWATER VEHICLE AND METHOD FOR COUPLING TO OCEAN BOTTOM DURING MARINE SEISMIC SURVEY,https://lens.org/163-032-510-312-707,2014,"An autonomous underwater vehicle (AUV) is configured to record seismic signals during a marine seismic survey. The AUV includes a body having a base (B) and first and second sides (A, C), the body having a head part and a tail part; a propulsion system for guiding the AUV to a final target on the ocean bottom; jet pumps connected to corresponding nozzles on the first and second sides (A, C); a control device connected to the jet pumps; and a seismic sensor configured to record seismic signals. The jet pumps are actuated by the control device in a given sequence so that the base (B) penetrates into the ocean bottom."
Remote-controlling commander with multi-function rotary dial,https://lens.org/070-539-544-726-677,1996,"A remote-controlling commander includes a rotary dial rotatably mounted on a commander housing for manual operation of the user. The commander also includes a position detector for monitoring angular position of the rotary dial, in which the angular position and/or angular displacement of the rotary dial represents which operation of the apparatus is to be controlled and an encoder for producing an encoded signal variable depending upon the angular position and/or angular displacement of the rotary dial. The encoded signal is transmitted through a transmitter to a receiver provided in the apparatus to be controlled. The received signal is decoded in the apparatus to trigger the function represented by the received signal. The received signal from the remote-controlling commander may be used to perform functions associated with a VTR, such as timing of video recording, picture searching, channel timing, and the like."
Remote-controlling commander with multi-function rotary dial,https://lens.org/014-611-102-088-607,1989,"A remote-controlling commander includes a rotary dial rotatably mounted on a commander housing for manual operation of the user. The commander also includes a position detector for monitoring angular position of the rotary dial, in which the angular position and/or angular displacement of the rotary dial represents which operation of the apparatus is to be controlled and an encoder for producing an encoded signal variable depending upon the angular position and/or angular displacement of the rotary dial. The encoded signal is transmitted through a transmitter to a receiver provided in the apparatus to be controlled. The received signal is decoded in the apparatus to trigger the function represented by the received signal. The received signal from the remote-controlling commander may be used to perform functions associated with a VTR, such as timing of video recording, picture searching, channel timing, and the like."
AERIAL DEVICE HAVING A THREE-DIMENSIONAL MEASUREMENT DEVICE,https://lens.org/158-061-240-933-387,2019,"A three-dimensional (3D) coordinate measuring system is provided. The system includes an aerial measuring device that has an aerial drone and a 3D measurement device. The 3D measurement device being rotatably attached to the aerial drone, the aerial drone is movable from a first position to a stationary second position. The 3D measurement device being configured to optically measure points on the surface of an object. The system further includes one or more processors configured to execute nontransitory computer readable instructions. The computer readable instructions comprise: moving the aerial measuring device from the first position; landing the aerial measuring device at the second position; rotating the 3D measurement device to optically measure a first object point; and determining a first 3D coordinates of the first object point with the 3D measuring device."
Aerial device having a three-dimensional measurement device,https://lens.org/180-712-561-672-724,2019,"A three-dimensional (3D) coordinate measuring system is provided. The system includes an aerial measuring device that has an aerial drone and a 3D measurement device. The 3D measurement device being rotatably attached to the aerial drone, the aerial drone is movable from a first position to a stationary second position. The 3D measurement device being configured to optically measure points on the surface of an object. The system further includes one or more processors configured to execute nontransitory computer readable instructions. The computer readable instructions comprise: moving the aerial measuring device from the first position; landing the aerial measuring device at the second position; rotating the 3D measurement device to optically measure a first object point; and determining a first 3D coordinates of the first object point with the 3D measuring device."
AERIAL DEVICE HAVING A THREE-DIMENSIONAL MEASUREMENT DEVICE,https://lens.org/113-896-952-194-79X,2018,"A three-dimensional (3D) coordinate measuring system is provided. The system includes an aerial measuring device that has an aerial drone and a 3D measurement device. The 3D measurement device being rotatably attached to the aerial drone, the aerial drone is movable from a first position to a stationary second position. The 3D measurement device being configured to optically measure points on the surface of an object. The system further includes one or more processors configured to execute nontransitory computer readable instructions. The computer readable instructions comprise: moving the aerial measuring device from the first position; landing the aerial measuring device at the second position; rotating the 3D measurement device to optically measure a first object point; and determining a first 3D coordinates of the first object point with the 3D measuring device."
Ionizing radiation detecting device based on remotely-piloted quadcopter,https://lens.org/069-000-830-262-24X,2015,"The invention relates to an ionizing radiation detecting device based on a remotely-piloted quadcopter. The ionizing radiation detecting device comprises the quadcopter, a motor I, a rotary rod, a transverse rod, a swing rod, a camera, a transmission case I, a transmission case II, an ionizing radiation detector and a remote controller, wherein the motor I is mounted below the quadcopter and connected to a 2.4G wireless receiving module, the rotary rod is vertically mounted on the rotary shaft of the motor I, the transverse rod is transversely mounted on the rotary rod, the swing rod is mounted on the transverse rod through a pin, the camera is mounted at the head end of the swing rod, the transmission case I and the transmission case II are respectively fixed on the transverse rod and at the bottom of the rotary rod, the ionizing radiation detector is mounted on the transmission case II, and the remote controller is used for remotely controlling the quadcopter. The quadcopter is controlled by the remote controller to take off and fly to an appointed position, the motor I is controlled to rotate to allow the rotary rod to drive the two transmission cases to rotate, 360-degree video collecting is achieved, the ionizing radiation detector is driven to rotate to allow the detecting probe of the ionizing radiation detector to aim at a to-be-detected target, video signals are transmitted to the liquid crystal display screen of the remote controller for image display and are saved, and the detected data can be transmitted to the radiation data display screen in real time for real-time display and storage."
DIGITAL TETHERING FOR TRACKING WITH AUTONOMOUS AERIAL ROBOT,https://lens.org/080-686-331-678-045,2014,"An aerial device automatically maintains a relative position with respect to a target. The aerial device can set a relative multi-dimensional position with respect to the target. The target can have an indicator (e.g., a visual marker for image capture tracking, or a radio indicator for tracking via signaling) that the aerial device reads. The aerial device can automatically adjust its flight path in response to movement of the target as indicated by the indicator. Thus, the aerial device can maintain a digital tether, moving with the target to maintain substantially the same relative position with respect to the target, tracking the target in multiple dimensions."
DIGITAL TETHERING FOR TRACKING WITH AUTONOMOUS AERIAL ROBOT,https://lens.org/170-052-560-873-539,2015,"An aerial device automatically maintains a relative position with respect to a target. The aerial device can set a relative multi-dimensional position with respect to the target. The target can have an indicator (e.g., a visual marker for image capture tracking, or a radio indicator for tracking via signaling) that the aerial device reads. The aerial device can automatically adjust its flight path in response to movement of the target as indicated by the indicator. Thus, the aerial device can maintain a digital tether, moving with the target to maintain substantially the same relative position with respect to the target, tracking the target in multiple dimensions."
DIGITAL TETHERING FOR TRACKING WITH AUTONOMOUS AERIAL ROBOT,https://lens.org/077-826-513-327-602,2015,"An aerial device automatically maintains a relative position with respect to a target. The aerial device can set a relative multi-dimensional position with respect to the target. The target can have an indicator (e.g., a visual marker for image capture tracking, or a radio indicator for tracking via signaling) that the aerial device reads. The aerial device can automatically adjust its flight path in response to movement of the target as indicated by the indicator. Thus, the aerial device can maintain a digital tether, moving with the target to maintain substantially the same relative position with respect to the target, tracking the target in multiple dimensions."
DIGITAL TETHERING FOR TRACKING WITH AUTONOMOUS AERIAL ROBOT,https://lens.org/044-135-638-632-563,2016,"An aerial device automatically maintains a relative position with respect to a target. The aerial device can set a relative multi-dimensional position with respect to the target. The target can have an indicator (e.g., a visual marker for image capture tracking, or a radio indicator for tracking via signaling) that the aerial device reads. The aerial device can automatically adjust its flight path in response to movement of the target as indicated by the indicator. Thus, the aerial device can maintain a digital tether, moving with the target to maintain substantially the same relative position with respect to the target, tracking the target in multiple dimensions."
Digital tethering for tracking with autonomous aerial robot,https://lens.org/128-129-398-075-378,2016,"An aerial device automatically maintains a relative position with respect to a target. The aerial device can set a relative multi-dimensional position with respect to the target. The target can have an indicator (e.g., a visual marker for image capture tracking, or a radio indicator for tracking via signaling) that the aerial device reads. The aerial device can automatically adjust its flight path in response to movement of the target as indicated by the indicator. Thus, the aerial device can maintain a digital tether, moving with the target to maintain substantially the same relative position with respect to the target, tracking the target in multiple dimensions."
METHOD AND APPARATUS FOR MANAGING LARGE AREA LIGHTING,https://lens.org/020-260-235-265-414,2022,A camera system for a venue including a camera mounted above the venue; a server including artificial intelligence (AI) adapted to follow a subject having a position; the AI adapted to generate aiming instructions based on the position of the subject. The camera being in communication with the server to receive and implement the aiming instructions. The camera system may include a wide area LED light mounted to a light pole. The camera may be mounted to the light pole. The camera system may include wide area LED light is in communication with the server. The wide area LED light produces light at an intensity and the server is adapted to vary the intensity based on the position of the subject.
METHOD AND APPARATUS FOR MANAGING LARGE AREA LIGHTING,https://lens.org/020-260-235-265-414,2022,A camera system for a venue including a camera mounted above the venue; a server including artificial intelligence (AI) adapted to follow a subject having a position; the AI adapted to generate aiming instructions based on the position of the subject. The camera being in communication with the server to receive and implement the aiming instructions. The camera system may include a wide area LED light mounted to a light pole. The camera may be mounted to the light pole. The camera system may include wide area LED light is in communication with the server. The wide area LED light produces light at an intensity and the server is adapted to vary the intensity based on the position of the subject.
SYSTEMS AND METHODS FOR GAMIFICATION OF DRONE BEHAVIOR USING ARTIFICIAL INTELLIGENCE,https://lens.org/050-047-300-607-173,2019,"A conventional drone with an image sensor can track an object identified by a user in its image sensor's field of view. The user draws a bounding box around the object, and as long as the drone keeps the object in the bounding box, the drone can track the object. Unfortunately, this tracking scheme isn't robust; if the object changes shape or aspect ratio or is occluded by another object, the drone will lose the object. Using a neural network to identify the object in the image stream from the image sensor increases the robustness of the tracking; a trained neural network can recognize the object from a variety of angles without any user input (no user-drawn bounding box necessary). Moreover, if the neural network is a lifelong deep neural network (L-DNN), it can learn new objects on the fly. The drone can respond by moving in a predetermined fashion with respect to the object."
Gas Detection Device and Gas Detection Method,https://lens.org/122-558-013-189-487,2018,"The unmanned flying body is provided with a gas detector, a distance meter, and an altitude controller. The gas detector emits diagonally downward to the forward side in a moving direction of the unmanned flying body a detecting light frequency-modulated by a predetermined modulation frequency setting a predetermined frequency as a central frequency. The gas detector receives the light, returned from a measurement target to which the detecting light is emitted (an area on a pipe member for transferring gas, irradiated with the detecting light), as first light. The measurement target is checked for gas leakage based on the received first light. The distance meter measures the distance between the gas detector and the measurement target. The altitude controller controls the flight altitude of the unmanned flying body based on the measured distance."
GAS DETECTION DEVICE AND GAS DETECTION METHOD,https://lens.org/190-903-776-566-560,2018,"The unmanned flying body is provided with a gas detector, a distance meter, and an altitude controller. The gas detector emits diagonally downward to the forward side in a moving direction of the unmanned flying body a detecting light frequency-modulated by a predetermined modulation frequency setting a predetermined frequency as a central frequency. The gas detector receives the light, returned from a measurement target to which the detecting light is emitted (an area on a pipe member for transferring gas, irradiated with the detecting light), as first light. The measurement target is checked for gas leakage based on the received first light. The distance meter measures the distance between the gas detector and the measurement target. The altitude controller controls the flight altitude of the unmanned flying body based on the measured distance."
Secondary sources of navigation data for improved control of an automonous vehicle,https://lens.org/147-508-201-840-961,2015,"A method comprises controlling the operation of an autonomous vehicle using navigation data from a first data source until the autonomous vehicle reaches a specific area for which a second data source has navigation data for the specific area, and using navigation data from the second data source to control operation of the autonomous vehicle while the autonomous vehicle is within the specific area. Non-limiting examples of a specific area include construction zones, private property, secure areas, and state parks. When the autonomous vehicle reaches these specific areas, navigation data specific to this area may be downloaded from a second data source."
"Apparatus, method, and medium for localizing moving robot and transmitter",https://lens.org/091-477-032-088-561,2008,"Provided are an apparatus allowing a moving robot to localize a user, or localizing the moving robot from a fixed location, and a method and medium thereof. The apparatus includes a motion controller to control the moving robot such that the sensor passes a plurality of measurement points by rotating the moving robot, a distance measuring unit, which includes the sensor that senses predetermined waves generated from the transmitter, to measure distances between the sensor and the transmitter at the plurality of measurement points, a rotational angle measuring unit to measure rotational angles of the moving robot at the measurement points, and a location calculator to calculate relative locations using input values of the measured distances, the measured rotational angles, and the radius of a circle determined by the sensor resulting from the rotation of the moving robot."
"Apparatus, method, and medium for localizing moving robot and transmitter",https://lens.org/190-780-863-405-848,2011,"Provided are an apparatus allowing a moving robot to localize a user, or localizing the moving robot from a fixed location, and a method and medium thereof. The apparatus includes a motion controller to control the moving robot such that the sensor passes a plurality of measurement points by rotating the moving robot, a distance measuring unit, which includes the sensor that senses predetermined waves generated from the transmitter, to measure distances between the sensor and the transmitter at the plurality of measurement points, a rotational angle measuring unit to measure rotational angles of the moving robot at the measurement points, and a location calculator to calculate relative locations using input values of the measured distances, the measured rotational angles, and the radius of a circle determined by the sensor resulting from the rotation of the moving robot."
END GATE STRUCTURE WITH AUTOMATIC POWER DOWN,https://lens.org/024-416-791-186-948,2019,"Techniques are described for tracking and determining a three dimensional path travelled by controlled unmanned aircraft (i.e. drones) or other moving objects. By monitoring the strength of communication signals transmitted by an object, the strength of control signals received by the object, and altitude data generated by the object, its three dimensional path is determined. For example, these techniques can be applied to racing drones to determine their positions on a course. An end gate structure for such a course that can automatically transmit disable signals to the drones upon completing the course is also described."
THREE-DIMENSIONAL PATHWAY TRACKING SYSTEM,https://lens.org/118-696-563-195-284,2019,"Techniques are described for tracking and determining a three dimensional path travelled by controlled unmanned aircraft (i.e. drones) or other moving objects. By monitoring the strength of communication signals transmitted by an object, the strength of control signals received by the object, and altitude data generated by the object, its three dimensional path is determined. For example, these techniques can be applied to racing drones to determine their positions on a course. An end gate structure for such a course that can automatically transmit disable signals to the drones upon completing the course is also described."
Three-dimensional pathway tracking system,https://lens.org/194-025-526-490-312,2020,"Techniques are described for tracking and determining a three dimensional path travelled by controlled unmanned aircraft (i.e. drones) or other moving objects. By monitoring the strength of communication signals transmitted by an object, the strength of control signals received by the object, and altitude data generated by the object, its three dimensional path is determined. For example, these techniques can be applied to racing drones to determine their positions on a course. An end gate structure for such a course that can automatically transmit disable signals to the drones upon completing the course is also described."
Electronic system to be applied in variable resistance exercise machine,https://lens.org/102-352-826-175-913,2003,"A control system is provided for an exercise machine. The control system varies the resistance of the exercise machine. The control system varies the resistance based on voice commands, based on commands programmed by the user, and based on how the user performs an exercise. The exercise machine can include a pneumatic system that can produce constant or variable resistance during on exercise, can include cable exercises, can include exercises utilizing a cam, and can include a cam that can be moved between different operative positions."
Electronic system to be applied in variable resistance exercise machine,https://lens.org/074-820-428-657-168,2005,"A control system is provided for an exercise machine. The control system varies the resistance of the exercise machine. The control system varies the resistance based on voice commands, based on commands programmed by the user, and based on how the user performs an exercise. The exercise machine can include a pneumatic system that can produce constant or variable resistance during on exercise, can include cable exercises, can include exercises utilizing a cam, and can include a cam that can be moved between different operative positions."
Electronic system to be applied invariable resistance exercise machine,https://lens.org/046-752-699-347-922,2008,"A control system is provided for an exercise machine. The control system varies the resistance of the exercise machine. The control system varies the resistance based on voice commands, based on commands programmed by the user, and based on how the user performs an exercise. The exercise machine can include a pneumatic system that can produce constant or variable resistance during on exercise, can include cable exercises, can include exercises utilizing a cam, and can include a cam that can be moved between different operative positions."
Electronic system to be applied invariable resistance exercise machine,https://lens.org/102-212-150-280-662,2009,"A control system is provided for an exercise machine. The control system varies the resistance of the exercise machine. The control system varies the resistance based on voice commands, based on commands programmed by the user, and based on how the user performs an exercise. The exercise machine can include a pneumatic system that can produce constant or variable resistance during on exercise, can include cable exercises, can include exercises utilizing a cam, and can include a cam that can be moved between different operative positions."
Electronic system to be applied in variable resistance exercise machine,https://lens.org/157-145-543-460-355,2008,"A control system is provided for an exercise machine. The control system varies the resistance of the exercise machine. The control system varies the resistance based on voice commands, based on commands programmed by the user, and based on how the user performs an exercise. The exercise machine can include a pneumatic system that can produce constant or variable resistance during on exercise, can include cable exercises, can include exercises utilizing a cam, and can include a cam that can be moved between different operative positions."
Remote control for a drilling machine,https://lens.org/099-785-763-376-044,2008,"A method and apparatus for remotely controlling a machine. A remote operator controls a tracking device including a signal system for selectively emitting a remote enable signal. The remote enable signal is relayed to a control system for the machine. The control system is proximate to the machine and is adapted to enable at least one action of the machine upon detecting the remote enable signal. The machine is also adapted to disable the same action of the drilling machine upon detecting an absence of the remote enable signal for a predetermined number of intervals, each interval being of a preselected duration."
Method for inspecting and/or manipulating a beam using an unmanned aerial vehicle,https://lens.org/012-328-836-586-49X,2019,"Method for inspecting and/or manipulating a beam at a lower side of a roof or deck, the beam including a strip, the method comprising the steps of: providing an unmanned aerial vehicle, UAV, wherein the UAV comprises a body, a number of rotors, a first arm; and an inspection and/or manipulation tool; - while the first arm is in the first position, flying the UAV towards the beam; - when the UAV contacts the beam, moving the first arm from the first position to the second position such that the end ofthe first arm is moved to a position vertically above the strip; - reduce the propulsion force until the UAV hangs from the beam with the end ofthe arm in contact with and supported by the strip; and - inspecting and/or manipulating the beam, using the inspection and/or manipulation tool, while the UAV hangs from the beam."
"Methods, Devices, and Systems for Controlling Smart Lighting Objects to Establish a Lighting Condition",https://lens.org/139-996-580-653-159,2015,"A device controls a lighting condition of smart objects. A networking framework is executed on the device and the smart objects. An RF signal is broadcast from the device to the smart objects. The signal requests the objects to transmit an ultrasound signal. Ultrasound signals from the objects are received in the device via microphones. A range and direction to each object may be determined based on reception times of the ultrasound signals. A map of the location of the objects is generated. The objects are controlled, via the networking framework, based on the map. A user interface overlay that shows the current lighting condition and location of objects using icons is presented on the device display. The icons are interactive controls for the objects, which may be interacted with for control of the corresponding object. The objects may be manually or automatically controlled to achieve a lighting condition."
"Methods, devices, and systems for controlling smart lighting objects to establish a lighting condition",https://lens.org/163-331-151-604-918,2016,"A device controls a lighting condition of smart objects. A networking framework is executed on the device and the smart objects. An RF signal is broadcast from the device to the smart objects. The signal requests the objects to transmit an ultrasound signal. Ultrasound signals from the objects are received in the device via microphones. A range and direction to each object may be determined based on reception times of the ultrasound signals. A map of the location of the objects is generated. The objects are controlled, via the networking framework, based on the map. A user interface overlay that shows the current lighting condition and location of objects using icons is presented on the device display. The icons are interactive controls for the objects, which may be interacted with for control of the corresponding object. The objects may be manually or automatically controlled to achieve a lighting condition."
METHODS AND SYSTEMS FOR TRANSPORTATION USING UNMANNED AERIAL VEHICLES,https://lens.org/171-365-893-160-645,2022,An unmanned aerial vehicle (UAV) for transporting a payload is provided. The UAV comprises a body and one or more propellers rotatably connected to the body. The UAV further comprises a battery mounted to the body. The battery is releasable from the bottom of the UAV. The UAV further comprises a payload container mounted to the body. The payload container is releasable from the bottom of the UAV to a landing platform associated with a UAV station.
METHODS AND SYSTEMS FOR TRANSPORTATION USING UNMANNED AERIAL VEHICLES,https://lens.org/120-690-129-986-58X,2017,An unmanned aerial vehicle (UAV) for transporting a payload is provided. The UAV comprises a body and one or more propellers rotatably connected to the body. The UAV further comprises a battery mounted to the body. The battery is releasable from the bottom of the UAV. The UAV further comprises a payload container mounted to the body. The payload container is releasable from the bottom of the UAV to a landing platform associated with a UAV station.
METHODS AND SYSTEMS FOR TRANSPORTATION USING UNMANNED AERIAL VEHICLES,https://lens.org/118-513-490-559-686,2020,An unmanned aerial vehicle (UAV) for transporting a payload is provided. The UAV comprises a body and one or more propellers rotatably connected to the body. The UAV further comprises a battery mounted to the body. The battery is releasable from the bottom of the UAV. The UAV further comprises a payload container mounted to the body. The payload container is releasable from the bottom of the UAV to a landing platform associated with a UAV station.
METHODS AND SYSTEMS FOR TRANSPORTATION USING UNMANNED AERIAL VEHICLES,https://lens.org/086-036-681-429-966,2017,An unmanned aerial vehicle (UAV) for transporting a payload is provided. The UAV comprises a body and one or more propellers rotatably connected to the body. The UAV further comprises a battery mounted to the body. The battery is releasable from the bottom of the UAV. The UAV further comprises a payload container mounted to the body. The payload container is releasable from the bottom of the UAV to a landing platform associated with a UAV station.
Unmanned aerial vehicle with twin-engine fore/AFT configuration and associated systems and methods,https://lens.org/034-299-904-785-350,2016,"An Unmanned Aerial Vehicle (UAV) for use in military and civilian functions, including a UAV being optimized by utilizing a front and a rearmost engine positioning in addition to an engine operating system for maximum fuel efficiency and performance."
REMOTE CONTROL SYSTEM,https://lens.org/106-390-520-681-912,2014,"A remote control apparatus includes a moving apparatus that has a control unit that stores map information and a target position and controls a tracking move to the target position along a moving path, and a remote control unit that transmits the target position input by a manipulating unit to the moving apparatus, and the control unit detects an input value of the manipulating unit as an amount of change, and autonomously moves the moving apparatus in a tracking manner while changing the target position in accordance with the amount of change."
USING ENTERTAINMENT SYSTEM REMOTE COMMANDER FOR AUDIO SYSTEM CALIBRATION,https://lens.org/012-280-187-499-141,2022,"A remote commander (RC) for a TV or other entertainment system component has a microphone. A device can query the RC for its serial number, access the Internet with the serial number to look up characteristics of the microphone, and then knowing the characteristics, use the RC microphone to detect sound such as speaker test chirps to calibrate an audio system in a convenient and user-friendly manner while achieving the accuracy of calibration that can only be obtained by using a calibrated microphone system."
METHOD FOR INSTALLING AN OBJECT USING AN UNMANNED AERIAL VEHICLE,https://lens.org/079-641-736-087-601,2016,"A method for using an unmanned aerial vehicle to install objects on wire and catenary structures is described. The method includes tagging the location, attaching the object to the UAV, navigating the UAV to the position, attaching the object, testing the attachment, releasing the object, inspecting the attachment, and returning the UAV to the ground. Sensors, flight control systems, means for attachment, and variations of embodiments of the methods, systems, and mechanical devices are described."
Method for installing an object using an unmanned aerial vehicle,https://lens.org/014-959-240-077-831,2018,"A method for using an unmanned aerial vehicle to install objects on wire and catenary structures is described. The method includes tagging the location, attaching the object to the UAV, navigating the UAV to the position, attaching the object, testing the attachment, releasing the object, inspecting the attachment, and returning the UAV to the ground. Sensors, flight control systems, means for attachment, and variations of embodiments of the methods, systems, and mechanical devices are described."
DRONE WITH A FRONT-VIEW CAMERA WITH SEGMENTATION OF THE SKY IMAGE FOR AUTO-EXPOSURE CONTROL,https://lens.org/036-450-844-224-720,2017,"The drone comprises a camera (14), an inertial unit (46) measuring the drone angles, and an extractor module (52) delivering image data of a mobile capture area of reduced size dynamically displaced in a direction opposite to that of the variations of angle measured by the inertial unit. The module analyses the image data elements of the useful area to assign to each one a weighting coefficient representative of a probability of belonging to the sky, and defines dynamically a boundary of segmentation (F) of the useful area between sky and ground as a function of these weighting coefficients. Two distinct groups of regions of interest ROIs are defined, for the sky area and for the ground area, respectively, and the dynamic exposure control means are controlled as a function of the image data of the ROIs of one of these groups, in particular by excluding the ROIs of the sky area."
Drone with a front-view camera with segmentation of the sky image for auto-exposure control,https://lens.org/108-198-517-954-193,2019,"The drone comprises a camera (14), an inertial unit (46) measuring the drone angles, and an extractor module (52) delivering image data of a mobile capture area of reduced size dynamically displaced in a direction opposite to that of the variations of angle measured by the inertial unit. The module analyses the image data elements of the useful area to assign to each one a weighting coefficient representative of a probability of belonging to the sky, and defines dynamically a boundary of segmentation (F) of the useful area between sky and ground as a function of these weighting coefficients. Two distinct groups of regions of interest ROIs are defined, for the sky area and for the ground area, respectively, and the dynamic exposure control means are controlled as a function of the image data of the ROIs of one of these groups, in particular by excluding the ROIs of the sky area."
Aerial photography system,https://lens.org/064-170-477-813-02X,1995,"A camera system for taking aerial, still photographs. The system includes a video camera mounted proximate the distal end of a telescoping mast assembly. The mast assembly can be extended, when oriented in a generally-vertical orientation, to effect elevation of the video camera. The video camera mounts a still camera such that lens axes of the video camera and still camera can be made to converge at a desired subject when the video camera has been elevated to a desired height. The system includes controllers for remotely operating motors to effect pan and tilt of the video camera, and to remotely control operation of the still camera."
Systems and methods for UAV docking,https://lens.org/095-224-288-969-020,2022,"An apparatus for housing an unmanned aerial vehicle (UAV) in or on a vehicle includes a landing connection component configured to form a connection between the UAV and the vehicle when the UAV is landed in or on the vehicle, and a cover movable between a plurality of positions to permit the UAV to take off and land in or on the vehicle. The cover includes an antenna or a satellite dish integrated thereto. An orientation of the antenna or the satellite dish is adjustable for tracking a motion of the UAV when the UAV is in flight."
SYSTEMS AND METHODS FOR UAV DOCKING,https://lens.org/143-887-144-175-279,2021,"An apparatus for housing an unmanned aerial vehicle (UAV) in or on a vehicle includes a landing connection component configured to form a connection between the UAV and the vehicle when the UAV is landed in or on the vehicle, and a cover movable between a plurality of positions to permit the UAV to take off and land in or on the vehicle. The cover includes an antenna or a satellite dish integrated thereto. An orientation of the antenna or the satellite dish is adjustable for tracking a motion of the UAV when the UAV is in flight."
Systems and methods for UAV docking,https://lens.org/095-224-288-969-020,2022,"An apparatus for housing an unmanned aerial vehicle (UAV) in or on a vehicle includes a landing connection component configured to form a connection between the UAV and the vehicle when the UAV is landed in or on the vehicle, and a cover movable between a plurality of positions to permit the UAV to take off and land in or on the vehicle. The cover includes an antenna or a satellite dish integrated thereto. An orientation of the antenna or the satellite dish is adjustable for tracking a motion of the UAV when the UAV is in flight."
SECURITY SYSTEM PROVIDING PROTECTION FROM DRONES,https://lens.org/032-110-509-414-846,2022,"The present invention is a security system for providing a zone (area) of protection from triphibian drones in the form of an apparatus comprising sonic sensors to sonically detect and triangulate the presence and current position of remotely controlled, operated, or otherwise unmanned vehicles within six-hundred meters of said apparatus; computer enabled software to automatically and securely identify a plurality of users, and to detect, configure, and establish a perimeter for a home or ranch with two or more sensors, and to automatically activate and provide notices and/ or warnings for users and occupants when drones are detected; and software to automatically activate/enable drone countermeasures to prevent intrusion by and provide protection against autonomous vehicles and aerial, aquatic, terrestrial, amphibian, biphibian, and triphibian drones into the space surrounding a home or ranch."
SYSTEM AND METHOD FOR GROUNDTRUTHING AND REMARKING MAPPED LANDMARK DATA,https://lens.org/066-478-406-187-811,2023,"A control system for an autonomous work vehicle includes a controller configured to obtain map data for an area that the autonomous work vehicle is traversing, wherein the map data includes mapped landmarks. The controller is configured to determine a current position of the autonomous work vehicle in the area based on feedback from at least a first sensor and to determine a distance between a landmark in the area from the autonomous work vehicle based on feedback from at least a second sensor and the current position of the autonomous work vehicle. The controller is configured to determine a difference between the distance and an estimated distance between the autonomous work vehicle and the landmark based on the map data and the current position of the autonomous work vehicle. The controller is configured to determine whether the landmark is accurately mapped in the map data."
SYSTEM AND METHOD FOR GROUNDTRUTHING AND REMARKING MAPPED LANDMARK DATA,https://lens.org/066-478-406-187-811,2023,"A control system for an autonomous work vehicle includes a controller configured to obtain map data for an area that the autonomous work vehicle is traversing, wherein the map data includes mapped landmarks. The controller is configured to determine a current position of the autonomous work vehicle in the area based on feedback from at least a first sensor and to determine a distance between a landmark in the area from the autonomous work vehicle based on feedback from at least a second sensor and the current position of the autonomous work vehicle. The controller is configured to determine a difference between the distance and an estimated distance between the autonomous work vehicle and the landmark based on the map data and the current position of the autonomous work vehicle. The controller is configured to determine whether the landmark is accurately mapped in the map data."
Promote two unmanned aerial vehicle control system of duration,https://lens.org/129-913-855-226-844,2016,"The utility model provides a promote two unmanned aerial vehicle control system of duration, it relates to aircraft technical field, GPS receiver and compass module no. 1, telemetering measurement radio transceiver module one, radio control receiver module one, two auto focus camera modules all with female unmanned aerial vehicle CPU mainboard connection, optic fibre docks successfully sensor module, planetary gear case servo motor one, potentiometre position sensor all is connected with butt joint / release linear drive ware motor control module, potentiometre position sensor and planetary gear case servo motor no. 1 are connected, infrared external reflection position sensor module, planetary gear case servo motor no. 2 all is connected with the directional motor control module of unmanned aerial vehicle, the directional motor control module of unmanned aerial vehicle and female unmanned aerial vehicle CPU mainboard connection. Degree of automation is high, easily controls, can be with the time of endurance extension 5 -10 of unmanned aerial vehicle system doubly, control two unmanned aerial vehicle's concatenation and separation in a flexible way, realize the continuous and smooth purpose of working process."
"Rapidly-deployable, drone-based wireless communications systems and methods for the operation thereof",https://lens.org/146-552-825-703-30X,2018,"Drone-based wireless communications systems are provided, as are methods carried-out by such wireless communications systems. In one embodiment, the wireless communications system includes a Satellite Signal Transformation (SST) unit and a plurality of aerial network drones, which can be deployed over a designated geographical area to form a multi-drone network thereover. During operation, the SST unit transmits a network source signal, which contains content extracted from a satellite signal. The multi-drone network receives the network source signal, disseminates drone relay signals containing the content through the multi-drone network, and broadcastings user device signals containing the content over the designated geographical area. In embodiments, the multi-drone network may broadcast multiple different types of user device signals for reception by various different types of user devices located within the designated geographical area, such as an area containing communication infrastructure disabled by a natural disaster, a hostile attack, or other catastrophic event."
Resilient remote surveillance system and method,https://lens.org/160-383-193-615-207,2016,"A method, system, and medium are provided for remotely monitoring a surveillance area, including deploying a secure enclosure that includes a controller coupled to a switch, a router, and a video-server appliance, the controller configured to provide remote operation and status information presentable via a remote server coupled to the router, and sending video information received by one or more cameras."
Resilient Remote Surveillance System and Method,https://lens.org/050-726-874-450-552,2016,"A method, system, and medium are provided for remotely monitoring a surveillance area, including deploying a secure enclosure that includes a controller coupled to a switch, a router, and a video-server appliance, the controller configured to provide remote operation and status information presentable via a remote server coupled to the router, and sending video information received by one or more cameras."
Electronic device and operating method thereof,https://lens.org/064-551-509-566-633,2018,"An electronic device is provided. The electronic device includes a gimbal; a first camera; a second camera to detect a point of interest on ground; at least one sensor; a first motor; a second motor to operate the first camera and the second camera to maintain horizontality; and at least one processor electrically connected to the first camera, the second camera, the at least one sensor, the first motor, and the second motor, wherein the at least one processor is configured to detect a change in an angle; control the second motor to control the second camera to maintain horizontality; determine whether the point of interest is changed; if the point of interest is not changed, control the first motor to maintain hovering; and, if the point of interest is changed, control the first motor to maintain hovering by moving to original position before moving and compensating for tilt."
ELECTRONIC DEVICE AND OPERATING METHOD THEREOF,https://lens.org/113-255-320-516-930,2018,"An electronic device is provided. The electronic device includes a gimbal; a first camera; a second camera to detect a point of interest on ground; at least one sensor; a first motor; a second motor to operate the first camera and the second camera to maintain horizontality; and at least one processor electrically connected to the first camera, the second camera, the at least one sensor, the first motor, and the second motor, wherein the at least one processor is configured to detect a change in an angle; control the second motor to control the second camera to maintain horizontality; determine whether the point of interest is changed; if the point of interest is not changed, control the first motor to maintain hovering; and, if the point of interest is changed, control the first motor to maintain hovering by moving to original position before moving and compensating for tilt."
UNMANNED AERIAL VEHICLE COMMUNICATION,https://lens.org/174-767-686-691-110,2022,"An unmanned aerial vehicle can be configured to adjust a beam direction, provide path information, act as a base station, act as a cluster head, include an improved directional antenna or array of directional antennas, communicate in a collaboration using belief propagation, receive communications from a serving station aiding in navigation or improved signal performance, or the like."
UNMANNED AERIAL VEHICLE COMMUNICATION,https://lens.org/005-160-269-195-053,2020,"An unmanned aerial vehicle can be configured to adjust a beam direction, provide path information, act as a base station, act as a cluster head, include an improved directional antenna or array of directional antennas, communicate in a collaboration using belief propagation, receive communications from a serving station aiding in navigation or improved signal performance, or the like."
Wearable device enablement for visually impaired user,https://lens.org/168-271-533-791-456,2022,"A wearable device determines an objective based on analyzing a voice of a user, where the wearable device comprises one or more wearable sensors and one or more wearable actuators. The wearable device identifies objects by the one or more wearable sensors. The wearable device determines an action based on the objective and the identified objects and guides the user to achieve and objective by the one or more wearable actuators."
Wearable device enablement for visually impaired user,https://lens.org/168-271-533-791-456,2022,"A wearable device determines an objective based on analyzing a voice of a user, where the wearable device comprises one or more wearable sensors and one or more wearable actuators. The wearable device identifies objects by the one or more wearable sensors. The wearable device determines an action based on the objective and the identified objects and guides the user to achieve and objective by the one or more wearable actuators."
WEARABLE DEVICE ENABLEMENT FOR VISUALLY IMPAIRED USER,https://lens.org/070-906-285-653-718,2022,"A wearable device determines an objective based on analyzing a voice of a user, where the wearable device comprises one or more wearable sensors and one or more wearable actuators. The wearable device identifies objects by the one or more wearable sensors. The wearable device determines an action based on the objective and the identified objects and guides the user to achieve and objective by the one or more wearable actuators."
WEARABLE DEVICE ENABLEMENT FOR VISUALLY IMPAIRED USER,https://lens.org/182-217-585-808-694,2022,"A wearable device determines an objective based on analyzing a voice of a user, where the wearable device comprises one or more wearable sensors and one or more wearable actuators. The wearable device identifies objects by the one or more wearable sensors. The wearable device determines an action based on the objective and the identified objects and guides the user to achieve and objective by the one or more wearable actuators."
"OBSTACLE AVOIDANCE CONTROL METHOD FOR UNMANNED AERIAL VEHICLE, RADAR SYSTEM, AND UNMANNED AERIAL VEHICLE",https://lens.org/119-725-550-004-895,2020,An unmanned aerial vehicle (UAV) obstacle avoidance control method includes: controlling a rotation device to perform a continuous rotation that drives a radar detecting device to rotate continuously. The rotation device is disposed on a body of a UAV and carries the radar detecting device. The method also includes: acquiring detection information of the radar detecting device during the continuous rotation; and controlling the UAV to fly based on the detection information.
Unmanned aerial vehicle and method using the same,https://lens.org/183-287-121-749-446,2020,"An unmanned aerial vehicle (UAV) includes a body, a plurality of rotated propulsion systems, and at least one air bag. The rotated propulsion systems are connected to the body and each includes a blade and an actuator configured to actuate the blade. The air bag is disposed on the body."
UNMANNED AERIAL VEHICLE AND METHOD USING THE SAME,https://lens.org/006-824-429-426-291,2019,"An unmanned aerial vehicle (UAV) includes a body, a plurality of rotated propulsion systems, and at least one air bag. The rotated propulsion systems are connected to the body and each includes a blade and an actuator configured to actuate the blade. The air bag is disposed on the body."
OPTIMIZED VISUALIZATION STREAMING FOR VEHICLE ENVIRONMENT VISUALIZATION,https://lens.org/116-558-349-558-066,2023,"In various examples, sensor data may be captured by sensors of an ego-object, such as a vehicle traveling in a physical environment, and a representation of the sensor data may be streamed from the ego-object to a remote location to facilitate various remote experiences, such as streaming to a remote viewer (e.g., a friend or relative), streaming to a remote or fleet operator, streaming to a mobile app configured to self-park or summon an ego-object, rendering a 3D augmented reality (AR) or virtual reality (VR) representation of the physical environment, and/or others. In some embodiments, the stream includes one or more command channels used to control data collection, rendering, stream content, or even vehicle maneuvers, such as during an emergency, self-park, or summon scenario."
"REMOTE CONTROLLING DEVICE, REMOTE CONTROLLED DEVICE AND METHOD THEREOF",https://lens.org/179-380-775-333-353,2015,"A remote controlling device, a remote controlled device and a method therefor are disclosed. The remote controlling device comprises a device association unit for finding and associating a remote controlled device, a webpage load unit for loading a webpage desired to be viewed, a specific object detection unit for detecting whether there is a specific object in the viewed webpage, an object information acquisition unit for acquiring information on the specific object when the specific object detection unit detects that there is the specific object, an event acquisition unit for acquiring a specific event, and a communication unit for transmitting the acquired specific event and information on the specific object associated with the specific event to the remote controlled device so that the remote controlled device acquires data corresponding to the information from a service terminal in accordance with the information and outputs the same."
Apparatus and method for remote control of lighting equipments,https://lens.org/023-452-003-582-563,2020,"An apparatus (11) for the remote control of lighting apparatuses, in particular emergency lighting apparatuses (12), comprising a transmitter apparatus provided with at least one white light source having controlled activation, a receiver device used as a receiver of digital optical signals (16), which integrates a control, programming and management system managed by a software program (14), and a lighting apparatus (12), which incorporates a receiving circuit comprising a receiver photosensor (13); the transmitter apparatus is constituted by a smartphone (11), which actuates optical commands directed at the lighting apparatus (12), in a form of encoded luminous messages or intensity- and duration-controlled sequences of light variations according to a specific optical code and at different levels of luminosity, by means of a modulating process of the switching-on and the switching-off of the light source integrated in said smartphone (11)."
APPARATUS AND METHOD FOR REMOTE CONTROL OF LIGHTING EQUIPMENTS,https://lens.org/087-060-113-732-269,2019,"An apparatus (11) for the remote control of lighting apparatuses, in particular emergency lighting apparatuses (12), comprising a transmitter apparatus provided with at least one white light source having controlled activation, a receiver device used as a receiver of digital optical signals (16), which integrates a control, programming and management system managed by a software program (14), and a lighting apparatus (12), which incorporates a receiving circuit comprising a receiver photosensor (13); the transmitter apparatus is constituted by a smartphone (11), which actuates optical commands directed at the lighting apparatus (12), in a form of encoded luminous messages or intensity- and duration-controlled sequences of light variations according to a specific optical code and at different levels of luminosity, by means of a modulating process of the switching-on and the switching-off of the light source integrated in said smartphone (11)."
MULTI-ANTENNA SYSTEM AND METHOD FOR REMOTELY CONTROLLING A FUNCTION,https://lens.org/137-166-292-340-961,2007,A system and method for remotely controlling a function. The system includes a transmitter and a receiver control circuit having a plurality of antennas. The transmitter transmits a wireless control signal having first and second signal portions. An antenna is selected based on the first signal portion. A function is performed when the second signal portion is received by the selected antenna and successfully decoded.
Multi-antenna system and method for remotely controlling a function,https://lens.org/094-260-403-474-878,2010,A system and method for remotely controlling a function. The system includes a transmitter and a receiver control circuit having a plurality of antennas. The transmitter transmits a wireless control signal having first and second signal portions. An antenna is selected based on the first signal portion. A function is performed when the second signal portion is received by the selected antenna and successfully decoded.
ONE BUTTON MULTIFUNCTION KEY FOB FOR CONTROLLING A SECURITY SYSTEM,https://lens.org/031-876-009-206-592,2007,"A security device which is a hand held portable remote device such as a key fob that allows a user to interact with a security system using a single button. The security system functions such as arming, disarming, panic, garage door open, lamp on/off, and lamp dimming control will be displayed by the security device as control options and will be selected by a user using a forward, backward, left or right tilting motion and depressing the power on/select button. Once a control option has been selected, the security device will transmit the control option to the security system. The security device has a portable housing, a wireless communication port for interface with a security system, a display panel, an accelerometer device, and processing circuitry. The accelerometer device is used to determine the tilt of the security device and provide a control signal related to the tilt. The security device also has an infrared communication port for downloading control options, and single push button, for turning the security device on and for initiating the transmission of the output signal."
One button multifunction key fob for controlling a security system,https://lens.org/067-182-245-569-408,2009,"A security device which is a hand held portable remote device such as a key fob that allows a user to interact with a security system using a single button. The security system functions such as arming, disarming, panic, garage door open, lamp on/off, and lamp dimming control will be displayed by the security device as control options and will be selected by a user using a forward, backward, left or right tilting motion and depressing the power on/select button. Once a control option has been selected, the security device will transmit the control option to the security system. The security device has a portable housing, a wireless communication port for interface with a security system, a display panel, an accelerometer device, and processing circuitry. The accelerometer device is used to determine the tilt of the security device and provide a control signal related to the tilt. The security device also has an infrared communication port for downloading control options, and single push button, for turning the security device on and for initiating the transmission of the output signal.
"
One button multifunction key fob for controlling a security system,https://lens.org/011-393-714-023-212,2010,"A security device which is a hand held portable remote device such as a key fob that allows a user to interact with a security system using a single button. The security system functions such as arming, disarming, panic, garage door open, lamp on/off, and lamp dimming control will be displayed by the security device as control options and will be selected by a user using a forward, backward, left or right tilting motion and depressing the power on/select button. Once a control option has been selected, the security device will transmit the control option to the security system. The security device has a portable housing, a wireless communication port for interface with a security system, a display panel, an accelerometer device, and processing circuitry. The accelerometer device is used to determine the tilt of the security device and provide a control signal related to the tilt. The security device also has an infrared communication port for downloading control options, and single push button, for turning the security device on and for initiating the transmission of the output signal."
One button multifuncion key fob for controlling a security system,https://lens.org/109-739-123-285-367,2007,"A security device which is a hand held portable remote device such as a key fob that allows a user to interact with a security system using a single button. The security system functions such as arming, disarming, panic, garage door open, lamp on/off, and lamp dimming control will be displayed by the security device as control options and will be selected by a user using a forward, backward, left or right tilting motion and depressing the power on/select button. Once a control option has been selected, the security device will transmit the control option to the security system. The security device has a portable housing, a wireless communication port for interface with a security system, a display panel, an accelerometer device, and processing circuitry. The accelerometer device is used to determine the tilt of the security device and provide a control signal related to the tilt. The security device also has an infrared communication port for downloading control options, and single push button, for turning the security device on and for initiating the transmission of the output signal."
"LED light bulb, lamp fixture with self-networking intercom, system and method therefore",https://lens.org/035-035-076-397-340,2018,"A networked light for illumination and intercom for communications in a single housing, with voice command and control, hands-free. The system in a housing configured to conventional looking lamp, bulb, fixture, lighting devices, suitable for a direct replacement of conventional illuminating devices typical found in homes or buildings. A network of such voice command and control systems may be further monitored and controlled from a base station that facilitates programming, communications, and higher functionality therebetween. The system provides speech recognition for powering on and off, dimming, brightening, and adjusting the lighting to preset, night and emergency settings. The voice recognition command controls the intercom to be active and attentive to requests, connecting two or more locations within a home or building structure, for speech exchanges in communications, via radio frequency transmitting and receiving of signal messages between the individual light and intercom system devices within a network of devices."
A SYSTEM AND A METHOD OF LOCATING ITEMS WITHIN A PARTICULAR RADIUS,https://lens.org/052-901-401-277-516,2013,"A system and a method of locating items within a particular radius includes providing a transmitter within an electronic device. A receiver is also provided on a handheld remote control device. The receiver includes a signal generator which upon activation generates one of either an auditory, visual or vibratory signal within a specified radius."
STRATOSPHERIC DRONE,https://lens.org/155-897-383-018-283,2017,"A stratospheric drone able to operate at an altitude between 17 km and 23 km(ISA), said stratospheric drone comprising: one fuselage; at least two wings; at least one tail;at least two motors and two corresponding propellers; at least one accumulator in each of said wings, so as to partly compensate the lift force on said wings with the weight of the accumulators in said wings; a payload pod at the front of the fuselage, for housing a removable payload,wherein the structure of the drone is designed and optimized for transporting a payload having a maximal mass between 20 and 50 kg."
Unmanned aerial vehicle systems and methods of use,https://lens.org/018-024-950-776-604,2018,"An improved unmanned aerial vehicular system having a rotor head assembly with any balanced number of rotary wings or blades, a generally tubular body assembly, a gimballed neck connecting the head to the body, and a navigation, communications and control unit such as for military and humanitarian operations, including payload delivery and pickup. The vehicle is generally guided using a global positioning satellite signal, and by pre-programmed or real time targeting. The vehicle is generally electrically powered and may be launched by one of (a) hand-launch, (b) air-drop, (c) catapult, (d) tube-launch, or (e) sea launch, and is capable of landing on both static and dynamic targets. Once launched, unmanned aerial vehicles may be formed into arrays on a target area and find use in surveillance, warfare, and in search-and-rescue operations."
Unmanned Aerial Vehicle Systems and Methods of Use,https://lens.org/055-318-985-602-87X,2018,"An improved unmanned aerial vehicular system having a rotor head assembly with any balanced number of rotary wings or blades, a generally tubular body assembly, a gimballed neck connecting the head to the body, and a navigation, communications and control unit such as for military and humanitarian operations, including payload delivery and pickup. The vehicle is generally guided using a global positioning satellite signal, and by pre-programmed or real time targeting. The vehicle is generally electrically powered and may be launched by one of (a) hand-launch, (b) air-drop, (c) catapult, (d) tube-launch, or (e) sea launch, and is capable of landing on both static and dynamic targets. Once launched, unmanned aerial vehicles may be formed into arrays on a target area and find use in surveillance, warfare, and in search-and-rescue operations."
Identification apparatus and method for receiving and processing audible commands,https://lens.org/104-767-019-062-119,2008,"An audible command can be utilized to both permit identification of the speaker and to permit subsequent actions that comprise a corresponding response to the audible command when the identity of the speaker correlates with that of a previously authorized individual. Such identification can be supplemented with other identification mechanisms. Hierarchical levels of permission can be utilized, with or without confidence level thresholds, to further protect the device against unauthorized access and/or manipulation."
IDENTIFICATION APPARATUS AND METHOD,https://lens.org/125-637-051-625-088,2004,"An audible command can be utilized to both permit identification of the speaker and to permit subsequent actions that comprise a corresponding response to the audible command when the identity of the speaker correlates with that of a previously authorized individual. Such identification can be supplemented with other identification mechanisms. Hierarchical levels of permission can be utilized, with or without confidence level thresholds, to further protect the device against unauthorized access and/or manipulation."
"SYSTEM, CONTROLLER AND METHOD USING VIRTUAL REALITY DEVICE FOR ROBOTIC SURGERY",https://lens.org/003-664-427-982-279,2019,"A control unit is provided for a surgical robot system, including a robot configured to operate an end-effector in a surgical site of a patient. The control unit includes a processor configured to transmit acquired live images of a patient, received from an image acquisition device, to a virtual reality (VR) device for display; to receive input data from the VR device, including tracking data from a VR tracking system of the VR device based on a user's response to the live images displayed on a viewer of the display unit of the VR device; to process the input data received from the VR device to determine a target in the patient; to determine a path for the end-effector to reach the target based upon the live images and the processed input data; and to transmit control signals to cause the robot to guide the end-effector to the target via the determined path."
"System, controller and method using virtual reality device for robotic surgery",https://lens.org/160-930-057-392-221,2022,"A control unit is provided for a surgical robot system, including a robot configured to operate an end-effector in a surgical site of a patient. The control unit includes a processor configured to transmit acquired live images of a patient, received from an image acquisition device, to a virtual reality (VR) device for display; to receive input data from the VR device, including tracking data from a VR tracking system of the VR device based on a user's response to the live images displayed on a viewer of the display unit of the VR device; to process the input data received from the VR device to determine a target in the patient; to determine a path for the end-effector to reach the target based upon the live images and the processed input data; and to transmit control signals to cause the robot to guide the end-effector to the target via the determined path."
"System, controller and method using virtual reality device for robotic surgery",https://lens.org/160-930-057-392-221,2022,"A control unit is provided for a surgical robot system, including a robot configured to operate an end-effector in a surgical site of a patient. The control unit includes a processor configured to transmit acquired live images of a patient, received from an image acquisition device, to a virtual reality (VR) device for display; to receive input data from the VR device, including tracking data from a VR tracking system of the VR device based on a user's response to the live images displayed on a viewer of the display unit of the VR device; to process the input data received from the VR device to determine a target in the patient; to determine a path for the end-effector to reach the target based upon the live images and the processed input data; and to transmit control signals to cause the robot to guide the end-effector to the target via the determined path."
"SYSTEM, CONTROLLER AND METHOD USING VIRTUAL REALITY DEVICE FOR ROBOTIC SURGERY",https://lens.org/137-758-816-824-203,2017,"A control unit is provided for a surgical robot system, including a robot configured to operate an end-effector in a surgical site of a patient. The control unit includes a processor configured to transmit acquired live images of a patient, received from an image acquisition device, to a virtual reality (VR) device for display; to receive input data from the VR device, including tracking data from a VR tracking system of the VR device based on a user's response to the live images displayed on a viewer of the display unit of the VR device; to process the input data received from the VR device to determine a target in the patient; to determine a path for the end-effector to reach the target based upon the live images and the processed input data; and to transmit control signals to cause the robot to guide the end-effector to the target via the determined path."
"SYSTEM, CONTROLLER AND METHOD USING VIRTUAL REALITY DEVICE FOR ROBOTIC SURGERY",https://lens.org/093-102-317-863-690,2020,"A control unit is provided for a surgical robot system, including a robot configured to operate an end-effector in a surgical site of a patient. The control unit includes a processor configured to transmit acquired live images of a patient, received from an image acquisition device, to a virtual reality (VR) device for display; to receive input data from the VR device, including tracking data from a VR tracking system of the VR device based on a user's response to the live images displayed on a viewer of the display unit of the VR device; to process the input data received from the VR device to determine a target in the patient; to determine a path for the end-effector to reach the target based upon the live images and the processed input data; and to transmit control signals to cause the robot to guide the end-effector to the target via the determined path."
"Moving robot, user terminal apparatus and control method thereof",https://lens.org/045-024-734-201-557,2018,"A moving robot configured to generate a map of an environment of a territory and allow a user to set a structure of the territory and information on the map used for a location-based service and to use a more intuitively intelligent service is provided. The moving robot includes an operation performer configured to move around a territory and perform a certain operation, a detector configured to collect map building information of the territory, and a controller configured to control the moving robot to move to a set particular area within the territory by referring to the map information of the territory generated based on the collected map building information and control the operation performer to perform the operation with respect to the particular area."
"MOVING ROBOT, USER TERMINAL APPARATUS AND CONTROL METHOD THEREOF",https://lens.org/026-142-030-201-733,2014,"A moving robot configured to generate a map of an environment of a territory and allow a user to set a structure of the territory and information on the map used for a location-based service and to use a more intuitively intelligent service is provided. The moving robot includes an operation performer configured to move around a territory and perform a certain operation, a detector configured to collect map building information of the territory, and a controller configured to control the moving robot to move to a set particular area within the territory by referring to the map information of the territory generated based on the collected map building information and control the operation performer to perform the operation with respect to the particular area."
"MOVING ROBOT, USER TERMINAL APPARATUS AND CONTROL METHOD THEREOF",https://lens.org/141-670-397-935-221,2014,"A moving robot configured to generate a map of an environment of a territory and allow a user to set a structure of the territory and information on the map used for a location-based service and to use a more intuitively intelligent service is provided. The moving robot includes an operation performer configured to move around a territory and perform a certain operation, a detector configured to collect map building information of the territory, and a controller configured to control the moving robot to move to a set particular area within the territory by referring to the map information of the territory generated based on the collected map building information and control the operation performer to perform the operation with respect to the particular area."
UNMANNED AERIAL VEHICLE INCLUDING MOUNTING STRUCTURE FOR PROPELLER,https://lens.org/166-230-801-528-985,2019,"An unmanned aerial vehicle is disclosed. The unmanned aerial vehicle includes a housing, a wireless communication circuit, a navigation circuit, a plurality of propulsion systems, and a propeller. At least one of the plurality of propulsion systems includes a motor, and a construction disposed to the motor. The construction includes a first side, a second side facing the motor in a direction opposite to the first side, a shaft inserting hole disposed to the second side, and a latching protrusion and a latching groove that are extended sequentially inside the shaft inserting hole. The propeller is fastened to the construction, and includes a hub coupled to the first side of the construction, a fixing shaft that protrudes in a direction of the construction that is inserted to the shaft inserting hole of the construction, and at least one protrusion on an outer circumferential surface of the fixing shaft."
WELDING APPARATUS,https://lens.org/003-570-216-483-608,2019,A welding apparatus includes a multi-axis robotic arm having a first end; a welding tool attached to the first end; an image acquisition device attached to the first end and having a light filtering system; the image acquisition device is configured to monitor a welding target and to provide an image of the welding target to an operator; a control unit is configured to control the robotic arm and the welding tool; an input interface for a human operator is associated to the control unit and is configured to provide an input signal to the control unit and to control the robotic arm and welding tool substantially in real time.
Universal Add-On Devices for Feature Enhancement of Openers for Movable Barriers,https://lens.org/156-164-314-531-399,2020,A universal add-on device for controlling a movable barrier opener to open and close a movable barrier includes a control module which wirelessly communicates with a user's mobile electronic device. The opener includes a hand-held remote transmitter having a push-button switch. The hand-held remote transmitter is configured to transmit wireless signals to the opener for initiating the opener to move the movable barrier upon actuation of a push button of the push-button switch. The control module is either connected to an actuator to physically actuate the push-button switch of the hand-held remote transmitter or electrically connected in parallel with the push-button switch to electrically actuate the push-button switch of the hand-held remote transmitter. The device enables a manufacturer's compatible remote transmitter or a universal remote transmitter to be utilized to control the movable barrier using the user's mobile electronic device such as a smart phone.
Universal add-on devices for feature enhancement of openers for movable barriers,https://lens.org/164-324-531-668-500,2022,A universal add-on device for controlling a movable barrier opener to open and close a movable barrier includes a control module which wirelessly communicates with a user's mobile electronic device. The opener includes a hand-held remote transmitter having a push-button switch. The hand-held remote transmitter is configured to transmit wireless signals to the opener for initiating the opener to move the movable barrier upon actuation of a push button of the push-button switch. The control module is either connected to an actuator to physically actuate the push-button switch of the hand-held remote transmitter or electrically connected in parallel with the push-button switch to electrically actuate the push-button switch of the hand-held remote transmitter. The device enables a manufacturer's compatible remote transmitter or a universal remote transmitter to be utilized to control the movable barrier using the user's mobile electronic device such as a smart phone.
Apparatus for stabilizing camera of autonomous vehicle and method thereof,https://lens.org/156-633-101-383-846,2022,An apparatus for stabilizing a camera of an autonomous vehicle includes: a sensor that detects vibration generated and applied to the camera due to a state of a road surface when the autonomous vehicle is traveling; a first actuator that attenuates roll vibration applied to the camera; a second actuator that attenuates pitch vibration applied to the camera; and a controller that controls the first actuator and the second actuator to attenuate the vibration detected by the sensor.
APPARATUS FOR STABILIZING CAMERA OF AUTONOMOUS VEHICLE AND METHOD THEREOF,https://lens.org/196-802-370-009-647,2021,An apparatus for stabilizing a camera of an autonomous vehicle includes: a sensor that detects vibration generated and applied to the camera due to a state of a road surface when the autonomous vehicle is traveling; a first actuator that attenuates roll vibration applied to the camera; a second actuator that attenuates pitch vibration applied to the camera; and a controller that controls the first actuator and the second actuator to attenuate the vibration detected by the sensor.
Apparatus for stabilizing camera of autonomous vehicle and method thereof,https://lens.org/156-633-101-383-846,2022,An apparatus for stabilizing a camera of an autonomous vehicle includes: a sensor that detects vibration generated and applied to the camera due to a state of a road surface when the autonomous vehicle is traveling; a first actuator that attenuates roll vibration applied to the camera; a second actuator that attenuates pitch vibration applied to the camera; and a controller that controls the first actuator and the second actuator to attenuate the vibration detected by the sensor.
AIRCRAFT AUGMENTED REALITY SYSTEM AND METHOD OF OPERATING,https://lens.org/130-682-411-497-31X,2020,"A method for operating an aircraft that includes an autonomous decision making system which can be an aircraft augmented reality system. The aircraft augmented reality system can include a data module, an environment module, and a display module. The aircraft augmented reality system can receive information and environmental data to display augmented reality data on a windshield in the cockpit of an aircraft."
VEHICLE MOUNTED CONTROLLER,https://lens.org/084-985-350-216-132,2005,A vehicle mounted control apparatus includes voice recognition section (5) for recognizing a voice command that a user inputs by means of microphone (8) connected to outside; and a control section (2) that analyzes a cause of incapability of recognition of the voice command when the voice command cannot be recognized by the voice recognition section (5) and changes the display format of a screen of display device (6) connected to outside on the basis of results of the analysis.
Construction site planning for autonomous construction vehicles,https://lens.org/138-254-177-216-283,2021,"A system for controlling an autonomous construction vehicle includes a controller configured to identify a boundary of a construction site, identify a slope within the boundary of the construction site, determine if the slope exceeds a predetermined threshold value, and create a path plan for an autonomous construction vehicle based on whether the first slope exceeds the threshold value to align the movement of the autonomous construction vehicle with the slope."
ARTIFICIAL INTELLIGENCE DEVICE,https://lens.org/032-596-990-555-559,2020,"An artificial intelligence device according to an embodiment of the present invention may include a microphone configured to receive voice; a sound output unit configured to output sound; an artificial intelligence unit configured to acquire context information of a target, based on at least one of an image received from a camera disposed outside and a voice received from the microphone, generate feedback information according to the acquired context information, and determine output volume intensity of the generated feedback information; and a controller configured to control the sound output unit to output the feedback information at the determined output volume intensity."
Artificial intelligence device,https://lens.org/042-303-976-639-298,2021,"An artificial intelligence device according to an embodiment of the present invention may include a microphone configured to receive voice; a sound output unit configured to output sound; an artificial intelligence unit configured to acquire context information of a target, based on at least one of an image received from a camera disposed outside and a voice received from the microphone, generate feedback information according to the acquired context information, and determine output volume intensity of the generated feedback information; and a controller configured to control the sound output unit to output the feedback information at the determined output volume intensity."
Navigation of autonomous mobile robots,https://lens.org/067-360-310-593-754,2022,"An autonomous cleaning robot includes a controller configured to execute instructions to perform one or more operations. The one or more operations includes operating a drive system to move the cleaning robot in a forward drive direction along a first obstacle surface with a side surface of the cleaning robot facing the first obstacle surface, then operating the drive system to turn the cleaning robot such that the side surface of the cleaning robot faces a second obstacle surface, then operating the drive system to move the cleaning robot in a rearward drive direction along the second obstacle surface, and then operating the drive system to move the cleaning robot in the forward drive direction along the second obstacle surface."
Navigation of autonomous mobile robots,https://lens.org/096-384-449-999-968,2023,"An autonomous cleaning robot includes a controller configured to execute instructions to perform one or more operations. The one or more operations includes operating a drive system to move the cleaning robot in a forward drive direction along a first obstacle surface with a side surface of the cleaning robot facing the first obstacle surface, then operating the drive system to turn the cleaning robot such that the side surface of the cleaning robot faces a second obstacle surface, then operating the drive system to move the cleaning robot in a rearward drive direction along the second obstacle surface, and then operating the drive system to move the cleaning robot in the forward drive direction along the second obstacle surface."
Navigation of autonomous mobile robots,https://lens.org/067-360-310-593-754,2022,"An autonomous cleaning robot includes a controller configured to execute instructions to perform one or more operations. The one or more operations includes operating a drive system to move the cleaning robot in a forward drive direction along a first obstacle surface with a side surface of the cleaning robot facing the first obstacle surface, then operating the drive system to turn the cleaning robot such that the side surface of the cleaning robot faces a second obstacle surface, then operating the drive system to move the cleaning robot in a rearward drive direction along the second obstacle surface, and then operating the drive system to move the cleaning robot in the forward drive direction along the second obstacle surface."
Navigation of autonomous mobile robots,https://lens.org/096-384-449-999-968,2023,"An autonomous cleaning robot includes a controller configured to execute instructions to perform one or more operations. The one or more operations includes operating a drive system to move the cleaning robot in a forward drive direction along a first obstacle surface with a side surface of the cleaning robot facing the first obstacle surface, then operating the drive system to turn the cleaning robot such that the side surface of the cleaning robot faces a second obstacle surface, then operating the drive system to move the cleaning robot in a rearward drive direction along the second obstacle surface, and then operating the drive system to move the cleaning robot in the forward drive direction along the second obstacle surface."
NAVIGATION OF AUTONOMOUS MOBILE ROBOTS,https://lens.org/051-320-486-743-296,2023,"An autonomous cleaning robot includes a controller configured to execute instructions to perform one or more operations. The one or more operations includes operating a drive system to move the cleaning robot in a forward drive direction along a first obstacle surface with a side surface of the cleaning robot facing the first obstacle surface, then operating the drive system to turn the cleaning robot such that the side surface of the cleaning robot faces a second obstacle surface, then operating the drive system to move the cleaning robot in a rearward drive direction along the second obstacle surface, and then operating the drive system to move the cleaning robot in the forward drive direction along the second obstacle surface."
NAVIGATION OF AUTONOMOUS MOBILE ROBOTS,https://lens.org/051-320-486-743-296,2023,"An autonomous cleaning robot includes a controller configured to execute instructions to perform one or more operations. The one or more operations includes operating a drive system to move the cleaning robot in a forward drive direction along a first obstacle surface with a side surface of the cleaning robot facing the first obstacle surface, then operating the drive system to turn the cleaning robot such that the side surface of the cleaning robot faces a second obstacle surface, then operating the drive system to move the cleaning robot in a rearward drive direction along the second obstacle surface, and then operating the drive system to move the cleaning robot in the forward drive direction along the second obstacle surface."
NAVIGATION OF AUTONOMOUS MOBILE ROBOTS,https://lens.org/026-783-545-194-691,2022,"An autonomous cleaning robot includes a controller configured to execute instructions to perform one or more operations. The one or more operations includes operating a drive system to move the cleaning robot in a forward drive direction along a first obstacle surface with a side surface of the cleaning robot facing the first obstacle surface, then operating the drive system to turn the cleaning robot such that the side surface of the cleaning robot faces a second obstacle surface, then operating the drive system to move the cleaning robot in a rearward drive direction along the second obstacle surface, and then operating the drive system to move the cleaning robot in the forward drive direction along the second obstacle surface."
UNMANNED AERIAL VEHICLE (UAV) LANDING SYSTEMS AND METHODS,https://lens.org/011-409-521-243-773,2019,A system (100) for landing an unmanned aerial vehicle (UAV) (102) at a destination (202) includes a landing coordination control unit (114) that is configured to switch the UAV (102) from a normal operating mode to a landing mode in response to the UAV (102) entering a regulated airspace (204) in relation to the destination (202). The normal operating mode includes normal instructions for flying and navigating to the destination (202). The landing mode includes landing instructions for a landing sequence into a landing zone (200) at the destination (202).
"AUTONOMOUS SEARCH LIGHT SYSTEM, WINCH SYSTEM COMPRISING AN AUTONOMOUS SEARCH LIGHT SYSTEM, AND AIRCRAFT COMPRISING AN AUTONOMOUS SEARCH LIGHT SYSTEM",https://lens.org/084-015-345-489-665,2022,An autonomous search light system for being mounted to an aircraft includes a search light for emitting an adjustable light output; an RF receiver with at least two RF antennas for receiving RF signals emitted by an RF transmitter; and a controller for determining a position of the RF transmitter in relation to the search light from the received RF signals and for controlling the search light based on the determined position of the RF transmitter.
"AUTONOMOUS SEARCH LIGHT SYSTEM, WINCH SYSTEM COMPRISING AN AUTONOMOUS SEARCH LIGHT SYSTEM, AND AIRCRAFT COMPRISING AN AUTONOMOUS SEARCH LIGHT SYSTEM",https://lens.org/084-015-345-489-665,2022,An autonomous search light system for being mounted to an aircraft includes a search light for emitting an adjustable light output; an RF receiver with at least two RF antennas for receiving RF signals emitted by an RF transmitter; and a controller for determining a position of the RF transmitter in relation to the search light from the received RF signals and for controlling the search light based on the determined position of the RF transmitter.
REMOTE OPERATION SYSTEM FOR HEAVY MACHINERY,https://lens.org/106-161-921-009-992,2010,"The invention relates to a remote control assembly for controlling the operation of an unmanned vehicle or machinery, the assembly is provided with ergonomic side elements suitable to be held between the two hands of a user, and a screen which is positioned essentially centrally to the top portion of the unit, while the periphery of the unit is provided with control and indication switches and/or gauges and/or indicator lights"
METHOD OF LANDING UNMANNED AERIAL ROBOT THROUGH STATION RECOGNITION IN UNMANNED AERIAL SYSTEM AND DEVICE SUPPORTING THE SAME,https://lens.org/118-600-642-269-115,2021,"A station recognition and a landing method are disclosed. More specifically, an unmanned aerial robot includes a camera sensor configured to capture a first pattern that is marked on a station cover and is used for a station identification and a second pattern that is marked inside a station and is used for a precision landing; a transceiver configured to transmit and receive a radio signal; and a processor functionally connected to the camera sensor and the transceiver, wherein the processor is configured to determine a landing station for landing based on the first pattern captured by the camera sensor, control the transceiver to transmit a radio signal that indicates the landing station to open the station cover, and perform the precision landing at the landing station based on the second pattern of the landing station."
Method of landing unmanned aerial robot through station recognition in unmanned aerial system and device supporting the same,https://lens.org/124-055-647-190-39X,2022,"A station recognition and a landing method are disclosed. More specifically, an unmanned aerial robot includes a camera sensor configured to capture a first pattern that is marked on a station cover and is used for a station identification and a second pattern that is marked inside a station and is used for a precision landing; a transceiver configured to transmit and receive a radio signal; and a processor functionally connected to the camera sensor and the transceiver, wherein the processor is configured to determine a landing station for landing based on the first pattern captured by the camera sensor, control the transceiver to transmit a radio signal that indicates the landing station to open the station cover, and perform the precision landing at the landing station based on the second pattern of the landing station."
Method of landing unmanned aerial robot through station recognition in unmanned aerial system and device supporting the same,https://lens.org/124-055-647-190-39X,2022,"A station recognition and a landing method are disclosed. More specifically, an unmanned aerial robot includes a camera sensor configured to capture a first pattern that is marked on a station cover and is used for a station identification and a second pattern that is marked inside a station and is used for a precision landing; a transceiver configured to transmit and receive a radio signal; and a processor functionally connected to the camera sensor and the transceiver, wherein the processor is configured to determine a landing station for landing based on the first pattern captured by the camera sensor, control the transceiver to transmit a radio signal that indicates the landing station to open the station cover, and perform the precision landing at the landing station based on the second pattern of the landing station."
Remote control fishing tackle,https://lens.org/103-044-886-741-245,1994,"A remote control fishing tackle having a main controller (10) and a separate float unit (30) for operating remotely from the main controller and connected thereto by a primary fishing line (351). A secondary fishing line (352) is suspended from the float unit and has a fish hook (353) thereon. The main controller has a radio transmitter (21) with an electric power source (23) and a reel (22) for the fishing line for unreeling and reeling in the float unit. The float unit has a receiver (31), batteries (60), two electric motor units (40, 41) driving separate propellers (44, 45) in two water channels (50, 51), or a common water channel (70), and electronic speed controllers (30, 33) operated by the receiver in response to signals from the transmitter controlled by separate control elements (11, 12) so that the float unit can be propelled forward and backward and turned. The reel is operated selectively by a power drive or manually (15)."
SYSTEM FOR IDENTIFYING AND CONTROLLING UNMANNED AERIAL VEHICLES,https://lens.org/165-582-972-056-145,2017,A beacon for attachment to an unmanned aerial vehicle that provides information needed to identify the owner of a particular unmanned vehicle. The beacon may also include a remote communications module configured to participate on wireless communications networks and a beacon control system configured to issue commands compatible with the unmanned aerial vehicle. The beacon may further a beacon control system configured to translate multiple types of commands from different controls systems into commands compatible with the unmanned aerial vehicle.
System for identifying and controlling unmanned aerial vehicles,https://lens.org/168-109-685-936-292,2017,A beacon for attachment to an unmanned aerial vehicle that provides information needed to identify the owner of a particular unmanned vehicle. The beacon may also include a remote communications module configured to participate on wireless communications networks and a beacon control system configured to issue commands compatible with the unmanned aerial vehicle. The beacon may further a beacon control system configured to translate multiple types of commands from different controls systems into commands compatible with the unmanned aerial vehicle.
Remotely-Controlled Vehicle Skill Structure,https://lens.org/091-498-499-435-646,2015,"A remotely-controlled vehicle skill structure that functions in combination with a remotely-controlled vehicle, such as a helicopter. The structure has at least one platform from which extends a vertical support. Attached to the vertical support is a skill element such as a landing pad, a ring, a semi-ring or a geometric opening. Preferably, the structure has multiple platforms in a multi-tiered design, with multiple skill elements extending upward and outward. A person operating a remotely-controlled helicopter performs various skill-requiring maneuvers including landing on the landing pad(s) and flying through the ring(s) and/or geometric openings. Feedback is provided in the form of lights, sounds and/or displayed information."
HELICOPTER WITH MULTI-ROTORS AND WIRELESS CAPABILITY,https://lens.org/137-666-927-715-271,2015,"An unmanned aerial vehicle/unmanned aircraft system including an airframe; a plurality of rotor assemblies respectively extending from a plurality of arms connected to said airframe, said rotor assemblies each having a rotor thereon with at least one rotor blade; a landing gear extending from said airframe; and a flight controller disposed on said airframe; wherein said flight controller receives instructions for unmanned aerial vehicle/unmanned aircraft system control."
Unmanned aerial vehicle/unmanned aircraft system,https://lens.org/068-346-760-837-635,2017,"An unmanned aerial vehicle/unmanned aircraft system including an airframe; a plurality of rotor assemblies respectively extending from a plurality of arms connected to said airframe, said rotor assemblies each having a rotor thereon with at least one rotor blade; a landing gear extending from said airframe; and a flight controller disposed on said airframe; wherein said flight controller receives instructions for unmanned aerial vehicle/unmanned aircraft system control."
REMOTE-CONTROLLING COMMANDER WITH MULTI-FUNCTION ROTARY DIAL,https://lens.org/111-522-580-724-016,1991,"A remote-controlling commander includes a rotary dial rotatably mounted on a commander housing for manual operation of the user. The commander also includes a position detector for monitoring angular-position of the rotary dial, in which the angular position and/or angular displacement of the rotary dial represents which operation of the apparatus is to be controlled and an encoder for producing an encoded signal variable depending upon the angular position and/or angular displacement of the rotary dial. The encoded signal is transmitted through a transmitter to a receiver provided in the apparatus to be controlled. The received signal is decoded in the apparatus to trigger the function represented by the received signal. The received signal from the remote-controlling commander may be used to perform functions associated with a VTR, such as timing of video recording, picture searching, channel timing, and the like."
"RADAR DEVICE, WIRELESS ROTATING DEVICE OF RADAR, AND UNMANNED AERIAL VEHICLE",https://lens.org/148-661-434-295-21X,2020,"An unmanned aerial vehicle (UAV) includes a housing and a radar device. The radar device is mounted at the housing and includes a base, an antenna assembly, a power transmitter assembly, and a power receiver assembly. The antenna assembly is arranged at the base and configured to rotate relative to the base around a rotation axis. The power transmitter assembly is configured to convert first electric power into electromagnetic energy and transmit the electromagnetic energy. The power receiver assembly is disposed at a distance from the power transmitter assembly, is electrically connected to the antenna assembly, and is configured to rotate with the antenna assembly, convert the received electromagnetic energy into electric power and deliver the electric power to the antenna assembly."
Speech recognition services,https://lens.org/107-734-296-986-81X,2022,"A speech recognition platform configured to receive an audio signal that includes speech from a user and perform automatic speech recognition (ASR) on the audio signal to identify ASR results. The platform may identify: (i) a domain of a voice command within the speech based on the ASR results and based on context information associated with the speech or the user, and (ii) an intent of the voice command. In response to identifying the intent, the platform may perform a corresponding action, such as streaming audio to the device, setting a reminder for the user, purchasing an item on behalf of the user, making a reservation for the user or launching an application for the user. The speech recognition platform, in combination with the device, may therefore facilitate efficient interactions between the user and a voice-controlled device."
Speech recognition services,https://lens.org/107-734-296-986-81X,2022,"A speech recognition platform configured to receive an audio signal that includes speech from a user and perform automatic speech recognition (ASR) on the audio signal to identify ASR results. The platform may identify: (i) a domain of a voice command within the speech based on the ASR results and based on context information associated with the speech or the user, and (ii) an intent of the voice command. In response to identifying the intent, the platform may perform a corresponding action, such as streaming audio to the device, setting a reminder for the user, purchasing an item on behalf of the user, making a reservation for the user or launching an application for the user. The speech recognition platform, in combination with the device, may therefore facilitate efficient interactions between the user and a voice-controlled device."
Speech recognition services,https://lens.org/020-901-113-835-076,2020,"A speech recognition platform configured to receive an audio signal that includes speech from a user and perform automatic speech recognition (ASR) on the audio signal to identify ASR results. The platform may identify: (i) a domain of a voice command within the speech based on the ASR results and based on context information associated with the speech or the user, and (ii) an intent of the voice command. In response to identifying the intent, the platform may perform a corresponding action, such as streaming audio to the device, setting a reminder for the user, purchasing an item on behalf of the user, making a reservation for the user or launching an application for the user. The speech recognition platform, in combination with the device, may therefore facilitate efficient interactions between the user and a voice-controlled device."
Speech recognition platforms,https://lens.org/050-234-777-519-799,2016,"A speech recognition platform configured to receive an audio signal that includes speech from a user and perform automatic speech recognition (ASR) on the audio signal to identify ASR results. The platform may identify: (i) a domain of a voice command within the speech based on the ASR results and based on context information associated with the speech or the user, and (ii) an intent of the voice command. In response to identifying the intent, the platform may perform a corresponding action, such as streaming audio to the device, setting a reminder for the user, purchasing an item on behalf of the user, making a reservation for the user or launching an application for the user. The speech recognition platform, in combination with the device, may therefore facilitate efficient interactions between the user and a voice-controlled device."
Speech recognition platforms,https://lens.org/124-596-520-569-791,2016,"A speech recognition platform configured to receive an audio signal that includes speech from a user and perform automatic speech recognition (ASR) on the audio signal to identify ASR results. The platform may identify: (i) a domain of a voice command within the speech based on the ASR results and based on context information associated with the speech or the user, and (ii) an intent of the voice command. In response to identifying the intent, the platform may perform a corresponding action, such as streaming audio to the device, setting a reminder for the user, purchasing an item on behalf of the user, making a reservation for the user or launching an application for the user. The speech recognition platform, in combination with the device, may therefore facilitate efficient interactions between the user and a voice-controlled device."
Robot control apparatus and robot system,https://lens.org/111-056-374-253-406,2018,"A robot control apparatus, which controls motions of an industrial robot based on processing results of an image processing apparatus which images the robot or objects around the robot, includes: a first communication unit which communicates with a computer for development as an external computer; a second communication unit which is connected to the image processing apparatus via a network; and a command processing unit which opens a communication port of the second communication unit and causes the second communication unit to start communication with the image processing apparatus via a server on the network in response to an open command received by the first communication unit."
ROBOT CONTROL APPARATUS AND ROBOT SYSTEM,https://lens.org/135-907-560-478-223,2013,"A robot control apparatus, which controls motions of an industrial robot based on processing results of an image processing apparatus which images the robot or objects around the robot, includes: a first communication unit which communicates with a computer for development as an external computer; a second communication unit which is connected to the image processing apparatus via a network; and a command processing unit which opens a communication port of the second communication unit and causes the second communication unit to start communication with the image processing apparatus via a server on the network in response to an open command received by the first communication unit."
ROBOT CONTROL APPARATUS AND ROBOT SYSTEM,https://lens.org/034-467-706-264-028,2016,"A robot control apparatus, which controls motions of an industrial robot based on processing results of an image processing apparatus which images the robot or objects around the robot, includes: a first communication unit which communicates with a computer for development as an external computer; a second communication unit which is connected to the image processing apparatus via a network; and a command processing unit which opens a communication port of the second communication unit and causes the second communication unit to start communication with the image processing apparatus via a server on the network in response to an open command received by the first communication unit."
Robot control apparatus and robot system,https://lens.org/192-812-247-187-679,2016,"A robot control apparatus, which controls motions of an industrial robot based on processing results of an image processing apparatus which images the robot or objects around the robot, includes: a first communication unit which communicates with a computer for development as an external computer; a second communication unit which is connected to the image processing apparatus via a network; and a command processing unit which opens a communication port of the second communication unit and causes the second communication unit to start communication with the image processing apparatus via a server on the network in response to an open command received by the first communication unit."
Method and system for launching and recovering underwater vehicles with an autonomous base,https://lens.org/101-340-321-736-135,2020,An autonomous underwater base for handling an autonomous underwater vehicle (AUV) equipped with seismic sensors for recording seismic signals during a marine seismic survey. The autonomous underwater base includes a storing module configured to store the AUV; an inlet/outlet module configured to control access of the AUV to the storing module; and a control module having a positioning system configured to adjust a position of the base in water. The positioning system autonomously drives the storing module from a first position to a second position underwater.
METHOD AND SYSTEM FOR LAUNCHING AND RECOVERING UNDERWATER VEHICLES WITH AN AUTONOMOUS BASE,https://lens.org/190-061-225-660-368,2019,An autonomous underwater base for handling an autonomous underwater vehicle (AUV) equipped with seismic sensors for recording seismic signals during a marine seismic survey. The autonomous underwater base includes a storing module configured to store the AUV; an inlet/outlet module configured to control access of the AUV to the storing module; and a control module having a positioning system configured to adjust a position of the base in water. The positioning system autonomously drives the storing module from a first position to a second position underwater.
Location for unmanned aerial vehicle landing and taking off,https://lens.org/166-479-663-164-864,2021,"An unmanned aerial vehicle (UAV) system operates with a flight management system and has controlled access UAV zones, each being UAV landing, loading, takeoff. A control and communication unit controls access to each UAV zone. A barrier around each zone controls entry into that zone. An opening in the barrier permits personnel to enter. A closure for the opening is locked by at least one remotely operable lock. A communications module is operable to control the lock for that zone to govern access to and entry into that zone by users. A flight management system is separate from the plurality of zones and in communication with the control and communication unit and with each communications module, and responsive to requests by users to allow access. At least some of the UAV zones are charging zones that include at least one charging cable for charging a battery of a UAV."
System and method for identification triggered by beacons,https://lens.org/018-629-250-297-09X,2018,"There is provided systems and methods of identification and automation of devices using a beacon. A system includes a beacon, an automation device, and a server. The beacon is configured to transmit a signal to the automation device in response to entering a defined geographic zone. The automation device is configured to receive the signal from the beacon, transmit, in response to receiving the signal, the signal to the server, receive an identification of a person possessing the beacon from the server, and activate an automation feature, wherein the automation feature uses the identification of the person possessing the beacon. An automation feature may include, but is not limited to, a video camera, a display device, or a stereo."
System and Method for Identification Triggered By Beacons,https://lens.org/100-962-112-796-836,2015,"There is provided systems and methods of identification and automation of devices using a beacon. A system includes a beacon, an automation device, and a server. The beacon is configured to transmit a signal to the automation device in response to entering a defined geographic zone. The automation device is configured to receive the signal from the beacon, transmit, in response to receiving the signal, the signal to the server, receive an identification of a person possessing the beacon from the server, and activate an automation feature, wherein the automation feature uses the identification of the person possessing the beacon. An automation feature may include, but is not limited to, a video camera, a display device, or a stereo."
METHOD AND APPARATUS THAT CONTROLS AUGMENTED REALITY (AR) APPARATUS BASED ON ACTION PREDICTION,https://lens.org/192-660-304-231-534,2020,"A method and apparatus for controlling an augmented reality (AR) apparatus are provided. The method includes acquiring a video, detecting a human body from the acquired video, performing an action prediction with regard to the detected human body, and controlling the AR apparatus based on a result of the action prediction and a mapping relationship between human body actions and AR functions."
Method and apparatus that controls augmented reality (AR) apparatus based on action prediction,https://lens.org/145-183-296-302-924,2022,"A method and apparatus for controlling an augmented reality (AR) apparatus are provided. The method includes acquiring a video, detecting a human body from the acquired video, performing an action prediction with regard to the detected human body, and controlling the AR apparatus based on a result of the action prediction and a mapping relationship between human body actions and AR functions."
ROTARY PROPELLER DRONE WITH INTEGRATED POWER STORAGE,https://lens.org/001-476-634-995-821,2016,An electrically powered unmanned aircraft system (UAS or drone) including a propeller including a core formed by battery material layers as a power source and integrated as a structural component of the drone. The battery material layers can be a graphene super capacitor or a nanopore battery structure. Power available from the integrated battery material layers can be used to power an electric motor included with the drone and operating to rotate the propeller.
Rotary propeller drone with integrated power storage,https://lens.org/105-840-009-913-965,2017,An electrically powered unmanned aircraft system (UAS or drone) including a propeller including a core formed by battery material layers as a power source and integrated as a structural component of the drone. The battery material layers can be a graphene super capacitor or a nanopore battery structure. Power available from the integrated battery material layers can be used to power an electric motor included with the drone and operating to rotate the propeller.
LARGE SCREEN VIDEO DISPLAY SYSTEM AND TELEVISION RECEIVER,https://lens.org/072-008-724-793-412,2000,"A television receiver for automatically judging from a command from a remote controller to control the power on/off, the picture brightness, and the picture contrast of a video projector using a video projector controller provided in the television receiver and for controlling the rolling up and down of a screen using a screen controller also provided in the television receiver."
Utilization of third party networks and third party unmanned aerial vehicle platforms,https://lens.org/175-366-276-151-954,2019,"A device receives a request for a flight path, for a UAV, from a first location to a second location, and calculates the flight path based on the request. The device determines network requirements for the flight path based on the request, and selects a network based on the network requirements. The device generates flight path instructions, and device provides the flight path instructions to the UAV to permit the UAV to travel from the first location to the second location via the flight path. The device receives, at a particular point of the flight path, an indication that the UAV is leaving a coverage area of the network and entering a coverage area of a third party network, and hands off the UAV to a third party device to permit the third party device to monitor traversal of the flight path by the UAV, via the third party network."
UTILIZATION OF THIRD PARTY NETWORKS AND THIRD PARTY UNMANNED AERIAL VEHICLE PLATFORMS,https://lens.org/160-618-471-651-405,2017,"A device receives a request for a flight path, for a UAV, from a first location to a second location, and calculates the flight path based on the request. The device determines network requirements for the flight path based on the request, and selects a network based on the network requirements. The device generates flight path instructions, and device provides the flight path instructions to the UAV to permit the UAV to travel from the first location to the second location via the flight path. The device receives, at a particular point of the flight path, an indication that the UAV is leaving a coverage area of the network and entering a coverage area of a third party network, and hands off the UAV to a third party device to permit the third party device to monitor traversal of the flight path by the UAV, via the third party network."
UTILIZATION OF THIRD PARTY NETWORKS AND THIRD PARTY UNMANNED AERIAL VEHICLE PLATFORMS,https://lens.org/094-171-366-888-304,2016,"A device receives a request for a flight path, for a UAV, from a first location to a second location, and calculates the flight path based on the request. The device determines network requirements for the flight path based on the request, and selects a network based on the network requirements. The device generates flight path instructions, and device provides the flight path instructions to the UAV to permit the UAV to travel from the first location to the second location via the flight path. The device receives, at a particular point of the flight path, an indication that the UAV is leaving a coverage area of the network and entering a coverage area of a third party network, and hands off the UAV to a third party device to permit the third party device to monitor traversal of the flight path by the UAV, via the third party network."
Utilization of third party networks and third party unmanned aerial vehicle platforms,https://lens.org/154-446-526-010-82X,2018,"A device receives a request for a flight path, for a UAV, from a first location to a second location, and calculates the flight path based on the request. The device determines network requirements for the flight path based on the request, and selects a network based on the network requirements. The device generates flight path instructions, and device provides the flight path instructions to the UAV to permit the UAV to travel from the first location to the second location via the flight path. The device receives, at a particular point of the flight path, an indication that the UAV is leaving a coverage area of the network and entering a coverage area of a third party network, and hands off the UAV to a third party device to permit the third party device to monitor traversal of the flight path by the UAV, via the third party network."
METHOD AND DEVICE FOR CONTROLLING HOME DEVICE,https://lens.org/167-608-834-783-980,2016,"A method by which a server controls a home device is provided. The method includes receiving a trigger signal generated by a sensor in a home in response to a mobile device being present at a specific location in the home, determining a home device corresponding to the specific location by using the trigger signal, selecting context information related to an operation of the determined home device from among context information received from the mobile device, and providing the selected context information to the home device."
UNMANNED AERIAL VEHICLE AS WELL AS DIRECTION FINDING SYSTEM,https://lens.org/035-048-469-450-475,2021,"An unmanned aerial vehicle comprises a main body (12) and at least two rotor units (22) configured to propel the unmanned aerial vehicle (10). The unmanned aerial vehicle (10) comprises at least two antenna units (18) configured to receive a radio signal. The antenna units (18) are located with respect to the main body (12) such that the antenna units (18) are assigned to different lateral sides of the main body (12). Further, a direction finding system (36) is described."
Personal audio assistant device and method,https://lens.org/009-377-634-646-485,2019,"A personal audio assistant includes a first microphone for capturing audio, a communication module communicatively coupled to the first microphone and for accessing information from a network, a memory storage unit communicatively coupled to the first microphone, and a voice controlled interface coupled to the microphone. The voice controlled interface is configured to access the network in response to detection of at least one or more voice commands from the captured audio and present results in response to accessing the network to a speaker via a text-to-speech synthesizer. Other embodiments are disclosed."
DRONE FOR CAPTURING IMAGES OF FIELD CROPS,https://lens.org/116-725-913-415-10X,2021,"The present invention provides a drone (unmanned aerial vehicle) capable of photographing a base part of the stem and a side of the leaf of the field crops for evaluating their growth status.A camera directed backward with a depression angle of about 60 degrees is installed at the bottom of the drone. The camera is configured to capture an image of the crop temporarily knocked down by the downdraft created by the rotor of the drone. Since the base part of the stem and the side of the leaf are exposed to the sky, images can be appropriately captured. The depression angle of the camera may be automatically adjustable depending on the flight speed, wind force, and wind direction. Further, it is preferable to rotate the entire body so that the camera is always directed to backward when the drone changes flying directions."
Methods for controlling an electric device using a control apparatus,https://lens.org/140-766-656-929-871,2022,"Methods of controlling objects using an apparatus including a motion sensor and a processing unit and include sensing motion, converting the motion into a command function and processing the command function based on the sensed motion."
Unmanned Aerial Vehicle Weapon System and Method of Operation,https://lens.org/161-103-463-593-915,2018,"An unmanned aerial vehicle weapon system and method of operation which includes an unmanned aerial vehicle having navigational and weapon aiming cameras, remote controlled flight controls and a rifle type of weapon mounted in the wing transversely to the axis of the fuselage where the aerial vehicle is directed to a general target area and controlled to fly in a circular trajectory above and around a specific target within the target area until acquiring the target with the aiming camera and adjusting the bank angle of the vehicle to direct the weapon to the specific target."
"INFORMATION PROCESSING DEVICE, MOBILE DEVICE, INFORMATION PROCESSING SYSTEM, METHOD, AND PROGRAM",https://lens.org/066-112-404-310-744,2023,"To realize a configuration enabling processing of displaying a flight path of a drone on a live-action image of the drone and the like. A data processing unit of a user terminal sets a real object included in a camera-captured image as a marker, generates marker reference coordinates with a configuration point of the set marker as an origin, and transmits position data on the marker reference coordinates to a mobile device such as a drone with the marker reference coordinates as coordinates shared with another device, for example, a mobile device such as a drone. For example, the data processing unit transforms the destination position of the drone or the position of the tracking target from the coordinate position on the user terminal camera coordinates to the coordinate position on the marker reference coordinates by applying the coordinate transformation matrix, and transmits the transformed coordinate position to the drone. In addition, the data processing unit receives the movement path from the drone as coordinate position data on the marker reference coordinates, transforms the coordinate position data into a coordinate position on the user terminal camera coordinates by applying the coordinate transformation matrix, and displays the path information on the display unit."
Aerial imaging device and system,https://lens.org/164-886-909-004-648,2020,"An imaging device 1 without on-board propulsion and capable of autonomous flight for capturing aerial images. The device may be launched from a ground launcher and follow a loop, curved flight course or arcuate flight path of pre-defined radius or radii range. The flight path may have a horizontal levelised component or flattened flight trajectory at maximum height, apogee 33. The device may have sensors providing data to a CPU controller for actuating control surfaces, e.g. elevons (11, figure 2) and capture images at a range of pitch angles using cameras (17). The device may dynamically adapt the flight path during flight and have multiple flight phases, e.g. vertical ascent, image capture phase, vertical descent homing phase. The device may be small, having fixed wings (9) and a power source, e.g. rechargeable battery, fuel cell, or supercapacitor (21). An on-board machine vision module may recognise a homing target 35, e.g. identifiable pattern or signal on an inflatable catcher (37, figure 9) and navigate towards it."
CHEMICAL ANALYZER WITH FREE SPACE COMMUNICATION LINK,https://lens.org/082-634-278-261-58X,1998,An analyzer unit (38) has a remote probe (32) coupled thereto and has a wireless transceiver (86) which receives commands from an external control (88). The analyzer unit (38) responds to the commands and broadcasts an analyzer output over the transceiver (86). The transceiver (86) includes an antenna and a wireless communication transmitter/receiver operable with the main analyzer unit (38) in an intrinsically safe housing.
"SMART LIGHTING DEVICE, AND SMART LIGHTING CONTROL SYSTEM AND METHOD",https://lens.org/168-103-301-810-678,2016,"A smart lighting device (1), and a smart lighting control system and method. The smart lighting device (1) includes a human detection module (14), a control module (15), and a microphone module (12). The microphone module (12) has operation modes including a sleep mode and a monitor mode. The human detection module (14) detects whether a human appears in a surrounding area of the smart lighting device in real-time, and sends a detection signal to the control module (15) when a human appearance is detected. The control module (15) receives and sends the detection signal to the microphone module (12) to switch from a sleep mode to a monitor mode. When receiving a control signal from the control module (15), the microphone module (12) switches to the monitor mode and collects audio signals in the surrounding area of the smart lighting device. The smart lighting device (1) further includes a wireless communication module (13) for wireless communication."
UNMANNED AERIAL VEHICLE (UAV) SYSTEMS AND METHODS FOR MAINTAINING CONTINUOUS UAV OPERATION,https://lens.org/106-985-826-865-91X,2022,"An unmanned aerial vehicle (UAV) system for maintaining UAV flight continuity, includes a ground station, a first UAV, a second UAV, a processor, and a memory. The memory contains instructions thereon, which, when executed by the processor in response to receiving a remaining battery charge signal from the first UAV, selectively deploy the second UAV from the ground station when the remaining battery charge signal indicates that a remaining battery charge of the first UAV is below a threshold value, and return the first UAV to the ground station."
Unmanned aerial vehicle (UAV) systems and methods for maintaining continuous UAV operation,https://lens.org/044-006-962-957-537,2023,"An unmanned aerial vehicle (UAV) system for maintaining UAV flight continuity, includes a ground station, a first UAV, a second UAV, a processor, and a memory. The memory contains instructions thereon, which, when executed by the processor in response to receiving a remaining battery charge signal from the first UAV, selectively deploy the second UAV from the ground station when the remaining battery charge signal indicates that a remaining battery charge of the first UAV is below a threshold value, and return the first UAV to the ground station."
Systems and methods for autonomous vehicle control using depolarization ratio of return signal,https://lens.org/106-340-013-824-928,2021,"An autonomous vehicle control system includes one or more processors. The one or more processors are configured to cause a transmitter to transmit a transmit signal from a laser source. The one or more processors are configured to cause a receiver to receive a return signal reflected by an object. The one or more processors are configured to cause one or more optics to generate a first polarized signal of the return signal with a first polarization, and generate a second polarized signal of the return signal with a second polarization that is orthogonal to the first polarization. The one or more processors are configured to operate a vehicle based on a ratio of reflectivity between the first polarized signal and the second polarized signal."
METHOD FOR INSPECTING AND/OR MANIPULATING A BEAM USING AN UNMANNED AERIAL VEHICLE AND UNMANNED AERIAL VEHICLE SUITABLE THEREFOR,https://lens.org/053-363-881-489-374,2021,"Method for inspecting and/or manipulating a beam at a lower side of a roof or deck, the beam including a strip, the method comprising the steps of: providing an unmanned aerial vehicle, UAV, wherein the UAV comprises a body, a number of rotors, a first arm; and an inspection and/or manipulation tool; while the first arm is in the first position, flying the UAV towards the beam;when the UAV contacts the beam, moving the first arm from the first position to the second position such that the end of the first arm is moved to a position vertically above the strip;reduce the propulsion force until the UAV hangs from the beam with the end of the arm in contact with and supported by the strip; andinspecting and/or manipulating the beam, using the inspection and/or manipulation tool, while the UAV hangs from the beam."
SYSTEM FOR SMART INTRUSION CONTROL USING WEARABLE AND BLE DEVICES,https://lens.org/012-786-648-049-281,2017,"An apparatus including a building automation system (10) that protects a secured geographic area (16), a plurality of non-overlapping geographic zones (18, 20, 22, 24) within the secured area, at least one portable Bluetooth device (48) carried by an authorized human user within the secured area, a Bluetooth receiver (54) associated with each of the plurality of zones that detects the portable device proximate the zone and a security controller (26) that arms and disarms at least one of the plurality of zones based upon the detection of the portable device proximate the at least one zone."
"SYSTEM, DEVICES AND METHODS FOR TELE-OPERATED ROBOTICS",https://lens.org/150-054-383-110-293,2020,"The system, devices and methods disclosed herein enable autonomous and tele-operation of tele-operated robots for maintenance of a property around known and unknown obstacles. A method may include using an unmanned aerial vehicle for obtaining additional data relating to the property and obstacles within the property and plan a path around the obstacles using data from sensors on-board the tele-operated robot and the aerial image. A method may also provide optimization of total time needed for performing the property maintenance and the labor costs in situations where manual intervention is needed for navigating the tele-operated robot around obstacles on the property or for removing obstacles on the property."
"SYSTEM, DEVICES AND METHODS FOR TELE-OPERATED ROBOTICS",https://lens.org/064-774-431-924-768,2021,"The system, devices and methods disclosed herein enable autonomous and tele-operation of tele-operated robots for maintenance of a property around known and unknown obstacles. A method may include using an unmanned aerial vehicle for obtaining additional data relating to the property and obstacles within the property and plan a path around the obstacles using data from sensors on-board the tele-operated robot and the aerial image. A method may also provide optimization of total time needed for performing the property maintenance and the labor costs in situations where manual intervention is needed for navigating the tele-operated robot around obstacles on the property or for removing obstacles on the property."
"SYSTEM, DEVICES AND METHODS FOR TELE-OPERATED ROBOTICS",https://lens.org/080-191-036-965-40X,2021,"The system, devices and methods disclosed herein enable autonomous and tele-operation of tele-operated robots for maintenance of a property around known and unknown obstacles. A method may include using an unmanned aerial vehicle for obtaining additional data relating to the property and obstacles within the property and plan a path around the obstacles using data from sensors on-board the tele-operated robot and the aerial image. A method may also provide optimization of total time needed for performing the property maintenance and the labor costs in situations where manual intervention is needed for navigating the tele-operated robot around obstacles on the property or for removing obstacles on the property."
"System, devices and methods for tele-operated robotics",https://lens.org/111-742-848-626-084,2021,"The system, devices and methods disclosed herein enable autonomous and tele-operation of tele-operated robots for maintenance of a property around known and unknown obstacles. A method may include using an unmanned aerial vehicle for obtaining additional data relating to the property and obstacles within the property and plan a path around the obstacles using data from sensors on-board the tele-operated robot and the aerial image. A method may also provide optimization of total time needed for performing the property maintenance and the labor costs in situations where manual intervention is needed for navigating the tele-operated robot around obstacles on the property or for removing obstacles on the property."
Moving robot and control method thereof using artificial intelligence,https://lens.org/136-664-315-831-014,2022,"The moving robot using artificial intelligence includes: a traveling unit to move a main body; an operation unit to perform a specific operation while generating noise; a sensing unit to sense an ambient situation during traveling; and a controller to determine whether a specific activation condition is satisfied, based on situation information sensed by the sensing unit, and, when the activation condition is determined to be satisfied during traveling, perform a control action to activate a low noise mode so that the operation unit performs the specific operation with relatively reducing the noise. The control method using artificial intelligence includes: determining whether a specific activation condition is satisfied, based on situation information acquired by sensing an ambient situation during traveling; and, when the activation condition is determined to be satisfied, performing a specific operation in an activated state of a low noise mode in which noise is relatively reduced."
Moving robot and control method thereof using artificial intelligence,https://lens.org/136-664-315-831-014,2022,"The moving robot using artificial intelligence includes: a traveling unit to move a main body; an operation unit to perform a specific operation while generating noise; a sensing unit to sense an ambient situation during traveling; and a controller to determine whether a specific activation condition is satisfied, based on situation information sensed by the sensing unit, and, when the activation condition is determined to be satisfied during traveling, perform a control action to activate a low noise mode so that the operation unit performs the specific operation with relatively reducing the noise. The control method using artificial intelligence includes: determining whether a specific activation condition is satisfied, based on situation information acquired by sensing an ambient situation during traveling; and, when the activation condition is determined to be satisfied, performing a specific operation in an activated state of a low noise mode in which noise is relatively reduced."
Unmanned aerial vehicle and target tracking method and device,https://lens.org/124-146-308-018-214,2015,"The invention provides a target tracking device for an unmanned aerial vehicle. A GPS positioning module and a control module are arranged on the unmanned aerial vehicle. The GPS positioning module is used for tracking a target and sending a landing signal to the control module when determining that the tracked target meets the set unmanned aerial vehicle landing condition. The control module is used for controlling the unmanned aerial vehicle to land after receiving the landing signal. The invention further discloses a target tracking method for the unmanned aerial vehicle. By means of the target tracking device and method, the energy utilization rate of the unmanned aerial vehicle can be increased."
TESTING DEVICE FOR EMERGENCY LIGHTING EQUIPMENT,https://lens.org/126-409-367-546-441,2022,"A testing device for emergency lighting equipment including a main control unit and at least one control module, where each of the at least one control module is used to check operational readiness of an emergency lighting device, and the main control unit and the at least one control module are all connected to a network to form a control system for a smart phone or a building security monitoring system to perform a remote inspection operation on at least one aforementioned emergency lighting device via the network."
"System, devices and methods for tele-operated robotics",https://lens.org/072-275-040-442-984,2023,"The system, devices and methods herein enable autonomous and tele-operation of tele-operated robots for maintenance of a property around known and unknown obstacles. A method may include using an unmanned aerial vehicle for obtaining additional data relating to the property and obstacles within the property and plan a path around the obstacles using data from sensors on-board the tele-operated robot and the aerial image. A method may also provide optimization of total time needed for performing the property maintenance and the labor costs in situations where manual intervention is needed for navigating the tele-operated robot around obstacles on the property or for removing obstacles on the property."
INVERTIBLE DRONE FOR SELECTIVE POWER CAPTURE,https://lens.org/164-369-993-690-584,2019,Various embodiments include methods for operating a photovoltaic-powered drone (101) having a photovoltaic surface (110) on one side of at least one of wing or fuselage body of the drone (101). The method may include determining a flight attitude for the drone based on a first drone attitude for optimizing light energy harvesting by the photovoltaic surface (110) and a second drone attitude for minimizing power expenditure by an onboard propulsion system of the drone (101) to reach a designated destination. The method may include flying the drone in the determined flight attitude while converting light into electricity en route to the designated destination.
Border surveillance and tagging unauthorized targets using drone aircraft and sensors,https://lens.org/096-844-113-050-147,2019,"A tagging drone (TD) responds to a received query of availability initiated from a command and control drone (CCD) or command and control station (CCS), over a network, for investigating or tagging a designated target. The TD receives one or more dispatching instructions and heads to the designated target. The TD performs tagging of the designated target and determines whether the designated target was successfully tagged as a tagged target. The tagged target is tracked and tracking data is provided for recovery resource capture of the tagged target."
BORDER SURVEILLANCE AND TAGGING UNAUTHORIZED TARGETS USING DRONE AIRCRAFT AND SENSORS,https://lens.org/017-414-002-579-405,2018,"A tagging drone (TD) responds to a received query of availability initiated from a command and control drone (CCD) or command and control station (CCS), over a network, for investigating or tagging a designated target. The TD receives one or more dispatching instructions and heads to the designated target. The TD performs tagging of the designated target and determines whether the designated target was successfully tagged as a tagged target. The tagged target is tracked and tracking data is provided for recovery resource capture of the tagged target."
SIMPLE MULTI-SENSOR CALIBRATION,https://lens.org/166-458-198-027-086,2017,"A method for calibrating multiple sensors onboard a UAV, wherein the UAV can be controlled to move along a predetermined calibration path or pattern while the sensors on the UAV collect sensor data. The predetermined calibration path or pattern can include simple geometric patterns (e.g., oval). The UAV can be moved manually (e.g., by hand) or remotely by a user, or the UAV may be controlled autonomously to move along the calibration path or pattern. The collected sensor data can then be processed to calibrate the multiple sensors including different types of sensors."
"Swingable arm mount for an aerial vehicle having a lift generating means, and an aerial vehicle, advantageously a multicopter with a swingable arm mount",https://lens.org/191-875-984-750-582,2020,"An aerial vehicle having an arm for supporting an a lift generating means, the aerial vehicle being advantageously a multicopter, comprising an arm mount means for swinging an arm supporting the lift generating means between a retracted position and an extended locked and releasable position."
"SWINGABLE ARM MOUNT FOR AN AERIAL VEHICLE HAVING A LIFT GENERATING MEANS, AND AN AERIAL VEHICLE, ADVANTAGEOUSLY A MULTICOPTER WITH A SWINGABLE ARM MOUNT",https://lens.org/098-524-198-481-236,2019,"An aerial vehicle having an arm for supporting an a lift generating means, the aerial vehicle being advantageously a multicopter, comprising an arm mount means for swinging an arm supporting the lift generating means between a retracted position and an extended locked and releasable position."
GUIDANCE OF MARINE VESSELS,https://lens.org/046-340-231-736-93X,2009,A method for controlling the cruise of an autonomous vessel incorporates using a subsystem of a payload of the vessel functional in generating locational data relating to a target. A controller for controlling the cruise control subsystems determining the bearing and the velocity of said vessel.
GUIDANCE OF MARINE VESSELS,https://lens.org/031-095-337-058-515,2007,A method for controlling the cruise of an autonomous vessel incorporates using a subsystem of a payload of the vessel functional in generating locational data relating to a target. A controller for controlling the cruise control subsystems determining the bearing and the velocity of said vessel.
GUIDANCE OF MARINE VESSELS,https://lens.org/046-519-287-200-608,2009,A method for controlling the cruise of an autonomous vessel incorporates using a subsystem of a payload of the vessel functional in generating locational data relating to a target. A controller for controlling the cruise control subsystems determining the bearing and the velocity of said vessel.
AUTOMATIC DEVICE DETECTION BY REMOTE CONTROL,https://lens.org/076-670-971-383-439,2013,A system includes a remote control and a processing device. The processing device includes an RFID tag. An identification code is stored in the RFID tag. The remote control includes an RFID reader and a transmitter. The RFID reader transmits an interrogation signal. The RFID tag receives the interrogation signal and transmits the identification code in response to the interrogation signal. The RFID reader receives the identification code and the transmitter transmits control signals to control the processing device including a control code associated with the identification code.
Unmanned Aerial Vehicle and Controller Association,https://lens.org/147-606-195-696-180,2021,"Apparatuses, systems, and methods for pairing/unpairing unmanned aerial vehicles (UAVs) to/from UAV controllers (UACs). A UAV and/or a UAC may initiate, based on a triggering condition, a paring/unpairing of the UAV to/from a host UAC and receive, from a network, a configuration update that may confirm the paring/unpairing of the UAV to/from the host UAC. The triggering condition may include at least one of the UAV moving from a location designated as controlled by the host UAC, the UAV moving into a location in which the host UAC is restricted from controlling the host UAV, and/or the host UAC losing signaling capabilities. The configuration update may include at least one of a cause code, an identifier associated with the UAV, an identifier associated with the host UAC, an identifier associated with an unmanned aerial system (UAS)."
LOAD ASSEMBLY AND UNMANNED AERIAL VEHICLE,https://lens.org/071-265-442-771-70X,2019,"An unmanned aerial vehicle (UAV) includes a UAV body including a first mounting member, a gimbal, and a plurality of stands. The gimbal includes a second mounting member connected to the first mounting member, and a gimbal body connected to the second mounting member. The plurality of stands are fixedly attached to the gimbal body and configured to rotate together with the gimbal body around a yaw axis of the gimbal body."
Load assembly and unmanned aerial vehicle,https://lens.org/095-459-401-406-577,2021,"An unmanned aerial vehicle (UAV) includes a UAV body including a first mounting member, a gimbal, and a plurality of stands. The gimbal includes a second mounting member connected to the first mounting member, and a gimbal body connected to the second mounting member. The plurality of stands are fixedly attached to the gimbal body and configured to rotate together with the gimbal body around a yaw axis of the gimbal body."
Wireless access control system and methods for intelligent door lock system,https://lens.org/173-722-385-174-931,2017,"A wireless access control system to lock or unlock a first door at a dwelling of a user. A user remote access device transmits a first signal and a second signal. The user remote access device includes a vibration mode that provides an alert to the user of the remote access device. The user remote access device is configured to be in communication with an intelligent door lock system at the dwelling with the first door. The intelligent door lock system includes: a drive shaft, a circuit coupled to an engine configured to cause a rotation of the drive shaft, and an energy source coupled to the drive shaft, the user remote access device configured to provide the first signal to the intelligent lock system for locking or unlocking of the first lock, the intelligent door lock system configured to allow controlled access to the dwelling that includes an occupant of the dwelling as well as a designated third person granted access rights by the occupant. The user remote access device is configured to be in communication to a second lock at a vehicle of the user or at an office of the user. The user remote access device is configured to communicate with the second lock with the second signal to cause the second lock to lock or be unlocked. The remote access device has a controller for generating the first and second signals."
"SURVEILLANCE METHOD, DRONE, MOBILE DEVICE, SURVEILLANCE SYSTEM, DATA CARRIER",https://lens.org/148-754-859-364-113,2018,"A surveillance method comprises launching, by a mobile target in a scenery, a drone equipped with a camera, establishing a wireless tracking link between the drone and the mobile target or a component carried by it, tracking the mobile target in the scenery by the drone in accordance with information obtained from the tracking link, taking one or more images of the scenery by the drones camera and generating corresponding image data, and wireless transmission of the image data of the one or more images from the drone to at least one first predetermined destination."
MOBILE NETWORK-BASED DRONE SUPERVISION METHOD AND APPARATUS,https://lens.org/195-248-806-070-720,2021,A mobile network-based drone supervision method is disclosed. The method includes: A core network element receives a request message from an application server. The request message includes a target event executed on a target drone. The core network element executes the target event on the target drone based on the request message. The core network element returns a response message to the application server. The response message includes an execution result of the target event.
Approach for estimating the geometry of roads and lanes by using vehicle trajectories,https://lens.org/095-345-784-566-782,2016,"A method and apparatus is provided for controlling the operation of an autonomous vehicle. According to one aspect, the autonomous vehicle may track the trajectories of other vehicles on a road. Based on the other vehicle's trajectories, the autonomous vehicle may generate a representative trajectory. Afterwards, the autonomous vehicle may change at least one of its speed or direction based on the representative trajectory."
Approach for estimating the geometry of roads and lanes by using vehicle trajectories,https://lens.org/122-145-711-694-880,2014,"A method and apparatus is provided for controlling the operation of an autonomous vehicle. According to one aspect, the autonomous vehicle may track the trajectories of other vehicles on a road. Based on the other vehicle's trajectories, the autonomous vehicle may generate a representative trajectory. Afterwards, the autonomous vehicle may change at least one of its speed or direction based on the representative trajectory."
Location-based personal audio,https://lens.org/076-099-218-139-196,2020,"Various implementations include wearable audio devices and related methods for controlling such devices. In some particular implementations, a computer-implemented method of controlling a wearable audio device configured to provide an audio output includes: receiving data indicating the wearable audio device is proximate a geographic location associated with a localized audio message; providing a prompt to initiate playback of the localized audio message to a user of the wearable audio device; and initiating playback of the localized audio message at the wearable audio device in response to actuation of the prompt by the user."
LOCATION-BASED PERSONAL AUDIO,https://lens.org/110-977-451-904-63X,2019,"Various implementations include wearable audio devices and related methods for controlling such devices. In some particular implementations, a computer-implemented method of controlling a wearable audio device configured to provide an audio output includes: receiving data indicating the wearable audio device is proximate a geographic location associated with a localized audio message; providing a prompt to initiate playback of the localized audio message to a user of the wearable audio device; and initiating playback of the localized audio message at the wearable audio device in response to actuation of the prompt by the user."
Remote controlled camera,https://lens.org/022-219-226-033-708,1977,"A remote controlled camera having a fitting member for mounting a signal receiving device to receive a remote control signal on the body of the camera, and a light intercepting device incorporated in the camera body to intersect a light path of an incident light beam through an eye-piece and to be actuated in conjunction with mounting operation of a reote control signal receiver on the camera body."
MONITORING SYSTEM AND CONTROL METHOD THEREOF,https://lens.org/042-400-721-959-614,2020,"Accordingly, the drone can take off or be landed immediately when the base station is moving or remains still."
System and method for camouflaging and recharging autonomous vehicles,https://lens.org/129-081-806-130-134,2019,"An unmanned autonomous vehicle is configured to delivery packages in a product delivery network. The vehicle includes an outer housing, a conversion circuit, a battery, and a control circuit. The outer housing includes a first layer that is configured to collect solar radiation, and a second layer that is configured to render a visual display. The conversion circuit is disposed within the outer housing, and is coupled to the first layer. The conversion circuit is configured to convert the collected solar radiation to electrical charge and store the charge in a battery. The control circuit is coupled to the second layer and is configured to independently determine one or more images to render at the second layer, and to cause the one or more images to be rendered at the second layer. The solar radiation is collected at the first layer simultaneously with the images being rendered at the second layer."
System and method for camouflaging and recharging autonomous vehicles,https://lens.org/113-916-080-195-634,2020,"An unmanned autonomous vehicle is configured to delivery packages in a product delivery network. The vehicle includes an outer housing, a conversion circuit, a battery, and a control circuit. The outer housing includes a first layer that is configured to collect solar radiation, and a second layer that is configured to render a visual display. The conversion circuit is disposed within the outer housing, and is coupled to the first layer. The conversion circuit is configured to convert the collected solar radiation to electrical charge and store the charge in a battery. The control circuit is coupled to the second layer and is configured to independently determine one or more images to render at the second layer, and to cause the one or more images to be rendered at the second layer. The solar radiation is collected at the first layer simultaneously with the images being rendered at the second layer."
SYSTEM AND METHOD FOR CAMOUFLAGING AND RECHARGING AUTONOMOUS VEHICLES,https://lens.org/043-554-248-749-643,2018,"An unmanned autonomous vehicle is configured to delivery packages in a product delivery network. The vehicle includes an outer housing, a conversion circuit, a battery, and a control circuit. The outer housing includes a first layer that is configured to collect solar radiation, and a second layer that is configured to render a visual display. The conversion circuit is disposed within the outer housing, and is coupled to the first layer. The conversion circuit is configured to convert the collected solar radiation to electrical charge and store the charge in a battery. The control circuit is coupled to the second layer and is configured to independently determine one or more images to render at the second layer, and to cause the one or more images to be rendered at the second layer. The solar radiation is collected at the first layer simultaneously with the images being rendered at the second layer."
"PRESENTING LOCATION RELATED INFORMATION AND IMPLEMENTING A TASK BASED ON GAZE, GESTURE, AND VOICE DETECTION",https://lens.org/041-332-239-342-896,2020,"Systems and methods for presenting information and executing a task. In an aspect, when a user gazes at a display of a standby device, location related information is presented. In another aspect, when a user utters a voice command and gazes at a device, a task is executed. In some aspects, device names and/or gestures are detected and utilized for implementing tasks. In some other aspects, a voice input, a gesture, and/or user information is used to determine a user command inside an autonomous vehicle."
"Presenting location related information and implementing a task based on gaze, gesture, and voice detection",https://lens.org/062-728-191-097-344,2020,"Systems and methods for presenting information and executing a task. In an aspect, when a user gazes at a display of a standby device, location related information is presented. In another aspect, when a user utters a voice command and gazes at a device, a task is executed. In some aspects, device names and/or gestures are detected and utilized for implementing tasks. In some other aspects, a voice input, a gesture, and/or user information is used to determine a user command inside an autonomous vehicle."
DISTRIBUTED SPEECH RECOGNITION SYSTEM,https://lens.org/164-860-002-355-815,2002,A method and an accompanying apparatus provide for a distributed voice recognition (VR) capability in a remote device (201). Remote device (201) decides and controls what portions of the VR processing may take place at remote device (201) and what other portions may take place at a base station (202) in wireless communication with remote device (201).
HYBRID REMOTELY/AUTONOMOUSLY OPERATED UNDERWATER VEHICLE,https://lens.org/099-978-869-484-386,2009,"Disclosed is an underwater vehicle that can be operated as a remotely operated vehicle (ROV) or as an autonomous vehicle (AUV). The underwater vehicle has a tether, which ma be a fiberoptic cable, that connects the vehicle to a control console. The underwater vehicle has vertical and lateral thrusters, pitch and yaw control fins, and a propulsor, all of which may be used in an ROV-mode when the underwater vehicle is operating at slow speeds. Th underwater vehicle may also be operated in a AUV-mode when operating at higher speeds. The operator may switch the vehicle between ROV-mode and AUV-mode. The underwater vehicle also has a fail-safe mode, in which the vehicle may navigate according to a pre loaded mission plan if the tether is severed."
HYBRID REMOTELY/AUTONOMOUSLY OPERATED UNDERWATER VEHICLE,https://lens.org/052-781-428-896-858,2010,"Disclosed is an underwater vehicle that can be operated as a remotely operated vehicle (ROV) or as an autonomous vehicle (AUV). The underwater vehicle has a tether, which ma be a fiberoptic cable, that connects the vehicle to a control console. The underwater vehicle has vertical and lateral thrusters, pitch and yaw control fins, and a propulsor, all of which may be used in an ROV-mode when the underwater vehicle is operating at slow speeds. Th underwater vehicle may also be operated in a AUV-mode when operating at higher speeds. The operator may switch the vehicle between ROV-mode and AUV-mode. The underwater vehicle also has a fail-safe mode, in which the vehicle may navigate according to a pre loaded mission plan if the tether is severed."
Autonomous approach and object pickup,https://lens.org/157-582-737-537-643,2018,"An example method includes receiving instructions to pick up an object with one or more lift elements of an autonomous vehicle. Based on a current positioning of the vehicle, the method further includes identifying the object to be picked up and a particular side of the object under which to place the one or more lift elements of the vehicle. The method additionally includes determining an approach path toward the object for the vehicle to follow to place the lift elements of the vehicle under the particular side of the object. The method further includes causing the vehicle to move along the determined approach path toward the object. The method additionally includes determining that the lift elements of the vehicle are placed under the particular side of the object. The method also includes causing the vehicle to lift the object with the lift elements."
Learning multi-device controller with personalized voice control,https://lens.org/062-466-453-514-930,2021,"Techniques for providing instruction to devices in the network are provided. For example, based at least in part on the list of currently active devices and the command, a controller can determine a sequence of IR signals associated with at least one currently active device and transmit, utilizing an IR transmitter incorporated with the controller, the sequence of IR signals to one or more of the currently active devices. In another example, an audio command and location information can be received and used to determine where a controller should transmit an IR signal that corresponds with the audio command, based at least in part on the location information."
Learning multi-device controller with personalized voice control,https://lens.org/056-130-368-359-853,2019,"Techniques for providing instruction to devices in the network are provided. For example, based at least in part on the list of currently active devices and the command, a controller can determine a sequence of IR signals associated with at least one currently active device and transmit, utilizing an IR transmitter incorporated with the controller, the sequence of IR signals to one or more of the currently active devices. In another example, an audio command and location information can be received and used to determine where a controller should transmit an IR signal that corresponds with the audio command, based at least in part on the location information."
Personalizing the learning home multi-device controller,https://lens.org/077-132-903-380-867,2019,"Techniques for providing instruction to devices in the network are provided. For example, based at least in part on the list of currently active devices and the command, a controller can determine a sequence of IR signals associated with at least one currently active device and transmit, utilizing an IR transmitter incorporated with the controller, the sequence of IR signals to one or more of the currently active devices. In another example, an audio command and location information can be received and used to determine where a controller should transmit an IR signal that corresponds with the audio command, based at least in part on the location information."
UNMANNED AERIAL VEHICLE,https://lens.org/066-861-683-394-052,2019,"An unmanned aerial vehicle, comprising: a fuselage having a first side board and a second side board spaced apart and connected by at least one transverse board; the first side board, the second side board, and the at least one transverse board being printed circuit boards; at least one of the first side board, the second side board, and the at least one transverse board having formed and mounted thereon conductive traces and at least one component, respectively, for controlling and monitoring the unmanned aerial vehicle; first and second wings mounted to the fuselage; and, a tail mounted to the fuselage."
UNMANNED AERIAL VEHICLE,https://lens.org/180-452-500-318-432,2014,"An unmanned aerial vehicle, comprising: a fuselage having a first side board and a second side board spaced apart and connected by at least one transverse board; the first side board, the second side board, and the at least one transverse board being printed circuit boards; at least one of the first side board, the second side board, and the at least one transverse board having formed and mounted thereon conductive traces and at least one component, respectively, for controlling and monitoring the unmanned aerial vehicle; first and second wings mounted to the fuselage; and, a tail mounted to the fuselage."
Unmanned aerial vehicle,https://lens.org/000-369-421-430-819,2015,"An unmanned aerial vehicle, comprising: a fuselage having a first side board and a second side board spaced apart and connected by at least one transverse board; the first side board, the second side board, and the at least one transverse board being printed circuit boards; at least one of the first side board, the second side board, and the at least one transverse board having formed and mounted thereon conductive traces and at least one component, respectively, for controlling and monitoring the unmanned aerial vehicle; first and second wings mounted to the fuselage; and, a tail mounted to the fuselage."
UNMANNED AERIAL VEHICLE,https://lens.org/112-681-365-305-390,2014,"An unmanned aerial vehicle, comprising: a fuselage having a first side board and a second side board spaced apart and connected by at least one transverse board; the first side board, the second side board, and the at least one transverse board being printed circuit boards; at least one of the first side board, the second side board, and the at least one transverse board having formed and mounted thereon conductive traces and at least one component, respectively, for controlling and monitoring the unmanned aerial vehicle; first and second wings mounted to the fuselage; and, a tail mounted to the fuselage."
Drone-based scanning for location-based services,https://lens.org/119-950-076-164-840,2022,"Systems and methods are provided for drone-based scanning of products in a retail space, for providing location-based services at the retail space. A system may include a drone aircraft or other self-navigating vehicle. The drone or vehicle automatically moves along the shelves of the retail space, after business hours, scanning product identifiers, and feeds product location information to a location-based-services server. The location-based services server may then provide a map of the retail space with product locations on the map that is accessible to a user's mobile device when the user is in the retail space. In this way, users can be guided directly to the current locations of potentially thousands of products that dynamically change locations."
DRONE-BASED SCANNING FOR LOCATION-BASED SERVICES,https://lens.org/107-307-089-573-67X,2020,"Systems and methods are provided for drone-based scanning of products in a retail space, for providing location-based services at the retail space. A system may include a drone aircraft or other self-navigating vehicle. The drone or vehicle automatically moves along the shelves of the retail space, after business hours, scanning product identifiers, and feeds product location information to a location-based-services server. The location-based services server may then provide a map of the retail space with product locations on the map that is accessible to a user's mobile device when the user is in the retail space. In this way, users can be guided directly to the current locations of potentially thousands of products that dynamically change locations."
Drone-based scanning for location-based services,https://lens.org/119-950-076-164-840,2022,"Systems and methods are provided for drone-based scanning of products in a retail space, for providing location-based services at the retail space. A system may include a drone aircraft or other self-navigating vehicle. The drone or vehicle automatically moves along the shelves of the retail space, after business hours, scanning product identifiers, and feeds product location information to a location-based-services server. The location-based services server may then provide a map of the retail space with product locations on the map that is accessible to a user's mobile device when the user is in the retail space. In this way, users can be guided directly to the current locations of potentially thousands of products that dynamically change locations."
SECURE RECOVERY SYSTEM FOR DRONE DELIVERED PACKAGES,https://lens.org/181-026-354-757-06X,2018,"Systems and methods for use in the secure recovery of drone delivered packages can include a housing, at least one electromechanically operated door securing access to the housing, and a retractable platform that can electromechanically extend from inside the housing to an area outside the housing when the at least one electromechanically operated door is opened. The retractable platform can serve as a landing pad for a delivery drone and/or as a base onto which a package can be received from a delivery drone. The retractable platform can electromechanically move back into the housing and the door can close after receiving the package. Communications components, alarms, and cameras can also be associated with the housing to facilitate its operation for package recovery and security."
Emergency shutdown and landing for unmanned aerial vehicles with air traffic control systems,https://lens.org/085-219-259-766-540,2018,A method for emergency shutdown and landing by an Air Traffic Control (ATC) system for Unmanned Aerial Vehicles (UAVs) includes detecting an Unmanned Aerial Vehicle (UAV) is one of distressed and rogue; determining timing for a shutdown and a location for landing; and communicating the determined timing and the landing location to the UAV by the Air Traffic Control system via one or more wireless networks comprising at least one cellular network.
"Apparatus, method, and computer readable medium for communicating between a user and a remote smartphone",https://lens.org/105-247-367-025-282,2019,"A method, apparatus and computer readable medium. The method may include receiving at least one out of (i) a call notification from a smartphone that is conveyed over a short-range wireless communication link of an apparatus, and (ii) a user voice command for initiating a call by the smartphone, the user voice command is detected by a microphone array of the apparatus; generating, a connection establishment command that once received by the voice-controlled digital assistant will cause the voice-controlled digital assistant to establish a short-range wireless communication connection with the apparatus; outputting the connection establishment commands; performing a speech-based user recognition process by a speech recognition module of the apparatus; and following a successful speech-based user recognition process and a successful establishment of the short-range wireless communication connection with the voice-controlled digital assistant, participating in a call by exchanging audio conveying signals between the smartphone and the voice-controlled digital assistant."
Moving target drone,https://lens.org/063-024-084-171-765,2014,"The utility model provides a moving target drone. The moving target drone comprises guide rails and a target drone body. The target drone body comprises a vehicle frame, the guide rails are two segmented parallel guide rails, each guide rail is formed by sequentially splicing a plurality of small guide rail sections, wheels are installed at the bottom of the vehicle frame, and the wheels are carried on the guide rails and move along the guide wheels. Each guide rail of the moving target drone is formed by sequentially splicing the multiple small guide rail sections, and is easy to lay and install. In addition, the guide rails are located under the wheels, the conditions of the wheels on the running road are improved, the distance between the wheels and the ground is heightened virtually, the influence on the moving target drone from mud or bumps or accumulated water on the road surface is reduced, and good conditions are provided for outdoor usage of the moving target drone. The moving target drone can also be used in an adit."
Secure payload deliveries via unmanned aerial vehicles,https://lens.org/083-237-983-161-979,2017,"A device receives a request for a flight path for a UAV to travel from a first location to a second location, and determines capability information for the UAV based on component information of the UAV. The device calculates the flight path based on the capability information, and generates flight path instructions that include delivery confirmation instructions. The device provides the flight path instructions to the UAV to permit the UAV to travel from the first location to the second location to deliver a payload, and obtains, based on the delivery confirmation instructions, user credentials associated with a user at the second location. The device determines whether the user is an authorized recipient of the payload, based on the user credentials, and causes the UAV to selectively deliver the payload to the user based on whether the user is the authorized recipient of the payload."
SECURE PAYLOAD DELIVERIES VIA UNMANNED AERIAL VEHICLES,https://lens.org/197-001-222-784-269,2016,"A device receives a request for a flight path for a UAV to travel from a first location to a second location, and determines capability information for the UAV based on component information of the UAV. The device calculates the flight path based on the capability information, and generates flight path instructions that include delivery confirmation instructions. The device provides the flight path instructions to the UAV to permit the UAV to travel from the first location to the second location to deliver a payload, and obtains, based on the delivery confirmation instructions, user credentials associated with a user at the second location. The device determines whether the user is an authorized recipient of the payload, based on the user credentials, and causes the UAV to selectively deliver the payload to the user based on whether the user is the authorized recipient of the payload."
"METHOD, DEVICE AND SYSTEM FOR PROVIDING FLIGHT PATH OF UNMANNED AERIAL VEHICLE",https://lens.org/027-690-179-517-801,2021,"A method for providing a flight path of an unmanned aerial vehicle (UAV) includes: obtaining information of an UAV in an idle state obtained by a first access network device from a management system of the UAV, the information of the UAV including an identification of the UAV and flight path information of the UAV; determining, according to the identification of the UAV, a target tracking area in which the UAV is located; sending a paging signaling to access network devices within the target tracking area, the paging signaling being configured to instruct paging the UAV; and sending the flight path information of the UAV to a second access network device after a connection between the second access network device in the target tracking area and the UAV is established successfully."
Autonomous Virtual Wall,https://lens.org/064-699-906-534-708,2021,"A virtual security network system can be used to prevent, deter or cease intrusion of an unauthorized person, animal or object into a secured area. The virtual security network system can include sensor units, a drone and a wide area network. Sensor units can be placed throughout a secured area and include a multitude of sensors with different capabilities that can detect a breach of the secured area. The drone can be mobilized upon receipt of a signal from a sensor unit when the secured area is breached to track an intruder. The drone can be equipped with pulsing lasers or a strobe light. The virtual security network system can also include a satellite, unmanned aerial vehicle, a launching and charging station for drone release and/or a drone fleet."
AUTONOMOUS VIRTUAL WALL,https://lens.org/082-472-657-350-882,2020,"A virtual security network system can be used to prevent, deter or cease intrusion of an unauthorized person, animal or object into a secured area. The virtual security network system can include sensor units, a drone and a wide area network. Sensor units can be placed throughout a secured area and include a multitude of sensors with different capabilities that can detect a breach of the secured area. The drone can be mobilized upon receipt of a signal from a sensor unit when the secured area is breached to track an intruder. The drone can be equipped with pulsing lasers or a strobe light. The virtual security network system can also include a satellite, unmanned aerial vehicle, a launching and charging station for drone release and/or a drone fleet."
AUTONOMOUS VIRTUAL WALL,https://lens.org/002-751-227-880-12X,2019,"A virtual security network system can be used to prevent, deter or cease intrusion of an unauthorized person, animal or object into a secured area. The virtual security network system can include sensor units, a drone and a wide area network. Sensor units can be placed throughout a secured area and include a multitude of sensors with different capabilities that can detect a breach of the secured area. The drone can be mobilized upon receipt of a signal from a sensor unit when the secured area is breached to track an intruder. The drone can be equipped with pulsing lasers or a strobe light. The virtual security network system can also include a satellite, unmanned aerial vehicle, a launching and charging station for drone release and/or a drone fleet."
Security system remote control,https://lens.org/142-384-660-162-73X,1999,"The present invention relates to a remote control unit for cooperating with a security system for convenient arming and disarming thereof and/or status thereof. A low cost of remote preferably cooperates with other components of the system to provide feedback to the user as to the state of the system. The remote control can also be used in a simple, non-threatening method of inputting a security code into a receiving device which is manually or otherwise activated."
Remote controlled security switch,https://lens.org/086-865-710-260-716,1998,"The remote controlled security device which can be controlled by a radiant energy transmitter so as to lock or unlock it, is mounted on the inside wall of a container and has a locking bar which is engageable with a locking plate that has an aligned opening for receiving locking bar of the security device. The locking bar can be moved by stepper motor from the locked to the unlocked position in response to actuation of the remote control transmitter to allow the door of the container to be locked or unlocked. There is also provided a key with an opening which can be inserted through the wall of the container to engage a projection which has the same shape as the opening in the key to allow the lock to be manually locked or unlocked."
Mobile device controlled dynamic room environment using a cast device,https://lens.org/178-699-305-983-544,2019,"A mobile device analyzes data associated with media handled by a cast device connected to a display device. The mobile device causes control signals to be sent, via the one or more communication interfaces, to one of multiple different devices in a room to change an operational parameter associated with the one of the multiple different devices."
MOBILE DEVICE CONTROLLED DYNAMIC ROOM ENVIRONMENT USING A CAST DEVICE,https://lens.org/100-354-401-398-114,2017,"A mobile device analyzes data associated with media handled by a cast device connected to a display device. The mobile device causes control signals to be sent, via the one or more communication interfaces, to one of multiple different devices in a room to change an operational parameter associated with the one of the multiple different devices."
MOBILE DEVICE CONTROLLED DYNAMIC ROOM ENVIRONMENT USING A CAST DEVICE,https://lens.org/028-018-248-154-305,2015,"A mobile device analyzes data associated with media handled by a cast device connected to a display device. The mobile device causes control signals to be sent, via the one or more communication interfaces, to one of multiple different devices in a room to change an operational parameter associated with the one of the multiple different devices."
Unmanned Aerial Vehicle (UAV),https://lens.org/175-475-934-275-338,2023,"An unmanned aerial vehicle (UAV) having a UAV body, a propeller, an engine, a motor and a battery. The engine includes an engine body and an engine output shaft arranged on the engine body. The motor includes a stator, a rotor and a stator connector. The UAV provides the motor rotor, propeller and engine output shaft to be coaxially connected, and the motor can be used as a generator to charge the battery by doing negative work on the engine output shaft, or as an electric motor, that is, to receive the power of the battery and do positive work on the engine output shaft to realize power output, so that the UAV can realize high energy utilization and power redundancy at the same time."
Unmanned Aerial Vehicle (UAV),https://lens.org/175-475-934-275-338,2023,"An unmanned aerial vehicle (UAV) having a UAV body, a propeller, an engine, a motor and a battery. The engine includes an engine body and an engine output shaft arranged on the engine body. The motor includes a stator, a rotor and a stator connector. The UAV provides the motor rotor, propeller and engine output shaft to be coaxially connected, and the motor can be used as a generator to charge the battery by doing negative work on the engine output shaft, or as an electric motor, that is, to receive the power of the battery and do positive work on the engine output shaft to realize power output, so that the UAV can realize high energy utilization and power redundancy at the same time."
"Ornithopter having a wing structure and a mechanism for imparting realistic, bird-like motion thereto",https://lens.org/016-076-715-933-325,2009,"An ornithopter having segmented, flapping wings and capable of bird-like flight. A main drive system provides flapping motion to the wings. Servo systems are provided for independently moving each wing forward and backward along a major axis of the aircraft fuselage, thereby providing a balance subsystem. A single servomechanism controls upward and downward direction of the wings thereby providing a center angle control subsystem. Two additional servo systems are provided to control a tail assembly that provides steering and other ancillary control functions. Each subsystem is controlled by a dedicated, onboard microcontroller. One embodiment of the aircraft is remotely controlled by a wireless data communication link. The aircraft may be constructed to resemble a natural bird, in both static appearance and flight characteristics. The aircraft may be scaled from model size to a full-size, passenger carrying aircraft."
DRONE BASED CAPTURE OF A MULTI-VIEW INTERACTIVE DIGITAL MEDIA,https://lens.org/134-526-929-958-775,2018,"Various embodiments of the present disclosure relate generally to systems and methods for drone-based systems and methods for capturing a multi-media representation of an entity. In some embodiments, the multi-media representation is digital, or multi-view, or interactive, and/or the combinations thereof. According to particular embodiments, a drone having a camera to is controlled or operated to obtain a plurality of images having location information. The plurality of images, including at least a portion of overlapping subject matter, are fused to form multi-view interactive digital media representations."
UNMANNED AERIAL VEHICLE CONTROL METHOD AND UNMANNED AERIAL VEHICLE,https://lens.org/184-976-910-060-596,2020,"A method for controlling an unmanned aerial vehicle, and an unmanned aerial vehicle thereof are provided. The method includes: determining a first relative height between the unmanned aerial vehicle and a ground reflector directly below the unmanned aerial vehicle and a second relative height between the unmanned aerial vehicle and a ground reflector ahead the unmanned aerial vehicle; determining a combined relative height for reflecting a front terrain change according to at least the first relative height and the second relative altitude; and controlling a flying attitude of the unmanned aerial vehicle according to the combined relative altitude. The present disclosure allows a UAV to complete the terrain following function well when the flying speed is too fast or the terrain is quite undulating."
METHODS AND UNMANNED AERIAL VEHICLES FOR LONGER DURATION FLIGHTS,https://lens.org/137-106-415-476-304,2022,The present application provides an unmanned aerial vehicle (UAV) for a long duration flight. An exemplary UAV may include a UAV body assembly. The UAV may also include a flight control system (FCS) coupled to the UAV body assembly. The UAV may further include a motor coupled to the UAV body assembly at one end and coupled to a propeller at the other end. The FCS is communicatively connected to the motor. A center of gravity (CG) of the UAV is at a point between 21% and 25% of a mean aerodynamic chord (MAC) of the UAV.
Robotic systems,https://lens.org/118-281-628-430-763,2017,"The control system for interpreting sensory input(s) such as light, sound, vision, GPS, etc, works by using a hierarchy of interconnected control units which each comprise sensor data input, reference input and a comparator to compare between these signals and provide an output. The control units are hierarchically arranged to feedback between themselves and in such a way that a perception is reached, taking inspiration from biological neurons, and as a result an output signal or signals is/are sent to a response unit (or units) such as an actuator which can control for example components of a vehicles propulsion system such as steering, acceleration, etc, so that an autonomous lunar rover can navigate between two points. The general architecture and design methodology is envisaged as being usable for other autonomous robotics applications."
Surveillance unit and method of use thereof,https://lens.org/188-121-332-573-497,2010,"A surveillance system and method of use thereof is disclosed. The surveillance system provides a continuous presence and may be operated by remote control. The system may automatically record video and audio when certain audio, such as a gun shot, is detected. The system may automatically contact the authorities, or other remotely located devices upon the occurrence of an undesirable event."
System and method for detecting and controlling a drone implanted in a network attached device such as a computer,https://lens.org/198-114-972-537-918,2006,"A system and method for detecting a drone implanted by a vandal in a network connected host device such as a computer, and controlling the output of the drone. The system includes an inbound intrusion detection system (IDS), an outbound IDS, a blocker such as a firewall, an inbound trace log for storing a trace of inbound traffic to the protected device, an outbound trace log for storing a trace of outbound traffic from the protected device, and a correlator. When the outbound IDS detects outbound distributed denial of service (DDoS) traffic, the outbound IDS instructs the blocker to block the outbound DDos traffic. The correlator then recalls the outbound trace log and the inbound trace log, correlates the logs, and deduces the source ID of a message responsible for triggering the drone. The correlator then instructs the blocker to block incoming messages that bear the source ID."
WIRELESS REMOTE CONTROLLED MIRROR WITH INTEGRAL LIGHTING,https://lens.org/079-625-702-453-087,2004,"A wireless remote controlled mirror having lights to illuminate a subject being viewed in the mirror, while enabling a user to selectively adjust a view of the subject from a remote location. When attached to a rear seat of a vehicle, the mirror can be remotely adjusted to view a child in a rear facing safety seat. The mirror includes a base adapted to mount to an object, a reflective lens that moves relative to the base, one or more electric motors to drive the reflective lens, and a receiver that detects a command signal from a wireless remote controller and energizes a motor to reorient the reflective lens to view the child. A plurality of light sources are selectively energized to emit light toward the subject, so that the mirror is usable after dark. The mirror can alternatively be mounted on other portions of a vehicle."
Prospector One,https://lens.org/094-292-773-964-651,2016,"This invention includes a drone with a metal detector attached to the bottom of the drone with a simple assembly. The Prospector One would be controlled by humans for exact locations the person wants to search. This can be utilized for the enthusiast who want to detect objects who search for valuables that are on the ground or underground. It can also be used by the military for important searches such as IUD's, underground explosives to save lives. Additionally, searching for pipe layout locations."
"CONTROL DEVICE, TASK SYSTEM, CONTROL METHOD AND CONTROL PROGRAM",https://lens.org/024-141-949-567-928,2022,"A control device according to an aspect of the present disclosure is a control device for a robot that operates in a facility used by a user, and includes a detection information acquisition unit that acquires detection information of the user who is present in a preset area of the facility, and a control unit that controls the robot such that the robot operates at a speed equal to or lower than a set maximum operation speed based on the detection information of the user."
"CONTROL DEVICE, TASK SYSTEM, CONTROL METHOD AND CONTROL PROGRAM",https://lens.org/024-141-949-567-928,2022,"A control device according to an aspect of the present disclosure is a control device for a robot that operates in a facility used by a user, and includes a detection information acquisition unit that acquires detection information of the user who is present in a preset area of the facility, and a control unit that controls the robot such that the robot operates at a speed equal to or lower than a set maximum operation speed based on the detection information of the user."
UNMANNED AERIAL VEHICLE,https://lens.org/095-187-111-581-282,2022,An unmanned aerial vehicle according to the present invention includes: a main body; an arm that extends from the main body to support a rotor; a first electrical conductor which is supported by the arm and to which a voltage is applied; a second electrical conductor which is supported by the arm and spaced apart from the first electrical conductor and to which a voltage lower than the voltage applied to the first electrical conductor is applied; and a controller configured to control electrical supply to the first and second electrical conductors.
UNMANNED AERIAL VEHICLE,https://lens.org/095-187-111-581-282,2022,An unmanned aerial vehicle according to the present invention includes: a main body; an arm that extends from the main body to support a rotor; a first electrical conductor which is supported by the arm and to which a voltage is applied; a second electrical conductor which is supported by the arm and spaced apart from the first electrical conductor and to which a voltage lower than the voltage applied to the first electrical conductor is applied; and a controller configured to control electrical supply to the first and second electrical conductors.
DEEPLEARNING METHOD FOR VOICE RECOGNITION MODEL AND VOICE RECOGNITION DEVICE BASED ON ARTIFICIAL NEURAL NETWORK,https://lens.org/116-570-675-917-249,2020,"A method for training an artificial neural network-based speech recognition model is disclosed. In the method for training an artificial neural network-based speech recognition model, a user's speech is learned by using target data representing features and non-target data representing non-features as random inputs and outputs, and then the user's speech is recognized under a noise situation. A method for training an artificial neural network-based speech recognition model and speech recognition device of the present disclosure can be associated with artificial intelligence modules, drones (unmanned aerial vehicles (UAVs)), robots, augmented reality (AR) devices, virtual reality (VR) devices, devices related to 5G service, etc."
Deeplearning method for voice recognition model and voice recognition device based on artificial neural network,https://lens.org/122-210-239-018-771,2021,"A method for training an artificial neural network-based speech recognition model is disclosed. In the method for training an artificial neural network-based speech recognition model, a user's speech is learned by using target data representing features and non-target data representing non-features as random inputs and outputs, and then the user's speech is recognized under a noise situation. A method for training an artificial neural network-based speech recognition model and speech recognition device of the present disclosure can be associated with artificial intelligence modules, drones (unmanned aerial vehicles (UAVs)), robots, augmented reality (AR) devices, virtual reality (VR) devices, devices related to 5G service, etc."
Target lifter with impact sensing,https://lens.org/178-558-717-921-041,1995,"This is a commercial capable heavy lifter capable of rotating or levering large objects up and down by remote control. When used to so raise and lower targets on a firing range, the target can be dropped automatically when the target receives one or more hits."
"ROBOT, METHOD OF CONTROLLING THE SAME, AND PROGRAM",https://lens.org/107-970-592-232-726,2019,"A robot (100) includes an operation unit (170) that causes the robot (100) to operate, a viewing direction determiner (150) that determines whether a viewing direction of a predetermined target is toward the robot (100) or not, and an operation controller (140) that controls the operation unit (170) based on a result of determination by the viewing direction determiner (150).
"
"ROBOT, METHOD OF CONTROLLING THE SAME, AND PROGRAM",https://lens.org/062-309-212-174-26X,2019,"A robot (100) includes an operation unit (170) that causes the robot (100) to operate, a viewing direction determiner (150) that determines whether a viewing direction of a predetermined target is toward the robot (100) or not, and an operation controller (140) that controls the operation unit (170) based on a result of determination by the viewing direction determiner (150)."
Unmanned aerial vehicle including mounting structure for propeller,https://lens.org/121-245-015-282-059,2021,"An unmanned aerial vehicle includes a housing, a wireless communication circuit, a navigation circuit, a plurality of propulsion systems, and a propeller. At least one of the plurality of propulsion systems includes a motor, and a construction disposed to the motor. The construction includes a first side, a second side facing the motor in a direction opposite to the first side, a shaft inserting hole disposed to the second side, and a latching protrusion and a latching groove that are extended sequentially inside the shaft inserting hole. The propeller is fastened to the construction, and includes a hub coupled to the first side of the construction, a fixing shaft that protrudes in a direction of the construction that is inserted to the shaft inserting hole of the construction, and at least one protrusion on an outer circumferential surface of the fixing shaft."
Utilizing an unmanned aerial vehicle platform which is equipped with a turntable assembly,https://lens.org/114-622-232-618-791,2019,"An unmanned aerial vehicle (UAV) platform includes a stationary base constructed and arranged to reside over a fixed location on a surface (e.g., a ground location, a ship's deck, a trailer or other vehicle, etc.). The UAV platform further includes a set of UAV interfaces constructed and arranged to interface directly with a UAV (e.g., a launcher, a net apparatus, etc.). The UAV platform further includes a turntable assembly which couples to the stationary base. The turntable assembly is constructed and arranged to couple to each UAV interface and control angular direction of that UAV interface over the fixed location. A method of operating a UAV platform includes deploying the UAV platform over a fixed location, preparing a UAV interface on a turntable assembly of the UAV platform, and rotating the turntable to control angular direction of the UAV interface over the fixed location."
UTILIZING AN UNMANNED AERIAL VEHICLE PLATFORM WHICH IS EQUIPPED WITH A TURNTABLE ASSEMBLY,https://lens.org/011-811-064-143-27X,2016,"An unmanned aerial vehicle (UAV) platform includes a stationary base constructed and arranged to reside over a fixed location on a surface (e.g., a ground location, a ship's deck, a trailer or other vehicle, etc.). The UAV platform further includes a set of UAV interfaces constructed and arranged to interface directly with a UAV (e.g., a launcher, a net apparatus, etc.). The UAV platform further includes a turntable assembly which couples to the stationary base. The turntable assembly is constructed and arranged to couple to each UAV interface and control angular direction of that UAV interface over the fixed location. A method of operating a UAV platform includes deploying the UAV platform over a fixed location, preparing a UAV interface on a turntable assembly of the UAV platform, and rotating the turntable to control angular direction of the UAV interface over the fixed location."
UTILIZING AN UNMANNED AERIAL VEHICLE PLATFORM WHICH IS EQUIPPED WITH A TURNTABLE ASSEMBLY,https://lens.org/071-679-913-007-776,2016,"An unmanned aerial vehicle (UAV) platform includes a stationary base constructed and arranged to reside over a fixed location on a surface (e.g., a ground location, a ship's deck, a trailer or other vehicle, etc.). The UAV platform further includes a set of UAV interfaces constructed and arranged to interface directly with a UAV (e.g., a launcher, a net apparatus, etc.). The UAV platform further includes a turntable assembly which couples to the stationary base. The turntable assembly is constructed and arranged to couple to each UAV interface and control angular direction of that UAV interface over the fixed location. A method of operating a UAV platform includes deploying the UAV platform over a fixed location, preparing a UAV interface on a turntable assembly of the UAV platform, and rotating the turntable to control angular direction of the UAV interface over the fixed location."
Utilizing an unmanned aerial vehicle platform which is equipped with a turntable assembly,https://lens.org/035-753-229-468-514,2018,"An unmanned aerial vehicle (UAV) platform includes a stationary base constructed and arranged to reside over a fixed location on a surface (e.g., a ground location, a ship's deck, a trailer or other vehicle, etc.). The UAV platform further includes a set of UAV interfaces constructed and arranged to interface directly with a UAV (e.g., a launcher, a net apparatus, etc.). The UAV platform further includes a turntable assembly which couples to the stationary base. The turntable assembly is constructed and arranged to couple to each UAV interface and control angular direction of that UAV interface over the fixed location. A method of operating a UAV platform includes deploying the UAV platform over a fixed location, preparing a UAV interface on a turntable assembly of the UAV platform, and rotating the turntable to control angular direction of the UAV interface over the fixed location."
Utilizing an unmanned aerial vehicle platform which is equipped with a turntable assembly,https://lens.org/028-382-216-623-622,2017,"An unmanned aerial vehicle (UAV) platform includes a stationary base constructed and arranged to reside over a fixed location on a surface (e.g., a ground location, a ship's deck, a trailer or other vehicle, etc.). The UAV platform further includes a set of UAV interfaces constructed and arranged to interface directly with a UAV (e.g., a launcher, a net apparatus, etc.). The UAV platform further includes a turntable assembly which couples to the stationary base. The turntable assembly is constructed and arranged to couple to each UAV interface and control angular direction of that UAV interface over the fixed location. A method of operating a UAV platform includes deploying the UAV platform over a fixed location, preparing a UAV interface on a turntable assembly of the UAV platform, and rotating the turntable to control angular direction of the UAV interface over the fixed location."
UTILIZING AN UNMANNED AERIAL VEHICLE PLATFORM WHICH IS EQUIPPED WITH A TURNTABLE ASSEMBLY,https://lens.org/164-688-561-440-563,2017,"An unmanned aerial vehicle (UAV) platform includes a stationary base constructed and arranged to reside over a fixed location on a surface (e.g., a ground location, a ship's deck, a trailer or other vehicle, etc.). The UAV platform further includes a set of UAV interfaces constructed and arranged to interface directly with a UAV (e.g., a launcher, a net apparatus, etc.). The UAV platform further includes a turntable assembly which couples to the stationary base. The turntable assembly is constructed and arranged to couple to each UAV interface and control angular direction of that UAV interface over the fixed location. A method of operating a UAV platform includes deploying the UAV platform over a fixed location, preparing a UAV interface on a turntable assembly of the UAV platform, and rotating the turntable to control angular direction of the UAV interface over the fixed location."
USER-ADJUSTABLE TRAJECTORIES FOR AUTOMATED VEHICLE REVERSING,https://lens.org/037-543-900-074-958,2019,"A method for autonomously maneuvering a vehicle in a rearward direction towards a point of interest is provided. The method includes receiving one or more images from a camera positioned on a back portion of the vehicle. The method includes overlaying a path on the one or more images. In addition, the method includes receiving a command by way of a user interface. The command includes instructions to adjust the path. The method includes adjusting the path based on the received command. The method also includes transmitting a drive command to a drive system supported by the vehicle. The drive command causes the vehicle to autonomously maneuver along the adjusted path in a rearward direction."
User-adjustable trajectories for automated vehicle reversing,https://lens.org/103-757-271-706-937,2023,"A method for autonomously maneuvering a vehicle in a rearward direction towards a point of interest is provided. The method includes receiving one or more images from a camera positioned on a back portion of the vehicle. The method includes overlaying a path on the one or more images. In addition, the method includes receiving a command by way of a user interface. The command includes instructions to adjust the path. The method includes adjusting the path based on the received command. The method also includes transmitting a drive command to a drive system supported by the vehicle. The drive command causes the vehicle to autonomously maneuver along the adjusted path in a rearward direction."
BIRD REPELLENT SYSTEM,https://lens.org/171-181-444-027-674,2015,"The bird repellent system is particularly adapted to repel various species of birds on and around airports, but may be readily adapted for use in other environments where birds have become a nuisance or hazard. The system includes both a ground vehicle and an airborne vehicle to optimize the effect against both sitting birds and birds in flight. Both vehicles are unmanned and operate autonomously, or by remote control as drones. The airborne vehicle is preferably a quad rotor craft for very slow and hovering flight. Both vehicles are equipped with GPS guidance and are preprogrammed to travel about a predetermined area or route. The two vehicles communicate with one another for optimum effect. Both vehicles include audio systems to broadcast startling sounds and/or bird distress cries in sound frequencies audible to humans as well as in ultrasonic frequencies known to be audible to various species of birds."
"UAV and body thereof, and gimbal camera",https://lens.org/018-808-869-472-772,2022,"An unmanned aerial vehicle (UAV) includes a body and a gimbal camera. The body includes a housing including an inwardly recessed mounting groove with a notch on one side of the mounting groove, and a protective cover arranged at the housing and configured to open and cover the notch. The gimbal camera includes a mounting frame detachably connected to the housing via the mounting groove; a gimbal arranged at the mounting frame; and a camera arranged at the gimbal. In response to the gimbal camera and the housing being connected via the mounting frame, the gimbal camera is at least partially accommodated in the notch."
"UAV and body thereof, and gimbal camera",https://lens.org/018-808-869-472-772,2022,"An unmanned aerial vehicle (UAV) includes a body and a gimbal camera. The body includes a housing including an inwardly recessed mounting groove with a notch on one side of the mounting groove, and a protective cover arranged at the housing and configured to open and cover the notch. The gimbal camera includes a mounting frame detachably connected to the housing via the mounting groove; a gimbal arranged at the mounting frame; and a camera arranged at the gimbal. In response to the gimbal camera and the housing being connected via the mounting frame, the gimbal camera is at least partially accommodated in the notch."
"UAV AND BODY THEREOF, AND GIMBAL CAMERA",https://lens.org/003-746-098-877-871,2021,"An unmanned aerial vehicle (UAV) includes a body and a gimbal camera. The body includes a housing including an inwardly recessed mounting groove with a notch on one side of the mounting groove, and a protective cover arranged at the housing and configured to open and cover the notch. The gimbal camera includes a mounting frame detachably connected to the housing via the mounting groove; a gimbal arranged at the mounting frame; and a camera arranged at the gimbal. In response to the gimbal camera and the housing being connected via the mounting frame, the gimbal camera is at least partially accommodated in the notch."
AUTHORIZATION FOR AN UNMANNED AERIAL VEHICLE,https://lens.org/131-630-324-738-500,2022,"Apparatuses, systems, and methods for receiving authorization for an unmanned aerial vehicle (or uncrewed aerial vehicle) (UAV) are disclosed. One method (700) includes receiving (705) a first request from an Access and Mobility Management Function (143) in which the first request includes an indication to establish user plane resources for Unmanned Aerial System (""UAS"") services for a UAV device (106). The method further includes retrieving (710) subscription information from a Unified Data Management (149) node, the subscription information indicating that UAV authorization is required by a UAS Service Subscriber (157) and/or UAS Traffic Management (157) server, and sending (715) a second request to a UAS network function (147) to initiate the UAV authorization."
AUTHORIZATION FOR AN UNMANNED AERIAL VEHICLE,https://lens.org/131-630-324-738-500,2022,"Apparatuses, systems, and methods for receiving authorization for an unmanned aerial vehicle (or uncrewed aerial vehicle) (UAV) are disclosed. One method (700) includes receiving (705) a first request from an Access and Mobility Management Function (143) in which the first request includes an indication to establish user plane resources for Unmanned Aerial System (""UAS"") services for a UAV device (106). The method further includes retrieving (710) subscription information from a Unified Data Management (149) node, the subscription information indicating that UAV authorization is required by a UAS Service Subscriber (157) and/or UAS Traffic Management (157) server, and sending (715) a second request to a UAS network function (147) to initiate the UAV authorization."
System and method for smart intrusion control using wearable BLE devices,https://lens.org/065-993-278-712-924,2019,"An apparatus including a building automation system that protects a secured geographic area, a plurality of non-overlapping geographic zones within the secured area, at least one portable Bluetooth device carried by an authorized human user within the secured area, a Bluetooth receiver associated with each of the plurality of zones that detects the portable device proximate the zone and a security controller that arms and disarms at least one of the plurality of zones based upon the detection of the portable device proximate the at least one zone."
System and method for changing a surface characteristic of a concrete bridge surface,https://lens.org/071-806-963-123-635,2021,"An automated concrete bridge paver with an ability to provide effective control of a concrete paver by a remotely locatable concrete bridge paver operator 202, which includes a fixed operator control station and a mobile wireless remote operator control station 210 which can be used when the remotely locatable concrete bridge paver operator 202 leaves the operator control station 204. Mobile wireless remote operator control station 210 includes a video screen which can display live video images from a plurality of remote wireless camera and sensor pods 212, which can be fixed on the paver or moved about the paver on an articulated arm, with or without a human basket."
SYSTEM AND METHOD FOR CHANGING A SURFACE CHARACTERISTIC DURING THE CREATION OF A CONCRETE BRIDGE SURFACE,https://lens.org/026-787-857-350-946,2019,"An automated concrete bridge paver with an ability to provide effective control of a concrete paver by a remotely locatable concrete bridge paver operator 202, which includes a fixed operator control station and a mobile wireless remote operator control station 210 which can be used when the remotely locatable concrete bridge paver operator 202 leaves the operator control station 204. Mobile wireless remote operator control station 210 includes a video screen which can display live video images from a plurality of remote wireless camera and sensor pods 212, which can be fixed on the paver or moved about the paver on an articulated arm, with or without a human basket."
SYSTEM AND METHOD FOR CHANGING A SURFACE CHARACTERISTIC OF A CONCRETE BRIDGE SURFACE,https://lens.org/026-497-809-094-348,2019,"An automated concrete bridge paver with an ability to provide effective control of a concrete paver by a remotely locatable concrete bridge paver operator 202, which includes a fixed operator control station and a mobile wireless remote operator control station 210 which can be used when the remotely locatable concrete bridge paver operator 202 leaves the operator control station 204. Mobile wireless remote operator control station 210 includes a video screen which can display live video images from a plurality of remote wireless camera and sensor pods 212, which can be fixed on the paver or moved about the paver on an articulated arm, with or without a human basket."
ELECTRONICALLY FILE AND FLY UNMANNED AERIAL VEHICLE,https://lens.org/152-710-090-806-807,2012,"Flight plans for an unmanned aerial vehicle (UAV) are automatically generated and filed with an air traffic control (ATC) system to quickly and easily secure approval for flying the UAV in a controlled airspace. In one example, one or more flight locations for a UAV are defined using a computing device. Using the computing device, an electronic flight plan is automatically generated based on the defined flight locations for the UAV. The flight plan can be transmitted to an ATC system. ATC approval, with or without modifications, or denial of the flight plan may also be received electronically and indicated on the operator device."
"Image processing method, and unmanned aerial vehicle and system",https://lens.org/021-525-305-572-215,2021,"Image processing method, drone, and drone-camera system are provided. The method includes acquiring, according to a current environmental parameter of the drone, a target sky image that matches the current environmental parameter; and determining a direction parameter of the camera device when capturing a to-be-stitched image. The to-be-stitched image is an image captured under the current environmental parameter. The method further includes stitching the target sky image with the to-be-stitched image according to the direction parameter to obtain a panoramic image."
"IMAGE PROCESSING METHOD, AND UNMANNED AERIAL VEHICLE AND SYSTEM",https://lens.org/180-534-046-748-502,2020,"Image processing method, drone, and drone-camera system are provided. The method includes acquiring, according to a current environmental parameter of the drone, a target sky image that matches the current environmental parameter; and determining a direction parameter of the camera device when capturing a to-be-stitched image. The to-be-stitched image is an image captured under the current environmental parameter. The method further includes stitching the target sky image with the to-be-stitched image according to the direction parameter to obtain a panoramic image."
SYSTEM AND METHOD FOR POSITION DETERMINATION FOR UNMANNED VEHICLES,https://lens.org/135-464-592-772-179,2019,"Sensory information is obtained at a drone (e.g., from sensors at the drone or deployed at other locations), and the sensory information defines the physical operating environment of the drone. The aerial drone is initially operated according to a current geographical location that is received. The sensory information is subsequently obtained, for example, from the sensors. An adjusted current geographical location of the aerial drone is selectively determined based upon an evaluation of the sensory information and a UWB beacon signal. The aerial drone is operated according to the adjusted current geographical location."
Unmanned aerial vehicle system for police multipurpose surveillance,https://lens.org/116-769-260-782-539,2015,"The invention discloses an unmanned aerial vehicle system for police multipurpose surveillance. The unmanned aerial vehicle system for the police multipurpose surveillance comprises an unmanned aerial vehicle platform, a flight control platform, a ground station control system, a digital image transmission system and a three axis stability augmentation cloud platform, wherein the digital picture transmission system comprises a portable image receiver, an image collecting system, an onboard wireless digital video transmission system and an onboard transmitting antenna, the flight control platform controls the unmanned aerial vehicle platform, the flight control platform collects images or video through the image collecting system of the digital image transmission system, and the images or the video is transmitted to the ground station control system through the portable image receiver, the onboard wireless digital video transmission system and the onboard transmitting antenna. The unmanned aerial vehicle system for the police multipurpose surveillance can accurately, effectively and timely complete real-time surveillance and effectively return real-time sound, video and picture information, can complete and implement the real-time surveillance and return the real-time information especially in severe environments and areas, where people difficulty reach or approach, timely performs judgment analysis according to the real-time information, reduces economic losses, and avoids personal injuries and deaths."
Control systems for water-sports watercraft,https://lens.org/002-633-674-401-576,2018,"An adjustable surf wake system can enhance a wake formed by a watercraft traveling through water. A rider control device can enable a rider to control the wake of the watercraft while riding the wake, such as for wake surfing. The rider can adjust the speed of the watercraft, can adjust the height of the wake, and/or can change the watercraft between a surf-left configuration and a surf-right configuration. The rider control device can include a position sensor. A drone can position a camera based on the position sensor of the rider control device for filming the rider."
AERIAL RECONNAISSANCE DRONE AND METHOD,https://lens.org/191-025-078-113-572,2022,"An aerial reconnaissance drone having a dragonfly format (elongate fuselage and flapping wings) with two cameras 4', 4"" having respective diagonal fields of view 5', 5"", arranged at respective ends of the fuselage, both pointing forwards, wherein the second camera has a diagonal field 5"" of view that is at most half that 5' of the first camera 4'. This has the advantage of providing a drone that can capture enhanced imagery when required, by performing a half turn and switching which camera is being used. Since this avoids placing two cameras in the same location both can have a clear view of surroundings yet it helps avoid off balance caused by placing too much mass in any particular off-centre location."
A MODULAR UNMANNED AERIAL VEHICLE SYSTEM FOR ADAPTABLE PARCEL DELIVERY,https://lens.org/081-502-224-336-901,2021,"A modular unmanned aerial vehicle (UAV) system comprises a body module, a rotor module, and a wing module. The body module includes a flight controller and a power distribution device. The body module is releasably attachable to the rotor module or the wing module, and the body module is releasably attachable to the rotor module. The rotor module includes one or more motors and electronic speed controllers (ESCs), while the wing module includes a wing having a flap, elevator, aileron, or rudder. Various UAV configurations can be formed from the body module, the rotor module, and the wing module. Each configuration includes different advantages for flight time, distance, battery life, and payload capacity. A UAV can be configured to a particular configuration to optimize parcel delivery."
Security camera system,https://lens.org/137-444-272-798-702,2022,"A security device is configured to be secured to a structure to monitor an area of interest surrounding the structure. Monitoring of the area of interest is done covertly to ensure that the security device remains undetectable. The security device includes a head that is operably and removably coupled to a base. The head includes a camera having a lens that is configured to capture video data within the area of interest. The captured (or recorded) video data is transmitted to a storage device within the base for storage. For added security and/or functionally, a user can wirelessly control and monitor the security device via a user interface device from anywhere in the world."
Voice control method and system,https://lens.org/087-821-577-217-357,2016,"The invention relates to a voice control method and a system. According to the method, firstly, an audio signal generated by noise equipment is picked up by means of an environmental noise pickup device. After that, the picked audio signal is coded as audio data, and the audio data are sent to a controlled terminal. Upon detecting a first audio signal, the controlled terminal converts the currently detected voice data into a second audio signal. The second audio signal is compared with the first audio signal, and the part of the first audio signal, matched with the second audio signal, is removed. In this way, a voice control command is generated. In response to the generated voice control command, the second audio signal in the first audio signal generated by the noise equipment is removed to improve the voice control accuracy."
IDENTIFICATION APPARATUS AND METHOD,https://lens.org/134-441-767-432-224,2009,"An audible command can be utilized to both permit identification of the speaker and to permit subsequent actions that comprise a corresponding response to the audible command when the identity of the speaker correlates with that of a previously authorized individual (Figure 1). Such identification can be supplemented with other identification mechanisms. Hierarchical levels of permission can be utilized, with or without confidence level thresholds, to further protect the device against unauthorized access and/or manipulation."
CONTROL SYSTEMS FOR WATER-SPORTS WATERCRAFT,https://lens.org/143-131-781-374-158,2018,"An adjustable surf wake system can enhance a wake formed by a watercraft travelling through water. A rider control device can enable a rider to control the wake of the watercraft while riding the wake, such as for wake surfing. The rider can adjust the speed of the watercraft, can adjust the height of the wake, and/or can change the watercraft between a surf-left configuration and a surf-right configuration. The rider control device can include a position sensor. A drone can position a camera based on the position sensor of the rider control device for filming the rider."
CONTROL SYSTEMS FOR WATER-SPORTS WATERCRAFT,https://lens.org/056-487-028-077-974,2022,"An adjustable surf wake system can enhance a wake formed by a watercraft travelling through water. A rider control device can enable a rider to control the wake of the watercraft while riding the wake, such as for wake surfing. The rider can adjust the speed of the watercraft, can adjust the height of the wake, and/or can change the watercraft between a surf-left configuration and a surf-right configuration. The rider control device can include a position sensor. A drone can position a camera based on the position sensor of the rider control device for filming the rider."
Control systems for water-sports watercraft,https://lens.org/012-896-468-448-100,2021,"An adjustable surf wake system can enhance a wake formed by a watercraft travelling through water. A rider control device can enable a rider to control the wake of the watercraft while riding the wake, such as for wake surfing. The rider can adjust the speed of the watercraft, can adjust the height of the wake, and/or can change the watercraft between a surf-left configuration and a surf-right configuration. The rider control device can include a position sensor. A drone can position a camera based on the position sensor of the rider control device for filming the rider."
Control systems for water-sports watercraft,https://lens.org/123-726-671-571-326,2019,"An adjustable surf wake system can enhance a wake formed by a watercraft travelling through water. A rider control device can enable a rider to control the wake of the watercraft while riding the wake, such as for wake surfing. The rider can adjust the speed of the watercraft, can adjust the height of the wake, and/or can change the watercraft between a surf-left configuration and a surf-right configuration. The rider control device can include a position sensor. A drone can position a camera based on the position sensor of the rider control device for filming the rider."
CONTROL SYSTEMS FOR WATER-SPORTS WATERCRAFT,https://lens.org/141-375-736-092-256,2020,"An adjustable surf wake system can enhance a wake formed by a watercraft travelling through water. A rider control device can enable a rider to control the wake of the watercraft while riding the wake, such as for wake surfing. The rider can adjust the speed of the watercraft, can adjust the height of the wake, and/or can change the watercraft between a surf-left configuration and a surf-right configuration. The rider control device can include a position sensor. A drone can position a camera based on the position sensor of the rider control device for filming the rider."
CONTROL SYSTEMS FOR WATER-SPORTS WATERCRAFT,https://lens.org/066-631-303-181-175,2017,"An adjustable surf wake system can enhance a wake formed by a watercraft travelling through water. A rider control device can enable a rider to control the wake of the watercraft while riding the wake, such as for wake surfing. The rider can adjust the speed of the watercraft, can adjust the height of the wake, and/or can change the watercraft between a surf-left configuration and a surf-right configuration. The rider control device can include a position sensor. A drone can position a camera based on the position sensor of the rider control device for filming the rider."
Multi-rotor unmanned aerial vehicle with function of loaded long-time flying,https://lens.org/127-003-117-268-297,2015,"The invention is applicable to the field of teleoperator and provides a multi-rotor unmanned aerial vehicle with a function of loaded long-time flying. The unmanned aerial vehicle comprises a flying device and a remote controller, wherein the remote controller is connected with the flying device via wireless communication and controls the flying device; and parameters are set remotely to allow the flying device to be capable of freely making motion in a set area. The loading capacity of the multi-rotor unmanned aerial vehicle is increased by several times; at the same time, with the increase of the loading capacity, battery capacity can be increased, so that the flying time in the air is prolonged for several times; and the cost is only increased by 30-50%, while the loading capacity is increased by several times. The vehicle meets low cost and high performance requirements of customers, and achieves manned flight on the premise of ensuring safety."
REMOTE CONTROL METHOD FOR SNOW REMOVAL AND DISASTER PREVENTION SYSTEM USING SMART PHONE,https://lens.org/010-681-956-155-12X,2013,"Provided is a remote control method of a snow removal system using a smart phone, which remotely controls the system installed at a site while checking conditions of a road and the system in real time when improvement of a road surface is needed because a condition of the road surface deteriorates due to dusts, yellow sand, frozen snow on the road surface, etc. The remote control method includes: accessing a remote terminal device in real time; allowing the access of the authorized manager using the smart phone; transmitting data; driving a CPU of the remote terminal device with SMS data to output a data value; stopping operation of the pump; comparing data input or output values stored and set in the CPU and a memory; determining whether to continuously perform a current operation; obtaining collected information; and feeding back all of the processed results to the smart phone."
METHOD AND SYSTEM FOR ASSESSING DAMAGE TO INFRASTRUCTURE,https://lens.org/079-844-948-708-393,2023,"A method and system may survey a property using aerial images captured from an unmanned aerial vehicle (UAV), a manned aerial vehicle (MAV) or from a satellite device. The method may include identifying a commercial property for a UAV to perform surveillance, and directing the UAV to hover over the commercial property and capture aerial images at predetermined time intervals. Furthermore, the method may include receiving the aerial images of the commercial property captured at the predetermined time intervals, detecting a surveillance event at the commercial property, generating a surveillance alert, and transmitting the surveillance alert to an electronic device associated with an owner of the commercial property."
METHOD AND SYSTEM FOR ASSESSING DAMAGE TO INFRASTRUCTURE,https://lens.org/079-844-948-708-393,2023,"A method and system may survey a property using aerial images captured from an unmanned aerial vehicle (UAV), a manned aerial vehicle (MAV) or from a satellite device. The method may include identifying a commercial property for a UAV to perform surveillance, and directing the UAV to hover over the commercial property and capture aerial images at predetermined time intervals. Furthermore, the method may include receiving the aerial images of the commercial property captured at the predetermined time intervals, detecting a surveillance event at the commercial property, generating a surveillance alert, and transmitting the surveillance alert to an electronic device associated with an owner of the commercial property."
Method and system for assessing damage to infrastructure,https://lens.org/171-255-591-974-005,2023,"A method and system may survey a property using aerial images captured from an unmanned aerial vehicle (UAV), a manned aerial vehicle (MAV) or from a satellite device. The method may include identifying a commercial property for a UAV to perform surveillance, and directing the UAV to hover over the commercial property and capture aerial images at predetermined time intervals. Furthermore, the method may include receiving the aerial images of the commercial property captured at the predetermined time intervals, detecting a surveillance event at the commercial property, generating a surveillance alert, and transmitting the surveillance alert to an electronic device associated with an owner of the commercial property."
DEVICE FOR CONTROLLING A ROBOT,https://lens.org/062-242-997-024-195,2010,"A device is disclosed for controlling a robot, with a robot control unit, and with a robot sensor such as a digital camera, which can be fitted on the robot and whose output signals can be supplied to an image recording unit. The output signals from the image recording unit connected to the camera can be supplied to an image processing device which is connected to the image recording unit. A coordinate transformation device is provided, in which the signals originating from the image processing unit and the robot control unit are processed and transformed into robot control signals, and the signals can be supplied back to the robot control unit."
DRONE INTERCEPTION,https://lens.org/190-540-346-750-421,2021,"The present disclosure provides a system for intercepting a rogue drone, the system comprising: a broad-angle electromagnetic radiation emitter for illuminating a cone of sky with coded electromagnetic radiation; and an air vehicle. The air vehicle comprises: an electromagnetic radiation detector for receiving coded electromagnetic radiation reflected from a rogue drone operating in the cone of sky; and a controller for determining the position of the rogue drone based on the received coded electromagnetic radiation. The present invention also provides an air vehicle for intercepting a rogue drone and a method of intercepting a rogue drone."
AERIAL CAMERA SYSTEM,https://lens.org/160-010-127-982-357,2012,"An aerial camera system including a plurality of main reels, a camera interface/safety reel and a stabilized camera head. The camera head is supported from main cables from the main reels with a safety reel cable providing power, data and video communication between the camera head and a main computer system. Each of the main reels, the camera interface/safety reel and the camera head are in communication with the main computer system, which controls the feeding and reeling in of the main cables. Further, the computer system controls the feeding and reeling in of the safety reel cable, which typically only follows the camera head as it moves in three-dimensional space, but may in emergency mode support the weight of the camera head and be used to slowly pull the camera head up and out of the way so that it does not interfere with any activity below the flight area."
Aerial camera system,https://lens.org/110-842-985-265-408,2018,"An aerial camera system including a plurality of main reels, a camera interface/safety reel and a stabilized camera head. The camera head is supported from main cables from the main reels with a safety reel cable providing power, data and video communication between the camera head and a main computer system. Each of the main reels, the camera interface/safety reel and the camera head are in communication with the main computer system, which controls the feeding and reeling in of the main cables. Further, the computer system controls the feeding and reeling in of the safety reel cable, which typically only follows the camera head as it moves in three-dimensional space, but may in emergency mode support the weight of the camera head and be used to slowly pull the camera head up and out of the way so that it does not interfere with any activity below the flight area."
Method for delivering a device to a target location,https://lens.org/195-662-251-057-525,2006,"An autonomous device that may include for example a camera, a transmitter for transmitting a signal from the camera and a storage compartment for retaining a substance in the device. A method of delivering a medicament to a patient including imaging a gastrointestinal tract with an autonomous device, identifying a target location in such tract, and releasing a medicament from the device at the target location."
Hub of intelligent IoT for light therapy and light therapy method based on IoT,https://lens.org/081-163-139-374-774,2022,"A hub of intelligent Internet of Things (IoT) for performing a light therapy using light irradiated by a light output device. The hub of intelligent IoT includes a sleep disorder reading unit determining whether a sleep disorder has occurred based on sleep pattern information; a control signal generator generating a control signal for controlling the light output device when it is determined that the sleep disorder has occurred; and a communication interface unit providing the control signal to the light output device. At least one device implementing the method of providing the intelligent voice recognition model may be associated with an artificial intelligence module, a unmanned aerial vehicle (UAV), a robot, an augmented reality (AR) device, a virtual reality (VR) device, devices related to 5G services, and the like."
HUB OF INTELLIGENT IoT FOR LIGHT THERAPY AND LIGHT THERAPY METHOD BASED ON IoT,https://lens.org/069-036-430-176-523,2020,"A hub of intelligent Internet of Things (IoT) for performing a light therapy using light irradiated by a light output device. The hub of intelligent IoT includes a sleep disorder reading unit determining whether a sleep disorder has occurred based on sleep pattern information; a control signal generator generating a control signal for controlling the light output device when it is determined that the sleep disorder has occurred; and a communication interface unit providing the control signal to the light output device. At least one device implementing the method of providing the intelligent voice recognition model may be associated with an artificial intelligence module, a unmanned aerial vehicle (UAV), a robot, an augmented reality (AR) device, a virtual reality (VR) device, devices related to 5G services, and the like."
UNMANNED AIRCRAFT,https://lens.org/151-427-755-592-787,2020,"In order to provide an unmanned aircraft capable of minimizing damage due to a crash caused by malfunction or the like during flight, a flight route is set on map information including a fall avoidance area, control is performed such that the aircraft flies on a set flight route, and information at each position during flight on the flight route is acquired in relation to the map information in real time to determine whether or not the aircraft is approaching the fall avoidance area. In a case where it is determined that the aircraft is approaching the fall avoidance area, control is performed so as to increase a flight speed."
Salvaging drone equipment,https://lens.org/177-232-961-446-960,1989,"Apparatus for salvaging a hit indicating sensor, mounted on a towed drone serving as target simulator and being fastened by means of a cable to a towing craft; the hit indicator is severed from the drone and parachuted to ground either on cable release or by external command."
An Unmanned Aerial Vehicle (UAV) Tracking System Based On Neural Network,https://lens.org/093-453-489-872-213,2021,"Abstract The invention relates to an unmanned aerial vehicle tracking system based on neural network, including an image acquisition module, a neural network processing module and a control module. The invention will gradually correct the rotation angle, flight height and flight speed of the UAV in the process of traveling by adjusting the rotational speed difference of each spiral wing and the overall rotational speed value during the key operation of the UAV according to the previous flight data. While ensuring that the UAV will not be damaged, the flight time of the UAV is gradually shortened, so as to effectively improve the flight efficiency of the UAV tracking system based on the neural network. Control module Neural network processing module Image acquisition module Flight database The control unit Fig.1"
DEVICE AND METHOD FOR CONTROLLING A ROBOT TO PERFORM A TASK,https://lens.org/171-235-387-034-755,2023,"A method for controlling a robot to perform a task. The method includes acquiring a target image data element comprising at least one target image from a perspective of an end-effector of the robot at a target position of the robot in which the robot has performed the task, acquiring an origin image data element comprising at least one origin image from the perspective of the end-effector of the robot at an origin position of the robot, supplying the origin image data element and the target image data element to a machine learning model configured to derive a delta movement between the origin current position and the target position and controlling the robot to move according to the delta movement to perform the task."
Multi-sensor-based unmanned aerial vehicle and method for controlling same,https://lens.org/128-002-558-312-427,2023,"An unmanned aerial vehicle may include: a sensor part configured to acquire inertia information or position information of the unmanned aerial vehicle; and a controller. The controller is configured to estimate the position of the unmanned aerial vehicle by applying the information acquired by the sensor part to an extended Kalman filter and control movement of the unmanned aerial vehicle, based on the estimated position of the unmanned aerial vehicle. The sensor part includes: an inertia sensor configured to acquire the inertia information of the unmanned aerial vehicle; a tag recognition sensor configured to recognize a tag attached to a rack and acquire absolute position information of the unmanned aerial vehicle; and an image sensor attached to the unmanned aerial vehicle so as to acquire an image of the movement environment of the unmanned aerial vehicle."
Multi-sensor-based unmanned aerial vehicle and method for controlling same,https://lens.org/128-002-558-312-427,2023,"An unmanned aerial vehicle may include: a sensor part configured to acquire inertia information or position information of the unmanned aerial vehicle; and a controller. The controller is configured to estimate the position of the unmanned aerial vehicle by applying the information acquired by the sensor part to an extended Kalman filter and control movement of the unmanned aerial vehicle, based on the estimated position of the unmanned aerial vehicle. The sensor part includes: an inertia sensor configured to acquire the inertia information of the unmanned aerial vehicle; a tag recognition sensor configured to recognize a tag attached to a rack and acquire absolute position information of the unmanned aerial vehicle; and an image sensor attached to the unmanned aerial vehicle so as to acquire an image of the movement environment of the unmanned aerial vehicle."
Control System for an Aircraft,https://lens.org/156-532-033-642-259,2008,A control system for an aircraft includes a main unit and a separate auxiliary unit in communication with the main unit. The main unit includes an arm support allowing attachment to an arm of an operator. The main unit also includes a control stick supported by the structural element and movable in a plurality of directions. The main unit further includes sensors for sensing movement of the control stick. The auxiliary unit includes a transmitter for sending a transmitter signal encoding the movement of the control stick to the aircraft.
Control system for an aircraft,https://lens.org/096-895-199-754-70X,2010,A control system for an aircraft includes a main unit and a separate auxiliary unit in communication with the main unit. The main unit includes an arm support allowing attachment to an arm of an operator. The main unit also includes a control stick supported by the structural element and movable in a plurality of directions. The main unit further includes sensors for sensing movement of the control stick. The auxiliary unit includes a transmitter for sending a transmitter signal encoding the movement of the control stick to the aircraft.
"Systems, apparatus, and methods for drone audio noise reduction",https://lens.org/128-622-690-166-954,2020,"Methods, systems, and apparatus for audio noise reduction from a drone are disclosed. An example apparatus includes an acoustic sensor to gather acoustic data and at least one rotational motion sensor to gather rotational motion data of a first rotor and second rotational motion data of a second rotor. The example apparatus also includes an analyzer to identify a first filter that matches the first rotational motion data and identify a second filter that matches the second rotational motion data. The analyzer also is to filter the acoustic data into filtered acoustic data with the first identified filter and the second identified filter and generate an audio signal based on the filtered acoustic data."
"SYSTEMS, APPARATUS, AND METHODS FOR DRONE AUDIO NOISE REDUCTION",https://lens.org/166-288-636-185-561,2019,"Methods, systems, and apparatus for audio noise reduction from a drone are disclosed. An example apparatus includes an acoustic sensor to gather acoustic data and at least one rotational motion sensor to gather rotational motion data of a first rotor and second rotational motion data of a second rotor. The example apparatus also includes an analyzer to identify a first filter that matches the first rotational motion data and identify a second filter that matches the second rotational motion data. The analyzer also is to filter the acoustic data into filtered acoustic data with the first identified filter and the second identified filter and generate an audio signal based on the filtered acoustic data."
METHOD AND APPARATUS FOR REMOTELY CONTROLLING A MICROPHONE,https://lens.org/118-244-602-766-522,2014,"A method and vehicle-based communication system are provided that control a remote microphone by determining that one or more of the remote microphone and a user of the remote microphone is in a field of view (FOV) of a video camera and, in response, instructing the remote microphone to configure itself to receive ambient audio. In various embodiments, the remote microphone may configure itself, or be explicitly instructed to configure itself, to receive ambient audio by adjusting one or more of a beam forming or omni-directional pattern, potentially including noise cancellation algorithms to facilitate reception of ambient audio in contrast to user directed audio. When the one or more of the remote microphone and a user of the remote microphone no longer is in a FOV of the video camera, the method and vehicle-based communication system may instruct the remote microphone to reconfigure itself to receive user directed audio."
Method for coordinating access points for backhaul aggregation in a telecommunications network and device,https://lens.org/144-205-354-205-160,2016,The device is adapted to implement the method.
Method for Controlling a Flight Movement of an Aerial Vehicle and Aerial Vehicle,https://lens.org/193-439-311-390-924,2022,"The preferred embodiments pertain to a method for controlling a flight movement of an aerial vehicle that includes acquiring first image data by means of a first camera device that is arranged on an aerial vehicle and configured for monitoring an environment of the aerial vehicle while flying, wherein the first image data are indicative of a first sequence of first camera images. The method also includes acquiring second image data by means of a second camera device that is arranged on an aerial vehicle and configured for monitoring the environment of the aerial vehicle while flying, wherein the second image data are indicative of a second sequence of second camera images. The processing includes determining object parameters for a position of a flight obstacle in the environment of the aerial vehicle if the first image analysis predicts the flight obstacle in the at least one camera measurement image and the second image analysis likewise identifies the flight obstacle in the at least one camera measurement image. An aerial vehicle is furthermore disclosed."
Method for Controlling a Flight Movement of an Aerial Vehicle and Aerial Vehicle,https://lens.org/193-439-311-390-924,2022,"The preferred embodiments pertain to a method for controlling a flight movement of an aerial vehicle that includes acquiring first image data by means of a first camera device that is arranged on an aerial vehicle and configured for monitoring an environment of the aerial vehicle while flying, wherein the first image data are indicative of a first sequence of first camera images. The method also includes acquiring second image data by means of a second camera device that is arranged on an aerial vehicle and configured for monitoring the environment of the aerial vehicle while flying, wherein the second image data are indicative of a second sequence of second camera images. The processing includes determining object parameters for a position of a flight obstacle in the environment of the aerial vehicle if the first image analysis predicts the flight obstacle in the at least one camera measurement image and the second image analysis likewise identifies the flight obstacle in the at least one camera measurement image. An aerial vehicle is furthermore disclosed."
Method for Controlling a Flight Movement of an Aerial Vehicle and Aerial Vehicle,https://lens.org/193-439-311-390-924,2022,"The preferred embodiments pertain to a method for controlling a flight movement of an aerial vehicle that includes acquiring first image data by means of a first camera device that is arranged on an aerial vehicle and configured for monitoring an environment of the aerial vehicle while flying, wherein the first image data are indicative of a first sequence of first camera images. The method also includes acquiring second image data by means of a second camera device that is arranged on an aerial vehicle and configured for monitoring the environment of the aerial vehicle while flying, wherein the second image data are indicative of a second sequence of second camera images. The processing includes determining object parameters for a position of a flight obstacle in the environment of the aerial vehicle if the first image analysis predicts the flight obstacle in the at least one camera measurement image and the second image analysis likewise identifies the flight obstacle in the at least one camera measurement image. An aerial vehicle is furthermore disclosed."
SYSTEMS AND METHODS FOR LOCALIZING AERIAL VEHICLE USING UNMANNED VEHICLE,https://lens.org/092-351-012-152-960,2020,A system includes at least one unmanned aerial vehicle and at least one unmanned vehicle communicatively coupled to the unmanned aerial vehicle. The unmanned aerial vehicle includes a propulsion system and an onboard pilot system configured to determine a flight path for the unmanned aerial vehicle. The unmanned vehicle includes a propulsion system and a localization system configured to determine a location of the unmanned aerial vehicle relative to the unmanned vehicle. The unmanned vehicle further includes a communication component configured to transmit location information to the unmanned aerial vehicle. The onboard pilot system is configured to determine the flight path based on the location information provided by the unmanned vehicle.
Automated camera system,https://lens.org/054-292-574-620-716,2005,An automated camera system for use during a sporting event includes at least one remote camera module positioned along a course or field of a sporting event. Each remote camera module includes a still photograph camera and a trigger device. Camera optical characteristics and orientation can be adjusted based on commands received from a user command center in electronic communication with the remote camera modules.
Smart device control method and smart device control system,https://lens.org/051-804-053-097-111,2016,"The present invention provides a smart device control method and a smart device control system. The method comprises: step S101, receiving a qualified human face image of a current user from user equipment and an instruction used for remotely controlling a smart device; step S102, determining whether the human face image matches a registered image of a registered user, and if yes, performing step S103, and if not, performing step S104; step S103, sending the instruction to the smart device; and step S104, prohibiting the instruction from being sent to the smart device. The method provided by the present invention can maximally lower the risk of an operation performed by a non-authentic user, thereby improving security of remotely controlling a smart device. The smart device control system also has the above advantages."
DRONE EQUIPPED WITH A VIDEO CAMERA SENDING SEQUENCES OF IMAGES CORRECTED FOR THE WOBBLE EFFECT,https://lens.org/118-326-016-627-748,2017,"The drone comprises a camera (14) having a rolling shutter digital sensor which sends video data (l) line by line. An inertial unit (26) sends a gyrometric signal representative of the variations in attitude (, , ) of the camera at a given instant. An image processing module (30) comprising an anti-wobble module receives the video data (l) and the gyrometric signal as inputs, and outputs video data processed and corrected for artifacts introduced by the vibrations of the motors of the drone. A complementary filtering module (36) applies a predetermined compensating transfer function to the gyrometric signal at the input of the anti-wobble module, which transfer function is an inverse transfer function of the frequency response of the gyrometric sensor of the inertial unit."
AUTOMATIC DUAL ROTOR SPEED CONTROL FOR HELICOPTERS,https://lens.org/126-994-367-301-970,2008,"A flight control system for a helicopter having a main rotor and a tail rotor is provided. The flight control system includes an automatic rotor speed control being configured to transition the main rotor and the tail rotor between a high speed and a low speed based upon a plurality of received information without requiring any pilot action, the plurality of received information comprising height above ground level, knot indicated air speed, outside air temperature, barometric altitude, pressure altitude, density altitude, and an engine operational status."
Automatic dual rotor speed control for helicopters,https://lens.org/084-538-817-174-104,2016,"A flight control system for a helicopter having a main rotor and a tail rotor is provided. The flight control system includes an automatic rotor speed control being configured to transition the main rotor and the tail rotor between a high speed and a low speed based upon a plurality of received information without requiring any pilot action, the plurality of received information comprising height above ground level, knot indicated air speed, outside air temperature, barometric altitude, pressure altitude, density altitude, and an engine operational status."
AUTOMATIC DUAL ROTOR SPEED CONTROL FOR HELICOPTERS,https://lens.org/196-773-040-806-31X,2007,"A flight control system for a helicopter having a main rotor and a tail rotor is provided. The flight control system includes an automatic rotor speed control being configured to transition the main rotor and the tail rotor between a high speed and a low speed based upon a plurality of received information without requiring any pilot action, the plurality of received information comprising height above ground level, knot indicated air speed, outside air temperature, barometric altitude, pressure altitude, density altitude, and an engine operational status."
Drone equipped with a video camera sending sequences of images corrected for the wobble effect,https://lens.org/159-370-232-786-01X,2018,"The drone comprises a camera (14) having a rolling shutter digital sensor which sends video data (l) line by line. An inertial unit (26) sends a gyrometric signal representative of the variations in attitude (, , ) of the camera at a given instant. An image processing module (30) comprising an anti-wobble module receives the video data (l) and the gyrometric signal as inputs, and outputs video data processed and corrected for artifacts introduced by the vibrations of the motors of the drone. A complementary filtering module (36) applies a predetermined compensating transfer function to the gyrometric signal at the input of the anti-wobble module, which transfer function is an inverse transfer function of the frequency response of the gyrometric sensor of the inertial unit."
AUTOMATIC DUAL ROTOR SPEED CONTROL FOR HELICOPTERS,https://lens.org/160-488-072-825-364,2008,"A flight control system for a helicopter having a main rotor and a tail rotor is provided. The flight control system includes an automatic rotor speed control being configured to transition the main rotor and the tail rotor between a high speed and a low speed based upon a plurality of received information without requiring any pilot action, the plurality of received information comprising height above ground level, knot indicated air speed, outside air temperature, barometric altitude, pressure altitude, density altitude, and an engine operational status."
Identification of unmanned aerial vehicles based on audio signatures,https://lens.org/089-901-777-418-893,2020,A device may receive audio information that includes an audio signature. The device may identify an unmanned aerial vehicle (UAV) based on the audio signature. The UAV may be identified based on a UAV identifier that is encoded into or determined based on the audio signature. The device may obtain profile information associated with the UAV based on the UAV identifier. The device may provide the profile information.
IDENTIFICATION OF UNMANNED AERIAL VEHICLES BASED ON AUDIO SIGNATURES,https://lens.org/058-541-809-902-997,2018,A device may receive audio information that includes an audio signature. The device may identify an unmanned aerial vehicle (UAV) based on the audio signature. The UAV may be identified based on a UAV identifier that is encoded into or determined based on the audio signature. The device may obtain profile information associated with the UAV based on the UAV identifier. The device may provide the profile information.
DENIAL OF SERVICE SYSTEMS AND METHODS,https://lens.org/114-442-741-267-186,2021,"A refuse vehicle system includes a refuse vehicle, a drone, and a controller. The drone includes a GPS and a sensor configured to provide data relating to a status of refuse within a scan area. The controller is configured to receive data from the sensor of the drone, determine the status of refuse within the scan area based on the data from the sensor of the drone, and at least one of generate a route for the refuse vehicle based on the status of refuse within the scan area, modify a route for the refuse vehicle based on the status of refuse within the scan area, and provide a signal to the refuse vehicle regarding the status of refuse within the scan area."
Vacuum cleaner and vacuum cleaning system and methods of use in a raised floor environment,https://lens.org/105-820-947-213-254,2015,"A remote-controlled, autonomous, or semi-autonomous vacuum cleaner for raised floor environments is especially configured to clean tight, hard-to-reach areas, such as the space between the floor and the raised panels of a raised access floor system and a control module for remotely operating the vacuum cleaner. The vacuum includes a body, a power source supported by the body, a vacuum module supported by the body, the vacuum module being configured to intake air and exhaust air, and a drive module supported by the body. The body includes an outer casing having channels formed therein, with the channels being configured to divide and channel exhaust flow and to direct exhaust flow in multiple directions."
Stand-alone remote real-time altitude readout method and system for small UAVs,https://lens.org/116-035-844-071-383,2019,"The invention comprises an apparatus and method for real-time readout of a recreational drone or UAV altitude. The invention includes an airborne sensor/transmitter unit and a ground based receiver/display unit. The airborne unit is removably attached to the flying vehicle and carried aloft. The ground based receiver/display unit is associated with the ground based operator (pilot) of the UAV. The airborne unit comprises an altitude sensor module, an RF transmitter module and a microcontroller/processor system. The ground based receiver/display unit comprises an RF receiver module, a microcontroller/processor system and a display system. UAV altitude sensed by the altitude sensor is transmitted to the ground unit for display in real-time. The invention facilitates the pilot's situational awareness, enhances safe operation and aids in compliance with applicable regulations."
Device and system for the automatic control of a helicopter,https://lens.org/172-805-673-888-055,2004,"Device and system for the automatic control of a helicopter.The automatic control device (6) comprises a vertical objective law (A) in respect of the pitching axis, which automatically determines a control command (UT1) for operating the tilting of the disk of main rotor of the helicopter, a speed limitation law (B) for limiting the airspeed of the helicopter with respect to at least one limit value, detection means (10) for automatically detecting whether the airspeed reaches the limit value, and toggling means (11) for, in order to select the objective law (A, B) whose control command (UT1, UT2) is used for the pitching axis, automatically toggling from the first law (A) to the second law (B), when the detection means (10) detect that the airspeed has reached the limit value."
PROGRAMMABLE WRIST DEVICE FOR MAKING AERIAL VIDEOS AND PHOTOS,https://lens.org/069-928-114-364-85X,2016,"A wrist programmable device (1) for making aerial videos and photos, comprising a watch strap (2) and a watch case body (4) removably coupled to said watch strap (2), said watch case body (4) having a bottom and a dial, at least videocamera means (T), hover means (13-14) for allowing said watch case body (4) to hover while separating from said watch strap (2), and programmable electronic means adapted to operatively control said at least videocamera means (T) and said hovering means (13-14)."
Systems and Methods for Autonomous Distress Tracking in Aerial Vehicles,https://lens.org/065-207-323-170-490,2019,Systems and methods for autonomous distress tracking (ADT) of aerial vehicles are provided. An autonomous distress tracking (ADT) system for an aerial vehicle is provided that includes one or more ADT devices. Each device includes at least one transmitter configured to transmit messages over one or more predetermined frequency bands. And ADT control system is configured to control a transmission rate of the one or more ADT devices based on flight plan data associated with an on-going flight of the aerial vehicle and performance data associated with the aerial vehicle during the on-going flight. The ADT control system can compare the flight plan data with the performance data to determine one or more deviations associated with the flight plan data and control a transmission rate of the one or more ADT devices based on the deviations.
Systems and methods for autonomous distress tracking in aerial vehicles,https://lens.org/123-198-984-917-74X,2020,Systems and methods for autonomous distress tracking (ADT) of aerial vehicles are provided. An autonomous distress tracking (ADT) system for an aerial vehicle is provided that includes one or more ADT devices. Each device includes at least one transmitter configured to transmit messages over one or more predetermined frequency bands. And ADT control system is configured to control a transmission rate of the one or more ADT devices based on flight plan data associated with an on-going flight of the aerial vehicle and performance data associated with the aerial vehicle during the on-going flight. The ADT control system can compare the flight plan data with the performance data to determine one or more deviations associated with the flight plan data and control a transmission rate of the one or more ADT devices based on the deviations.
Unmanned aerial image capture platform,https://lens.org/053-562-104-918-308,2019,"Methods and systems are disclosed for an unmanned aerial vehicle (UAV) configured to autonomously navigate a physical environment while capturing images of the physical environment. In some embodiments, the motion of the UAV and a subject in the physical environment may be estimated based in part on images of the physical environment captured by the UAV. In response to estimating the motions, image capture by the UAV may be dynamically adjusted to satisfy a specified criterion related to a quality of the image capture."
Unmanned aerial image capture platform,https://lens.org/143-410-666-941-606,2021,"Methods and systems are disclosed for an unmanned aerial vehicle (UAV) configured to autonomously navigate a physical environment while capturing images of the physical environment. In some embodiments, the motion of the UAV and a subject in the physical environment may be estimated based in part on images of the physical environment captured by the UAV. In response to estimating the motions, image capture by the UAV may be dynamically adjusted to satisfy a specified criterion related to a quality of the image capture."
UNMANNED AERIAL IMAGE CAPTURE PLATFORM,https://lens.org/138-292-357-443-691,2018,"Methods and systems are disclosed for an unmanned aerial vehicle (UAV) configured to autonomously navigate a physical environment while capturing images of the physical environment. In some embodiments, the motion of the UAV and a subject in the physical environment may be estimated based in part on images of the physical environment captured by the UAV. In response to estimating the motions, image capture by the UAV may be dynamically adjusted to satisfy a specified criterion related to a quality of the image capture."
UNMANNED AERIAL IMAGE CAPTURE PLATFORM,https://lens.org/129-510-174-442-027,2020,"Methods and systems are disclosed for an unmanned aerial vehicle (UAV) configured to autonomously navigate a physical environment while capturing images of the physical environment. In some embodiments, the motion of the UAV and a subject in the physical environment may be estimated based in part on images of the physical environment captured by the UAV. In response to estimating the motions, image capture by the UAV may be dynamically adjusted to satisfy a specified criterion related to a quality of the image capture."
Unmanned Aerial Image Capture Platform,https://lens.org/050-953-909-900-120,2022,"Methods and systems are disclosed for an unmanned aerial vehicle (UAV) configured to autonomously navigate a physical environment while capturing images of the physical environment. In some embodiments, the motion of the UAV and a subject in the physical environment may be estimated based in part on images of the physical environment captured by the UAV. In response to estimating the motions, image capture by the UAV may be dynamically adjusted to satisfy a specified criterion related to a quality of the image capture."
Unmanned aerial image capture platform,https://lens.org/155-656-074-005-000,2022,"Methods and systems are disclosed for an unmanned aerial vehicle (UAV) configured to autonomously navigate a physical environment while capturing images of the physical environment. In some embodiments, the motion of the UAV and a subject in the physical environment may be estimated based in part on images of the physical environment captured by the UAV. In response to estimating the motions, image capture by the UAV may be dynamically adjusted to satisfy a specified criterion related to a quality of the image capture."
Unmanned Aerial Image Capture Platform,https://lens.org/167-954-357-172-301,2023,"Methods and systems are disclosed for an unmanned aerial vehicle (UAV) configured to autonomously navigate a physical environment while capturing images of the physical environment. In some embodiments, the motion of the UAV and a subject in the physical environment may be estimated based in part on images of the physical environment captured by the UAV. In response to estimating the motions, image capture by the UAV may be dynamically adjusted to satisfy a specified criterion related to a quality of the image capture."
Unmanned aerial image capture platform,https://lens.org/155-656-074-005-000,2022,"Methods and systems are disclosed for an unmanned aerial vehicle (UAV) configured to autonomously navigate a physical environment while capturing images of the physical environment. In some embodiments, the motion of the UAV and a subject in the physical environment may be estimated based in part on images of the physical environment captured by the UAV. In response to estimating the motions, image capture by the UAV may be dynamically adjusted to satisfy a specified criterion related to a quality of the image capture."
CONTROL METHOD OF AUTONOMOUS VEHICLE,https://lens.org/062-344-599-568-709,2020,"A method of controlling of an autonomous vehicle according to an embodiment of the present disclosure, the method comprising the steps of: acquiring state information of a driver from a sensor mounted inside the vehicle; determining a glare state of the driver based on state information of the driver; operating a primary light source blocking when recognizing a glare state of the driver; operating, by the primary light source blocking, a light source blocking device mounted on the vehicle at the moment of recognizing the glare state of the driver, and tracking a gaze direction of the driver through a first image to acquire the gaze direction of the driver; and operating secondary light source blocking, when the acquired gaze direction of the driver is outside a predetermined range. The autonomous vehicle according to the present disclosure may be associated with an artificial intelligence module, a drone (UAV), a robot, an AR device, a VR device, a device related to 5G service, etc."
AUTONOMOUS PACKAGE STORAGE AND RETRIEVAL SYSTEM USING A DRONE,https://lens.org/139-437-693-221-255,2021,"A package delivery drone comprises at least one propeller for generating lift and an article containment area for containing an article to be carried by the drone. The floor of the article containment area comprises a dynamic support surface for supporting the article and allowing the article to move into, out of and through the article containment area. The package delivery drone interfaces with a docking station having a shelf for exchanging packages with the drone."
Apparatus and method for legged locomotion integrating passive dynamics with active force control,https://lens.org/017-205-673-066-749,2014,A robot for legged locomotion incorporating passive dynamics with active force control and method are provided.
APPARATUS AND METHOD FOR LEGGED LOCOMOTION INTEGRATING PASSIVE DYNAMICS WITH ACTIVE FORCE CONTROL,https://lens.org/048-904-747-619-519,2013,A robot for legged locomotion incorporating passive dynamics with active force control and method are provided.
Drone based capture of a multi-view interactive digital media,https://lens.org/140-723-616-921-066,2021,"Various embodiments of the present disclosure relate generally to systems and methods for drone-based systems and methods for capturing a multi-media representation of an entity. In some embodiments, the multi-media representation is digital, or multi-view, or interactive, and/or the combinations thereof. According to particular embodiments, a drone having a camera is controlled or operated to obtain a plurality of images having location information. The plurality of images, including at least a portion of overlapping subject matter, are fused to form multi-view interactive digital media representations."
AUTONOMOUS VEHICLE OPERATION,https://lens.org/059-669-126-406-387,2016,"A method for an autonomous vehicle to follow a target is provided. The method may include obtaining a position and a velocity of a target and obtaining a position of an autonomous vehicle. The method may also include obtaining a path that encloses the position of the target and determining a path rate for the autonomous vehicle to move along the path based on the velocity of the target. The method may also include determining a path position along the path based on the position of the autonomous vehicle and determining a change in the position of the autonomous vehicle based on the path position, the path rate, and the velocity of the target. The method may also include adjusting a velocity and a direction of the autonomous vehicle to achieve the change in the position of the autonomous vehicle."
Autonomous vehicle operation,https://lens.org/143-714-756-253-295,2017,"A method for an autonomous vehicle to follow a target is provided. The method may include obtaining a position and a velocity of a target and obtaining a position of an autonomous vehicle. The method may also include obtaining a path that encloses the position of the target and determining a path rate for the autonomous vehicle to move along the path based on the velocity of the target. The method may also include determining a path position along the path based on the position of the autonomous vehicle and determining a change in the position of the autonomous vehicle based on the path position, the path rate, and the velocity of the target. The method may also include adjusting a velocity and a direction of the autonomous vehicle to achieve the change in the position of the autonomous vehicle."
Autonomous vehicle operation,https://lens.org/011-296-181-768-013,2017,"A method for an autonomous vehicle to follow a target is provided. The method may include obtaining a position and a velocity of a target and obtaining a position of an autonomous vehicle. The method may also include obtaining a path that encloses the position of the target and determining a path rate for the autonomous vehicle to move along the path based on the velocity of the target. The method may also include determining a path position along the path based on the position of the autonomous vehicle and determining a change in the position of the autonomous vehicle based on the path position, the path rate, and the velocity of the target. The method may also include adjusting a velocity and a direction of the autonomous vehicle to achieve the change in the position of the autonomous vehicle."
AUTONOMOUS VEHICLE OPERATION,https://lens.org/178-043-750-386-017,2018,"A method for an autonomous vehicle to follow a target is provided. The method may include obtaining a position and a velocity of a target and obtaining a position of an autonomous vehicle. The method may also include obtaining a path that encloses the position of the target and determining a path rate for the autonomous vehicle to move along the path based on the velocity of the target. The method may also include determining a path position along the path based on the position of the autonomous vehicle and determining a change in the position of the autonomous vehicle based on the path position, the path rate, and the velocity of the target. The method may also include adjusting a velocity and a direction of the autonomous vehicle to achieve the change in the position of the autonomous vehicle."
AUTONOMOUS VEHICLE OPERATION,https://lens.org/035-865-767-087-459,2017,"A method for an autonomous vehicle to follow a target is provided. The method may include obtaining a position and a velocity of a target and obtaining a position of an autonomous vehicle. The method may also include obtaining a path that encloses the position of the target and determining a path rate for the autonomous vehicle to move along the path based on the velocity of the target. The method may also include determining a path position along the path based on the position of the autonomous vehicle and determining a change in the position of the autonomous vehicle based on the path position, the path rate, and the velocity of the target. The method may also include adjusting a velocity and a direction of the autonomous vehicle to achieve the change in the position of the autonomous vehicle."
APPARATUS AND METHOD FOR REMOTE CONTROL OF LIGHTING EQUIPMENTS,https://lens.org/027-818-517-571-406,2017,"An apparatus (11) for the remote control of lighting apparatuses, in particular emergency lighting apparatuses (12), comprising a transmitter apparatus provided with at least one light source having controlled activation, a receiver device used as a receiver of digital optical signals (16), which integrates a control, programming and management system managed by a software program (14), and a lighting apparatus (12), which incorporates a receiving circuit comprising a receiver photosensor (13); the transmitter apparatus is constituted by a smartphone (11), which actuates optical commands directed at the lighting apparatus (12), in a form of encoded luminous messages or intensity- and duration-controlled sequences of light variations according to a specific optical code and at different levels of luminosity, by means of a modulating process of the switching-on and the switching-off of the light source integrated in said smartphone (11)."
Wireless remote controlled mirror with integral lighting,https://lens.org/171-247-519-769-920,2004,"A wireless remote controlled mirror having lights to illuminate a subject being viewed in the mirror, while enabling a user to selectively adjust a view of the subject from a remote location. When attached to a rear seat of a vehicle, the mirror can be remotely adjusted to view a child in a rear-facing safety seat. The mirror includes a base adapted to mount to an object, a reflective lens that moves relative to the base, one or more electric motors to drive the reflective lens, and a receiver that detects a command signal from a wireless remote controller and energizes a motor to reorient the reflective lens to view the child. A plurality of light sources are selectively energized to emit light toward the subject, so that the mirror is usable after dark. The mirror can alternatively be mounted on other portions of a vehicle."
Wireless remote controlled mirror with integral lighting,https://lens.org/063-051-143-873-358,2003,"A wireless remote controlled mirror having lights to illuminate a subject being viewed in the mirror, while enabling a user to selectively adjust a view of the subject from a remote location. When attached to a rear seat of a vehicle, the mirror can be remotely adjusted to view a child in a rear-facing safety seat. The mirror includes a base adapted to mount to an object, a reflective lens that moves relative to the base, one or more electric motors to drive the reflective lens, and a receiver that detects a command signal from a wireless remote controller and energizes a motor to reorient the reflective lens to view the child. A plurality of light sources are selectively energized to emit light toward the subject, so that the mirror is usable after dark. The mirror can alternatively be mounted on other portions of a vehicle."
TRANSMITTER CONFIGURATION,https://lens.org/194-463-877-311-814,2008,"A system and method for controlling a remotely operated device, the remotely operated device controllable by an original transmitter. The system includes a processing circuit configured to receive information based on a first control signal transmitted by the original transmitter. The processing circuit is configured to automatically learn information relating to the first control signal to generate a second control signal. The second control signal is configured to control the remotely operated device based on the information received from the original transmitter. The system also includes a transmitter circuit in communication with the processing circuit. The transmitter circuit is configured to transmit the second control signal to the remotely operated device."
Unmanned aerial vehicle,https://lens.org/034-376-880-001-297,2021,"Provided is an unmanned aerial vehicle that broadcasts a route and future location information of the unmanned aerial vehicle within preset coverage based on sensing data and current location information of the unmanned aerial vehicle. The unmanned aerial vehicle includes a calculator configured to calculate a predicted route and second location information of the unmanned aerial vehicle corresponding to a preset period of time based on first location information and sensing data; and a transmitter configured to periodically broadcast a first notification signal that includes the first location information, the predicted route, and the second location information."
UNMANNED AERIAL VEHICLE,https://lens.org/188-333-701-923-304,2017,"Provided is an unmanned aerial vehicle that broadcasts a route and future location information of the unmanned aerial vehicle within preset coverage based on sensing data and current location information of the unmanned aerial vehicle. The unmanned aerial vehicle includes a calculator configured to calculate a predicted route and second location information of the unmanned aerial vehicle corresponding to a preset period of time based on first location information and sensing data; and a transmitter configured to periodically broadcast a first notification signal that includes the first location information, the predicted route, and the second location information."
Arming arrangement with rotatable airfoils,https://lens.org/044-959-806-926-328,1990,"An arming arrangement with rotatable airfoils or blades of a propeller constituting the deliverants for an arming criterium. The blades of the driving propeller for a drone, have the rotational movement thereof determined from the tail end of the drone towards one side of the propeller hub through a beam or radiation coupling and is then conducted to a counting evaluating circuit for the derivation of a release signal for the arming device."
Robotic Vehicle,https://lens.org/073-769-712-500-347,2018,"A robotic vehicle has legs and propellers to enable it to walk, fly, and or swim."
ROBOTIC VEHICLE,https://lens.org/106-489-013-619-487,2017,"A robotic vehicle has legs and propellers to enable it to walk, fly, and or swim."
Robotic vehicle,https://lens.org/081-929-478-937-232,2020,"A robotic vehicle has legs and propellers to enable it to walk, fly, and or swim."
ROBOTIC VEHICLE,https://lens.org/086-868-641-846-951,2016,"A robotic vehicle has legs and propellers to enable it to walk, fly, and or swim."
Method of controlling device and device thereof,https://lens.org/177-605-702-750-06X,2020,"A device and a method of controlling the device are provided. The method includes detecting a mobile device within a distance from the device, receiving user configuration information from the mobile device, and performing an operation of the device based on the user configuration information."
METHOD OF CONTROLLING DEVICE AND DEVICE THEREOF,https://lens.org/061-966-993-324-921,2016,"A device and a method of controlling the device are provided. The method includes detecting a mobile device within a distance from the device, receiving user configuration information from the mobile device, and performing an operation of the device based on the user configuration information."
METHOD OF CONTROLLING DEVICE AND DEVICE THEREOF,https://lens.org/104-666-059-940-550,2018,"A device and a method of controlling the device are provided. The method includes detecting a mobile device within a distance from the device, receiving user configuration information from the mobile device, and performing an operation of the device based on the user configuration information."
Method of controlling device and device thereof,https://lens.org/006-491-055-902-392,2018,"A device and a method of controlling the device are provided. The method includes detecting a mobile device within a distance from the device, receiving user configuration information from the mobile device, and performing an operation of the device based on the user configuration information."
METHODS AND APPARATUS TO NAVIGATE DRONES BASED ON WEATHER DATA,https://lens.org/057-159-169-402-199,2018,"Methods and apparatus to adjusting a flight path of a drone based on weather data are disclosed herein. An example apparatus includes navigating, via a processor of a drone, according to a flight path; intercepting, via the processor of the drone, weather data identified by a weather source within a threshold range of the flight path; and when the weather data corresponds to undesirable weather data, adjusting, via the processor of the drone, the flight path to avoid a region corresponding to the weather source."
METHODS AND APPARATUS TO NAVIGATE DRONES BASED ON WEATHER DATA,https://lens.org/051-365-004-638-944,2018,"Methods and apparatus to adjusting a flight path of a drone based on weather data are disclosed herein. An example apparatus includes navigating, via a processor of a drone, according to a flight path; intercepting, via the processor of the drone, weather data identified by a weather source within a threshold range of the flight path; and when the weather data corresponds to undesirable weather data, adjusting, via the processor of the drone, the flight path to avoid a region corresponding to the weather source."
STOWABLE UNMANNED AERIAL VEHICLES AND ASSOCIATED SYSTEMS AND METHODS,https://lens.org/059-550-276-888-045,2017,"Stowable and deployable unmanned aerial vehicles (UAVs), and associated systems and methods are disclosed. A UAV in accordance with a particular embodiment includes a main body, frames carried by the main body, and motors carried by the frames. At least two frames are positioned to move relative to each other between a stowed configuration in which the frames are generally aligned proximate to each other and a deployed configuration different from the stowed configuration. The main body can include a first body portion pivotably connected to a second body portion. In a stowed configuration, the body portions can generally overlap each other. A UAV in accordance with particular embodiments includes a modular electronics unit carried by the UAV and including a camera, a battery, and a vehicle controller. Modular electronics units can be configured to be removably connected to and disconnected from the UAV and other vehicles."
STOWABLE UNMANNED AERIAL VEHICLES AND ASSOCIATED SYSTEMS AND METHODS,https://lens.org/038-520-507-459-83X,2017,"Stowable and deployable unmanned aerial vehicles (UAVs), and associated systems and methods are disclosed. A UAV in accordance with a particular embodiment includes a main body, frames carried by the main body, and motors carried by the frames. At least two frames are positioned to move relative to each other between a stowed configuration in which the frames are generally aligned proximate to each other and a deployed configuration different from the stowed configuration. The main body can include a first body portion pivotably connected to a second body portion. In a stowed configuration, the body portions can generally overlap each other. A UAV in accordance with particular embodiments includes a modular electronics unit carried by the UAV and including a camera, a battery, and a vehicle controller. Modular electronics units can be configured to be removably connected to and disconnected from the UAV and other vehicles."
System and method for detecting and controlling a drone implanted in a network attached device such as a computer,https://lens.org/148-295-710-439-498,2003,"A system and method for detecting a drone implanted by a vandal in a network connected host device such as a computer, and controlling the output of the drone. The system includes an inbound intrusion detection system (IDS), an outbound IDS, a blocker such as a firewall, an inbound trace log for storing a trace of inbound traffic to the protected device, an outbound trace log for storing a trace of outbound traffic from the protected device, and a correlator. When the outbound IDS detects outbound distributed denial of service (DDoS) traffic, the outbound IDS instructs the blocker to block the outbound DDoS traffic. The correlator then recalls the outbound trace log and the inbound trace log, correlates the logs, and deduces the source ID of a message responsible for triggering the drone. The correlator then instructs the blocker to block incoming messages that bear the source ID."
Autonomously acting robot that recognizes direction of sound source,https://lens.org/184-176-858-502-16X,2022,"A robot detects a voice using a microphone array, and identifies a sound source direction. The robot directs a head portion in the sound source direction. When an object including characteristics as a voice emitting body is detected in a filming region of a sound source direction identified using the microphone array, the voice emitting body is identified as a voice emission source. When a voice emitting body is identified as a voice emission source, the robot directs a body toward a sound source (emission source). When a special environmental sound is detected, a predetermined motion is executed."
Autonomously acting robot that recognizes direction of sound source,https://lens.org/184-176-858-502-16X,2022,"A robot detects a voice using a microphone array, and identifies a sound source direction. The robot directs a head portion in the sound source direction. When an object including characteristics as a voice emitting body is detected in a filming region of a sound source direction identified using the microphone array, the voice emitting body is identified as a voice emission source. When a voice emitting body is identified as a voice emission source, the robot directs a body toward a sound source (emission source). When a special environmental sound is detected, a predetermined motion is executed."
AUTONOMOUSLY ACTING ROBOT THAT RECOGNIZES DIRECTION OF SOUND SOURCE,https://lens.org/113-366-252-499-332,2019,"A robot detects a voice using a microphone array, and identifies a sound source direction. The robot directs a head portion in the sound source direction. When an object including characteristics as a voice emitting body is detected in a filming region of a sound source direction identified using the microphone array, the voice emitting body is identified as a voice emission source. When a voice emitting body is identified as a voice emission source, the robot directs a body toward a sound source (emission source). When a special environmental sound is detected, a predetermined motion is executed."
RE-SEARCH METHOD DURING UAV LANDING PROCESS,https://lens.org/130-858-324-914-505,2019,"An unmanned aerial vehicle (UAV) landing system is disclosed. The UAV landing system includes a memory; an imaging device; and a processor in communication with the memory and imaging device, wherein the processor is configured to: acquire, via the imaging device, a landing target; descend the UAV into a first zone associated with the landing target; determine if the landing target is within a field of view; and descend the UAV toward the landing target if the landing target is determined to be within the field of view."
RE-SEARCH METHOD DURING UAV LANDING PROCESS,https://lens.org/188-109-717-790-044,2018,"An unmanned aerial vehicle (UAV) landing system is disclosed. The UAV landing system includes a memory; an imaging device; and a processor in communication with the memory and imaging device, wherein the processor is configured to: acquire, via the imaging device, a landing target; descend the UAV into a first zone associated with the landing target; determine if the landing target is within a field of view; and descend the UAV toward the landing target if the landing target is determined to be within the field of view."
CUSTOMIZED PACKAGING FOR UNMANNED AUTONOMOUS VEHICLE ITEM DELIVERY,https://lens.org/110-395-710-505-415,2017,Various embodiments enable delivering an item using an unmanned autonomous vehicle (UAV) in response to receiving an electronic order for an item. Order parameters may be determined based on the electronic order identifying the item and details regarding delivery of the item. UAV components may be selected for operating the UAV based on UAV parameters meeting the order parameters. UAV-compliant packaging parameters may be determined for transporting the item carried by the UAV. Selected UAV-compliant packaging may enable the UAV to meet at least some of the order parameters and the UAV parameters. Assembly of the UAV may be coordinated to include the selected UAV components and selected UAV-compliant packaging with the item therein. The selected UAV-compliant packaging may meet the determined UAV-compliant packaging parameters. The assembled UAV and packaging may be dispatched for delivering the item.
Customized packaging for unmanned autonomous vehicle item delivery,https://lens.org/118-825-403-175-514,2019,Various embodiments enable delivering an item using an unmanned autonomous vehicle (UAV) in response to receiving an electronic order for an item. Order parameters may be determined based on the electronic order identifying the item and details regarding delivery of the item. UAV components may be selected for operating the UAV based on UAV parameters meeting the order parameters. UAV-compliant packaging parameters may be determined for transporting the item carried by the UAV. Selected UAV-compliant packaging may enable the UAV to meet at least some of the order parameters and the UAV parameters. Assembly of the UAV may be coordinated to include the selected UAV components and selected UAV-compliant packaging with the item therein. The selected UAV-compliant packaging may meet the determined UAV-compliant packaging parameters. The assembled UAV and packaging may be dispatched for delivering the item.
Remote controlled lift assembly,https://lens.org/139-350-928-587-277,2022,A remote controlled lift assembly includes a pair of supports is each mountable to a respective outrigger of scaffolding. A winch unit is positionable on the supports when the supports are mounted on the scaffolding and the winch unit has a cable extending downwardly therefrom. The cable is lowered or lifted when the winch is actuated. A receiver is coupled to the winch unit and the receiver is in electrical communication with the winch unit. A remote control is provided that is carried by a user and the remote control is in wireless electrical communication with the receiver. In this way the user can remotely lift and lower the cable for lifting and lowering cargo.
Remote controlled lift assembly,https://lens.org/139-350-928-587-277,2022,A remote controlled lift assembly includes a pair of supports is each mountable to a respective outrigger of scaffolding. A winch unit is positionable on the supports when the supports are mounted on the scaffolding and the winch unit has a cable extending downwardly therefrom. The cable is lowered or lifted when the winch is actuated. A receiver is coupled to the winch unit and the receiver is in electrical communication with the winch unit. A remote control is provided that is carried by a user and the remote control is in wireless electrical communication with the receiver. In this way the user can remotely lift and lower the cable for lifting and lowering cargo.
Remote Controlled Lift Assembly,https://lens.org/189-158-296-068-818,2021,A remote controlled lift assembly includes a pair of supports is each mountable to a respective outrigger of scaffolding. A winch unit is positionable on the supports when the supports are mounted on the scaffolding and the winch unit has a cable extending downwardly therefrom. The cable is lowered or lifted when the winch is actuated. A receiver is coupled to the winch unit and the receiver is in electrical communication with the winch unit. A remote control is provided that is carried by a user and the remote control is in wireless electrical communication with the receiver. In this way the user can remotely lift and lower the cable for lifting and lowering cargo.
PORTABLE AERIAL RECONNAISSANCE TARGETING INTELLIGENCE DEVICE,https://lens.org/024-309-153-999-502,2017,"A device for obtaining surveillance information from an aerial vehicle. The device includes a camera configured to obtain image data based on a position of the vehicle, a transceiver configured to receive operator controls and output the obtained image data, a designator unit configured to emit a light source onto a surface of an object of interest to illuminate that surface when a designation command is received from an operator, a gimbal mechanism having a plurality of motors configured to orient the designator unit, a gimbal controller configured to control the motors of the gimbal mechanism, and a controller configured to control the designator unit to continuously emit the light source onto the surface of the object irrespective of the position of the vehicle. The controller compensates for an orientation of the designator unit based on the aerial vehicle's movement such that the designator unit continuously illuminates the object."
PORTABLE AERIAL RECONNAISSANCE TARGETING INTELLIGENCE DEVICE,https://lens.org/054-752-595-632-964,2017,"A device for obtaining surveillance information from an aerial vehicle. The device includes a camera configured to obtain image data based on a position of the vehicle, a transceiver configured to receive operator controls and output the obtained image data, a designator unit configured to emit a light source onto a surface of an object of interest to illuminate that surface when a designation command is received from an operator, a gimbal mechanism having a plurality of motors configured to orient the designator unit, a gimbal controller configured to control the motors of the gimbal mechanism, and a controller configured to control the designator unit to continuously emit the light source onto the surface of the object irrespective of the position of the vehicle. The controller compensates for an orientation of the designator unit based on the aerial vehicle's movement such that the designator unit continuously illuminates the object."
PORTABLE AERIAL RECONNAISSANCE TARGETING INTELLIGENCE DEVICE,https://lens.org/170-339-100-015-785,2017,"A device for obtaining surveillance information from an aerial vehicle. The device includes a camera configured to obtain image data based on a position of the vehicle, a transceiver configured to receive operator controls and output the obtained image data, a designator unit configured to emit a light source onto a surface of an object of interest to illuminate that surface when a designation command is received from an operator, a gimbal mechanism having a plurality of motors configured to orient the designator unit, a gimbal controller configured to control the motors of the gimbal mechanism, and a controller configured to control the designator unit to continuously emit the light source onto the surface of the object irrespective of the position of the vehicle. The controller compensates for an orientation of the designator unit based on the aerial vehicle's movement such that the designator unit continuously illuminates the object."
Portable aerial reconnaissance targeting intelligence device,https://lens.org/135-063-349-096-353,2020,"A device for obtaining surveillance information from an aerial vehicle. The device includes a camera configured to obtain image data based on a position of the vehicle, a transceiver configured to receive operator controls and output the obtained image data, a designator unit configured to emit a light source onto a surface of an object of interest to illuminate that surface when a designation command is received from an operator, a gimbal mechanism having a plurality of motors configured to orient the designator unit, a gimbal controller configured to control the motors of the gimbal mechanism, and a controller configured to control the designator unit to continuously emit the light source onto the surface of the object irrespective of the position of the vehicle. The controller compensates for an orientation of the designator unit based on the aerial vehicle's movement such that the designator unit continuously illuminates the object."
PORTABLE AERIAL RECONNAISSANCE TARGETING INTELLIGENCE DEVICE,https://lens.org/144-657-459-677-540,2018,"A device for obtaining surveillance information from an aerial vehicle. The device includes a camera configured to obtain image data based on a position of the vehicle, a transceiver configured to receive operator controls and output the obtained image data, a designator unit configured to emit a light source onto a surface of an object of interest to illuminate that surface when a designation command is received from an operator, a gimbal mechanism having a plurality of motors configured to orient the designator unit, a gimbal controller configured to control the motors of the gimbal mechanism, and a controller configured to control the designator unit to continuously emit the light source onto the surface of the object irrespective of the position of the vehicle. The controller compensates for an orientation of the designator unit based on the aerial vehicle's movement such that the designator unit continuously illuminates the object."
"AUTONOMOUS MOVEMENT DEVICE, AUTONOMOUS MOVEMENT METHOD AND PROGRAM RECORDING MEDIUM",https://lens.org/079-884-410-360-301,2019,"An autonomous movement device includes an obstacle detector, a map creator, an obstacle canceller, and a router. The obstacle detector detects an obstacle. The map creator records information about the obstacle detected by the obstacle detector on an environment map. The obstacle canceller cancels the information about the obstacle recorded by the map creator from the environment map. The router sets a moving route based on the information recorded on the environment map."
"Autonomous movement device, autonomous movement method and program recording medium",https://lens.org/153-508-746-742-277,2020,"An autonomous movement device includes an obstacle detector, a map creator, an obstacle canceller, and a router. The obstacle detector detects an obstacle. The map creator records information about the obstacle detected by the obstacle detector on an environment map. The obstacle canceller cancels the information about the obstacle recorded by the map creator from the environment map. The router sets a moving route based on the information recorded on the environment map."
Method for sensor data processing,https://lens.org/164-669-418-443-370,2021,"A method for remote operation of a robot, preferably including: recording a set of sensor streams; transmitting a transmission stream; selecting a received stream for display; and/or displaying the selected stream. A system, preferably including a robot and a remote operation system connected to the robot by one or more communication networks."
Method for sensor data processing,https://lens.org/001-707-684-025-458,2020,"A method for remote operation of a robot, preferably including: recording a set of sensor streams; transmitting a transmission stream; selecting a received stream for display; and/or displaying the selected stream. A system, preferably including a robot and a remote operation system connected to the robot by one or more communication networks."
METHOD FOR SENSOR DATA PROCESSING,https://lens.org/059-120-525-154-30X,2018,"A method for remote operation of a robot, preferably including: recording a set of sensor streams; transmitting a transmission stream; selecting a received stream for display; and/or displaying the selected stream. A system, preferably including a robot and a remote operation system connected to the robot by one or more communication networks."
METHOD FOR SENSOR DATA PROCESSING,https://lens.org/132-753-143-018-754,2020,"A method for remote operation of a robot, preferably including: recording a set of sensor streams; transmitting a transmission stream; selecting a received stream for display; and/or displaying the selected stream. A system, preferably including a robot and a remote operation system connected to the robot by one or more communication networks."
CAMERA APPARATUS AND SYSTEM,https://lens.org/119-893-409-225-763,2015,A camera apparatus is provided comprising a camera including camera control electronics and a control means wherein the control means is located within the camera. A system is also provided comprising the camera apparatus and a remote control terminal in communication with the apparatus wherein control of the camera is via a user interface generated at the control terminal from data signals received from the control means located within the camera.
METHOD AND SYSTEM FOR MONITORING UNMANNED AERIAL VEHICLE,https://lens.org/111-316-170-841-626,2021,"A method for monitoring an unmanned aerial vehicle (UAV) includes: acquiring, by a processor of the UAV, an UAV monitoring message, wherein the UAV monitoring message includes information on one or more of: identification information related to the UAV and status information related to the UAV ( S201); composing, by the processor of the UAV, a Service Discovery Frame (SDF) carrying the UAV monitoring message, the SDF being compliant with a Neighbor Awareness Networking (NAN) protocol (S202); wirelessly broadcasting, by the UAV, the SDF carrying the UAV monitoring message; receiving the broadcasted SDF by a user terminal (S203); acquiring the UAV monitoring message from the received SDF by the user terminal (S204); and outputting the UAV monitoring message through an interface of the user terminal (S205)."
Controller for an unmanned aerial vehicle,https://lens.org/014-254-857-808-892,2019,"An unmanned aerial vehicle (UAV) 60 captures image data which includes an image of part of a vehicle 40 which is obscured from a field of view 73 of a user 50 of a user device 70. The UAV controller uses positional data relating to the UAV, the vehicle and the user device, processes that data to determine the relative locations, and outputs image data that is received from the UAV. The relative locations may be used to determine the obscured portions of the vehicle, and the positional data may comprise (differential) GPS data. The UAV may have an inertial navigation system (INS). Time-of-flight measurement data or image recognition algorithms may also be used. The UAV may be controlled to keep it on the opposite side of the vehicle to the user, or to capture images of a part of the vehicle near an obstacle detected by a vehicle sensor."
Unmanned aerial vehicle light flash synchronization,https://lens.org/115-745-017-512-309,2021,"Herein is disclosed an unmanned aerial vehicle light flash comprising a support structure; a camera coupled to the support structure and configured to take a photograph; one or more processors coupled to the support structure and configured to control a predetermined flight plan of the unmanned aerial vehicle, control the camera, generate or process a synchronization signal to synchronize a light flash to be generated by a further unmanned aerial vehicle with a taking of the photograph by the camera; a transceiver coupled to the support structure and configured to transmit or receive the synchronization signal to or from the further unmanned aerial vehicle."
EXTENDABLE CAMERA,https://lens.org/134-737-790-071-298,2015,"An extendable imager configured to capture an image responsive to a command from a mobile device and an arm coupled to the imager, the arm configured to extend the imager from a surface of the mobile device."
"ROBOT, ROBOT SYSTEM, CONTROL DEVICE, AND CONTROL METHOD",https://lens.org/134-608-467-726-556,2017,"A robot includes: a hand; and a control unit that operates the hand, in which the control unit generates three-dimensional point group information for a partial image forming a captured image obtained by an imaging unit, and causes the hand to hold an object included in the partial image."
"Robot, robot system, control device, and control method",https://lens.org/063-313-376-493-900,2020,"A robot includes: a hand; and a control unit that operates the hand, in which the control unit generates three-dimensional point group information for a partial image forming a captured image obtained by an imaging unit, and causes the hand to hold an object included in the partial image."
"Robot, robot system, control device, and control method",https://lens.org/086-828-237-918-558,2017,"A robot includes: a hand; and a control unit that operates the hand, in which the control unit generates three-dimensional point group information for a partial image forming a captured image obtained by an imaging unit, and causes the hand to hold an object included in the partial image."
"ROBOT, ROBOT SYSTEM, CONTROL DEVICE, AND CONTROL METHOD",https://lens.org/092-885-228-069-337,2015,"A robot includes: a hand; and a control unit that operates the hand, in which the control unit generates three-dimensional point group information for a partial image forming a captured image obtained by an imaging unit, and causes the hand to hold an object included in the partial image."
Storage unit for an unmanned aerial vehicle,https://lens.org/145-903-437-660-657,2021,"A storage unit for an Unmanned Aerial Vehicle (UAV) includes a container, a UAV landing platform, and a receptacle. The container is provided for enclosing the UAV. The receptacle is positioned above the UAV landing platform and it includes at least one inclined surface for guiding a landing UAV to a predetermined UAV landing position on the UAV landing platform."
SYSTEM AND METHOD FOR CONTROLLING APPLIANCES USING MOTION GESTURES,https://lens.org/055-722-234-983-67X,2020,"A method and system of controlling an appliance includes: receiving, from a first home appliance, a request to start video image processing for detecting a motion gesture of a user (402); processing a sequence of image frames captured by a camera corresponding to the first home appliance to identify a first motion gesture (404); selecting a second home appliance as a target home appliance for the first motion gesture in accordance with one or more target selection criteria, including first target selection criteria based on a location of the user relative to the first hone appliance and second target selection criteria based on a level of match between the first motion gesture and a first control gesture corresponding to the second home appliance (406); and generating a control command to control the second home appliance in accordance with the first control gesture corresponding to the second home appliance (408)."
AERIAL VEHICLE,https://lens.org/066-092-385-172-247,2023,"An aerial vehicle includes a body and a wireless charging receiver pad connected to the body, whereby the aerial vehicle is configured to be wirelessly charged when parked above a wireless charging transmitter pad. The aerial vehicle includes landing gear connected to the body and extending underneath the body. The landing gear is configured for actuation to control the location of the receiver pad with respect to the transmitter pad."
AERIAL VEHICLE,https://lens.org/066-092-385-172-247,2023,"An aerial vehicle includes a body and a wireless charging receiver pad connected to the body, whereby the aerial vehicle is configured to be wirelessly charged when parked above a wireless charging transmitter pad. The aerial vehicle includes landing gear connected to the body and extending underneath the body. The landing gear is configured for actuation to control the location of the receiver pad with respect to the transmitter pad."
Aerial vehicle,https://lens.org/006-709-849-535-925,2023,"An aerial vehicle includes a body and a wireless charging receiver pad connected to the body, whereby the aerial vehicle is configured to be wirelessly charged when parked above a wireless charging transmitter pad. The aerial vehicle includes landing gear connected to the body and extending underneath the body. The landing gear is configured for actuation to control the location of the receiver pad with respect to the transmitter pad."
Remotely controlled backhoe,https://lens.org/130-110-325-758-188,2012,A remotely controlled backhoe is provided to permit operation of a backhoe and visual monitoring of a volatile or dangerous excavation site from a safe distance. The backhoe has an articulated rear boom arm and a rear bucket. Cameras are coupled to the backhoe proximate a left rear corner and a right rear corner of the cabin roof. A rear boom arm control is positioned on a remote control unit. The rear boom arm control is operationally coupled to the rear boom arm for maneuvering the rear boom arm. A rear bucket control is also positioned on the remote control unit and operationally coupled to the rear bucket for maneuvering the rear bucket. A monitor is coupled to the remote control unit and operationally coupled to the left rear camera and the right rear camera for displaying images from the left rear camera and the right rear camera.
Compartmentalized self registration of external devices,https://lens.org/110-026-141-799-13X,2015,"A device may receive, from a peripheral device, information for controlling the peripheral device. The information for controlling the peripheral device may include information identifying a voice command associated with the peripheral device and information identifying a function corresponding to the voice command. The device may receive, from a user, the voice command. The device may cause the peripheral device to perform the function based on receiving the voice command."
COMPARTMENTALIZED SELF REGISTRATION OF EXTERNAL DEVICES,https://lens.org/046-503-586-203-44X,2015,"A device may receive, from a peripheral device, information for controlling the peripheral device. The information for controlling the peripheral device may include information identifying a voice command associated with the peripheral device and information identifying a function corresponding to the voice command. The device may receive, from a user, the voice command. The device may cause the peripheral device to perform the function based on receiving the voice command."
EXOSKELETON DEVICE,https://lens.org/077-480-003-935-936,2019,An exoskeleton device is provided herein that includes a control unit including a controller. At least one embedded sensor is configured to acquire data. An actuator is in electrical communication with the at least one embedded sensor and the controller. The controller is configured to adjust a level of assistance or resistance provided by the actuator in response to a change in a performance metric as measured by the acquired data.
EXOSKELETON DEVICE,https://lens.org/049-298-552-719-949,2021,An exoskeleton device is provided herein that includes a control unit including a controller. At least one embedded sensor is configured to acquire data. An actuator is in electrical communication with the at least one embedded sensor and the controller. The controller is configured to adjust a level of assistance or resistance provided by the actuator in response to a change in a performance metric as measured by the acquired data.
Exoskeleton device,https://lens.org/178-568-047-671-096,2021,An exoskeleton device is provided herein that includes a control unit including a controller. At least one embedded sensor is configured to acquire data. An actuator is in electrical communication with the at least one embedded sensor and the controller. The controller is configured to adjust a level of assistance or resistance provided by the actuator in response to a change in a performance metric as measured by the acquired data.
MULTI-SENSOR ENVIRONMENTAL MAPPING,https://lens.org/157-071-977-142-005,2021,"A method for controlling a UAV in an environment includes receiving first and second sensing signals from a vision sensor and a proximity sensor, respectively, coupled to the UAV. The first and second sensing signals include first and second depth information of the environment, respectively. The method further includes selecting the first and second sensing signals for generating first and second portions of an environmental map, respectively, based on a suitable criterion associated with distinct characteristics of various portions of the environment or distinct capabilities of the vision sensor and the proximity sensor, generating first and second sets of depth images for the first and second portions of the environmental map, respectively, based on the first and second sensing signals, respectively, combining the first and second sets of depth images to generate the environmental map; and effecting the UAV to navigate in the environment using the environmental map."
PORTABLE CONTROLLER FOR OPERATING A DEVICE FROM A REMOTE LOCATION,https://lens.org/075-016-773-774-727,2006,"A portable remote controller is disclosed herein. The remote controller is useful with a vehicle or other controlled device so that an operator can run all primary functions therewith from one hand while doing something else with the other hand. In some embodiments, the remote controller is readily dockable for storage, working with other applications, positioning and operation in a fixed remote location, or able to be passed to someone else for like usage."
Resilient Remote Surveillance System and Method,https://lens.org/103-992-965-189-911,2014,"A method, system, and medium are provided for remotely monitoring a surveillance area, including deploying a ruggedized, secure enclosure that includes a controller coupled to a switch, a router, and a video-server appliance within the enclosure, the controller configured to provide remote operation and status information by way of a graphical user interface presentable via a remote server coupled to the router via a wireless link, wherein each of the controller, switch, router, and video-server appliance is configured to be powered by a battery; by way of a communications path to a remote computing device, sending video information received by one or more cameras coupled to the enclosure; and periodically sending data through a wireless portion of the communications path even if no video information is sent through the wireless portion."
Resilient remote surveillance system and method,https://lens.org/183-148-868-035-273,2015,"A method, system, and medium are provided for remotely monitoring a surveillance area, including deploying a ruggedized, secure enclosure that includes a controller coupled to a switch, a router, and a video-server appliance within the enclosure, the controller configured to provide remote operation and status information by way of a graphical user interface presentable via a remote server coupled to the router via a wireless link, wherein each of the controller, switch, router, and video-server appliance is configured to be powered by a battery; by way of a communications path to a remote computing device, sending video information received by one or more cameras coupled to the enclosure; and periodically sending data through a wireless portion of the communications path even if no video information is sent through the wireless portion."
Navigation system with operation obstacle alert mechanism and method of operation thereof,https://lens.org/005-799-355-850-98X,2021,"A navigation system includes: a control unit configured to: identify a route obstacle in a travel environment of a user vehicle during operation of the user vehicle in an autonomous operation mode; generate an obstacle handling assessment of whether the user vehicle is capable of navigation beyond the route obstacle in the autonomous operation mode; generate an obstacle orientation alert based on the obstacle handling assessment and an engagement state of a system user of the user vehicle; a user interface, coupled to the control unit, configured to present the obstacle orientation alert."
NAVIGATION SYSTEM WITH OPERATION OBSTACLE ALERT MECHANISM AND METHOD OF OPERATION THEREOF,https://lens.org/181-064-144-215-040,2020,"A navigation system includes: a control unit configured to: identify a route obstacle in a travel environment of a user vehicle during operation of the user vehicle in an autonomous operation mode; generate an obstacle handling assessment of whether the user vehicle is capable of navigation beyond the route obstacle in the autonomous operation mode; generate an obstacle orientation alert based on the obstacle handling assessment and an engagement state of a system user of the user vehicle; a user interface, coupled to the control unit, configured to present the obstacle orientation alert."
Software-defined multi-mode ultra-wideband radar for autonomous vertical take-off and landing of small unmanned aerial systems,https://lens.org/134-088-798-441-25X,2015,"A small unmanned aerial system (sUAS) is used for aerial and on the ground surveillance while an operator of the sUAS, or other personnel, remain at a safe distance. The sUAS system can perform an autonomous landing and can be operated at an extended, e.g., greater than 100 meters, standoff from the detection apparatus and potential harm. The sUAS may be implemented as an easy-to-operate, small vertical take-off and landing (VTOL) aircraft with a set of optical, thermal, and chemical detection modules for performing aerial surveillance and ground surveillance after landing."
SOFTWARE-DEFINED MULTI-MODE ULTRA-WIDEBAND RADAR FOR AUTONOMOUS VERTICAL TAKE-OFF AND LANDING OF SMALL UNMANNED AERIAL SYSTEMS,https://lens.org/191-047-578-443-17X,2014,"A small unmanned aerial system (sUAS) is used for aerial and on the ground surveillance while an operator of the sUAS, or other personnel, remain at a safe distance. The sUAS system can perform an autonomous landing and can be operated at an extended, e.g., greater than 100 meters, standoff from the detection apparatus and potential harm. The sUAS may be implemented as an easy-to-operate, small vertical take-off and landing (VTOL) aircraft with a set of optical, thermal, and chemical detection modules for performing aerial surveillance and ground surveillance after landing."
Privacy mode for always-on voice-activated information assistant,https://lens.org/038-104-311-584-919,2016,"A user device and method discriminately provides audible responses to a voice command received by a user device that supports voice activation. The method includes detecting a first pre-established, audible activation command that activates the user device. In response to detecting the first pre-established, audible activation command, the method includes producing a first audible acknowledgement within loudspeaker proximity of the user device and then monitoring for detection of at least one second, audible acknowledgement produced by another user device within a pre-set time interval, which detection would indicate that the other user device is also responding. The method includes processing and responding to a received audible command in response to not detecting. However, in response to detecting, the method includes triggering entry into a privacy mode of audible command input and producing a privacy mode announcement via at least one of a display and a sound producing component."
PRIVACY MODE FOR ALWAYS-ON VOICE-ACTIVATED INFORMATION ASSISTANT,https://lens.org/190-576-661-195-450,2014,"A user device and method discriminately provides audible responses to a voice command received by a user device that supports voice activation. The method includes detecting a first pre-established, audible activation command that activates the user device. In response to detecting the first pre-established, audible activation command, the method includes producing a first audible acknowledgement within loudspeaker proximity of the user device and then monitoring for detection of at least one second, audible acknowledgement produced by another user device within a pre-set time interval, which detection would indicate that the other user device is also responding. The method includes processing and responding to a received audible command in response to not detecting. However, in response to detecting, the method includes triggering entry into a privacy mode of audible command input and producing a privacy mode announcement via at least one of a display and a sound producing component."
Method and apparatus for surface attachment of modular unmanned aerial vehicle for inspection,https://lens.org/192-098-927-250-074,2023,A modular aerial vehicle for inspection of enclosed and open space environments. The aerial vehicle is employed for inspection of various environments in remotely controlled and autonomous fashions. The aerial vehicle is capable of carrying different sensory modules depending on the specific application including surface inspection. Aerial vehicle may be connected to a tether cable for electrical power delivery and transmission of control commands. The aerial vehicle may utilize a landing structure which allows landing on any angled metallic or non-metallic surface.
METHOD AND APPARATUS FOR SURFACE ATTACHMENT OF MODULAR UNMANNED AERIAL VEHICLE FOR INSPECTION,https://lens.org/037-733-244-505-787,2020,A modular aerial vehicle for inspection of enclosed and open space environments. The aerial vehicle is employed for inspection of various environments in remotely controlled and autonomous fashions. The aerial vehicle is capable of carrying different sensory modules depending on the specific application including surface inspection. Aerial vehicle may be connected to a tether cable for electrical power delivery and transmission of control commands. The aerial vehicle may utilize a landing structure which allows landing on any angled metallic or non-metallic surface.
Method and apparatus for surface attachment of modular unmanned aerial vehicle for inspection,https://lens.org/192-098-927-250-074,2023,A modular aerial vehicle for inspection of enclosed and open space environments. The aerial vehicle is employed for inspection of various environments in remotely controlled and autonomous fashions. The aerial vehicle is capable of carrying different sensory modules depending on the specific application including surface inspection. Aerial vehicle may be connected to a tether cable for electrical power delivery and transmission of control commands. The aerial vehicle may utilize a landing structure which allows landing on any angled metallic or non-metallic surface.
Remote control unmanned fishing boat and device for remote control thereof,https://lens.org/111-213-182-230-804,2001,"This invention concerns a remote control unmanned fishing boat intended for enjoyment of remote control fishing and a remote control device for use with the boat. The invention contemplates enabling the operator to advance the boat forward and backward and change the direction of the advance of the boat by manipulating the remote control device 2. By the operator using the remote control device 2 for actuating a depth sounder, the information concerning the depth of water and the condition of water bottom determined by the depth sounder is displayed on a monitor 41 of the remote control device 2. When the optimum position for fishing is found consequently, the operator is allowed to lower his fish hook in the water by manipulating the remote control device 2."
Flying robot,https://lens.org/062-487-839-488-635,2023,"A flying robot comprising: a flying body unit; a propulsion portion comprising a plurality of propulsion units configured to cause propulsion to occur by driving rotor blades, the plurality of propulsion units being provided on the flying body unit; a working body unit; a manipulator unit configured to be capable of executing predetermined work and comprising one or more work manipulators provided on the working body unit; and connection units provided on the working body unit and the flying body unit so as to enable the flying body unit to be connected with and disconnected from the working body unit; wherein the flying robot executes the predetermined work by the work manipulators in a state in which the working body unit and the flying body unit are connected at the connection units. The flying robot is caused to execute a wide range of content of work as far as possible."
FLYING ROBOT,https://lens.org/074-014-758-633-373,2021,"A flying robot comprising: a flying body unit; a propulsion portion comprising a plurality of propulsion units configured to cause propulsion to occur by driving rotor blades, the plurality of propulsion units being provided on the flying body unit; a working body unit; a manipulator unit configured to be capable of executing predetermined work and comprising one or more work manipulators provided on the working body unit; and connection units provided on the working body unit and the flying body unit so as to enable the flying body unit to be connected with and disconnected from the working body unit; wherein the flying robot executes the predetermined work by the work manipulators in a state in which the working body unit and the flying body unit are connected at the connection units. The flying robot is caused to execute a wide range of content of work as far as possible."
Controlling a robot in an environment,https://lens.org/198-465-791-780-411,2022,"There is provided a method of controlling a robot within an environment comprising: i) receiving, from a 3D scanner, data relating to at least a portion of the environment for constructing a 3D point cloud representing at least a portion of the environment; ii) comparing the 3D point cloud to a virtual 3D model of the environment and, based upon the comparison, determining a position of the robot; then iii) determining a movement trajectory for the robot based upon the determined position of the robot. Also provided is a control apparatus and a robot control system."
CONTROLLING A ROBOT IN AN ENVIRONMENT,https://lens.org/018-220-786-299-348,2019,"There is provided a method of controlling a robot within an environment comprising: i) receiving, from a 3D scanner, data relating to at least a portion of the environment for constructing a 3D point cloud representing at least a portion of the environment; ii) comparing the 3D point cloud to a virtual 3D model of the environment and, based upon the comparison, determining a position of the robot; then iii) determining a movement trajectory for the robot based upon the determined position of the robot. Also provided is a control apparatus and a robot control system."
CONTROLLING A ROBOT IN AN ENVIRONMENT,https://lens.org/118-514-601-670-665,2019,"There is provided a method of controlling a robot within an environment comprising: i) receiving, from a 3D scanner, data relating to at least a portion of the environment for constructing a 3D point cloud representing at least a portion of the environment; ii) comparing the 3D point cloud to a virtual 3D model of the environment and, based upon the comparison, determining a position of the robot; then iii) determining a movement trajectory for the robot based upon the determined position of the robot. Also provided is a control apparatus and a robot control system."
Controlling a robot in an environment,https://lens.org/198-465-791-780-411,2022,"There is provided a method of controlling a robot within an environment comprising: i) receiving, from a 3D scanner, data relating to at least a portion of the environment for constructing a 3D point cloud representing at least a portion of the environment; ii) comparing the 3D point cloud to a virtual 3D model of the environment and, based upon the comparison, determining a position of the robot; then iii) determining a movement trajectory for the robot based upon the determined position of the robot. Also provided is a control apparatus and a robot control system."
Bifurcated speaker specific and non-speaker specific speech recognition method and apparatus,https://lens.org/176-809-513-655-598,2000,"Bifurcated speaker specific and non-speaker specific method and apparatus is provided for enabling speech-based remote control and for recognizing the speech of an unspecified speaker at extremely high recognition rates regardless of the speaker's age, sex, or individual speech mannerisms. A device main unit is provided with a speech recognition processor for recognizing speech and taking an appropriate action, and with a user terminal containing specific speaker capture and/or preprocessing capabilities. The user terminal exchanges data with the speech recognition processor using radio transmission. The user terminal may be provided with a conversion rule generator that compares the speech of a user with previously compiled standard speech feature data and, based on this comparison result, generates a conversion rule for converting the speaker's speech feature parameters to corresponding standard speaker's feature information. The speech recognition processor, in turn, may reference the conversion rule developed in the user terminal and perform speech recognition based on the input speech feature parameters that have been converted above."
System for identifying and controlling unmanned aerial vehicles,https://lens.org/101-586-107-635-421,2018,A beacon for attachment to an unmanned aerial vehicle that provides information needed to identify the owner of a particular unmanned vehicle. The beacon may also include a remote communications module configured to participate on wireless or optical communications networks and a beacon control system configured to issue commands compatible with the unmanned aerial vehicle. The beacon may further a beacon control system configured to translate multiple types of commands from different controls systems into commands compatible with the unmanned aerial vehicle.
SYSTEM FOR IDENTIFYING AND CONTROLLING UNMANNED AERIAL VEHICLES,https://lens.org/099-588-520-353-945,2018,A beacon for attachment to an unmanned aerial vehicle that provides information needed to identify the owner of a particular unmanned vehicle. The beacon may also include a remote communications module configured to participate on wireless or optical communications networks and a beacon control system configured to issue commands compatible with the unmanned aerial vehicle. The beacon may further a beacon control system configured to translate multiple types of commands from different controls systems into commands compatible with the unmanned aerial vehicle.
AERIAL VEHICLE INCLUDING AUTONOMOUS ROTOR SPEED CONTROL,https://lens.org/018-956-854-654-914,2016,"A rotary aerial vehicle (AV) includes an engine configured to rotate at least one rotor at a variable rotor speed, a full authority electronic microcontroller (FAEM) in electrical communication with the engine. The FAEM is configured to output at least one electronic engine control signal that controls operation of the engine. An electronic rotor speed microcontroller (ERSM) is in electrical communication with the FAEM, and the ERSM is configured to dynamically determine at least one mission objective of the rotary AV, and outputs an electronic rotor speed control signal that commands the FAEM to adjust the rotor speed of the at least one rotor."
Aerial vehicle including autonomous rotor speed control,https://lens.org/175-604-146-267-757,2020,"A rotary aerial vehicle (AV) includes an engine configured to rotate at least one rotor at a variable rotor speed, a full authority electronic microcontroller (FAEM) in electrical communication with the engine. The FAEM is configured to output at least one electronic engine control signal that controls operation of the engine. An electronic rotor speed microcontroller (ERSM) is in electrical communication with the FAEM, and the ERSM is configured to dynamically determine at least one mission objective of the rotary AV, and outputs an electronic rotor speed control signal that commands the FAEM to adjust the rotor speed of the at least one rotor."
AERIAL VEHICLE INCLUDING AUTONOMOUS ROTOR SPEED CONTROL,https://lens.org/111-299-613-603-87X,2018,"A rotary aerial vehicle (AV) includes an engine configured to rotate at least one rotor at a variable rotor speed, a full authority electronic microcontroller (FAEM) in electrical communication with the engine. The FAEM is configured to output at least one electronic engine control signal that controls operation of the engine. An electronic rotor speed microcontroller (ERSM) is in electrical communication with the FAEM, and the ERSM is configured to dynamically determine at least one mission objective of the rotary AV, and outputs an electronic rotor speed control signal that commands the FAEM to adjust the rotor speed of the at least one rotor."
AERIAL VEHICLE INCLUDING AUTONOMOUS ROTOR SPEED CONTROL,https://lens.org/191-418-007-236-695,2017,"A rotary aerial vehicle (AV) includes an engine configured to rotate at least one rotor at a variable rotor speed, a full authority electronic microcontroller (FAEM) in electrical communication with the engine. The FAEM is configured to output at least one electronic engine control signal that controls operation of the engine. An electronic rotor speed microcontroller (ERSM) is in electrical communication with the FAEM, and the ERSM is configured to dynamically determine at least one mission objective of the rotary AV, and outputs an electronic rotor speed control signal that commands the FAEM to adjust the rotor speed of the at least one rotor."
ACOUSTIC MODEM-BASED GUIDING METHOD FOR AUTONOMOUS UNDERWATER VEHICLE FOR MARINE SEISMIC SURVEYS,https://lens.org/114-815-983-525-917,2014,"An autonomous underwater vehicle (AUV) records seismic signals during a marine seismic survey. The AUV includes a communication device configured to acoustically receive location information from plural transducers of a vessel, wherein each transducer of the vessel transmits its own geographical location; a navigation system configured to receive the location information from the communication device and to calculate current and target positions of the AUV; a propulsion system configured to drive the AUV from the current position to the target position; and a seismic sensor for recording seismic data after reaching a final target position."
Acoustic modem-based guiding method for autonomous underwater vehicle for marine seismic surveys,https://lens.org/076-165-055-686-699,2017,"An autonomous underwater vehicle (AUV) records seismic signals during a marine seismic survey. The AUV includes a communication device configured to acoustically receive location information from plural transducers of a vessel, wherein each transducer of the vessel transmits its own geographical location; a navigation system configured to receive the location information from the communication device and to calculate current and target positions of the AUV; a propulsion system configured to drive the AUV from the current position to the target position; and a seismic sensor for recording seismic data after reaching a final target position."
ACOUSTIC MODEM-BASED GUIDING METHOD FOR AUTONOMOUS UNDERWATER VEHICLE FOR MARINE SEISMIC SURVEYS,https://lens.org/044-968-196-626-380,2015,"An autonomous underwater vehicle (AUV) records seismic signals during a marine seismic survey. The AUV includes a communication device configured to acoustically receive location information from plural transducers of a vessel, wherein each transducer of the vessel transmits its own geographical location; a navigation system configured to receive the location information from the communication device and to calculate current and target positions of the AUV; a propulsion system configured to drive the AUV from the current position to the target position; and a seismic sensor for recording seismic data after reaching a final target position."
METHOD AND APPARATUS FOR CONTROLLING SOUND BOX,https://lens.org/165-957-649-828-393,2020,"A method for controlling a sound box, includes: in response to the sound box being in a standby state, emitting an ultrasonic signal, and receiving a reflected ultrasonic signal reflected by an external object; acquiring a moving trajectory of the external object according to the reflected ultrasonic signal; and determining a target operation instruction to be executed according to the moving trajectory of the external object."
METHOD AND APPARATUS FOR CONTROLLING SOUND BOX,https://lens.org/165-957-649-828-393,2020,"A method for controlling a sound box, includes: in response to the sound box being in a standby state, emitting an ultrasonic signal, and receiving a reflected ultrasonic signal reflected by an external object; acquiring a moving trajectory of the external object according to the reflected ultrasonic signal; and determining a target operation instruction to be executed according to the moving trajectory of the external object."
"AUTONOMOUS MOBILE BODY CONTROL DEVICE, AUTONOMOUS MOBILE BODY, AND AUTONOMOUS MOBILE BODY CONTROL METHOD",https://lens.org/198-397-519-863-718,2023,"An autonomous mobile body control device includes a control unit that is capable of executing a first movement control that controls movement of an autonomous mobile body on the basis of a main map, and a second movement control that controls the movement of the autonomous mobile body on the basis of a local map. In the case that a map used when causing the autonomous mobile body to move is switched from the main map to the local map, or alternatively, in the case that the map used when causing the autonomous mobile body to move is switched from the local map to the main map, the control unit temporarily executes a third movement control that controls the movement of the autonomous mobile body on the basis of a landmark appearing in an acquired image."
Autonomous Aerial Vehicle Hardware Configuration,https://lens.org/102-711-830-046-69X,2023,"An introduced autonomous aerial vehicle can include multiple cameras for capturing images of a surrounding physical environment that are utilized for motion planning by an autonomous navigation system. In some embodiments, the cameras can be integrated into one or more rotor assemblies that house powered rotors to free up space within the body of the aerial vehicle. In an example embodiment, an aerial vehicle includes multiple upward-facing cameras and multiple downward-facing cameras with overlapping fields of view to enable stereoscopic computer vision in a plurality of directions around the aerial vehicle. Similar camera arrangements can also be implemented in fixed-wing aerial vehicles."
Autonomous aerial vehicle hardware configuration,https://lens.org/149-875-734-121-510,2022,"An introduced autonomous aerial vehicle can include multiple cameras for capturing images of a surrounding physical environment that are utilized for motion planning by an autonomous navigation system. In some embodiments, the cameras can be integrated into one or more rotor assemblies that house powered rotors to free up space within the body of the aerial vehicle. In an example embodiment, an aerial vehicle includes multiple upward-facing cameras and multiple downward-facing cameras with overlapping fields of view to enable stereoscopic computer vision in a plurality of directions around the aerial vehicle. Similar camera arrangements can also be implemented in fixed-wing aerial vehicles."
Autonomous Aerial Vehicle Hardware Configuration,https://lens.org/094-336-842-507-393,2022,"An introduced autonomous aerial vehicle can include multiple cameras for capturing images of a surrounding physical environment that are utilized for motion planning by an autonomous navigation system. In some embodiments, the cameras can be integrated into one or more rotor assemblies that house powered rotors to free up space within the body of the aerial vehicle. In an example embodiment, an aerial vehicle includes multiple upward-facing cameras and multiple downward-facing cameras with overlapping fields of view to enable stereoscopic computer vision in a plurality of directions around the aerial vehicle. Similar camera arrangements can also be implemented in fixed-wing aerial vehicles."
Autonomous aerial vehicle hardware configuration,https://lens.org/149-875-734-121-510,2022,"An introduced autonomous aerial vehicle can include multiple cameras for capturing images of a surrounding physical environment that are utilized for motion planning by an autonomous navigation system. In some embodiments, the cameras can be integrated into one or more rotor assemblies that house powered rotors to free up space within the body of the aerial vehicle. In an example embodiment, an aerial vehicle includes multiple upward-facing cameras and multiple downward-facing cameras with overlapping fields of view to enable stereoscopic computer vision in a plurality of directions around the aerial vehicle. Similar camera arrangements can also be implemented in fixed-wing aerial vehicles."
Autonomous Aerial Vehicle Hardware Configuration,https://lens.org/102-711-830-046-69X,2023,"An introduced autonomous aerial vehicle can include multiple cameras for capturing images of a surrounding physical environment that are utilized for motion planning by an autonomous navigation system. In some embodiments, the cameras can be integrated into one or more rotor assemblies that house powered rotors to free up space within the body of the aerial vehicle. In an example embodiment, an aerial vehicle includes multiple upward-facing cameras and multiple downward-facing cameras with overlapping fields of view to enable stereoscopic computer vision in a plurality of directions around the aerial vehicle. Similar camera arrangements can also be implemented in fixed-wing aerial vehicles."
AUTONOMOUS AERIAL VEHICLE HARDWARE CONFIGURATION,https://lens.org/082-839-238-257-753,2019,"An introduced autonomous aerial vehicle can include multiple cameras for capturing images of a surrounding physical environment that are utilized for motion planning by an autonomous navigation system. In some embodiments, the cameras can be integrated into one or more rotor assemblies that house powered rotors to free up space within the body of the aerial vehicle. In an example embodiment, an aerial vehicle includes multiple upward-facing cameras and multiple downward-facing cameras with overlapping fields of view to enable stereoscopic computer vision in a plurality of directions around the aerial vehicle. Similar camera arrangements can also be implemented in fixed-wing aerial vehicles."
Autonomous Aerial Vehicle Hardware Configuration,https://lens.org/094-336-842-507-393,2022,"An introduced autonomous aerial vehicle can include multiple cameras for capturing images of a surrounding physical environment that are utilized for motion planning by an autonomous navigation system. In some embodiments, the cameras can be integrated into one or more rotor assemblies that house powered rotors to free up space within the body of the aerial vehicle. In an example embodiment, an aerial vehicle includes multiple upward-facing cameras and multiple downward-facing cameras with overlapping fields of view to enable stereoscopic computer vision in a plurality of directions around the aerial vehicle. Similar camera arrangements can also be implemented in fixed-wing aerial vehicles."
Autonomous Aerial Vehicle Hardware Configuration,https://lens.org/111-014-913-854-759,2023,"An introduced autonomous aerial vehicle can include multiple cameras for capturing images of a surrounding physical environment that are utilized for motion planning by an autonomous navigation system. In some embodiments, the cameras can be integrated into one or more rotor assemblies that house powered rotors to free up space within the body of the aerial vehicle. In an example embodiment, an aerial vehicle includes multiple upward-facing cameras and multiple downward-facing cameras with overlapping fields of view to enable stereoscopic computer vision in a plurality of directions around the aerial vehicle. Similar camera arrangements can also be implemented in fixed-wing aerial vehicles."
Autonomous Aerial Vehicle Hardware Configuration,https://lens.org/111-014-913-854-759,2023,"An introduced autonomous aerial vehicle can include multiple cameras for capturing images of a surrounding physical environment that are utilized for motion planning by an autonomous navigation system. In some embodiments, the cameras can be integrated into one or more rotor assemblies that house powered rotors to free up space within the body of the aerial vehicle. In an example embodiment, an aerial vehicle includes multiple upward-facing cameras and multiple downward-facing cameras with overlapping fields of view to enable stereoscopic computer vision in a plurality of directions around the aerial vehicle. Similar camera arrangements can also be implemented in fixed-wing aerial vehicles."
Autonomous Aerial Vehicle Hardware Configuration,https://lens.org/013-275-142-275-523,2022,"An introduced autonomous aerial vehicle can include multiple cameras for capturing images of a surrounding physical environment that are utilized for motion planning by an autonomous navigation system. In some embodiments, the cameras can be integrated into one or more rotor assemblies that house powered rotors to free up space within the body of the aerial vehicle. In an example embodiment, an aerial vehicle includes multiple upward-facing cameras and multiple downward-facing cameras with overlapping fields of view to enable stereoscopic computer vision in a plurality of directions around the aerial vehicle. Similar camera arrangements can also be implemented in fixed-wing aerial vehicles."
Autonomous Aerial Vehicle Hardware Configuration,https://lens.org/013-275-142-275-523,2022,"An introduced autonomous aerial vehicle can include multiple cameras for capturing images of a surrounding physical environment that are utilized for motion planning by an autonomous navigation system. In some embodiments, the cameras can be integrated into one or more rotor assemblies that house powered rotors to free up space within the body of the aerial vehicle. In an example embodiment, an aerial vehicle includes multiple upward-facing cameras and multiple downward-facing cameras with overlapping fields of view to enable stereoscopic computer vision in a plurality of directions around the aerial vehicle. Similar camera arrangements can also be implemented in fixed-wing aerial vehicles."
Autonomous Aerial Vehicle Hardware Configuration,https://lens.org/094-336-842-507-393,2022,"An introduced autonomous aerial vehicle can include multiple cameras for capturing images of a surrounding physical environment that are utilized for motion planning by an autonomous navigation system. In some embodiments, the cameras can be integrated into one or more rotor assemblies that house powered rotors to free up space within the body of the aerial vehicle. In an example embodiment, an aerial vehicle includes multiple upward-facing cameras and multiple downward-facing cameras with overlapping fields of view to enable stereoscopic computer vision in a plurality of directions around the aerial vehicle. Similar camera arrangements can also be implemented in fixed-wing aerial vehicles."
Remote monitoring system for a security lock,https://lens.org/013-494-126-374-943,2007,"A remote control, monitoring and recording system for a security system to remove control from the site of the door to an off-site location, and to help prevent unauthorised access to a safe or vault."
SYSTEM AND METHOD FOR PROVIDING VOICE ASSISTANT SERVICE,https://lens.org/101-910-315-700-250,2020,"Provided are an artificial intelligence (Al) system that utilizes a machine learning algorithm such as deep learning, etc., and an application of the Al system. A method performed by a device for providing a voice assistant service through a voice assistant program includes: receiving, from an external device, a character specialized model for the voice assistant program; receiving a user voice input including a request for a response of the voice assistant program and a word indicating a character; determining the character specialized model according to the word indicating the character; generating a response message to the request for the response of the voice assistant program, using the character specialized model; and outputting the generated response message."
Two-Axis Bracket Assembly With Smart Linear Actuators and Remote Smart Controller,https://lens.org/015-813-540-648-581,2021,"A 2-axis bracket assembly with smart linear actuators forms a mount for one or more sensors, and is controllable via a remote smart controller for the actuators, which may in turn be controlled by a remote PC and may control multiple 2-axis bracket assemblies. A two-axis gimballed support is mounted to an elevated structure, and a sensor is fixed thereto. The gimballed support includes a gimbal assembly, and a bracket to mount the assembly on a pole, a bracket assembly to hold the sensor. The gimbal assembly connects the pole bracket to the sensor bracket, permitting two-axis motion therebetween. Two smart linear actuators, one connecting the pole bracket to the gimbal assembly, and one connecting the sensor bracket to the gimbal assembly control the position of the sensor bracket and the sensor."
Robot and robot system,https://lens.org/037-284-762-807-928,2020,"A robot includes a base, an arm provided on the base, an actuator that drives the arm, a connector to which at least a part of a first wire of another apparatus is connected, and a second wire that connects the actuator and the connector, and the base has a housing having an hole, to which the connector is fixed and a lid covering at least a part of the hole, through which the first wire is inserted."
Robot And Robot System,https://lens.org/195-578-616-128-532,2018,"A robot includes a base, an arm provided on the base, an actuator that drives the arm, a connector to which at least a part of a first wire of another apparatus is connected, and a second wire that connects the actuator and the connector, and the base has a housing having an hole, to which the connector is fixed and a lid covering at least a part of the hole, through which the first wire is inserted."
DEVICE AND METHOD FOR READING UTILITY METERS,https://lens.org/088-286-717-013-159,2022,"A device (1) for reading utility meters comprises a transceiver configured to send and/or receive data to/from utility meters; a drone (3) having a seat (31), the transceiver being inserted in the seat (31); fastening means (4) configured to lock the transceiver in the seat (31)."
DEVICE AND METHOD FOR READING UTILITY METERS,https://lens.org/088-286-717-013-159,2022,"A device (1) for reading utility meters comprises a transceiver configured to send and/or receive data to/from utility meters; a drone (3) having a seat (31), the transceiver being inserted in the seat (31); fastening means (4) configured to lock the transceiver in the seat (31)."
AUTONOMOUS DRILLING,https://lens.org/067-265-082-935-285,2015,"A control system for autonomous drilling comprises an acoustic sensor (13) configured to provide acoustic data in near real time, a CPU (12) and a drilling module (3) with a steerable drilling device (9) and a drilling motor (11). The CPU (12) is configured to detect a different material (210) based on the acoustic data, and for providing the drilling device (3) with a directional vector (90) independent of a priori or predefined curvature. The CPU ( 12) may be disposed in the drilling module (3). In an alternative embodiment, the CPU (12) is located at the surface, and the autonomous drilling is performed as a mode of operation without any human intervention or steering."
UNMANNED VEHICLE AND UNMANNED VEHICLE CONTROLLING SYSTEM,https://lens.org/139-830-087-900-216,2020,"An unmanned vehicle and an unmanned vehicle controlling system are disclosed. The unmanned vehicle controlling system includes the unmanned vehicle and a controller. The unmanned vehicle includes a body, a first localization module and a second localization module. The first localization module and the second localization module are disposed on the body. The controller is used for sending a localization signal to the first localization module and a second localization module. The unmanned vehicle controls the direction that the body faces and the distance between the unmanned vehicle and the controller."
UNMANNED VEHICLE AND UNMANNED VEHICLE CONTROLLING SYSTEM,https://lens.org/179-027-009-123-368,2020,"An unmanned vehicle and an unmanned vehicle controlling system are disclosed. The unmanned vehicle controlling system includes the unmanned vehicle and a controller. The unmanned vehicle includes a body, a first localization module and a second localization module. The first localization module and the second localization module are disposed on the body. The controller is used for sending a localization signal to the first localization module and a second localization module. The unmanned vehicle controls the direction that the body faces and the distance between the unmanned vehicle and the controller."
Smoke marker,https://lens.org/141-016-292-882-059,1977,"A smoke marker for indicating the location of a target drone. An aluminum tube with one open end and one closed end contains a polyethylene bottle filled with titanium tetrachloride, a smoke chemical. The bottle is held in place within the tube by means of set screws adjacent the bottle's neck. A nylon washer containing an explosive primer and a metallic disc are disposed between the bottle and the closed end of the tube. The open end of the tube is potted closed with styrofoam potting. Upon ignition, the explosive primer forces the copper disc to collapse the bottom of the bottle. The neck of the bottle shears and the titanium tetrachloride is expelled from the aluminum tube and the bottle, creating a 25 to 30 foot cloud of smoke."
RADAR ANTENNA FOR USE IN A MINIATURE UNMANNED AERIAL VEHICLE,https://lens.org/171-986-998-341-604,2021,"A radar antenna suitable for a drone is provided, which is able to compensate for the agility of drone motion. The radar antenna contains a sandwich of two printed circuit boards between three conductive plates. A first printed circuit board comprises a preferably circular array of first antenna elements such as dipoles. A second printed circuit board, parallel to the first printed circuit board, comprises an array of second antenna elements. One of the array of first antenna elements and the array of second antenna elements is an array of transmission antenna elements and the other an array of reception antenna elements. The first printed circuit board is located below the second printed circuit board. Three conductive plates are used to shape the antenna patterns from the antenna elements so that the main lobes of the antenna patterns are directed obliquely downwards and the antenna patterns from the different array at least partly overlap, suppressing vertical side lobes. A first conductive plate separates the first and second printed circuit boards. A second conductive plate is located above the second printed circuit board, extending radially outward beyond the first conductive plate. A third conductive plate is located below the first printed circuit board. The first conductive plate extends radially outward beyond the third conductive plate."
RADAR ANTENNA FOR USE IN A MINIATURE UNMANNED AERIAL VEHICLE,https://lens.org/171-557-404-296-75X,2019,"A radar antenna suitable for a drone is provided, which is able to compensate for the agility of drone motion. The radar antenna contains a sandwich of two printed circuit boards between three conductive plates. A first printed circuit board comprises a preferably circular array of first antenna elements such as dipoles. A second printed circuit board, parallel to the first printed circuit board, comprises an array of second antenna elements. One of the array of first antenna elements and the array of second antenna elements is an array of transmission antenna elements and the other an array of reception antenna elements. The first printed circuit board is located below the second printed circuit board. Three conductive plates are used to shape the antenna patterns from the antenna elements so that the main lobes of the antenna patterns are directed obliquely downwards and the antenna patterns from the different array at least partly overlap, suppressing vertical side lobes. A first conductive plate separates the first and second printed circuit boards. A second conductive plate is located above the second printed circuit board, extending radially outward beyond the first conductive plate. A third conductive plate is located below the first printed circuit board. The first conductive plate extends radially outward beyond the third conductive plate."
Remotely controlled sound mask,https://lens.org/032-920-079-842-342,1987,"A sound masking apparatus especially useful for setting background noise levels in discrete zones includes a signal source, power amplifier, programmable attenuator and remote control. The remote control is a short range radio transmitter that sends a series of pulses that are decoded to control the attenuator. The attenuator selects among discrete possible volume levels using serially-connected analog multiplexers, the multiplexer-selected lines connecting the signal to a desired part of a resistor network defining voltage dividers. The short range radio control makes a single remote controller operable to control volume levels in any zone of a multiple zone installation without direct access to the signal source, whereby the user can change volume levels in small increments to accomodate changing conditions or preferences and to slowly bring sound masking units to full volume levels."
"System for deploying a first object for capturing, immobilising or disabling a second object",https://lens.org/110-242-820-238-525,2016,"A system for deploying a first object for capturing, immobilising or disabling a second object. The system including a projectile 101 for carrying the first object within, and a launcher 103 for launching the projectile towards the second object, wherein the projectile is configured to deploy the first object in the vicinity of the second object to capture, immobilise or disable the second object. The projectile includes control circuitry (303, fig 6b) for activation the deployment mechanism. The launcher includes a barrel (401, fig 10a), launching mechanism (403), aiming mechanism (405) and control circuitry (409). The first object may be a net 105. A parachute 107 may be included which may be deployed from the projectile during flight. The second object may be a drone or unmanned aerial vehicle (UAV). The parachute enables the captured drone to safely descend to the ground and be recovered for examination."
METHOD AND SYSTEM FOR MONITORING UNMANNED AERIAL VEHICLE,https://lens.org/047-048-324-122-839,2022,"A method for monitoring an unmanned aerial vehicle (UAV) includes: acquiring, by a processor of the UAV, a UAV monitoring message, wherein the UAV monitoring message includes information on one or more of: identification information related to the UAV and status information related to the UAV; composing, by the processor of the UAV, a Service Discovery Frame (SDF) carrying the UAV monitoring message, the SDF being compliant with a Neighbor Awareness Networking (NAN) protocol; wirelessly broadcasting, by the UAV, the SDF carrying the UAV monitoring message; receiving the broadcasted SDF by a user terminal; acquiring the UAV monitoring message from the received SDF by the user terminal; and outputting the UAV monitoring message through an interface of the user terminal."
METHOD AND SYSTEM FOR MONITORING UNMANNED AERIAL VEHICLE,https://lens.org/047-048-324-122-839,2022,"A method for monitoring an unmanned aerial vehicle (UAV) includes: acquiring, by a processor of the UAV, a UAV monitoring message, wherein the UAV monitoring message includes information on one or more of: identification information related to the UAV and status information related to the UAV; composing, by the processor of the UAV, a Service Discovery Frame (SDF) carrying the UAV monitoring message, the SDF being compliant with a Neighbor Awareness Networking (NAN) protocol; wirelessly broadcasting, by the UAV, the SDF carrying the UAV monitoring message; receiving the broadcasted SDF by a user terminal; acquiring the UAV monitoring message from the received SDF by the user terminal; and outputting the UAV monitoring message through an interface of the user terminal."
"Autonomous system for unmanned aerial vehicle landing, charging and takeoff",https://lens.org/182-861-833-172-355,2020,"An unmanned aerial vehicle (UAV) can automatically guide itself to the vicinity of a charging station of an automated landing, charging and takeoff system, which then assists with the close-range laser guidance of the UAV in order for it to dock, without the need for landing gear. The dock has locating valleys that help the booms of the UAV to self-align under the force of gravity. Electrical connections are automatically made for data download and charging. A cover may be closed over the UAV during charging."
"Autonomous system for unmanned aerial vehicle landing, charging and takeoff",https://lens.org/001-809-326-183-090,2017,"An unmanned aerial vehicle (UAV) can automatically guide itself to the vicinity of a charging station of an automated landing, charging and takeoff system, which then assists with the close-range laser guidance of the UAV in order for it to dock, without the need for landing gear. The dock has locating valleys that help the booms of the UAV to self-align under the force of gravity. Electrical connections are automatically made for data download and charging. A cover may be closed over the UAV during charging."
INTERACTIVE REMOTE CONTROL,https://lens.org/097-456-178-573-549,2010,"A remote control that includes buttons on the side or bottom may be used to control television viewing provided through a set-top box. In one particular implementation, a method may include receiving, by the set-top box, a signal from the remote control indicating entry to an interactive input mode and receiving another signal from the remote control indicating motion of the remote control. The set-top box may identify an intended command based on the second signal and control television programming in response to the command."
Interactive remote control,https://lens.org/126-872-453-881-291,2012,"A remote control that includes buttons on the side or bottom may be used to control television viewing provided through a set-top box. In one particular implementation, a method may include receiving, by the set-top box, a signal from the remote control indicating entry to an interactive input mode and receiving another signal from the remote control indicating motion of the remote control. The set-top box may identify an intended command based on the second signal and control television programming in response to the command."
System for autonomous mobile device assisted communication,https://lens.org/172-470-774-459-725,2022,"An autonomous mobile device (AMD) may be used in an environment as a communication endpoint for voice or video communications. An incoming request for communication may initiate a process in which the AMD finds a user within the environment. Information obtained from sensors onboard the AMD or in the environment may be used to determine the whereabouts of the user. If an existing communication endpoint is not available to the user or cannot support a requested communication modality, the AMD may travel to permitted areas within the environment to find the user, while avoiding areas designated as private. Once found, communication may be established with the user. If the incoming request expires, the AMD may present information indicative of the request to the user."
System for autonomous mobile device assisted communication,https://lens.org/172-470-774-459-725,2022,"An autonomous mobile device (AMD) may be used in an environment as a communication endpoint for voice or video communications. An incoming request for communication may initiate a process in which the AMD finds a user within the environment. Information obtained from sensors onboard the AMD or in the environment may be used to determine the whereabouts of the user. If an existing communication endpoint is not available to the user or cannot support a requested communication modality, the AMD may travel to permitted areas within the environment to find the user, while avoiding areas designated as private. Once found, communication may be established with the user. If the incoming request expires, the AMD may present information indicative of the request to the user."
Acousto-optic interaction device of multi-rotor unmanned aerial vehicle,https://lens.org/145-359-221-998-601,2015,"The utility model relates to an acousto-optic interaction device of a multi-rotor unmanned aerial vehicle. The acousto-optic interaction device comprises a voice player, an illuminator and a control assembly; the voice player and the illuminator are respectively connected with the control assembly; the control assembly is used for controlling the working conditions of the voice player and the illuminator according to a flight status signal sent by a controller of the multi-rotor unmanned aerial vehicle. According to the acousto-optic interaction device of the multi-rotor unmanned aerial vehicle, disclosed by the utility model, an operator can be accurately informed about the flight status and the flight direction of the multi-rotor unmanned aerial vehicle."
Selection of networks for communicating with unmanned aerial vehicles,https://lens.org/017-931-084-898-244,2018,"A device receives a request for a flight path, for a UAV, from a first location to a second location, and calculates the flight path based on the request for the flight path. The device determines network requirements for the flight path based on the request, and determines scores for multiple networks with coverage areas covering a portion of the flight path. The device selects a particular network, from the multiple networks, based on the network requirements for the flight path and based on the scores for the multiple networks. The device causes a connection with the UAV and the particular network to be established, and generates flight path instructions for the flight path. The device provides, via the connection with the particular network, the flight path instructions to the UAV to permit the UAV to travel from the first location to the second location via the flight path."
Selection of networks for communicating with unmanned aerial vehicles,https://lens.org/089-149-371-180-616,2021,"A device receives a request for a flight path, for a UAV, from a first location to a second location, and calculates the flight path based on the request for the flight path. The device determines network requirements for the flight path based on the request, and determines scores for multiple networks with coverage areas covering a portion of the flight path. The device selects a particular network, from the multiple networks, based on the network requirements for the flight path and based on the scores for the multiple networks. The device causes a connection with the UAV and the particular network to be established, and generates flight path instructions for the flight path. The device provides, via the connection with the particular network, the flight path instructions to the UAV to permit the UAV to travel from the first location to the second location via the flight path."
SELECTION OF NETWORKS FOR COMMUNICATING WITH UNMANNED AERIAL VEHICLES,https://lens.org/121-483-700-943-242,2021,"A device receives a request for a flight path, for a UAV, from a first location to a second location, and calculates the flight path based on the request for the flight path. The device determines network requirements for the flight path based on the request, and determines scores for multiple networks with coverage areas covering a portion of the flight path. The device selects a particular network, from the multiple networks, based on the network requirements for the flight path and based on the scores for the multiple networks. The device causes a connection with the UAV and the particular network to be established, and generates flight path instructions for the flight path. The device provides, via the connection with the particular network, the flight path instructions to the UAV to permit the UAV to travel from the first location to the second location via the flight path."
SELECTION OF NETWORKS FOR COMMUNICATING WITH UNMANNED AERIAL VEHICLES,https://lens.org/193-865-164-114-541,2017,"A device receives a request for a flight path, for a UAV, from a first location to a second location, and calculates the flight path based on the request for the flight path. The device determines network requirements for the flight path based on the request, and determines scores for multiple networks with coverage areas covering a portion of the flight path. The device selects a particular network, from the multiple networks, based on the network requirements for the flight path and based on the scores for the multiple networks. The device causes a connection with the UAV and the particular network to be established, and generates flight path instructions for the flight path. The device provides, via the connection with the particular network, the flight path instructions to the UAV to permit the UAV to travel from the first location to the second location via the flight path."
SELECTION OF NETWORKS FOR COMMUNICATING WITH UNMANNED AERIAL VEHICLES,https://lens.org/163-775-121-279-699,2016,"A device receives a request for a flight path, for a UAV, from a first location to a second location, and calculates the flight path based on the request for the flight path. The device determines network requirements for the flight path based on the request, and determines scores for multiple networks with coverage areas covering a portion of the flight path. The device selects a particular network, from the multiple networks, based on the network requirements for the flight path and based on the scores for the multiple networks. The device causes a connection with the UAV and the particular network to be established, and generates flight path instructions for the flight path. The device provides, via the connection with the particular network, the flight path instructions to the UAV to permit the UAV to travel from the first location to the second location via the flight path."
"UAV, METHOD AND SYSTEM FOR CLEANING A WALL BODY",https://lens.org/127-377-210-949-579,2017,A method for cleaning a wall body with a UAV includes obtaining a path to be cleaned; flying to a region to be cleaned according to the path to be cleaned; recognizing a wall surface in the region to be cleaned; and using a cleaning device carried by the UAV to clean the wall surface.
"UAV, method and system for cleaning a wall body",https://lens.org/050-113-278-089-893,2019,A method for cleaning a wall body with a UAV includes obtaining a path to be cleaned; flying to a region to be cleaned according to the path to be cleaned; recognizing a wall surface in the region to be cleaned; and using a cleaning device carried by the UAV to clean the wall surface.
"MOTION CONTROL METHOD AND DEVICE, AND ROBOT WITH ENHANCED MOTION CONTROL",https://lens.org/068-276-311-880-602,2019,"The present disclosure relates to a motion control method and device for a robot, and a robot with enhanced motion control. The method includes: receiving audio information by an audio receiver of the audio processing device in response to a key of an instrument being pressed, wherein the instrument is disposed within a default distance from the audio receiver; decoding the audio information and transforming the audio information into audio signals hs an audio decoder of the audio processing device; determining an expected movement of at least one joint of the robot according to a sound-freedom mapping table, and generating an adjustment message; receiving Joint-location information of the joint of the robot at a current moment; and driving the joint of the robot by the servo according to the adjustment message and the joint-location information."
UNMANNED AERIAL VEHICLE AUTHENTICATION AND AUTHORIZATION BY UNMANNED AERIAL SYSTEM TRAFFIC MANAGEMENT OVER USER PLANE,https://lens.org/164-429-182-573-562,2021,"An unmanned aerial vehicle (UAV) authentication and authorization may be performed by a third- party service provider (e.g., an unmanned aerial system traffic management (UTM) over a user plane (UP)). An UAV may be configured to send an UAV ID to a network. The UAV may receive, from the network, security information that indicates an authorization of a connection to a third-party service provider. The UAV may establish, based on the security information, the connection to the third-party service provider for communications with the third-party service provider. The security information may include signature information of the third-party service provider, and one or more of a subscription identifier (ID) associated with the UAV, the UAV ID, or an ID of the third-party service provider."
CONFIRMATION OF SUCCESSFUL DELIVERY BY AN UNMANNED AERIAL VEHICLE (UAV),https://lens.org/061-127-660-264-361,2021,"Methods and devices for confirmation of successful delivery by an unmanned aerial vehicle (UAV) are disclosed. A UAV is configured to navigate to a delivery destination, authenticate a receiving zone at the delivery destination, release, in dependence upon authentication of the receiving zone, the package into the receiving zone, capture, by a camera of the UAV, an image of the receiving zone, and generate delivery confirmation data including the image the receiving zone. A recipient device is configured to detect, by the device disposed in a receiving zone for receiving a package, a UAV in proximity to a receiving zone, authenticate the UAV, detect delivery of the package in the receiving zone, capture, by a camera of the device, an image of the package, and generate delivery confirmation data including the image the package and location data obtained from a GPS sensor in the device."
CONFIRMATION OF SUCCESSFUL DELIVERY BY AN UNMANNED AERIAL VEHICLE (UAV),https://lens.org/026-970-094-395-075,2021,"Methods and devices for confirmation of successful delivery by an unmanned aerial vehicle (UAV) are disclosed. A UAV is configured to navigate to a delivery destination, authenticate a receiving zone at the delivery destination, release, in dependence upon authentication of the receiving zone, the package into the receiving zone, capture, by a camera of the UAV, an image of the receiving zone, and generate delivery confirmation data including the image the receiving zone. A recipient device is configured to detect, by the device disposed in a receiving zone for receiving a package, a UAV in proximity to a receiving zone, authenticate the UAV, detect delivery of the package in the receiving zone, capture, by a camera of the device, an image of the package, and generate delivery confirmation data including the image the package and location data obtained from a GPS sensor in the device."
Autonomous vehicle research system,https://lens.org/033-272-404-601-563,2019,"An autonomous vehicle research system includes a vehicle having an attached frame and an engine. A sensing, control and data logging unit, mounted on the frame and in control communication with the engine senses vehicle operational parameters, controls the engine and to steering, and transmits operational data and log operational data. An operator control unit in communication with the sensing, control and data logging unit receives operational data from the sensing, control and data logging unit and presents visual real time display of the operational data. The operator control unit includes a manual cut-off switch that causes the engine to cease moving the vehicle. A remote control unit is manually switchable between a remote control mode and an autonomous control mode. In the remote control mode, the user controls the vehicle remotely. In the autonomous mode, the sensing, control and data logging unit controls the vehicle autonomously."
Autonomous Vehicle Research System,https://lens.org/040-363-830-603-040,2018,"An autonomous vehicle research system includes a vehicle having an attached frame and an engine. A sensing, control and data logging unit, mounted on the frame and in control communication with the engine senses vehicle operational parameters, controls the engine and to steering, and transmits operational data and log operational data. An operator control unit in communication with the sensing, control and data logging unit receives operational data from the sensing, control and data logging unit and presents visual real time display of the operational data. The operator control unit includes a manual cut-off switch that causes the engine to cease moving the vehicle. A remote control unit is manually switchable between a remote control mode and an autonomous control mode. In the remote control mode, the user controls the vehicle remotely. In the autonomous mode, the sensing, control and data logging unit controls the vehicle autonomously."
NAVIGATION DEVICE,https://lens.org/062-002-108-847-667,2000,"A navigation device for opening/closing the door of an electric garage automatically by remote control but not manual operation without opening/closing the door erroneously. The navigation device is connectable to a wireless garage door opener transmitter (50). The navigation device transmits an opening signal to the wireless garage door opener transmitter (50) when the location of the car calculated by a GPS receiver (24) and the azimuth measured by a gyro sensor (40) are within predetermined ranges of preset opening instruction position and azimuth of the electric garage door, respectively and when the speed of the car measured by a car speed sensor (38) is lower than a predetermined value. This makes it possible to prevent the electric garage door from being erroneously opened, when a car approaches the electric garage so as not to enter the electric garage."
System and method for providing autonomous photography and videography,https://lens.org/033-068-077-683-486,2023,"An aerial system, including a processing system, an optical system, an actuation system and a lift mechanism, includes an autonomous photography and/or videography system 70 , implemented, at least in part, by the processing system 22 , the optical system 26 , the actuation system 28 and the lift mechanism 32 . The autonomous photograph and/or videography system performs the steps of establishing a desired flight trajectory, detecting a target, controlling the flight of the aerial system as a function of the desired flight trajectory relative to the target using the lift mechanism and controlling the camera to capture pictures and/or video."
System and method for providing autonomous photography and videography,https://lens.org/033-068-077-683-486,2023,"An aerial system, including a processing system, an optical system, an actuation system and a lift mechanism, includes an autonomous photography and/or videography system 70 , implemented, at least in part, by the processing system 22 , the optical system 26 , the actuation system 28 and the lift mechanism 32 . The autonomous photograph and/or videography system performs the steps of establishing a desired flight trajectory, detecting a target, controlling the flight of the aerial system as a function of the desired flight trajectory relative to the target using the lift mechanism and controlling the camera to capture pictures and/or video."
UNMANNED AERIAL VEHICLE AUTHENTICATION AND AUTHORIZATION BY UNMANNED AERIAL SYSTEM TRAFFIC MANAGEMENT OVER USER PLANE,https://lens.org/135-718-375-987-074,2023,"An unmanned aerial vehicle (UAV) authentication and authorization may be performed by a third-party service provider (e.g., an unmanned aerial system traffic management (UTM) over a user plane (UP)). An UAV may be configured to send an UAV ID to a network. The UAV may receive, from the network, security information that indicates an authorization of a connection to a third-party service provider. The UAV may establish, based on the security information, the connection to the third-party service provider for communications with the third-party service provider. The security information may include signature information of the third-party service provider, and one or more of a subscription identifier (ID) associated with the UAV, the UAV ID, or an ID of the third-party service provider."
UNMANNED AERIAL VEHICLE AUTHENTICATION AND AUTHORIZATION BY UNMANNED AERIAL SYSTEM TRAFFIC MANAGEMENT OVER USER PLANE,https://lens.org/135-718-375-987-074,2023,"An unmanned aerial vehicle (UAV) authentication and authorization may be performed by a third-party service provider (e.g., an unmanned aerial system traffic management (UTM) over a user plane (UP)). An UAV may be configured to send an UAV ID to a network. The UAV may receive, from the network, security information that indicates an authorization of a connection to a third-party service provider. The UAV may establish, based on the security information, the connection to the third-party service provider for communications with the third-party service provider. The security information may include signature information of the third-party service provider, and one or more of a subscription identifier (ID) associated with the UAV, the UAV ID, or an ID of the third-party service provider."
AUTONOMOUS DRIVING CONTROL APPARATUS,https://lens.org/133-695-989-530-683,2017,An autonomous driving control apparatus executes an autonomous driving control of a vehicle. The autonomous driving control apparatus includes: a first determination unit configured to determine whether the autonomous driving control can be engaged or not; an autonomous driving control engage trigger input unit; a triggered engage mode configured to engage the autonomous driving control when an autonomous driving control engage trigger is input by a driver to the autonomous driving control engage trigger input unit after the first determination unit determines that the autonomous driving control can be engaged; an automatic engage mode configured to automatically engage the autonomous driving control when the first determination unit determines that the autonomous driving control can be engaged; and a switching unit configured to switch between the triggered engage mode and the automatic engage mode.
Autonomous driving control apparatus,https://lens.org/110-665-947-225-398,2019,An autonomous driving control apparatus executes an autonomous driving control of a vehicle. The autonomous driving control apparatus includes: a first determination unit configured to determine whether the autonomous driving control can be engaged or not; an autonomous driving control engage trigger input unit; a triggered engage mode configured to engage the autonomous driving control when an autonomous driving control engage trigger is input by a driver to the autonomous driving control engage trigger input unit after the first determination unit determines that the autonomous driving control can be engaged; an automatic engage mode configured to automatically engage the autonomous driving control when the first determination unit determines that the autonomous driving control can be engaged; and a switching unit configured to switch between the triggered engage mode and the automatic engage mode.
SYSTEMS AND METHODS FOR AUTONOMOUS VEHICLE CONTROL USING DEPOLARIZATION RATIO OF RETURN SIGNAL,https://lens.org/193-289-926-214-539,2022,"An autonomous vehicle control system includes one or more processors. The one or more processors are configured to cause a transmitter to transmit a transmit signal from a laser source. The one or more processors are configured to cause a receiver to receive a return signal reflected by an object. The one or more processors are configured to cause one or more optics to generate a first polarized signal of the return signal with a first polarization, and generate a second polarized signal of the return signal with a second polarization. The one or more processors are configured to calculate a value of reflectivity based on a signal-to-noise ratio (SNR) value of the first polarized signal and an SNR value of the second polarized signal. The one or more processors are configured to operate a vehicle based on the value of reflectivity."
Systems and methods for autonomous vehicle control using depolarization ratio of return signal,https://lens.org/148-708-212-717-152,2021,"An autonomous vehicle control system includes one or more processors. The one or more processors are configured to cause a transmitter to transmit a transmit signal from a laser source. The one or more processors are configured to cause a receiver to receive a return signal reflected by an object. The one or more processors are configured to cause one or more optics to generate a first polarized signal of the return signal with a first polarization, and generate a second polarized signal of the return signal with a second polarization. The one or more processors are configured to calculate a value of reflectivity based on a signal-to-noise ratio (SNR) value of the first polarized signal and an SNR value of the second polarized signal. The one or more processors are configured to operate a vehicle based on the value of reflectivity."
GROUND STATION AND TETHER FOR UNMANNED AERIAL VEHICLES,https://lens.org/140-207-235-894-905,2018,"An unmanned aerial vehicle system includes a ground station including a case, a power supply housed in the case, and a tether having a first end and a second end opposite to the first end. The first end of the tether is coupled to the case. The unmanned aerial vehicle system also includes a module including smart battery authentication circuitry configured to be coupled to the second end of the tether. The module is configured to be connected to an unmanned aerial vehicle. The smart battery authentication circuitry enables the unmanned aerial vehicle to receive power from the power supply housed in the case when the module is connected to the unmanned aerial vehicle."
GROUND STATION AND TETHER FOR UNMANNED AERIAL VEHICLES,https://lens.org/144-571-698-313-552,2018,"An unmanned aerial vehicle system includes a ground station including a case, a power supply housed in the case, and a tether having a first end and a second end opposite to the first end. The first end of the tether is coupled to the case. The unmanned aerial vehicle system also includes a module including smart battery authentication circuitry configured to be coupled to the second end of the tether. The module is configured to be connected to an unmanned aerial vehicle. The smart battery authentication circuitry enables the unmanned aerial vehicle to receive power from the power supply housed in the case when the module is connected to the unmanned aerial vehicle."
GROUND STATION AND TETHER FOR UNMANNED AERIAL VEHICLES,https://lens.org/020-412-970-609-535,2018,"An unmanned aerial vehicle system includes a ground station including a case, a power supply housed in the case, and a tether having a first end and a second end opposite to the first end. The first end of the tether is coupled to the case. The unmanned aerial vehicle system also includes a module including smart battery authentication circuitry configured to be coupled to the second end of the tether. The module is configured to be connected to an unmanned aerial vehicle. The smart battery authentication circuitry enables the unmanned aerial vehicle to receive power from the power supply housed in the case when the module is connected to the unmanned aerial vehicle."
Ground station and tether for unmanned aerial vehicles,https://lens.org/108-797-254-754-45X,2020,"An unmanned aerial vehicle system includes a ground station including a case, a power supply housed in the case, and a tether having a first end and a second end opposite to the first end. The first end of the tether is coupled to the case. The unmanned aerial vehicle system also includes a module including smart battery authentication circuitry configured to be coupled to the second end of the tether. The module is configured to be connected to an unmanned aerial vehicle. The smart battery authentication circuitry enables the unmanned aerial vehicle to receive power from the power supply housed in the case when the module is connected to the unmanned aerial vehicle."
DEVICE VERIFICATION,https://lens.org/070-187-253-022-307,2023,"An apparatus comprising at least one processor; and at least one memory including computer program code; the at least one memory and the computer program code configured to, with the at least one processor, cause the apparatus to perform: cause to request, from at least one server, location based information based, at least in part, on a current location of a device; cause to transmit, to the at least one server, capability information of the device to autonomously perform at least one physical action; receiving at least one dynamically created physical challenge to be autonomously performed by the device, the at least one dynamically created physical challenge based, at least in part, on the capability information of the device and/or one or more capabilities of environment of the device; and controlling the device to autonomously perform at least one physical action based, at least in part, on the at least one dynamically created physical challenge."
MOTOR CONTROL OPTIMIZATIONS FOR UNMANNED AERIAL VEHICLES,https://lens.org/174-118-811-845-554,2023,A method comprising: communicating signals and transmitting the signals. Communicating the signals from an operation system to a motor controller of an unmanned aerial vehicle (UAV). Transmitting the signals from the motor controller to motors of the UAV. Applying a smoothing filter to the signals transmitted from the motor controller to the motors of the UAV to generate filtered signals. Controlling the motors with the filtered signals so that the motors operate to control movement of the UAV.
Autonomous weapon system for guidance and combat assessment,https://lens.org/118-719-937-721-584,2022,An autonomous weapon system for improved guidance of a projectile for homing a target includes a guided projectile including at least one sensor and a carrier projectile and at least one guidance and reconnaissance unit including a transmitter for communication via light. The system uses emitted light for both positioning and communication of target coordinates which provides an accurate and cost effective system for combatting point and surface targets by indirect fire.
Autonomous weapon system for guidance and combat assessment,https://lens.org/118-719-937-721-584,2022,An autonomous weapon system for improved guidance of a projectile for homing a target includes a guided projectile including at least one sensor and a carrier projectile and at least one guidance and reconnaissance unit including a transmitter for communication via light. The system uses emitted light for both positioning and communication of target coordinates which provides an accurate and cost effective system for combatting point and surface targets by indirect fire.
AUTONOMOUS WEAPON SYSTEM FOR GUIDANCE AND COMBAT ASSESSMENT,https://lens.org/141-006-891-429-089,2020,An autonomous weapon system for improved guidance of a projectile for homing a target includes a guided projectile including at least one sensor and a carrier projectile and at least one guidance and reconnaissance unit including a transmitter for communication via light. The system uses emitted light for both positioning and communication of target coordinates which provides an accurate and cost effective system for combatting point and surface targets by indirect fire.
REMOTE INTERACTION DEVICE WITH TRACKING OF REMOTE MOVEMENT INPUT,https://lens.org/140-728-780-669-918,2020,"Systems, devices, and methods are provided for remote interaction with a subject in an environment. The device has audio-visual recording and transmitting functionality to provide an operator at a remote location with an audio-visual feed of the environment near the device. The device also has a light emission component which the operator controls and which projects light onto a surface in the environment in the vicinity of the device. The systems, devices, and methods provide operators with the ability to control the positions of the light emission by tracking movement at a remote device at the remote location."
REMOTE INTERACTION DEVICE WITH TRACKING OF REMOTE MOVEMENT INPUT,https://lens.org/140-728-780-669-918,2020,"Systems, devices, and methods are provided for remote interaction with a subject in an environment. The device has audio-visual recording and transmitting functionality to provide an operator at a remote location with an audio-visual feed of the environment near the device. The device also has a light emission component which the operator controls and which projects light onto a surface in the environment in the vicinity of the device. The systems, devices, and methods provide operators with the ability to control the positions of the light emission by tracking movement at a remote device at the remote location."
Remote interaction device with tracking of remote movement input,https://lens.org/153-707-168-118-254,2018,"Systems, devices, and methods are provided for remote interaction with a subject in an environment. The device has audio-visual recording and transmitting functionality to provide an operator at a remote location with an audio-visual feed of the environment near the device. The device also has a light emission component which the operator controls and which projects light onto a surface in the environment in the vicinity of the device. The systems, devices, and methods provide operators with the ability to control the positions of the light emission by tracking movement at a remote device at the remote location."
REMOTE INTERACTION DEVICE WITH TRACKING OF REMOTE MOVEMENT INPUT,https://lens.org/113-372-666-865-604,2019,"Systems, devices, and methods are provided for remote interaction with a subject in an environment. The device has audio-visual recording and transmitting functionality to provide an operator at a remote location with an audio-visual feed of the environment near the device. The device also has a light emission component which the operator controls and which projects light onto a surface in the environment in the vicinity of the device. The systems, devices, and methods provide operators with the ability to control the positions of the light emission by tracking movement at a remote device at the remote location."
REMOTE INTERACTION DEVICE WITH TRACKING OF REMOTE MOVEMENT INPUT,https://lens.org/011-086-238-396-906,2017,"Systems, devices, and methods are provided for remote interaction with a subject in an environment. The device has audio-visual recording and transmitting functionality to provide an operator at a remote location with an audio-visual feed of the environment near the device. The device also has a light emission component which the operator controls and which projects light onto a surface in the environment in the vicinity of the device. The systems, devices, and methods provide operators with the ability to control the positions of the light emission by tracking movement at a remote device at the remote location."
METHOD AND APPARATUS FOR REMOTE CAMERA CONTROL,https://lens.org/126-948-335-798-604,2010,A method for remotely controlling a camera is disclosed. One or more first control signals having a first protocol are externally sent to a first interface of a camera. One or more second control signals having a second protocol are externally sent to a second interface of the camera different from the first interface. The one or more first control signals and the one or more second control signals are coordinated to effect control of at least one exposure function of the camera. An apparatus for remotely controlling a camera is also disclosed.
"METHOD, PLATFORM AND SYSTEM FOR EXTENDING WIRELESS SIGNAL COVERAGE OF A WIRELESS NETWORK",https://lens.org/012-075-389-278-328,2022,"A method, a platform and a system for extending wireless signal coverage of a wireless network are provided. The method is performed by a platform (200) located in a first wireless signal coverage area (101) provided by an access point (100) of the wireless network, and is configured to provide a second wireless signal coverage area (201). The method comprising: tracking a position of a wireless device (300); predicating a movement of the wireless device (300) based on the tracking result; upon predicting that the wireless device (300) is to be moved out of the first wireless signal coverage area (101) and the second wireless signal coverage area (201), instructing a drone (500) with a wireless signal extender to move to a target geographical position based on the current position of the wireless device (300) to provide a first extended wireless signal coverage area."
"METHOD, PLATFORM AND SYSTEM FOR EXTENDING WIRELESS SIGNAL COVERAGE OF A WIRELESS NETWORK",https://lens.org/012-075-389-278-328,2022,"A method, a platform and a system for extending wireless signal coverage of a wireless network are provided. The method is performed by a platform (200) located in a first wireless signal coverage area (101) provided by an access point (100) of the wireless network, and is configured to provide a second wireless signal coverage area (201). The method comprising: tracking a position of a wireless device (300); predicating a movement of the wireless device (300) based on the tracking result; upon predicting that the wireless device (300) is to be moved out of the first wireless signal coverage area (101) and the second wireless signal coverage area (201), instructing a drone (500) with a wireless signal extender to move to a target geographical position based on the current position of the wireless device (300) to provide a first extended wireless signal coverage area."
"METHOD, PLATFORM AND SYSTEM FOR EXTENDING WIRELESS SIGNAL COVERAGE OF A WIRELESS NETWORK",https://lens.org/012-075-389-278-328,2022,"A method, a platform and a system for extending wireless signal coverage of a wireless network are provided. The method is performed by a platform (200) located in a first wireless signal coverage area (101) provided by an access point (100) of the wireless network, and is configured to provide a second wireless signal coverage area (201). The method comprising: tracking a position of a wireless device (300); predicating a movement of the wireless device (300) based on the tracking result; upon predicting that the wireless device (300) is to be moved out of the first wireless signal coverage area (101) and the second wireless signal coverage area (201), instructing a drone (500) with a wireless signal extender to move to a target geographical position based on the current position of the wireless device (300) to provide a first extended wireless signal coverage area."
CARRYING DRONE CONNECTED PALLET,https://lens.org/163-130-357-566-24X,2022,"The present invention is to provide a pallet for connection with a carrying drone when carrying goods by using the carrying drone, which may include a body part which presses and supports goods 10 loaded on a support plate 200 from the top, connects and fixes the goods 10 with the support plate 200 up and down through a strap 300, and has a fastening port 130 to be fastenable to a carry drone 500, and a power supply unit 400 which is embedded in a partial region of the body to provide power to the carrying drone 500 connected to a power cable 510."
REMOTE ASSISTANCE SYSTEM FOR AIRCRAFT,https://lens.org/142-130-271-483-775,2019,A device for an aircraft having at least one first communication with an air traffic control center. The device establishes a second communication with a remote assistance center and performs a first mixing of audio signals from the first communication or communications and of audio signals from the second communication and transmits the result to the pilot. The device also performs a second mixing of audio signals from the first communication or communications and of audio signals from the pilot and transmits the result to the remote assistance center by using the second communication. The device performs a relaying of commands received via the second communication to devices of the aircraft. An operator in the remote assistance center listens to the exchanges between the pilot and the air traffic control center and can exchange with the pilot and relieve him or her of certain tasks.
Remote assistance system for aircraft,https://lens.org/029-976-868-456-748,2020,A device for an aircraft having at least one first communication with an air traffic control center. The device establishes a second communication with a remote assistance center and performs a first mixing of audio signals from the first communication or communications and of audio signals from the second communication and transmits the result to the pilot. The device also performs a second mixing of audio signals from the first communication or communications and of audio signals from the pilot and transmits the result to the remote assistance center by using the second communication. The device performs a relaying of commands received via the second communication to devices of the aircraft. An operator in the remote assistance center listens to the exchanges between the pilot and the air traffic control center and can exchange with the pilot and relieve him or her of certain tasks.
Remote assistance system for aircraft,https://lens.org/029-976-868-456-748,2020,A device for an aircraft having at least one first communication with an air traffic control center. The device establishes a second communication with a remote assistance center and performs a first mixing of audio signals from the first communication or communications and of audio signals from the second communication and transmits the result to the pilot. The device also performs a second mixing of audio signals from the first communication or communications and of audio signals from the pilot and transmits the result to the remote assistance center by using the second communication. The device performs a relaying of commands received via the second communication to devices of the aircraft. An operator in the remote assistance center listens to the exchanges between the pilot and the air traffic control center and can exchange with the pilot and relieve him or her of certain tasks.
System and method for manipulating an anatomy,https://lens.org/048-058-400-817-292,2021,"A system includes a robotic manipulator and an end effector coupled to the robotic manipulator and being moveable for interacting with a target site in a manual mode and an autonomous mode of operation. A navigation system is configured to track a position of the end effector and the target site. One or more controllers are configured to define a virtual boundary relative to the target site, prevent the end effector from penetrating the virtual boundary in the autonomous mode, and allow the end effector to penetrate the virtual boundary in the manual mode."
System And Method For Manipulating An Anatomy,https://lens.org/161-104-046-422-140,2020,"A system includes a robotic manipulator and an end effector coupled to the robotic manipulator and being moveable for interacting with a target site in a manual mode and an autonomous mode of operation. A navigation system is configured to track a position of the end effector and the target site. One or more controllers are configured to define a virtual boundary relative to the target site, prevent the end effector from penetrating the virtual boundary in the autonomous mode, and allow the end effector to penetrate the virtual boundary in the manual mode."
ELECTRONIC DEVICE AND ALARM CONTROL METHOD OF THE ELECTRONIC DEVICE,https://lens.org/044-094-092-497-639,2016,"In an alarm control method executed in an electronic device, voice commands are set using a voice capturing device and stored into a storage device. The voice commands are set for controlling an alarm of the electronic device. In event the alarm rings, real-time audio data is captured using the voice capturing device. The voice commands are read from the storage device, and the voice commands are compared with the audio data to determine that at least one voice command matches the audio data. The alarm is controlled according to a matched voice command."
Voice-controlled device control using acoustic echo cancellation statistics,https://lens.org/001-247-107-790-032,2020,Devices and techniques are generally described for control of a voice-controlled device using acoustic echo cancellation statistics. A reference signal representing the audio stream may be sent to an acoustic echo cancellation (AEC) unit. A microphone may receive an input audio signal and send the input audio signal to the AEC unit. The AEC unit may attenuate at least a part of the input audio signal. AEC statistics related to the attenuation of at least the part of the input audio signal may be determined over a first period of time. A wake-word in the input audio signal may be detected during the first period of time. A determination may be made that the wake-word is part of the playback of the audio stream based at least in part on the AEC statistics.
UNMANNED AERIAL VEHICLE FOR INFRASTRUCTURE MAINTENANCE,https://lens.org/189-927-071-552-733,2019,"An unmanned aerial vehicle (UAV) includes a body that supports one or more rotors, the one or more rotors each driven by a motor and configured to provide lift to the body. The UAV further includes a parts handler coupled to the body, the parts handler configured to grasp a payload, and rotate the payload with respect to an external structure to couple the payload to, or decouple the payload from, the external structure. The UAV includes a stabilizing mechanism extending from the body, the stabilizing mechanism configured to contact the external structure without transferring entire weight of the UAV to the external structure and prevent rotation of the body when the part-handler rotates the payload."
Method of navigating an unmanned aerial vehicle for streetlight maintenance,https://lens.org/039-045-622-378-601,2023,"An unmanned aerial vehicle (UAV) includes a body that supports one or more rotors, the one or more rotors each driven by a motor and configured to provide lift to the body. The UAV further includes a parts handler coupled to the body, the parts handler configured to grasp a payload, and rotate the payload with respect to an external structure to couple the payload to, or decouple the payload from, the external structure. The UAV includes a stabilizing mechanism extending from the body, the stabilizing mechanism configured to contact the external structure without transferring entire weight of the UAV to the external structure and prevent rotation of the body when the part-handler rotates the payload."
Unmanned aerial vehicle for infrastructure maintenance,https://lens.org/140-504-779-461-295,2020,"An unmanned aerial vehicle (UAV) includes a body that supports one or more rotors, the one or more rotors each driven by a motor and configured to provide lift to the body. The UAV further includes a parts handler coupled to the body, the parts handler configured to grasp a payload, and rotate the payload with respect to an external structure to couple the payload to, or decouple the payload from, the external structure. The UAV includes a stabilizing mechanism extending from the body, the stabilizing mechanism configured to contact the external structure without transferring entire weight of the UAV to the external structure and prevent rotation of the body when the part-handler rotates the payload."
Method of navigating an unmanned aerial vehicle for streetlight maintenance,https://lens.org/039-045-622-378-601,2023,"An unmanned aerial vehicle (UAV) includes a body that supports one or more rotors, the one or more rotors each driven by a motor and configured to provide lift to the body. The UAV further includes a parts handler coupled to the body, the parts handler configured to grasp a payload, and rotate the payload with respect to an external structure to couple the payload to, or decouple the payload from, the external structure. The UAV includes a stabilizing mechanism extending from the body, the stabilizing mechanism configured to contact the external structure without transferring entire weight of the UAV to the external structure and prevent rotation of the body when the part-handler rotates the payload."
Unmanned aerial vehicle for infrastructure maintenance,https://lens.org/140-504-779-461-295,2020,"An unmanned aerial vehicle (UAV) includes a body that supports one or more rotors, the one or more rotors each driven by a motor and configured to provide lift to the body. The UAV further includes a parts handler coupled to the body, the parts handler configured to grasp a payload, and rotate the payload with respect to an external structure to couple the payload to, or decouple the payload from, the external structure. The UAV includes a stabilizing mechanism extending from the body, the stabilizing mechanism configured to contact the external structure without transferring entire weight of the UAV to the external structure and prevent rotation of the body when the part-handler rotates the payload."
UNMANNED AERIAL VEHICLE FOR INFRASTRUCTURE MAINTENANCE,https://lens.org/097-544-839-133-656,2020,"An unmanned aerial vehicle (UAV) includes a body that supports one or more rotors, the one or more rotors each driven by a motor and configured to provide lift to the body. The UAV further includes a parts handler coupled to the body, the parts handler configured to grasp a payload, and rotate the payload with respect to an external structure to couple the payload to, or decouple the payload from, the external structure. The UAV includes a stabilizing mechanism extending from the body, the stabilizing mechanism configured to contact the external structure without transferring entire weight of the UAV to the external structure and prevent rotation of the body when the part-handler rotates the payload."
Display and/or packaging system,https://lens.org/030-281-926-517-487,2014,"An enclosure includes an optical structure which divides the enclosure into a front section and a back section which includes a background setting. The enclosure includes a preprogrammed code located along an exterior wall. A smart phone can be used to sense the code and project an image onto the optical structure, which image is reflected enabling a viewer to see the reflected image superimposed on the background setting."
Interactive display and/or packaging system,https://lens.org/023-246-575-708-689,2015,"An enclosure includes an optical structure which divides the enclosure into a front section and a back section which includes a background setting. The enclosure includes a preprogrammed code located along an exterior wall. A smart phone can be used to sense the code and project an image onto the optical structure, which image is reflected enabling a viewer to see the reflected image superimposed on the background setting."
"Camera image stabilization method, apparatus and computer program",https://lens.org/163-253-100-351-673,2011,A camera comprises a user interface for the input of information indicative of the activity of a user. A control unit controls at least one function of the camera in response to the information.
"Camera image stabilization method, apparatus and computer program",https://lens.org/173-548-704-580-881,2003,A camera comprises a user interface for the input of information indicative of the activity of a user. A control unit controls at least one function of the camera in response to the information.
Automated wireless device configuration with a wireless network,https://lens.org/182-868-051-142-305,2013,"A wireless network enabled camera (101) includes a microphone and is set up to communicate with a wireless network enabled smartphone (102) over a wireless network. In this way, the wireless camera may operate as a baby monitor or intruder alarm. Network enabling codes for a local network are collected at the smartphone, and converted to audio signals (103). These are then output by the smartphone (102) and detected by the microphone on the wireless camera (101). The audio signals (103) are then converted back to the network codes by the wireless camera (101) to establish communication with a local network router (104). This allows automated set up of a wireless device within a wireless network without having to manually enter a Service Set Identifier (SSID), Wired Equivalent Privacy (WEP) or network key. An additional feature allows automatic camera activation based upon detecting a preset noise level and duration, upon which the video feed can be pushed to the smartphone."
SYSTEMS AND METHODS FOR UNMANNED AERIAL VEHICLE LANDING,https://lens.org/107-407-891-574-176,2015,Provided herein are systems and method for autonomously or semi-autonomously landing an unmanned aerial vehicle (UAV) on a landing pad. The landing pad can include features configured to correct misalignment of the UAV on the landing pad. The landing pad can additionally include one or more markers than can be identified by the UAV to aid the UAV in locating the landing pad and determining the location of the UAV relative to the landing pad.
SYSTEMS AND METHODS FOR UNMANNED AERIAL VEHICLE LANDING,https://lens.org/034-137-515-574-515,2016,Provided herein are systems and method for autonomously or semi-autonomously landing an unmanned aerial vehicle (UAV) on a landing pad. The landing pad can include features configured to correct misalignment of the UAV on the landing pad. The landing pad can additionally include one or more markers than can be identified by the UAV to aid the UAV in locating the landing pad and determining the location of the UAV relative to the landing pad.
SYSTEMS AND METHODS FOR UNMANNED AERIAL VEHICLE LANDING,https://lens.org/014-771-039-327-419,2015,Provided herein are systems and method for autonomously or semi-autonomously landing an unmanned aerial vehicle (UAV) on a landing pad. The landing pad can include features configured to correct misalignment of the UAV on the landing pad. The landing pad can additionally include one or more markers than can be identified by the UAV to aid the UAV in locating the landing pad and determining the location of the UAV relative to the landing pad.
Systems and methods for unmanned aerial vehicle landing,https://lens.org/144-205-679-141-900,2018,Provided herein are systems and method for autonomously or semi-autonomously landing an unmanned aerial vehicle (UAV) on a landing pad. The landing pad can include features configured to correct misalignment of the UAV on the landing pad. The landing pad can additionally include one or more markers than can be identified by the UAV to aid the UAV in locating the landing pad and determining the location of the UAV relative to the landing pad.
"LEVELING INSTRUMENT, AN ELECTROMECHANICAL LIFTER AND A SELF LEVELING INTEGRATED LIFTING SYSTEM USING BOTH OF THEM",https://lens.org/079-429-453-587-413,2013,"This self-leveling device is employed in the field of lifting of aircraft, helicopters, civil and military flying vehicles, watercraft, camping vehicles, trains, bridges, radar, etc., and for all those activities that require self leveling and centring during lifting and lowering operations with fast results, without damages to the structure and in perfect safety (eg.: for helicopter lifting, for internal load balance, for safery during take-off and landing). The device is composed of a number of electromechanical lifting groups that operate synchronistically and autonomously from one another, linked with an electronic central general control for operation and a leveling cell. The whole system provides perfect self-leveling in case of unstable ground, for weighing and leveling purposes, targeting, weight balance, maintenance, etc."
AUTONOMOUS AERIAL VEHICLE,https://lens.org/157-541-041-602-928,2017,"Autonomous aerial vehicles and methods of operating the same. An unmanned aerial vehicle in accordance with various embodiments may receive a defined flight path, at least a portion of which is underground. The vehicle may then autonomously travel along the defined flight path and gather imagery regarding its environment as it travels."
Autonomous aerial vehicle,https://lens.org/075-369-385-154-650,2019,"Autonomous aerial vehicles and methods of operating the same. An unmanned aerial vehicle in accordance with various embodiments may receive a defined flight path, at least a portion of which is underground. The vehicle may then autonomously travel along the defined flight path and gather imagery regarding its environment as it travels."
ARTIFICIAL INTELLIGENCE ROBOT FOR PROVIDING VOICE RECOGNITION FUNCTION AND METHOD OF OPERATING THE SAME,https://lens.org/028-568-254-687-649,2021,"An artificial intelligence robot for providing a voice recognition service includes a memory configured to store voice identification information, a microphone configured to receive a voice command; and a processor configured to extract voice identification information from a wake-up command included in the voice command and used to activate the voice recognition service and operate the voice recognition function in a deactivation state when the extracted voice identification information does not match the voice identification information stored in the memory."
Terrain adaptive flight control,https://lens.org/192-336-063-516-314,2016,"A helicopter is provided and includes an air frame formed to accommodate a pilot, flight control elements disposed on the airframe to generate lift and thrust in accordance with control commands issued by the pilot and a current control mode, a sensor disposed on the airframe to sense helicopter proximity to terrain and obstacles and a flight computer configured to change the current control mode based on sensed helicopter proximity to the terrain and the obstacles.
"
Terrain adaptive flight control,https://lens.org/054-024-446-528-797,2016,"A helicopter is provided and includes an air frame formed to accommodate a pilot, flight control elements disposed on the airframe to generate lift and thrust in accordance with control commands issued by the pilot and a current control mode, a sensor disposed on the airframe to sense helicopter proximity to terrain and obstacles and a flight computer configured to change the current control mode based on sensed helicopter proximity to the terrain and the obstacles."
TERRAIN ADAPTIVE FLIGHT CONTROL,https://lens.org/193-937-818-847-542,2015,"A helicopter is provided and includes an air frame formed to accommodate a pilot, flight control elements disposed on the airframe to generate lift and thrust in accordance with control commands issued by the pilot and a current control mode, a sensor disposed on the airframe to sense helicopter proximity to terrain and obstacles and a flight computer configured to change the current control mode based on sensed helicopter proximity to the terrain and the obstacles."
Terrain adaptive flight control,https://lens.org/037-742-018-957-237,2015,"A helicopter is provided and includes an air frame formed to accommodate a pilot, flight control elements disposed on the airframe to generate lift and thrust in accordance with control commands issued by the pilot and a current control mode, a sensor disposed on the airframe to sense helicopter proximity to terrain and obstacles and a flight computer configured to change the current control mode based on sensed helicopter proximity to the terrain and the obstacles."
UNMANNED AERIAL VEHICLE,https://lens.org/031-977-341-525-037,2023,"An unmanned aircraft (100) according to the present disclosure is equipped with a flight propeller (2) and includes a main body (1), a locomotion unit having an aquatic locomotion mechanism and a terrestrial locomotion mechanism independent of the flight propeller, and a connector that connects the main body and the locomotion mechanisms."
UNMANNED AERIAL VEHICLE,https://lens.org/031-977-341-525-037,2023,"An unmanned aircraft (100) according to the present disclosure is equipped with a flight propeller (2) and includes a main body (1), a locomotion unit having an aquatic locomotion mechanism and a terrestrial locomotion mechanism independent of the flight propeller, and a connector that connects the main body and the locomotion mechanisms."
Toy with remotely controlled security alarm,https://lens.org/052-688-881-520-65X,2003,"A security alarm device is replicated in a toy vehicle. The security device includes a remote control which also can control vehicle functions. The remote control may control alarm arm and disarm, alarm and vehicle sounds such as arm, disarm, alarm set off, engine rev'ing and tire screeching; motor drive; and vehicle lights. The security alarm device includes an LED which indicates whether the alarm is armed or unarmed, and a motion sensor which sets the arm off (e.g., emitting a siren sound) when the toy vehicle is moved in its armed state."
VARIABLE CONDITION MOTOR CONTROLLER,https://lens.org/147-547-575-002-796,2023,"An aerial vehicle, comprising: one or more motors, one or more sensors, and a flight sub-system. The one or more sensors configured to detect data. The flight sub-system includes an attitude controller module; a rate controller module; and a compensator module. The compensator module is configured to: determine a maximum RPM of the one or more motors or a maximum torque of the one or more motors; receive a torque vector from the rate controller module; determine a rotational speed of the one or more motors to generate a desired flight orientation based upon the torque vector; and consider sensor data from the one or more sensors to adjust the rotational speed of the one or more motors."
Unmanned aerial vehicle control method and system based on moving base,https://lens.org/146-849-358-195-605,2023,"An unmanned aerial vehicle (UAV) control method includes a takeoff process, a following process and a landing process, wherein the takeoff process includes the following steps: unlocking the UAV, and detecting the current horizontal position of the UAV in the horizontal direction and the current altitude of the UAV in the vertical direction; determining whether the current horizontal position and the current altitude meet takeoff criteria, and controlling the UAV to bounce off and enter into a takeoff state if the determination result is positive. The system provided by the present disclosure employs the above-mentioned method to control a UAV. The method and system provided by the present disclosure meet three functional requirements for a UAV on a moving base platform, namely, stable takeoff, following process and accurate landing, thus decrease the difficulties in the use of a UAV on a moving platform."
UNMANNED AERIAL VEHICLE CONTROL METHOD AND SYSTEM BASED ON MOVING BASE,https://lens.org/067-589-954-717-711,2022,"An unmanned aerial vehicle (UAV) control method includes a takeoff process, a following process and a landing process, wherein the takeoff process includes the following steps: unlocking the UAV, and detecting the current horizontal position of the UAV in the horizontal direction and the current altitude of the UAV in the vertical direction; determining whether the current horizontal position and the current altitude meet takeoff criteria, and controlling the UAV to bounce off and enter into a takeoff state if the determination result is positive. The system provided by the present disclosure employs the above-mentioned method to control a UAV. The method and system provided by the present disclosure meet three functional requirements for a UAV on a moving base platform, namely, stable takeoff, following process and accurate landing, thus decrease the difficulties in the use of a UAV on a moving platform."
Large-scale pipe intelligence automatic welding aircraft nose,https://lens.org/005-732-971-479-735,2015,"The utility model provides the novel intelligent automatic welding aircraft nose of large-scale pipe, its characterized in that comprises bottom plate, aircraft nose control box, girder board, the electronic guiding mechanism of welding torch gesture, the automatic conveying mechanism of welding wire, the automatic running gear of welding torch, the real-time position detecting system of welding torch, the control of TV camera, hand-held wireless remote control box. It is unsettled under, that aircraft nose control box and welding torch and posture adjustment mechanism arrange girder board both sides respectively in, and two skies that the automatic travel drive mechanism of aircraft nose arranged the bottom plate in are internal, and the aircraft nose control box is then hung on the bottom plate of girder one side, and welding torch attitude control and automatic thread feeding mechanism be the opposite side, and they hang on the girder, for treating welded tube way seam, attaches remote control receiving unit and the real-time position detecting system of welding torch on this side girder board in addition promptly, and hand-held wireless remote control ware is provided with 8 and sets up the function key: about, four manual works are preset and are put about the welding torch, and opening that online speed governing knob, start and welding machine were shaken hands stops the key of communicating by letter. The operating means control of whole aircraft nose, the implementation of motion is accomplished by the wireless remote control box completely."
DRONE STATION,https://lens.org/111-827-901-747-33X,2023,"A drone station according to an embodiment of the present disclosure comprises: a roof allowing a drone to land thereon; a side wall formed to be erected around all sides of the roof from the lower side of the roof; a nozzle which is formed at an edge at which the roof and the side wall meet each other, and sprays an air current upward; a grill formed on the side wall to allow external air to be introduced thereinto; a guide panel disposed inside the grill to guide fluid flow so that fluid flows from the grill to the nozzle; and a rotor disposed inside the guide panel to move fluid from the grill side to the nozzle side through a rotating operation."
DRONE STATION,https://lens.org/111-827-901-747-33X,2023,"A drone station according to an embodiment of the present disclosure comprises: a roof allowing a drone to land thereon; a side wall formed to be erected around all sides of the roof from the lower side of the roof; a nozzle which is formed at an edge at which the roof and the side wall meet each other, and sprays an air current upward; a grill formed on the side wall to allow external air to be introduced thereinto; a guide panel disposed inside the grill to guide fluid flow so that fluid flows from the grill to the nozzle; and a rotor disposed inside the guide panel to move fluid from the grill side to the nozzle side through a rotating operation."
"MORE ENDEARING ROBOT, METHOD OF CONTROLLING THE SAME, AND NON-TRANSITORY RECORDING MEDIUM",https://lens.org/174-359-489-905-156,2018,"A more endearing robot includes an operation unit that causes the robot to operate, a viewing direction determiner that determines whether a viewing direction of a predetermined target is toward the robot or not, and an operation controller that controls the operation unit based on a result of determination by the viewing direction determiner."
"More endearing robot, method of controlling the same, and non-transitory recording medium",https://lens.org/123-397-863-277-258,2021,"A more endearing robot includes an operation unit that causes the robot to operate, a viewing direction determiner that determines whether a viewing direction of a predetermined target is toward the robot or not, and an operation controller that controls the operation unit based on a result of determination by the viewing direction determiner."
"CONTROL DEVICE, CONTROL SYSTEM, AND NON-TRANSITORY COMPUTER READABLE MEDIUM",https://lens.org/088-978-824-737-301,2020,A control device includes a first receiving unit that receives an operation instruction given by voice or generated from voice; a second receiving unit that receives information concerning a sound volume of the voice input to a voice input unit provided corresponding to a target apparatus; a target apparatus specifying unit that specifies a target apparatus on a basis of the information concerning the sound volume received by the second receiving unit; and a transmitting unit that transmits an operation command based on the operation instruction received by the first receiving unit to the target apparatus specified by the target apparatus specifying unit.
"Control device, control system, and non-transitory computer readable medium",https://lens.org/028-661-024-516-832,2022,A control device includes a first receiving unit that receives an operation instruction given by voice or generated from voice; a second receiving unit that receives information concerning a sound volume of the voice input to a voice input unit provided corresponding to a target apparatus; a target apparatus specifying unit that specifies a target apparatus on a basis of the information concerning the sound volume received by the second receiving unit; and a transmitting unit that transmits an operation command based on the operation instruction received by the first receiving unit to the target apparatus specified by the target apparatus specifying unit.
"Control device, control system, and non-transitory computer readable medium",https://lens.org/028-661-024-516-832,2022,A control device includes a first receiving unit that receives an operation instruction given by voice or generated from voice; a second receiving unit that receives information concerning a sound volume of the voice input to a voice input unit provided corresponding to a target apparatus; a target apparatus specifying unit that specifies a target apparatus on a basis of the information concerning the sound volume received by the second receiving unit; and a transmitting unit that transmits an operation command based on the operation instruction received by the first receiving unit to the target apparatus specified by the target apparatus specifying unit.
UNMANNED AERIAL VEHICLE,https://lens.org/172-333-096-956-86X,2019,"The present disclosure provides an Unmanned Aerial Vehicle (UAV). The vehicle includes a main body; a supporting frame that is connected to the main body; two mounting brackets that are spaced apart; a plurality of shock absorbing structures that connect the supporting frame and the mounting brackets; and two gimbals configured to carry a plurality of payloads. The two gimbals are respectively connected to the two mounting brackets, and the shock absorbing structures absorb shocks on the gimbals."
Sensory augmentation system,https://lens.org/049-482-258-118-202,2020,A programmable control unit including a gps receiver and having the capability of receiving a plurality user-programmable waypoints and calculating distance and direction for each of the programmable waypoints. The programmable control unit further including a mechanism capable of producing a signal to assist a user to maintain a course toward a waypoint wherein the programmable control unit may be programmed by the user to set the frequency of the signal.
SENSORY AUGMENTATION SYSTEM,https://lens.org/037-407-840-126-536,2019,A programmable control unit including a gps receiver and having the capability of receiving a plurality user-programmable waypoints and calculating distance and direction for each of the programmable waypoints. The programmable control unit further including a mechanism capable of producing a signal to assist a user to maintain a course toward a waypoint wherein the programmable control unit may be programmed by the user to set the frequency of the signal.
Electronic device for processing image and method for controlling the same,https://lens.org/016-444-724-145-669,2022,"A method for controlling an electronic device is provided. The method includes obtaining an image, detecting at least one object in a facial area from the image, and applying a virtual light source effect to the image based on an attribute of the detected object and displaying the image."
ELECTRONIC DEVICE FOR PROCESSING IMAGE AND METHOD FOR CONTROLLING THE SAME,https://lens.org/062-249-359-352-76X,2020,"A method for controlling an electronic device is provided. The method includes obtaining an image, detecting at least one object in a facial area from the image, and applying a virtual light source effect to the image based on an attribute of the detected object and displaying the image."
ELECTRONIC DEVICE FOR PROCESSING IMAGE AND METHOD FOR CONTROLLING THE SAME,https://lens.org/018-480-736-923-975,2016,"A method for controlling an electronic device is provided. The method includes obtaining an image, detecting at least one object in a facial area from the image, and applying a virtual light source effect to the image based on an attribute of the detected object and displaying the image."
Electronic device for processing image and method for controlling the same,https://lens.org/198-566-723-042-022,2019,"A method for controlling an electronic device is provided. The method includes obtaining an image, detecting at least one object in a facial area from the image, and applying a virtual light source effect to the image based on an attribute of the detected object and displaying the image."
Remotely controlled robot,https://lens.org/066-347-293-157-72X,2019,"A battery powered remotely controlled robot is equipped with a drive subsystem for ground travel, a flight subsystem for flight operations, and an obstacle detection subsystem. The robot is configured so that during a mission the drive subsystem is energized to maneuver the robot on the ground for a majority of the mission. The robot is further configured so that upon detection of an obstacle, the flight subsystem is energized to traverse the obstacle. The fight subsystem is energized only to traverse obstacles thus saving battery power and increasing the mission time."
REMOTELY CONTROLLED ROBOT,https://lens.org/138-341-081-306-482,2018,"A battery powered remotely controlled robot is equipped with a drive subsystem for ground travel, a flight subsystem for flight operations, and an obstacle detection subsystem. The robot is configured so that during a mission the drive subsystem is energized to maneuver the robot on the ground for a majority of the mission. The robot is further configured so that upon detection of an obstacle, the flight subsystem is energized to traverse the obstacle. The fight subsystem is energized only to traverse obstacles thus saving battery power and increasing the mission time."
ABILITY TO CREATE USER PREFERENCES FOR BUILDING SYSTEMS FROM HISTORICAL USE PATTERNS,https://lens.org/088-417-714-795-527,2020,A method of controlling a building system is provided. The method comprising: detecting a first current position of a user device; obtaining a building system list including building systems adjustable at the first current position; obtaining an action request list including action requests transmitted from the user device to the building system on the building system list; generating one or more scenes in response to the action request list and the building system list; selecting a scene; and adjusting one or more of the building systems on the building list in response to the scene.
ABILITY TO CREATE USER PREFERENCES FOR BUILDING SYSTEMS FROM HISTORICAL USE PATTERNS,https://lens.org/145-689-865-950-795,2019,A method of controlling a building system is provided. The method comprising: detecting a first current position of a user device; obtaining a building system list including building systems adjustable at the first current position; obtaining an action request list including action requests transmitted from the user device to the building system on the building system list; generating one or more scenes in response to the action request list and the building system list; selecting a scene; and adjusting one or more of the building systems on the building list in response to the scene.
"MULTI-ROTOR UNMANNED AERIAL VEHICLE, POWER SYSTEM, ELECTRONIC SPEED CONTROL, AND CONTROL METHOD AND SYSTEM THEREOF",https://lens.org/008-765-027-825-658,2019,A multi-rotor UAV includes a frame and a plurality of propulsion systems configured on the frame. Each propulsion system includes a motor and an electronic speed control (ESC) device. The ESC device of each propulsion system includes: a first communication interface; and a processor configured to acquire voltage information at the first communication interface and determine address information of the ESC according to the voltage information. The multi-rotor UAV further includes a controller connected to the first communication interface of the ESC device of each propulsion system. The controller is configured to send a throttle signal to the ESC device of each propulsion system.
Secure self learning system,https://lens.org/172-957-645-565-884,2000,"A method and system for the remote control of devices having a secure self learn capability. The system includes an encoder and a decoder, the encoder encoding variable information including a user key using a non-linear algorithm to produce an encoded value transmitted to the decoder, the decoder decoding the value using the same algorithm. In a learning mode a new encoder is to be added to the system. The new encoder produces an encoded value using a key generation seed. The decoder, upon receiving the encoded key generation seed, produces a decoding key based upon the decoded key generation seed. The decoding key is stored in the decoder memory allowing valid recognition of the new encoder in a secure manner."
Secure self learning system,https://lens.org/025-996-954-104-610,1997,"A method and system for the remote control of devices having a secure self learn capability. The system includes an encoder and a decoder, the encoder encoding variable information including a user key using a non-linear algorithm to produce an encoded value transmitted to the decoder, the decoder decoding the value using the same algorithm. In a learning mode a new encoder is to be added to the system. The new encoder produces an encoded value using a key generation seed. The decoder, upon receiving the encoded key generation seed, produces a decoding key based upon the decoded key generation seed. The decoding key is stored in the decoder memory allowing valid recognition of the new encoder in a secure manner."
Secure self learning system,https://lens.org/160-159-982-719-782,2001,"A method and system for the remote control of devices having a secure self learn capability. The system includes an encoder and a decoder, the encoder encoding variable information including a user key using a non-linear algorithm to produce an encoded value transmitted to the decoder, the decoder decoding the value using the same algorithm. In a learning mode a new encoder is to be added to the system. The new encoder produces an encoded value using a key generation seed. The decoder, upon receiving the encoded key generation seed, produces a decoding key based upon the decoded key generation seed. The decoding key is stored in the decoder memory allowing valid recognition of the new encoder in a secure manner."
METHOD FOR TRANSFERRING CONTROL OF AN AUTONOMOUS VEHICLE TO A REMOTE OPERATOR,https://lens.org/070-897-617-809-693,2019,"One variation of a method for transferring control of an autonomous vehicle to a remote operator includes: accessing a specification for triggering manual control of autonomous vehicles; identifying a road segment, within a geographic region, exhibiting characteristics defined by the specification; and associating a location of the road segment, represented in a navigation map, with a remote operator trigger. The method also includes, at the autonomous vehicle operating within the geographic region: autonomously navigating along a route; transmitting a request for manual assistance to the remote operator in response to approaching the location associated with the remote operator trigger; transmitting sensor data to a remote operator portal associated with the remote operator; and executing a navigational command received from the remote operator via the remote operator portal; and resuming autonomous navigation along the route after passing the location."
System and method for changing a surface characteristic of a concrete bridge surface,https://lens.org/178-790-443-296-731,2023,"An automated concrete bridge paver with an ability to provide effective control of a concrete paver by a remotely locatable concrete bridge paver operator, which includes a fixed operator control station and a mobile wireless remote operator control station which can be used when the remotely locatable concrete bridge paver operator leaves the operator control station. Mobile wireless remote operator control station includes a video screen which can display live video images from a plurality of remote wireless camera and sensor pods, which can be fixed on the paver or moved about the paver on an articulated arm, with or without a human basket."
SYSTEM AND METHOD FOR CHANGING A SURFACE CHARACTERISTIC OF A CONCRETE BRIDGE SURFACE,https://lens.org/048-129-381-501-334,2021,"An automated concrete bridge paver with an ability to provide effective control of a concrete paver by a remotely locatable concrete bridge paver operator, which includes a fixed operator control station and a mobile wireless remote operator control station which can be used when the remotely locatable concrete bridge paver operator leaves the operator control station. Mobile wireless remote operator control station includes a video screen which can display live video images from a plurality of remote wireless camera and sensor pods, which can be fixed on the paver or moved about the paver on an articulated arm, with or without a human basket."
DRONE TRACKING STEERED ANTENNA SYSTEM,https://lens.org/020-888-864-650-992,2020,"A system for tracking an unmanned aerial vehicle (UAV) with a directional antenna can include a tracking module which is configured to be secured relative to a UAV, and which can be configured to operate independently of the UAV. The tracking module may include a processor, a power source, a GPS module, and a transmitter, and may transmit geolocation information of the UAV to a base station. The transmission of geolocation information may occur over a LoRa radio link. The base station may include a processor, a GPS module, a receiver, and one or more movable directional antennas. The orientation of the movable directional antenna may be changed to track the location of the UAV, based on the geolocation information of the UAV and the base station. The directional antennas may replace the antennas of a UAV controller associated with the UAV to increase the operational range of the UAV."
DRONE TRACKING STEERED ANTENNA SYSTEM,https://lens.org/020-888-864-650-992,2020,"A system for tracking an unmanned aerial vehicle (UAV) with a directional antenna can include a tracking module which is configured to be secured relative to a UAV, and which can be configured to operate independently of the UAV. The tracking module may include a processor, a power source, a GPS module, and a transmitter, and may transmit geolocation information of the UAV to a base station. The transmission of geolocation information may occur over a LoRa radio link. The base station may include a processor, a GPS module, a receiver, and one or more movable directional antennas. The orientation of the movable directional antenna may be changed to track the location of the UAV, based on the geolocation information of the UAV and the base station. The directional antennas may replace the antennas of a UAV controller associated with the UAV to increase the operational range of the UAV."
GUIDANCE APPARATUS FOR AUTONOMOUS VEHICLE AND METHOD THEREFOR,https://lens.org/037-743-851-702-861,2021,"A guidance apparatus for an autonomous vehicle and a method therefor are provided. The guidance apparatus includes a first guidance device that guides a passenger in the autonomous vehicle through first response information, a second guidance device that guides a rescuer outside the autonomous vehicle through second response information, and a controller that controls guidance on the first response information and guidance on the second response information, when abnormality occurs in the autonomous vehicle."
Guidance apparatus for autonomous vehicle and method therefor,https://lens.org/165-842-270-978-530,2022,"A guidance apparatus for an autonomous vehicle and a method therefor are provided. The guidance apparatus includes a first guidance device that guides a passenger in the autonomous vehicle through first response information, a second guidance device that guides a rescuer outside the autonomous vehicle through second response information, and a controller that controls guidance on the first response information and guidance on the second response information, when abnormality occurs in the autonomous vehicle."
Guidance apparatus for autonomous vehicle and method therefor,https://lens.org/165-842-270-978-530,2022,"A guidance apparatus for an autonomous vehicle and a method therefor are provided. The guidance apparatus includes a first guidance device that guides a passenger in the autonomous vehicle through first response information, a second guidance device that guides a rescuer outside the autonomous vehicle through second response information, and a controller that controls guidance on the first response information and guidance on the second response information, when abnormality occurs in the autonomous vehicle."
Unmanned aerial robotic vehicle with mounting mechanism,https://lens.org/150-723-184-883-942,2020,"An unmanned aerial robotic vehicle (UARV) that can fly to an object such as a palm tree, hover in place adjacent to the object, mount itself securely and releasably to a mounting location on the object using a mounting mechanism, and which uses an incorporated utility system for performing one or more utilitarian functions, such as use of a cutting tool to trim palm tree branches and foliage."
AN UNMANNED AERIAL ROBOTIC VEHICLE WITH MOUNTING MECHANISM,https://lens.org/047-759-432-386-381,2017,"An unmanned aerial robotic vehicle (UARV) that can fly to an object such as a palm tree, hover in place adjacent to the object, mount itself securely and releasably to a mounting location on the object using a mounting mechanism, and which uses an incorporated utility system for performing one or more utilitarian functions, such as use of a cutting tool to trim palm tree branches and foliage."
UNMANNED AERIAL ROBOTIC VEHICLE WITH MOUNTING MECHANISM,https://lens.org/059-555-339-433-084,2018,"An unmanned aerial robotic vehicle (UARV) that can fly to an object such as a palm tree, hover in place adjacent to the object, mount itself securely and releasably to a mounting location on the object using a mounting mechanism, and which uses an incorporated utility system for performing one or more utilitarian functions, such as use of a cutting tool to trim palm tree branches and foliage."
Unmanned Aerial Vehicle,https://lens.org/157-483-166-787-839,2023,"An unmanned aerial robotic vehicle (UARV) that can fly to an object such as a palm tree, hover in place adjacent to the object, mount itself securely and releasably to a mounting location on the object using a mounting mechanism, and which uses an incorporated utility system for performing one or more utilitarian functions, such as use of a cutting tool to trim palm tree branches and foliage."
Robot teleoperation using mobile device motion sensors and web standards,https://lens.org/041-526-041-951-077,2023,"A method includes receiving an indication that a web-based application has been accessed for control of a robotic device by a mobile device, wherein the mobile device comprises one or more sensors to detect movement of the mobile device. The method further includes subscribing the web-based application to at least one motion event web API, wherein the at least one motion event web API listens normalizes motion data from the one or more sensors of the mobile device into one or more standardized motion parameters. The method additionally includes receiving the one or more standardized motion parameters of the mobile device from the at least one motion event web API. The method further includes converting the one or more standardized motion parameters into one or more requested movement commands for the robotic device. The method further includes sending the one or more requested movement commands to the robotic device."
"COUNTER DRONE DEVICE, AND METHOD OF USING THE SAME",https://lens.org/199-668-089-239-875,2017,"A counter drone device adapted to render propellers of drones inoperable. The counter drone device may be a weighted filament adapted to be projecting into the propeller of a drone so as to entangle/ensnare/wrap around propeller shaft and/or blades, rendering the drone inoperable."
"COUNTER DRONE DEVICE, AND METHOD OF USING THE SAME",https://lens.org/125-953-523-784-613,2019,"A counter drone device adapted to render propellers of drones inoperable. The counter drone device may be a weighted filament adapted to be projecting into the propeller of a drone so as to entangle/ensnare/wrap around propeller shaft and/or blades, rendering the drone inoperable."
"Method for operating an autonomous vehicle, and autonomous vehicle",https://lens.org/037-498-657-159-424,2022,"A method for operating an autonomous vehicle. The method includes the transmission of status data to a processing unit, which is independent of the autonomous vehicle, using a wireless communications link. The method furthermore includes monitoring of the function of the autonomous vehicle by the independent processing unit while taking the status data into account, and when a malfunction of the autonomous vehicle is detected, the independent processing unit determines target data for guiding the autonomous vehicle to a stopping position. The target data are transmitted to the autonomous vehicle, and the autonomous vehicle is guided to the stopping position with the aid of the target data. A position of the autonomous vehicle is determined using signals from the wireless communications link and is taken into account when determining the target data."
"METHOD FOR OPERATING AN AUTONOMOUS VEHICLE, AND AUTONOMOUS VEHICLE",https://lens.org/044-622-981-160-215,2021,"A method for operating an autonomous vehicle. The method includes the transmission of status data to a processing unit, which is independent of the autonomous vehicle, using a wireless communications link. The method furthermore includes monitoring of the function of the autonomous vehicle by the independent processing unit while taking the status data into account, and when a malfunction of the autonomous vehicle is detected, the independent processing unit determines target data for guiding the autonomous vehicle to a stopping position. The target data are transmitted to the autonomous vehicle, and the autonomous vehicle is guided to the stopping position with the aid of the target data. A position of the autonomous vehicle is determined using signals from the wireless communications link and is taken into account when determining the target data."
"Method for operating an autonomous vehicle, and autonomous vehicle",https://lens.org/037-498-657-159-424,2022,"A method for operating an autonomous vehicle. The method includes the transmission of status data to a processing unit, which is independent of the autonomous vehicle, using a wireless communications link. The method furthermore includes monitoring of the function of the autonomous vehicle by the independent processing unit while taking the status data into account, and when a malfunction of the autonomous vehicle is detected, the independent processing unit determines target data for guiding the autonomous vehicle to a stopping position. The target data are transmitted to the autonomous vehicle, and the autonomous vehicle is guided to the stopping position with the aid of the target data. A position of the autonomous vehicle is determined using signals from the wireless communications link and is taken into account when determining the target data."
System and method of control for autonomous or remote-controlled vehicle platform,https://lens.org/160-305-732-749-930,2022,"A system and method for controlling a vehicle platform, the system comprising on onboard controller and an off-board controller that work together to provide autonomous navigation in fields or similar areas where the vehicle is deployed, perception for obstacle detection and avoidance, and a user interface for user/ vehicle interaction and control."
"DEVICES, SYSTEMS, AND METHODS FOR OPERATING INTELLIGENT VEHICLES USING SEPARATE DEVICES",https://lens.org/122-575-904-664-442,2022,"A system for providing autonomous driving of a radio controlled vehicle through an ambient environment is disclosed herein. The system can include a modular device with at least one sensor configured to generate signals associated with characteristics of the ambient environment, a bed plate configured to be mechanically coupled to the RC vehicle, and a modular control circuit configured to be mechanically coupled to the bed plate and communicably coupled to the modular device, wherein the modular control circuit is configured to be communicably coupled to hardware of the RC vehicle and control the RC vehicle in response to commands received from the modular device."
"DEVICES, SYSTEMS, AND METHODS FOR OPERATING INTELLIGENT VEHICLES USING SEPARATE DEVICES",https://lens.org/122-575-904-664-442,2022,"A system for providing autonomous driving of a radio controlled vehicle through an ambient environment is disclosed herein. The system can include a modular device with at least one sensor configured to generate signals associated with characteristics of the ambient environment, a bed plate configured to be mechanically coupled to the RC vehicle, and a modular control circuit configured to be mechanically coupled to the bed plate and communicably coupled to the modular device, wherein the modular control circuit is configured to be communicably coupled to hardware of the RC vehicle and control the RC vehicle in response to commands received from the modular device."
Flight control system for aircraft and test for testing such a flight control system,https://lens.org/033-559-104-279-734,2011,A test system for testing a flight control system of an aircraft includes a test device that: (1) accesses information available from the flight control system and (2) controls a computer of the flight control system.
An unmanned aerial vehicle system for inspecting railroad assets,https://lens.org/069-724-972-410-846,2022,"An aerial system control network (2500), an unmanned aerial vehicle (UAV) system (2400), and a method (2600) provide for inspecting railroad assets using a UAV (2420). The aerial system control network includes a plurality of towers (2510, 2515) and a ground control system (2520) connected to the plurality of communication towers. The ground control system transmits, via the plurality of communication towers, a flight plan including a rail system (100) and a flight path (1010); receives, via the plurality of communication towers, data while the UAV is in monitoring the rail system; detects an interference (1500, 1501, 1502) along the flight path based on the received data, and adjusts the flight plan based on the interference."
An unmanned aerial vehicle system for inspecting railroad assets,https://lens.org/177-395-736-452-295,2020,"An aerial system control network (2500), an unmanned aerial vehicle (UAV) system (2400), and a method (2600) provide for inspecting railroad assets using a UAV (2420). The aerial system control network includes a plurality of towers (2510, 2515) and a ground control system (2520) connected to the plurality of communication towers. The ground control system transmits, via the plurality of communication towers, a flight plan including a rail system (100) and a flight path (1010); receives, via the plurality of communication towers, data while the UAV is in monitoring the rail system; detects an interference (1500, 1501, 1502) along the flight path based on the received data, and adjusts the flight plan based on the interference."
An unmanned aerial vehicle system for inspecting railroad assets,https://lens.org/069-724-972-410-846,2022,"An aerial system control network (2500), an unmanned aerial vehicle (UAV) system (2400), and a method (2600) provide for inspecting railroad assets using a UAV (2420). The aerial system control network includes a plurality of towers (2510, 2515) and a ground control system (2520) connected to the plurality of communication towers. The ground control system transmits, via the plurality of communication towers, a flight plan including a rail system (100) and a flight path (1010); receives, via the plurality of communication towers, data while the UAV is in monitoring the rail system; detects an interference (1500, 1501, 1502) along the flight path based on the received data, and adjusts the flight plan based on the interference."
AN UNMANNED AERIAL VEHICLE SYSTEM FOR INSPECTING RAILROAD ASSETS,https://lens.org/059-446-668-328-653,2019,"An aerial system control network (2500), an unmanned aerial vehicle (UAV) system (2400), and a method (2600) provide for inspecting railroad assets using a UAV (2420). The aerial system control network includes a plurality of towers (2510, 2515) and a ground control system (2520) connected to the plurality of communication towers. The ground control system transmits, via the plurality of communication towers, a flight plan including a rail system (100) and a flight path (1010); receives, via the plurality of communication towers, data while the UAV is in monitoring the rail system; detects an interference (1500, 1501, 1502) along the flight path based on the received data, and adjusts the flight plan based on the interference."
ENVIRONMENTAL MONITORING UAV SYSTEM,https://lens.org/147-360-810-491-463,2017,"The present invention relates to an environmental monitoring UAV system comprises a drone provided with an air monitoring platform that is adapted for taking air sample(s) by enforcing air to flow through or into at least one sampling medium, during the flight of said drone."
Environmental Monitoring UAV System,https://lens.org/080-199-923-777-858,2018,"The present invention relates to an environmental monitoring UAV system comprises a drone provided with an air monitoring platform that is adapted for taking air sample(s) by enforcing air to flow through or into at least one sampling medium, during the flight of said drone."
Environmental monitoring UAV system,https://lens.org/089-124-612-701-152,2019,"The present invention relates to an environmental monitoring UAV system comprises a drone provided with an air monitoring platform that is adapted for taking air sample(s) by enforcing air to flow through or into at least one sampling medium, during the flight of said drone."
ENVIRONMENTAL MONITORING UAV SYSTEM,https://lens.org/033-953-107-588-183,2016,"The present invention relates to an environmental monitoring UAV system comprises a drone provided with an air monitoring platform that is adapted for taking air sample(s) by enforcing air to flow through or into at least one sampling medium, during the flight of said drone."
COMMUNICATION CHANNEL BETWEEN A REMOTE CONTROL AND A HEARING ASSISTIVE DEVICE,https://lens.org/097-520-370-420-845,2019,"A remote-control unit (10) for controlling a hearing assistive device (20) by sending a control signal with instructions as an acoustic signal, has an input transducer (14), an output transducer (15), and a processor (11) adapted for setting the volume of the output from the output transducer (15). The processor (11) is adapted for activating the input transducer (14) for receiving environmental sound, analyzing the environmental sound, determining and setting the volume of the output from the output transducer (15) based on the environmental sound, and outputting the control signal at the set volume via the output transducer (15)."
Communication channel between a remote control and a hearing assistive device,https://lens.org/044-366-371-847-781,2020,"A remote-control unit (10) for controlling a hearing assistive device (20) by sending a control signal with instructions as an acoustic signal, has an input transducer (14), an output transducer (15), and a processor (11) adapted for setting the volume of the output from the output transducer (15). The processor (11) is adapted for activating the input transducer (14) for receiving environmental sound, analyzing the environmental sound, determining and setting the volume of the output from the output transducer (15) based on the environmental sound, and outputting the control signal at the set volume via the output transducer (15)."
Autonomous Flight Termination System and Method,https://lens.org/198-393-863-175-051,2018,"An autonomous flight termination system for terminating vehicle flight after the vehicle is launched from an aircraft includes a global positioning system (GPS) receiver; a termination unit selected from a cut-off switch connected to terminate vehicle flight when actuated, and a switch connected to detonate an explosive on the vehicle; a system controller for receiving a first signal indicating separation of the vehicle from the aircraft and a second signal from the GPS receiver to calculate an actual vehicle trajectory, and for sending a third signal to actuate the termination unit to terminate the flight of the vehicle when the actual vehicle trajectory is determined to be outside the safety bounds of a mission-planned flight trajectory; and a failsafe controller connected to receive operational data of the system controller, and to actuate the termination unit when the operational data indicates that the system is in an error state."
Autonomous flight termination system and method,https://lens.org/023-749-724-398-878,2019,"An autonomous flight termination system for terminating vehicle flight after the vehicle is launched from an aircraft includes a global positioning system (GPS) receiver; a termination unit selected from a cut-off switch connected to terminate vehicle flight when actuated, and a switch connected to detonate an explosive on the vehicle; a system controller for receiving a first signal indicating separation of the vehicle from the aircraft and a second signal from the GPS receiver to calculate an actual vehicle trajectory, and for sending a third signal to actuate the termination unit to terminate the flight of the vehicle when the actual vehicle trajectory is determined to be outside the safety bounds of a mission-planned flight trajectory; and a failsafe controller connected to receive operational data of the system controller, and to actuate the termination unit when the operational data indicates that the system is in an error state."
AIRCRAFT,https://lens.org/190-422-242-572-205,2010,"An unmanned aerial vehicle (UAV) in the form of a tail sitter flying wing adapted for vertical take off and landing and transitions between flight as a helicopter and wing-borne flight. The vehicle is electrically powered from onboard batteries and equipped with rotors on miniature helicopter rotor heads at the tips of the wing for both lift, during take off and landing, and forward thrust. In planform the wing comprises, to each side of its longitudinal axis, an inner section with swept back leading and trailing edges, and an outer section with a leading edge more perpendicular to the longitudinal axis, being only mildly swept back or substantially unswept, and a swept forward trailing edge."
Television program record scheduling using compressed codes,https://lens.org/003-439-401-508-674,2000,"The invention regards a remote control unit (1100) for control of home electronic devices comprising: a housing; a memory for storing data; and means for receiving data from an external source (1142) wherein said means for receiving comprise a microphone (1162) which is disposed on a surface portion of said housing. Preferably, the received data comprises data representative of selections of one or more of a plurality of remote control signal protocols. The remote control (1100) comprises a transmitter (1158) for transmitting remote control signals for controlling audio/visual electronic devices according to the selections of remote control signal protocols."
Methods and apparatus for continuing a zoom of a stationary camera utilizing a drone,https://lens.org/090-234-262-495-442,2018,"A method and apparatus for a video-camera equipped UAV to continue a zoom of the stationary video camera is provided herein. More particularly, a camera mounted on an unmanned aerial vehicle (UAV) is used to extend a field of view (FOV) of a fixed camera in a way that it is seamless for a user who is looking at the video stream and utilizes a joystick to manipulate the camera settings."
METHODS AND APPARATUS FOR CONTINUING A ZOOM OF A STATIONARY CAMERA UTILIZING A DRONE,https://lens.org/053-434-590-624-56X,2018,"A method and apparatus for a video-camera equipped UAV to continue a zoom of the stationary video camera is provided herein. More particularly, a camera mounted on an unmanned aerial vehicle (UAV) is used to extend a field of view (FOV) of a fixed camera in a way that it is seamless for a user who is looking at the video stream and utilizes a joystick to manipulate the camera settings."
METHODS AND APPARATUS FOR CONTINUING A ZOOM OF A STATIONARY CAMERA UTILIZING A DRONE,https://lens.org/090-116-106-366-57X,2017,"A method and apparatus for a video-camera equipped UAV to continue a zoom of the stationary video camera is provided herein. More particularly, a camera mounted on an unmanned aerial vehicle (UAV) is used to extend a field of view (FOV) of a fixed camera in a way that it is seamless for a user who is looking at the video stream and utilizes a joystick to manipulate the camera settings."
Methods and apparatus for continuing a zoom of a stationary camera utilizing a drone,https://lens.org/000-157-276-235-958,2019,"A method and apparatus for a video-camera equipped UAV to continue a zoom of the stationary video camera is provided herein. More particularly, a camera mounted on an unmanned aerial vehicle (UAV) is used to extend a field of view (FOV) of a fixed camera in a way that it is seamless for a user who is looking at the video stream and utilizes a joystick to manipulate the camera settings."
"Method, apparatus for controlling a smart device and computer storge medium",https://lens.org/076-932-800-968-35X,2020,"The disclosure relates to a method for controlling a smart device, an apparatus, and non-transitory computer-readable medium. The method includes acquiring a video stream captured by a smart camera that is bound to the user account, wherein the video stream includes multi-frame video that includes a plurality of one-frame video images; performing pattern recognition on each of the plurality of one-frame video images, wherein the pattern recognition is configured to determine an area that includes at least one smart device in at least one of the plurality of one-frame video images; determining, based on the pattern recognition, a target area that includes the smart device in a first one-frame video image of the plurality of one-frame video images; displaying the first one-frame video image including the target area on a touch screen; detecting, via the touch screen, a control operation within the target area of the first one-frame video image; and controlling the smart device located in the target area based on the control operation."
"METHOD, APPARATUS FOR CONTROLLING A SMART DEVICE AND COMPUTER STORGE MEDIUM",https://lens.org/044-690-859-182-028,2018,"The disclosure relates to a method for controlling a smart device, an apparatus, and non-transitory computer-readable medium. The method includes acquiring a video stream captured by a smart camera that is bound to the user account, wherein the video stream includes multi-frame video that includes a plurality of one-frame video images; performing pattern recognition on each of the plurality of one-frame video images, wherein the pattern recognition is configured to determine an area that includes at least one smart device in at least one of the plurality of one-frame video images; determining, based on the pattern recognition, a target area that includes the smart device in a first one-frame video image of the plurality of one-frame video images; displaying the first one-frame video image including the target area on a touch screen; detecting, via the touch screen, a control operation within the target area of the first one-frame video image; and controlling the smart device located in the target area based on the control operation."
"Method, apparatus for controlling a smart device and computer storge medium",https://lens.org/045-458-165-755-741,2021,"The disclosure relates to a method for controlling a smart device, an apparatus, and non-transitory computer-readable medium. The method includes acquiring a video stream captured by a smart camera that is bound to the user account, wherein the video stream includes multi-frame video that includes a plurality of one-frame video images; performing pattern recognition on each of the plurality of one-frame video images, wherein the pattern recognition is configured to determine an area that includes at least one smart device in at least one of the plurality of one-frame video images; determining, based on the pattern recognition, a target area that includes the smart device in a first one-frame video image of the plurality of one-frame video images; displaying the first one-frame video image including the target area on a touch screen; detecting, via the touch screen, a control operation within the target area of the first one-frame video image; and controlling the smart device located in the target area based on the control operation."
AIRCRAFT SEARCH LIGHT SYSTEM,https://lens.org/057-299-632-366-690,2021,"An aircraft search light system is disclosed. Voice commands may be used to control one or more aspects of the operation of the aircraft search light system, including to initiate the detection of objects in image data, to select a particular object in the image data to be tracked by the search light, and the like. The search light may be moved based upon processed image data, for instance such that the selected object continues to be illuminated by the search light. Voice commands may also be used to initiate movement the search light relative to the selected object (e.g., to keep the selected object in the field of view of the search light). Audio output may be generated by the aircraft search light system to provide information to aircraft personnel on the processed image data, and on which one or more subsequent voice commands may be based."
Aircraft search light system,https://lens.org/100-959-350-028-384,2022,"An aircraft search light system is disclosed. Voice commands may be used to control one or more aspects of the operation of the aircraft search light system, including to initiate the detection of objects in image data, to select a particular object in the image data to be tracked by the search light, and the like. The search light may be moved based upon processed image data, for instance such that the selected object continues to be illuminated by the search light. Voice commands may also be used to initiate movement the search light relative to the selected object (e.g., to keep the selected object in the field of view of the search light). Audio output may be generated by the aircraft search light system to provide information to aircraft personnel on the processed image data, and on which one or more subsequent voice commands may be based."
Aircraft search light system,https://lens.org/100-959-350-028-384,2022,"An aircraft search light system is disclosed. Voice commands may be used to control one or more aspects of the operation of the aircraft search light system, including to initiate the detection of objects in image data, to select a particular object in the image data to be tracked by the search light, and the like. The search light may be moved based upon processed image data, for instance such that the selected object continues to be illuminated by the search light. Voice commands may also be used to initiate movement the search light relative to the selected object (e.g., to keep the selected object in the field of view of the search light). Audio output may be generated by the aircraft search light system to provide information to aircraft personnel on the processed image data, and on which one or more subsequent voice commands may be based."
"Control apparatus, control system and control method",https://lens.org/076-804-587-172-646,2023,A control device mounted in a first mobile body that includes a camera and an antenna includes: the camera configured to operate such that a direction of an optical axis of the camera and an oriented direction of the antenna are linked to each other; an identification unit configured to identify a second mobile body through image recognition from a captured image captured by the camera operating; and an antenna control unit configured to control the oriented direction of the antenna such that a position of the identified second mobile body in the captured image is a predetermined position.
"Control apparatus, control system and control method",https://lens.org/076-804-587-172-646,2023,A control device mounted in a first mobile body that includes a camera and an antenna includes: the camera configured to operate such that a direction of an optical axis of the camera and an oriented direction of the antenna are linked to each other; an identification unit configured to identify a second mobile body through image recognition from a captured image captured by the camera operating; and an antenna control unit configured to control the oriented direction of the antenna such that a position of the identified second mobile body in the captured image is a predetermined position.
UNMANNED AERIAL VEHICLE AND METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE,https://lens.org/077-998-987-995-929,2022,"An unmanned aerial vehicle traveling with an imaging device includes at least one memory and at least one processor which function as: an estimation unit configured to estimate an amount of power consumed by the imaging device and the unmanned aerial vehicle during a time period in which the imaging device and the unmanned aerial vehicle travel from a current location to a target position; and a control unit configured to execute control to give a predetermined notification based on a remaining amount of power of a power supply unit configured to supply power to the imaging device and the unmanned aerial vehicle, and an amount of power consumption estimated by the estimation unit."
UNMANNED AERIAL VEHICLE AND METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE,https://lens.org/077-998-987-995-929,2022,"An unmanned aerial vehicle traveling with an imaging device includes at least one memory and at least one processor which function as: an estimation unit configured to estimate an amount of power consumed by the imaging device and the unmanned aerial vehicle during a time period in which the imaging device and the unmanned aerial vehicle travel from a current location to a target position; and a control unit configured to execute control to give a predetermined notification based on a remaining amount of power of a power supply unit configured to supply power to the imaging device and the unmanned aerial vehicle, and an amount of power consumption estimated by the estimation unit."
UNMANNED AERIAL VEHICLE AND METHOD FOR CONTROLLING UNMANNED AERIAL VEHICLE,https://lens.org/077-998-987-995-929,2022,"An unmanned aerial vehicle traveling with an imaging device includes at least one memory and at least one processor which function as: an estimation unit configured to estimate an amount of power consumed by the imaging device and the unmanned aerial vehicle during a time period in which the imaging device and the unmanned aerial vehicle travel from a current location to a target position; and a control unit configured to execute control to give a predetermined notification based on a remaining amount of power of a power supply unit configured to supply power to the imaging device and the unmanned aerial vehicle, and an amount of power consumption estimated by the estimation unit."
Sound playing control method and system,https://lens.org/103-511-079-265-254,2015,"The invention relates to a sound playing control method and system. According to the method and system, a sound box is mounted on an aircraft, so that the sound box can be driven by the aircraft so a to fly and move; location information of a scene where sound is located is converted into location information of an external space; corresponding fly control data are generated so as to control the aircraft to fly to a location corresponding to the location information of the sound in the external space; the playing location of the sound is controlled, so that the sound will not just be emitted from a constant location only, but can be played under the driving of the aircraft when the location of the sound changes in the external space, and therefore, the sound playing can be better matched with the scene, and a better audio visual scene can be provided for a user, and user experience can be greatly improved, and higher and higher requirements of the user can be greatly satisfied."
Audio canceling of audio generated from nearby aerial vehicles,https://lens.org/036-801-722-967-720,2019,"The implementations described include an audio canceling device that receives an unmanned aerial vehicle (UAV) audio signature representative of audio generated by an unmanned aerial vehicle, monitors audio within an environment in which the audio canceling device is located for audio generated by the UAV, generates an attenuation-signal based on detected audio generated by the UAV, and outputs the attenuation-signal to attenuate the audio generated by the UAV. In one example, the audio canceling device may be used to attenuate audio generated by a UAV that is permeating into a user's home during delivery of an item to the user's home by the UAV."
"Leveling instrument, an electromechanical lifter and a self leveling integrated lifting system using both of them",https://lens.org/020-163-394-712-192,2004,"This self-leveling device is employed in the field of lifting of aircraft, helicopters, civil and military flying vehicles, watercraft, camping vehicles, trains, bridges, radar, etc., and for all those activities that require self-leveling and centring during lifting and lowering operations with fast results, without damages to the structure and in perfect safety (eg.: for helicopter lifting, for internal load balance, for safery during take-off and landing). The device is composed of a number of electromechanical lifting groups that operate synchronistically and autonomously from one another, linked with an electronic central general control for operation and a leveling cell. The whole system provides perfect self-leveling in case of unstable ground, for weighing and leveling purposes, targeting, weight balance, maintenance, etc."
"PROCESS, SYSTEM, METHOD AND APPARATUS FOR MONITORING STATUS AND CONTROL OF EQUIPMENT",https://lens.org/130-966-460-490-397,2015,"The present invention provides am apparatus and methods for an equipment monitoring system coupled to equipment, such as a garage door opener, sprinkler system, HVAC, and other equipment amenable to remote operation. The system permits a user to operate equipment controls via a smartphone, tablet, or other networked appliance. Photography and video equipment may be incorporated to validate equipment status and operation."
Unmanned aerial vehicle control vehicle,https://lens.org/005-967-837-131-558,2020,"The utility model provides an unmanned aerial vehicle control vehicle which comprises a vehicle body, a control area and an equipment area are sequentially arranged behind a driving area in the vehicle body, a partition plate is arranged between the driving area and the control area, the operation area and the equipment area are separated through a partition, a driving seat is arranged in the driving area, and a long-row explosion-flashing alarm lamp is installed at the top outside the driving area. A vehicle body LED display screen is arranged on the upper portion of the middle partition in the control area, a display control operation platform is arranged on the lower portion of the middle partition, a seat is arranged in front of the display control operation platform, a display screenis arranged on the display control operation platform, and an equipment installation cabinet is arranged at the bottom of the display control operation platform and extends towards the equipment areaalong the vehicle bottom; an electric turnover cabin door is arranged at the top of the equipment area; an electric lifting platform is arranged under the electric turnover cabin door, radar and unmanned aerial vehicle countering equipment is arranged on the electric lifting platform, and an auxiliary rear crawling ladder is arranged at the tail of the outer side of the vehicle body. Through reasonable arrangement and elaborate design, the vehicle is high in maneuverability, efficient and capable of adapting to various environments."
Multifunction light controller equipped with localized control,https://lens.org/108-089-099-024-985,2018,"An apparatus and method allow end users to interactively create complex lighting patterns by remote control. Applications include decorative lighting, landscape lighting, signage, or advertising platforms. A lighting control system is equipped with sensors that receive remote control signals from a variety of different sources, and route the control signals to modulate receptacles coupled to different lighting circuits, thereby independently controlling multiple light arrays to achieve separate light patterns, or to coordinate different lighting effects. The control signals independently energize localized groups of lamps to provide enhanced lighting effects, while using significantly less wire material. Interactive remote control is provided via a mobile computing device such as a smart phone running a customized program. In one embodiment, the remote control device communicates selections to a Bluetooth-equipped speaker to produce sound-controlled lighting effects."
FOLDABLE UAV,https://lens.org/081-919-532-653-822,2022,"An unmanned aerial vehicle (UAV) includes a central body having a first side and a second side opposite to the first side, and a first arm and a second arm extendable from the central body and respectively disposed on the first side and the second side. Each arm of the first arm and the second arm includes a plurality of sections and holds a set of rotor blades via a rotor shaft, and the plurality of sections includes a first section and a second section rotatably connected to the first section. The each arm of the first arm and the second arm is configured to transform between a flight configuration in which the second section of the each arm is extended away from the central body and a compact configuration in which the plurality of sections of the each arm are located at a corresponding side of the central body."
MARKER BASED SMART LANDING PAD,https://lens.org/155-556-531-411-680,2022,"A smart landing pad comprises a flexible display that shows images or patterns, and a protective layer over the display. The protective layer allows a UAV to land without damaging the display. Locator and range finder devices, coupled to the display, communicate with the UAV. The display is operative for wireless communications with a computer or mobile device that provides on-demand user functions, allowing for dynamically changing or customizing the images/patterns shown on the display. The images/patterns comprise a background area showing changeable images that match an environment where the landing pad is placed, and a target landing area surrounded by the background area. The target landing area includes a changeable insensitive, contrast portion, and changeable marker pattern portions having changeable colors/shapes. The images/patterns also include changeable QR codes on the target landing area. The display is IoT enabled so that data from the landing pad is remotely cloud accessible."
Marker based smart landing pad,https://lens.org/175-466-455-712-647,2023,"A smart landing pad comprises a flexible display that shows images or patterns, and a protective layer over the display. The protective layer allows a UAV to land without damaging the display. Locator and range finder devices, coupled to the display, communicate with the UAV. The display is operative for wireless communications with a computer or mobile device that provides on-demand user functions, allowing for dynamically changing or customizing the images/patterns shown on the display. The images/patterns comprise a background area showing changeable images that match an environment where the landing pad is placed, and a target landing area surrounded by the background area. The target landing area includes a changeable insensitive, contrast portion, and changeable marker pattern portions having changeable colors/shapes. The images/patterns also include changeable QR codes on the target landing area. The display is IoT enabled so that data from the landing pad is remotely cloud accessible."
MARKER BASED SMART LANDING PAD,https://lens.org/155-556-531-411-680,2022,"A smart landing pad comprises a flexible display that shows images or patterns, and a protective layer over the display. The protective layer allows a UAV to land without damaging the display. Locator and range finder devices, coupled to the display, communicate with the UAV. The display is operative for wireless communications with a computer or mobile device that provides on-demand user functions, allowing for dynamically changing or customizing the images/patterns shown on the display. The images/patterns comprise a background area showing changeable images that match an environment where the landing pad is placed, and a target landing area surrounded by the background area. The target landing area includes a changeable insensitive, contrast portion, and changeable marker pattern portions having changeable colors/shapes. The images/patterns also include changeable QR codes on the target landing area. The display is IoT enabled so that data from the landing pad is remotely cloud accessible."
UAV HARDWARE ARCHITECTURE,https://lens.org/041-276-068-010-657,2022,"A UAV includes an application processing circuit configured to process primary image data obtained by a primary imaging senor carried by a gimbal; a real-time sensing circuit configured to process, in a real time manner, secondary image data obtained by a secondary imaging sensor not carried by a gimbal; and a flight control circuit. The flight control circuit is configured to communicate, through a first communication channel, with the application processing circuit to receive the processed primary image data and use the processed primary image data to control the UAV to perform a first function; and communicate, through a second communication channel, with the real-time sensing circuit to receive the processed secondary image data and use the processed secondary image data to control the UAV to perform a second function. The second function is different from the first function. The second communication channel is independent from the first communication channel."
UAV HARDWARE ARCHITECTURE,https://lens.org/041-276-068-010-657,2022,"A UAV includes an application processing circuit configured to process primary image data obtained by a primary imaging senor carried by a gimbal; a real-time sensing circuit configured to process, in a real time manner, secondary image data obtained by a secondary imaging sensor not carried by a gimbal; and a flight control circuit. The flight control circuit is configured to communicate, through a first communication channel, with the application processing circuit to receive the processed primary image data and use the processed primary image data to control the UAV to perform a first function; and communicate, through a second communication channel, with the real-time sensing circuit to receive the processed secondary image data and use the processed secondary image data to control the UAV to perform a second function. The second function is different from the first function. The second communication channel is independent from the first communication channel."
SYSTEM AND METHOD FOR DRONE AND OBJECT CLASSIFICATION,https://lens.org/092-599-209-865-541,2020,"A method and system device provides a unique object identification process by obtaining information from one or more of radar signals, infrared signals, optical signals, audio signals, and other signals. The method includes continuously receiving object data at the device, applying by a machine learning system, a set of parameters to process the object identification and confidence level, and outputting or updating the object identification, confidence level, and actionable recommendations. The radar data includes a Doppler signature having a wrapped signal due to a sampling rate of the radar system. The Doppler signature is used to train the machine learning system to identify drone types."
SYSTEM AND METHOD FOR DRONE AND OBJECT CLASSIFICATION,https://lens.org/169-171-771-367-122,2020,"A method and system device provides a unique object identification process by obtaining information from one or more of radar signals, infrared signals, optical signals, audio signals, and other signals. The method includes continuously receiving object data at the device, applying by a machine learning system, a set of parameters to process the object identification and confidence level, and outputting or updating the object identification, confidence level, and actionable recommendations. The radar data includes a Doppler signature having a wrapped signal due to a sampling rate of the radar system. The Doppler signature is used to train the machine learning system to identify drone types."
Augmented reality ultrasound-control system for enabling remote direction of a user of ultrasound equipment by experienced practitioner,https://lens.org/194-395-956-160-709,2023,"A system for providing remote direction of a user of ultrasound equipment comprising a local apparatus comprising an ultrasound tool 14 and an augmented reality device 16 for capturing video 26, displaying an ultrasound image, and displaying directions to the user 38, fig 3, and a remote apparatus 28 for displaying the captured video and generating directions using a controller 30 wherein the remote apparatus provides the direction data to the augmented reality device. The ultrasound tool may be an ultrasound transducer and the augmented reality device may be a headset. The AR device may display a visual representation of the directional data and may further display a translucent rendering of the ultrasound transducer. The directional data may be rendered as path-lines or trajectory data representing a recommended path of travel. The controller may comprise trackable sensors or fiduciary markers. The system may utilise wireless internet protocol and may comprise portable computing devices such as a phone or tablet."
Augmented reality ultrasound-control system for enabling remote direction of a user of ultrasound equipment by experienced practitioner,https://lens.org/194-395-956-160-709,2023,"A system for providing remote direction of a user of ultrasound equipment comprising a local apparatus comprising an ultrasound tool 14 and an augmented reality device 16 for capturing video 26, displaying an ultrasound image, and displaying directions to the user 38, fig 3, and a remote apparatus 28 for displaying the captured video and generating directions using a controller 30 wherein the remote apparatus provides the direction data to the augmented reality device. The ultrasound tool may be an ultrasound transducer and the augmented reality device may be a headset. The AR device may display a visual representation of the directional data and may further display a translucent rendering of the ultrasound transducer. The directional data may be rendered as path-lines or trajectory data representing a recommended path of travel. The controller may comprise trackable sensors or fiduciary markers. The system may utilise wireless internet protocol and may comprise portable computing devices such as a phone or tablet."
"Device for controlling TV viewing, capable of bi-directional video calling",https://lens.org/026-690-508-473-98X,2021,"A device for controlling TV viewing, capable of bi-directional video calling, may: connect a TV and a smartphone via a communication network; transmit an image captured by an embedded camera to the smartphone; establish bi-directional TV video calling between the embedded camera, TV, and smartphone by displaying an image signal of the smartphone via the TV; control TV viewing by linking to the smartphone via the wireless communication network; and support video calling between the TV and smartphone via a simple button operation when the elderly, infirm, and children, young and old, who have difficulty using a separate communication means are in an emergency situation."
"Leveling instrument, an electromechanical lifter and a self leveling integrated lifting system using both of them",https://lens.org/193-327-186-858-21X,2007,"This self-leveling device is employed in the field of lifting of aircraft, helicopters, civil and military flying vehicles, watercraft, camping vehicles, trains, bridges, radar, etc., and for all those activities that require self-leveling and centring during lifting and lowering operations with fast results, without damages to the structure and in perfect safety (eg.: for helicopter lifting, for internal load balance, for safety during take-off and landing). The device is composed of a number of electromechanical lifting groups that operate synchronistically and autonomously from one another, linked with an electronic central general control for operation and a leveling cell. The whole system provides perfect self-leveling in case of unstable ground, for weighing and leveling purposes, targeting, weight balance, maintenance, etc."
Airborne bee eliminator of unmanned aerial vehicle,https://lens.org/002-649-165-370-819,2020,"The utility model discloses an airborne bee eliminator of an unmanned aerial vehicle. The system comprises an unmanned aerial vehicle, a remote controller, a sprayer, a camera and a controller, the remote controller is matched with the unmanned aerial vehicle through signals; the camera and the remote controller are matched with the controller through signals; wherein the camera and the sprayer are arranged on the unmanned aerial vehicle, the sprayer comprises a high-pressure pump, an adjusting spray pipe and a box body, the high-pressure pump is electrically connected with a control panel ofthe unmanned aerial vehicle, the remote controller can control starting and stopping of the high-pressure pump, the high-pressure pump communicates with the adjusting spray head and the box body, andthe box body is used for containing bee-killing pesticide liquid. Personal safety of operators is guaranteed to the maximum extent, wasps and the like can be removed quickly, accurately and efficiently without power failure, inconvenience and danger caused by manual pole climbing for removing foreign matter on a power transmission line pole tower are avoided, labor intensity of the operators is relieved, requirements for the operation environment are lowered, and the application range of the unmanned aerial vehicle is widened."
MODULAR UAV WITH MODULE IDENTIFICATION,https://lens.org/085-098-064-997-578,2018,"A modular unmanned aerial vehicle (UAV) can include a main body and one or more peripherals configured to be removably attached to the main body. The main body can be configured to identify the peripheral, such as through the provision of an identifying signal on the provisional. The processor can cause the UAV to execute a function based at least in part on the identification of the attached peripheral, or by user interaction with the peripheral or another component of the UAV."
Federated automated interoperation between premises and autonomous resources,https://lens.org/119-066-873-416-265,2022,"In some embodiments, the disclosed subject matter involves communication and negotiation between an autonomous entity or vehicle with a network of communication resources within a smart premises. The communication resources may include entry, landing or navigation beacons and a building infrastructure service. Negotiation for guidance, entry and other authorized tasks or services may be performed in a distributed fashion while en route or in proximity to a communication resource, rather than scheduled by a centralized server. Other embodiments are described and claimed."
FEDERATED AUTOMATED INTEROPERATION BETWEEN PREMISES AND AUTONOMOUS RESOURCES,https://lens.org/142-116-715-999-633,2019,"In some embodiments, the disclosed subject matter involves communication and negotiation between an autonomous entity or vehicle with a network of communication resources within a smart premises. The communication resources may include entry, landing or navigation beacons and a building infrastructure service. Negotiation for guidance, entry and other authorized tasks or services may be performed in a distributed fashion while en route or in proximity to a communication resource, rather than scheduled by a centralized server. Other embodiments are described and claimed."
MULTI-FACTOR AUTHENTICATION WITH GEOLOCATION AND VOICE COMMAND,https://lens.org/077-992-665-166-389,2020,"A method of multi-factor authentication is performed by an access control device. In response to detecting a voice command, the access control device sends a query to a location server for a current location of a user equipment (UE) included in a list of trusted UEs. The access control device may then receive an indication of the current location from the location server and in response thereto, the access control device may determine whether the current location of the UE is within a threshold distance of the access control device. If so, the access control device may generate an access signal that indicates that a user associated with the UE is authorized to access a protected resource."
Multi-factor authentication with geolocation and voice command,https://lens.org/010-286-484-536-986,2021,"A method of multi-factor authentication is performed by an access control device. In response to detecting a voice command, the access control device sends a query to a location server for a current location of a user equipment (UE) included in a list of trusted UEs. The access control device may then receive an indication of the current location from the location server and in response thereto, the access control device may determine whether the current location of the UE is within a threshold distance of the access control device. If so, the access control device may generate an access signal that indicates that a user associated with the UE is authorized to access a protected resource."
SYSTEMS AND METHODS FOR DISPATCHING AND NAVIGATING AN UNMANNED AERIAL VEHICLE,https://lens.org/073-487-731-320-952,2022,"A system for dispatching and navigating an unmanned aerial vehicle (UAV) to a target location comprises a UAV and a navigation module comprising a processor and a memory storing a 3D map comprising the target location and machine-readable instructions such that, when executed by the navigation module processor, cause the processor to perform a method comprising identifying a location of the UAV with respect to the 3D map, receiving a target location input, identifying the target location with respect to the 3D map, generating at least one potential route connecting the location of the UAV and the target location, assigning to at least one potential route an evaluation score according to at least one route assessment criterion, selecting the potential route having the highest evaluation score as a preferred route, and transmitting the preferred route to the UAV."
REMOTE CONTROL DEVICE,https://lens.org/035-488-628-567-929,1985,"A remote control device includes a transmitter (10) which is driven by a battery (E) and generates light or an ultrasonic signal, and a receiver (20) which teceives the light or the ultrasonic signal for generating a corresponding control signal. The light or the ultrasonic signal produced by the transmitter (10) is modulated in accordance with Barker series data representing the control signal. The light or the ultrasonic signal received by the receiver (20) is converted into an electric signal and is supplied to an autocorrelation function generating circuit (26)."
AUTONOMOUS VEHICLES AND METHODS OF USING SAME,https://lens.org/137-425-154-372-926,2019,"An autonomous vehicle and methods of using same is disclosed. The vehicle includes one or more sensors (102, 103, 104, 105, 106) arranged on at least one of a dashboard (110), a roof (112), and a center console of the vehicle, or one or more image capturing devices (6) for capturing one or more images from a left side and a right side of the vehicle. The vehicle may also include an electronic control unit (ECU) (220) configured to communicate with the one or more sensors (102, 103, 104, 105, 106) or the one or more image capturing devices (6), and at least one of a morphing surface (236), a windshield display, and one or more displays (1, 2, 3, 4, 5, 900) configured to be controlled by the ECU (220)."
AUTONOMOUS VEHICLES AND METHODS OF USING SAME,https://lens.org/194-556-416-989-756,2019,"An autonomous vehicle and methods of using same is disclosed. The vehicle includes one or more sensors (102, 103, 104, 105, 106) arranged on at least one of a dashboard (110), a roof (112), and a center console of the vehicle, or one or more image capturing devices (6) for capturing one or more images from a left side and a right side of the vehicle. The vehicle may also include an electronic control unit (ECU) (220) configured to communicate with the one or more sensors (102, 103, 104, 105, 106) or the one or more image capturing devices (6), and at least one of a morphing surface (236), a windshield display, and one or more displays (1, 2, 3, 4, 5, 900) configured to be controlled by the ECU (220)."
"DOORBELL, KEY MANAGEMENT SYSTEM, AND INTERCOM SYSTEM",https://lens.org/023-076-954-595-275,2021,"A doorbell (2) includes an operation unit (22) capable of performing a calling operation, a camera (26), a microphone (23), a speaker (24), and a control unit (21) connected to the operation unit (22), the camera (26), the microphone (23) and the speaker (24) and capable of performing direct or indirect communication with an external device in which delivery item information relating to a delivery item is recorded. The control unit (21) is configured to acquire the delivery item information from the external device, and based on the delivery item information, to transmit a delivery notification of the delivery item to an information terminal (3) associated with a resident of a residence to which the doorbell (2) is attached."
"DOORBELL, KEY MANAGEMENT SYSTEM, AND INTERCOM SYSTEM",https://lens.org/166-775-542-916-894,2020,"A doorbell (2) includes an operation unit (22) capable of performing a calling operation, a camera (26), a microphone (23), a speaker (24), and a control unit (21) connected to the operation unit (22), the camera (26), the microphone (23) and the speaker (24) and capable of performing direct or indirect communication with an external device in which delivery item information relating to a delivery item is recorded. The control unit (21) is configured to acquire the delivery item information from the external device, and based on the delivery item information, to transmit a delivery notification of the delivery item to an information terminal (3) associated with a resident of a residence to which the doorbell (2) is attached."
METHODS AND DEVICES FOR AUTONOMOUS VEHICLE OPERATION,https://lens.org/174-462-338-955-354,2019,"A device for controlling an autonomous vehicle includes a processor and a memory including instructions that, when executed by the processor, cause the processor to detect that the autonomous vehicle has one or more malfunctioning components and to determine, in response to the detection, a likelihood that the autonomous vehicle is able to reach a desired stop location based on one or more factors associated with the one or more malfunctioning components. The device determines at least one maneuver for the autonomous vehicle based on the likelihood, and causes the autonomous vehicle to perform the at least one maneuver."
DRONE COLLISION AVOIDANCE SYSTEM,https://lens.org/158-402-765-353-88X,2019,"The invention is a device that when fitted to an aircraft (1) projects a signal before the aircraft on a frequency or a range of frequencies used for recreational unmanned flying vehicles or drones (3). The projection angle and strength of the signal from the aircraft would vary depending on each aircraft type and size and would temporarily override any control of any drone that flew into the signal area (2). Depending on the proximity of the drone to the aircraft, the signal would tell the drone to ascend or descend (3) allowing the aircraft to pass safely thereby avoiding the risk of collision."
Communication device and method of providing location information therein,https://lens.org/086-377-995-843-09X,2010,"A communication device, computer program product and method of providing location information therein are disclosed. The communication device includes a wireless communication unit and a controller connected to the wireless communication unit and configured to share device location information with another communication device, the controller further configured to hierarchically set a device location resolution level to be shared with the another communication device.
"
COMMUNICATION DEVICE AND METHOD OF PROVIDING LOCATION INFORMATION THEREIN,https://lens.org/141-208-811-662-303,2014,"A communication device, computer program product and method of providing location information therein are disclosed. The communication device includes a wireless communication unit and a controller connected to the wireless communication unit and configured to share device location information with another communication device, the controller further configured to hierarchically set a device location resolution level to be shared with the another communication device."
Communication device and method of providing location information therein,https://lens.org/123-310-879-595-862,2009,"A communication device, computer program product and method of providing location information therein are disclosed. The communication device includes a wireless communication unit and a controller connected to the wireless communication unit and configured to share device location information with another communication device, the controller further configured to hierarchically set a device location resolution level to be shared with the another communication device."
COMMUNICATION DEVICE AND METHOD OF PROVIDING LOCATION INFORMATION THEREIN,https://lens.org/162-060-590-281-681,2009,"A communication device, computer program product and method of providing location information therein are disclosed. The communication device includes a wireless communication unit and a controller connected to the wireless communication unit and configured to share device location information with another communication device, the controller further configured to hierarchically set a device location resolution level to be shared with the another communication device."
Methods and Apparatus for Unmanned Aerial Vehicle Autonomous Aviation,https://lens.org/071-388-730-850-584,2016,"In some embodiments, an Unmanned Aerial Vehicle (UAV) is configured to navigate to a first location point from a plurality of location points. The plurality of location points defines a flight pattern. The UAV is further configured to receive a set of location coordinates of a moving object. The UAV is configured to determine the distance between the moving object and the UAV based on the set of location coordinates of the moving object and the first location point of the UAV. When the distance between the moving object and the UAV reaches a pre-determined threshold, the UAV is configured to advance to a second location point from the plurality of location points."
Method and vehicle system for remote-controlling vehicle audio system,https://lens.org/009-779-893-285-700,2004,"A method for remotely controlling a vehicle audio system, which is controlled in accordance with an instruction from an infrared remote control unit, uses a radio frequency remote control unit to remotely control the vehicle audio system. A security system receives a command transmitted from the radio frequency remote control unit. In a security control mode, the vehicle security system performs security control based on the command. In an audio control mode, the security system transmits the command to an audio control interface unit. The audio control interface unit converts the command transmitted from the security system into an infrared remote control unit command. Based on the infrared remote control unit command, an infrared emitter is driven to emit infrared rays, thus controlling the vehicle audio system by the infrared rays."
MULTIFUNCTION AUTOMATIC VIDEO RECORDING DEVICE,https://lens.org/000-641-236-625-825,2013,"The automatic video recording systems disclosed comprise a remote device associated with a recorded subject, is waterproof and shockproof, assists in orienting a recording camera at the subject, senses voice commands, and records sound and the voice of the subject. The apparatus may be built using various degrees of integration of its components. The related methods hereof include automatically adjusting the focus and zoom of the camera depending on the location and velocity of the subject."
Waterproof Electronic Device,https://lens.org/067-948-602-729-892,2017,"The automatic video recording systems disclosed comprise a remote device associated with a recorded subject, is waterproof and shockproof, assists in orienting a recording camera at the subject, senses voice commands, and records sound and the voice of the subject. The apparatus may be built using various degrees of integration of its components. The related methods hereof include automatically adjusting the focus and zoom of the camera depending on the location and velocity of the subject."
Enhancements to mechanical robot,https://lens.org/078-093-974-395-836,2013,"A mechanical robot can have a GPS receiver for localization, to enable it to navigate and/or perform location-specific functions. Also, the robot can be caused to ambulate in a location, taking pictures of guests and/or sounding an alarm if an unknown person is imaged by a camera on the robot. Further, the robot can be given a voice message for a recipient, and then ambulate around until, using face or voice recognition, it recognizes the intended recipient and delivers the message, e.g., aurally using a speaker."
Enhancements to mechanical robot,https://lens.org/133-977-258-417-842,2006,"A mechanical robot can have a GPS receiver for localization, to enable it to navigate and/or perform location-specific functions. Also, the robot can be caused to ambulate in a location, taking pictures of guests and/or sounding an alarm if an unknown person is imaged by a camera on the robot. Further, the robot can be given a voice message for a recipient, and then ambulate around until, using face or voice recognition, it recognizes the intended recipient and delivers the message, e.g., aurally using a speaker."
User interface with position awareness,https://lens.org/111-940-603-497-760,2016,A remote control device (100) for controlling lighting systems includes a sensor (155) configured to determine a location of the remote control device (100) in relation to the lighting systems (115). A controller (145) is configured to determine a nearest light source (120) of the lighting systems (115) relative to the location of the remote control device (100) and to control this nearest light source (120). The controller (145) is configured to change a configuration of the remote control device (100) in response to changing its location. A transceiver (105) transmit a signal to multiple light sources (120) which measure the strength and/or time of flight of this signal for use in determining the location of the remote control device (100). The light sources (120) provide the remote control device (100) with identifying information unique to each one of them including their locations.
User Interface with Position Awareness,https://lens.org/043-476-466-362-876,2009,A remote control device (100) for controlling lighting systems includes a sensor (155) configured to determine a location of the remote control device (100) in relation to the lighting systems (115). A controller (145) is configured to determine a nearest light source (120) of the lighting systems (115) relative to the location of the remote control device (100) and to control this nearest light source (120). The controller (145) is configured to change a configuration of the remote control device (100) in response to changing its location. A transceiver (105) transmit a signal to multiple light sources (120) which measure the strength and/or time of flight of this signal for use in determining the location of the remote control device (100). The light sources (120) provide the remote control device (100) with identifying information unique to each one of them including their locations.
System And Method For Manipulating An Anatomy,https://lens.org/020-612-910-884-929,2019,"A system includes a robotic manipulator comprising an arm and an end effector coupled to the arm and being moveable by the arm for interacting with a target site in a manual mode and an autonomous mode of operation. A navigation system is configured to track a position of the end effector and the target site. One or more controllers are configured to define a first virtual boundary relative to the target site, prevent the end effector from penetrating the first virtual boundary in the manual mode, and allow the end effector to penetrate the first virtual boundary in the autonomous mode."
System and method for manipulating an anatomy,https://lens.org/068-829-925-140-390,2020,"A system includes a robotic manipulator comprising an arm and an end effector coupled to the arm and being moveable by the arm for interacting with a target site in a manual mode and an autonomous mode of operation. A navigation system is configured to track a position of the end effector and the target site. One or more controllers are configured to define a first virtual boundary relative to the target site, prevent the end effector from penetrating the first virtual boundary in the manual mode, and allow the end effector to penetrate the first virtual boundary in the autonomous mode."
Automatic guidance unit for aerial delivery unit,https://lens.org/137-866-128-135-867,2003,"Methods and systems for programming the automatic guidance unit of an aerial delivery system. The operator selects on a hand-held unit the desired flight parameters such as the latitude, longitude and altitude of the desired landing site, as well as the desired landing heading and default heading. A microprocessor converts this data into digital data that is stored on a removable EEPROM memory key. This key is then removed from the hand-held unit and at any convenient time, inserted into a mating female receptacle in the automatic guidance unit of the aerial delivery system. The programmed information originally entered in the hand-held unit is then transferred into the guidance unit of the aerial delivery system."
WIRELESS REMOTE CONTROLLED MIRROR WITH INTEGRAL LIGHTING,https://lens.org/047-924-963-718-628,2004,"A wireless remote controlled mirror (10) having lights (216) to illuminate a subject being viewed in the mirror, while enabling a user to selectively adjust a view of the subject from a remote location. When attached to a rear seat of a vehicle via a mirror base (192), the mirror can be remotely adjusted to view a child in a rear-facing safety seat."
Autonomous underwater vehicle for marine seismic surveys,https://lens.org/050-759-605-165-762,2017,"An autonomous underwater vehicle (AUV) for recording seismic signals during a marine seismic survey. The AUV includes a body extending along an axis X and having a head portion, a middle portion, and a tail portion, wherein the middle portion is sandwiched between the head portion and the tail portion along the X axis; a cross-section of the middle portion, substantially perpendicular on the X axis, having a triangular-like shape; the head portion including a base portion having the triangular-like shape and configured to match the middle portion; the head portion having a tip that, when projected along the X axis on the base portion, substantially coincides with a centroid of the base portion having the triangular-like shape; and a seismic payload located within the body and configured to record seismic signals."
AUTONOMOUS UNDERWATER VEHICLE FOR MARINE SEISMIC SURVEYS,https://lens.org/121-192-938-805-202,2014,"An autonomous underwater vehicle (AUV) for recording seismic signals during a marine seismic survey. The AUV includes a body extending along an axis X and having a head portion, a middle portion, and a tail portion, wherein the middle portion is sandwiched between the head portion and the tail portion along the X axis; a cross-section of the middle portion, substantially perpendicular on the X axis, having a triangular-like shape; the head portion including a base portion having the triangular-like shape and configured to match the middle portion; the head portion having a tip that, when projected along the X axis on the base portion, substantially coincides with a centroid of the base portion having the triangular-like shape; and a seismic payload located within the body and configured to record seismic signals."
Remote interaction device,https://lens.org/174-244-384-901-765,2017,"Systems, devices, and methods are provided for remote interaction with a subject in an environment. The device has audio-visual recording and transmitting functionality to provide an operator at a remote location with an audio-visual feed of the environment near the device. The device also has a light emission component which the operator controls and which projects light onto a surface in the environment in the vicinity of the device. The systems, devices, and methods provide operators with the ability to interact with pets and provide exercise and stimulation to pets when their owners are away."
REMOTE INTERACTION DEVICE,https://lens.org/136-586-784-739-180,2018,"Systems, devices, and methods are provided for remote interaction with a subject in an environment. The device has audio-visual recording and transmitting functionality to provide an operator at a remote location with an audio-visual feed of the environment near the device. The device also has a light emission component which the operator controls and which projects light onto a surface in the environment in the vicinity of the device. The systems, devices, and methods provide operators with the ability to interact with pets and provide exercise and stimulation to pets when their owners are away."
REMOTE INTERACTION DEVICE,https://lens.org/076-917-811-733-796,2019,"Systems, devices, and methods are provided for remote interaction with a subject in an environment. The device has audio-visual recording and transmitting functionality to provide an operator at a remote location with an audio-visual feed of the environment near the device. The device also has a light emission component which the operator controls and which projects light onto a surface in the environment in the vicinity of the device. The systems, devices, and methods provide operators with the ability to interact with pets and provide exercise and stimulation to pets when their owners are away."
Remote interaction device,https://lens.org/151-336-323-090-464,2017,"Systems, devices, and methods are provided for remote interaction with a subject in an environment. The device has audio-visual recording and transmitting functionality to provide an operator at a remote location with an audio-visual feed of the environment near the device. The device also has a light emission component which the operator controls and which projects light onto a surface in the environment in the vicinity of the device. The systems, devices, and methods provide operators with the ability to interact with pets and provide exercise and stimulation to pets when their owners are away."
Remote interaction device,https://lens.org/156-129-159-790-433,2015,"Systems, devices, and methods are provided for remote interaction with a subject in an environment. The device has audio-visual recording and transmitting functionality to provide an operator at a remote location with an audio-visual feed of the environment near the device. The device also has a light emission component which the operator controls and which projects light onto a surface in the environment in the vicinity of the device. The systems, devices, and methods provide operators with the ability to interact with pets and provide exercise and stimulation to pets when their owners are away."
Remote interaction device,https://lens.org/193-901-127-371-093,2019,"Systems, devices, and methods are provided for remote interaction with a subject in an environment. The device has audio-visual recording and transmitting functionality to provide an operator at a remote location with an audio-visual feed of the environment near the device. The device also has a light emission component which the operator controls and which projects light onto a surface in the environment in the vicinity of the device. The systems, devices, and methods provide operators with the ability to interact with pets and provide exercise and stimulation to pets when their owners are away."
REMOTE INTERACTION DEVICE,https://lens.org/115-236-302-486-036,2014,"Systems, devices, and methods are provided for remote interaction with a subject in an environment. The device has audio-visual recording and transmitting functionality to provide an operator at a remote location with an audio-visual feed of the environment near the device. The device also has a light emission component which the operator controls and which projects light onto a surface in the environment in the vicinity of the device. The systems, devices, and methods provide operators with the ability to interact with pets and provide exercise and stimulation to pets when their owners are away."
ROBOT AND AUDIO DATA PROCESSING METHOD THEREOF,https://lens.org/164-937-474-481-505,2020,"The present disclosure provides a robot and an audio data processing method thereof. The robot includes a body, a main control module, and a sound pickup module. The sound pickup module includes microphones divided into a first microphone array and a second microphone array; the first microphone array includes N microphones disposed around the body; the second microphone array includes M microphones disposed on the body and located on a line connecting two of the microphones in the first microphone array; the main control module is configured to obtain N channels of audio data through the first microphone array, obtain M channels of audio data through the second microphone array, and perform a sound source localization and a sound pickup based on the N channels of audio data and the M channels of audio data."
Robot and audio data processing method thereof,https://lens.org/066-971-274-217-968,2020,"The present disclosure provides a robot and an audio data processing method thereof. The robot includes a body, a main control module, and a sound pickup module. The sound pickup module includes microphones divided into a first microphone array and a second microphone array; the first microphone array includes N microphones disposed around the body; the second microphone array includes M microphones disposed on the body and located on a line connecting two of the microphones in the first microphone array; the main control module is configured to obtain N channels of audio data through the first microphone array, obtain M channels of audio data through the second microphone array, and perform a sound source localization and a sound pickup based on the N channels of audio data and the M channels of audio data."
REMOTE CONTROL TRANSMITTER,https://lens.org/016-157-183-567-129,2007,"A remote control transmitter is capable of performing remote control reliably with an inexpensive structure, in which a light-emitting element having an approximately bombshell-shaped translucent body including translucent resin and a lighting element main body incorporated in the rear part of the translucent body are provided in the front surface of a remote controller main body. The light-emitting element emits a light beam with a signal superimposed thereon when an operation part on the remote controller main body is operated, and an angle widening unit for widening the projection angle of the light beam emitted from the light-emitting element on the optical axis of the light beam is provided. The angle widening unit includes an inwardly tapered hole recessed in the front surface of the translucent body and a half mirror formed on the inner peripheral surface of the tapered hole, in which the angle widening unit reflects the light beam at the half mirror in order to widen the projection angle of the light beam."
"Control unit, a video device including said control unit, and a control method",https://lens.org/165-140-746-082-822,2009,"The present invention discloses a control unit, a video device employing said control unit and a control method thereof, wherein the control unit includes: a recognition device which is used to recognize the target in the target image; a calculation device which is used to calculate and transform the position coordinate of the recognized imaging target from the recognition device and output the position of the operation unit."
"Control unit, a video device including said control unit, and a control method",https://lens.org/140-028-499-180-005,2013,"The present invention discloses a control unit, a video device employing said control unit and a control method thereof, wherein the control unit includes: a recognition device which is used to recognize the target in the target image; a calculation device which is used to calculate and transform the position coordinate of the recognized imaging target from the recognition device and output the position of the operation unit."
Remote control device.,https://lens.org/154-833-212-727-035,1983,"A remote control device includes a transmitter (10) which is driven by a battery (E) and generates light or an ultrasonic signal, and a receiver (20) which receives the light or the ultrasonic signal for generating a corresponding control signal. The light or the ultrasonic signal produced by the transmitter (10) is modulated in accordance with Barker series data representing the control signal. The light or the ultrasonic signal received by the receiver (20) is converted into an electric signal and is supplied to an autocorrelation function generating circuit (26)."
Remote Aerodrome for UAVs,https://lens.org/142-525-135-633-296,2017,"An Aerodrome providing safe storage for Unmanned Aerial Vehicles (UAVs) that includes an enclosure to protect UAVs from the elements (weather). The Aerodrome includes an enclosure, a foldable flight deck, a service interface, and a telescoping video and audio feed unit. The aerodrome can be remotely operated, and can be mounted on a roof of a structure or vehicle, allowing a completely automated service of the UAV without the need of a person being physically present in the vicinity of the UAV."
REMOTE AERODROME FOR UAVS,https://lens.org/008-368-696-307-111,2018,"An Aerodrome providing safe storage for Unmanned Aerial Vehicles (UAVs) that includes an enclosure to protect UAVs from the elements (weather). The Aerodrome includes an enclosure, a foldable flight deck, a service interface, and a telescoping video and audio feed unit. The aerodrome can be remotely operated, and can be mounted on a roof of a structure or vehicle, allowing a completely automated service of the UAV without the need of a person being physically present in the vicinity of the UAV."
Accessibility remote control for the blind,https://lens.org/097-581-359-113-739,2019,"A remotely controlled device receives a first command from a remote control (RC) but does not execute the command. Instead, the remotely controlled device waits to receive the first command within a threshold period, and if not received twice within the period, the first command is then executed. However, the first command is not executed if it is received twice, at which point the name of the corresponding RC key is announced. A second double command caused by a second double press of the same key on the RC causes the remotely controlled device to announce the function of the key. The logic may be executed in the RC as well as or in lieu of executing it in the remotely controlled device."
Accessibility remote control for the blind,https://lens.org/033-511-817-195-562,2018,"A remotely controlled device receives a first command from a remote control (RC) but does not execute the command. Instead, the remotely controlled device waits to receive the first command within a threshold period, and if not received twice within the period, the first command is then executed. However, the first command is not executed if it is received twice, at which point the name of the corresponding RC key is announced. A second double command caused by a second double press of the same key on the RC causes the remotely controlled device to announce the function of the key. The logic may be executed in the RC as well as or in lieu of executing it in the remotely controlled device."
SYSTEM AND METHOD FOR PROVIDING AUTONOMOUS PHOTOGRAPHY AND VIDEOGRAPHY,https://lens.org/110-213-621-961-961,2019,"An aerial system, including a processing system, an optical system, an actuation system and a lift mechanism, includes an autonomous photography and/or videography system 70, implemented, at least in part, by the processing system 22, the optical system 26, the actuation system 28 and the lift mechanism 32. The autonomous photograph and/or videography system performs the steps of establishing a desired flight trajectory, detecting a target, controlling the flight of the aerial system as a function of the desired flight trajectory relative to the target using the lift mechanism and controlling the camera to capture pictures and/or video."
SYSTEM AND METHOD FOR PROVIDING AUTONOMOUS PHOTOGRAPHY AND VIDEOGRAPHY,https://lens.org/122-399-914-023-841,2018,"An aerial system, including a processing system, an optical system, an actuation system and a lift mechanism, includes an autonomous photography and/or videography system 70, implemented, at least in part, by the processing system 22, the optical system 26, the actuation system 28 and the lift mechanism 32. The autonomous photograph and/or videography system performs the steps of establishing a desired flight trajectory, detecting a target, controlling the flight of the aerial system as a function of the desired flight trajectory relative to the target using the lift mechanism and controlling the camera to capture pictures and/or video."
System and method for providing autonomous photography and videography,https://lens.org/030-363-820-336-222,2019,"An aerial system, including a processing system, an optical system, an actuation system and a lift mechanism, includes an autonomous photography and/or videography system 70, implemented, at least in part, by the processing system 22, the optical system 26, the actuation system 28 and the lift mechanism 32. The autonomous photograph and/or videography system performs the steps of establishing a desired flight trajectory, detecting a target, controlling the flight of the aerial system as a function of the desired flight trajectory relative to the target using the lift mechanism and controlling the camera to capture pictures and/or video."
SYSTEM AND METHOD FOR PROVIDING AUTONOMOUS PHOTOGRAPHY AND VIDEOGRAPHY,https://lens.org/087-595-243-328-521,2021,"An aerial system, including a processing system, an optical system, an actuation system and a lift mechanism, includes an autonomous photography and/or videography system 70, implemented, at least in part, by the processing system 22, the optical system 26, the actuation system 28 and the lift mechanism 32. The autonomous photograph and/or videography system performs the steps of establishing a desired flight trajectory, detecting a target, controlling the flight of the aerial system as a function of the desired flight trajectory relative to the target using the lift mechanism and controlling the camera to capture pictures and/or video."
System and method for providing autonomous photography and videography,https://lens.org/162-440-271-643-766,2021,"An aerial system, including a processing system, an optical system, an actuation system and a lift mechanism, includes an autonomous photography and/or videography system 70, implemented, at least in part, by the processing system 22, the optical system 26, the actuation system 28 and the lift mechanism 32. The autonomous photograph and/or videography system performs the steps of establishing a desired flight trajectory, detecting a target, controlling the flight of the aerial system as a function of the desired flight trajectory relative to the target using the lift mechanism and controlling the camera to capture pictures and/or video."
WIRELESS ULTRASOUND PROBE ADAPTER,https://lens.org/146-282-558-244-294,2017,"An ultrasound wireless probe adapter is presented. The adapter includes a first coupling unit configured to detachably couple the adapter to ultrasound probe assemblies, a second coupling unit configured to wirelessly couple the adapter to a smart device, and a microcontroller. The microcontroller is configured to wirelessly communicate with the smart device to accept user inputs, generate and transmit one of excitation signals and control and configuration signals to the ultrasound probe assemblies based on the user inputs and a category of the ultrasound probe assemblies to initiate emission of acoustic signals towards a region of interest in a subject, receive echo signals generated by the ultrasound probe assemblies in response to one of the transmitted excitation signals or the transmitted control and configuration signals, and process received beam signals based on a processing capability of the smart device to generate one of partially-processed image data and fully-processed image data."
System and method using image analysis for controlling a flight path of a surface inspection unmanned aerial vehicle,https://lens.org/163-192-793-865-610,2023,"Provided are a computer system and method using image analysis for controlling a flight path of a surface inspection unmanned aerial vehicle, wherein the computer system is configured to: acquire an image captured by a drone; perform image analysis on the acquired image; extract, in a result of the image analysis, a point whose an edge variation amount is equal to or greater than a predetermined threshold; acquire a position coordinate of the extracted point; in a case where there are a plurality of points, set a flight path of the drone in a manner of flying in an order of edge variation amounts of the plurality of points from large to small; and control the drone to fly towards the acquired position coordinate and perform capturing with a camera using light other than visible light."
Position-based control of unmanned aerial vehicles,https://lens.org/052-699-695-125-81X,2021,"The position of a UAV within a three-dimensional space is changed based on a change in position of a controller of the UAV. First and second sensor data are produced using sensors of the controller to maintain stable altitude output for the UAV. The first sensor data indicates a geolocation of the controller, and the second sensor data indicates a barometric pressure of an environment in which the controller is located. The first and second sensor data are post-processed using a complementary filter based on respective altitude measurements of the first and second sensor data to determine an altitude of the controller. A position of the controller is determined within a three-dimensional space based on the altitude. Data indicative of the position of the controller within the three-dimensional space is then transmitted to the UAV to cause a change in a position of the UAV within the three-dimensional space."
POSITION-BASED CONTROL OF UNMANNED AERIAL VEHICLES,https://lens.org/194-626-041-483-660,2019,"The position of a UAV within a three-dimensional space is changed based on a change in position of a controller of the UAV. First and second sensor data are produced using sensors of the controller to maintain stable altitude output for the UAV. The first sensor data indicates a geolocation of the controller, and the second sensor data indicates a barometric pressure of an environment in which the controller is located. The first and second sensor data are post-processed using a complementary filter based on respective altitude measurements of the first and second sensor data to determine an altitude of the controller. A position of the controller is determined within a three-dimensional space based on the altitude. Data indicative of the position of the controller within the three-dimensional space is then transmitted to the UAV to cause a change in a position of the UAV within the three-dimensional space."
POSITION-BASED CONTROL OF UNMANNED AERIAL VEHICLES,https://lens.org/039-699-612-975-237,2022,"The position of a UAV within a three-dimensional space is changed based on a change in position of a controller of the UAV. First and second sensor data are produced using sensors of the controller to maintain stable altitude output for the UAV. The first sensor data indicates a geolocation of the controller, and the second sensor data indicates a barometric pressure of an environment in which the controller is located. The first and second sensor data are post-processed using a complementary filter based on respective altitude measurements of the first and second sensor data to determine an altitude of the controller. A position of the controller is determined within a three-dimensional space based on the altitude. Data indicative of the position of the controller within the three-dimensional space is then transmitted to the UAV to cause a change in a position of the UAV within the three-dimensional space."
"Reverse propulsion aerial gaming systems, methods, and devices",https://lens.org/009-988-761-142-098,2018,"An optical-based aerial gaming system comprises: a multirotor unmanned flying device comprising: a main body; a plurality of propulsion units, a wireless receiver configured to receive data via radio communication; a wireless transmitter configured to send data via radio communication; one or more light generators configured to project laser or infrared light from the unmanned flying device; and one or more light sensors configured to detect laser or infrared light projected by a separate unmanned flying device; and a remote control unit comprising: a wireless transmitter configured to send data via radio communication; and a wireless receiver configured to receive data via radio communication, wherein the unmanned flying device is configured to transmit to the remote control unit, using the wireless transmitter of the unmanned flying device, at least a portion of encoded data of the detected laser or infrared light."
"REVERSE PROPULSION AERIAL GAMING SYSTEMS, METHODS, AND DEVICES",https://lens.org/107-667-604-434-527,2017,"An optical-based aerial gaming system comprises: a multirotor unmanned flying device comprising: a main body; a plurality of propulsion units, a wireless receiver configured to receive data via radio communication; a wireless transmitter configured to send data via radio communication; one or more light generators configured to project laser or infrared light from the unmanned flying device; and one or more light sensors configured to detect laser or infrared light projected by a separate unmanned flying device; and a remote control unit comprising: a wireless transmitter configured to send data via radio communication; and a wireless receiver configured to receive data via radio communication, wherein the unmanned flying device is configured to transmit to the remote control unit, using the wireless transmitter of the unmanned flying device, at least a portion of encoded data of the detected laser or infrared light."
"REVERSE PROPULSION AERIAL GAMING SYSTEMS, METHODS, AND DEVICES",https://lens.org/074-187-344-875-829,2018,"An optical-based aerial gaming system comprises: a multirotor unmanned flying device comprising: a main body; a plurality of propulsion units, a wireless receiver configured to receive data via radio communication; a wireless transmitter configured to send data via radio communication; one or more light generators configured to project laser or infrared light from the unmanned flying device; and one or more light sensors configured to detect laser or infrared light projected by a separate unmanned flying device; and a remote control unit comprising: a wireless transmitter configured to send data via radio communication; and a wireless receiver configured to receive data via radio communication, wherein the unmanned flying device is configured to transmit to the remote control unit, using the wireless transmitter of the unmanned flying device, at least a portion of encoded data of the detected laser or infrared light."
OPTICAL-BASED AERIAL GAMING SYSTEMS,https://lens.org/049-813-666-558-796,2018,"An optical-based aerial gaming system comprises: a multirotor unmanned flying device comprising: a main body; a plurality of propulsion units, a wireless receiver configured to receive data via radio communication; a wireless transmitter configured to send data via radio communication; one or more light generators configured to project laser or infrared light from the unmanned flying device; and one or more light sensors configured to detect laser or infrared light projected by a separate unmanned flying device; and a remote control unit comprising: a wireless transmitter configured to send data via radio communication; and a wireless receiver configured to receive data via radio communication, wherein the unmanned flying device is configured to transmit to the remote control unit, using the wireless transmitter of the unmanned flying device, at least a portion of encoded data of the detected laser or infrared light."
SYSTEMS AND METHODS FOR OBSTACLE AVOIDANCE FOR UNMANNED AUTONOMOUS VEHICLES,https://lens.org/015-659-415-314-010,2023,"Collision avoidance is an important issue for unmanned autonomous vehicles (UAVs). As such, UAVs can be outfitted with a simple and inexpensive sensor for use in collision avoidance. The sensor can be attached to a gimbal and can include a RADAR transmit antenna, a RADAR receive antenna, and an optical camera. The RADAR transmit antenna and RADAR receive antenna are part of a RADAR system. The optical camera and the RADAR system are bore sighted to one another by aligning their fields of view. The optical camera captures an image of a target when the RADAR system indicates the target is in the field of view. The RADAR system and image data can be used to determine a target trajectory. The target trajectory can be used to avoid a collision with the target."
PROJECTILE LAUNCHED UAV RECONNAISSANCE SYSTEM AND METHOD,https://lens.org/114-145-301-449-110,2016,"A method, system and computer readable medium for projectile launched UAV reconnaissance/surveillance are described. The method can include determining a designated target. The method can also include estimating a distance and trajectory from a launch point to the target and communicating distance and trajectory information to a launcher, a projectile and a communication and control system. The method can also include firing a separation charge when the UAV projectile reaches a predetermined point along the flight path, the separation charge being configured to separate a UAV from a projectile casing. The method can further include deploying the UAV and activating a propulsion system of the UAV and obtaining signals via one or more sensors."
DCAS - Drone Collision and Avoidance system,https://lens.org/168-449-692-745-380,2017,"The invention is a device that when fitted to an aircraft (1) projects a signal before the aircraft on a frequency or a range of frequencies used for recreational unmanned flying vehicles or drones (3). The projection angle and strength of the signal from the aircraft would vary depending on each aircraft type and size and would temporarily override any control of any drone that flew into the signal area (2). Depending on the proximity of the drone to the aircraft, the signal would tell the drone to ascend or descend (3) allowing the aircraft to pass safely thereby avoiding the risk of collision. Figure 1"
INVERTIBLE DRONE FOR SELECTIVE POWER CAPTURE,https://lens.org/021-144-502-507-464,2019,Various embodiments include methods for operating a photovoltaic- powered drone (101) having a photovoltaic surface (110) on one side of at least one of wing (106) and/or body (102) of the drone (101). Various embodiments may include flying the drone (101) in a first drone attitude that directs the photovoltaic surface (110) on the one side of the drone to face in a first direction toward a first source of light (9). Various embodiments may also include inverting the drone in flight to a second drone attitude that directs the photovoltaic surface (110) toward a second direction toward a second source of light (66) different from the first source of light (9). The artificial light may be transmitted from a ground-based beam emitter (60).
Vehicle antenna control system and method,https://lens.org/154-191-779-795-096,2018,"A control system and method is provided for raising and lowering a vehicle antenna. The control system includes a location receiver for generating vehicle location data, an obstacle detection unit which generates an obstacle signal, an antenna, an antenna motor for raising and lowering the antenna and a control unit. The control unit controls the antenna motor as a function of the vehicle location data and the obstacle signal. The control unit compares the vehicle location signal to stored or received geofencing information defining a geofenced area, and causes the antenna motor to raise the antenna when the vehicle location corresponding to the vehicle location data is inside the geofenced area and no obstacle is detected. The control unit causes the antenna motor to lower the antenna when the vehicle location corresponding to the vehicle location data is outside the geofenced area or if an obstacle is detected."
REMOTE CONTROL DEVICE,https://lens.org/131-221-389-044-457,2018,"There is provided a small remote control device for an actuator of a mobile crane that can be operated by one hand and with which it is easy to perform operations specific to large cranes, the remote control device being provided with: a device body; a plurality of selectors which are each disposed on an operation surface, and which set the operating direction of the actuator selected by movement in a first direction or a section direction from a neutral position to a forward direction or a reverse direction; and a trigger which moves the actuator selected by the selectors in the forward direction or the reverse direction according to the operation amount. Of the plurality of selectors, the two selectors, which are most frequently used in a work preparation step for the mobile crane are disposed adjacent to the vicinity of the center of the operation surface."
SPORTING CAMERA,https://lens.org/116-199-002-255-881,2016,"An apparatus is provided for providing a camera unit for use in close proximity to a sporting event. The apparatus includes a sideline marking structure including a camera device and a computerized controller in wireless communication with a remote system. The sideline marking structure can include sideline markers in football, baseball, or soccer."
UNMANNED AERIAL VEHICLE AND METHOD FOR ASSEMBLING UNMANNED AERIAL VEHICLE,https://lens.org/166-632-093-188-482,2020,An unmanned aerial vehicle (UAV) includes an aircraft body and a rotor assembly mounted on the aircraft body. The UAV also includes a barometer disposed external to the aircraft body and separated from the rotor assembly at a predetermined distance.
Unmanned aerial vehicle image processing system and method,https://lens.org/171-056-791-409-391,2016,"An unmanned aerial vehicle image processing system includes a digital camera mounted on an unmanned aerial vehicle, an autopilot controller installed in the unmanned aerial vehicle and pre-loaded with a base image, and a computer device. The autopilot controller programs a flight path as a series of mission lags to cover a target polygon on the base image in a lawnmower pattern for controlling the unmanned aerial vehicle to perform a flight mission in which the autopilot controller records plural GPS/INS data and triggers the digital camera to take plural photos which are further calibrated to generate plural calibrated photos corresponding to the plural GPS/INS data, respectively. The computer device processes the plural calibrated photos to generate plural projected photos by using the corresponding plural GPS/INS data, respectively, and stitches the plural projected photos to a mosaic image by a photo-stitching process."
UNMANNED AERIAL VEHICLE IMAGE PROCESSING SYSTEM AND METHOD,https://lens.org/063-094-582-324-975,2012,"An unmanned aerial vehicle image processing system includes a digital camera mounted on an unmanned aerial vehicle, an autopilot controller installed in the unmanned aerial vehicle and pre-loaded with a base image, and a computer device. The autopilot controller programs a flight path as a series of mission lags to cover a target polygon on the base image in a lawnmower pattern for controlling the unmanned aerial vehicle to perform a flight mission in which the autopilot controller records plural GPS/INS data and triggers the digital camera to take plural photos which are further calibrated to generate plural calibrated photos corresponding to the plural GPS/INS data, respectively. The computer device processes the plural calibrated photos to generate plural projected photos by using the corresponding plural GPS/INS data, respectively, and stitches the plural projected photos to a mosaic image by a photo-stitching process."
System and method for retrieving information while commanding operation of an appliance,https://lens.org/061-230-272-776-248,2007,"When a command key of a controlling platform is activated, the platform performs an operation to initiate a playing of media content and also initiates the retrieval of information from an information source. The information retrieved is related to the media content and is displayed in a display of the controlling platform."
PACKAGE COUPLING APPARATUS WITH ATTACHMENT PLATE FOR SECURING A PACKAGE TO A UAV AND METHOD OF SECURING A PACKAGE FOR DELIVERY,https://lens.org/149-961-271-463-223,2023,"A package coupling apparatus for securing a package to an unmanned aerial vehicle (UAV) is provided. The package coupling apparatus includes a support plate configured to be secured to an upper surface of the package and a handle extending up from the support plate. The handle includes a handle opening and a bridge that extends over the handle opening, wherein the bridge is configured to be secured by a component of the UAV."
Package Coupling Apparatus with Attachment Plate for Securing a Package to a UAV and Method of Securing a Package for Delivery,https://lens.org/033-858-495-702-287,2023,"A package coupling apparatus for securing a package to an unmanned aerial vehicle (UAV) is provided. The package coupling apparatus includes a support plate configured to be secured to an upper surface of the package and a handle extending up from the support plate. The handle includes a handle opening and a bridge that extends over the handle opening, wherein the bridge is configured to be secured by a component of the UAV."
Beamformer rotation,https://lens.org/053-132-210-062-443,2022,"A mobile device capable of capturing voice commands includes a beamformer for determining audio data corresponding to one or more directions and a beam selector for selecting in which direction a source of target audio lies. The device determines, based on data from one or more sensors, an angle through which the device has rotated. Based on the angle and one or more rotation-compensation functions, the device interpolates audio data corresponding to the one or more directions to compensate for the rotation such that the direction corresponding to the source of target audio remains selected."
Aerial and ground robotic system,https://lens.org/075-454-990-578-175,2007,"An aerial and ground robotic system has a number of mobile nodes creating a mesh network, including at least one aerial node. A sensor is provided on the at least one aerial node. A base station receives data from the sensor through the mesh network."
Autonomous drive system,https://lens.org/005-439-102-304-543,2020,"An autonomous drive system for a vehicle. The system has an autonomous drive module configured to pilot the vehicle. A control module monitors operating performance of the autonomous drive system. A location module identifies the vehicle's location. A transmitter/receiver communicates with a high risk location monitoring module at a location remote to the vehicle. When the control module determines that performance of the autonomous drive system is below a predetermined performance threshold, the control module retrieves the vehicle's location from the location module and transmits the vehicle's location to the high risk location monitoring module, which records the vehicle's current location to notify other vehicles that autonomous drive issues may occur at the vehicle's location."
PLUSH TOY AUDIO CONTROLLER,https://lens.org/035-584-786-659-909,2020,"A master device uses a slave device to connect to the Internet to provide intelligent and dynamic responses. The master device receives input from a user. The master device processes the input and generates a command that is to be transmitted to the slave device via a sound wave. The sound wave is either an audible sound wave or an inaudible sound wave. The command instructs the slave device to perform a certain action and to provide a response back to the master device. The slave device executes the command in response to detecting the sound wave. Subsequent to executing the command, the slave device generates its own sound wave, which includes the response, and transmits the sound wave to the master device. The master device receives the response and tailors another response for the user. The master device then provides the tailored response to the user."
Autonomous Drive System,https://lens.org/074-753-562-588-506,2019,"An autonomous drive system for a vehicle. The system has an autonomous drive module configured to pilot the vehicle. A control module monitors operating performance of the autonomous drive system. A location module identifies the vehicle's location. A transmitter/receiver communicates with a high risk location monitoring module at a location remote to the vehicle. When the control module determines that performance of the autonomous drive system is below a predetermined performance threshold, the control module retrieves the vehicle's location from the location module and transmits the vehicle's location to the high risk location monitoring module, which records the vehicle's current location to notify other vehicles that autonomous drive issues may occur at the vehicle's location."
SYSTEMS AND METHODS OF PILOT ASSIST FOR SUBSEA VEHICLES,https://lens.org/166-183-347-567-802,2019,"A method for controlling a subsea vehicle. The method includes receiving sensor data representing a subsea environment from one or more sensors of the subsea vehicle. The method identifies one or more objects present in the subsea environment based on the sensor data using an artificial intelligence machine. The method transmits at least a portion of the sensor data, including an identification of the one or more objects, to a user interface. The method includes receiving a requested vehicle task from the user interface. The requested vehicle task being selected by a user via the user interface. The method performs the requested vehicle task without vehicle position control from the user."
Systems and methods of pilot assist for subsea vehicles,https://lens.org/167-290-038-916-351,2020,"A method for controlling a subsea vehicle. The method includes receiving sensor data representing a subsea environment from one or more sensors of the subsea vehicle. The method identifies one or more objects present in the subsea environment based on the sensor data using an artificial intelligence machine. The method transmits at least a portion of the sensor data, including an identification of the one or more objects, to a user interface. The method includes receiving a requested vehicle task from the user interface. The requested vehicle task being selected by a user via the user interface. The method performs the requested vehicle task without vehicle position control from the user."
SYSTEMS AND METHODS OF PILOT ASSIST FOR SUBSEA VEHICLES,https://lens.org/187-401-210-484-883,2020,"A method for controlling a subsea vehicle. The method includes receiving sensor data representing a subsea environment from one or more sensors of the subsea vehicle. The method identifies one or more objects present in the subsea environment based on the sensor data using an artificial intelligence machine. The method transmits at least a portion of the sensor data, including an identification of the one or more objects, to a user interface. The method includes receiving a requested vehicle task from the user interface. The requested vehicle task being selected by a user via the user interface. The method performs the requested vehicle task without vehicle position control from the user."
"X-RAY INSPECTION DEVICE FOR DRONE, X-RAY INSPECTION DEVICE EMPLOYING DRONE, AND X-RAY GENERATOR DEVICE FOR DRONE",https://lens.org/132-874-593-021-943,2020,"An X-ray inspection device for a drone includes: a suspension device provided in the drone; an X-ray generator device for a drone, the X-ray generator device being movable up and down by the suspension device and including an X-ray source that emits an X-ray toward an object to be inspected; and a detector that is movable up and down by the suspension device and detects the X-ray transmitted through the object to be inspected."
THERMOSTAT WITH INTERACTIVE FEATURES AND SYSTEM AND METHOD FOR USE OF SAME,https://lens.org/053-199-731-435-950,2022,"A thermostat with interactive features and a system and a method for use of the same are disclosed. In one embodiment of the thermostat, the thermostat receives various types of thermostat data such as information about display-based interactions with the thermostat, information about a plurality of amenities on a residential property co-located with the thermostat, and information from a proximate wireless-enabled programmable device interacting with the thermostat. The thermostat may render a map view of the property based on obtained map data. The map view may include an interactive graphical representation of the residential property and be annotated with at least a portion of the thermostat data."
BATTERY POWER MANAGEMENT IN A THERMOSTAT WITH A WIRELESS TRANSCEIVER,https://lens.org/119-208-963-642-080,2017,"A thermostat includes a controller for controlling the thermostat, a battery supplying power for the thermostat, and a wireless transceiver for receiving control information from a remote device and for transmitting information to the remote device. The controller sets a default time schedule for enabling the wireless transceiver."
Battery power management in a thermostat with a wireless transceiver,https://lens.org/076-815-892-705-801,2017,"A thermostat includes a controller for controlling the thermostat, a battery supplying power for the thermostat, and a wireless transceiver for receiving control information from a remote device and for transmitting information to the remote device. The controller sets a default time schedule for enabling the wireless transceiver."
BATTERY POWER MANAGEMENT IN A THERMOSTAT WITH A WIRELESS TRANSCEIVER,https://lens.org/011-130-133-384-998,2014,"A thermostat includes a controller for controlling the thermostat, a battery supplying power for the thermostat, and a wireless transceiver for receiving control information from a remote device and for transmitting information to the remote device. The controller sets a default time schedule for enabling the wireless transceiver."
Battery Power Management in a Thermostat With a Wireless Transceiver,https://lens.org/160-597-195-141-547,2015,"A thermostat includes a controller for controlling the thermostat, a battery supplying power for the thermostat, and a wireless transceiver for receiving control information from a remote device and for transmitting information to the remote device. The controller sets a default time schedule for enabling the wireless transceiver."
Battery Power Management in a Thermostat With a Wireless Transceiver,https://lens.org/108-124-584-983-603,2014,"A thermostat includes a controller for controlling the thermostat, a battery supplying power for the thermostat, and a wireless transceiver for receiving control information from a remote device and for transmitting information to the remote device. The controller sets a default time schedule for enabling the wireless transceiver."
UAV OBSTACLE AVOIDANCE SYSTEM AND CONTROL METHOD THEREOF,https://lens.org/169-445-529-184-657,2020,"A UAV obstacle avoidance system and a control method thereof are provided. The UAV obstacle avoidance system comprises a cover, at least two obstacle avoidance lens modules and an infrared light source. The infrared light source is located between the at least two obstacle avoidance lens modules. Each obstacle avoidance lens module comprises a sensing unit and an infrared shutter. The sensing unit comprises a filter layer and a sensing element. The filter layer is located between the cover and the sensing element, and the filter layer has at least one filter region, wherein one of the filter regions is an infrared filter region. The infrared shutter is located between the cover and the sensing unit and configured to switch an infrared cut-off filter to a turn-on state or a turn-off state. The UAV obstacle avoidance system and the control method thereof can be used for day and night environments."
Home automation system,https://lens.org/065-894-594-112-927,2006,"An improved home automation system that permits the user of the system to remotely control the operation of various devices including garage doors and powered entry gates. The system is packaged in a manner that ""walks"" the user through the initialization process to thereby reduce or eliminate errors associated with the initialization and set-up of the system. Furthermore, the configuration permits the user to initialize the system without the use of tools, such as screwdrivers. The system is configured with improved functionality that permits the user to readily control individual devices and/or selected groups of devices with a powerful hand-held universal remote transmitter."
Home automation system,https://lens.org/017-621-610-203-745,2004,"An improved home automation system that permits the user of the system to remotely control the operation of various devices including garage doors and powered entry gates. The system is packaged in a manner that ""walks"" the user through the initialization process to thereby reduce or eliminate errors associated with the initialization and set-up of the system. Furthermore, the configuration permits the user to initialize the system without the use of tools, such as screwdrivers. The system is configured with improved functionality that permits the user to readily control individual devices and/or selected groups of devices with a powerful hand-held universal remote transmitter."
"Navigation aircraft capable of achieving automatic tracking, video recognition and intelligent aerial photographing",https://lens.org/198-729-167-827-411,2014,"The utility model discloses a navigation aircraft capable of achieving automatic tracking, video recognition and intelligent aerial photographing. The navigation aircraft comprises a supporting frame, a flight control panel, four brushless motors and four electronic speed regulators. Fan blades are connected with power shafts through the brushless motors, the power shafts are connected with the electronic speed regulators, the flight control panel is provided with a wireless receiving module used for communicating with the ground, a face recognition module used for processing collected images and a camera, and the wireless receiving module is matched with a transmitting antenna on a remote controller. According to the navigation aircraft, a captured face is connected with the aircraft, a specific target is tracked, and the navigation aircraft is suitable for being used in the suspect arresting process, and workload of workers is greatly reduced."
Unmanned aerial vehicle emergency control system,https://lens.org/065-382-369-026-513,2016,"The utility model discloses an unmanned aerial vehicle emergency control system, including unmanned aerial vehicle and intelligent terminal, unmanned aerial vehicle includes controller, flight drive arrangement, information acquisition device, navigation head and wireless communication device, and the controller is connected with flight drive arrangement, information acquisition device, navigation head and wireless communication device respectively, and unmanned aerial vehicle passes through wireless communication device and is connected with the intelligent terminal communication, still including defending signal device, unmanned aerial vehicle still includes the management and control device to unmanned aerial vehicle emergency control system, and the management and control device is connected with the controller, and defence signal device carries out signal transmission with the management and control device through the ripples, defence signal device is used for generating the signal that replaces intelligent terminal control unmanned aerial vehicle to with signal transmission for the management and control device, the management and control device is used for received signal to judge whether carry out defence signal device control unmanned aerial vehicle, and cut off the operation of intelligent terminal control unmanned aerial vehicle."
"Controller, control method using controller, and control system",https://lens.org/007-571-735-861-471,2023,"A controller for controlling an operation of a machine or a robot for handling an object by includes: a sensor signal acquisition unit that acquires a signal from a sensor that outputs three-dimensional point cloud data and a corresponding camera image of an imaging subject; a region acquisition unit that acquires a region having a height lower than a predetermined value; a non-object region setting unit that sets, as a non-object region, a region of the camera image corresponding to the acquired region; a complementary color setting unit that sets a color of the non-object region to a color complementary to a color of the object; an object position recognition unit that recognizes a position of the object relative to the imaging subject from the camera image; and an operation control unit that controls the operation of the machine or the robot using at least the recognized position."
METHOD OF CONTROLLING OBSTACLE AVOIDANCE FOR UNMANNED AERIAL VEHICLE AND UNMANNED AERIAL VEHICLE,https://lens.org/132-281-960-136-045,2019,"A method of controlling obstacle avoidance for an unmanned aerial vehicle (UAV) includes obtaining current attitude information of the UAV, where the UAV includes a craft body and a detection apparatus attached to the craft body, and controlling a detection direction of the detection apparatus to be in a preset direction according to the current attitude information of the UAV."
ARTIFICIAL INTELLIGENCE-BASED APPARATUS AND METHOD FOR CONTROLLING HOME THEATER SPEECH,https://lens.org/059-226-336-055-789,2019,"The artificial intelligence (AI)-based apparatus for controlling home-theater speech, which performs separation and synthesis on speech output from an electronic device of a user, includes an input unit that receives the speech, and a processor that separates and extract, from the speech from the input unit, a first signal representing a speech signal related to language or dialogue and a second signal representing a speech signal related to background sound or effect sound; extracts feature vectors of the first signal and the second signal to perform unsupervised learning; and calculates an amplitude difference between the first signal and the second signal according to a result of the unsupervised learning, and adjusting the amplitude difference according to an output method preset by the user."
AIRCRAFT,https://lens.org/192-233-968-312-488,2015,"A flight system comprising an aircraft equipped with at least four rotors and having a payload, a number of rotors rotating in one direction and a number of rotors rotating in the other direction, as well as a remote control, the aircraft being connected to the remote control, so as to transmit data, via respective transmitter/receiver units, both the aircraft and the remote control having a data processing device connected to the respective transmitter/receiver unit, both the aircraft and the remote control having the same sensors for flight attitude detection, where, when there is an angle change in the remote control around its X- and/or Y- and/or Z-axis, the amount of the angle change correlates with a definable speed of the aircraft, the speed specified according to the angle change being transmitted as a target value of the data processing device of the aircraft and/or of the remote control."
ARTIFICIAL INTELLIGENCE ROBOT AND METHOD OF OPERATING THE SAME,https://lens.org/193-857-241-117-421,2021,"An artificial intelligence robot includes a camera configured to acquire image data, a memory configured to store an object recognition model used to recognize an object from the image data, and a processor configured to acquire a speech command, determine whether an intention of the acquired speech command is object search, recognize an object from the image data based on the object recognition model during traveling when the intention of object search, and output a notification indicating that the object has been recognized when the recognized object is an intended object."
CELL PHONE CASE WITH EXTENDABLE REMOTE CAMERA CONTROL,https://lens.org/089-180-024-211-663,2016,"A remote camera control for a cell phone camera is extendably attached to a cell phone case to retract into and he held in the cell phone case when not in use and to be extended from the cell phone case when in use to also serve as a handle for holding the cell phone case and cell phone therein a distance away from the user for taking ""'selfies"" or other pictures."
Item delivery with an unmanned aerial vehicle and unmanned aerial vehicle retrieval system,https://lens.org/145-767-778-404-607,2017,"Described is a system and method for utilizing unmanned aerial vehicles (UAV) to facilitate delivery of ordered items to user specified delivery destinations. In one implementation, the UAV may be configured as a one-way UAV that is designed to transport ordered items to the user specified delivery destination but not return to a materials handling facility under its own power. Instead, the one-way UAV may remain at the delivery destination for later retrieval by a retrieval unit (e.g., truck)."
Item delivery with an aerial vehicle,https://lens.org/079-502-729-436-383,2019,"Described is a system and method for utilizing unmanned aerial vehicles (UAV) to facilitate delivery of ordered items to user specified delivery destinations. In one implementation, the UAV may be configured as a one-way UAV that is designed to transport ordered items to the user specified delivery destination but not return to a materials handling facility under its own power. Instead, the one-way UAV may remain at the delivery destination for later retrieval by a retrieval unit (e.g., truck)."
Methods and systems for automatically yielding to high-priority traffic,https://lens.org/180-755-801-337-977,2013,"A method of navigating a mobile robotic device may include receiving, by a mobile robotic device, a wireless transmission from a transponder associated with an object, where the object is within a range of the mobile robotic device and in response to receiving the notification, altering a navigation course by the mobile robotic device to allow the object to pass the mobile robotic device. The mobile robotic device may be preprogrammed with at least a portion of the navigation course. The method may include resuming the navigation course by the mobile robotic device."
METHODS AND SYSTEMS FOR AUTOMATICALLY YIELDING TO HIGH-PRIORITY TRAFFIC,https://lens.org/191-920-569-482-357,2012,"A method of navigating a mobile robotic device may include receiving, by a mobile robotic device, a wireless transmission from a transponder associated with an object, where the object is within a range of the mobile robotic device and in response to receiving the notification, altering a navigation course by the mobile robotic device to allow the object to pass the mobile robotic device. The mobile robotic device may be preprogrammed with at least a portion of the navigation course. The method may include resuming the navigation course by the mobile robotic device."
REMOTE CONTROL FOR CONTROLLING A TELEVISION RECEIVER,https://lens.org/154-597-855-940-647,2014,"A remote control for controlling a television receiver. The remote control comprises a communication mechanism for communicating with the receiver, an active NFC reader for communicating with an active or passive NFC device, and a mechanism for transmitting the information received from the NFC device to the receiver. The remote control allows the use of a near filed communication (NFC) portable device (e.g., card or smartphone) for transactions using a television."
Visual control selection of remote mechanisms,https://lens.org/066-591-899-864-730,1998,"An apparatus for selecting and controlling devices located remotely from a local site where an operator resides. A laser or other source of a focused electromagnetic bean moves in association with a camera located at the remote site. The camera thus can detect the object on which the focused laser beam projects. The camera outputs a video signal which is transmitted from the remote site to the local site. The operator at the local site views the video signal on a monitor so that the operator can determine the location of the laser beam. When the laser beam illuminates at least one particular transponder out of one or a plurality of transponders, the transponder outputs a signal to at least one device to activate or deactivate the device, thus providing the operator remote control of the device. A light may also be associated with the transponder and activates when the transponder has been selected to provide a positive indication to the operator that only the particular transponder has been selected. A remote controller may also be provided at the remote site to control operation of the particular, selected device of the plurality. The controller receives commands from the operator at the local site, thereby providing the operator with selection and control capabilities."
IPIZED DEVICE FOR UAV FLIGHT CONTROLLER,https://lens.org/158-080-908-009-068,2022,"An IPized device for UAV flight controller includes a flight control transmission and control interface module connected to the UAV flight controller for capturing flight control data message of the UAV flight controller. An IPized device module uses an IP address to control and transmit data to the UAV, to convert the flight control data message into a packet format message of the Ethernet, and then to use a data transmission module to transmit the packet form message to the local network or the Internet. The IPized device module is used to receive a control message packet of the local area network or the Internet, and to convert the control message packet into a flight control message of the communication protocol of the UAV flight controller. The flight control message is then transmitted to the UAV flight controller through the flight control transmission and control interface module."
Remote control using passive components,https://lens.org/198-906-197-700-563,2018,A receiver includes: a wireless local area network (WLAN) router; wherein the receiver is configured to receive data from a remote control and to generate commands to be transmitted to one or more devices via an interface of the WLAN router.
REMOTE CONTROL USING PASSIVE COMPONENTS,https://lens.org/101-716-815-488-576,2017,A receiver includes: a wireless local area network (WLAN) router; wherein the receiver is configured to receive data from a remote control and to generate commands to be transmitted to one or more devices via an interface of the WLAN router.
AUTONOMOUS UNDERWATER VEHICLE AND METHOD FOR COUPLING TO OCEAN BOTTOM DURING MARINE SEISMIC SURVEY,https://lens.org/167-773-438-053-272,2016,"An autonomous underwater vehicle (AUV) is configured to record seismic signals during a marine seismic survey. The AUV includes a body having a base (B) and first and second sides (A, C), the body having a head part and a tail part; a propulsion system for guiding the AUV to a final target on the ocean bottom; a seismic sensor configured to record seismic signals; and an anchoring system configured to rock or twist the base in a given sequence so that the base (B) penetrates into the ocean bottom."
Autonomous underwater vehicle and method for coupling to ocean bottom during marine seismic survey,https://lens.org/160-195-521-814-064,2017,"An autonomous underwater vehicle (AUV) is configured to record seismic signals during a marine seismic survey. The AUV includes a body having a base (B) and first and second sides (A, C), the body having a head part and a tail part; a propulsion system for guiding the AUV to a final target on the ocean bottom; a seismic sensor configured to record seismic signals; and an anchoring system configured to rock or twist the base in a given sequence so that the base (B) penetrates into the ocean bottom."
AUDIO CONTROL SYSTEM OF ELECTROMAGNETIC CRADLE,https://lens.org/084-964-035-957-050,2020,"An audio control system of an electromagnetic cradle includes an audio transmitting and receiving unit, a cloud server, and a function execution unit. The audio transmitting and receiving unit receives an audio command emitted from a user. The cloud server is connected with the audio transmitting and receiving unit through a network. The cloud server identifies and compares the audio command of the audio transmitting and receiving unit. The function execution unit is connected with the cloud server through the network. The function control module is driven by function indication of the cloud server to execute related functions, including playing the music, lighting or shaking the cradle."
Audio control system of electromagnetic cradle,https://lens.org/087-223-486-588-275,2021,"An audio control system of an electromagnetic cradle includes an audio transmitting and receiving unit, a cloud server, and a function execution unit. The audio transmitting and receiving unit receives an audio command emitted from a user. The cloud server is connected with the audio transmitting and receiving unit through a network. The cloud server identifies and compares the audio command of the audio transmitting and receiving unit. The function execution unit is connected with the cloud server through the network. The function control module is driven by function indication of the cloud server to execute related functions, including playing the music, lighting or shaking the cradle."
Home cleaning robot,https://lens.org/106-610-731-746-669,2002,"An autonomously movable cleaning robot comprising a platform and motive force to autonomously move the robot on a substantially horizontal surface having boundaries. The robot further has a computer processing unit for storing, receiving and transmitting data, and a cleaning implement operatively associated with the robot. The robot receives input data from an external source. The external source may be physical manipulation of the robot, remote control, or by triangulation from at least three external transmitters."
Image-based velocity control for a turning vehicle,https://lens.org/014-031-273-038-89X,2022,"An autonomous vehicle control system is provided. The control system may include a plurality of cameras to acquire a plurality of images of an area in a vicinity of a vehicle; and at least one processing device configured to: recognize a curve to be navigated based on map data and vehicle position information; determine an initial target velocity for the vehicle based on at least one characteristic of the curve as reflected in the map data; adjust a velocity of the vehicle to the initial target velocity; determine, based on the plurality of images, observed characteristics of the curve; determine an updated target velocity based on the observed characteristics of the curve; and adjust the velocity of the vehicle to the updated target velocity."
Image-based velocity control for a turning vehicle,https://lens.org/014-031-273-038-89X,2022,"An autonomous vehicle control system is provided. The control system may include a plurality of cameras to acquire a plurality of images of an area in a vicinity of a vehicle; and at least one processing device configured to: recognize a curve to be navigated based on map data and vehicle position information; determine an initial target velocity for the vehicle based on at least one characteristic of the curve as reflected in the map data; adjust a velocity of the vehicle to the initial target velocity; determine, based on the plurality of images, observed characteristics of the curve; determine an updated target velocity based on the observed characteristics of the curve; and adjust the velocity of the vehicle to the updated target velocity."
DRONE WEAPON SYSTEM,https://lens.org/046-382-815-925-510,2020,"In some embodiments, an armed aircraft comprised of a remotely operated unmanned air vehicle (UAV) or drone, a recoil compensator, and a remotely operated modified firearm mounted to the frame or mounting assembly of said aircraft."
METHOD AND APPARATUS FOR INTELLIGENT INSPECTION AND INTERACTION BETWEEN A VEHICLE AND A DRONE,https://lens.org/041-561-969-762-488,2019,"An approach is provided for intelligent inspection and interaction between a vehicle and a drone. The approach, for example, involves retrieving vehicle specification data for the vehicle. The vehicle specification data identifies one or more sensors of the vehicle, one or more sensor locations on the vehicle corresponding to the one or more sensors, or a combination thereof. The approach also involves configuring the drone device to move from a docked location to the one or more sensor locations on the vehicle based on the vehicle specification data. The approach further involves initiating an inspection function, an interaction function, or a combination thereof between the drone device and the vehicle when the drone device is positioned in proximity to the one or more sensor locations."
Method and apparatus for intelligent inspection and interaction between a vehicle and a drone,https://lens.org/051-410-352-585-797,2020,"An approach is provided for intelligent inspection and interaction between a vehicle and a drone. The approach, for example, involves retrieving vehicle specification data for the vehicle. The vehicle specification data identifies one or more sensors of the vehicle, one or more sensor locations on the vehicle corresponding to the one or more sensors, or a combination thereof. The approach also involves configuring the drone device to move from a docked location to the one or more sensor locations on the vehicle based on the vehicle specification data. The approach further involves initiating an inspection function, an interaction function, or a combination thereof between the drone device and the vehicle when the drone device is positioned in proximity to the one or more sensor locations."
"AUTONOMOUS SEARCH LIGHT SYSTEM, WINCH SYSTEM COMPRISING AN AUTONOMOUS SEARCH LIGHT SYSTEM, AND AIRCRAFT COMPRISING AN AUTONOMOUS SEARCH LIGHT SYSTEM",https://lens.org/102-228-197-094-441,2022,"Autonomous search light system (4) for being mounted to an aircraft (2), the autonomous search light system (4) comprising: a search light (12) for emitting an adjustable light output (6); an RF receiver (16) with at least two RF antennas (18a, 18b, 18c) for receiving RF signals emitted by an RF transmitter (10); and a controller (14) for determining a position of the RF transmitter (10) in relation to the search light (12) from the received RF signals and for controlling the search light (12) based on the determined position of the RF transmitter (10)."
"AUTONOMOUS SEARCH LIGHT SYSTEM, WINCH SYSTEM COMPRISING AN AUTONOMOUS SEARCH LIGHT SYSTEM, AND AIRCRAFT COMPRISING AN AUTONOMOUS SEARCH LIGHT SYSTEM",https://lens.org/102-228-197-094-441,2022,"Autonomous search light system (4) for being mounted to an aircraft (2), the autonomous search light system (4) comprising: a search light (12) for emitting an adjustable light output (6); an RF receiver (16) with at least two RF antennas (18a, 18b, 18c) for receiving RF signals emitted by an RF transmitter (10); and a controller (14) for determining a position of the RF transmitter (10) in relation to the search light (12) from the received RF signals and for controlling the search light (12) based on the determined position of the RF transmitter (10)."
Intelligent sound field control system,https://lens.org/015-608-058-050-44X,2016,"An intelligent sound field control system, which relates to a sound field modulation device and is provided with a WiFi/wireless/wire network main control device, a notebook computer, a wireless universal serial bus dongle, a tablet computer, a motion control electronic device and a reflecting medium, is capable of integrally controlling states of different sound reflecting mediums. Accordingly, an indoor acoustic parameter can be varied and electromechanical integration can be achieved, thereby promoting usage convenience, accuracy and usability."
INTELLIGENT SOUND FIELD CONTROL SYSTEM,https://lens.org/163-626-446-904-625,2015,"An intelligent sound field control system, which relates to a sound field modulation device and is provided with a WiFi/wireless/wire network main control device, a notebook computer, a wireless universal serial bus dongle, a tablet computer, a motion control electronic device and a reflecting medium, is capable of integrally controlling states of different sound reflecting mediums. Accordingly, an indoor acoustic parameter can be varied and electromechanical integration can be achieved, thereby promoting usage convenience, accuracy and usability."
Floor sweeping robot controlled by smart phone,https://lens.org/018-787-123-214-734,2016,"The invention discloses a floor sweeping robot controlled by a smart phone. The floor sweeping robot comprises a core control system, a wireless charging device, a wireless communication device, a power moving mechanism, a sweeping mechanism, an environment monitoring module, a vision system, a voice system and a humidifying system; wherein the vision system comprises an infrared sensor, a distance sensor and a photographing system. The floor sweeping robot is wirelessly charged through a charging pile. A user can set the operation mode of the floor sweeping robot by means of a smart phone control system, and furthermore can transmit an instruction through speech. In the sweeping process, the robot can determine whether to humidify the environment. All information which comprises analog three-dimensional pictures, real-time cleaning video pictures and indoor environment information is transmitted to the smart phone for viewing by the user. The floor sweeping robot according to the invention has advantages of reducing potential safety hazard, realizing more convenient and quicker user operation and improving user experience."
"REMOTE MONITORING METHOD, APPARATUS, AND SYSTEM, USING SMART PHONE",https://lens.org/194-057-302-214-972,2018,"A remote monitoring method includes the steps of: (c) receiving a control data for changing an image area captured by the smart phone from a communication channel, which transmits and receives data through an Internet, by the smart phone; (d) controlling a cradle through a short-range network using a pan/tilt control data for controlling one or more of pan and tilt of the cradle, on which the smart phone is mounted, using the received control data, by the smart phone; and (e) encoding an image captured through a provided camera module and outputting the encoded image through the Internet, after controlling the cradle, by the smart phone."
RADIO FREQUENCY DEVICE DETECTION AND INTERVENTION,https://lens.org/034-372-268-562-647,2018,"Systems, devices and methods are disclosed for detecting, characterizing and engaging unmanned vehicles. In one aspect, a method includes detecting an object, such as an unmanned aerial, land or aquatic vehicle that communicates using a radio control (RC) communications protocol, traveling to a zone including scanning one or more frequencies of RF signals; analyzing one or both of time and frequency information of the RF signals to characterize the detected object; and engaging the detected object as an authorized or unauthorized object in the monitored zone."
Radio frequency device detection and intervention,https://lens.org/008-387-897-028-331,2018,"Systems, devices and methods are disclosed for detecting, characterizing and engaging unmanned vehicles. In one aspect, a method includes detecting an object, such as an unmanned aerial, land or aquatic vehicle that communicates using a radio control (RC) communications protocol, traveling to a zone including scanning one or more frequencies of RF signals; analyzing one or both of time and frequency information of the RF signals to characterize the detected object; and engaging the detected object as an authorized or unauthorized object in the monitored zone."
RADIO FREQUENCY DEVICE DETECTION AND INTERVENTION,https://lens.org/184-573-899-422-608,2018,"Systems, devices and methods are disclosed for detecting, characterizing and engaging unmanned vehicles. In one aspect, a method includes detecting an object, such as an unmanned aerial, land or aquatic vehicle that communicates using a radio control (RC) communications protocol, traveling to a zone including scanning one or more frequencies of RF signals; analyzing one or both of time and frequency information of the RF signals to characterize the detected object; and engaging the detected object as an authorized or unauthorized object in the monitored zone."
PLATFORM,https://lens.org/010-494-293-115-122,2019,"A platform, adapted to accommodate a UAV (Unmanned Aerial Vehicle), includes a base and a cover. The base includes a first connection port and a power source, and the power source is coupled to the first connection port including a first connection electrode and a second connection electrode. The cover includes at least one fan and a second connection port corresponding to the first connection port of the base, the at least one fan is coupled to the second connection port, and the second connection port includes a first contact electrode and a second contact electrode. The cover is connected to the base and moves between an open position and a closed position relative to the base. The first connection port is connected to the second connection port when the cover is at the closed position, and the power source provides power to the at least one fan."
Platform,https://lens.org/067-658-566-878-480,2020,"A platform, adapted to accommodate a UAV (Unmanned Aerial Vehicle), includes a base and a cover. The base includes a first connection port and a power source, and the power source is coupled to the first connection port including a first connection electrode and a second connection electrode. The cover includes at least one fan and a second connection port corresponding to the first connection port of the base, the at least one fan is coupled to the second connection port, and the second connection port includes a first contact electrode and a second contact electrode. The cover is connected to the base and moves between an open position and a closed position relative to the base. The first connection port is connected to the second connection port when the cover is at the closed position, and the power source provides power to the at least one fan."
Unmanned aerial vehicle based surveillance as a service,https://lens.org/117-109-238-910-998,2019,"The delivery of a package using an unmanned aerial vehicle (UAV) may include performing a surveillance action at a property of an authorized party. The surveillance action may include imaging the property, and may be performed before or after the package is delivered. Surveillance data such as image data gathered in a surveillance action may be modified to remove or obscure adjacent properties not associated with the property of the authorized party. Based on surveillance data, the probability or confidence value of a surveillance event may be determined and a surveillance alert may be generated. Surveillance actions may be scheduled by a central controller to ensure that the surveillance action may be performed without exhausting the resources, such as battery power or time, of the UAV. Surveillance actions may be received as an interrupt and may have an associated priority level."
"Laryngoscope, Laryngoscope Arm and Laryngoscope System",https://lens.org/158-500-892-871-187,2016,"A laryngoscope and system are provided, the laryngoscope comprising a handle, an arm, a camera harness comprising a deployable camera, and a light. The arm comprises a first canal adapted to receive the camera upon deployment and a second canal adapted to transmit light from the handle into an oral cavity. The handle comprises a remote ejection element. The laryngoscope system comprises a handle capable of direct wireless communication with a display unit."
"Laryngoscope, laryngoscope arm and laryngoscope system",https://lens.org/167-964-079-717-402,2018,"A laryngoscope and system are provided, the laryngoscope comprising a handle, an arm, a camera harness comprising a deployable camera, and a light. The arm comprises a first canal adapted to receive the camera upon deployment and a second canal adapted to transmit light from the handle into an oral cavity. The handle comprises a remote ejection element. The laryngoscope system comprises a handle capable of direct wireless communication with a display unit."
Remote control systems with ambient noise sensor,https://lens.org/193-130-122-529-995,2004,A remote control system includes a remote control transmitter that transmit a signal and a receiver than can receive the signal from the transmitter. A control device performs a function having a first and a second option. The control device responds to the signal received by the receiver and performs the first option if the distance between the remote control transmitter and the receiver is greater than a particular distance and performs a function based on the ambient noise level.
Remote control systems with ambient noise sensor,https://lens.org/096-895-818-397-482,2005,A remote control system includes a remote control transmitter that transmit a signal and a receiver than can receive the signal from the transmitter. A control device performs a function having a first and a second option. The control device responds to the signal received by the receiver and performs the first option if the distance between the remote control transmitter and the receiver is greater than a particular distance and performs a function based on the ambient noise level.
Autonomous aerial vehicle airspace claiming and announcing,https://lens.org/048-295-984-006-555,2023,"A processing system of an autonomous aerial vehicle including at least one processor may obtain mapping data describing at least a portion of a facility, navigate, via the mapping data, to a space within the facility to perform an assigned task, and collect spatial sensor data within the space. The processing system may then detect, from the spatial sensor data, at least one object within the space, define a reserved zone within the space to perform the assigned task, based upon the at least one object that is detected, and present at least one of an audible announcement or a visual announcement of the reserved zone."
AUTONOMOUS AERIAL VEHICLE AIRSPACE CLAIMING AND ANNOUNCING,https://lens.org/123-908-101-120-678,2022,"A processing system of an autonomous aerial vehicle including at least one processor may obtain mapping data describing at least a portion of a facility, navigate, via the mapping data, to a space within the facility to perform an assigned task, and collect spatial sensor data within the space. The processing system may then detect, from the spatial sensor data, at least one object within the space, define a reserved zone within the space to perform the assigned task, based upon the at least one object that is detected, and present at least one of an audible announcement or a visual announcement of the reserved zone."
AUTONOMOUS AERIAL VEHICLE AIRSPACE CLAIMING AND ANNOUNCING,https://lens.org/123-908-101-120-678,2022,"A processing system of an autonomous aerial vehicle including at least one processor may obtain mapping data describing at least a portion of a facility, navigate, via the mapping data, to a space within the facility to perform an assigned task, and collect spatial sensor data within the space. The processing system may then detect, from the spatial sensor data, at least one object within the space, define a reserved zone within the space to perform the assigned task, based upon the at least one object that is detected, and present at least one of an audible announcement or a visual announcement of the reserved zone."
SYSTEMS AND METHODS USING A BACKUP NAVIGATIONAL TOOL FOR UNMANNED AERIAL VEHICLES DELIVERING MERCHANDISE,https://lens.org/110-571-704-575-716,2019,"In some embodiments, apparatuses and methods are provided herein useful to delivering merchandise using unmanned aerial vehicles (UAVs). In some embodiments, there is provided a system including: a UAV having a motorized flight system, a storage area, a transceiver, an imaging, and a GPS tracking device; a memory device for storing position coordinates of the UAV; a flight simulator database including storing geographic and landscape features along the UAVs flight path; and a control circuit configured to: navigate the UAV using GPS, store position coordinates, capture image sequences of the geographic and landscape features, and if the GPS fails to provide accurate position information, communicate with the flight simulator database, calculate a predicted position for the UAV, compare the image sequences with images from the flight simulator database, and determine the actual position of the UAV if individual images in the image sequences match images from the flight simulator database."
Unmanned aerial vehicle (UAV) for collecting audio data,https://lens.org/133-557-824-045-705,2018,A UAV is provided to cancel background noise from audio data collected by the UAV. The UAV is provided with one or more background microphones in a proximity of one or more background noise-producing components. The UAV is also provided with one or more audio source collecting microphones. The audio data collected by the background microphones may be used to reduce or cancel interfering background noise from the audio signal detected by the audio source collecting microphone. The target audio may be captured or recorded with little or no background noise.
AN UNMANNED AERIAL VEHICLE (UAV) FOR COLLECTING AUDIO DATA,https://lens.org/005-334-711-069-277,2020,A UAV is provided to cancel background noise from audio data collected by the UAV. The UAV is provided with one or more background microphones in a proximity of one or more background noise-producing components. The UAV is also provided with one or more audio source collecting microphones. The audio data collected by the background microphones may be used to reduce or cancel interfering background noise from the audio signal detected by the audio source collecting microphone. The target audio may be captured or recorded with little or no background noise.
Robotic system,https://lens.org/158-985-156-914-212,2020,"A robot system comprises a base (2), a robot arm (1) connected to the base, a camera (10), at least one objective lens in the camera (10) being movable with the robot arm (1), and a screen (16). A control unit (15) is configured to detect a change in the distance between an object (21) detected by the camera (10) and the objective lens, and to vary the zoom factor of a zoom function of the camera (10) according to the change in distance."
ROBOTIC SYSTEM,https://lens.org/105-686-390-009-808,2016,"A robot system comprises a base (2), a robot arm (1) connected to the base, a camera (10), at least one objective lens in the camera (10) being movable with the robot arm (1), and a screen (16). A control unit (15) is configured to detect a change in the distance between an object (21) detected by the camera (10) and the objective lens, and to vary the zoom factor of a zoom function of the camera (10) according to the change in distance."
RESPONDER OVERSIGHT SYSTEM FOR AN AUTONOMOUS VEHICLE,https://lens.org/070-764-308-674-802,2023,"A system includes an autonomous vehicle (AV) comprising a sensor, a control subsystem, and an operation server. The control subsystem receives sensor data comprising location coordinates of the AV from the sensor. The operation server detects an unexpected event from the sensor data, comprising at least one of an accident, an inspection, and a report request. The operation server receives a message from a user comprising a request to access particular information regarding the AV and location data. The operation server associates the AV with the user if the location coordinates of the AV match location data of the user. The operation server establishes a communication path between the user and a remote operator for further communications."
RESPONDER OVERSIGHT SYSTEM FOR AN AUTONOMOUS VEHICLE,https://lens.org/070-764-308-674-802,2023,"A system includes an autonomous vehicle (AV) comprising a sensor, a control subsystem, and an operation server. The control subsystem receives sensor data comprising location coordinates of the AV from the sensor. The operation server detects an unexpected event from the sensor data, comprising at least one of an accident, an inspection, and a report request. The operation server receives a message from a user comprising a request to access particular information regarding the AV and location data. The operation server associates the AV with the user if the location coordinates of the AV match location data of the user. The operation server establishes a communication path between the user and a remote operator for further communications."
PROPULSION DEVICE FOR AN OVER-ACTUATED UAV,https://lens.org/122-393-260-758-154,2022,"A propulsion device for an unmanned aerial vehicle (UAV), and an UAV with improved maneuverability and fault tolerance. The propulsion device includes a propeller motor, a first motor, and a second motor in a stacked-up configuration disposed relative to a local z-axis, the local z-axis being orthogonal to a local first axis and a local second axis. The first motor is operable to enable a first rotational displacement of the propeller motor about the local first axis. The second motor is operable to enable a second rotational displacement of the first motor body about the local second axis, the local second axis being orthogonal to the local first axis."
PROPULSION DEVICE FOR AN OVER-ACTUATED UAV,https://lens.org/122-393-260-758-154,2022,"A propulsion device for an unmanned aerial vehicle (UAV), and an UAV with improved maneuverability and fault tolerance. The propulsion device includes a propeller motor, a first motor, and a second motor in a stacked-up configuration disposed relative to a local z-axis, the local z-axis being orthogonal to a local first axis and a local second axis. The first motor is operable to enable a first rotational displacement of the propeller motor about the local first axis. The second motor is operable to enable a second rotational displacement of the first motor body about the local second axis, the local second axis being orthogonal to the local first axis."
Unmanned aerial vehicle assistant,https://lens.org/015-177-232-566-74X,2016,"Techniques and systems for providing miniaturized unmanned aerial vehicles (UAVs) are disclosed. The techniques and systems can include significant off-board processing support for the UAVs to enable the UAVs to be smaller, lighter, and less expensive than conventional UAVs. The techniques and systems can include routines to provide enhanced support for police during routine traffic stops. The techniques and systems can also include routines to locate objects or people including, for example, locating a lost child in a crowd or a lost vehicle in a parking lot. The miniaturized UAVs can provide enhances perception for the user to enable the user to over and around objects for improved visibility and safety, among other things."
Unmanned aerial vehicle assistant for monitoring of user activity,https://lens.org/079-381-383-553-823,2018,"Techniques and systems for providing miniaturized unmanned aerial vehicles (UAVs) are disclosed. The techniques and systems can include significant off-board processing support for the UAVs to enable the UAVs to be smaller, lighter, and less expensive than conventional UAVs. The techniques and systems can include routines to provide enhanced support for police during routine traffic stops. The techniques and systems can also include routines to locate objects or people including, for example, locating a lost child in a crowd or a lost vehicle in a parking lot. The miniaturized UAVs can provide enhances perception for the user to enable the user to over and around objects for improved visibility and safety, among other things."
VOICE ASSISTANT WITH CONTEXTUALLY-ADJUSTED AUDIO OUTPUT,https://lens.org/186-112-790-223-403,2021,"A voice assistant has a contextually-adjusted audio output. The audio output can be adjusted, for example, based on media content characteristics."
SYSTEMS AND METHODS USING A BACKUP NAVIGATIONAL TOOL FOR UNMANNED AERIAL VEHICLES DELIVERING MERCHANDISE,https://lens.org/146-625-132-268-223,2018,"In some embodiments, apparatuses and methods are provided herein useful to delivering merchandise using unmanned aerial vehicles (UAVs). In some embodiments, there is provided a system including: a UAV having a motorized flight system, a storage area, a transceiver, an imaging, and a GPS tracking device; a memory device for storing position coordinates of the UAV; a flight simulator database including storing geographic and landscape features along the UAV's flight path; and a control circuit configured to: navigate the UAV using GPS, store position coordinates, capture image sequences of the geographic and landscape features, and if the GPS fails to provide accurate position information, communicate with the flight simulator database, calculate a predicted position for the UAV, compare the image sequences with images from the flight simulator database, and determine the actual position of the UAV if individual images in the image sequences match images from the flight simulator database."
AUTONOMOUS MOBILE DEVICE,https://lens.org/133-100-749-633-389,2011,"An electronic controller defining an autonomous mobile device a self-location estimation unit to estimate a self-location based on a local map that is created according to distance/angle information relative to an object in the vicinity and the travel distance of an omni wheel, an environmental map creation unit to create an environmental map of a mobile area based on the self-location and the local map during the guided travel with using a joystick, a registration switch to register the self-location of the autonomous mobile device as the position coordinate of the setting point when the autonomous mobile device reaches a predetermined setting point during the guided travel, a storage unit to store the environmental map and the setting point, a route planning unit to plan the travel route by using the setting point on the environmental map stored in the storage unit, and a travel control unit to control the autonomous mobile device to autonomously travel along the travel route."
CLEANING ROBOT,https://lens.org/074-987-674-435-522,2016,"Provided is a cleaning robot including a main body; a driving unit configured to move the main body; a communication unit configured to establish wireless communication with a user terminal to which a manipulation command is input; and a controller configured to transmit a position detecting signal to the user terminal, and detect a position of the user terminal based on a time difference between the position detecting signal and a response signal transmitted from the user terminal."
CLEANING ROBOT,https://lens.org/171-408-470-908-460,2019,"Provided is a cleaning robot including a main body; a driving unit configured to move the main body; a communication unit configured to establish wireless communication with a user terminal to which a manipulation command is input; and a controller configured to transmit a position detecting signal to the user terminal, and detect a position of the user terminal based on a time difference between the position detecting signal and a response signal transmitted from the user terminal."
Cleaning robot,https://lens.org/110-582-783-273-604,2020,"Provided is a cleaning robot including a main body; a driving unit configured to move the main body; a communication unit configured to establish wireless communication with a user terminal to which a manipulation command is input; and a controller configured to transmit a position detecting signal to the user terminal, and detect a position of the user terminal based on a time difference between the position detecting signal and a response signal transmitted from the user terminal."
UPDATING AIRSPACE AWARENESS FOR UNMANNED AERIAL VEHICLES,https://lens.org/089-529-693-611-348,2022,"Methods, apparatuses, system, devices, and computer program products for updating airspace awareness for unmanned aerial vehicles are disclosed. In a particular embodiment, the classification of a detected object is identified based on sensor data collected by an in-flight unmanned aerial vehicle (UAV). The location of the object is determined based on the sensor data. An airspace awareness controller generates, in dependence upon the classification of the object and the location of the object, an airspace awareness update concerning the object."
UPDATING AIRSPACE AWARENESS FOR UNMANNED AERIAL VEHICLES,https://lens.org/075-664-117-326-729,2022,"Methods, apparatuses, system, devices, and computer program products for updating airspace awareness for unmanned aerial vehicles are disclosed. In a particular embodiment, the classification of a detected object is identified based on sensor data collected by an in-flight unmanned aerial vehicle (UAV). The location of the object is determined based on the sensor data. An airspace awareness controller generates, in dependence upon the classification of the object and the location of the object, an airspace awareness update concerning the object."
UPDATING AIRSPACE AWARENESS FOR UNMANNED AERIAL VEHICLES,https://lens.org/075-664-117-326-729,2022,"Methods, apparatuses, system, devices, and computer program products for updating airspace awareness for unmanned aerial vehicles are disclosed. In a particular embodiment, the classification of a detected object is identified based on sensor data collected by an in-flight unmanned aerial vehicle (UAV). The location of the object is determined based on the sensor data. An airspace awareness controller generates, in dependence upon the classification of the object and the location of the object, an airspace awareness update concerning the object."
UPDATING AIRSPACE AWARENESS FOR UNMANNED AERIAL VEHICLES,https://lens.org/089-529-693-611-348,2022,"Methods, apparatuses, system, devices, and computer program products for updating airspace awareness for unmanned aerial vehicles are disclosed. In a particular embodiment, the classification of a detected object is identified based on sensor data collected by an in-flight unmanned aerial vehicle (UAV). The location of the object is determined based on the sensor data. An airspace awareness controller generates, in dependence upon the classification of the object and the location of the object, an airspace awareness update concerning the object."
Operation of a tethered drone,https://lens.org/026-522-371-747-253,2022,"A drone may receive power from mobile base station equipment via an air-to-ground power feed during flight, which allows the drone to remain in flight for longer periods of time than relying on battery power alone. The air-to-ground power feed may be included in a tether that includes multiple air-to-ground power feeds or communication feeds. In some cases, the drone is powered by an on-board power system during takeoff and landing sequences to avoid damage to the tether or the drone and/or signal interference within the tether. In some cases, the drone may follow flight patterns during takeoff and landing sequences to avoid damage to the tether or the drone and/or signal interference within the tether."
Operation of a tethered drone,https://lens.org/026-522-371-747-253,2022,"A drone may receive power from mobile base station equipment via an air-to-ground power feed during flight, which allows the drone to remain in flight for longer periods of time than relying on battery power alone. The air-to-ground power feed may be included in a tether that includes multiple air-to-ground power feeds or communication feeds. In some cases, the drone is powered by an on-board power system during takeoff and landing sequences to avoid damage to the tether or the drone and/or signal interference within the tether. In some cases, the drone may follow flight patterns during takeoff and landing sequences to avoid damage to the tether or the drone and/or signal interference within the tether."
OPERATION OF A TETHERED DRONE,https://lens.org/017-360-628-629-565,2020,"A drone may receive power from mobile base station equipment via an air-to-ground power feed during flight, which allows the drone to remain in flight for longer periods of time than relying on battery power alone. The air-to-ground power feed may be included in a tether that includes multiple air-to-ground power feeds or communication feeds. In some cases, the drone is powered by an on-board power system during takeoff and landing sequences to avoid damage to the tether or the drone and/or signal interference within the tether. In some cases, the drone may follow flight patterns during takeoff and landing sequences to avoid damage to the tether or the drone and/or signal interference within the tether."
"Mechanically steered and horizontally polarized antenna for aerial vehicles, and associated systems and methods",https://lens.org/068-082-900-008-411,2019,"A mechanically steered, horizontally polarized, directional antennae for aerial vehicles, such as UAVs. The antenna system can include a planar substrate with a horizontally polarized antenna embedded therein. A rotation member, on one end, can be attached to the planar substrate, and can extend from an external surface of the aerial vehicle. An actuator can be coupled to the rotation member to rotate the rotation member. A communication controller of the aerial vehicle can control the actuator to beam horizontally polarized radiofrequency (RF) waves to a target receiver or receive a wave front from a target transmitter."
"MECHANICALLY STEERED AND HORIZONTALLY POLARIZED ANTENNA FOR AERIAL VEHICLES, AND ASSOCIATED SYSTEMS AND METHODS",https://lens.org/183-660-503-311-215,2019,"A mechanically steered, horizontally polarized, directional antennae for aerial vehicles, such as UAVs. The antenna system can include a planar substrate with a horizontally polarized antenna embedded therein. A rotation member, on one end, can be attached to the planar substrate, and can extend from an external surface of the aerial vehicle. An actuator can be coupled to the rotation member to rotate the rotation member. A communication controller of the aerial vehicle can control the actuator to beam horizontally polarized radiofrequency (RF) waves to a target receiver or receive a wave front from a target transmitter."
"MECHANICALLY STEERED AND HORIZONTALLY POLARIZED ANTENNA FOR AERIAL VEHICLES, AND ASSOCIATED SYSTEMS AND METHODS",https://lens.org/115-492-335-795-612,2017,"A mechanically steered, horizontally polarized, directional antennae for aerial vehicles, such as UAVs. The antenna system can include a planar substrate with a horizontally polarized antenna embedded therein. A rotation member, on one end, can be attached to the planar substrate, and can extend from an external surface of the aerial vehicle. An actuator can be coupled to the rotation member to rotate the rotation member. A communication controller of the aerial vehicle can control the actuator to beam horizontally polarized radiofrequency (RF) waves to a target receiver or receive a wave front from a target transmitter."
"Mechanically steered and horizontally polarized antenna for aerial vehicles, and associated systems and methods",https://lens.org/170-827-872-051-009,2020,"A mechanically steered, horizontally polarized, directional antennae for aerial vehicles, such as UAVs. The antenna system can include a planar substrate with a horizontally polarized antenna embedded therein. A rotation member, on one end, can be attached to the planar substrate, and can extend from an external surface of the aerial vehicle. An actuator can be coupled to the rotation member to rotate the rotation member. A communication controller of the aerial vehicle can control the actuator to beam horizontally polarized radiofrequency (RF) waves to a target receiver or receive a wave front from a target transmitter."
"Mechanically steered and horizontally polarized antenna for aerial vehicles, and associated systems and methods",https://lens.org/002-906-435-362-70X,2016,"A mechanically steered, horizontally polarized, directional antennae for aerial vehicles, such as UAVs. The antenna system can include a planar substrate with a horizontally polarized antenna embedded therein. A rotation member, on one end, can be attached to the planar substrate, and can extend from an external surface of the aerial vehicle. An actuator can be coupled to the rotation member to rotate the rotation member. A communication controller of the aerial vehicle can control the actuator to beam horizontally polarized radiofrequency (RF) waves to a target receiver or receive a wave front from a target transmitter."
"MECHANICALLY STEERED AND HORIZONTALLY POLARIZED ANTENNA FOR AERIAL VEHICLES, AND ASSOCIATED SYSTEMS AND METHODS",https://lens.org/052-320-095-154-220,2015,"A mechanically steered, horizontally polarized, directional antennae for aerial vehicles, such as UAVs. The antenna system can include a planar substrate with a horizontally polarized antenna embedded therein. A rotation member, on one end, can be attached to the planar substrate, and can extend from an external surface of the aerial vehicle. An actuator can be coupled to the rotation member to rotate the rotation member. A communication controller of the aerial vehicle can control the actuator to beam horizontally polarized radiofrequency (RF) waves to a target receiver or receive a wave front from a target transmitter."
"Mechanically steered and horizontally polarized antenna for aerial vehicles, and associated systems and methods",https://lens.org/149-857-287-945-18X,2021,"A mechanically steered, horizontally polarized, directional antennae for aerial vehicles, such as UAVs. The antenna system can include a planar substrate with a horizontally polarized antenna embedded therein. A rotation member, on one end, can be attached to the planar substrate, and can extend from an external surface of the aerial vehicle. An actuator can be coupled to the rotation member to rotate the rotation member. A communication controller of the aerial vehicle can control the actuator to beam horizontally polarized radiofrequency (RF) waves to a target receiver or receive a wave front from a target transmitter."
"MECHANICALLY STEERED AND HORIZONTALLY POLARIZED ANTENNA FOR AERIAL VEHICLES, AND ASSOCIATED SYSTEMS AND METHODS",https://lens.org/031-063-488-289-533,2020,"A mechanically steered, horizontally polarized, directional antennae for aerial vehicles, such as UAVs. The antenna system can include a planar substrate with a horizontally polarized antenna embedded therein. A rotation member, on one end, can be attached to the planar substrate, and can extend from an external surface of the aerial vehicle. An actuator can be coupled to the rotation member to rotate the rotation member. A communication controller of the aerial vehicle can control the actuator to beam horizontally polarized radiofrequency (RF) waves to a target receiver or receive a wave front from a target transmitter."
"Mechanically steered and horizontally polarized antenna for aerial vehicles, and associated systems and methods",https://lens.org/049-653-597-404-389,2018,"A mechanically steered, horizontally polarized, directional antennae for aerial vehicles, such as UAVs. The antenna system can include a planar substrate with a horizontally polarized antenna embedded therein. A rotation member, on one end, can be attached to the planar substrate, and can extend from an external surface of the aerial vehicle. An actuator can be coupled to the rotation member to rotate the rotation member. A communication controller of the aerial vehicle can control the actuator to beam horizontally polarized radiofrequency (RF) waves to a target receiver or receive a wave front from a target transmitter."
"UNMANNED AERIAL VEHICLE, UNMANNED AERIAL VEHICLE SYSTEM, AND BATTERY SYSTEM",https://lens.org/005-602-468-405-557,2020,"An unmanned aerial vehicle includes a main body, a propulsion assembly including a rotary blade and a motor to rotate the rotary blade about a rotation axis, the propulsion assembly being attached to the main body, a rechargeable battery to supply electric power to the propulsion assembly, a leg portion connected to the main body on a lower side of the main body in a vertical direction, and a power receiving coil to provide non-contact power feeding, the power receiving coil being electrically connected to the battery and being provided in the leg portion."
"Unmanned aerial vehicle, unmanned aerial vehicle system, and battery system",https://lens.org/162-335-701-929-197,2021,"An unmanned aerial vehicle includes a main body, a propulsion assembly including a rotary blade and a motor to rotate the rotary blade about a rotation axis, the propulsion assembly being attached to the main body, a rechargeable battery to supply electric power to the propulsion assembly, a leg portion connected to the main body on a lower side of the main body in a vertical direction, and a power receiving coil to provide non-contact power feeding, the power receiving coil being electrically connected to the battery and being provided in the leg portion."
Systems and methods for providing dynamic communicative lighting in a robotic environment,https://lens.org/092-420-991-575-655,2019,"A robotic system is disclosed that includes an articulated arm with an end effector. The robotic system is for use in a robotic environment requiring interaction with persons in the robotic environment, and includes a plurality of lights that are illuminated responsive to known near-future movements of the articulated arm to convey the known near-future movements of the articulated arm to the persons in the robot environment."
Systems and methods for providing dynamic communicative lighting in a robotic environment,https://lens.org/162-559-325-126-405,2021,"A robotic system is disclosed that includes an articulated arm with an end effector. The robotic system is for use in a robotic environment requiring interaction with persons in the robotic environment, and includes a plurality of lights that are illuminated responsive to known near-future movements of the articulated arm to convey the known near-future movements of the articulated arm to the persons in the robot environment."
SYSTEMS AND METHODS FOR PROVIDING DYNAMIC COMMUNICATIVE LIGHTING IN A ROBOTIC ENVIRONMENT,https://lens.org/173-637-804-401-38X,2021,"A robotic system is disclosed that includes an articulated arm with an end effector. The robotic system is for use in a robotic environment requiring interaction with persons in the robotic environment, and includes a plurality of lights that are illuminated responsive to known near-future movements of the articulated arm to convey the known near-future movements of the articulated arm to the persons in the robot environment."
SYSTEMS AND METHODS FOR PROVIDING DYNAMIC COMMUNICATIVE LIGHTING IN A ROBOTIC ENVIRONMENT,https://lens.org/156-750-548-507-107,2020,"A robotic system is disclosed that includes an articulated arm with an end effector. The robotic system is for use in a robotic environment requiring interaction with persons in the robotic environment, and includes a plurality of lights that are illuminated responsive to known near-future movements of the articulated arm to convey the known near-future movements of the articulated arm to the persons in the robot environment."
Systems and methods for providing dynamic communicative lighting in a robotic environment,https://lens.org/183-899-473-140-770,2020,"A robotic system is disclosed that includes an articulated arm with an end effector. The robotic system is for use in a robotic environment requiring interaction with persons in the robotic environment, and includes a plurality of lights that are illuminated responsive to known near-future movements of the articulated arm to convey the known near-future movements of the articulated arm to the persons in the robot environment."
MOBILE DEVICE WITH GRAPHICAL USER INTERFACE FOR MONITORING A BUILDING AUTOMATION SYSTEM,https://lens.org/072-457-795-421-900,2014,"A mobile device with a graphical user interface (GUI) for remotely monitoring and/or remotely interacting with a configurable building automation systems (BAS). In particular, the mobile device receives status data from the BAS, the GUI displays the status data on the mobile device, and the GUI allows a user to interact with the BAS."
"INFORMATION PROCESSING SYSTEM, METHOD FOR PRESENTING DELIVERY SERVICE DETAIL, AND PROGRAM",https://lens.org/034-673-185-155-738,2023,"The control unit 16 of the UAV 1 detects the UAV 50 as a search target on the basis of the sensing data obtained by sensing of the sensor unit 14, and moves the UAV 1 to a position above the detected UAV 50. Then, the control unit 16 identifies a current position of the UAV 1 when the UAV 1 has moved to the position above the UAV 50, and transmits search position information indicating the identified current position as the current position of the UAV 50."
"INFORMATION PROCESSING SYSTEM, METHOD FOR PRESENTING DELIVERY SERVICE DETAIL, AND PROGRAM",https://lens.org/034-673-185-155-738,2023,"The control unit 16 of the UAV 1 detects the UAV 50 as a search target on the basis of the sensing data obtained by sensing of the sensor unit 14, and moves the UAV 1 to a position above the detected UAV 50. Then, the control unit 16 identifies a current position of the UAV 1 when the UAV 1 has moved to the position above the UAV 50, and transmits search position information indicating the identified current position as the current position of the UAV 50."
Systems and methods for autonomous landing using a three dimensional evidence grid,https://lens.org/040-900-031-595-41X,2015,"Abstract A method for autonomous landing of an unmanned aerial vehicle (UAV) comprising: obtaining sensor data corresponding to one or more objects outside of the aircraft using at least one onboard sensor; using the sensor data to create a three dimensional evidence grid, wherein a three dimensional evidence grid is a three dimensional world model based on the sensor data; combining a priori data with the three dimensional evidence grid; locating a landing zone based on the combined three dimensional evidence grid and a priori data; validating an open spots in the landing zone, wherein validating includes performing surface condition assessment of a surface of the open spots; generating landing zone motion characterization, wherein landing zone motion characterization includes characterizing real time landing zone pitching, heaving, rolling or forward motion; processing the three dimensional evidence grid data to generate flight controls to land the aircraft in one of the open spots. Use sensor data from onboard sensors to create a 3D 101 Evidence Grid Use a priori data to create a historical evidence grid 103 Combine a priori data with 3D evidence grid 105 Locate a ship or landing zone 107 Validate open spots in landing zone 109 Process evidence grid data to generate flight controls 111 Match approach motion with deck motion 113"
UNMANNED AERIAL VEHICLE AND METHOD OF USING A PLURALITY OF UNMANNED AERIAL VEHICLES TO SHOW A FEELING EFFECT,https://lens.org/022-228-917-526-004,2018,"An unmanned aerial vehicle including a feeling-effect showing device is provided. The feeling-effect showing device is adapted for showing a feeling effect such as a visual effect and/or an audio effect. In addition, a method of using a plurality of unmanned aerial vehicles to show a feeling effect is also provided."
Airborne collection of acoustic data using an unmanned aerial vehicle,https://lens.org/192-471-117-511-001,2005,"An acoustic data collection system that uses an antenna array aboard a powered unmanned and remotely controlled parafoil. The antenna array has multiple microphone elements, whose outputs are combined to provide directionality to the data acquisition."
AIRBORNE COLLECTION OF ACOUSTIC DATA USING AN UNMANNED AERIAL VEHICLE,https://lens.org/051-368-335-328-098,2009,"An acoustic data collection system that uses an antenna array aboard a powered unmanned and remotely controlled parafoil. The antenna array has multiple microphone elements, whose outputs are combined to provide directionality to the data acquisition."
AIRBORNE COLLECTION OF ACOUSTIC DATA USING AN UNMANNED AERIAL VEHICLE,https://lens.org/012-485-517-514-236,2005,"An acoustic data collection system that uses an antenna array aboard a powered unmanned and remotely controlled parafoil. The antenna array has multiple microphone elements, whose outputs are combined to provide directionality to the data acquisition."
UNMANNED AERIAL VEHICLE,https://lens.org/114-518-479-082-941,2018,"An unmanned aerial vehicle includes a plurality of arm units, each having a rotary wing, a motor, and an arm main body and detachably coupled to a main body; the main body having a plurality of receptacles for coupling to the arm units; and a battery unit detachably coupled to the main body to be exposed to outside, in which at least a part of the battery unit is exposed to outside when the battery unit is coupled to the main body."
Unmanned aerial vehicle,https://lens.org/104-818-292-555-368,2018,"An unmanned aerial vehicle includes a plurality of arm units, each having a rotary wing, a motor, and an arm main body and detachably coupled to a main body; the main body having a plurality of receptacles for coupling to the arm units; and a battery unit detachably coupled to the main body to be exposed to outside, in which at least a part of the battery unit is exposed to outside when the battery unit is coupled to the main body."
SYSTEM AND METHOD FOR SURGICAL INSTRUMENT USE PREDICTION,https://lens.org/188-858-937-805-98X,2023,A surgical robotic system includes a controller configured to access usage data pertaining to a surgical instrument and to estimate a predicted number of uses remaining for the surgical instrument. The controller is further configured to enable or disable the surgical instrument based on the predicted number of uses remaining.
SYSTEM AND METHOD FOR SURGICAL INSTRUMENT USE PREDICTION,https://lens.org/188-858-937-805-98X,2023,A surgical robotic system includes a controller configured to access usage data pertaining to a surgical instrument and to estimate a predicted number of uses remaining for the surgical instrument. The controller is further configured to enable or disable the surgical instrument based on the predicted number of uses remaining.
DRONE BOX,https://lens.org/040-511-101-061-634,2018,"The application provides a storage unit for an Unmanned Aerial Vehicle (UAV). The storage unit includes a container, a UAV landing platform, and a receptacle. The container is provided for enclosing the UAV. The receptacle is positioned above the UAV landing platform and it includes at least one inclined surface for guiding a landing UAV to a predetermined UAV landing position on the UAV landing platform."
Radio control transmissions,https://lens.org/042-684-380-905-593,2018,"An object, such as an unmanned aerial, terrestrial or marine vehicle (UAV, UTV, UMV) or drone, travelling to a zone is detected by scanning frequency bands of radio frequency (RF) signals, mixing the RF signals, in duplicate, with first and second local oscillator signals, which may be 90 degrees out of phase, provided by a phase locked loop, filtering, in duplicate, with a narrow-band filter, amplifying, in duplicate and generating, via an RF power detector, an analog measure of RF signal power. An RF signature is generated and compared to known radio control (RC) communication protocols to determine the RC communication protocol used by the object and the detected object is engaged by transmitting an interference signal in synchrony with the RC communication protocol of the object. The interference signal may be transmitted at a frequency and timing associated with a frequency hopping scheme of the RC communication protocol used by the object."
Accommodating mobile destinations for unmanned aerial vehicles,https://lens.org/127-787-379-354-054,2018,"A device receives a request for a flight path for a UAV to travel from a location to an anticipated location associated with a mobile device, and determines capability information for the UAV based on component information associated with the UAV. The device receives information associated with a current location, a direction of travel, and a speed of the mobile device, and calculates the flight path from the location to the anticipated location associated with the mobile device based on the capability information and based on the information associated with the current location, the direction of travel, and the speed of the mobile device. The device generates flight path instructions for the flight path, and provides the flight path instructions to the UAV to permit the UAV to travel from the location to the anticipated location associated with the mobile device, based on the flight path instructions."
ACCOMMODATING MOBILE DESTINATIONS FOR UNMANNED AERIAL VEHICLES,https://lens.org/194-825-083-112-931,2017,"A device receives a request for a flight path for a UAV to travel from a location to an anticipated location associated with a mobile device, and determines capability information for the UAV based on component information associated with the UAV. The device receives information associated with a current location, a direction of travel, and a speed of the mobile device, and calculates the flight path from the location to the anticipated location associated with the mobile device based on the capability information and based on the information associated with the current location, the direction of travel, and the speed of the mobile device. The device generates flight path instructions for the flight path, and provides the flight path instructions to the UAV to permit the UAV to travel from the location to the anticipated location associated with the mobile device, based on the flight path instructions."
ACCOMMODATING MOBILE DESTINATIONS FOR UNMANNED AERIAL VEHICLES,https://lens.org/063-613-678-221-657,2016,"A device receives a request for a flight path for a UAV to travel from a location to an anticipated location associated with a mobile device, and determines capability information for the UAV based on component information associated with the UAV. The device receives information associated with a current location, a direction of travel, and a speed of the mobile device, and calculates the flight path from the location to the anticipated location associated with the mobile device based on the capability information and based on the information associated with the current location, the direction of travel, and the speed of the mobile device. The device generates flight path instructions for the flight path, and provides the flight path instructions to the UAV to permit the UAV to travel from the location to the anticipated location associated with the mobile device, based on the flight path instructions."
ROBOT DEVICE AND METHOD FOR CONTROLLING THE SAME,https://lens.org/090-707-199-954-964,2000,"A robot device in which information is captured from external, a specific object is detected by using the information, whether or not the object, if detected, fulfills a predetermined condition is judged, and the robot device is instructed to make a predetermined motion according to the result of the judgment. The robot can make a biologically natural motion, enhancing the amusability. A method for controlling such a robot device is also disclosed."
Toy with remotely controlled security alarm,https://lens.org/198-824-403-412-695,2000,"A security alarm device is replicated in a toy vehicle. The security device includes a remote control which also can control vehicle functions. The remote control may control alarm arm and disarm, alarm and vehicle sounds such as arm, disarm, alarm set off, engine revving, tire screeching, motor drive, and vehicle lights. The security alarm device includes an LED which indicates whether the alarm is armed or unarmed, and a motion sensor which sets the alarm off (e.g., emitting a siren sound) when the toy vehicle is moved in its armed state."
Toy with remotely controlled security alarm,https://lens.org/063-596-123-614-367,2006,"A security alarm device is replicated in a toy vehicle. The security device includes a remote control which also can control vehicle functions. The remote control may control alarm arm and disarm, alarm and vehicle sounds such as arm, disarm, alarm set off, engine revving, tire screeching, motor drive, and vehicle lights. The security alarm device includes an LED which indicates whether the alarm is armed or unarmed, and a motion sensor which sets the alarm off (e.g., emitting a siren sound) when the toy vehicle is moved in its armed state."
COMMUNICATION SYSTEM,https://lens.org/071-676-486-006-301,2022,"A communication system according to one embodiment comprises: a communication device including a tracking unit which rotates with respect to a first axis, a second axis, and a third axis that are orthogonal to each other and which performs radio-wave communication with a moving object moving within the field of view; and a controller for controlling the communication device so that the tracking unit rotates with respect to the first axis and the second axis in the range of a first trajectory angle of the moving body and rotates with respect to the second axis and the third axis in the range of a second trajectory angle of the moving object."
HYBRID UNMANNED AERIAL VEHICLE,https://lens.org/186-916-024-646-232,2021,"A hybrid unmanned aerial vehicle (UAV) (100) is disclosed that comprises a body, at least one battery (120) disposed in a dedicated space (220) of the body and at least one electrical motor for operating at least one propeller (110) of the UAV. The at least one electrical motor is configured to operate on the energy provided by the at least one battery (120). The UAV comprises a liquid or gaseous fuel powered, and liquid cooled power generator (130) for charging the at least one battery (120). A coolant circulator pump (330) circulates liquid coolant of the power generator (130) in a closed circulation loop (331, 332, 115) configured to conduct heat away from the power generator (130), and a radiator (115) is configured to transfer thermal energy from the liquid coolant to air passing through the radiator. The UAV further comprises a configurable deflector frame (170) disposed adjacent to the radiator (115) and configured to deflect the heated air flow (360) from the radiator. The configurable deflector frame is selectively configurable for deflecting said heated air flow away from the body (200) of the UAV when ambient temperature is in a first temperature range in which performance of the at least one battery (120) is at or near nominal, and for deflecting said heated air flow (360) towards said dedicated space (220) for warming up the at least one battery when ambient temperature is in a second temperature range in which performance of the at least one battery would otherwise become lowered, wherein the second temperature range is below said first temperature range. A corresponding method for operating a UAV is also disclosed."
Control and Navigation Device for an Autonomously Moving System and Autonomously Moving System,https://lens.org/067-717-730-334-707,2023,"The invention relates to a control and navigation device for an autonomously moving system, which comprises the following: a sensor device, which is configured to acquire sensor data, and for this purpose a LiDAR sensor installation, which is configured for 360-degree acquisition; a fisheye camera installation, which is configured for 360-degree acquisition; and a radar sensor installation, which is configured for 360-degree acquisition; a data processing installation with an AI-based software application, which is configured to determine control signals for purposes of navigating an autonomously moving system by means of processing of the sensor data; and a data communication interface, which is connected to the data processing installation, and is configured to provide the control signals for transmission to a controller of the autonomously moving system. The sensor device, the data processing installation, and the data communication interface are arranged at an assembly component, which is configured to assemble, in a detachable manner, the sensor device, the data processing installation, and the data communication interface together as a common module at the autonomously moving system. Furthermore, an autonomously moving system is provided."
Control and Navigation Device for an Autonomously Moving System and Autonomously Moving System,https://lens.org/067-717-730-334-707,2023,"The invention relates to a control and navigation device for an autonomously moving system, which comprises the following: a sensor device, which is configured to acquire sensor data, and for this purpose a LiDAR sensor installation, which is configured for 360-degree acquisition; a fisheye camera installation, which is configured for 360-degree acquisition; and a radar sensor installation, which is configured for 360-degree acquisition; a data processing installation with an AI-based software application, which is configured to determine control signals for purposes of navigating an autonomously moving system by means of processing of the sensor data; and a data communication interface, which is connected to the data processing installation, and is configured to provide the control signals for transmission to a controller of the autonomously moving system. The sensor device, the data processing installation, and the data communication interface are arranged at an assembly component, which is configured to assemble, in a detachable manner, the sensor device, the data processing installation, and the data communication interface together as a common module at the autonomously moving system. Furthermore, an autonomously moving system is provided."
UNMANNED AERIAL VEHICLE (UAV) AND A SYSTEM FOR MONITORING AND MAINTAINING LUMINAIRES USING THE UAV,https://lens.org/109-965-756-433-740,2020,"A system for monitoring and maintaining luminaires using an unmanned aerial vehicle. The system comprises one or more luminaires, a computing device and one or more Unmanned Aerial Vehicle. The computing device receives the information about the working condition of the one or more luminaires accordingly generate a command for a UAV of the one or more UAVs to diagnose and identify one or more issues with the one or more luminaires causing the faulty condition."
REMOTE CONTROL ALARM DEVICE,https://lens.org/056-608-319-932-721,1985,"A remotely controlled alarm device is disclosed, comprising a box-shaped casing. The two side walls of the casing are each provided with visual alerting components, and the front wall is provided with an auditory alerting component. The casing contains a power source and a control box electrically connected to the power source and to the alerting components. The casing further contains a radio receiver adapted to switch on the alerting components from a considerable distance away from the device. The receiver is activated by a pocket-sized radio emitter."
On-demand designated delivery locator,https://lens.org/033-090-184-326-557,2018,"Delivery area guidance may be provided to an unmanned aerial vehicle (UAV) delivering a package to a customer. For example, a UAV may be programmed to fly to a delivery area. When the UAV approaches the delivery area, the UAV may send a signal that it has a package for the customer. A delivery area guidance (DAG) device associated with the customer may receive the signal and project a visible landing marker to guide the UAV to a designated delivery location. The DAG device may monitor motion near the designated delivery location, indicate existence of obstacles, and/or notify inhabitance of the approach of the UAV and/or receipt of the package."
NAVIGABLE 3D VIEW OF A PREMISES ALARM EVENT,https://lens.org/150-794-689-702-439,2023,"A control device for a premises security system is provided. The control device includes processing circuitry configured to receive a plurality of video streams associated with the plurality of image capture devices, stitch together at least a portion of the plurality of video streams to generate a three-dimensional (3D) view, determine an alarm event associated with the premises security system, and overlay at least one virtual object onto the 3D view, where the at least one virtual object indicates the alarm event and data associated with the alarm event."
"APPARATUS, SYSTEMS AND METHODS FOR PAIRING A CONTROLLED DEVICE WITH AN RF REMOTE CONTROL USING AN RFID TAG",https://lens.org/059-687-710-369-457,2012,"Systems and methods are operable to initiate a pairing process and a de-pairing process between a controlled device and a radio frequency (RF) remote control. An exemplary embodiment detects presence of a radio frequency identifier (RFID) tag in an interrogation zone established by an RFID tag reader, automatically initiates a pairing process in response to detecting the presence of the RFID tag in the interrogation zone, and completes the pairing process between the RF remote control and the controlled device, wherein the pairing process identifies a unique identifier associated with the RF remote control. A subsequently received RF signal emitted by the RF remote control includes at least one command configured to control operation of the controlled device and includes the unique identifier."
"Apparatus, systems and methods for pairing a controlled device with an RF remote control using an RFID tag",https://lens.org/095-844-055-830-80X,2016,"Systems and methods are operable to initiate a pairing process and a de-pairing process between a controlled device and a radio frequency (RF) remote control. An exemplary embodiment detects presence of a radio frequency identifier (RFID) tag in an interrogation zone established by an RFID tag reader, automatically initiates a pairing process in response to detecting the presence of the RFID tag in the interrogation zone, and completes the pairing process between the RF remote control and the controlled device, wherein the pairing process identifies a unique identifier associated with the RF remote control. A subsequently received RF signal emitted by the RF remote control includes at least one command configured to control operation of the controlled device and includes the unique identifier."
"APPARATUS, SYSTEMS AND METHODS FOR PAIRING A CONTROLLED DEVICE WITH AN RF REMOTE CONTROL USING AN RFID TAG",https://lens.org/036-054-793-187-311,2015,"Systems and methods are operable to initiate a pairing process and a de-pairing process between a controlled device and a radio frequency (RF) remote control. An exemplary embodiment detects presence of a radio frequency identifier (RFID) tag in an interrogation zone established by an RFID tag reader, automatically initiates a pairing process in response to detecting the presence of the RFID tag in the interrogation zone, and completes the pairing process between the RF remote control and the controlled device, wherein the pairing process identifies a unique identifier associated with the RF remote control. A subsequently received RF signal emitted by the RF remote control includes at least one command configured to control operation of the controlled device and includes the unique identifier."
"APPARATUS, SYSTEMS AND METHODS FOR PAIRING A CONTROLLED DEVICE WITH AN RF REMOTE CONTROL USING AN RFID TAG",https://lens.org/061-733-106-850-056,2012,"Systems and methods are operable to initiate a pairing process and a de-pairing process between a controlled device and a radio frequency (RF) remote control. An exemplary embodiment detects presence of a radio frequency identifier (RFID) tag in an interrogation zone established by an RFID tag reader, automatically initiates a pairing process in response to detecting the presence of the RFID tag in the interrogation zone, and completes the pairing process between the RF remote control and the controlled device, wherein the pairing process identifies a unique identifier associated with the RF remote control. A subsequently received RF signal emitted by the RF remote control includes at least one command configured to control operation of the controlled device and includes the unique identifier."
"Apparatus, systems and methods for pairing a controlled device with an RF remote control using an RFID tag",https://lens.org/081-140-476-546-31X,2013,"Systems and methods are operable to initiate a pairing process and a de-pairing process between a controlled device and a radio frequency (RF) remote control. An exemplary embodiment detects presence of a radio frequency identifier (RFID) tag in an interrogation zone established by an RFID tag reader, automatically initiates a pairing process in response to detecting the presence of the RFID tag in the interrogation zone, and completes the pairing process between the RF remote control and the controlled device, wherein the pairing process identifies a unique identifier associated with the RF remote control. A subsequently received RF signal emitted by the RF remote control includes at least one command configured to control operation of the controlled device and includes the unique identifier."
"APPARATUS, SYSTEMS AND METHODS FOR PAIRING A CONTROLLED DEVICE WITH AN RF REMOTE CONTROL USING AN RFID TAG",https://lens.org/187-875-363-105-818,2013,"Systems and methods are operable to initiate a pairing process and a de-pairing process between a controlled device and a radio frequency (RF) remote control. An exemplary embodiment detects presence of a radio frequency identifier (RFID) tag in an interrogation zone established by an RFID tag reader, automatically initiates a pairing process in response to detecting the presence of the RFID tag in the interrogation zone, and completes the pairing process between the RF remote control and the controlled device, wherein the pairing process identifies a unique identifier associated with the RF remote control. A subsequently received RF signal emitted by the RF remote control includes at least one command configured to control operation of the controlled device and includes the unique identifier."
UNDERWATER DRONE WITH CAPACITY OF MULTI-SHOOTING VIEW,https://lens.org/106-847-138-875-73X,2019,"An underwater drone is disclosed and includes a drone body (1), a first image capturing module (3) and an image reflecting module (4). An accommodating chamber (10) is formed in the drone body (1). The first image capturing module (3) is disposed in the accommodating chamber (10) and for capturing an image of a first object which is located on a first outer side out of the drone body (1). The image reflecting module (4) is disposed in the accommodating chamber (10) and for reflecting the image of the first object to the first image capturing module (4). Thus, the underwater drone is equipped with multiple image capturing modules (2, 3) for multi-shooting view."
Apparatus and method for calling mobile robot,https://lens.org/060-762-798-364-29X,2010,"An apparatus for calling a mobile robot includes a generator installed at a remote controller, and generating an RF signal and infrared signal for calling a mobile robot when a call signal is inputted by a user; and a controller installed at the mobile robot, calculating a direction of the remote controller based on a position of an infrared ray receiver that receives the infrared signal when an RF signal is received, rotating the mobile robot in the calculated direction, and then making the mobile robot to go straight ahead. When a user calls the mobile robot from a specific place, the mobile robot can move by itself to the specific space, thereby enhancing users' convenience."
Apparatus and method for calling mobile robot,https://lens.org/129-475-042-509-030,2006,"An apparatus for calling a mobile robot includes a generator installed at a remote controller, and generating an RF signal and infrared signal for calling a mobile robot when a call signal is inputted by a user; and a controller installed at the mobile robot, calculating a direction of the remote controller based on a position of an infrared ray receiver that receives the infrared signal when an RF signal is received, rotating the mobile robot in the calculated direction, and then making the mobile robot to go straight ahead. When a user calls the mobile robot from a specific place, the mobile robot can move by itself to the specific space, thereby enhancing users' convenience."
"POSITION ACQUISITION CONTROL METHOD, USER TERMINAL AND DEVICE",https://lens.org/100-753-419-873-25X,2020,"A method of controlling a location acquisition, a user terminal and a device are provided. The method includes: determining whether a predetermined condition is satisfied; in the case that the predetermined condition is satisfied, sending control information configured to control a relevant behavior of acquiring a location of the user terminal."
Autonomous fall monitor having sensor compensation,https://lens.org/124-324-647-509-850,2019,"A communicator for autonomous monitoring, detecting, and tracking of movement and orientation of a portion of a body of a wearer is disclosed. The communicator includes a sensor configured to detect a translational and/or rotational movement of the portion of the body of the wearer; an altimeter to measure changes in altitude of the portion of the body of the wearer; and a processor configured to determine an orientation and/or position of the portion of the body of the wearer. The processor further configured to compensate for the measured changes in altitude. The sensor is implemented at least by one of the following: accelerometer(s), gyroscope(s), and/or magnetometer(s)."
AUTONOMOUS FALL MONITOR HAVING SENSOR COMPENSATION,https://lens.org/147-326-713-733-273,2018,"A communicator for autonomous monitoring, detecting, and tracking of movement and orientation of a portion of a body of a wearer is disclosed. The communicator includes a sensor configured to detect a translational and/or rotational movement of the portion of the body of the wearer; an altimeter to measure changes in altitude of the portion of the body of the wearer; and a processor configured to determine an orientation and/or position of the portion of the body of the wearer. The processor further configured to compensate for the measured changes in altitude. The sensor is implemented at least by one of the following: accelerometer(s), gyroscope(s), and/or magnetometer(s)."
AUTONOMOUS FALL MONITOR HAVING SENSOR COMPENSATION,https://lens.org/060-924-239-668-851,2018,"A communicator for autonomous monitoring, detecting, and tracking of movement and orientation of a portion of a body of a wearer is disclosed. The communicator includes a sensor configured to detect a translational and/or rotational movement of the portion of the body of the wearer; an altimeter to measure changes in altitude of the portion of the body of the wearer; and a processor configured to determine an orientation and/or position of the portion of the body of the wearer. The processor further configured to compensate for the measured changes in altitude. The sensor is implemented at least by one of the following: accelerometer(s), gyroscope(s), and/or magnetometer(s)."
COMPACT UNMANNED AERIAL VEHICLE,https://lens.org/056-815-256-375-236,2009,"A UAV having an airframe supporting a tri-rotor triangular array, each tri-rotor comprising a pair of rotors (21,23) on the same axis, withan individual motor (20,22) for each rotor, the pairs of rotors being arrangedto contra-rotate."
UNMANNED AERIAL VEHICLE WITH PROTECTIVE OUTER CAGE,https://lens.org/004-264-758-475-515,2021,"Unmanned aerial vehicle (UAV) including an inner frame, an inner flight propulsion system mounted on the inner frame, an outer frame, a gimbal system comprising at least two rotational couplings coupling the inner propulsion system to the outer frame, a control system, a power source, and an outer frame actuation system configured to actively orient the outer frame with respect to the inner frame."
Unmanned aerial vehicle with protective outer cage,https://lens.org/003-680-756-758-454,2023,"Unmanned aerial vehicle (UAV) including an inner frame, an inner flight propulsion system mounted on the inner frame, an outer frame, a gimbal system comprising at least two rotational couplings coupling the inner propulsion system to the outer frame, a control system, a power source, and an outer frame actuation system configured to actively orient the outer frame with respect to the inner frame."
Aerial Photographing System,https://lens.org/019-719-680-304-494,2014,"An aerial photographing system, comprising a flying vehicle being remotely controlled, a camera (7, 8) tiltably supported in any direction via a gimbal (25), a retro-reflector (9) tilting integrally with the camera, being set in a known relation with the camera and used as an object to be measured, and a total station (3) for tracking the retro-reflector and for measuring position of the retro-reflector."
Aerial photographing system,https://lens.org/146-555-536-124-049,2016,"An aerial photographing system, comprising a flying vehicle being remotely controlled, a camera (7, 8) tiltably supported in any direction via a gimbal (25), a retro-reflector (9) tilting integrally with the camera, being set in a known relation with the camera and used as an object to be measured, and a total station (3) for tracking the retro-reflector and for measuring position of the retro-reflector."
Unmanned aerial system with transportable screen,https://lens.org/031-517-461-502-49X,2020,"An unmanned aerial system (UAS) that displays an image, video or other effect is described. The UAS may include a camera that captures the image for display. The UAS may be used in connection with a water display, and multiple UASs may operate together."
Unmanned Aerial System With Transportable Screen,https://lens.org/060-906-965-389-225,2017,"An unmanned aerial system (UAS) that displays an image, video or other effect is described. The UAS may include a camera that captures the image for display. The UAS may be used in connection with a water display, and multiple UASs may operate together."
UNMANNED AERIAL SYSTEM WITH TRANSPORTABLE SCREEN,https://lens.org/143-258-034-653-856,2017,"An unmanned aerial system (UAS) that displays an image, video or other effect is described. The UAS may include a camera that captures the image for display. The UAS may be used in connection with a water display, and multiple UASs may operate together."
Autonomous anonymity,https://lens.org/195-848-824-449-004,2019,An autonomous anonymity system includes a universal access transceiver. The universal access transceiver is designed and arranged to selectively provide a notification when autonomous aircraft operation is authorized.
AUTONOMOUS ANONYMITY,https://lens.org/066-503-160-937-994,2020,An autonomous anonymity system includes a universal access transceiver. The universal access transceiver is designed and arranged to selectively provide a notification when autonomous aircraft operation is authorized.
Electronic apparatus and WiFi connecting method thereof,https://lens.org/145-135-033-423-170,2021,"A voice assistant of an electronic apparatus receives a user voice requesting connection of WiFi communication between an external electronic apparatus and an access point, transmits authentication information for authentication of the external electronic apparatus to be displayed on the external electronic apparatus, and based on receiving a user voice corresponding to the authentication information being displayed, transmits connection information for establishing the WiFi communication to the external electronic apparatus."
ELECTRONIC APPARATUS AND WIFI CONNECTING METHOD THEREOF,https://lens.org/044-628-010-613-979,2020,"A voice assistant of an electronic apparatus receives a user voice requesting connection of WiFi communication between an external electronic apparatus and an access point, transmits authentication information for authentication of the external electronic apparatus to be displayed on the external electronic apparatus, and based on receiving a user voice corresponding to the authentication information being displayed, transmits connection information for establishing the WiFi communication to the external electronic apparatus."
ELECTRONIC APPARATUS AND WIFI CONNECTING METHOD THEREOF,https://lens.org/044-628-010-613-979,2020,"A voice assistant of an electronic apparatus receives a user voice requesting connection of WiFi communication between an external electronic apparatus and an access point, transmits authentication information for authentication of the external electronic apparatus to be displayed on the external electronic apparatus, and based on receiving a user voice corresponding to the authentication information being displayed, transmits connection information for establishing the WiFi communication to the external electronic apparatus."
Robot System,https://lens.org/128-895-459-144-326,2019,"A robot system includes a robot and a network device, and in which the robot includes a first network controller including a first network terminal configured to connect to the network device and a second network controller including a second network terminal configured to connect to the network device and the same first network information is set in the first network controller and the second network controller."
SMALL UAS WITH HIGH DEFINITION VIDEO,https://lens.org/058-316-604-840-306,2014,A sensor system comprising specific subassemblies provides high definition video in small unmanned aerial systems. The sensor system provides for efficient space and power utilization.
SMALL UAS WITH HIGH DEFINITION VIDEO,https://lens.org/005-743-149-695-998,2014,A sensor system comprising specific subassemblies provides high definition video in small unmanned aerial systems. The sensor system provides for efficient space and power utilization.
SMALL UAS WITH HIGH DEFINITION VIDEO,https://lens.org/087-571-836-128-529,2014,A sensor system comprising specific subassemblies provides high definition video in small unmanned aerial systems. The sensor system provides for efficient space and power utilization.
Small UAS With High Definition Video,https://lens.org/124-342-567-437-024,2015,A sensor system comprising specific subassemblies provides high definition video in small unmanned aerial systems. The sensor system provides for efficient space and power utilization.
MANAGING ENGAGEMENT METHODS OF A DIGITAL ASSISTANT WHILE COMMUNICATING WITH A USER OF THE DIGITAL ASSISTANT,https://lens.org/199-559-644-472-287,2023,"A method for interacting by a digital assistant with a user of the digital assistant, comprising: determining by the digital assistant an action to be executed by the digital assistant, wherein the action is determined based on at least a sensed current state of the user and a sensed current state of an environment near the user; selecting an engagement method from a plurality of engagement methods based on the current state of the user, the current state of an environment near the user, and the selected action; generating a customized plan for executing the selected action based on at least the selected engagement method; and executing the generated plan by employing an input/output (I/O) device on which the digital assistant is executing."
CONTROLLING AUTONOMOUS VEHICLES IN CONNECTION WITH TRANSPORT SERVICES,https://lens.org/114-684-460-151-576,2017,"Systems for controlling autonomous vehicles are disclosed. Using one or more location detection resources, the system can receive vehicle data from an autonomous vehicle as the autonomous vehicle progresses towards a pickup location of a requesting user and receive requester data from a mobile computing device of the requester. The system can determine when the autonomous vehicle and the requester are at or within a threshold distance of the pickup location. Subsequently, the system can instruct the autonomous vehicle to perform one or more non-driving operations to facilitate use of the autonomous vehicle by the requester."
CONTROLLING AUTONOMOUS VEHICLES IN CONNECTION WITH TRANSPORT SERVICES,https://lens.org/003-024-235-356-999,2022,"Systems for controlling autonomous vehicles are disclosed. Using one or more location detection resources, the system can receive vehicle data from an autonomous vehicle as the autonomous vehicle progresses towards a pickup location of a requesting user and receive requester data from a mobile computing device of the requester. The system can determine when the autonomous vehicle and the requester are at or within a threshold distance of the pickup location. Subsequently, the system can instruct the autonomous vehicle to perform one or more non-driving operations to facilitate use of the autonomous vehicle by the requester."
Controlling autonomous vehicles in connection with transport services,https://lens.org/179-886-007-134-00X,2018,"Systems for controlling autonomous vehicles are disclosed. Using one or more location detection resources, the system can receive vehicle data from an autonomous vehicle as the autonomous vehicle progresses towards a pickup location of a requesting user and receive requester data from a mobile computing device of the requester. The system can determine when the autonomous vehicle and the requester are at or within a threshold distance of the pickup location. Subsequently, the system can instruct the autonomous vehicle to perform one or more non-driving operations to facilitate use of the autonomous vehicle by the requester."
CONTROLLING AUTONOMOUS VEHICLES IN CONNECTION WITH TRANSPORT SERVICES,https://lens.org/003-024-235-356-999,2022,"Systems for controlling autonomous vehicles are disclosed. Using one or more location detection resources, the system can receive vehicle data from an autonomous vehicle as the autonomous vehicle progresses towards a pickup location of a requesting user and receive requester data from a mobile computing device of the requester. The system can determine when the autonomous vehicle and the requester are at or within a threshold distance of the pickup location. Subsequently, the system can instruct the autonomous vehicle to perform one or more non-driving operations to facilitate use of the autonomous vehicle by the requester."
Controlling autonomous vehicles in connection with transport services,https://lens.org/091-562-704-409-513,2021,"Systems for controlling autonomous vehicles are disclosed. Using one or more location detection resources, the system can receive vehicle data from an autonomous vehicle as the autonomous vehicle progresses towards a pickup location of a requesting user and receive requester data from a mobile computing device of the requester. The system can determine when the autonomous vehicle and the requester are at or within a threshold distance of the pickup location. Subsequently, the system can instruct the autonomous vehicle to perform one or more non-driving operations to facilitate use of the autonomous vehicle by the requester."
Controlling autonomous vehicles in connection with transport services,https://lens.org/022-613-322-074-599,2018,"Systems for controlling autonomous vehicles are disclosed. Using one or more location detection resources, the system can receive vehicle data from an autonomous vehicle as the autonomous vehicle progresses towards a pickup location of a requesting user and receive requester data from a mobile computing device of the requester. The system can determine when the autonomous vehicle and the requester are at or within a threshold distance of the pickup location. Subsequently, the system can instruct the autonomous vehicle to perform one or more non-driving operations to facilitate use of the autonomous vehicle by the requester."
Drone Landing System,https://lens.org/148-456-645-612-948,2022,"A drone landing system comprises a first landing surface 104 parallel to and fast with a second landing surface 110 (the landing surfaces are arranged back-to-back and unitary or rigidly joined). Securing means (e.g. electromagnet(s) and/or mechanically engaging means, e.g. rotatable hooks, slidable bars) releasably secure a drone 130 to the first landing surface. A rotation mechanism revolves the landing surfaces between a first position in which the first landing surface is exposed to receive a drone and a second position in which the first landing surface is within a housing. The first landing surface, together with the attached first UAV, may be rotated by 180 degrees, exposing the second landing surface to receive a second drone. A deployable concertina cover may protect landing surfaces from rain. A robotic arm (156, figure 5A) may reposition a drone, load/unload a payload 132 while the drone is stowed, remove/insert a drone battery."
Drone Landing System,https://lens.org/148-456-645-612-948,2022,"A drone landing system comprises a first landing surface 104 parallel to and fast with a second landing surface 110 (the landing surfaces are arranged back-to-back and unitary or rigidly joined). Securing means (e.g. electromagnet(s) and/or mechanically engaging means, e.g. rotatable hooks, slidable bars) releasably secure a drone 130 to the first landing surface. A rotation mechanism revolves the landing surfaces between a first position in which the first landing surface is exposed to receive a drone and a second position in which the first landing surface is within a housing. The first landing surface, together with the attached first UAV, may be rotated by 180 degrees, exposing the second landing surface to receive a second drone. A deployable concertina cover may protect landing surfaces from rain. A robotic arm (156, figure 5A) may reposition a drone, load/unload a payload 132 while the drone is stowed, remove/insert a drone battery."
AUTONOMOUS DIGITAL MEDIA PROCESSING SYSTEMS AND METHODS,https://lens.org/079-700-742-676-055,2023,A system for monitoring and recording and processing an activity includes one or more cameras for automatically recording video of the activity. A remote media system is located at the location of the activity. A network media processor and services is communicatively coupled with the remote media system. The remote media system includes one or more AI enabled cameras. The AI enabled camera is configured to record the activity. The network media processor is configured to receive an activation request of the AI enabled camera and the validate the record request.
Autonomous digital media processing systems and methods,https://lens.org/062-876-171-905-302,2023,A system for monitoring and recording and processing an activity includes one or more cameras for automatically recording video of the activity. A remote media system is located at the location of the activity. A network media processor and services is communicatively coupled with the remote media system. The remote media system includes one or more AI enabled cameras. The AI enabled camera is configured to record the activity. The network media processor is configured to receive an activation request of the AI enabled camera and the validate the record request.
Autonomous digital media processing systems and methods,https://lens.org/062-876-171-905-302,2023,A system for monitoring and recording and processing an activity includes one or more cameras for automatically recording video of the activity. A remote media system is located at the location of the activity. A network media processor and services is communicatively coupled with the remote media system. The remote media system includes one or more AI enabled cameras. The AI enabled camera is configured to record the activity. The network media processor is configured to receive an activation request of the AI enabled camera and the validate the record request.
AUTONOMOUS DIGITAL MEDIA PROCESSING SYSTEMS AND METHODS,https://lens.org/079-700-742-676-055,2023,A system for monitoring and recording and processing an activity includes one or more cameras for automatically recording video of the activity. A remote media system is located at the location of the activity. A network media processor and services is communicatively coupled with the remote media system. The remote media system includes one or more AI enabled cameras. The AI enabled camera is configured to record the activity. The network media processor is configured to receive an activation request of the AI enabled camera and the validate the record request.
AUTONOMOUS DIGITAL MEDIA PROCESSING SYSTEMS AND METHODS,https://lens.org/129-313-846-781-409,2021,A system for monitoring and recording and processing an activity includes one or more cameras for automatically recording video of the activity. A remote media system is located at the location of the activity. A network media processor and services is communicatively coupled with the remote media system. The remote media system includes one or more AI enabled cameras. The AI enabled camera is configured to record the activity. The network media processor is configured to receive an activation request of the AI enabled camera and the validate the record request.
INTERACTION METHOD AND DEVICE FOR MOBILE TERMINAL AND CLOUD PLATFORM OF UNMANNED AERIAL VEHICLE,https://lens.org/056-993-972-023-073,2020,"An interaction method includes obtaining a livestreaming confirmation from a server, obtaining a livestreaming address corresponding to the UAV from the server, and playing a real time video stream according to the livestreaming address. The livestreaming confirmation indicates that the UAV is in a livestreaming status. The real time video stream is uploaded to the server by a mobile terminal associated with the UAV."
DRONE TELEMETRY SYSTEM,https://lens.org/060-199-675-345-435,2023,"A device includes a processor. The processor is configured to execute instructions to: receive a request from an application to subscribe to a telemetry messaging service; grant a subscription to the telemetry messaging service, to the application based on the request; receive telemetry messages from drones over a radio access network (RAN); process the telemetry messages; and provide the processed telemetry messages to the application over the RAN."
DRONE TELEMETRY SYSTEM,https://lens.org/060-199-675-345-435,2023,"A device includes a processor. The processor is configured to execute instructions to: receive a request from an application to subscribe to a telemetry messaging service; grant a subscription to the telemetry messaging service, to the application based on the request; receive telemetry messages from drones over a radio access network (RAN); process the telemetry messages; and provide the processed telemetry messages to the application over the RAN."
Remote control for a camera having an optical fiber,https://lens.org/065-787-948-593-606,1994,"A remote control apparatus of a camera including a remote control signal receiving element and a remote control mode indicating element provided in the camera body, a plurality of indicating windows on the sides of the camera body, and an optical connector for optically connecting the remote control signal receiving element and remote control mode indicating element to the indicating windows."
Home security camera,https://lens.org/061-159-343-061-823,2015,"The utility model provides a home security camera. The home security camera can be remotely controlled by a mobile phone to move, and a user can observe the larger range of the home through the home security camera. The home security camera comprises a base (1) and a camera main body (8) and further comprises an angle adjusting motor (2) arranged on the base (1). An angle adjusting shaft (3) extends out of the angle adjusting motor (2), a lead screw motor (4) is arranged on the angle adjusting shaft (3), a rotating shaft of the lead screw motor (4) is connected with a lead screw (5), a nut (6) capable of moving up and down along the lead screw is arranged on the lead screw (5), and the camera main body (8) is arranged on the nut (6). The home security camera further comprises a remote control module (9), the angle adjusting motor (2), the lead screw motor (4) and the camera main body (8) are all electrically connected with the remote control module (9), and a wireless communication unit connected with wifi signals is arranged on the remote control module (9)."
System and methods for autonomous tracking and surveillance,https://lens.org/097-742-147-580-84X,2009,"A system and methods for autonomously tracking and simultaneously providing surveillance of a target from air vehicles. In one embodiment the system receives inputs from outside sources, creates tracks, identifies the targets and generates flight plans for unmanned air vehicles (UAVs) and camera controls for surveillance of the targets. The system uses predictive algorithms and aircraft control laws. The system comprises a plurality of modules configured to accomplish these tasks. One embodiment comprises an automatic target recognition (ATR) module configured to receive video information, process the video information, and produce ATR information including target information. The embodiment further comprises a multi-sensor integrator (MSI) module configured to receive the ATR information, an air vehicle state input and a target state input, process the inputs and produce track information for the target. The embodiment further comprises a target module configured to receive the track information, process the track information, and produce predicted future state target information. The embodiment further comprises an ownship module configured to receive the track information, process the track information, and produce predicted future state air vehicle information. The embodiment further comprises a planner module configured to receive the predicted future state target information and the predicted future state air vehicle information and generate travel path information including flight and camera steering commands for the air vehicle.
"
System and methods for autonomous tracking and surveillance,https://lens.org/144-613-141-205-805,2014,"A system and methods for autonomously tracking and simultaneously providing surveillance of a target from air vehicles. In one embodiment the system receives inputs from outside sources, creates tracks, identifies the targets and generates flight plans for unmanned air vehicles (UAVs) and camera controls for surveillance of the targets. The system uses predictive algorithms and aircraft control laws. The system comprises a plurality of modules configured to accomplish these tasks. One embodiment comprises an automatic target recognition (ATR) module configured to receive video information, process the video information, and produce ATR information including target information. The embodiment further comprises a multi-sensor integrator (MSI) module configured to receive the ATR information, an air vehicle state input and a target state input, process the inputs and produce track information for the target. The embodiment further comprises a target module configured to receive the track information, process the track information, and produce predicted future state target information. The embodiment further comprises an ownship module configured to receive the track information, process the track information, and produce predicted future state air vehicle information. The embodiment further comprises a planner module configured to receive the predicted future state target information and the predicted future state air vehicle information and generate travel path information including flight and camera steering commands for the air vehicle."
DEVICE AND METHOD TO REMOTELY SEVER WIRES,https://lens.org/126-532-423-428-364,2013,"A cutting device accessory can be used with surveillance robots. Device can attach to a robot and allow an operator to remotely cut wires or strings laid along the ground. The robot can operate by dragging a hook behind it to catch wires or strings. The hook can form the lower jaw of a wire cutter that pivots on a cutter housing fixed on the end of an extension or tail off the back of the robot. The upper jaw can be fixed to this cutter housing adjacent to the lower jaw, allowing a shearing or cleaving action when the lower jaw is closed upon the upper jaw."
"Cognitive testing, debugging, and remediation of drone",https://lens.org/109-233-686-563-094,2020,"A computer-implemented method includes obtaining fault information regarding a fault associated with a first drone. The computer-implemented method additionally includes obtaining context parameter data of the first drone. The computer-implemented method additionally includes, responsive to obtaining the fault information and the context parameter data, determining to apply a first test case of a plurality of test cases based on a first risk value determined for the first test case using the context parameter data. The first test case is associated with the fault. The computer-implemented method additionally includes causing the first drone to initiate execution of the first test case."
"COGNITIVE TESTING, DEBUGGING, AND REMEDIATION OF DRONE",https://lens.org/189-411-412-462-318,2019,"A computer-implemented method includes obtaining fault information regarding a fault associated with a first drone. The computer-implemented method additionally includes obtaining context parameter data of the first drone. The computer-implemented method additionally includes, responsive to obtaining the fault information and the context parameter data, determining to apply a first test case of a plurality of test cases based on a first risk value determined for the first test case using the context parameter data. The first test case is associated with the fault. The computer-implemented method additionally includes causing the first drone to initiate execution of the first test case."
"Cellphone remote control device, system and method",https://lens.org/038-456-368-270-071,2015,"The invention provides a cellphone remote control device. The cellphone remote control device is wirelessly connected with a cellphone, and is used for collecting event information generated when being operated and sending the event information to the cellphone in a wireless manner. After being received by the cellphone, the event information is converted into an executable order, and the executable order is performed by the cellphone, so that the cellphone remote control device realizes remote control over the cellphone. The invention also provides a cellphone remote control system and method. The original cellphone control method is maintained, and a set of cellphone control device separated from a cellphone display device is added, so as to realize remote control of the cellphone."
Unmanned vehicle and base station,https://lens.org/024-709-247-982-018,2019,"An unmanned vehicle and base station are disclosed that provide an efficient, automated, and quick system for loading onto and un-loading from the unmanned vehicle modular attachments or cartridges. The UAV can also include numerous components, modules, functionalities, and built-in features, including an emergency operation mode, payload delivery mode, and dispensing mode, among other advantages."
Video surveillance and home security apparatus using the UMTS network and a method for the management of said apparatus,https://lens.org/034-600-378-275-202,2009,"The present invention provides for an advanced UMTS terminal specifically designed as a video surveillance product which allows the user to manage, monitor and receive alerts from remote locations over the UMTS cellular network. The device has onboard local wireless connectivity which allows the user to simply and intuitively control ""home automation"" functions directly from a UMTS device. The apparatus provides for: UMTS/GPRS connectivity, privacy management through a white list, alerting via outgoing video call, MMS or SMS messages, and user configuration via video call, and local connectivity to various sensors and/or actuators through standard wireless connections. Video cameras are also provided which can be controlled remotely using DTMF control and allowing local storage of video images."
System and device for rental dispensing of UAVs,https://lens.org/166-052-366-317-243,2019,"A UAV rental dispensing system employs a vending device that a consumer can rent a UAV from for a variety purposes requiring a video function thereon. The vending device may have multiple drones/UAVs enclosed therein, and be placed in predetermined locations. The vending device would provide launch and recovery, storage, power, charging, diagnostics and data transfer. Although the vending device will include an interface screen for accessing information, transactions may occur over the Internet or phone/data lines via a smart phone app or the like. The device will have a hinge or sliding door thereon with a landing pad/docket inside for charging of the batteries. After charging, the drone will be moved to a storage section automatically. When the drone is to be used, the reverse will occur. The level of charge will be checked before exiting the vending machine with necessary flight information uploaded by data lines or wirelessly."
System for rental dispensing of UAVs,https://lens.org/195-218-756-202-723,2020,"A UAV rental dispensing system employs a vending device that a consumer can rent a UAV from for a variety purposes requiring a video function thereon. The vending device may have multiple drones/UAVs enclosed therein, and be placed in predetermined locations. The vending device would provide launch and recovery, storage, power, charging, diagnostics and data transfer. Although the vending device will include an interface screen for accessing information, transactions may occur over the Internet or phone/data lines via a smart phone app or the like. The device will have a hinge or sliding door thereon with a landing pad/docket inside for charging of the batteries. After charging, the drone will be moved to a storage section automatically. When the drone is to be used, the reverse will occur. The level of charge will be checked before exiting the vending machine with necessary flight information uploaded by data lines or wirelessly."
System and Method for Robotic Ticket Scratching via Live Remote Mobile Interface,https://lens.org/164-966-992-202-177,2023,"A controller is configured to obtain, from a first camera associated with a ticket machine, a first image stream; transmit the first image stream to an application server; receive, from the application server, a first command for the ticket machine; cause the ticket machine to provide, based on the first command, a ticket having a scratching area; receive a user-provided scratching command from the application server; and cause a robotic scratching device to scratch the scratching area in accordance with the scratching command."
"PARCEL CHUTE FOR AN OUTER WALL OF A BUILDING OR AN ENCLOSURE OF A BALCONY, METHOD FOR DELIVERING A PARCEL USING AN UNMANNED AIRCRAFT AND FOR GUIDING THE PARCEL THROUGH A PARCEL CHUTE, OUTER WALL OF A BUILDING AND ENCLOSURE FOR A BALCONY OF A BUILDING",https://lens.org/145-732-098-751-023,2022,"A parcel chute (1) is provided for an outer wall (13) of a building or an enclosure of a balcony which is used for the automatic delivery and collection of a parcel (2) by an unmanned aircraft, in particular a logistics drone. A method for delivering a parcel (2) using an unmanned aircraft, in particular a logistics drone, an outer wall (13) with a parcel chute (1), and an enclosure with a parcel chute (1) are also provided."
"PARCEL CHUTE FOR AN OUTER WALL OF A BUILDING OR AN ENCLOSURE OF A BALCONY, METHOD FOR DELIVERING A PARCEL USING AN UNMANNED AIRCRAFT AND FOR GUIDING THE PARCEL THROUGH A PARCEL CHUTE, OUTER WALL OF A BUILDING AND ENCLOSURE FOR A BALCONY OF A BUILDING",https://lens.org/145-732-098-751-023,2022,"A parcel chute (1) is provided for an outer wall (13) of a building or an enclosure of a balcony which is used for the automatic delivery and collection of a parcel (2) by an unmanned aircraft, in particular a logistics drone. A method for delivering a parcel (2) using an unmanned aircraft, in particular a logistics drone, an outer wall (13) with a parcel chute (1), and an enclosure with a parcel chute (1) are also provided."
Apparatus for detecting cells in circulating bloodstream,https://lens.org/045-680-938-843-645,2018,A device for the real-time
Apparatus for detecting cells in circulating bloodstream,https://lens.org/067-472-301-777-240,2021,A device for the real-time
System and method for controlling an image collecting device to carry out a target location,https://lens.org/083-830-795-940-69X,2013,"System and method for controlling an image collecting device to carry out a target location are provided, which includes: an acoustic sound source locating unit, configured to carry out target location based on a received acoustical signal and transmit the located position to an application layer strategy unit; a voice recognition unit, configured to carry out a recognition and matching process with a stored acoustical signal based on the received acoustical signal, and transmit the recognition result to the application layer strategy unit; and the application layer strategy unit, configured to decide an expected PTZ position of the image collecting device based on the position and the recognition result. The system controls the image collecting device to automatically carry out a target location based on the results of the acoustic sound source location and voice recognition, which thus improves an operating maintainability of the image collecting device."
SYSTEM AND METHOD FOR CONTROLLING AN IMAGE COLLECTING DEVICE TO CARRY OUT A TARGET LOCATION,https://lens.org/081-452-604-489-085,2010,"System and method for controlling an image collecting device to carry out a target location are provided, which includes: an acoustic sound source locating unit, configured to carry out target location based on a received acoustical signal and transmit the located position to an application layer strategy unit; a voice recognition unit, configured to carry out a recognition and matching process with a stored acoustical signal based on the received acoustical signal, and transmit the recognition result to the application layer strategy unit; and the application layer strategy unit, configured to decide an expected PTZ position of the image collecting device based on the position and the recognition result. The system controls the image collecting device to automatically carry out a target location based on the results of the acoustic sound source location and voice recognition, which thus improves an operating maintainability of the image collecting device."
Dynamic access point based positioning,https://lens.org/136-342-118-773-474,2015,"A wireless device that includes an access point (AP) scanner, a transceiver, and a controller coupled to the AP scanner and transceiver. The AP scanner is configured to scan wireless network channels utilized by one or more APs to transmit data packets, probe responses, and beacons. The transceiver is configured to transmit one or more probe requests to the one or more APs and receive one or more probe responses and beacons from the one or more APs. The controller is configured to determine a proximate geographic position of the wireless device based on signal strength of the one or more probe responses and beacons received from the one or more APs. The controller also dynamically adapts a parameter utilized in determining the proximate geographic position of the wireless device."
UAV-based sensing for worksite operations,https://lens.org/156-444-856-585-638,2017,"A sensor senses an attribute of a worksite at a location that is geographically spaced from a corresponding mobile machine. An operation is performed at the location, based upon the sensed attribute. An action signal is generated based on the effect data. An unmanned aerial vehicle communicates effect data, indicative of an effect of the operation at the location, to the mobile machine. The action signal can be used to control worksite operations."
UAV-BASED SENSING FOR WORKSITE OPERATIONS,https://lens.org/000-910-771-126-625,2017,"A sensor senses an attribute of a worksite at a location that is geographically spaced from a corresponding mobile machine. An operation is performed at the location, based upon the sensed attribute. An action signal is generated based on the effect data. An unmanned aerial vehicle communicates effect data, indicative of an effect of the operation at the location, to the mobile machine. The action signal can be used to control worksite operations."
"UNMANNED AIRCRAFT RETURN FLIGHT CONTROL METHOD, DEVICE, AND UNMANNED AERIAL VEHICLE",https://lens.org/055-101-628-120-672,2020,"A method for controlling return flight of an unmanned aircraft includes receiving location information of an updated return flight location transmitted from a ground terminal. The method also includes determining a target flight path based on a current velocity, current location information, and location information of the updated return flight location of the unmanned aircraft. The method further includes controlling the unmanned aircraft to return flight toward the updated return flight location based on the target flight path."
"VEHICLE, INFORMATION PROCESSING SYSTEM, NON-TRANSITORY STORAGE MEDIUM, AND INFORMATION PROCESSING DEVICE",https://lens.org/175-692-038-377-10X,2023,"A vehicle configured to autonomously deliver a package includes a control unit configured to acquire designation information generated along with designation by a user about an unattended delivery location for delivery of the package, and drive the vehicle to place the package at the unattended delivery location designated by the user when the unattended delivery location is identified by verifying the unattended delivery location based on the acquired designation information."
"AMPHIBIOUS VTOL SUPER DRONE CAMERA IN A MOBILE CASE (PHONE CASE) WITH MULTIPLE AERIAL AND AQUATIC FLIGHT MODES FOR CAPTURING PANORAMIC VIRTUAL REALITY VIEWS, SELFIE AND INTERACTIVE VIDEO",https://lens.org/162-558-697-470-026,2016,"A mobile case system comprising a real time broadcast stream recording; an unmanned aerial vehicle; a camera stabilization device; a camera movement device; one or more onboard cameras providing real-time first-person video and real-time first-person views and and 360-degree panoramic video recording used for virtual reality views and interactive video; a video transmitter and receiver device configured to perform high definition low latency real time video downlink; a one and two way telemetry device; a live broadcast device; a headset enabling real-time first-person video; a public database for viewing flight activity; software for licensing videos with a watermarked preview; software for autonomously extracting and compiling the usable video footage into a video montage synced to music; and onboard or separate software for stitching videos to form virtual reality views or interactive video, alternative embodiments the case may be adapted as power bank memory device, and use for aerial delivery."
PLUG-AND-PLAY MULTIFUNCTIONAL ATTACHMENT OF REMOTE CONTROL ROTORCRAFT,https://lens.org/153-855-888-625-582,2017,"Disclosed is a plug-and-play multifunctional attachment of a remote control rotorcraft, which includes: an attachment body that includes a device board and a remote control receiver unit. The device board has a top surface to which a first coupling member is mounted. The remote control receiver unit is mounted to and electrically connected to a bottom surface of the device board. Wireless transmission of a signal is enabled between a remote control device and the remote control receiver unit. A second coupling member is mounted to a bottom of an unmanned aircraft to enable selective engagement and coupling between the second coupling member and the first coupling member."
LIGHTING AND CONTROL SYSTEMS AND METHODS,https://lens.org/140-717-842-954-738,2013,"Lighting and control systems and methods for a lighting node and a remote control device are disclosed. The remote control device may be coupled to the lighting node via an identification process, such as broadcasting an identification request from the remote control device to nearby lighting nodes. The lighting node can respond to the identification request by sending an identifier to the remote control device such that future commands sent from the remote control device is limited to be responded by the lighting node having the identifier stored thereon. Once coupled, the remote control device can adjust spectral content produced by the lighting node based on user-configuration or a color profile captured via an optical sensor. The adjustment via the remote control device may further include calibration and recalibration of the lighting node utilizing a feedback mechanism with the optical sensor."
Lighting and control systems and methods,https://lens.org/102-334-964-172-201,2015,"Lighting and control systems and methods for a lighting node and a remote control device are disclosed. The remote control device may be coupled to the lighting node via an identification process, such as broadcasting an identification request from the remote control device to nearby lighting nodes. The lighting node can respond to the identification request by sending an identifier to the remote control device such that future commands sent from the remote control device is limited to be responded by the lighting node having the identifier stored thereon. Once coupled, the remote control device can adjust spectral content produced by the lighting node based on user-configuration or a color profile captured via an optical sensor. The adjustment via the remote control device may further include calibration and recalibration of the lighting node utilizing a feedback mechanism with the optical sensor."
UNMANNED AIRCRAFT SYSTEMS AND METHODS,https://lens.org/005-907-602-350-858,2019,"Some embodiments provide a system to identify geographic zones into which unmanned aircraft systems (UAS) are inhibited from flying. In some instances, the system detects, while the UAS is in flight and traveling along a flight path to a delivery location where the UAS is scheduled to deliver a package, a no fly zone (NFZ) into which the UAS is to avoid flying; obtains a revised flight path to the delivery location that includes a detour route around the no fly zone; directs the motor controller to control the motors to implement the revised flight path; and detects when the UAS is at a threshold distance from the delivery location and initiate delivery of the package."
Unmanned aircraft systems and methods,https://lens.org/088-270-971-276-61X,2019,"Some embodiments provide a system to identify geographic zones into which unmanned aircraft systems (UAS) are inhibited from flying. In some instances, the system detects, while the UAS is in flight and traveling along a flight path to a delivery location where the UAS is scheduled to deliver a package, a no fly zone (NFZ) into which the UAS is to avoid flying; obtains a revised flight path to the delivery location that includes a detour route around the no fly zone; directs the motor controller to control the motors to implement the revised flight path; and detects when the UAS is at a threshold distance from the delivery location and initiate delivery of the package."
UNMANNED AIRCRAFT SYSTEMS AND METHODS,https://lens.org/128-563-258-044-723,2017,"Some embodiments provide a system to identify geographic zones into which unmanned aircraft systems (UAS) are inhibited from flying. In some instances, the system detects, while the UAS is in flight and traveling along a flight path to a delivery location where the UAS is scheduled to deliver a package, a no fly zone (NFZ) into which the UAS is to avoid flying; obtains a revised flight path to the delivery location that includes a detour route around the no fly zone; directs the motor controller to control the motors to implement the revised flight path; and detects when the UAS is at a threshold distance from the delivery location and initiate delivery of the package."
Unmanned aircraft systems and methods,https://lens.org/155-737-800-288-303,2019,"Some embodiments provide a system to identify geographic zones into which unmanned aircraft systems (UAS) are inhibited from flying. In some instances, the system detects, while the UAS is in flight and traveling along a flight path to a delivery location where the UAS is scheduled to deliver a package, a no fly zone (NFZ) into which the UAS is to avoid flying; obtains a revised flight path to the delivery location that includes a detour route around the no fly zone; directs the motor controller to control the motors to implement the revised flight path; and detects when the UAS is at a threshold distance from the delivery location and initiate delivery of the package."
Communication and Monitoring System,https://lens.org/101-550-838-027-740,2015,"An audio-video communication system comprises a wireless exterior module located proximate an entrance, a computerized controller running a software application, and a remote peripheral device. The wireless exterior module includes a proximity sensor for detecting a person at the entrance, a video camera for recording an image of the person at the entrance, a microphone for recording the person at the entrance, a speaker for playing audio to the person at the entrance, a transmitter for communicating sounds and images of the person at the entrance, and a receiver for receiving communications at the wireless exterior module. The computerized controller is disposed in wireless electronic communication with the wireless exterior module via the transmitter and the receiver of the wireless exterior module. The remote peripheral device is configured to electronically communicate with the computerized controller for viewing an image from the video camera communicated from the wireless exterior module."
Communication and monitoring system,https://lens.org/008-585-477-411-93X,2020,"An audio-video communication system comprises a wireless exterior module located proximate an entrance, a computerized controller running a software application, and a remote peripheral device. The wireless exterior module includes a proximity sensor for detecting a person at the entrance, a video camera for recording an image of the person at the entrance, a microphone for recording the person at the entrance, a speaker for playing audio to the person at the entrance, a transmitter for communicating sounds and images of the person at the entrance, and a receiver for receiving communications at the wireless exterior module. The computerized controller is disposed in wireless electronic communication with the wireless exterior module via the transmitter and the receiver of the wireless exterior module. The remote peripheral device is configured to electronically communicate with the computerized controller for viewing an image from the video camera communicated from the wireless exterior module."
Communication and monitoring system,https://lens.org/096-585-153-761-927,2016,"An audio-video communication system comprises a wireless exterior module located proximate an entrance, a computerized controller running a software application, and a remote peripheral device. The wireless exterior module includes a proximity sensor for detecting a person at the entrance, a video camera for recording an image of the person at the entrance, a microphone for recording the person at the entrance, a speaker for playing audio to the person at the entrance, a transmitter for communicating sounds and images of the person at the entrance, and a receiver for receiving communications at the wireless exterior module. The computerized controller is disposed in wireless electronic communication with the wireless exterior module via the transmitter and the receiver of the wireless exterior module. The remote peripheral device is configured to electronically communicate with the computerized controller for viewing an image from the video camera communicated from the wireless exterior module."
Communication and monitoring system,https://lens.org/142-487-225-663-953,2018,"An audio-video communication system comprises a wireless exterior module located proximate an entrance, a computerized controller running a software application, and a remote peripheral device. The wireless exterior module includes a proximity sensor for detecting a person at the entrance, a video camera for recording an image of the person at the entrance, a microphone for recording the person at the entrance, a speaker for playing audio to the person at the entrance, a transmitter for communicating sounds and images of the person at the entrance, and a receiver for receiving communications at the wireless exterior module. The computerized controller is disposed in wireless electronic communication with the wireless exterior module via the transmitter and the receiver of the wireless exterior module. The remote peripheral device is configured to electronically communicate with the computerized controller for viewing an image from the video camera communicated from the wireless exterior module."
Communication and Monitoring System,https://lens.org/034-590-446-766-972,2015,"An audio-video communication system comprises a wireless exterior module located proximate an entrance, a computerized controller running a software application, and a remote peripheral device. The wireless exterior module includes a proximity sensor for detecting a person at the entrance, a video camera for recording an image of the person at the entrance, a microphone for recording the person at the entrance, a speaker for playing audio to the person at the entrance, a transmitter for communicating sounds and images of the person at the entrance, and a receiver for receiving communications at the wireless exterior module. The computerized controller is disposed in wireless electronic communication with the wireless exterior module via the transmitter and the receiver of the wireless exterior module. The remote peripheral device is configured to electronically communicate with the computerized controller for viewing an image from the video camera communicated from the wireless exterior module."
Communication and monitoring system,https://lens.org/061-104-771-149-321,2008,"An audio-video communication system comprises a wireless exterior module located proximate an entrance, a computerized controller running a software application, and a remote peripheral device. The wireless exterior module includes a proximity sensor for detecting a person at the entrance, a video camera for recording an image of the person at the entrance, a microphone for recording the person at the entrance, a speaker for playing audio to the person at the entrance, a transmitter for communicating sounds and images of the person at the entrance, and a receiver for receiving communications at the wireless exterior module. The computerized controller is disposed in wireless electronic communication with the wireless exterior module via the transmitter and the receiver of the wireless exterior module. The remote peripheral device is configured to electronically communicate with the computerized controller for viewing an image from the video camera communicated from the wireless exterior module."
Detection and viewing system,https://lens.org/084-506-341-007-215,2008,"An audio-video communication system comprises a wireless exterior module located proximate an entrance, a computerized controller running a software application, and a remote peripheral device. The wireless exterior module includes a proximity sensor for detecting a person at the entrance, a video camera for recording an image of the person at the entrance, a microphone for recording the person at the entrance, a speaker for playing audio to the person at the entrance, a transmitter for communicating sounds and images of the person at the entrance, and a receiver for receiving communications at the wireless exterior module. The computerized controller is disposed in wireless electronic communication with the wireless exterior module via the transmitter and the receiver of the wireless exterior module. The remote peripheral device is configured to electronically communicate with the computerized controller for viewing an image from the video camera communicated from the wireless exterior module."
Communication and Monitoring System,https://lens.org/126-750-359-425-702,2016,"An audio-video communication system comprises a wireless exterior module located proximate an entrance, a computerized controller running a software application, and a remote peripheral device. The wireless exterior module includes a proximity sensor for detecting a person at the entrance, a video camera for recording an image of the person at the entrance, a microphone for recording the person at the entrance, a speaker for playing audio to the person at the entrance, a transmitter for communicating sounds and images of the person at the entrance, and a receiver for receiving communications at the wireless exterior module. The computerized controller is disposed in wireless electronic communication with the wireless exterior module via the transmitter and the receiver of the wireless exterior module. The remote peripheral device is configured to electronically communicate with the computerized controller for viewing an image from the video camera communicated from the wireless exterior module."
Communication and monitoring system,https://lens.org/103-197-247-576-404,2020,"An audio-video communication system comprises a wireless exterior module located proximate an entrance, a computerized controller running a software application, and a remote peripheral device. The wireless exterior module includes a proximity sensor for detecting a person at the entrance, a video camera for recording an image of the person at the entrance, a microphone for recording the person at the entrance, a speaker for playing audio to the person at the entrance, a transmitter for communicating sounds and images of the person at the entrance, and a receiver for receiving communications at the wireless exterior module. The computerized controller is disposed in wireless electronic communication with the wireless exterior module via the transmitter and the receiver of the wireless exterior module. The remote peripheral device is configured to electronically communicate with the computerized controller for viewing an image from the video camera communicated from the wireless exterior module."
"APPARATUS COMPRISING SMART SATELLITE ANTENNA, CAPABLE OF PERFORMING MULTICASTING AND MULTISENSING-BASED EMERGENCY SITUATION DETECTION, AND OPERATING METHOD THEREFOR",https://lens.org/059-487-095-981-145,2022,"Disclosed herein is a smart satellite antenna apparatus including a satellite tracking antenna. The smart satellite antenna apparatus includes a controller that receives a command to select a channel of a satellite broadcast from a user and controls the movement and rotation of the satellite tracking antenna corresponding to the channel of the satellite broadcast. The controller transfers satellite broadcast content, received corresponding to the channel, via a wired link so that the satellite broadcast content is displayed on a display device, sets up a multicasting network based on wireless links so that the satellite broadcast content is displayed on a plurality of wireless devices other than the display device via the wireless links, and manages the multicasting network so that the satellite broadcast content is transferred to each of the plurality of wireless devices via the multicasting network and the satellite broadcast content is shared among the display device and the plurality of wireless devices."
"APPARATUS COMPRISING SMART SATELLITE ANTENNA, CAPABLE OF PERFORMING MULTICASTING AND MULTISENSING-BASED EMERGENCY SITUATION DETECTION, AND OPERATING METHOD THEREFOR",https://lens.org/059-487-095-981-145,2022,"Disclosed herein is a smart satellite antenna apparatus including a satellite tracking antenna. The smart satellite antenna apparatus includes a controller that receives a command to select a channel of a satellite broadcast from a user and controls the movement and rotation of the satellite tracking antenna corresponding to the channel of the satellite broadcast. The controller transfers satellite broadcast content, received corresponding to the channel, via a wired link so that the satellite broadcast content is displayed on a display device, sets up a multicasting network based on wireless links so that the satellite broadcast content is displayed on a plurality of wireless devices other than the display device via the wireless links, and manages the multicasting network so that the satellite broadcast content is transferred to each of the plurality of wireless devices via the multicasting network and the satellite broadcast content is shared among the display device and the plurality of wireless devices."
UNMANNED AERIAL VEHICLE AND CONTROLLER COMMUNICATION,https://lens.org/131-801-108-457-935,2022,"In embodiments of systems and methods for managing communication between an unmanned aerial vehicle (UAV) and an unmanned aerial vehicle controller (UAC), the UAV may receive from an unmanned aerial system traffic management (UTM) device a command request from the UAC, including one or more destination Generic Public Subscription Identifiers (GPSIs), a control command, a data command, and a first tunnel-to-add indication. The UAV may send to the UAV via the UTM device a command response, which may include information responsive to the command request, and a second tunnel-to-add indication. The UAV may establish an application layer communication tunnel with the UAC based on the first tunnel-to-add indication and the second tunnel-to-add indication. The communication tunnel may be configured to enable further communications with the UAC."
UNMANNED AERIAL VEHICLE AND CONTROLLER COMMUNICATION,https://lens.org/131-801-108-457-935,2022,"In embodiments of systems and methods for managing communication between an unmanned aerial vehicle (UAV) and an unmanned aerial vehicle controller (UAC), the UAV may receive from an unmanned aerial system traffic management (UTM) device a command request from the UAC, including one or more destination Generic Public Subscription Identifiers (GPSIs), a control command, a data command, and a first tunnel-to-add indication. The UAV may send to the UAV via the UTM device a command response, which may include information responsive to the command request, and a second tunnel-to-add indication. The UAV may establish an application layer communication tunnel with the UAC based on the first tunnel-to-add indication and the second tunnel-to-add indication. The communication tunnel may be configured to enable further communications with the UAC."
UNMANNED AERIAL VEHICLE AND CONTROLLER COMMUNICATION,https://lens.org/178-216-194-121-896,2022,"In embodiments of systems and methods for managing communication between an unmanned aerial vehicle (UAV) and an unmanned aerial vehicle controller (UAC), the UAV may receive from an unmanned aerial system traffic management (UTM) device a command request from the UAC, including one or more destination Generic Public Subscription Identifiers (GPSIs), a control command, a data command, and a first tunnel-to-add indication. The UAV may send to the UAV via the UTM device a command response, which may include information responsive to the command request, and a second tunnel-to-add indication. The UAV may establish an application layer communication tunnel with the UAC based on the first tunnel-to-add indication and the second tunnel-to-add indication. The communication tunnel may be configured to enable further communications with the UAC."
UNMANNED AERIAL VEHICLE AND CONTROLLER COMMUNICATION,https://lens.org/178-216-194-121-896,2022,"In embodiments of systems and methods for managing communication between an unmanned aerial vehicle (UAV) and an unmanned aerial vehicle controller (UAC), the UAV may receive from an unmanned aerial system traffic management (UTM) device a command request from the UAC, including one or more destination Generic Public Subscription Identifiers (GPSIs), a control command, a data command, and a first tunnel-to-add indication. The UAV may send to the UAV via the UTM device a command response, which may include information responsive to the command request, and a second tunnel-to-add indication. The UAV may establish an application layer communication tunnel with the UAC based on the first tunnel-to-add indication and the second tunnel-to-add indication. The communication tunnel may be configured to enable further communications with the UAC."
Programmable remote control,https://lens.org/060-816-710-656-492,1999,"The invention regards a remote control unit (1100) for control of home electronic devices comprising: a housing; a memory for storing data; and means for receiving data from an external source (1142) wherein said means for receiving comprise a microphone (1162) which is disposed on a surface portion of said housing. Preferably, the received data comprises data representative of selections of one or more of a plurality of remote control signal protocols. The remote control (1100) comprises a transmitter (1158) for transmitting remote control signals for controlling audio/visual electronic devices according to the selections of remote control signal protocols. <IMAGE>"
METHOD FOR CREATING A 3D MODEL OF AN OBJECT,https://lens.org/164-677-198-336-361,2019,"A method for creating a 3D model of an object (1), in which a rotary wing drone (2) with at least one image recording apparatus (3) is used to record a plurality of at least partly overlapping images of the object (1) and the 3D model is calculated therefrom. The rotary wing drone (2) continuously measures the distance from the object (1) with at least one distance sensor (4) and independently flies over the object (1) at a predetermined distance (7) and the flyover is terminated once the object (1) has been recorded in its entirety."
Electronics System,https://lens.org/119-058-247-089-631,2007,"An electronics system includes an electronic appliance with a display, a video camera for photographing an operator, and a universal remote controller for remotely controlling the electronic appliance. The image of the operator photographed with the video camera is converted into a mirror image. The mirror image of the operator is overlapped with an operational image which includes control icons and a pointer, and the overlapped images are displayed on the display. The operator manipulates a button on the universal remote controller, and the universal remote controller emits light. The light is detected by a detection unit of the electronics system. When the light is brought on to the pointer, the pointer starts to follow a movement of the universal remote controller manipulated by the operator. The operator moves the pointer onto a required one of the control icons and operates the button of the universal remote controller, to execute a control operation associated with the control icon."
LOCK AND METHOD FOR OPERATING SAME,https://lens.org/131-852-566-027-289,2023,"A method for operating a lock. A wireless command is received from a trusted device in a proximity range of the lock to enable a proximity mode. The proximity range is selectable by a user of the trusted device via an application. The proximity mode is enabled, and while enabled, a command is received to activate or deactivate the lock. The lock is activated or deactivated in response to the received activating or deactivating command."
LOCK AND METHOD FOR OPERATING SAME,https://lens.org/131-852-566-027-289,2023,"A method for operating a lock. A wireless command is received from a trusted device in a proximity range of the lock to enable a proximity mode. The proximity range is selectable by a user of the trusted device via an application. The proximity mode is enabled, and while enabled, a command is received to activate or deactivate the lock. The lock is activated or deactivated in response to the received activating or deactivating command."
AUTONOMOUS DIGITAL MEDIA PROCESSING SYSTEMS AND METHODS,https://lens.org/150-232-972-526-069,2022,A system for monitoring and recording and processing an activity includes one or more cameras for automatically recording video of the activity. A remote media system is located at the location of the activity. A network media processor and services is communicatively coupled with the remote media system. The remote media system includes one or more AI enabled cameras. The AI enabled camera is configured to record the activity. The network media processor is configured to receive an activation request of the AI enabled camera and validate the record request.
"MOVING FLYING OBJECT FOR SCANNING AN OBJECT, AND SYSTEM FOR ANALYZING DAMAGE TO THE OBJECT",https://lens.org/198-530-955-343-76X,2019,"An aircraft that includes a helicopter drone on which a 3D scanner is mounted via an actively rotatable joint is provided. The 3D scanner has at least one high-resolution camera for recording a multiplicity of overlapping images of the object from different recording positions and recording directions, so that comparison of the images allows a position and orientation of the 3D scanner relative to the object to be ascertained. In addition, the aircraft has a coordination device for coordinated control of the 3D scanner, the joint and the helicopter drone. The system for damage analysis has an aircraft and an image processing module generating a data representation of a surface profile of the object on the basis of the recorded images. In addition, the system includes a rating device for checking the surface profile and for outputting a damage statement on the basis of the check."
"Moving flying object for scanning an object, and system for analyzing damage to the object",https://lens.org/160-810-271-376-47X,2022,"An aircraft that includes a helicopter drone on which a 3D scanner is mounted via an actively rotatable joint is provided. The 3D scanner has at least one high-resolution camera for recording a multiplicity of overlapping images of the object from different recording positions and recording directions, so that comparison of the images allows a position and orientation of the 3D scanner relative to the object to be ascertained. In addition, the aircraft has a coordination device for coordinated control of the 3D scanner, the joint and the helicopter drone. The system for damage analysis has an aircraft and an image processing module generating a data representation of a surface profile of the object on the basis of the recorded images. In addition, the system includes a rating device for checking the surface profile and for outputting a damage statement on the basis of the check."
"Moving flying object for scanning an object, and system for analyzing damage to the object",https://lens.org/160-810-271-376-47X,2022,"An aircraft that includes a helicopter drone on which a 3D scanner is mounted via an actively rotatable joint is provided. The 3D scanner has at least one high-resolution camera for recording a multiplicity of overlapping images of the object from different recording positions and recording directions, so that comparison of the images allows a position and orientation of the 3D scanner relative to the object to be ascertained. In addition, the aircraft has a coordination device for coordinated control of the 3D scanner, the joint and the helicopter drone. The system for damage analysis has an aircraft and an image processing module generating a data representation of a surface profile of the object on the basis of the recorded images. In addition, the system includes a rating device for checking the surface profile and for outputting a damage statement on the basis of the check."
Remote controller of biped robot,https://lens.org/143-830-215-800-303,2004,"A remote controller for a biped robot is of a simple arrangement capable of remotely controlling movement of the biped robot while taking into account the stability of the attitude of the robot. A manipulation unit 23 outputs, to a robot A, signals representative of manipulated positions of manipulator levers 26, 26 which correspond respectively to both legs 2, 2 of the robot A. A control unit 19 mounted in the robot A generates a motion command (desired gait) for determining motions of the legs for at least two steps of a walking action of the robot A depending on the manipulated positions of manipulator levers 26, 26 which are represented by output signal data from the manipulation unit 23, and controls motions of the legs 2, 2 based on the motion command."
Remote controller of biped robot,https://lens.org/066-970-093-863-974,2004,"A remote controller for a biped robot is of a simple arrangement capable of remotely controlling movement of the biped robot while taking into account the stability of the attitude of the robot. A manipulation unit 23 outputs, to a robot A, signals representative of manipulated positions of manipulator levers 26, 26 which correspond respectively to both legs 2, 2 of the robot A. A control unit 19 mounted in the robot A generates a motion command (desired gait) for determining motions of the legs for at least two steps of a walking action of the robot A depending on the manipulated positions of manipulator levers 26, 26 which are represented by output signal data from the manipulation unit 23, and controls motions of the legs 2, 2 based on the motion command."
"Unmanned aircraft, information processing method, and recording medium",https://lens.org/146-076-098-934-325,2021,"An unmanned aircraft includes: a sensor that includes at least a microphone that generates sound data; and a processor. The processor determines the quality of a target sound by use of the sound data generated by the microphone, identifies a sound source direction from the unmanned aircraft to the sound source of the target sound by use of data generated by the sensor, and controls an unmanned aircraft state that is a state of the unmanned aircraft such that a direction of a sound pickup area is aligned with the sound source direction, in accordance with the determined quality. The sound pickup area is a range in which sound pickup quality of the microphone is higher than that of another area."
"UNMANNED AIRCRAFT, INFORMATION PROCESSING METHOD, AND RECORDING MEDIUM",https://lens.org/175-280-266-482-138,2020,"An unmanned aircraft includes: a sensor that includes at least a microphone that generates sound data; and a processor. The processor determines the quality of a target sound by use of the sound data generated by the microphone, identifies a sound source direction from the unmanned aircraft to the sound source of the target sound by use of data generated by the sensor, and controls an unmanned aircraft state that is a state of the unmanned aircraft such that a direction of a sound pickup area is aligned with the sound source direction, in accordance with the determined quality. The sound pickup area is a range in which sound pickup quality of the microphone is higher than that of another area."
UNMANNED VEHICLE RECOGNITION AND THREAT MANAGEMENT,https://lens.org/107-188-723-897-139,2023,"Systems and methods for automated unmanned aerial vehicle recognition. A multiplicity of receivers captures RF data and transmits the RF data to at least one node device. The at least one node device comprises a signal processing engine, a detection engine, a classification engine, and a direction finding engine. The at least one node device is configured with an artificial intelligence algorithm. The detection engine and classification engine are trained to detect and classify signals from unmanned vehicles and their controllers based on processed data from the signal processing engine. The direction finding engine is operable to provide lines of bearing for detected unmanned vehicles."
Unmanned vehicle recognition and threat management,https://lens.org/055-498-015-890-939,2023,"Systems and methods for automated unmanned aerial vehicle recognition. A multiplicity of receivers captures RF data and transmits the RF data to at least one node device. The at least one node device comprises a signal processing engine, a detection engine, a classification engine, and a direction finding engine. The at least one node device is configured with an artificial intelligence algorithm. The detection engine and classification engine are trained to detect and classify signals from unmanned vehicles and their controllers based on processed data from the signal processing engine. The direction finding engine is operable to provide lines of bearing for detected unmanned vehicles."
UNMANNED VEHICLE RECOGNITION AND THREAT MANAGEMENT,https://lens.org/012-765-898-638-190,2019,"Systems and methods for automated unmanned aerial vehicle recognition. A multiplicity of receivers captures RF data and transmits the RF data to at least one node device. The at least one node device comprises a signal processing engine, a detection engine, a classification engine, and a direction finding engine. The at least one node device is configured with an artificial intelligence algorithm. The detection engine and classification engine are trained to detect and classify signals from unmanned vehicles and their controllers based on processed data from the signal processing engine. The direction finding engine is operable to provide lines of bearing for detected unmanned vehicles."
Unmanned vehicle recognition and threat management,https://lens.org/055-498-015-890-939,2023,"Systems and methods for automated unmanned aerial vehicle recognition. A multiplicity of receivers captures RF data and transmits the RF data to at least one node device. The at least one node device comprises a signal processing engine, a detection engine, a classification engine, and a direction finding engine. The at least one node device is configured with an artificial intelligence algorithm. The detection engine and classification engine are trained to detect and classify signals from unmanned vehicles and their controllers based on processed data from the signal processing engine. The direction finding engine is operable to provide lines of bearing for detected unmanned vehicles."
UNMANNED VEHICLE RECOGNITION AND THREAT MANAGEMENT,https://lens.org/107-188-723-897-139,2023,"Systems and methods for automated unmanned aerial vehicle recognition. A multiplicity of receivers captures RF data and transmits the RF data to at least one node device. The at least one node device comprises a signal processing engine, a detection engine, a classification engine, and a direction finding engine. The at least one node device is configured with an artificial intelligence algorithm. The detection engine and classification engine are trained to detect and classify signals from unmanned vehicles and their controllers based on processed data from the signal processing engine. The direction finding engine is operable to provide lines of bearing for detected unmanned vehicles."
UNMANNED VEHICLE RECOGNITION AND THREAT MANAGEMENT,https://lens.org/148-515-265-513-566,2020,"Systems and methods for automated unmanned aerial vehicle recognition. A multiplicity of receivers captures RF data and transmits the RF data to at least one node device. The at least one node device comprises a signal processing engine, a detection engine, a classification engine, and a direction finding engine. The at least one node device is configured with an artificial intelligence algorithm. The detection engine and classification engine are trained to detect and classify signals from unmanned vehicles and their controllers based on processed data from the signal processing engine. The direction finding engine is operable to provide lines of bearing for detected unmanned vehicles."
UNMANNED VEHICLE RECOGNITION AND THREAT MANAGEMENT,https://lens.org/068-537-189-421-965,2023,"Systems and methods for automated unmanned aerial vehicle recognition. A multiplicity of receivers captures RF data and transmits the RF data to at least one node device. The at least one node device comprises a signal processing engine, a detection engine, a classification engine, and a direction finding engine. The at least one node device is configured with an artificial intelligence algorithm. The detection engine and classification engine are trained to detect and classify signals from unmanned vehicles and their controllers based on processed data from the signal processing engine. The direction finding engine is operable to provide lines of bearing for detected unmanned vehicles."
Alert system for an unmanned aerial vehicle,https://lens.org/173-253-225-096-47X,2018,"An unmanned aerial vehicle for aerial transportation of delivery items. The unmanned aerial vehicle includes an attachment device to fasten and unfasten one or more delivery items to the unmanned aerial vehicle, a motor to aerially transport the one or more delivery items along a delivery route, a sensor mounted on the unmanned aerial vehicle to detect at least one environmental variable during the delivery route, and an alert system to generate a status associated with the unmanned aerial vehicle along the delivery route to an observer when the environmental variable exceeds a predetermined threshold."
ALERT SYSTEM FOR AN UNMANNED AERIAL VEHICLE,https://lens.org/191-377-744-320-493,2020,"An unmanned aerial vehicle for aerial transportation of delivery items. The unmanned aerial vehicle includes an attachment device to fasten and unfasten one or more delivery items to the unmanned aerial vehicle, a motor to aerially transport the one or more delivery items along a delivery route, a sensor mounted on the unmanned aerial vehicle to detect at least one environmental variable during the delivery route, and an alert system to generate a status associated with the unmanned aerial vehicle along the delivery route to an observer when the environmental variable exceeds a predetermined threshold."
Alert system for an unmanned aerial vehicle,https://lens.org/103-591-430-036-970,2019,"An unmanned aerial vehicle for aerial transportation of delivery items. The unmanned aerial vehicle includes an attachment device to fasten and unfasten one or more delivery items to the unmanned aerial vehicle, a motor to aerially transport the one or more delivery items along a delivery route, a sensor mounted on the unmanned aerial vehicle to detect at least one environmental variable during the delivery route, and an alert system to generate a status associated with the unmanned aerial vehicle along the delivery route to an observer when the environmental variable exceeds a predetermined threshold."
ALERT SYSTEM FOR AN UNMANNED AERIAL VEHICLE,https://lens.org/004-427-963-870-884,2018,"An unmanned aerial vehicle for aerial transportation of delivery items. The unmanned aerial vehicle includes an attachment device to fasten and unfasten one or more delivery items to the unmanned aerial vehicle, a motor to aerially transport the one or more delivery items along a delivery route, a sensor mounted on the unmanned aerial vehicle to detect at least one environmental variable during the delivery route, and an alert system to generate a status associated with the unmanned aerial vehicle along the delivery route to an observer when the environmental variable exceeds a predetermined threshold."
ALERT SYSTEM FOR AN UNMANNED AERIAL VEHICLE,https://lens.org/105-996-692-387-138,2017,"An unmanned aerial vehicle for aerial transportation of delivery items. The unmanned aerial vehicle includes an attachment device to fasten and unfasten one or more delivery items to the unmanned aerial vehicle, a motor to aerially transport the one or more delivery items along a delivery route, a sensor mounted on the unmanned aerial vehicle to detect at least one environmental variable during the delivery route, and an alert system to generate a status associated with the unmanned aerial vehicle along the delivery route to an observer when the environmental variable exceeds a predetermined threshold."
Alert system for an unmanned aerial vehicle,https://lens.org/173-638-851-557-090,2020,"An unmanned aerial vehicle for aerial transportation of delivery items. The unmanned aerial vehicle includes an attachment device to fasten and unfasten one or more delivery items to the unmanned aerial vehicle, a motor to aerially transport the one or more delivery items along a delivery route, a sensor mounted on the unmanned aerial vehicle to detect at least one environmental variable during the delivery route, and an alert system to generate a status associated with the unmanned aerial vehicle along the delivery route to an observer when the environmental variable exceeds a predetermined threshold."
Methods for autonomous tracking and surveillance,https://lens.org/158-649-386-227-087,2015,"A system and methods for autonomously tracking and simultaneously providing surveillance of a target from air vehicles. In one embodiment the system receives inputs from outside sources, creates tracks, identifies the targets and generates flight plans for unmanned air vehicles (UAVs) and camera controls for surveillance of the targets. The system uses predictive algorithms and aircraft control laws. The system comprises a plurality of modules configured to accomplish these tasks. One embodiment comprises an automatic target recognition (ATR) module configured to receive video information, process the video information, and produce ATR information including target information. The embodiment further comprises a multisensor integrator (MSI) module configured to receive the ATR information, an air vehicle state input and a target state input, process the inputs and produce track information for the target. The embodiment further comprises a target module configured to receive the track information, process the track information, and produce predicted future state target information. The embodiment further comprises an ownship module configured to receive the track information, process the track information, and produce predicted future state air vehicle information. The embodiment further comprises a planner module configured to receive the predicted future state target information and the predicted future state air vehicle information and generate travel path information including flight and camera steering commands for the air vehicle."
APPARATUS FOR CONTROLLING POSTURE OF RADIO-CONTROLLED HELICOPTER FOR HOBBY USE,https://lens.org/163-207-370-233-557,1994,"By this apparatus, a radio-controlled helicopter for hobby use can be operated remotely, safely and easily. The apparatus is mounted on the helicopter together with an ordinary radio control receiver. In flying the helicopter, angular velocity measuring means measures the angular velocity of yawing of the helicopter. Angle calculating means integrates the angular velocity measured and determines the angle through which the helicopter yaws. Manipulated variable determining means determines the manipulated variable of the rudder servo on the basis of a manipulated variable inputted through an inputting means, the angular velocity measured, and the angle calculated. Manipulated variable outputting means outputs the manipulated variable to the rudder servo, which operates in accordance with the manipulated variable."
"TRANSDUCER DEVICE, SONAR MODULE AND CONTROL METHOD THEREOF",https://lens.org/136-238-173-309-551,2020,"A transducer device, a sonar module (3) for use with an autonomous device (100) and a control method thereof are disclosed. The autonomous device (100) may utilize reflection distance information corresponding to different transducer components to discover changes of the surrounding environment and determine appropriate responding operations according to various criteria for different purposes. A transducer unit (6) of the sonar module (3) in embodiments of the invention comprises at least a first transducer component (60) and a second transducer component (61). The first transducer component (60) and the second transducer component (61) are coaxially arranged on a base and in circular shapes. A second pointing angle of the second transducer component (61) is smaller than a first pointing angle of the first transducer component (60)."
GROUND INDEPENDENT LIFTING SYSTEM,https://lens.org/102-080-050-305-584,2018,"A ground independent aerial lifting and transportation system (1), for lifting and/or transporting at least one object (2) having a weight in the range of from 100 to 2000 kg, wherein the system comprises at least one aerostat (3) and at least one lifting and transportation device (4) wherein said aerostat (3) is connected to at least one drone (5) having at least one rotor (6), wherein said at least one drone (5) is able to lift and carry a work load of at least 150 kg in addition to its own weight, and wherein said at least one aerostat is sized to carry the dead load of the system (1)."
System and Method for Authenticating User of Robotaxi,https://lens.org/018-920-228-820-183,2022,"An embodiment system for authenticating a user of a robotaxi includes a smart phone configured to request an authentication of the user based on a digital key, an authentication server configured to create a first authentication number, transmit the first authentication number to the smart phone, receive a second authentication number from the robotaxi when the authentication using the digital key fails, and request unlocking of a door to the robotaxi when the first authentication number and the second authentication number match, and the robotaxi configured to receive the second authentication number from the user, transmit the second authentication number to the authentication server, and unlock the door in response to the request from the authentication server."
System and Method for Authenticating User of Robotaxi,https://lens.org/018-920-228-820-183,2022,"An embodiment system for authenticating a user of a robotaxi includes a smart phone configured to request an authentication of the user based on a digital key, an authentication server configured to create a first authentication number, transmit the first authentication number to the smart phone, receive a second authentication number from the robotaxi when the authentication using the digital key fails, and request unlocking of a door to the robotaxi when the first authentication number and the second authentication number match, and the robotaxi configured to receive the second authentication number from the user, transmit the second authentication number to the authentication server, and unlock the door in response to the request from the authentication server."
System and method for authenticating user of robotaxi,https://lens.org/029-432-466-197-207,2023,"An embodiment system for authenticating a user of a robotaxi includes a smart phone configured to request an authentication of the user based on a digital key, an authentication server configured to create a first authentication number, transmit the first authentication number to the smart phone, receive a second authentication number from the robotaxi when the authentication using the digital key fails, and request unlocking of a door to the robotaxi when the first authentication number and the second authentication number match, and the robotaxi configured to receive the second authentication number from the user, transmit the second authentication number to the authentication server, and unlock the door in response to the request from the authentication server."
System and method for authenticating user of robotaxi,https://lens.org/029-432-466-197-207,2023,"An embodiment system for authenticating a user of a robotaxi includes a smart phone configured to request an authentication of the user based on a digital key, an authentication server configured to create a first authentication number, transmit the first authentication number to the smart phone, receive a second authentication number from the robotaxi when the authentication using the digital key fails, and request unlocking of a door to the robotaxi when the first authentication number and the second authentication number match, and the robotaxi configured to receive the second authentication number from the user, transmit the second authentication number to the authentication server, and unlock the door in response to the request from the authentication server."
Aerial photography device and aerial photography method thereof,https://lens.org/187-882-416-519-80X,2015,"The invention provides an aerial photography device and an aerial photography method thereof. The aerial photography device comprises an unmanned aerial vehicle (1) and at least one audio acquisition module (2, 2', 2'') arranged on the ground. The unmanned aerial vehicle (1) comprises a video acquisition module (3) and a control module (4). A timing unit (5) sends time information to the audio acquisition modules (2, 2', 2'') and the video acquisition module (3). A measuring unit (6) measures position between the unmanned aerial vehicle (1) and the audio acquisition modules (2, 2', 2'') and sends the position to a synthesis unit (7). The audio acquisition modules (2, 2', 2'') and the video acquisition module (3) separately acquire and send audio data with the time information and video data with the time information to the synthesis unit (7) according to the time information. The synthesis unit (7) synthesizes the audio data and the video data which are acquired by nearest audio acquisition modules (2, 2', 2'') according to the time information."
Vehicle altitude restrictions and control,https://lens.org/171-044-327-943-20X,2023,"An unmanned aerial vehicle (UAV) includes a vehicle body, one or more propulsion units coupled to the vehicle body and configured to effect movement of the UAV, and one or more processors coupled to the one or more propulsion units and individually or collectively configured to receive one or more sets of altitude restrictions for the UAV, receive location information indicating a current location of the UAV, determine a priority of the one or more sets of altitude restrictions by which the UAV abides based on the location information, select a set from the one or more sets of altitude restrictions based on the determined priority, and generate control signals to control the one or more propulsion units such that the UAV is operated in compliance with the selected set of altitude restrictions."
VEHICLE ALTITUDE RESTRICTIONS AND CONTROL,https://lens.org/088-335-499-661-999,2022,"An unmanned aerial vehicle (UAV) includes a vehicle body, one or more propulsion units coupled to the vehicle body and configured to effect movement of the UAV, and one or more processors coupled to the one or more propulsion units and individually or collectively configured to receive one or more sets of altitude restrictions for the UAV, receive location information indicating a current location of the UAV, determine a priority of the one or more sets of altitude restrictions by which the UAV abides based on the location information, select a set from the one or more sets of altitude restrictions based on the determined priority, and generate control signals to control the one or more propulsion units such that the UAV is operated in compliance with the selected set of altitude restrictions."
Autonomous underwater vehicle,https://lens.org/195-749-096-410-406,2020,"An autonomous underwater vehicle including an underwater vehicle main body incorporating a power source, a buoy connected to the underwater vehicle main body through a rope, and an ejector configured to, with the underwater vehicle main body floating on a sea surface, eject the buoy from the underwater vehicle main body by compressed gas in an obliquely upward direction."
SYSTEM AND METHOD FOR TESTING A WIRELESS COMMUNICATION DEVICE,https://lens.org/115-006-983-709-026,2018,"The present disclosure relates to system(s) and method(s) for testing a wireless communication device installed over an Unmanned Arial Vehicle (UAV) is illustrated. The method may comprise transmitting navigation data to an Unmanned Arial Vehicle (UAV). The method may further comprise transmitting one or more test packets, to a wireless communication device installed over the UAV when the UAV is in the vicinity of the second location. The set of test packets may be transmitted via a short range communication channel. The method may further comprise receiving one or more response data packets from the wireless communication device via a cloud communication channel. The method may further comprise generating a test report based on comparison of the one or more response data packets with the one or more test packets."
"CONTROLLER, INDOOR ENVIRONMENT ADJUSTMENT SYSTEM, AND INDOOR ENVIRONMENT ADJUSTMENT METHOD",https://lens.org/092-144-577-805-357,2017,"A controller, an indoor environment adjustment system and an indoor environment adjustment method are provided so as to automatically adjust an indoor environment. The controller is connected to at least one sensor and at least one smart home device, and configured to acquire indoor environment parameters collected by the at least one sensor, and send an adjustment instruction to the at least one smart home device in accordance with the indoor environment parameters."
"Controller, indoor environment adjustment system, and indoor environment adjustment method",https://lens.org/194-400-241-741-896,2019,"A controller, an indoor environment adjustment system and an indoor environment adjustment method are provided so as to automatically adjust an indoor environment. The controller is connected to at least one sensor and at least one smart home device, and configured to acquire indoor environment parameters collected by the at least one sensor, and send an adjustment instruction to the at least one smart home device in accordance with the indoor environment parameters."
Robot,https://lens.org/185-484-467-401-67X,2020,"A robot includes a base, an arm provided on the base and rotating around a rotation axis, a control board provided on an inside of the base and configured to control driving of the arm, a power supply board provided on the inside of the base and configured to supply electric power to the control board, and a main substrate provided on the inside of the base detachably from the base and configured to support the control board and the power supply board."
Robot,https://lens.org/053-612-940-329-296,2019,"A robot includes a base, an arm provided on the base and rotating around a rotation axis, a control board provided on an inside of the base and configured to control driving of the arm, a power supply board provided on the inside of the base and configured to supply electric power to the control board, and a main substrate provided on the inside of the base detachably from the base and configured to support the control board and the power supply board."
Device for controlling sound reproducing device and method of controlling the device,https://lens.org/103-110-660-223-640,2018,"A device and method of controlling a sound reproducing device are disclosed. The device includes a communication unit, which transmits and receives data to and from the sound reproducing device; a sensing unit, which detects a motion of the device and obtains azimuth information regarding an azimuth pointed by a pre-set region of the device based on the motion; and a control unit, which receives the azimuth information regarding the sound reproducing device from the sound reproducing device via the communication unit and, if it is determined that the azimuth information regarding the device corresponds to the azimuth information regarding the sound reproducing device within a pre-set range, determines the sound reproducing device as a controlled device."
DEVICE FOR CONTROLLING SOUND REPRODUCING DEVICE AND METHOD OF CONTROLLING THE DEVICE,https://lens.org/144-018-795-649-855,2016,"A device and method of controlling a sound reproducing device are disclosed. The device includes a communication unit, which transmits and receives data to and from the sound reproducing device; a sensing unit, which detects a motion of the device and obtains azimuth information regarding an azimuth pointed by a pre-set region of the device based on the motion; and a control unit, which receives the azimuth information regarding the sound reproducing device from the sound reproducing device via the communication unit and, if it is determined that the azimuth information regarding the device corresponds to the azimuth information regarding the sound reproducing device within a pre-set range, determines the sound reproducing device as a controlled device."
METHOD AND APPARATUS TO PROVIDE COMPREHENSIVE SMART ASSISTANT SERVICES,https://lens.org/184-419-635-218-093,2019,"An apparatus supports smart assistant services with a plurality of smart service providers (510). The apparatus includes an audio device (104) that receives a speech signal having a user utterance (154), captures the user utterance when the user utterance includes a user wake word, and sends the captured utterance to a backend computing device (105). The backend computing device replaces the user wake word with specific wake words associated with different smart service providers (502). The processed utterances (551) are then sent to selected smart service providers (502). The backend computing device subsequently constructs feedback to the user utterance based on voice responses from the different smart service providers (553). The backend computing device then passes a digital representation of the feedback (155) to the audio device, and the audio device converts the digital representation to an audio reply to the user utterance."
Tube-launched unmanned aerial vehicle,https://lens.org/112-380-625-907-330,2020,"An unmanned aerial vehicle (UAV) 1, of the vertical take-off and landing (VTOL) type that can be launched from a launcher tube 2, comprises a housing 10 and a transition mechanism 100 for transitioning the UAV 1 between a collapsed configuration for stowing the UAV 1 in a launcher tube 21 and a flight configuration. The housing 10 and the transition mechanism 100 are configured so that one or more rotors 12a-d that, in use, are connected to the transition mechanism 100 are located substantially within the housing 10 in the collapsed configuration and outside the housing 10 in the flight configuration. A launcher 2, for launching the UAV 1, comprises a hollow tube 21 for receiving a UAV 1 in a collapsed configuration and a trigger mechanism 26 for triggering a propulsion mechanism for propelling the UAV 1 out of an end of the hollow tube 21."
AUTONOMOUS VEHICLE SAFETY SYSTEM AND METHOD,https://lens.org/140-367-939-425-27X,2022,"An autonomous vehicle safety system, a method of operating the same and an autonomous vehicle equipped with the autonomous vehicle safety system. An autonomous vehicle Bluetooth receiver is connected in a signal transmitting fashion to the engine control unit of an autonomous vehicle. Upon receiving a signal from a remote Bluetooth transmitter at a predefined proximity distance between the transmitter and the receiver, a microcontroller connected to the receiver actuates a relay switch disabling the engine control unit. The engine control unit may then also engage the vehicle breaks, lock the steering in place, and only after not receiving a proximal Bluetooth signal for a particular time span, enable again the autonomous vehicle operating mode."
AUTONOMOUS VEHICLE SAFETY SYSTEM AND METHOD,https://lens.org/153-366-793-245-803,2022,"An autonomous vehicle safety system, a method of operating the same and an autonomous vehicle equipped with the autonomous vehicle safety system. An autonomous vehicle Bluetooth receiver is connected in a signal transmitting fashion to the engine control unit of an autonomous vehicle. Upon receiving a signal from a remote Bluetooth transmitter at a predefined proximity distance between the transmitter and the receiver, a microcontroller connected to the receiver actuates a relay switch disabling the engine control unit. The engine control unit may then also engage the vehicle breaks, lock the steering in place, and only after not receiving a proximal Bluetooth signal for a particular time span, enable again the autonomous vehicle operating mode."
AUTONOMOUS VEHICLE SAFETY SYSTEM AND METHOD,https://lens.org/140-367-939-425-27X,2022,"An autonomous vehicle safety system, a method of operating the same and an autonomous vehicle equipped with the autonomous vehicle safety system. An autonomous vehicle Bluetooth receiver is connected in a signal transmitting fashion to the engine control unit of an autonomous vehicle. Upon receiving a signal from a remote Bluetooth transmitter at a predefined proximity distance between the transmitter and the receiver, a microcontroller connected to the receiver actuates a relay switch disabling the engine control unit. The engine control unit may then also engage the vehicle breaks, lock the steering in place, and only after not receiving a proximal Bluetooth signal for a particular time span, enable again the autonomous vehicle operating mode."
AUTONOMOUS VEHICLE SAFETY SYSTEM AND METHOD,https://lens.org/153-366-793-245-803,2022,"An autonomous vehicle safety system, a method of operating the same and an autonomous vehicle equipped with the autonomous vehicle safety system. An autonomous vehicle Bluetooth receiver is connected in a signal transmitting fashion to the engine control unit of an autonomous vehicle. Upon receiving a signal from a remote Bluetooth transmitter at a predefined proximity distance between the transmitter and the receiver, a microcontroller connected to the receiver actuates a relay switch disabling the engine control unit. The engine control unit may then also engage the vehicle breaks, lock the steering in place, and only after not receiving a proximal Bluetooth signal for a particular time span, enable again the autonomous vehicle operating mode."
SNUBBER FOR GIMBAL WITH DOG FOR SNUBBER ELEMENTS,https://lens.org/180-916-033-960-76X,2013,"An unmanned aerial vehicle comprising: a fuselage; and a sensor system 10 coupled to the fuselage; wherein the sensor system includes: an outer shell 50; an inner gimbal 52 within the outer shell; and extendible snubbers 60 that selectively couple together the inner gimbal 52 and the outer shell 50; wherein, when the snubbers are not extended, the inner gimbal is vibrationally isolated from the outer shell, and able to move relative to the outer shell; and wherein, when the snubbers are extended, the inner gimbal is stiffly coupled to the outer shell."
Robot for assisting a user in hearing,https://lens.org/034-672-484-206-246,2022,"Provided a robot for assisting hearing of a user, while minimizing an influence on the surroundings. The robot includes a speaker, a microphone configured to recognize a voice, a processor configured to acquire a position of a user's face when a hearing aid command is acquired on the basis of the voice recognized through the microphone, and a driving unit configured to cause the speaker to be moved toward the position of the user's face, wherein the processor acquires a sound which is a target of hearing aid, generates an assistant sound by amplifying a predetermined frequency band of the sound or converting the predetermined frequency band of the sound into a different frequency band, and outputs the assistant sound through the speaker."
ROBOT,https://lens.org/041-867-133-647-158,2021,"Provided a robot for assisting hearing of a user, while minimizing an influence on the surroundings. The robot includes a speaker, a microphone configured to recognize a voice, a processor configured to acquire a position of a user's face when a hearing aid command is acquired on the basis of the voice recognized through the microphone, and a driving unit configured to cause the speaker to be moved toward the position of the user's face, wherein the processor acquires a sound which is a target of hearing aid, generates an assistant sound by amplifying a predetermined frequency band of the sound or converting the predetermined frequency band of the sound into a different frequency band, and outputs the assistant sound through the speaker."
Robot for assisting a user in hearing,https://lens.org/034-672-484-206-246,2022,"Provided a robot for assisting hearing of a user, while minimizing an influence on the surroundings. The robot includes a speaker, a microphone configured to recognize a voice, a processor configured to acquire a position of a user's face when a hearing aid command is acquired on the basis of the voice recognized through the microphone, and a driving unit configured to cause the speaker to be moved toward the position of the user's face, wherein the processor acquires a sound which is a target of hearing aid, generates an assistant sound by amplifying a predetermined frequency band of the sound or converting the predetermined frequency band of the sound into a different frequency band, and outputs the assistant sound through the speaker."
SYSTEM AND METHODS FOR AUTOMATED AIRPORT AIR TRAFFIC CONTROL SERVICES,https://lens.org/075-987-088-910-665,2014,"A system and method for automating Air Traffic Control operations at or near an airport, as a complete standalone automated system replacing the need for a human controller to make aircraft movement decisions nor the need communicate with pilots, or as semi-automated, where a controller controls how the system operates. The system with related methods and computer hardware and computer software package, automatically manages manned aircraft, remote controlled UAV and airborne-able vehicles traffic at or near an airport, eliminates ATC-induced and reduce pilot-induced runway incursions and excursions, processes control messages related to aircraft or Pilots, communicates with Pilot over ATC radio frequency, receives aircraft positions, communicates control messages with the aircraft avionics, provides pilots a dynamic airport map with continuous display of nearby traffic operations, shows clearance and information related to runway operations, warns pilot of runway conditions and turbulence from other operations, warns when landing gear is not locked, displays the pilot emergency exits during takeoff roll, shows the pilot when and where to exit from the runway, shows the pilot where and when to cross a junction, calculates and displays pilot optimal speed and timing on taxiways and junctions for saving fuel, calculates congestions, calculates best taxiway routes, calculates when aircraft can cross a runway, provides directives and information to pilot over CPDLC display or dynamic Airport map for airside operations, alerts and triggers breaks of the aircraft on wrong path or when hold-short bar is breached, displays emergency personnel with routing map and final aircraft resting position for emergency operations, takes over an aircraft operation when aircraft is hijacked or deviates from the flight plan, provide standalone or manned Remote Tower functionality, Records and retains all information related to airport airside operations including aircraft positions and conditions from sensors and reports for runways, junctions and taxiways, Records and retains aircraft data and cockpit voice to ground- based servers to eliminate black-box requirements, calculate future weather and airport capacity from aircraft at or nearby airport, coordinates handoff operations with other ATC positions, interfaces with ACDM systems, airport operations center, flow center and network operations center."
Driver Protection Cameras with Motion Activation and Beacon Locator,https://lens.org/114-177-110-073-532,2015,"A camera system used to record audio/video data includes an internal visual recording unit, an external visual recording unit, a remote control, and a remote data storage device. The internal visual recording unit and the external visual recording unit are controlled by the remote control. Both the internal visual recording unit and the external visual recording unit each have a camera that is used to record audio/video data. The remote control contains a microphone for specifically recording audio. All recorded audio/video data is transferred to the remote data storage device wirelessly. Additionally, both the internal visual recording unit and the external visual recording unit each contain a beacon locator. Data from the beacon locator are also transferred to the remote data storage device."
Design of a New Security Patrol Hexapod Robot,https://lens.org/008-035-814-231-627,2019,"This hexapod robot, which is designed for security patrolling, features strong terrain adaptability and has many functions. It is mostly used in environment like neighborhood communities, factories, military zones, natural habitats etc., where environment detection and various alarms are needed. The main body is divided into three segments. Each segment is connected by a spherical hinge with another section. They are all have two degrees of freedom due to the installation of driving motors. We designed a new kind of wheel called the OS-shaped wheel, the ""0"" mode is used for fast traveling on level ground, and the ""S"" mode is used to go across lower obstacles. The OS-shaped wheels can be switched automatically or manually."
ROTARY-WING UNMANNED AERIAL VEHICLE,https://lens.org/087-959-767-604-173,2023,A rotary wing unmanned aerial vehicle (UAV) includes an elongate body 12 having a top end 14 and a bottom end 16 with a plurality of flat sides extending therebetween and defining an internal cavity 30. An exhaust opening 32 and lift propeller 34 are provided at the bottom end 16 of the body 12. The UAV 10 further includes a pressurizing arrangement in the form of spaced-apart openings in the sides and in the top and complementary propellers mounted therein in order to urge air through the openings into the internal cavity 30. This arrangement provides a compact UAV with high lift capabilities.
ROTARY-WING UNMANNED AERIAL VEHICLE,https://lens.org/087-959-767-604-173,2023,A rotary wing unmanned aerial vehicle (UAV) includes an elongate body 12 having a top end 14 and a bottom end 16 with a plurality of flat sides extending therebetween and defining an internal cavity 30. An exhaust opening 32 and lift propeller 34 are provided at the bottom end 16 of the body 12. The UAV 10 further includes a pressurizing arrangement in the form of spaced-apart openings in the sides and in the top and complementary propellers mounted therein in order to urge air through the openings into the internal cavity 30. This arrangement provides a compact UAV with high lift capabilities.
THE REMOTE CONTROL DEVICE FOR CHANGING THE LIGHTING BULBS,https://lens.org/004-943-791-260-06X,2020,"The remote control device for changing the lighting lamp is a set, that consisting of a remote control and an operator set, which by changing the height of the lighting bulbs and its accessories, it allows the changing, inspection, or repair of this set at a lower altitude and eliminates the need for a lift or any other same devices to replace, inspect, or repair light bulbs that are located at a height, there is a need for lift and footstool to reach this set (lighting fixtures and its accessories), which always has a high risk of falling from the height. also, in people's passage when doing these things, traffic jam is created, and working at high altitudes, also poses a danger to pedestrians in those passages. the components of this remote control device are as following: cables or wires, armature or motors, power distribution boxes with fuses, power cables of motor inputs, boxes and exterior of the device, screw for connecting device to the surface, cable reel or power cord and remote control receiver. in addition to the efficiency of the city lighting system, this device can be used in homes, niches and factories as well."
DYNAMIC CONTROL OF AN UNMANNED AERIAL VEHICLE USING A RECONFIGURABLE INTELLIGENT SURFACE,https://lens.org/055-090-630-083-283,2022,A method for establishing a direct communication using an unmanned aerial vehicle (UAV) with a reconfiguration intelligent surface (RIS) includes configuring RIS parameters based on compensating for undesired oscillations of a position and an orientation associated with the UAV. A signal reflection associated with a beam signal is steered to a target area based on the RIS parameters and by the RIS of the UAV. The signal beam is from a transmitter.
DYNAMIC CONTROL OF AN UNMANNED AERIAL VEHICLE USING A RECONFIGURABLE INTELLIGENT SURFACE,https://lens.org/055-090-630-083-283,2022,A method for establishing a direct communication using an unmanned aerial vehicle (UAV) with a reconfiguration intelligent surface (RIS) includes configuring RIS parameters based on compensating for undesired oscillations of a position and an orientation associated with the UAV. A signal reflection associated with a beam signal is steered to a target area based on the RIS parameters and by the RIS of the UAV. The signal beam is from a transmitter.
Control method for unmanned aerial vehicle after the unmanned aerial vehicle has been disassembled and unmanned aerial vehicle,https://lens.org/188-741-959-279-483,2021,"An unmanned aerial vehicle (UAV) including a detection device configured to detect that a disassembly operation has been performed on the UAV and a controller configured to determine whether the disassembly operation is an unauthorized disassembly operation, and prohibit the UAV from moving in response to the disassembly operation being the unauthorized disassembly operation, where the detection device is communicatively connected to the controller."
CONTROL METHOD FOR UNMANNED AERIAL VEHICLE AFTER THE UNMANNED AERIAL VEHICLE HAS BEEN DISASSEMBLED AND UNMANNED AERIAL VEHICLE,https://lens.org/055-332-591-925-116,2020,"An unmanned aerial vehicle (UAV) including a detection device configured to detect that a disassembly operation has been performed on the UAV and a controller configured to determine whether the disassembly operation is an unauthorized disassembly operation, and prohibit the UAV from moving in response to the disassembly operation being the unauthorized disassembly operation, where the detection device is communicatively connected to the controller."
AUTOMATIC SAFETY PARACHUTE DEPLOYMENT SYSTEM FOR MULTI ROTOR DRONES,https://lens.org/197-378-283-286-183,2020,"This invention relates to the use of an automatic safety parachute deployment system for drones (UAVs), which utilizes an airflow trigger that deploys one or more parachutes under certain aerodynamic conditions from the upward airflow during a flight malfunction. The system is mechanically activated without the use of electronics, batteries or an ejection spring which reduces the complexity and weight."
Automatic safety parachute deployment system for multi rotor drones,https://lens.org/017-930-705-154-746,2022,"This invention relates to the use of an automatic safety parachute deployment system for drones (UAVs), which utilizes an airflow trigger that deploys one or more parachutes under certain aerodynamic conditions from the upward airflow during a flight malfunction. The system is mechanically activated without the use of electronics, batteries or an ejection spring which reduces the complexity and weight."
AUTOMATIC BUILDING SYSTEM CONTROL RESTRICTIONS BASED ON PHYSICAL PRESENCE DEFINED BY ACCESS CONTROL EVENT INFORMATION AND KNOWLEDGE BASE SYSTEM,https://lens.org/091-050-680-316-03X,2019,A method of controlling a building system is provided. The method comprising: receiving an action request to adjust a building device from a user device; obtaining a token from a previous action request from the user device to adjust the building device when a token exists from a previous action request; transmitting the token for validation within the building device; and adjusting the building device when the token has been validated.
Automatic building system control restrictions based on physical presence defined by access control event information and knowledge base system,https://lens.org/088-941-999-364-624,2023,A method of controlling a building system is provided. The method comprising: receiving an action request to adjust a building device from a user device; obtaining a token from a previous action request from the user device to adjust the building device when a token exists from a previous action request; transmitting the token for validation within the building device; and adjusting the building device when the token has been validated.
Automatic building system control restrictions based on physical presence defined by access control event information and knowledge base system,https://lens.org/088-941-999-364-624,2023,A method of controlling a building system is provided. The method comprising: receiving an action request to adjust a building device from a user device; obtaining a token from a previous action request from the user device to adjust the building device when a token exists from a previous action request; transmitting the token for validation within the building device; and adjusting the building device when the token has been validated.
AUTOMATIC BUILDING SYSTEM CONTROL RESTRICTIONS BASED ON PHYSICAL PRESENCE DEFINED BY ACCESS CONTROL EVENT INFORMATION AND KNOWLEDGE BASE SYSTEM,https://lens.org/194-417-112-506-313,2020,A method of controlling a building system is provided. The method comprising: receiving an action request to adjust a building device from a user device; obtaining a token from a previous action request from the user device to adjust the building device when a token exists from a previous action request; transmitting the token for validation within the building device; and adjusting the building device when the token has been validated.
KEYPAD PROJECTION,https://lens.org/196-548-202-545-810,2017,"A method for security and/or automation systems is described. In one embodiment, the method may include detecting a proximity of a user at a home automation device. The method may further include projecting an external display of home automation system information from the home automation device onto a surface. In some embodiments, the external display may be projected based, at least in part, on the detected proximity of the user at the home automation device."
KEYPAD PROJECTION,https://lens.org/055-634-042-541-375,2016,"A method for security and/or automation systems is described. In one embodiment, the method may include detecting a proximity of a user at a home automation device. The method may further include projecting an external display of home automation system information from the home automation device onto a surface. In some embodiments, the external display may be projected based, at least in part, on the detected proximity of the user at the home automation device."
Keypad projection,https://lens.org/154-506-354-383-92X,2018,"A method for security and/or automation systems is described. In one embodiment, the method may include detecting a proximity of a user at a home automation device. The method may further include projecting an external display of home automation system information from the home automation device onto a surface. In some embodiments, the external display may be projected based, at least in part, on the detected proximity of the user at the home automation device."
Keypad projection,https://lens.org/020-018-368-588-422,2016,"A method for security and/or automation systems is described. In one embodiment, the method may include detecting a proximity of a user at a home automation device. The method may further include projecting an external display of home automation system information from the home automation device onto a surface. In some embodiments, the external display may be projected based, at least in part, on the detected proximity of the user at the home automation device."
Keypad projection,https://lens.org/156-437-289-275-207,2021,"A method for security and/or automation systems is described. In one embodiment, the method may include detecting a proximity of a user at a home automation device. The method may further include projecting an external display of home automation system information from the home automation device onto a surface. In some embodiments, the external display may be projected based, at least in part, on the detected proximity of the user at the home automation device."
Detection and communication of safety events,https://lens.org/099-472-834-198-875,2022,An Unmanned aerial vehicle (UAV) for detecting and communicating safety-related events to a safety server is provided. A network status of a communication network over which devices associated with the vehicle are communicating with the safety server is identified. The UAV receives metadata including at least location data from the devices when the network status of the communication network indicates low or unavailable connectivity that is hindering communication of the metadata to the safety server by the devices. The UAV processes the metadata and detects safety events associated with the vehicle. The UAV communicates the safety events to the safety server based on at least a safety criterion including detachment of the UAV from the vehicle when the UAV is unable to communicate with the safety server in its attached configuration with the vehicle due to network issues.
Detection and Communication of Safety Events,https://lens.org/166-684-411-951-127,2020,An Unmanned aerial vehicle (UAV) for detecting and communicating safety-related events to a safety server is provided. A network status of a communication network over which devices associated with the vehicle are communicating with the safety server is identified. The UAV receives metadata including at least location data from the devices when the network status of the communication network indicates low or unavailable connectivity that is hindering communication of the metadata to the safety server by the devices. The UAV processes the metadata and detects safety events associated with the vehicle. The UAV communicates the safety events to the safety server based on at least a safety criterion including detachment of the UAV from the vehicle when the UAV is unable to communicate with the safety server in its attached configuration with the vehicle due to network issues.
Detection and Communication of Safety Events,https://lens.org/166-684-411-951-127,2020,An Unmanned aerial vehicle (UAV) for detecting and communicating safety-related events to a safety server is provided. A network status of a communication network over which devices associated with the vehicle are communicating with the safety server is identified. The UAV receives metadata including at least location data from the devices when the network status of the communication network indicates low or unavailable connectivity that is hindering communication of the metadata to the safety server by the devices. The UAV processes the metadata and detects safety events associated with the vehicle. The UAV communicates the safety events to the safety server based on at least a safety criterion including detachment of the UAV from the vehicle when the UAV is unable to communicate with the safety server in its attached configuration with the vehicle due to network issues.
MARINE SURFACE DRONE AND METHOD FOR CHARACTERISING AN UNDERWATER ENVIRONMENT IMPLEMENTED BY SUCH A DRONE,https://lens.org/031-163-696-274-334,2020,"Disclosed is a marine surface drone including: - an on-board multi-beam sonar; - a system for controlling the sonar, configured to command, for a given position of the drone, a plurality of consecutive transmissions of acoustic waves, the control system controlling the sonar transmitters so as to vary the characteristics of the transmitted acoustic waves, from one of the transmissions to the next, and - an acquisition unit configured to determine, from echo signals acquired in response to the plurality of transmissions, a three-dimensional image representing the content of a given observation volume. The invention also relates to a method for characterising an underwear environment, implemented by such a drone."
Automatic take-off control strategy design of small unmanned helicopter,https://lens.org/065-776-883-849-557,2015,"The invention discloses an automatic take-off control strategy design for a small unmanned helicopter, comprising steps of 1 determining whether a take-off order is responded, if yes, automatically starting up an engine and applying rotation speed stable control, 2 recording information of current longitude, height and yaw angle and solving mean values,3 if the step 2 determines that the rotation speed of the engine is stable, performing self-increscent on the collective pitch, 4 if the step 3 determines that the collective pitch reaches the pre-off-land collective pitch, performing plane position and posture control on the helicopter and continuously performing self-increment on the collective pitch until the helicopter is off the land, 5 if the step 4 determines that the helicopter is off the land, updating the collective pitch balancing value and invoking a vertical channel control law until the preset take-off height is approached, and if the step 5 determines that the take-off height is reached, and invoking a spot hovering control law to finish the take-off. The automatic take-off control strategy design for the small unmanned helicopter can improve the automatic take-off capability of the miniaturized unmanned helicopter and enhances the usage range, and is small in complexity and high in reliability."
Remote control programming using images,https://lens.org/056-672-273-592-026,2017,Imaging capabilities of a remote control are leveraged to automatically identify a remotely controllable device and program the remote control accordingly. The remote control uses its built-in image device to obtain an image of a remotely controllable device. The image is processed and compared to a database to determine the specific type of device. Other variations include information of a location of the remote control and/or a location of a controllable device to facilitate in determining and controlling a device.
Remote control programming using images,https://lens.org/114-802-654-680-040,2016,Imaging capabilities of a remote control are leveraged to automatically identify a remotely controllable device and program the remote control accordingly. The remote control uses its built-in image device to obtain an image of a remotely controllable device. The image is processed and compared to a database to determine the specific type of device. Other variations include information of a location of the remote control and/or a location of a controllable device to facilitate in determining and controlling a device.
REMOTE CONTROL PROGRAMMING USING IMAGES,https://lens.org/137-510-848-065-871,2016,Imaging capabilities of a remote control are leveraged to automatically identify a remotely controllable device and program the remote control accordingly. The remote control uses its built-in image device to obtain an image of a remotely controllable device. The image is processed and compared to a database to determine the specific type of device. Other variations include information of a location of the remote control and/or a location of a controllable device to facilitate in determining and controlling a device.
REMOTE CONTROL PROGRAMMING USING IMAGES,https://lens.org/148-874-398-765-489,2014,Imaging capabilities of a remote control are leveraged to automatically identify a remotely controllable device and program the remote control accordingly. The remote control uses its built-in image device to obtain an image of a remotely controllable device. The image is processed and compared to a database to determine the specific type of device. Other variations include information of a location of the remote control and/or a location of a controllable device to facilitate in determining and controlling a device.
AIR MOBILITY AND CONTROL METHOD THEREOF,https://lens.org/090-543-826-158-118,2023,"An air mobility includes a global navigation satellite system (GNSS) receiver, an antenna array, and a controller electrically connected to the GNSS receiver and the antenna array. The controller is configured to identify a first location of the air mobility including an altitude of the air mobility based on an output of the GNSS receiver, identify a first relative direction of facing a communication target with respect to the first location of the air mobility, control the antenna array so that a wireless signal by the antenna array is deflected in the first relative direction, predict a second relative direction of facing the communication target based on a movement of the air mobility, and control the antenna array so that the wireless signal by the antenna array is deflected in the second relative direction."
Telematics process for helicopters,https://lens.org/115-075-458-038-083,2005,"The invention relates to a telematics method for helicopters. According to the inventive method, the use spectrum of helicopters which are provided with all-weather flight guidance and obstacle warning systems is enlarged and flight security is further improved by transmitting data and/or speech by means of terrestrial and/or satellite-supported mobile radio telecommunications networks and by connecting to a locating system. Logistics processes of the helicopter operation and of the institutions benefiting from a helicopter use are optimized."
SYSTEMS AND METHODS FOR DETECTING PROPELLERS,https://lens.org/118-948-327-775-058,2020,"A propulsion assembly for an unmanned aerial vehicle (UAV) includes a motor configured to rotate in a first direction, a propeller seat configured to be driven by the motor to rotate in the first direction and to receive a propeller, and a sensor configured to collect sensing data useful for determining whether the propeller is locked to the propeller seat, without requiring operation of the motor."
Systems and methods for detecting propellers,https://lens.org/189-105-178-798-941,2022,"A propulsion assembly for an unmanned aerial vehicle (UAV) includes a motor configured to rotate in a first direction, a propeller seat configured to be driven by the motor to rotate in the first direction and to receive a propeller, and a sensor configured to collect sensing data useful for determining whether the propeller is locked to the propeller seat, without requiring operation of the motor."
Systems and methods for detecting propellers,https://lens.org/189-105-178-798-941,2022,"A propulsion assembly for an unmanned aerial vehicle (UAV) includes a motor configured to rotate in a first direction, a propeller seat configured to be driven by the motor to rotate in the first direction and to receive a propeller, and a sensor configured to collect sensing data useful for determining whether the propeller is locked to the propeller seat, without requiring operation of the motor."
SYSTEMS AND METHODS FOR PROVIDING DYNAMIC COMMUNICATIVE LIGHTING IN A ROBOTIC ENVIRONMENT,https://lens.org/147-352-175-291-699,2017,"A robotic system is disclosed that includes an articulated arm with an end effector. The robotic system is for use in a robotic environment requiring interaction with persons in the robotic environment, and includes a plurality of lights that are illuminated responsive to known near-future movements of the articulated arm to convey the known near-future movements of the articulated arm to the persons in the robot environment"
SYSTEMS AND METHODS FOR PROVIDING DYNAMIC COMMUNICATIVE LIGHTING IN A ROBOTIC ENVIRONMENT,https://lens.org/112-995-887-815-672,2019,"A robotic system is disclosed that includes an articulated arm with an end effector. The robotic system is for use in a robotic environment requiring interaction with persons in the robotic environment, and includes a plurality of lights that are illuminated responsive to known near-future movements of the articulated arm to convey the known near-future movements of the articulated arm to the persons in the robot environment"
SYSTEMS AND METHODS FOR PROVIDING DYNAMIC COMMUNICATIVE LIGHTING IN A ROBOTIC ENVIRONMENT,https://lens.org/049-620-647-508-178,2021,"A robotic system is disclosed that includes an articulated arm with an end effector. The robotic system is for use in a robotic environment requiring interaction with persons in the robotic environment, and includes a plurality of lights that are illuminated responsive to known near-future movements of the articulated arm to convey the known near-future movements of the articulated arm to the persons in the robot environment"
Removable sensor payload system for unmanned aerial vehicle performing media capture and property analysis,https://lens.org/129-380-712-210-977,2022,"An unmanned aerial vehicle (UAV) may couple to a sensor payload device that includes cameras, radar, lidar, and/or other sensors. The UAV, coupled to the sensor payload device, may fly within the airspace of and/or around a property and capture images and/or sensor measurements of the property. The images and sensor measurements may be certified so that they may be verified as unaltered by viewers. A 3D representation of the property may be generated, and defects in the property may be detected by comparing the 3D representation to media depicting property defects. A report identifying the defects may be generated."
REMOVABLE SENSOR PAYLOAD SYSTEM FOR UNMANNED AERIAL VEHICLE PERFORMING MEDIA CAPTURE AND PROPERTY ANALYSIS,https://lens.org/058-394-360-237-44X,2023,"An unmanned aerial vehicle (UAV) may couple to a sensor payload device that includes cameras, radar, lidar, and/or other sensors. The UAV, coupled to the sensor payload device, may fly within the airspace of and/or around a property and capture images and/or sensor measurements of the property. The images and sensor measurements may be certified so that they may be verified as unaltered by viewers. A 3D representation of the property may be generated, and defects in the property may be detected by comparing the 3D representation to media depicting property defects. A report identifying the defects may be generated."
REMOVABLE SENSOR PAYLOAD SYSTEM FOR UNMANNED AERIAL VEHICLE PERFORMING MEDIA CAPTURE AND PROPERTY ANALYSIS,https://lens.org/008-091-825-025-382,2020,"An unmanned aerial vehicle (UAV) may couple to a sensor payload device that includes cameras, radar, lidar, and/or other sensors. The UAV, coupled to the sensor payload device, may fly within the airspace of and/or around a property and capture images and/or sensor measurements of the property. The images and sensor measurements may be certified so that they may be verified as unaltered by viewers. A 3D representation of the property may be generated, and defects in the property may be detected by comparing the 3D representation to media depicting property defects. A report identifying the defects may be generated."
Removable sensor payload system for unmanned aerial vehicle performing media capture and property analysis,https://lens.org/129-380-712-210-977,2022,"An unmanned aerial vehicle (UAV) may couple to a sensor payload device that includes cameras, radar, lidar, and/or other sensors. The UAV, coupled to the sensor payload device, may fly within the airspace of and/or around a property and capture images and/or sensor measurements of the property. The images and sensor measurements may be certified so that they may be verified as unaltered by viewers. A 3D representation of the property may be generated, and defects in the property may be detected by comparing the 3D representation to media depicting property defects. A report identifying the defects may be generated."
PLURAL RELAY SENSOR DELIVERY SYSTEM,https://lens.org/060-093-771-598-568,2023,A system for sending surveillance signals from a hostile environment to an operator. The system comprises an operably movable tractor for ground hauling a trailer and an independently operable drone. The trailer has an actuatable elevator for holding a stockpile of relay sensors and comprising a pair of co-acting elevator belts defining a chute therebetween. The elevator holds a stack of relay sensors for elevation to a pickup-position by the drone. Optionally a conveyor chute may replenish the stack of relay sensors in the elevator.
Unmanned aerial vehicle as well as direction finding system,https://lens.org/165-788-496-332-578,2023,"An unmanned aerial vehicle includes a main body and at least two rotor units configured to propel the unmanned aerial vehicle. The unmanned aerial vehicle includes at least two antenna units configured to receive a radio signal. The antenna units are located with respect to the main body such that the antenna units are assigned to different lateral sides of the main body. Further, a direction finding system is described."
UNMANNED AERIAL VEHICLE AS WELL AS DIRECTION FINDING SYSTEM,https://lens.org/069-091-184-180-181,2021,"An unmanned aerial vehicle includes a main body and at least two rotor units configured to propel the unmanned aerial vehicle. The unmanned aerial vehicle includes at least two antenna units configured to receive a radio signal. The antenna units are located with respect to the main body such that the antenna units are assigned to different lateral sides of the main body. Further, a direction finding system is described."
UAV authentication method and system,https://lens.org/102-704-824-777-167,2020,"An authentication method includes that an authentication apparatus of an unmanned aerial vehicle (UAV) generates a session key, the authentication apparatus receives a device identification (ID) of a device and a randomly generated random number from the device of the UAV, the authentication apparatus obtains a device key of the device according to the device ID of the device, the authentication apparatus encrypts the session key and the random number according to the device key of the device, and the authentication apparatus sends the encrypted session key and the encrypted random number to the device."
UAV AUTHENTICATION METHOD AND SYSTEM,https://lens.org/010-025-327-056-756,2018,"An authentication method includes that an authentication apparatus of an unmanned aerial vehicle (UAV) generates a session key, the authentication apparatus receives a device identification (ID) of a device and a randomly generated random number from the device of the UAV, the authentication apparatus obtains a device key of the device according to the device ID of the device, the authentication apparatus encrypts the session key and the random number according to the device key of the device, and the authentication apparatus sends the encrypted session key and the encrypted random number to the device."
CROWD-SOURCED DETECTION AND TRACKING OF UNMANNED AERIAL SYSTEMS,https://lens.org/052-083-070-798-277,2021,"A method includes receiving (502) a first notification of an unmanned aerial system (UAS) (306) flying in an area. The method also includes sending (504) a second notification to multiple mobile devices (102a-102d, 200, 304) of multiple users (302) located in the area, where the second notification requests the multiple users to look for the UAS. The method further includes receiving (508) information about the UAS from one or more of the mobile devices of one or more of the users, where the information is obtained by the one or more mobile devices. The method also includes determining (510) an assessment of the UAS based on the information about the UAS received from the one or more mobile devices. In addition, the method includes sending (512) a third notification to at least some of the mobile devices, where the third notification includes information regarding the assessment of the UAS."
SYSTEMS AND METHODS FOR MONITORING FLIGHT,https://lens.org/105-091-997-406-049,2018,A device for recording user operation data for a remotely controlled vehicle includes a memory off-board the remotely controlled vehicle and a housing receiving the memory. The memory is configured to record user operation data comprising outgoing operation commands that affect operation of the remotely controlled vehicle. The outgoing operation commands are received via a remote controller of the remotely controlled vehicle and transmitted to the remotely controlled vehicle. The housing is removable from the remote controller and more resistant to destruction than the rest of the remote controller.
Systems and methods for monitoring flight,https://lens.org/088-467-306-498-094,2020,A device for recording user operation data for a remotely controlled vehicle includes a memory off-board the remotely controlled vehicle and a housing receiving the memory. The memory is configured to record user operation data comprising outgoing operation commands that affect operation of the remotely controlled vehicle. The outgoing operation commands are received via a remote controller of the remotely controlled vehicle and transmitted to the remotely controlled vehicle. The housing is removable from the remote controller and more resistant to destruction than the rest of the remote controller.
Aerially deployed illumination system,https://lens.org/046-772-267-020-14X,2013,"An aerially deployed illumination system is provided which may be remotely operated or preprogrammed to illuminate a designated target, such as a geographic area, vehicle, or personnel. In particular, a remotely controlled UAV having an illumination system disposed thereon is provided, the illumination system comprised of a concentrated light source and light movement apparatus operable to rapidly scan the target with the light source, thereby providing an illusion of a large area of illumination. Preferably, a line is created from the light source, the line being rapidly moved over the target in specific patterns and at specific frequencies. The system may further include a plurality of UAV's capable of ad hoc networking, so as to illuminate both large areas, as well as stationary and moving targets. In addition, the UAV's having an illumination system disposed thereon may be disposed within a projectile, the projectile tube or gun launched, and the UAV ejected from the projectile over a designated target, thereby enabling quick delivery of the UAV to an area of interest."
Aerially Deployed Illumination System,https://lens.org/194-001-741-719-291,2012,"An aerially deployed illumination system is provided which may be remotely operated or preprogrammed to illuminate a designated target, such as a geographic area, vehicle, or personnel. In particular, a remotely controlled UAV having an illumination system disposed thereon is provided, the illumination system comprised of a concentrated light source and light movement apparatus operable to rapidly scan the target with the light source, thereby providing an illusion of a large area of illumination. Preferably, a line is created from the light source, the line being rapidly moved over the target in specific patterns and at specific frequencies. The system may further include a plurality of UAV's capable of ad hoc networking, so as to illuminate both large areas, as well as stationary and moving targets. In addition, the UAV's having an illumination system disposed thereon may be disposed within a projectile, the projectile tube or gun launched, and the UAV ejected from the projectile over a designated target, thereby enabling quick delivery of the UAV to an area of interest."
UNMANNED AERIAL VEHICLE (UAV) SYSTEMS AND METHODS FOR MAINTAINING ROADWAY PERSONNEL SAFETY,https://lens.org/054-197-424-104-526,2022,"An unmanned aerial vehicle (UAV) system for maintaining roadway personnel safety includes a monitoring device configured to be worn by a user and to provide a notification, a UAV including a sensor configured to sense a signal indicating a railway condition and/or a railway event, and a ground station configured to house the UAV when the UAV is not in use. The ground station is further configured to be mounted on a train or vehicle. The system further includes a processor and a memory that contains instructions, which, when executed by the processor, cause the system to selectively deploy the UAV from the ground station when the ground station is supported on the train or the vehicle, receive the signal from the sensor, detect the railway condition and/or the railway event based on the received signal, and transmit the notification to the monitoring device based on the based on the sensed signal."
UNMANNED AERIAL VEHICLE (UAV) SYSTEMS AND METHODS FOR MAINTAINING ROADWAY PERSONNEL SAFETY,https://lens.org/054-197-424-104-526,2022,"An unmanned aerial vehicle (UAV) system for maintaining roadway personnel safety includes a monitoring device configured to be worn by a user and to provide a notification, a UAV including a sensor configured to sense a signal indicating a railway condition and/or a railway event, and a ground station configured to house the UAV when the UAV is not in use. The ground station is further configured to be mounted on a train or vehicle. The system further includes a processor and a memory that contains instructions, which, when executed by the processor, cause the system to selectively deploy the UAV from the ground station when the ground station is supported on the train or the vehicle, receive the signal from the sensor, detect the railway condition and/or the railway event based on the received signal, and transmit the notification to the monitoring device based on the based on the sensed signal."
Trainable transceiver and camera systems and methods,https://lens.org/104-576-226-451-246,2017,"A system for installation in a vehicle and for controlling a remote device includes a camera, a trainable transceiver, and a control circuit coupled to the camera and the trainable transceiver. The control circuit is configured to use geographic location information to determine when to initiate a process of using the camera to identify the remote device and transmit an activation signal formatted to control the remote device. Upon initiation of the process, the control circuit is configured to use the camera to identify the remote device by comparing information received via the camera to information stored in memory, and wherein the control circuit is configured to automatically transmit an activation signal formatted to control the remote device, using the trainable transceiver, in response to identifying the remote device."
Voice command security and authorization in user computing devices,https://lens.org/141-993-628-894-575,2023,"Techniques described herein include receiving, authorizing, and processing voice commands to control computing devices and perform various device capabilities. In some examples, a user computing device may implement voice command functionality using multiple independent components, with shared security credentials established between different combinations of components. An intermediate voice authorization component may receive and compare voice input data received from a user interface component with voice template data stored securely by a voice data component, to protect against a component becoming compromised by malware or exposure to an untrusted system. Voice commands may be used to execute, disable, or enable various capabilities on the user device, including different device applications and features, and may be authorized by different users with various security and authorization techniques."
UNMANNED AERIAL VEHICLE (UAV) SYSTEMS AND METHODS FOR MAINTAINING RAILWAY SITUATIONAL AWARENESS,https://lens.org/022-870-965-862-537,2022,"An unmanned aerial vehicle (UAV) system for maintaining railway situational awareness, includes a ground station configured to be mounted to a train, a UAV including a sensor, a processor, and a memory. The sensor is configured to provide a signal indicative of condition and/or an event. The memory contains instructions, which, when executed by the processor, cause the system to: selectively deploy the UAV, from the ground station mounted to the train, receive the signal from the sensor; and determine a condition and/or an event, relative to the train, based on the sensed signal."
UNMANNED AERIAL VEHICLE (UAV) SYSTEMS AND METHODS FOR MAINTAINING RAILWAY SITUATIONAL AWARENESS,https://lens.org/022-870-965-862-537,2022,"An unmanned aerial vehicle (UAV) system for maintaining railway situational awareness, includes a ground station configured to be mounted to a train, a UAV including a sensor, a processor, and a memory. The sensor is configured to provide a signal indicative of condition and/or an event. The memory contains instructions, which, when executed by the processor, cause the system to: selectively deploy the UAV, from the ground station mounted to the train, receive the signal from the sensor; and determine a condition and/or an event, relative to the train, based on the sensed signal."
DEVICE FOR CONTROLLING THE DISPLAY OF A WEATHER RADAR IMAGE ON BOARD AN AIRCRAFT,https://lens.org/162-245-636-552-565,2015,"The device for controlling the display of a radar image on board an aircraft, in particular a weather radar image, is suitable for performing at least one predetermined test on a radar echo in order to decide on a representation corresponding to the echo in a radar image display."
Payload-release device position tracking,https://lens.org/167-722-701-362-532,2020,"An unmanned aerial vehicle (UAV) is disclosed that includes a retractable payload delivery system. The payload delivery system can lower a payload to the ground using a delivery device that secures the payload during descent and releases the payload upon reaching the ground. The location of the delivery device can be determined as it is lowered to the ground using image tracking. The UAV can include an imaging system that captures image data of the suspended delivery device and identifies image coordinates of the delivery device, and the image coordinates can then be mapped to a location. The UAV may also be configured to account for any deviations from a planned path of descent in real time to effect accurate delivery locations of released payloads."
Payload-Release Device Position Tracking,https://lens.org/054-457-612-484-245,2018,"An unmanned aerial vehicle (UAV) is disclosed that includes a retractable payload delivery system. The payload delivery system can lower a payload to the ground using a delivery device that secures the payload during descent and releases the payload upon reaching the ground. The location of the delivery device can be determined as it is lowered to the ground using image tracking. The UAV can include an imaging system that captures image data of the suspended delivery device and identifies image coordinates of the delivery device, and the image coordinates can then be mapped to a location. The UAV may also be configured to account for any deviations from a planned path of descent in real time to effect accurate delivery locations of released payloads."
Translational correction of payload-release device based on tracked position,https://lens.org/071-340-498-235-807,2017,"An unmanned aerial vehicle (UAV) is disclosed that includes a retractable payload delivery system. The payload delivery system can lower a payload to the ground using a delivery device that secures the payload during descent and releases the payload upon reaching the ground. The location of the delivery device can be determined as it is lowered to the ground using image tracking. The UAV can include an imaging system that captures image data of the suspended delivery device and identifies image coordinates of the delivery device, and the image coordinates can then be mapped to a location. The UAV may also be configured to account for any deviations from a planned path of descent in real time to effect accurate delivery locations of released payloads."
Payload-Release Device Position Tracking,https://lens.org/190-065-654-268-32X,2023,"An unmanned aerial vehicle (UAV) is disclosed that includes a retractable payload delivery system. The payload delivery system can lower a payload to the ground using a delivery device that secures the payload during descent and releases the payload upon reaching the ground. The location of the delivery device can be determined as it is lowered to the ground using image tracking. The UAV can include an imaging system that captures image data of the suspended delivery device and identifies image coordinates of the delivery device, and the image coordinates can then be mapped to a location. The UAV may also be configured to account for any deviations from a planned path of descent in real time to effect accurate delivery locations of released payloads."
Payload-Release Device Position Tracking,https://lens.org/109-681-196-405-092,2020,"An unmanned aerial vehicle (UAV) is disclosed that includes a retractable payload delivery system. The payload delivery system can lower a payload to the ground using a delivery device that secures the payload during descent and releases the payload upon reaching the ground. The location of the delivery device can be determined as it is lowered to the ground using image tracking. The UAV can include an imaging system that captures image data of the suspended delivery device and identifies image coordinates of the delivery device, and the image coordinates can then be mapped to a location. The UAV may also be configured to account for any deviations from a planned path of descent in real time to effect accurate delivery locations of released payloads."
Payload-release device position tracking,https://lens.org/101-136-402-831-38X,2017,"An unmanned aerial vehicle (UAV) is disclosed that includes a retractable payload delivery system. The payload delivery system can lower a payload to the ground using a delivery device that secures the payload during descent and releases the payload upon reaching the ground. The location of the delivery device can be determined as it is lowered to the ground using image tracking. The UAV can include an imaging system that captures image data of the suspended delivery device and identifies image coordinates of the delivery device, and the image coordinates can then be mapped to a location. The UAV may also be configured to account for any deviations from a planned path of descent in real time to effect accurate delivery locations of released payloads."
Autonomous mobile apparatus and method of mobility,https://lens.org/051-626-463-374-004,2012,"When an autonomous mobile apparatus moves autonomously along near a master and there is an object in the surrounding environment recognized by a camera and a communication device and the like, a danger level detecting portion detects a danger level of the object to the master, and an actuator controlling portion and an electric motor move the autonomous mobile apparatus based on the danger level. As a result, the autonomous mobile apparatus moves autonomously along near the master, as well as detects the danger level to the master and moves based on the danger level. Accordingly, the autonomous mobile apparatus can move in a manner so as to ensure the safety of the master taking this danger level into account."
AUTONOMOUS MOBILE APPARATUS AND METHOD OF MOBILITY,https://lens.org/090-747-820-534-594,2010,"When an autonomous mobile apparatus moves autonomously along near a master and there is an object in the surrounding environment recognized by a camera and a communication device and the like, a danger level detecting portion detects a danger level of the object to the master, and an actuator controlling portion and an electric motor move the autonomous mobile apparatus based on the danger level. As a result, the autonomous mobile apparatus moves autonomously along near the master, as well as detects the danger level to the master and moves based on the danger level. Accordingly, the autonomous mobile apparatus can move in a manner so as to ensure the safety of the master taking this danger level into account."
SYSTEM AND METHOD FOR INSPECTING STABILITY OF HEAT TRANSFER PIPE BY USING DRONE,https://lens.org/044-178-334-070-960,2022,"A system according to an embodiment of the present invention relates to a system for inspecting the stability of a heat transfer pipe by using a drone, the system comprising: the drone including a global positioning system (GPS) module and a thermal imaging camera that captures images of the heat transfer pipe to generate a heat map; and a control unit that receives, from the drone, information about the location of a rupture in the heat transfer pipe, identifies the location of the rupture in the heat transfer pipe, and controls the flight of the drone, wherein the drone loads the heat map onto a geographic information system (GIS) and is configured to compare the heat map with an initial heat transfer pipe and, when the heat map does not match the initial heat transfer pipe, generate and transmit the information about the location of the rupture in the heat transfer pipe."
SYSTEM AND METHOD FOR INSPECTING STABILITY OF HEAT TRANSFER PIPE BY USING DRONE,https://lens.org/044-178-334-070-960,2022,"A system according to an embodiment of the present invention relates to a system for inspecting the stability of a heat transfer pipe by using a drone, the system comprising: the drone including a global positioning system (GPS) module and a thermal imaging camera that captures images of the heat transfer pipe to generate a heat map; and a control unit that receives, from the drone, information about the location of a rupture in the heat transfer pipe, identifies the location of the rupture in the heat transfer pipe, and controls the flight of the drone, wherein the drone loads the heat map onto a geographic information system (GIS) and is configured to compare the heat map with an initial heat transfer pipe and, when the heat map does not match the initial heat transfer pipe, generate and transmit the information about the location of the rupture in the heat transfer pipe."
Hybrid unmanned aerial vehicle,https://lens.org/147-410-322-575-425,2021,"A hybrid unmanned aerial vehicle (UAV) 100 comprises a body with at least one battery 120 disposed in a dedicated space of the body and at least one electrical motor for operating at least one propeller 110 of the UAV. The at least one electrical motor is configured to operate on the energy provided by the at least one battery. The UAV comprises a liquid or gaseous fuel powered, and liquid cooled power generator for charging the at least one battery. A coolant circulator pump circulates liquid coolant of the power generator and a radiator 115 is configured to transfer thermal energy from the liquid coolant to air passing through the radiator. The UAV further comprises a configurable deflector frame 170 disposed adjacent to the radiator and configured to deflect the heated air flow from the radiator. The deflector frame is selectively configurable for deflecting said heated air flow away from the body of the UAV when ambient temperature is in a first temperature range in which performance of the at least one battery is at or near nominal, and for deflecting said heated air flow towards said dedicated space for warming up the at least one battery when ambient temperature is in a second temperature range in which performance of the at least one battery would otherwise become lowered, wherein the second temperature range is below said first temperature range."
SYSTEMS AND METHODS FOR HYBRID AUTONOMOUS CONTROL OF AN ELECTRIC AIRCRAFT,https://lens.org/063-659-442-591-321,2023,"A system and method for hybrid autonomous control of an electric aircraft is provided. The system generally includes a sensor and a flight controller. The sensor is configured to detect an aircraft position datum, detect an aircraft rate datum, and transmit the aircraft position datum and the aircraft rate datum to a flight controller. The flight controller is configured to receive an aircraft position datum, to receive an aircraft rate datum, and to generate a recommended autopilot output as a function of at least a threshold datum, the aircraft position datum, and the aircraft rate datum."
SYSTEMS AND METHODS FOR HYBRID AUTONOMOUS CONTROL OF AN ELECTRIC AIRCRAFT,https://lens.org/063-659-442-591-321,2023,"A system and method for hybrid autonomous control of an electric aircraft is provided. The system generally includes a sensor and a flight controller. The sensor is configured to detect an aircraft position datum, detect an aircraft rate datum, and transmit the aircraft position datum and the aircraft rate datum to a flight controller. The flight controller is configured to receive an aircraft position datum, to receive an aircraft rate datum, and to generate a recommended autopilot output as a function of at least a threshold datum, the aircraft position datum, and the aircraft rate datum."
"VOICE RECOGNITION APPARATUS, VEHICLE HAVING THE SAME, AND CONTROL METHOD OF VOICE RECOGNITION APPARATUS",https://lens.org/129-738-641-383-187,2018,"A voice recognition apparatus may include a receiver configured to receive a voice command; a provider configured to output a guidance message; and a controller configured to control the provider in response to the voice command, analyze a listening pattern of the guidance message transmitted by the receiver, and adjust an output of the guidance message based on the listening pattern."
Method and system for receiving and displaying UAV data,https://lens.org/004-428-748-769-980,2023,"A handheld computing device comprises: a display; a camera operable to capture image data representing a scene, the scene comprising a UAV; an RF receiver configured to receive identification data wirelessly from the UAV as a result of the UAV having broadcast the identification data; and a controller configured to cause the received identification data and/or data based on the received identification data to be displayed on the display at the same time as a representation of the UAV."
Method and system for receiving and displaying UAV data,https://lens.org/004-428-748-769-980,2023,"A handheld computing device comprises: a display; a camera operable to capture image data representing a scene, the scene comprising a UAV; an RF receiver configured to receive identification data wirelessly from the UAV as a result of the UAV having broadcast the identification data; and a controller configured to cause the received identification data and/or data based on the received identification data to be displayed on the display at the same time as a representation of the UAV."
"METHODS, COMPUTER PROGRAMS, COMPUTING DEVICES AND CONTROLLERS",https://lens.org/021-511-378-041-135,2020,"A handheld computing device comprises: a display; a camera operable to capture image data representing a scene, the scene comprising a UAV; an RF receiver configured to receive identification data wirelessly from the UAV as a result of the UAV having broadcast the identification data; and a controller configured to cause the received identification data and/or data based on the received identification data to be displayed on the display at the same time as a representation of the UAV."
"METHODS, COMPUTER PROGRAMS, COMPUTING DEVICES AND CONTROLLERS",https://lens.org/136-217-935-099-683,2023,"A handheld computing device comprises: a display; a camera operable to capture image data representing a scene, the scene comprising a UAV; an RF receiver configured to receive identification data wirelessly from the UAV as a result of the UAV having broadcast the identification data; and a controller configured to cause the received identification data and/or data based on the received identification data to be displayed on the display at the same time as a representation of the UAV."
"REMOTE-CONTROLLED TOY AIRCRAFT FOR USE IN A CONFINED SPACE, PARTICULARLY A ROOM",https://lens.org/054-474-323-741-019,1997,"A toy aircraft for use in a confined space, particularly a room, including a model aircraft (1) with an electric motor (11) driving a propeller (19) and means for controlling the model aircraft in flight, a remote control device (2) comprising an electrical power supply (21) and electrical control means for controlling the flight of the model aircraft, and a flexible cable (3) electrically connecting the remote control device (2) to the model aircraft (1) to supply power to the electric motor (11) from the electrical power supply and to connect said electrical control means to said steering means. The wing loading of the model aircraft (1) trailing the connecting cable (3) is </= 1.5 g/dm<2>, and the flexible cable is attached to the underside of the model aircraft adjacent to the centre of gravity thereof."
ARCHITECTURE FOR A MEDIA SYSTEM,https://lens.org/023-932-114-980-241,2020,A media system that includes one or more smart devices.
Architecture for a media system,https://lens.org/134-791-354-162-625,2021,A media system that includes one or more smart devices.
ARCHITECTURE FOR A MEDIA SYSTEM,https://lens.org/101-060-531-617-752,2017,A media system that includes one or more smart devices.
DRONE VEHICLE FOR PERFORMING MAINTENANCE ON A RAILROAD,https://lens.org/173-517-803-766-989,2019,"A drone vehicle (100) for performing maintenance on a railroad is provided, comprising: a vehicle body (122) that supports first and second workheads, the first workhead being coupled to the vehicle support body by a first longitudinal positioning device, and the second workhead being coupled to the vehicle support body by a second longitudinal positioning device; a propulsion device (124) coupled to the vehicle body (122) that propels the vehicle; and a control system (126) configured to obtain tie position data and operate the first and second workheads based on the tie position data."
AERIAL VEHICLE-GROUND VEHICLE COORDINATION,https://lens.org/195-217-648-064-496,2018,An aerial vehicle can proceed to a target location upon receiving a message based on a ground vehicle being at an aerial vehicle deploy location. A user can be identified from an image captured at the target location. The aerial vehicle can be navigated to lead the user to a rendezvous with the vehicle.
Aerial vehicle-ground vehicle coordination,https://lens.org/094-094-968-576-897,2022,An aerial vehicle can proceed to a target location upon receiving a message based on a ground vehicle being at an aerial vehicle deploy location. A user can be identified from an image captured at the target location. The aerial vehicle can be navigated to lead the user to a rendezvous with the vehicle.
AERIAL VEHICLE-GROUND VEHICLE COORDINATION,https://lens.org/044-277-056-637-253,2019,An aerial vehicle can proceed to a target location upon receiving a message based on a ground vehicle being at an aerial vehicle deploy location. A user can be identified from an image captured at the target location. The aerial vehicle can be navigated to lead the user to a rendezvous with the vehicle.
VOICE ACTIVATION METHOD FOR SERVICE PROVISIONING ON SMART ASSISTANT DEVICES,https://lens.org/118-434-871-770-658,2019,"A device and a method for authenticating a user. The method includes selecting the phrase key from a plurality of phrase keys. The method also includes receiving, from a target service a file that includes parsed data based on speech recognition processing of a phrase spoken by a user. Additionally, the method includes sending a notification the target service, upon a determination that the parsed data matches a phrase key. The method further includes receiving a set of user credentials from the target service and sending the set of user credentials to the virtual assistant device."
Voice activation method for service provisioning on smart assistant devices,https://lens.org/131-581-767-186-479,2022,"A device and a method for authenticating a user. The method includes selecting the phrase key from a plurality of phrase keys. The method also includes receiving, from a target service a file that includes parsed data based on speech recognition processing of a phrase spoken by a user. Additionally, the method includes sending a notification the target service, upon a determination that the parsed data matches a phrase key. The method further includes receiving a set of user credentials from the target service and sending the set of user credentials to the virtual assistant device."
Robot,https://lens.org/183-075-296-971-685,2022,"A method of operating a robot 103 comprises generating a representation of an environment 109 of the robot 103 by operating one or more sensors of the robot to sense a set of parameters representative of the environment and creating or receiving from an electronic user device 105 a list of objects 107 in the environment 109 and associated identifiers for each object 107 in the list and then receiving control data from the electronic user device 105 which control data comprises an identifier for an object 107 in the generated list that a user of the electronic user device 105 wishes to locate within the environment 109. In response to receipt of the control data, the robot 103 and the one or more sensors are operated to search the environment 109 to determine a location of the identified object 107. An indication of the determined location may be transmitted to the electronic user device 105. The list of objects may include the last known location for at least one object 107."
Robot,https://lens.org/183-075-296-971-685,2022,"A method of operating a robot 103 comprises generating a representation of an environment 109 of the robot 103 by operating one or more sensors of the robot to sense a set of parameters representative of the environment and creating or receiving from an electronic user device 105 a list of objects 107 in the environment 109 and associated identifiers for each object 107 in the list and then receiving control data from the electronic user device 105 which control data comprises an identifier for an object 107 in the generated list that a user of the electronic user device 105 wishes to locate within the environment 109. In response to receipt of the control data, the robot 103 and the one or more sensors are operated to search the environment 109 to determine a location of the identified object 107. An indication of the determined location may be transmitted to the electronic user device 105. The list of objects may include the last known location for at least one object 107."
Robot,https://lens.org/103-654-650-238-510,2021,"A method of operating a robot 103 comprises generating a representation of an environment 109 of the robot 103 by operating one or more sensors of the robot to sense a set of parameters representative of the environment and creating or receiving from an electronic user device 105 a list of objects 107 in the environment 109 and associated identifiers for each object 107 in the list and then receiving control data from the electronic user device 105 which control data comprises an identifier for an object 107 in the generated list that a user of the electronic user device 105 wishes to locate within the environment 109. In response to receipt of the control data, the robot 103 and the one or more sensors are operated to search the environment 109 to determine a location of the identified object 107. An indication of the determined location may be transmitted to the electronic user device 105. The list of objects may include the last known location for at least one object 107."
"CONTROLLER, CONTROL METHOD, AND NON-TRANSITORY COMPUTER READABLE MEDIA",https://lens.org/011-733-415-145-568,2023,"A controller for a vehicle capable of autonomous driving. The controller executes detecting an emergency vehicle traveling around the vehicle based on surrounding environment information, and determining how to deal with the emergency vehicle in response to a detection of the emergency vehicle. In the determining how to deal with the emergency vehicle, the controller executes, at least, determining to cause the vehicle to take an avoidance action for the emergency vehicle, and determining to cause the vehicle to take a preliminary action for the avoidance action."
"CONTROLLER, CONTROL METHOD, AND NON-TRANSITORY COMPUTER READABLE MEDIA",https://lens.org/011-733-415-145-568,2023,"A controller for a vehicle capable of autonomous driving. The controller executes detecting an emergency vehicle traveling around the vehicle based on surrounding environment information, and determining how to deal with the emergency vehicle in response to a detection of the emergency vehicle. In the determining how to deal with the emergency vehicle, the controller executes, at least, determining to cause the vehicle to take an avoidance action for the emergency vehicle, and determining to cause the vehicle to take a preliminary action for the avoidance action."
Autonomous Anonymity,https://lens.org/122-056-173-107-436,2016,"An autonomous anonymity system includes a universal access transceiver. The universal access transceiver is designed and arranged to selectively provide a notification when autonomous aircraft operation is authorized,"
ROBOT AND METHOD FOR CONTROLLING THE SAME,https://lens.org/139-512-092-443-810,2021,"A robot and a method for controlling the robot are provided. The robot includes: at least one motor provided in the robot; a camera configured to capture an image of a door; and a processor configured to determine, on the basis of at least one of depth information and a feature point identified from the image, a target position not overlapping with a moving area of the door, and control the at least one motor such that predetermined operations are performed with respect to the target position. The feature point includes at least one of a handle and a hinge of the door."
Remote control illuminating device for mounting alongside a driveway and allowing the driver to be remotely and wirelessly illumiated during a darkened environment,https://lens.org/183-068-646-739-830,2020,"A remote controlled illuminating device of the embodiments of the present invention mounts alongside a driveway, on a post, a mailbox, or the like, and allows the driveway to be remotely and wirelessly illuminated during a darkened environment. The remote controlled illuminating device includes a transmitter, a receiver, a controller, a power source, and a light source. The transmitter selectively transmits a wireless signal. The receiver is in electrical communication with the light source and the controller, and receives the wireless signal. The controller is in electrical communication with the receiver and the power source. The light source is in electrical communication with the receiver and mounts alongside the driveway to illuminate when the transmitter is activated thereby allowing the driveway to be remotely and wirelessly illuminated during the darkened environment."
Intelligent tow bar,https://lens.org/019-402-891-176-511,2007,"A tow bar for connecting and controlling two autonomous vehicles with respect to one another. The tow bar including a plurality of sections with at least one sensor, mounted or coupled onto each, for measuring and determining the orientation of one autonomous vehicle in relation to the other autonomous vehicle. A signal may be transmitted to either or to both of the autonomous vehicles to control propulsion and/or steering and/or braking of the vehicles when an adjustment is required to maintain stability of the tandem vehicles."
VOICE RECOGNITION APPARATUS AND VOICE RECOGNITION METHOD,https://lens.org/082-979-487-697-56X,2023,"A voice recognition device receives requests to control devices installed in a moving body based on instructions voiced by a user, and comprises a speech acquisition unit that acquires speech, a speech data conversion unit that converts the acquired speech into speech data, a control target device identification unit that analyzes the speech data to identify the control target device, a detection mode setting unit that sets a detection mode for identifying the control request corresponding to the speech data in accordance with the control target device, and a control request identification unit that analyzes the speech data to identify the control request with respect to the control target device, based on the set detection mode."
VOICE RECOGNITION APPARATUS AND VOICE RECOGNITION METHOD,https://lens.org/082-979-487-697-56X,2023,"A voice recognition device receives requests to control devices installed in a moving body based on instructions voiced by a user, and comprises a speech acquisition unit that acquires speech, a speech data conversion unit that converts the acquired speech into speech data, a control target device identification unit that analyzes the speech data to identify the control target device, a detection mode setting unit that sets a detection mode for identifying the control request corresponding to the speech data in accordance with the control target device, and a control request identification unit that analyzes the speech data to identify the control request with respect to the control target device, based on the set detection mode."
UNMANNED AERIAL VEHICLE,https://lens.org/164-286-327-609-840,2023,"An unmanned aerial vehicle (""UAV"") (1) for non-destructive testing (""NDT"") comprises: an outer protective cage (2), a propulsion system (3) mounted inside the outer protective cage (2) and fixed thereto, an arm (4) comprising a first end (5) attached to the outer protective cage (2), and an NDT sensor (6) mounted at a second end (7) of the arm (4), wherein the arm (4) extends outward from the outer protective cage (2), the arm (4) having a length (L) between 1 and 50 percent of an overall linear dimension (D) of the outer protective cage (2)."
UNMANNED AERIAL VEHICLE,https://lens.org/164-286-327-609-840,2023,"An unmanned aerial vehicle (""UAV"") (1) for non-destructive testing (""NDT"") comprises: an outer protective cage (2), a propulsion system (3) mounted inside the outer protective cage (2) and fixed thereto, an arm (4) comprising a first end (5) attached to the outer protective cage (2), and an NDT sensor (6) mounted at a second end (7) of the arm (4), wherein the arm (4) extends outward from the outer protective cage (2), the arm (4) having a length (L) between 1 and 50 percent of an overall linear dimension (D) of the outer protective cage (2)."
CORDLESS TELEPHONE APPARATUS AND CORDLESS TELEPHONE SYSTEM,https://lens.org/150-371-237-155-337,2016,"A cordless base unit includes a controller that performs control in a case where an incoming call arrives from the landline telephone network, in such a manner that the cordless handset and the mobile information terminal perform sound ringing for the incoming call, that automatic answering starts after a predetermined time has elapsed and the sound ringing for the incoming call is stopped except for the mobile information terminal that is set to be used outside of the house, and that while the automatic answering is performed, the mobile information terminal that is set to be used outside of the house continues to perform the sound ringing for the incoming call."
Cordless telephone apparatus and cordless telephone system,https://lens.org/075-483-959-789-823,2018,"A cordless base unit includes a controller that performs control in a case where an incoming call arrives from the landline telephone network, in such a manner that the cordless handset and the mobile information terminal perform sound ringing for the incoming call, that automatic answering starts after a predetermined time has elapsed and the sound ringing for the incoming call is stopped except for the mobile information terminal that is set to be used outside of the house, and that while the automatic answering is performed, the mobile information terminal that is set to be used outside of the house continues to perform the sound ringing for the incoming call."
SYSTEM AND METHOD FOR AUDIO AUGMENTED REALITY,https://lens.org/062-607-438-707-570,2015,"A system, controller, and computer readable medium for providing an audio augmented reality to a user. The system can detect an object, event, or the like in the environment of a user and play a digitized sound and/or a synthesized sound in response to the detected object, event, or the like. The user can specify preferences for sounds played in response to the detected object or event."
System and method for audio augmented reality,https://lens.org/040-080-078-410-258,2017,"A system, controller, and computer readable medium for providing an audio augmented reality to a user. The system can detect an object, event, or the like in the environment of a user and play a digitized sound and/or a synthesized sound in response to the detected object, event, or the like. The user can specify preferences for sounds played in response to the detected object or event."
AUTONOMOUS EMERGENCY DESCENDING AND LANDING OF AIRCRAFTS,https://lens.org/036-599-754-060-537,2015,"The presently disclosed subject matter includes, inter alia, a system, a method and a computer program product of autonomous descent of an aircraft (e.g. UAV), with a non-operating engine, from a current position to a desired position in the sky. The disclosed subject matter can be used for example for enabling a UAV with a non-operating engine to glide from a point of engine failure detection through an exit point of a descending spiral to a landing window. Once the landing window has been reached, the aircraft can execute an autonomous landing procedure and land at a selected landing site notwithstanding engine failure, and also a possible uplink communication failure."
Systems and methods for restricting drone airspace access,https://lens.org/117-222-818-318-258,2017,"Methods, systems, and devices are disclosed for providing conditional access for a drone for accessing a restricted area. Conditional access information associated with conditional access restrictions for the restricted area may be received by the drone. The drone may compare the received conditional access information to one or more access parameters for the drone. The drone may access the restricted area based on the comparison of the received conditional access information and the access parameter. A drone may take corrective action when the received conditional access information does not permit access to the restricted area based on the access parameter for the drone."
SYSTEMS AND METHODS FOR RESTRICTING DRONE AIRSPACE ACCESS,https://lens.org/042-994-958-179-123,2016,"Methods, systems, and devices are disclosed for providing conditional access for a drone for accessing a restricted area. Conditional access information associated with conditional access restrictions for the restricted area may be received by the drone. The drone may compare the received conditional access information to one or more access parameters for the drone. The drone may access the restricted area based on the comparison of the received conditional access information and the access parameter. A drone may take corrective action when the received conditional access information does not permit access to the restricted area based on the access parameter for the drone."
Systems and Methods for Restricting Drone Airspace Access,https://lens.org/152-723-998-221-967,2017,"Methods, systems, and devices are disclosed for providing conditional access for a drone for accessing a restricted area. Conditional access information associated with conditional access restrictions for the restricted area may be received by the drone. The drone may compare the received conditional access information to one or more access parameters for the drone. The drone may access the restricted area based on the comparison of the received conditional access information and the access parameter. A drone may take corrective action when the received conditional access information does not permit access to the restricted area based on the access parameter for the drone."
Systems and Methods for Restricting Drone Airspace Access,https://lens.org/014-913-187-234-944,2016,"Methods, systems, and devices are disclosed for providing conditional access for a drone for accessing a restricted area. Conditional access information associated with conditional access restrictions for the restricted area may be received by the drone. The drone may compare the received conditional access information to one or more access parameters for the drone. The drone may access the restricted area based on the comparison of the received conditional access information and the access parameter. A drone may take corrective action when the received conditional access information does not permit access to the restricted area based on the access parameter for the drone."
Systems and methods for restricting drone airspace access,https://lens.org/054-820-888-022-66X,2019,"Methods, systems, and devices are disclosed for providing conditional access for a drone for accessing a restricted area. Conditional access information associated with conditional access restrictions for the restricted area may be received by the drone. The drone may compare the received conditional access information to one or more access parameters for the drone. The drone may access the restricted area based on the comparison of the received conditional access information and the access parameter. A drone may take corrective action when the received conditional access information does not permit access to the restricted area based on the access parameter for the drone."
Still video camera system with remote controller,https://lens.org/168-678-211-077-756,2001,"A still video camera system including a still video camera and a remote controller for remotely operating the still video camera by transmitting a control signal to the still video camera. The remote controller is detachably coupled to the still video camera, and when the remote controller is coupled to the still video camera, a signal transmission device of the remote controller is utilized for transmitting the image data to an external device."
System and Method to Remotely Operate a Door,https://lens.org/139-569-166-650-984,2020,"A system and method to remotely operate a door, the method including: transmitting a door's proximity to a mobile device; receiving, by the mobile device, identifying information from a remote intermediary processing server; receiving, from a user, a command to operate the door; and transmitting the command to operate the door."
System and Method to Remotely Operate a Door,https://lens.org/139-569-166-650-984,2020,"A system and method to remotely operate a door, the method including: transmitting a door's proximity to a mobile device; receiving, by the mobile device, identifying information from a remote intermediary processing server; receiving, from a user, a command to operate the door; and transmitting the command to operate the door."
ELECTRONIC CONTROL DEVICE,https://lens.org/189-601-470-187-841,2016,"An electronic remote control device, including a body; a touchpad formed by capacitive sensors; a processor and software; and position sensors; wherein the processor and software are arranged to read out inputs from the position sensors and dynamically allocate functions to the capacitive sensors in the touchpad depending on the position of the touchpad in relation to the horizon."
Electronic Control Device,https://lens.org/050-863-064-555-388,2018,"An electronic remote control device, including a body; a touchpad formed by capacitive sensors; a processor and software; and position sensors; wherein the processor and software are arranged to read out inputs from the position sensors and dynamically allocate functions to the capacitive sensors in the touchpad depending on the position of the touchpad in relation to the horizon."
Electronic control device,https://lens.org/069-720-092-248-23X,2019,"An electronic remote control device, including a body; a touchpad formed by capacitive sensors; a processor and software; and position sensors; wherein the processor and software are arranged to read out inputs from the position sensors and dynamically allocate functions to the capacitive sensors in the touchpad depending on the position of the touchpad in relation to the horizon."
Alternative inexpensive cloud-based mass market alarm system with alarm monitoring and reporting,https://lens.org/185-821-145-695-972,2018,"A security system including a wireless alarm sensor that detects a threat within a secured geographic area, a cloud application that monitors the alarm sensor and reports threats detected by the alarm sensor within the secured area to a human user of the secured area and a wireless publically accessible communication system defined by a plurality of relatively low power communication devices and a local base station, the alarm sensor detects a nearby one of the plurality of low power communication devices and wirelessly connects to the cloud application through the nearby one low power communication device and local base station."
CONSTRUCTION SITE PLANNING FOR AUTONOMOUS CONSTRUCTION VEHICLES,https://lens.org/173-436-875-694-414,2020,"A system for controlling an autonomous construction vehicle may include a controller configured to identify a boundary of a construction site, identify a slope within the boundary of the construction site, determine if the slope exceeds a predetermined threshold value, and create a path plan for an autonomous construction vehicle based on whether the first slope exceeds the threshold value to align the movement of the autonomous construction vehicle with the slope."
Remote control of projection and camera system,https://lens.org/165-968-559-438-221,2016,"A device includes a projection and camera system to create an augmented reality environment in which images are projected onto a scene and user movement within the scene is captured. The projection and camera system have a camera to image scattered IR light from the scene and compute time of flight values used in depth mapping of objects in the room. The system also has a projector to project the images onto the scene. The system controls the camera and projector mounted in a moveable head of a lamp with a motor mounted elsewhere in the lamp. In one implementation, the motor is mounted in the base of a table lamp."
Remote control of projection and camera system,https://lens.org/190-519-206-660-372,2015,"A device includes a projection and camera system to create an augmented reality environment in which images are projected onto a scene and user movement within the scene is captured. The projection and camera system have a camera to image scattered IR light from the scene and compute time of flight values used in depth mapping of objects in the room. The system also has a projector to project the images onto the scene. The system controls the camera and projector mounted in a moveable head of a lamp with a motor mounted elsewhere in the lamp. In one implementation, the motor is mounted in the base of a table lamp."
ELECTRONIC APPARATUS AND OPERATING METHOD THEREOF,https://lens.org/067-232-830-944-013,2017,"An operating method of an external imaging device is provided which includes establishing a wireless connection with an electronic device comprising a display using a wireless communication device, receiving a parameter from the electronic device through the wireless connection, the parameter determined based on at least part of at least one photo and information, controlling a navigation device to autonomously fly to a set position based on the parameter, capturing an image using the camera, and sending the image to the electronic device through the wireless connection."
Home automation system,https://lens.org/071-514-159-908-613,2002,"Home automation system (31) comprising an array of functional devices (37), a plurality of input devices (38) associated with the array of functional devices and a control unit (49), interconnected via radio link and constituting a home automation system (32). The system (31) is employed in combination with an autonomous safety/security system (33) having input sensors (41), local and/or remote signalling devices (42) and a control unit (43) between the sensors and the signalling devices. The system also comprises connecting means between the control unit (43) of the safety/security system and the control unit (49) of the automation system (32) for activation of the safety/security system by the automation system and/or for activation of the automation system by the safety/security system. <IMAGE>"
INTERACTIVE MOBILE COMMUNICATION DEVICE,https://lens.org/157-978-729-569-232,2012,A system and method is described for allowing a mobile communication device using location data to control electronic devices located within a predefined area of coverage.
AN UNMANNED AERIAL VEHICLE AND A CHARGING PLATFORM FOR AN UNMANNED AERIAL VEHICLE,https://lens.org/071-388-866-418-352,2020,"An unmanned aerial vehicle (UAV) comprising: an electrical propulsion system; a battery for powering the electrical propulsion system; charging circuitry for charging the battery; a housing comprising a first plurality of arms extending outwardly from the housing for supporting the UAV on a charging platform that is smaller than the UAV, wherein the charging circuitry is configured to be charged using at least some of a plurality of contact charging pads, and wherein at least some of the plurality of contact charging pads are positioned on at least some of the first plurality of arms and extend over at least an underside portion of those arms."
AN UNMANNED AERIAL VEHICLE AND A CHARGING PLATFORM FOR AN UNMANNED AERIAL VEHICLE,https://lens.org/071-388-866-418-352,2020,"An unmanned aerial vehicle (UAV) comprising: an electrical propulsion system; a battery for powering the electrical propulsion system; charging circuitry for charging the battery; a housing comprising a first plurality of arms extending outwardly from the housing for supporting the UAV on a charging platform that is smaller than the UAV, wherein the charging circuitry is configured to be charged using at least some of a plurality of contact charging pads, and wherein at least some of the plurality of contact charging pads are positioned on at least some of the first plurality of arms and extend over at least an underside portion of those arms."
LOADING OF EPHEMERIS DATA INTO A DRONE,https://lens.org/012-156-692-837-107,2017,"The invention relates to a method, implemented in a drone piloting device (16), of loading satellite ephemeris data, the drone (10) comprising a geolocation module, the method comprising a step of establishing a communication between the piloting device (16) and the drone (10) according to a given communication mode. The method further comprises the following steps implemented in the piloting device: loading ephemeris data (E26) from a remote server (32) connected to a communication network (30), and sending the loaded ephemeris data (E25) to said drone. The invention has also for object a method of loading satellite ephemeris data, implemented in a drone, for updating ephemeris data of a geolocation module."
AUTOMATIC TAKE-OFF AND LANDING CONTROL DEVICE,https://lens.org/102-780-010-695-271,2016,"An automatic take-off and landing control device for an aircraft is provided. The control device comprises at least two of at least one local tracking device adapted for receiving at least one local signal from at least one local ground station and for determining a position of the aircraft based on the local signals, at least one GNSS tracking device adapted for receiving a GNSS signal and for determining a position of the aircraft based on the GNSS signal; and at least one camera device adapted for observing an environment of the aircraft and for determining a position of the aircraft based on the camera signal."
Automatic take-off and landing control device,https://lens.org/122-558-228-918-173,2017,"An automatic take-off and landing control device for an aircraft is provided. The control device comprises at least two of at least one local tracking device adapted for receiving at least one local signal from at least one local ground station and for determining a position of the aircraft based on the local signals, at least one GNSS tracking device adapted for receiving a GNSS signal and for determining a position of the aircraft based on the GNSS signal; and at least one camera device adapted for observing an environment of the aircraft and for determining a position of the aircraft based on the camera signal."
CONTROL SIGNAL BASED ON A COMMAND TAPPED BY A USER,https://lens.org/133-541-207-267-314,2014,"A system includes at least three accelerometers disposed in different locations of an area with a surface to capture respective vibration data corresponding to a command tapped onto the surface by a user and a processing system to receive the vibration data from each accelerometer, identify the command and a location of the user from the vibration data, and generate a control signal based on the command and the location."
USER INTERFACE WITH POSITION AWARENESS,https://lens.org/125-747-171-767-213,2016,A remote control device for controlling lighting systems includes a sensor configured to determine a location of the remote control device in relation to the lighting systems. A controller is configured to determine a nearest light source of the lighting systems relative to the location of the remote control device and to control this nearest light source. The controller is configured to change a configuration of the remote control device in response to changing its location. A transceiver transmit a signal to multiple light sources which measure the strength and/or time of flight of this signal for use in determining the location of the remote control device. The light sources provide the remote control device with identifying information unique to each one of them including their locations.
User interface with position awareness,https://lens.org/003-280-232-673-30X,2019,A remote control device for controlling lighting systems includes a sensor configured to determine a location of the remote control device in relation to the lighting systems. A controller is configured to determine a nearest light source of the lighting systems relative to the location of the remote control device and to control this nearest light source. The controller is configured to change a configuration of the remote control device in response to changing its location. A transceiver transmit a signal to multiple light sources which measure the strength and/or time of flight of this signal for use in determining the location of the remote control device. The light sources provide the remote control device with identifying information unique to each one of them including their locations.
AUTONOMOUS INTELLIGENCE SURVEILLANCE RECONNAISSANCE AND PAYLOAD DELIVERY SYSTEM WITH SAFE RETURN,https://lens.org/013-087-089-286-873,2018,"An intelligence, surveillance, and reconnaissance system and associated operating method is disclosed including a ground station and one or more autonomous aerial vehicles. Each automomous vehicle is adapted to a) self-monitor a plurality of environment data; b) calculate, based at least in part upon the environment data, a soft wall radius from which it can return to the command and control interface station; c) receive a destination position to which it is commanded to fly; d) determine if the destination position is beyond the soft wall radius; and e) communicate an alert to the command and control interface station if the destination position is beyond the soft wall radius."
METHOD AND SYSTEM FOR CONTROLLING UNMANNED AIR VEHICLE,https://lens.org/160-112-800-061-433,2018,"A method and a system for establishing a route of an unmanned aerial vehicle are provided. The method includes identifying an object from surface scanning data and shaping a space, which facilitates autonomous flight, as a layer, collecting surface image data for a flight path from the shaped layer, and analyzing a change in image resolution according to a distance from the object through the collected surface image data and extracting an altitude value on a flight route."
METHOD AND SYSTEM FOR PROVIDING ROUTE OF UNMANNED AIR VEHICLE,https://lens.org/181-448-143-728-63X,2020,"A method and a system for establishing a route of an unmanned aerial vehicle are provided. The method includes identifying an object from surface scanning data and shaping a space, which facilitates autonomous flight, as a layer, collecting surface image data for a flight path from the shaped layer, and analyzing a change in image resolution according to a distance from the object through the collected surface image data and extracting an altitude value on a flight route."
Method and system for generating a map for a flight of an unmanned aerial vehicle,https://lens.org/111-904-444-356-355,2022,"A method and a system for establishing a route of an unmanned aerial vehicle are provided. The method includes identifying an object from surface scanning data and shaping a space, which facilitates autonomous flight, as a layer, collecting surface image data for a flight path from the shaped layer, and analyzing a change in image resolution according to a distance from the object through the collected surface image data and extracting an altitude value on a flight route."
METHOD AND SYSTEM FOR PROVIDING ROUTE OF UNMANNED AIR VEHICLE,https://lens.org/137-675-595-902-058,2017,"A method and a system for establishing a route of an unmanned aerial vehicle are provided. The method includes identifying an object from surface scanning data and shaping a space, which facilitates autonomous flight, as a layer, collecting surface image data for a flight path from the shaped layer, and analyzing a change in image resolution according to a distance from the object through the collected surface image data and extracting an altitude value on a flight route."
Method and system for providing route of unmanned air vehicle,https://lens.org/047-651-557-332-219,2018,"A method and a system for establishing a route of an unmanned aerial vehicle are provided. The method includes identifying an object from surface scanning data and shaping a space, which facilitates autonomous flight, as a layer, collecting surface image data for a flight path from the shaped layer, and analyzing a change in image resolution according to a distance from the object through the collected surface image data and extracting an altitude value on a flight route."
Method and system for generating a map for a flight of an unmanned aerial vehicle,https://lens.org/111-904-444-356-355,2022,"A method and a system for establishing a route of an unmanned aerial vehicle are provided. The method includes identifying an object from surface scanning data and shaping a space, which facilitates autonomous flight, as a layer, collecting surface image data for a flight path from the shaped layer, and analyzing a change in image resolution according to a distance from the object through the collected surface image data and extracting an altitude value on a flight route."
METHOD AND SYSTEM FOR PROVIDING ROUTE OF UNMANNED AIR VEHICLE,https://lens.org/131-251-551-532-844,2019,"A method and a system for establishing a route of an unmanned aerial vehicle are provided. The method includes identifying an object from surface scanning data and shaping a space, which facilitates autonomous flight, as a layer, collecting surface image data for a flight path from the shaped layer, and analyzing a change in image resolution according to a distance from the object through the collected surface image data and extracting an altitude value on a flight route."
Method and system for controlling unmanned air vehicle,https://lens.org/095-682-521-275-876,2020,"A method and a system for establishing a route of an unmanned aerial vehicle are provided. The method includes identifying an object from surface scanning data and shaping a space, which facilitates autonomous flight, as a layer, collecting surface image data for a flight path from the shaped layer, and analyzing a change in image resolution according to a distance from the object through the collected surface image data and extracting an altitude value on a flight route."
Apparatus and method for calling mobile robot,https://lens.org/055-970-898-742-150,2007,"An apparatus for calling a mobile robot (200) includes a generator (101,102) installed at a remote controller (100), and generating an RF signal and infrared signal for calling a mobile robot (200) when a call signal is inputted by a user; and a controller (202) installed at the mobile robot (200), calculating a direction of the remote controller (100) based on a position of an infrared ray receiver that receives the infrared signal when an RF signal is received, rotating the mobile robot (200) in the calculated direction, and then making the mobile robot (200) to go straight ahead. When a user calls the mobile robot (200) from a specific place, the mobile robot (200) can move by itself to the specific space, thereby enhancing users' convenience.
"
Methods and systems for home monitoring and control,https://lens.org/012-187-471-174-882,2019,"This application is directed to a method of home monitoring and control implemented by a doorbell installed at a door of a home, an application executable by a monitoring device, and a remote server. The doorbell has a button that, upon being touched, depressed or activated, wirelessly causes an audio speaker of an electronic device to sound an audible notification and/or a message to be sent to a monitoring device associated with an occupant of the home to indicate presence of a person at the door. The doorbell also has a camera that captures video data within a field of view. The remote server receives the video data from the doorbell and relays them to the monitoring device. The application receives and displays at least a portion of the video data captured by the camera."
System and method for managing and analyzing multimedia information,https://lens.org/108-519-679-900-82X,2021,"A UAV data processing and management system is provided including an encoder broadcaster and data manager which provides end users with a single interface for searching and sharing any video or imagery source, from any device with no client software required. Data inputs to the resource can include UAV video, photos, traffic cameras, fixed surveillance systems, iOS and Android device pictures, and other data (e.g., texts, emails) and inputs from all forms of social media, such as Twitter, Instagram, Facebook, etc. The cloud based manager is built with collaboration and sharing in mind while at the same time maintaining data privacy, security protection, chain-of-custody control and audit trail maintenance. Analytic tools are integrated accordingly as plug-ins or as a store of available app resources which are easily removed, added and customized based on user needs and system requirements and cost constraints."
SYSTEM AND METHOD FOR MANAGING AND ANALYZING MULTIMEDIA INFORMATION,https://lens.org/097-073-240-536-987,2021,"A UAV data processing and management system is provided including an encoder broadcaster and data manager which provides end users with a single interface for searching and sharing any video or imagery source, from any device with no client software required. Data inputs to the resource can include UAV video, photos, traffic cameras, fixed surveillance systems, iOS and Android device pictures, and other data (e.g., texts, emails) and inputs from all forms of social media, such as Twitter, Instagram, Facebook, etc. The cloud based manager is built with collaboration and sharing in mind while at the same time maintaining data privacy, security protection, chain-of-custody control and audit trail maintenance. Analytic tools are integrated accordingly as plug-ins or as a store of available app resources which are easily removed, added and customized based on user needs and system requirements and cost constraints."
SYSTEM AND METHOD FOR MANAGING AND ANALYZING MULTIMEDIA INFORMATION,https://lens.org/163-134-940-063-381,2015,"A UAV data processing and management system is provided including an encoder broadcaster and data manager which provides end users with a single interface for searching and sharing any video or imagery source, from any device with no client software required. Data inputs to the resource can include UAV video, photos, traffic cameras, fixed surveillance systems, iOS and Android device pictures, and other data (e.g., texts, emails) and inputs from all forms of social media, such as Twitter, Instagram, Facebook, etc. The cloud based manager is built with collaboration and sharing in mind while at the same time maintaining data privacy, security protection, chain-of-custody control and audit trail maintenance. Analytic tools are integrated accordingly as plug-ins or as a store of available app resources which are easily removed, added and customized based on user needs and system requirements and cost constraints."
SYSTEM AND METHOD TO FACILITATE REMOTE AND ACCURATE MANEUVERING OF UNMANNED AERIAL VEHICLE UNDER COMMUNICATION LATENCY,https://lens.org/047-507-937-802-781,2022,"The present invention relates to a system and method to facilitate remote and accurate maneuvering of unmanned aerial vehicle (UAV) under communication latency. The UAV provides a ground control station (GCS), with a video feed of an area of interest (AOI), after a time T from actual capturing of the video by the UAV, due to latency in video and communication between the UAV and the GCS. The GCS further receives control commands directly from a controller of the user, and transmit the video feed along with interactive marker(s), step by step marking of singular points using raycast vector, and/or virtual UAV being overlaid on top of the video feed to a display module or VR headset associated with the user, to facilitate the user to assess how much movement the user is exerting on the UAV through the controller, and also see how the actual UAV will perform or maneuver in the AOI after time T, thereby facilitating the user to continuously assess and rectify maneuvering or directing of the UAV in the AOI."
UNMANNED AERIAL VEHICLE-COMBINED AUTONOMOUS MOBILE ROBOT CHECKING SYSTEM,https://lens.org/194-241-872-281-173,2022,"An autonomous mobile robot checking system comprises a transmission line, an unmanned aerial vehicle and an autonomous mobile device. The unmanned aerial vehicle is used for sensing stacked goods to generate sensing information. The autonomous mobile device is used for receiving the sensing information through the transmission line, and supplying power to the unmanned aerial vehicle through the transmission line to enable the unmanned aerial vehicle to sense the stacked goods. The autonomous mobile device provides a checking result for the stacked goods based on the sensing information."
UNMANNED AERIAL VEHICLE-COMBINED AUTONOMOUS MOBILE ROBOT CHECKING SYSTEM,https://lens.org/194-241-872-281-173,2022,"An autonomous mobile robot checking system comprises a transmission line, an unmanned aerial vehicle and an autonomous mobile device. The unmanned aerial vehicle is used for sensing stacked goods to generate sensing information. The autonomous mobile device is used for receiving the sensing information through the transmission line, and supplying power to the unmanned aerial vehicle through the transmission line to enable the unmanned aerial vehicle to sense the stacked goods. The autonomous mobile device provides a checking result for the stacked goods based on the sensing information."
UNMANNED AERIAL VEHICLE-COMBINED AUTONOMOUS MOBILE ROBOT CHECKING SYSTEM,https://lens.org/009-779-279-448-696,2022,"An autonomous mobile robot checking system comprises a transmission line, an unmanned aerial vehicle and an autonomous mobile device. The unmanned aerial vehicle is used for sensing stacked goods to generate sensing information. The autonomous mobile device is used for receiving the sensing information through the transmission line, and supplying power to the unmanned aerial vehicle through the transmission line to enable the unmanned aerial vehicle to sense the stacked goods. The autonomous mobile device provides a checking result for the stacked goods based on the sensing information."
DIGITAL VOICE ASSISTANT OPERATION SYSTEM,https://lens.org/077-912-276-633-913,2019,"A digital voice assistant operation system includes an access point, an electronic device, an audio device and a digital voice assistant module. The access point is in communication with a voice recognition module through network connection. The electronic device is in communication with the access point through network connection. After the user provides a voice command to the audio device, the voice command is transmitted to the voice recognition module through the audio device, the digital voice assistant module and the access point. After the voice recognition module recognizes the voice command, an operating signal corresponding to the voice command is outputted from the voice recognition module to the electronic device. Consequently, the electronic device performs an operation according to the operating signal."
SNOW PLOW MODE FOR AUTONOMOUS DRIVING,https://lens.org/050-020-889-421-127,2018,"According to one embodiment, a fully-autonomous vehicle, when properly equipped, can be used to clear snow, hail, leaves, and/or other debris from a driveway, roadway, parking lot, etc. For example, a vehicle capable of fully autonomous operation can operate in a snow plow mode. In such operations, the vehicle can identify, or be informed of, weather conditions such as snow that would impede travel on paved surfaces such as driveways and roads. When such conditions exist and if the vehicle is properly equipped with a plow or other snow removal equipment, the vehicle and operate in an autonomous manner to clear the user's driveway and/or one or more other driveways, roadways, parking lots, or other paved surfaces depending upon prior permission from the vehicle's owner and based on a variety of factors."
Snow plow mode for autonomous driving,https://lens.org/194-374-368-035-108,2018,"According to one embodiment, a fully-autonomous vehicle, when properly equipped, can be used to clear snow, hail, leaves, and/or other debris from a driveway, roadway, parking lot, etc. For example, a vehicle capable of fully autonomous operation can operate in a snow plow mode. In such operations, the vehicle can identify, or be informed of, weather conditions such as snow that would impede travel on paved surfaces such as driveways and roads. When such conditions exist and if the vehicle is properly equipped with a plow or other snow removal equipment, the vehicle and operate in an autonomous manner to clear the user's driveway and/or one or more other driveways, roadways, parking lots, or other paved surfaces depending upon prior permission from the vehicle's owner and based on a variety of factors."
VOICE-ENABLED EXTERNAL SMART PROCESSING SYSTEM WITH DISPLAY,https://lens.org/053-568-863-769-259,2021,"A voice-enabled external smart battery processing system is provided. At least one sensor includes a microphone and is configured to identify an input audio signal from a user. A low-power processor is configured to process the input audio signal and initiate a voice assistant session for a host device. A battery is configured to provide power to the processor and the host device, while a display provides visual output based on the input audio signal."
UNMANNED AERIAL VEHICLE PROTECTIVE FRAME CONFIGURATION,https://lens.org/121-174-325-383-714,2023,"An unmanned aerial vehicle, comprising a monolithic uni-body frame including a hub (1120) positioned near a center of the UAV; a plurality of motor arms (1108), each motor arm having a first end and a second end, each first end coupled to the hub; and a perimeter protective barrier (1114) completely surrounding the hub and the plurality of motor arms. The frame and perimeter protective barrier are formed as a monolithic uni-body to increase the structural integrity of the UAV."
DRONE GLASS BREAKER,https://lens.org/110-749-363-035-337,2022,An unmanned aerial vehicle (UAV) includes a UAV frame; and a propulsion system coupled to the UAV frame and configured to cause the vehicle to be airborne. The UAV also includes a control system configured to control the flight of the vehicle and a glass breaker coupled to the UAV frame.
DRONE GLASS BREAKER,https://lens.org/110-749-363-035-337,2022,An unmanned aerial vehicle (UAV) includes a UAV frame; and a propulsion system coupled to the UAV frame and configured to cause the vehicle to be airborne. The UAV also includes a control system configured to control the flight of the vehicle and a glass breaker coupled to the UAV frame.
Airborne Manipulator System,https://lens.org/078-801-344-768-110,2009,"A manipulator arm system on a ducted air-fan UAV is disclosed herein. The target site may be accurately located by the UAV, and the manipulator system may accurately locate the payload at the target site. The manipulator arm may select tools from a toolbox located on-board the UAV to assist in payload placement or the execution of remote operations. The system may handle the delivery of mission payloads, environmental sampling, and sensor placement and repair."
VISUALIZATION AND MODIFICATION OF OPERATIONAL BOUNDING ZONES USING AUGMENTED REALITY,https://lens.org/149-287-166-353-872,2019,"An augmented reality (AR) system for visualizing and modifying robot operational zones. The system includes an AR device such as a headset in communication with a robot controller. The AR device includes software for the AR display and modification of the operational zones. The AR device is registered with the robot coordinate frame via detection of a visual marker. The AR device displays operational zones overlaid on real world images of the robot and existing fixtures, where the display is updated as the user moves around the robot work cell. Control points on the virtual operational zones are displayed and allow the user to reshape the operational zones. The robot can be operated during the AR session, running the robot's programmed motion and evaluating the operational zones. Zone violations are highlighted in the AR display. When zone definition is complete, the finalized operational zones are uploaded to the robot controller."
VISUALIZATION AND MODIFICATION OF OPERATIONAL BOUNDING ZONES USING AUGMENTED REALITY,https://lens.org/184-497-189-783-167,2020,"An augmented reality (AR) system for visualizing and modifying robot operational zones. The system includes an AR device such as a headset in communication with a robot controller. The AR device includes software for the AR display and modification of the operational zones. The AR device is registered with the robot coordinate frame via detection of a visual marker. The AR device displays operational zones overlaid on real world images of the robot and existing fixtures, where the display is updated as the user moves around the robot work cell. Control points on the virtual operational zones are displayed and allow the user to reshape the operational zones. The robot can be operated during the AR session, running the robot's programmed motion and evaluating the operational zones. Zone violations are highlighted in the AR display. When zone definition is complete, the finalized operational zones are uploaded to the robot controller."
Two-sided toy vehicle,https://lens.org/104-179-933-998-970,2015,"A slim, two-sided remote controlled toy vehicle with high speed, high maneuverability and high shock and crash resistance. A remote control scheme based on digital signals embedded in infrared beams allows improved control and high-speed terrestrial and aerial stunt capabilities. The toy intelligently implements infrared communication, on board micro-control units, flip sensors, sounds, lights and other pre-programmed actions. Various stunt accessories are also provided, to increase the play value of the toy."
Two-sided toy vehicle,https://lens.org/038-898-446-920-526,2013,"A slim, two-sided remote controlled toy vehicle with high speed, high maneuverability and high shock and crash resistance. A remote control scheme based on digital signals embedded in infrared beams allows improved control and high-speed terrestrial and aerial stunt capabilities. The toy intelligently implements infrared communication, on board micro-control units, flip sensors, sounds, lights and other pre-programmed actions. Various stunt accessories are also provided, to increase the play value of the toy."
TWO-SIDED TOY VEHICLE,https://lens.org/030-815-665-840-350,2012,"A slim, two-sided remote controlled toy vehicle with high speed, high maneuverability and high shock and crash resistance. A remote control scheme based on digital signals embedded in infrared beams allows improved control and high-speed terrestrial and aerial stunt capabilities. The toy intelligently implements infrared communication, on board micro-control units, flip sensors, sounds, lights and other pre-programmed actions. Various stunt accessories are also provided, to increase the play value of the toy."
TWO-SIDED TOY VEHICLE,https://lens.org/104-256-782-492-089,2013,"A slim, two-sided remote controlled toy vehicle with high speed, high maneuverability and high shock and crash resistance. A remote control scheme based on digital signals embedded in infrared beams allows improved control and high-speed terrestrial and aerial stunt capabilities. The toy intelligently implements infrared communication, on board micro-control units, flip sensors, sounds, lights and other pre-programmed actions. Various stunt accessories are also provided, to increase the play value of the toy."
Two-sided toy vehicle,https://lens.org/071-527-077-032-497,2014,"A slim, two-sided remote controlled toy vehicle with high speed, high maneuverability and high shock and crash resistance. A remote control scheme based on digital signals embedded in infrared beams allows improved control and high-speed terrestrial and aerial stunt capabilities. The toy intelligently implements infrared communication, on board micro-control units, flip sensors, sounds, lights and other pre-programmed actions. Various stunt accessories are also provided, to increase the play value of the toy."
Two-sided toy vehicle,https://lens.org/137-930-029-446-196,2014,"A slim, two-sided remote controlled toy vehicle with high speed, high maneuverability and high shock and crash resistance. A remote control scheme based on digital signals embedded in infrared beams allows improved control and high-speed terrestrial and aerial stunt capabilities. The toy intelligently implements infrared communication, on board micro-control units, flip sensors, sounds, lights and other pre-programmed actions. Various stunt accessories are also provided, to increase the play value of the toy."
Local Positioning System for an Unmanned Aerial Vehicle,https://lens.org/094-902-511-184-458,2019,"The present invention relates to an unmanned aerial vehicle (UAV) for inspecting infrastructure. The UAV includes a drone, and a navigation system including one or more sensors for sensing the infrastructure. The navigation system navigates the drone relative to the sensed infrastructure. The UAV further includes an inspection system transported by the navigated drone and for inspecting the infrastructure. Advantageously, the UAV can maneuver to and inspect hard-to-reach locations of the infrastructure."
"Operating device, operating method, operating system, and operating program",https://lens.org/175-872-006-636-902,2020,"A technique for more reliably capturing a lost unmanned aerial vehicle in tracking the unmanned aerial vehicle by a surveying device is provided. A UAV search controlling part configured to be used in a search for an unmanned aerial vehicle that flies along a predetermined flight path includes an estimating part and a search controlling part. The estimating part estimates, on the basis of location data of a surveying device that surveys a location of the unmanned aerial vehicle by using laser light and on the basis of the predetermined flight path, a direction of the unmanned aerial vehicle as seen from the surveying device at a specific time. The search controlling part controls to allow the surveying device to search for the unmanned aerial vehicle, on the basis of the estimated direction."
"OPERATING DEVICE, OPERATING METHOD, OPERATING SYSTEM, AND OPERATING PROGRAM",https://lens.org/098-282-063-021-92X,2018,"A technique for more reliably capturing a lost unmanned aerial vehicle in tracking the unmanned aerial vehicle by a surveying device is provided. A UAV search controlling part configured to be used in a search for an unmanned aerial vehicle that flies along a predetermined flight path includes an estimating part and a search controlling part. The estimating part estimates, on the basis of location data of a surveying device that surveys a location of the unmanned aerial vehicle by using laser light and on the basis of the predetermined flight path, a direction of the unmanned aerial vehicle as seen from the surveying device at a specific time. The search controlling part controls to allow the surveying device to search for the unmanned aerial vehicle, on the basis of the estimated direction."
DRONE BOX,https://lens.org/122-585-698-487-850,2021,The application provides a storage unit for an Unmanned Aerial Vehicle (UAV) and a method of operating a storage unit for a UAV. The storage unit can comprise a container for enclosing the UAV; a moveable UAV landing platform; and a UAV alignment unit configured to push the UAV on the movable UAV landing platform to a predetermined landing area of the moveable UAV landing platform.
Mobile robot and course adjusting method thereof,https://lens.org/070-216-457-659-553,2002,"A mobile robot capable of recognizing its location and adjusting its direction in response to an obstacle in its way includes a running device, an obstacle detecting device for detecting the presence of an obstacle, a location recognizing device, a controlling portion, and a power supply. The location recognizing device includes a first vision camera directed toward the ceiling of a room and a first vision board. The first vision camera recognizes a base mark on the ceiling. The first vision board processes an image from the first vision camera and transmits the image data to the controlling portion. The obstacle detecting device includes a line laser for emitting a linear light beam toward the obstacle, a second vision camera for recognizing a reflective linear light beam from the obstacle, and a second vision board for processing image data captured by the second vision camera."
Mobile robot and course adjusting method thereof,https://lens.org/165-645-391-620-137,2002,"A mobile robot capable of recognizing its location and adjusting its direction in response to an obstacle in its way includes a running device, an obstacle detecting device for detecting the presence of an obstacle, a location recognizing device, a controlling portion, and a power supply. The location recognizing device includes a first vision camera directed toward the ceiling of a room and a first vision board. The first vision camera recognizes a base mark on the ceiling. The first vision board processes an image from the first vision camera and transmits the image data to the controlling portion. The obstacle detecting device includes a line laser for emitting a linear light beam toward the obstacle, a second vision camera for recognizing a reflective linear light beam from the obstacle, and a second vision board for processing image data captured by the second vision camera."
"Remote controller, electronic apparatus and remote control system",https://lens.org/103-788-725-985-355,2008,"A remote controller (10) sets up a pairing via two-way communications. The remote controller contains a light-emitting unit (22) that emits a pairing-set-up request code for requesting a pairing-set-up start using infrared rays. The remote controller also contains a communication unit (24) that receives unique information transmitted using the radio wave in response to the pairing-set-up request code emitted from the light-emitting unit (22) and transmits unique information of the remote controller using the radio wave. The remote controller further contains a control unit (14, 16, 18) that controls the light-emitting unit and the communication unit to register the unique information received by the communication unit and to set a partner of the pairing."
LAWN MOWER ROBOT AND METHOD OF CONTROLLING THE SAME,https://lens.org/096-100-688-722-58X,2018,"A lawn mower robot being operated within an operation region defined by a boundary mark portion which has a boundary wire generating a specific signal, comprising: a main body which receives the signal generated by the boundary wire and is driven in a certain region of the operation region."
Method and Apparatus for Unmanned Aerial Maritime Float Vehicle That Sense and Report Relevant Data from Physical and Operational Environment,https://lens.org/047-240-213-499-676,2020,"Method and apparatus for unmanned aerial maritime float vehicle that sense and report relevant data from physical and operational environment. The apparatus is comprised of an unmanned aerial vehicle and cabled unmanned underwater vehicle. The method wherein a end-user's controller is coupled wirelessly to the unmanned aerial vehicle transceiver to allow relevant live data to be collected from sky and ground, Upon landing on a water's surface the cable is repelled and control signals and data are transmitted to the cabled unmanned underwater vehicle transceiver, thus high speed feedback and sensor signals can be transmitted from the cabled UUV back to the UAV then both the UUV and UAV high speed feedback and sensor signals are wirelessly sent back to the user's controller through the UAV."
Still camera with remote audio recording unit.,https://lens.org/139-104-440-587-149,1995,"A camera system includes a main camera body (10) having a main camera processor coupled to a main body operator interface (16), a recording head drive circuit (36) and wireless communication receiver, wherein the recording head drive circuit (36) is coupled to a recording head (38). A remote control unit (22) is also provided that includes a processor unit (48) coupled to an audio record/playback circuit (50), a remote operator interface (26) and a wireless communication transmitter (28), wherein the audio record circuit is coupled to a microphone. In operation, the processor unit of the remote control unit (22) controls the record/playback circuit (90) to record an audio segment of a selected duration based on control signals received from the operator interface. The processor unit (48) transmits sound ID data corresponding to the recorded audio segment to the main camera control processor via the wireless communication transmitter and receiver, and the main camera control processor (32) controls the operation of the recording head drive circuit to record the sound ID data on a recording strip located on a photographic film."
DEVICE AND METHOD FOR PROVIDING RESPONSE MESSAGE TO USER INPUT,https://lens.org/190-851-201-625-855,2019,"A method, performed by a device, of providing a response message to a user input includes obtaining location information of the device; executing a service providing agent corresponding to the location information; receiving a speech input from a user; generating the response message based on the received speech input, the response message being related to a service provided by the executed service providing agent; and displaying the generated response message, wherein the executed service providing agent generates the response message using a model trained using an artificial intelligence (AI) algorithm, the trained model being one from among a plurality of trained models each corresponding to a respective service from among a plurality of services provided by a respective service providing agent from among a plurality of service providing agents, and wherein the trained model corresponds to the executed service providing agent."
Device and method for providing response message to user input,https://lens.org/132-327-293-362-401,2021,"A method, performed by a device, of providing a response message to a user input includes obtaining location information of the device; executing a service providing agent corresponding to the location information; receiving a speech input from a user; generating the response message based on the received speech input, the response message being related to a service provided by the executed service providing agent; and displaying the generated response message, wherein the executed service providing agent generates the response message using a model trained using an artificial intelligence (AI) algorithm, the trained model being one from among a plurality of trained models each corresponding to a respective service from among a plurality of services provided by a respective service providing agent from among a plurality of service providing agents, and wherein the trained model corresponds to the executed service providing agent."
Method and system for controlling audio-video-navigation (AVN) of vehicle through smart device,https://lens.org/043-356-035-422-148,2021,"A method and system for controlling an Audio Video Navigation (AVN) of a vehicle by a smart device are disclosed, which control the AVN by a smart device including a mobile phone carried by a passenger accommodated on a back seat of the vehicle, using beacon and physical web technologies, controlling various functions of the AVN embedded in the vehicle may include constructing a virtual tunnel connected to an Internet of Things (IoT) server, acquiring an external Uniform Resource Locator (URL) for a service from the IoT server, generating the acquired external URL as a beacon packet, and transmitting the generated beacon packet to the smart device using a Bluetooth Low Energy (BLE) signal within the vehicle."
METHOD AND SYSTEM FOR CONTROLLING AUDIO-VIDEO-NAVIGATION (AVN) OF VEHICLE THROUGH SMART DEVICE,https://lens.org/009-313-456-627-624,2018,"A method and system for controlling an Audio Video Navigation (AVN) of a vehicle by a smart device are disclosed, which control the AVN by a smart device including a mobile phone carried by a passenger accommodated on a back seat of the vehicle, using beacon and physical web technologies, controlling various functions of the AVN embedded in the vehicle may include constructing a virtual tunnel connected to an Internet of Things (IoT) server, acquiring an external Uniform Resource Locator (URL) for a service from the IoT server, generating the acquired external URL as a beacon packet, and transmitting the generated beacon packet to the smart device using a Bluetooth Low Energy (BLE) signal within the vehicle."
SITUATIONAL AWARENESS ROBOT,https://lens.org/185-695-490-590-851,2021,"A system and methods for assessing an environment are disclosed. A method includes causing a robot to transmit data to first and second user devices, causing the robot to execute a first action, and, responsive to a second instruction, causing the robot to execute a second action. At least one user device is outside the environment of the robot. At least one action includes recording a video of at least a portion of the environment, displaying the video in real time on both user devices, and storing the video on a cloud-based network. The other action includes determining a first physical location of the robot, determining a desired second physical location of the robot, and propelling the robot from the first location to the second location. Determining the desired second location is responsive to detecting a touch on a touchscreen video feed displaying the video in real time."
DRONE BOX,https://lens.org/037-976-931-322-874,2017,"The application provides a storage unit for an Unmanned Aerial Vehicle (UAV). The storage unit includes a container, a UAV landing platform, and a receptacle. The container is provided for enclosing the UAV. The receptacle is positioned above the UAV landing platform and it includes at least one inclined surface for guiding a landing UAV to a predetermined UAV land- ing position on the UAV landing platform."
Drone box,https://lens.org/062-625-707-532-131,2020,"The application provides a storage unit for an Unmanned Aerial Vehicle (UAV). The storage unit includes a container, a UAV landing platform, and a receptacle. The container is provided for enclosing the UAV. The receptacle is positioned above the UAV landing platform and it includes at least one inclined surface for guiding a landing UAV to a predetermined UAV land- ing position on the UAV landing platform."
Drone box,https://lens.org/025-901-258-598-077,2018,"The application provides a storage unit for an Unmanned Aerial Vehicle (UAV). The storage unit includes a container, a UAV landing platform, and a receptacle. The container is provided for enclosing the UAV. The receptacle is positioned above the UAV landing platform and it includes at least one inclined surface for guiding a landing UAV to a predetermined UAV land- ing position on the UAV landing platform."
ELECTRONIC DEVICE AND CONTROL METHOD THEREOF,https://lens.org/010-940-390-590-192,2023,"An electronic device and a control method thereof are provided. The electronic device includes a camera, a camera flash, and at least one processor configured to control the camera to capture a natural light image and a depth image of an object, control the camera and the camera flash to capture an artificial light image of the object, obtain distance information from the depth image to generate a depth mask image, create a cluster mask image from the natural light image, obtain a flash image in which the illuminance of the natural light image has been removed from the illuminance of the artificial light image, obtain an optimization parameter based on the distance information, the depth mask image, the cluster mask image, and the flash image, and obtain three-dimensional topographic information and surface reflection information about the object based on the obtained optimization parameter."
Enhanced security in access control systems,https://lens.org/020-997-220-693-738,2022,"A method, system, and devices for providing enhanced security to access control systems. The system includes a user device, a first device and a second device. The user device sends a command to the first device. The command is further authorized to enable a communication between the first device and the second device. In an event of any security breach on the second device, the second device may generate an alert and transmit the same to the first device. In response to the alert, the first device may sound an alarm or siren for the concerned user."
ENHANCED SECURITY IN ACCESS CONTROL SYSTEMS,https://lens.org/139-186-078-058-181,2021,"A method, system, and devices for providing enhanced security to access control systems. The system includes a user device, a first device and a second device. The user device sends a command to the first device. The command is further authorized to enable a communication between the first device and the second device. In an event of any security breach on the second device, the second device may generate an alert and transmit the same to the first device. In response to the alert, the first device may sound an alarm or siren for the concerned user."
Enhanced security in access control systems,https://lens.org/020-997-220-693-738,2022,"A method, system, and devices for providing enhanced security to access control systems. The system includes a user device, a first device and a second device. The user device sends a command to the first device. The command is further authorized to enable a communication between the first device and the second device. In an event of any security breach on the second device, the second device may generate an alert and transmit the same to the first device. In response to the alert, the first device may sound an alarm or siren for the concerned user."
Device for automating and/or controlling of machine tools or production machines,https://lens.org/079-785-051-334-609,2004,"A device for automating and/or controlling machine tools or production machines is described. The device includes at least one computer which is located remote from a machine. The computer operates like a handheld controller and is connected via at least one bus system, which can be wired or wireless, with each machine for unidirectionally or bidirectionally transmitting data and control signals. All control functions of the machine are integrated in the remote controller. This device can automate and/or control machine tools and production machines in a simple and cost-effective manner."
Device for automating and/or controlling of machine tools or production machines,https://lens.org/011-560-683-304-622,2006,"A device for automating and/or controlling machine tools or production machines is described. The device includes at least one computer which is located remote from a machine. The computer operates like a handheld controller and is connected via at least one bus system, which can be wired or wireless, with each machine for unidirectionally or bidirectionally transmitting data and control signals. All control functions of the machine are integrated in the remote controller. This device can automate and/or control machine tools and production machines in a simple and cost-effective manner."
REMOTE-CONTROLLED DECORATION,https://lens.org/156-468-955-229-774,2008,"A remote-controlled decoration includes a decorative main body and a remote controller. The decorative main body includes an internal chamber, and a base mounted to a lower open end of the chamber. The base is provided with a circuit board connected to a power source, at least one LED light, and a receiver. The remote controller includes a signal transmitter for remotely transmitting a control signal to the receiver on the decorative main body, so as to control the LED light to light or extinguish."
Unmanned aerial vehicle,https://lens.org/054-050-780-405-687,2021,An unmanned aerial vehicle capable of employing active noise cancelling without being influenced by wind from a rotor is provided. The unmanned aerial vehicle includes a processor and at least one speaker. The processor acquires operational information regarding each of at least one generator and generates an opposite phase signal having an opposite phase relative to a signal corresponding to the operational information. The at least one generator generates a force to fly the unmanned aerial vehicle. The operational information correlates with noise generated by each of the at least one generator. The at least one speaker outputs sound based on the opposite phase signal.
REMOTE CONTROL FOR AN AUDIO SIGNAL PLAYING APPARATUS,https://lens.org/158-363-047-967-538,1999,"A remote control (1) of the type used for remotely controlling parameters on a television or Hi Fi set, such as sound, is adapted to be connected to a telephone (4), the remote control (1) incorporating switch means (12) for switching on the remote control in response to an incoming signal indicative of sound, and means for emitting a control signal to change a required parameter, such as by reducing or eliminating the level of sound of a television (3) when the telephone rings."
"Unmanned Aerial Vehicle Display Method, Apparatus, and Medium",https://lens.org/014-275-641-585-469,2018,"An advertising apparatus comprises an unmanned aerial vehicle (UAV) having at least one motor, and at least one propeller operably connected to said at least one motor for providing vertical lift to said UAV, and a three-dimensional advertising assembly operably attached to said UAV, said advertising assembly comprising a display medium for providing a non-planar, viewable display for conveying at least one image to a viewer."
Uninhabited airborne vehicle in-flight refueling system,https://lens.org/053-931-470-449-717,2004,"A method and system is provided for performing automated air refueling of uninhabited airborne vehicles (UAVs). The method and system includes any combination of a positioning system component, an air collision avoidance system (ACAS) component, a voice processing component, an image processing component, a flight controller, a wireless data link connecting the UAV with the tanker, and refueling components. The ACAS component receives position information of other aircraft, such as UAVs and tankers, over the wireless data link, and generates navigation instructions based on the received position information, and sends the generated navigation instructions to the flight controller. The refueling components include sensors that determine the status of the refueling components. Refueling of the UAV is based on the determined status."
Uninhabited airborne vehicle in-flight refueling system,https://lens.org/163-750-745-217-604,2004,"A method and system is provided for performing automated air refueling of uninhabited airborne vehicles (UAVs). The method and system includes any combination of a positioning system component, an air collision avoidance system (ACAS) component, a voice processing component, an image processing component, a flight controller, a wireless data link connecting the UAV with the tanker, and refueling components. The ACAS component receives position information of other aircraft, such as UAVs and tankers, over the wireless data link, and generates navigation instructions based on the received position information, and sends the generated navigation instructions to the flight controller. The refueling components include sensors that determine the status of the refueling components. Refueling of the UAV is based on the determined status."
Apparatus and method for implementing an endoscopic marker,https://lens.org/004-655-071-275-742,2004,"A wireless endoscope unit includes an RF transmitter for transmitting and receiving signals via an antenna, and an arrangement for taking individual images of the surroundings. These images are then transferred via the RF transmitter to an external image processing unit. In this case, a control serves for executing control commands received via the RF receiver. A dye container is included for keeping a dye and an exit opening, connected to the dye container, is for implementing the dye in tissue in accordance with the control commands of the control."
AERIAL VEHICLE WITH DEPLOYABLE COMPONENTS,https://lens.org/016-620-410-837-144,2019,"An unmanned aerial vehicle (UAV) comprising: a fuselage; and at least one stabilizer. The base of the stabilizer is configured to pivot about a first axis and a second axis, wherein the at least one stabilizer is configurable in at least the following arrangements: a compact arrangement comprising: the at least one stabilizer stowed against the fuselage, and a deployed arrangement comprising: the least one stabilizer deployed from the fuselage about the first axis."
Systems and methods for autonomous airworthiness pre-flight checks for UAVs,https://lens.org/029-803-807-419-569,2023,"A method includes determining an operational condition associated with an unmanned aerial vehicle (UAV). The method includes, responsive to determining the operational condition, causing the UAV to perform a pre-flight check. The pre-flight check includes hovering the UAV above a takeoff location. The pre-flight check includes, while hovering the UAV, moving one or more controllable components of the UAV in accordance with a predetermined sequence of movements. The pre-flight check includes obtaining, by one or more sensors of the UAV, sensor data indicative of a flight response of the UAV to moving the one or more controllable components while hovering the UAV. The pre-flight check includes comparing the sensor data to expected sensor data associated with an expected flight response to the predetermined sequence of movements while hovering the UAV. The pre- flight check includes, based on comparing the sensor data to the expected sensor data, evaluating performance of the UAV."
Systems and methods for autonomous airworthiness pre-flight checks for UAVs,https://lens.org/029-803-807-419-569,2023,"A method includes determining an operational condition associated with an unmanned aerial vehicle (UAV). The method includes, responsive to determining the operational condition, causing the UAV to perform a pre-flight check. The pre-flight check includes hovering the UAV above a takeoff location. The pre-flight check includes, while hovering the UAV, moving one or more controllable components of the UAV in accordance with a predetermined sequence of movements. The pre-flight check includes obtaining, by one or more sensors of the UAV, sensor data indicative of a flight response of the UAV to moving the one or more controllable components while hovering the UAV. The pre-flight check includes comparing the sensor data to expected sensor data associated with an expected flight response to the predetermined sequence of movements while hovering the UAV. The pre- flight check includes, based on comparing the sensor data to the expected sensor data, evaluating performance of the UAV."
SYSTEMS AND METHODS FOR AUTONOMOUS AIRWORTHINESS PRE-FLIGHT CHECKS FOR UAVS,https://lens.org/130-515-181-319-340,2022,"A method includes determining an operational condition associated with an unmanned aerial vehicle (UAV). The method includes, responsive to determining the operational condition, causing the UAV to perform a pre-flight check. The pre-flight check includes hovering the UAV above a takeoff location. The pre-flight check includes, while hovering the UAV, moving one or more controllable components of the UAV in accordance with a predetermined sequence of movements. The pre-flight check includes obtaining, by one or more sensors of the UAV, sensor data indicative of a flight response of the UAV to moving the one or more controllable components while hovering the UAV. The pre-flight check includes comparing the sensor data to expected sensor data associated with an expected flight response to the predetermined sequence of movements while hovering the UAV. The pre- flight check includes, based on comparing the sensor data to the expected sensor data, evaluating performance of the UAV."
SYSTEMS AND METHODS FOR AUTONOMOUS AIRWORTHINESS PRE-FLIGHT CHECKS FOR UAVS,https://lens.org/130-515-181-319-340,2022,"A method includes determining an operational condition associated with an unmanned aerial vehicle (UAV). The method includes, responsive to determining the operational condition, causing the UAV to perform a pre-flight check. The pre-flight check includes hovering the UAV above a takeoff location. The pre-flight check includes, while hovering the UAV, moving one or more controllable components of the UAV in accordance with a predetermined sequence of movements. The pre-flight check includes obtaining, by one or more sensors of the UAV, sensor data indicative of a flight response of the UAV to moving the one or more controllable components while hovering the UAV. The pre-flight check includes comparing the sensor data to expected sensor data associated with an expected flight response to the predetermined sequence of movements while hovering the UAV. The pre- flight check includes, based on comparing the sensor data to the expected sensor data, evaluating performance of the UAV."
"PARCEL CHUTE FOR AN OUTER WALL OF A BUILDING OR AN ENCLOSURE OF A BALCONY, METHOD FOR DELIVERING A PARCEL USING AN UNMANNED AIRCRAFT AND FOR GUIDING THE PARCEL THROUGH A PARCEL CHUTE, OUTER WALL OF ABUILDING AND ENCLOSURE FOR A BALCONY OF A BUILDING",https://lens.org/050-095-492-439-27X,2022,"The invention relates to a parcel chute (1) for an outer wall (13) of a building or an enclosure of a balcony which is used for the automatic delivery and collection of a parcel (2) by means of an unmanned aircraft, in particular a logistics drone; a method for delivering a parcel (2) using an unmanned aircraft, in particular a logistics drone; an outer wall (13) with a parcel chute (1); and an enclosure with a parcel chute (1)."
"PARCEL CHUTE FOR AN OUTER WALL OF A BUILDING OR AN ENCLOSURE OF A BALCONY, METHOD FOR DELIVERING A PARCEL USING AN UNMANNED AIRCRAFT AND FOR GUIDING THE PARCEL THROUGH A PARCEL CHUTE, OUTER WALL OF ABUILDING AND ENCLOSURE FOR A BALCONY OF A BUILDING",https://lens.org/050-095-492-439-27X,2022,"The invention relates to a parcel chute (1) for an outer wall (13) of a building or an enclosure of a balcony which is used for the automatic delivery and collection of a parcel (2) by means of an unmanned aircraft, in particular a logistics drone; a method for delivering a parcel (2) using an unmanned aircraft, in particular a logistics drone; an outer wall (13) with a parcel chute (1); and an enclosure with a parcel chute (1)."
SYSTEM AND METHODS FOR AUTOMATED AIRPORT AIR TRAFFIC CONTROL SERVICES,https://lens.org/172-303-269-815-620,2018,"A system and method for automating Air Traffic Control operations at or near an airport. as a complete standalone automated system replacing the need for a human controller to make aircraft movement decisions nor the need communicate with pilots, or as semi-automated, where a controller controls how the system operates. The system with related methods and computer hardware and computer software package, automatically manages manned aircraft, remote controlled UAV and airborne-able vehicles traffic at or near an airport, eliminates ATC-induced and reduce pilot-induced runway incursions and excursions, processes control messages related to aircraft or Pilots, communicates with Pilot over ATC radio frequency, receives aircraft positions, communicates control messages with the aircraft avionics, provides pilots a dynamic map with continuous display of nearby traffic operations, shows clearance and information related to runway operations, warns pilot of runway conditions and turbulence from other operations, warns when landing gear is not locked, displays the pilot emergency exits during takeoff roll, shows the pilot when and where to exit from the runway, shows the pilot where and when to cross a junction, calculates and displays pilot optimal speed and timing on taxiways and junctions for saving fuel, calculates congestions, calculates best taxiway routes, calculates when aircraft can cross a runway, provides directives and information to pilot over CPDLC display or dynamic map for airside operations, alerts and triggers breaks of the aircraft on wrong path or when hold-short bar is breached, displays emergency personnel with routing map and final aircraft resting position for emergency operations, takes over an aircraft operation when aircraft is hijacked or deviates from the flight plan, provide standalone or manned Remote Tower functionality, Records and retains all information related to airport airside operations including aircraft positions and conditions from sensors and reports for runways, junctions and taxiways, Records and retains aircraft data and cockpit voice to ground-based servers to eliminate black-box requirements, calculate future weather and airport capacity from aircraft at or nearby airport, coordinates handoff operations with other ATC positions, interfaces with ACDM systems, airport operations center, flow center and network operations center."
Unmanned aerial vehicle and techniques for securing a payload to the UAV in a desired orientation,https://lens.org/158-089-676-444-976,2020,"An unmanned aerial vehicle system is provided including an unmanned aerial vehicle (UAV) having a fuselage, a tether having a first end secured to a winch system positioned in the UAV and a second end secured to a payload coupling apparatus, a payload coupling apparatus receptacle positioned in the fuselage of the UAV, a payload having a handle, wherein the handle of the payload is positioned within a slot in the payload coupling apparatus. A method of securing a payload to a UAV is also provided."
Unmanned aerial vehicle and techniques for securing a payload to the UAV in a desired orientation,https://lens.org/038-220-633-371-076,2022,"An unmanned aerial vehicle system is provided including an unmanned aerial vehicle (UAV) having a fuselage, a tether having a first end secured to a winch system positioned in the UAV and a second end secured to a payload coupling apparatus, a payload coupling apparatus receptacle positioned in the fuselage of the UAV, a payload having a handle, wherein the handle of the payload is positioned within a slot in the payload coupling apparatus. A method of securing a payload to a UAV is also provided."
Unmanned aerial vehicle and techniques for securing a payload to the UAV in a desired orientation,https://lens.org/047-211-792-508-967,2020,"An unmanned aerial vehicle system is provided including an unmanned aerial vehicle (UAV) having a fuselage, a tether having a first end secured to a winch system positioned in the UAV and a second end secured to a payload coupling apparatus, a payload coupling apparatus receptacle positioned in the fuselage of the UAV, a payload having a handle, wherein the handle of the payload is positioned within a slot in the payload coupling apparatus. A method of securing a payload to a UAV is also provided."
Unmanned Aerial Vehicle and Techniques for Securing a Payload to the UAV in a Desired Orientation,https://lens.org/058-998-834-953-382,2021,"An unmanned aerial vehicle system is provided including an unmanned aerial vehicle (UAV) having a fuselage, a tether having a first end secured to a winch system positioned in the UAV and a second end secured to a payload coupling apparatus, a payload coupling apparatus receptacle positioned in the fuselage of the UAV, a payload having a handle, wherein the handle of the payload is positioned within a slot in the payload coupling apparatus. A method of securing a payload to a UAV is also provided."
UNMANNED AERIAL VEHICLE AND TECHNIQUES FOR SECURING A PAYLOAD TO THE UAV IN A DESIRED ORIENTATION,https://lens.org/142-422-333-841-967,2023,"An unmanned aerial vehicle system is provided including an unmanned aerial vehicle (UAV) having a fuselage, a tether having a first end secured to a winch system positioned in the UAV and a second end secured to a payload coupling apparatus, a payload coupling apparatus receptacle positioned in the fuselage of the UAV, a payload having a handle, wherein the handle of the payload is positioned within a slot in the payload coupling apparatus. A method of securing a payload to a UAV is also provided."
Unmanned aerial vehicle and techniques for securing a payload to the UAV in a desired orientation,https://lens.org/038-220-633-371-076,2022,"An unmanned aerial vehicle system is provided including an unmanned aerial vehicle (UAV) having a fuselage, a tether having a first end secured to a winch system positioned in the UAV and a second end secured to a payload coupling apparatus, a payload coupling apparatus receptacle positioned in the fuselage of the UAV, a payload having a handle, wherein the handle of the payload is positioned within a slot in the payload coupling apparatus. A method of securing a payload to a UAV is also provided."
"APPARATUS AND METHOD FOR DETECTING, IDENTIFYING AND LOCATING DRONES",https://lens.org/031-362-698-988-72X,2022,"A drone detection, identification and location system and method may illuminate a target with one or multiple selected radio-frequency (RF) carrier frequencies. Both direct emissions received from the target and re-emissions generated by the target may be processed to determine whether the target is a drone. The re-emissions may be generated by circuitry of the target resulting from the illumination with the one or multiple RF carrier frequencies. The re-emissions may comprise cross-modulation products (CMPs) including forced non-linear emissions (FNLEs). The direct emissions and the re-emissions may be processed to generate an RF signature for the target. The target may be determined to be drone and the type of drone may be identified based on the RF signature."
"APPARATUS AND METHOD FOR DETECTING, IDENTIFYING AND LOCATING DRONES",https://lens.org/031-362-698-988-72X,2022,"A drone detection, identification and location system and method may illuminate a target with one or multiple selected radio-frequency (RF) carrier frequencies. Both direct emissions received from the target and re-emissions generated by the target may be processed to determine whether the target is a drone. The re-emissions may be generated by circuitry of the target resulting from the illumination with the one or multiple RF carrier frequencies. The re-emissions may comprise cross-modulation products (CMPs) including forced non-linear emissions (FNLEs). The direct emissions and the re-emissions may be processed to generate an RF signature for the target. The target may be determined to be drone and the type of drone may be identified based on the RF signature."
"APPARATUS AND METHOD FOR DETECTING, IDENTIFYING AND LOCATING DRONES",https://lens.org/031-362-698-988-72X,2022,"A drone detection, identification and location system and method may illuminate a target with one or multiple selected radio-frequency (RF) carrier frequencies. Both direct emissions received from the target and re-emissions generated by the target may be processed to determine whether the target is a drone. The re-emissions may be generated by circuitry of the target resulting from the illumination with the one or multiple RF carrier frequencies. The re-emissions may comprise cross-modulation products (CMPs) including forced non-linear emissions (FNLEs). The direct emissions and the re-emissions may be processed to generate an RF signature for the target. The target may be determined to be drone and the type of drone may be identified based on the RF signature."
Controlling Method and System for Autonomous Vehicle,https://lens.org/062-178-269-487-059,2018,"A controlling method for an autonomous vehicle includes identifying a line track by the computing device via the camera set, and traveling the autonomous vehicle on a floor along the line track. When the autonomous vehicle is traveled relative to a wall, the line track is the wall-floor intersection, and the autonomous vehicle travels along the line track and parallel to the wall in a first predetermined distance determined by the computing device via the rangefinder and/or the camera set. When the autonomous vehicle travels where no walls are measured by the rangefinder and the camera set, the line track is a marking line on the floor, and the autonomous vehicle travels along the marking line in a second predetermined distance determined by the computing device via the camera set, and determining the travel path of the autonomous vehicle according to a preset map installed in the computing device."
ELECTRONIC DEVICE CONTROLLED BY A MOTION AND CONTROLLING METHOD THEREOF,https://lens.org/158-040-950-110-366,2012,"An electronic device is provided. The electronic device includes a motion recognition unit which recognizes motion of an object and a control unit which, if a push motion in which the object located in front of the electronic device is moved in a direction of the electronic device is sensed by the motion recognition unit, activates a motion recognition mode, tracks the motion of the object, and performs a control operation of the electronic device corresponding to a subsequent motion of the object. The control unit may inactivate the motion recognition mode if an end motion in which the motion of the object is in a direction to contact a body part of a user or an additional object is recognized by the motion recognition unit while the motion recognition mode is activated."
ROBOTIC SYSTEM AND METHOD OF MOVEMENT CONTROL USING SYNTHETIC ARRAY RADAR AND PASSIVE BEACONS,https://lens.org/117-929-512-610-167,2018,"A system includes a moveable element adapted to move relative to a coordinate system defined for a robot, an object detection transceiver unit adapted to be mounted on the moveable element, and a controller. The controller controls the object detection transceiver unit to emit a signal and obtain a return signal for an operational cell of the robot at each of a series of predetermined positions to emulate a transceiver aperture larger than an aperture of the object detection transceiver unit. A location corresponding to a marker present in the operational cell is determined from the return signals. A predetermined operation is carried out where the predetermined operation includes using the determined location to guide movement of the robot."
Robotic system and method of movement control using synthetic array radar and passive beacons,https://lens.org/117-820-220-541-789,2023,"A system includes a moveable element adapted to move relative to a coordinate system defined for a robot, an object detection transceiver unit adapted to be mounted on the moveable element, and a controller. The controller controls the object detection transceiver unit to emit a signal and obtain a return signal for an operational cell of the robot at each of a series of predetermined positions to emulate a transceiver aperture larger than an aperture of the object detection transceiver unit. A location corresponding to a marker present in the operational cell is determined from the return signals. A predetermined operation is carried out where the predetermined operation includes using the determined location to guide movement of the robot."
ROBOTIC SYSTEM AND METHOD OF MOVEMENT CONTROL USING SYNTHETIC ARRAY RADAR AND PASSIVE BEACONS,https://lens.org/073-717-233-719-662,2019,"A system includes a moveable element adapted to move relative to a coordinate system defined for a robot, an object detection transceiver unit adapted to be mounted on the moveable element, and a controller. The controller controls the object detection transceiver unit to emit a signal and obtain a return signal for an operational cell of the robot at each of a series of predetermined positions to emulate a transceiver aperture larger than an aperture of the object detection transceiver unit. A location corresponding to a marker present in the operational cell is determined from the return signals. A predetermined operation is carried out where the predetermined operation includes using the determined location to guide movement of the robot."
Robotic system and method of movement control using synthetic array radar and passive beacons,https://lens.org/117-820-220-541-789,2023,"A system includes a moveable element adapted to move relative to a coordinate system defined for a robot, an object detection transceiver unit adapted to be mounted on the moveable element, and a controller. The controller controls the object detection transceiver unit to emit a signal and obtain a return signal for an operational cell of the robot at each of a series of predetermined positions to emulate a transceiver aperture larger than an aperture of the object detection transceiver unit. A location corresponding to a marker present in the operational cell is determined from the return signals. A predetermined operation is carried out where the predetermined operation includes using the determined location to guide movement of the robot."
SYSTEM AND METHOD OF ACCESSING A DEVICE,https://lens.org/115-657-656-142-850,2009,"A method of accessing a device is provided. A command is received from an agent, over a network, for executing at least one instruction for accessing the device. Information is sent to the agent, over the network, regarding the execution of the at least one instruction."
System and method of accessing a device,https://lens.org/022-876-466-420-766,2010,"A method of accessing a device is provided. A command is received from an agent, over a network, for executing at least one instruction for accessing the device. Information is sent to the agent, over the network, regarding the execution of the at least one instruction.
"
SYSTEMS AND METHODS FOR AUTONOMOUS VEHICLE CONTROL USING DEPOLARIZATION RATIO OF RETURN SIGNAL,https://lens.org/074-874-755-908-458,2022,"An autonomous vehicle control system includes one or more processors configured to cause a transmitter to transmit a transmit signal from a laser source, cause a receiver to receive a return signal reflected by an object, cause one or more optics to generate a first polarized signal of the return signal with a first polarization, generate a second polarized signal of the return signal with a second polarization that is orthogonal to the first polarization, and calculate a ratio of reflectivity between the first polarized signal and the second polarized signal by calculating a ratio between an average signal-to-noise ratio (SNR) value of the first polarized signal and an average SNR value of the second polarized signal. The one or more processors are configured to operate a vehicle based on the ratio of reflectivity between the first polarized signal and the second polarized signal."
Systems and methods for autonomous vehicle control using depolarization ratio of return signal,https://lens.org/062-981-380-439-699,2022,"An autonomous vehicle control system includes one or more processors configured to cause a transmitter to transmit a transmit signal from a laser source, cause a receiver to receive a return signal reflected by an object, cause one or more optics to generate a first polarized signal of the return signal with a first polarization, generate a second polarized signal of the return signal with a second polarization that is orthogonal to the first polarization, and calculate a ratio of reflectivity between the first polarized signal and the second polarized signal by calculating a ratio between an average signal-to-noise ratio (SNR) value of the first polarized signal and an average SNR value of the second polarized signal. The one or more processors are configured to operate a vehicle based on the ratio of reflectivity between the first polarized signal and the second polarized signal."
SYSTEMS AND METHODS FOR AUTONOMOUS VEHICLE CONTROL USING DEPOLARIZATION RATIO OF RETURN SIGNAL,https://lens.org/182-719-876-894-705,2023,"An autonomous vehicle control system includes one or more processors configured to cause a transmitter to transmit a transmit signal from a laser source, cause a receiver to receive a return signal reflected by an object, cause one or more optics to generate a first polarized signal of the return signal with a first polarization, generate a second polarized signal of the return signal with a second polarization that is orthogonal to the first polarization, and calculate a ratio of reflectivity between the first polarized signal and the second polarized signal by calculating a ratio between an average signal-to-noise ratio (SNR) value of the first polarized signal and an average SNR value of the second polarized signal. The one or more processors are configured to operate a vehicle based on the ratio of reflectivity between the first polarized signal and the second polarized signal."
Systems and methods for autonomous vehicle control using depolarization ratio of return signal,https://lens.org/062-981-380-439-699,2022,"An autonomous vehicle control system includes one or more processors configured to cause a transmitter to transmit a transmit signal from a laser source, cause a receiver to receive a return signal reflected by an object, cause one or more optics to generate a first polarized signal of the return signal with a first polarization, generate a second polarized signal of the return signal with a second polarization that is orthogonal to the first polarization, and calculate a ratio of reflectivity between the first polarized signal and the second polarized signal by calculating a ratio between an average signal-to-noise ratio (SNR) value of the first polarized signal and an average SNR value of the second polarized signal. The one or more processors are configured to operate a vehicle based on the ratio of reflectivity between the first polarized signal and the second polarized signal."
Systems and methods for autonomous vehicle control using depolarization ratio of return signal,https://lens.org/062-981-380-439-699,2022,"An autonomous vehicle control system includes one or more processors configured to cause a transmitter to transmit a transmit signal from a laser source, cause a receiver to receive a return signal reflected by an object, cause one or more optics to generate a first polarized signal of the return signal with a first polarization, generate a second polarized signal of the return signal with a second polarization that is orthogonal to the first polarization, and calculate a ratio of reflectivity between the first polarized signal and the second polarized signal by calculating a ratio between an average signal-to-noise ratio (SNR) value of the first polarized signal and an average SNR value of the second polarized signal. The one or more processors are configured to operate a vehicle based on the ratio of reflectivity between the first polarized signal and the second polarized signal."
VOICE ACTIVATED REAL ESTATE ACCESS CONTROL,https://lens.org/102-809-613-540-136,2022,"A method of providing real estate access control includes receiving a voice input at a voice assistant unit; sending the voice input from the voice assistant unit to a language processing system; at the language processing system, processing the voice input to define a message; sending the message from the language processing system to a locking device management system; at the locking device management system, processing the message as one of a command to a locking device and a query regarding the locking device."
VOICE ACTIVATED REAL ESTATE ACCESS CONTROL,https://lens.org/102-809-613-540-136,2022,"A method of providing real estate access control includes receiving a voice input at a voice assistant unit; sending the voice input from the voice assistant unit to a language processing system; at the language processing system, processing the voice input to define a message; sending the message from the language processing system to a locking device management system; at the locking device management system, processing the message as one of a command to a locking device and a query regarding the locking device."
LIDAR SYSTEM AND AUTONOMOUS DRIVING SYSTEM USING THE SAME,https://lens.org/106-430-348-113-457,2020,"Provided are a lidar system and an autonomous driving system using the same. The lidar system includes: a light emitter configured to include a light source generating a laser beam and a scanner moving the laser beam from the light source to scan an object with the laser beam; a receiving sensor configured to convert light reflected and received by the object into an electrical signal; and a signal processor configured to include a trans impedance amplifier amplifying an output signal of the receiving sensor, an analog to digital converter converting an output signal of the trans impedance amplifier into a digital signal, and a gain controller varying a gain of the trans impedance amplifier. According to the lidar system, an autonomous vehicle, an AI device, and an external device may be linked with an artificial intelligence module, a drone, a robot, an Augmented or Virtual Reality device, etc."
Lidar system and autonomous driving system using the same,https://lens.org/148-518-374-031-703,2021,"Provided are a lidar system and an autonomous driving system using the same. The lidar system includes: a light emitter configured to include a light source generating a laser beam and a scanner moving the laser beam from the light source to scan an object with the laser beam; a receiving sensor configured to convert light reflected and received by the object into an electrical signal; and a signal processor configured to include a trans impedance amplifier amplifying an output signal of the receiving sensor, an analog to digital converter converting an output signal of the trans impedance amplifier into a digital signal, and a gain controller varying a gain of the trans impedance amplifier. According to the lidar system, an autonomous vehicle, an AI device, and an external device may be linked with an artificial intelligence module, a drone, a robot, an Augmented or Virtual Reality device, etc."
Small-sized rotating flapping wing unmanned aerial vehicle,https://lens.org/192-116-295-389-292,2014,"The utility model discloses a small-sized rotating flapping wing unmanned aerial vehicle, and belongs to the technical field of aircrafts. The aerial vehicle consists of a machine body, a landing gear, an energy system, a control system, a left rotating flapping wing and a right rotating flapping wing, wherein the energy system comprises a motor, a convenient-to-charge lithium battery, a reduction gear set and a speed governing device; the control system comprises a radio remote control transmitter and a radio remote control receiver or adopts an automatic navigation control device and a steering gear; the left and right rotating flapping wings have the same structure, are symmetrically arranged on the left and right sides of the machine body, and are driven by power to provide thrust; the aerial vehicle can be perpendicularly lifted and hovered; the left rotating flapping wing consists of a left main shaft, a left rotating arm, a left wing panel, a left wing shaft, a left guide rod and a left guider; the right rotating flapping wing consists of a right main shaft, a right rotating arm, a right wing panel, a right wing shaft, a right guide rod and a right guider. The aerial vehicle is simple in structure and higher in efficiency, and can be provided with photographic equipment for many tasks such as aerial photography, geographic survey, traffic duty, military reconnaissance and rescue and relief work."
Wearable robot and method of controlling the same,https://lens.org/090-622-949-089-445,2018,"There is provided a method of controlling a wearable robot. The method includes measuring an electrical signal from a scalp of a wearer, estimating a current walking speed of the wearer using the measured electrical signal, and outputting assistive torque which allows the estimated current walking speed to approximate a target walking speed."
WEARABLE ROBOT AND METHOD OF CONTROLLING THE SAME,https://lens.org/073-330-943-224-422,2015,"There is provided a method of controlling a wearable robot. The method includes measuring an electrical signal from a scalp of a wearer, estimating a current walking speed of the wearer using the measured electrical signal, and outputting assistive torque which allows the estimated current walking speed to approximate a target walking speed."
ROBOT,https://lens.org/025-072-083-019-786,2012,"This robot includes an arm and a joint provided on one end portion of the arm, and either the arm or the joint is provided with an end effector driving source to operate an end effector mounted to the arm through the joint."
SYSTEMS AND METHODS FOR AUTONOMOUSLY BACKING A VEHICLE TO A DOCK,https://lens.org/154-091-720-320-928,2019,"In some embodiments, techniques are provided for autonomously backing a vehicle to a target object such as a loading dock, a loading bay, a dock level er, a garage door, a wall area, another vehicle, or an end of an alley. The target object is determined, and an autonomous backing module of the vehicle determines relevant distances and angles. Using this information, the autonomous backing module may determine a path to the target object, and transmit commands to components of the vehicle to autonomously control the vehicle along the determined path to the target object."
Systems and methods for autonomously backing a vehicle to a dock,https://lens.org/181-490-711-800-222,2020,"In some embodiments, techniques are provided for autonomously backing a vehicle to a target object such as a loading dock, a loading bay, a dock level er, a garage door, a wall area, another vehicle, or an end of an alley. The target object is determined, and an autonomous backing module of the vehicle determines relevant distances and angles. Using this information, the autonomous backing module may determine a path to the target object, and transmit commands to components of the vehicle to autonomously control the vehicle along the determined path to the target object."
SYSTEMS AND METHODS FOR AUTONOMOUSLY BACKING A VEHICLE TO A DOCK,https://lens.org/109-851-082-916-512,2021,"In some embodiments, techniques are provided for autonomously backing a vehicle to a target object such as a loading dock, a loading bay, a dock level er, a garage door, a wall area, another vehicle, or an end of an alley. The target object is determined, and an autonomous backing module of the vehicle determines relevant distances and angles. Using this information, the autonomous backing module may determine a path to the target object, and transmit commands to components of the vehicle to autonomously control the vehicle along the determined path to the target object."
Communication device,https://lens.org/037-912-649-134-375,2009,"The method to remotely control a device located in a building or house by a handheld mobile device. The device may be a TV tuner, microwave oven, VCR, bathroom, room light, air conditioner, room heater, door lock, or camera."
Autonomous Mobile Robot And Method For Controlling An Autonomous Mobile Robot,https://lens.org/072-072-827-398-008,2021,"An autonomous mobile robot is described having a propulsion module designed to move the robot in its surroundings, a control module designed to transmit control commands to the propulsion module, the control commands being designed to control the movement of the robot, and a security module designed to detect a dangerous situation, classing an actual movement of the robot as dangerous on the basis of predetermined criteria, and to change or stop the movement of the robot when the movement is classed as dangerous."
Unmanned vehicle maintenance,https://lens.org/182-959-358-039-04X,2023,An unmanned aerial vehicle includes a blade that is configured to rotate relative to a body of the unmanned aerial vehicle to enable the unmanned aerial vehicle to fly. The blade defines at least one cavity. The blade includes a power source and an auxiliary rotor configured to use the power source to rotate relative to the blade to cause the blade to fly. The auxiliary rotor is configured to withdraw into the at least one cavity. The blade is configured to decouple from the unmanned aerial vehicle. The auxiliary rotor is configured to extend from the at least one cavity and cause the blade to fly such that the blade navigates away from the unmanned aerial vehicle using the auxiliary rotor.
Unmanned vehicle maintenance,https://lens.org/182-959-358-039-04X,2023,An unmanned aerial vehicle includes a blade that is configured to rotate relative to a body of the unmanned aerial vehicle to enable the unmanned aerial vehicle to fly. The blade defines at least one cavity. The blade includes a power source and an auxiliary rotor configured to use the power source to rotate relative to the blade to cause the blade to fly. The auxiliary rotor is configured to withdraw into the at least one cavity. The blade is configured to decouple from the unmanned aerial vehicle. The auxiliary rotor is configured to extend from the at least one cavity and cause the blade to fly such that the blade navigates away from the unmanned aerial vehicle using the auxiliary rotor.
UNMANNED VEHICLE MAINTENANCE,https://lens.org/081-695-090-004-277,2022,An unmanned aerial vehicle includes a blade that is configured to rotate relative to a body of the unmanned aerial vehicle to enable the unmanned aerial vehicle to fly. The blade defines at least one cavity. The blade includes a power source and an auxiliary rotor configured to use the power source to rotate relative to the blade to cause the blade to fly. The auxiliary rotor is configured to withdraw into the at least one cavity. The blade is configured to decouple from the unmanned aerial vehicle. The auxiliary rotor is configured to extend from the at least one cavity and cause the blade to fly such that the blade navigates away from the unmanned aerial vehicle using the auxiliary rotor.
Remote active camera and method of controlling same,https://lens.org/120-022-746-615-502,2020,"Provided is a remote active camera including an image capture unit; a gimbal unit that changes a direction in which the image capture unit is directed; a memory in which images having an identification number are stored; a communication unit that transmits acquired images to a remote control apparatus and receives target designation information from the remote control apparatus; a tracking unit that includes a first tracking unit which tracks a position of a preset reference target from a first image, and a second tracking unit which tracks positions of the designation target and the reference target from a second image; and a controller that compares identification numbers of the first and second images, estimates or detects a position value of the designation target on the basis of positions of the designation target and the reference target, and a position of the reference target, and controls the gimbal unit."
"SECURITY DEVICE, BROADCAST RECEIVING DEVICE, CAMERA DEVICE, AND IMAGE CAPTURING METHOD THEREOF",https://lens.org/022-088-049-603-02X,2015,"A security device includes an interface configured to be connected to a camera, a storage configured to store reference audio data, a microphone configured to receive a sound input and convert the sound input into audio data, and a controller configured to, in response to the converted audio data corresponding to the reference audio data, activate the camera."
"Presenting location related information and implementing a task based on gaze, gesture, and voice detection",https://lens.org/179-440-283-204-119,2021,"Systems and methods for presenting information and executing a task. In an aspect, when a user gazes at a display of a standby device, location related information is presented. In another aspect, when a user utters a voice command and gazes or gestures at a device, a task is executed. In another aspect, a partial address in a voice input, a gesture, and user information are used to determine a destination in an autonomous vehicle. In another aspect, a partial name in a voice input and a gesture are used to determine a product in a purchase process."
"Presenting Location Related Information and Implementing a Task Based on Gaze, Gesture, and Voice Detection",https://lens.org/130-644-572-481-944,2021,"Systems and methods for presenting information and executing a task. In an aspect, when a user gazes at a display of a standby device, location related information is presented. In another aspect, when a user utters a voice command and gazes or gestures at a device, a task is executed. In another aspect, a partial address in a voice input, a gesture, and user information are used to determine a destination in an autonomous vehicle. In another aspect, a partial name in a voice input and a gesture are used to determine a product in a purchase process."
APPARATUS AND METHOD FOR A REMOTE CONTROL OF EMERGENCY LIGHTING EQUIPMENT,https://lens.org/088-214-438-398-866,2022,"Described is an apparatus for the remote control of emergency lighting equipment (12, L1, L2, . . . , LN), comprising a smartphone or tablet (11), equipped with a flash designed to send optical commands in the form of coded luminous messages, and a control, programming and storage system, managed by an APR (14), designed to modulate the switching ON and OFF of the flash of the smartphone or tablet (11) for sending coded luminous messages, and at least one lighting appliance or emergency lamp (12, L1, L2, . . . , LN). The emergency lamp (12, L1, L2 . . . , LN) is able to receive the optical commands in order to carry out operational and/or configuration mode tests both during installation and for a predetermined period of time starting from the moment in which the electrical power supply is restored to the lamp after being removed for a defined period of time."
METHOD AND APPARATUS FOR HANDOVER,https://lens.org/079-417-914-292-573,2022,An apparatus which can cause control information to be sent from a source base station to a target base station via a user plane.
Robotic system for SPECT imaging,https://lens.org/194-148-894-853-324,2018,"A robotic arm, movable in three rotational degrees of freedom has a base end and a distal end supporting SPECT imaging detectors. A patient support assembly is movable in a linear degree of freedom. A controller causes the robotic arm to move the SPECT imaging detectors, in three dimensions, around the patient's body to obtain SPECT images. The control causes the patient support assembly to move along the linear degree of freedom, maintaining alignment of the patient's body with the SPECT imaging detectors."
ROBOTIC SYSTEM FOR SPECT IMAGING,https://lens.org/114-180-202-453-329,2016,"A robotic arm, movable in three rotational degrees of freedom has a base end and a distal end supporting SPECT imaging detectors. A patient support assembly is movable in a linear degree of freedom. A controller causes the robotic arm to move the SPECT imaging detectors, in three dimensions, around the patient's body to obtain SPECT images. The control causes the patient support assembly to move along the linear degree of freedom, maintaining alignment of the patient's body with the SPECT imaging detectors."
"AUTONOMOUS VEHICLE, PASSENGER VEHICLE, AND VEHICLE TRANSFER SYSTEM",https://lens.org/159-524-808-329-911,2022,"An autonomous vehicle allows passengers to transfer from a passenger vehicle, which is a relatively large vehicle, to the autonomous vehicle. The autonomous vehicle is provided with an autonomous travel control unit (steering control unit) configured to, when the passenger vehicle is stopped, cause the autonomous vehicle to pull up alongside the passenger vehicle such that an entrance (second entrance) of the autonomous vehicle is placed next to an entrance (first entrance) of the passenger vehicle."
"AUTONOMOUS VEHICLE, PASSENGER VEHICLE, AND VEHICLE TRANSFER SYSTEM",https://lens.org/159-524-808-329-911,2022,"An autonomous vehicle allows passengers to transfer from a passenger vehicle, which is a relatively large vehicle, to the autonomous vehicle. The autonomous vehicle is provided with an autonomous travel control unit (steering control unit) configured to, when the passenger vehicle is stopped, cause the autonomous vehicle to pull up alongside the passenger vehicle such that an entrance (second entrance) of the autonomous vehicle is placed next to an entrance (first entrance) of the passenger vehicle."
Remotely positionable light,https://lens.org/041-633-144-998-269,2012,"A work light assembly remotely positionable by means of a radio frequency transmitter signaling a motion controller driving a linear actuator. The light source is mounted on a pivoting boom that is in turn mounted to an upright post that telescopes up or down by means of manual controls interfaced with the controller, or by way of an RF transmitter commanding the controller. Motive properties such as maximum telescoping travel speed are preset at the controller."
Remote control transmitting device of robot,https://lens.org/078-616-849-548-151,1995,"A remote control transmitting device for a robot includes a secret number switching unit for inputting user's secret numbers; a function selecting switch for allowing the user to select a robotic function; a high level & open signal transmitting circuit for outputting voltage signals representing various robotic functions, respectively; an operation command switching unit for receiving operation commands from the user such as release, warning sound, scouting, left, forward and right; a low and enable signal transmitting circuit for outputting a low signal and an enable signal after receipt of the user's operation command signal outputted from the operation command switching unit; and an encoder for outputting encoded signals in accordance with the low & enable signal transmitting circuit, the secret number switching unit and the high level & open signal transmitting circuit."
Aircraft,https://lens.org/117-039-659-539-911,2013,"An unmanned aerial vehicle (UAV) in the form of a ""tail sitter"" flying wing adapted for vertical take off and landing and transitions between flight as a helicopter and wing-borne flight. The vehicle is electrically powered from onboard batteries and equipped with rotors on miniature helicopter rotor heads at the tips of the wing for both lift, during take off and landing, and forward thrust. In planform the wing comprises, to each side of its longitudinal axis, an inner section with swept back leading and trailing edges, and an outer section with a leading edge more perpendicular to the longitudinal axis, being only mildly swept back or substantially unswept, and a swept forward trailing edge."
Robotic retrieval apparatus,https://lens.org/017-300-175-754-173,2006,"A robotic device and method of use for fetching an object, the method including driving the device until a docking signal is acquired and then toward the docking signal to dock with a docking element of a door of a storage cabinet or refrigerator, and then driving the device away from the door so as to open it and then rotating the device about the docking element to place a vertically extended pincer clamp of the device around a target object positioned at a specified location within the door, followed by closing the pincer clamp so as to grip the target object and rotating the device about the docking element while carrying the target object so as to close the door. The object is then carried by the device to a specified programmed location to deliver the object."
RADIO FREQUENCY CONTROLLED AIRCRAFT,https://lens.org/042-044-224-992-271,2013,"A radio-controlled model airplane, including: a fuselage; first and second wings connected to the fuselage; and a control system including: a battery; a receiver powered by the battery and arranged to receive radio frequency signals; and a computer powered by the battery, electrically connected to the receiver, and arranged to transmit control signals in response to the received radio frequency signals. The airplane also includes a first motor powered by the battery and arranged to receive the transmitted control signals to rotate a propeller; and a single flexible wire: passing through an opening in a distal end of the first wing; with a first end fixed to a point at or near a junction of the first wing and the fuselage; and with a second end for connection to a point outside of the model airplane."
Radio frequency controlled aircraft,https://lens.org/045-405-323-914-981,2014,"A radio-controlled model airplane, including: a fuselage; first and second wings connected to the fuselage; and a control system including: a battery; a receiver powered by the battery and arranged to receive radio frequency signals; and a computer powered by the battery, electrically connected to the receiver, and arranged to transmit control signals in response to the received radio frequency signals. The airplane also includes a first motor powered by the battery and arranged to receive the transmitted control signals to rotate a propeller; and a single flexible wire: passing through an opening in a distal end of the first wing; with a first end fixed to a point at or near a junction of the first wing and the fuselage; and with a second end for connection to a point outside of the model airplane."
"Radio controlled aircraft, remote controller and methods for use therewith",https://lens.org/092-574-107-209-403,2022,A radio controlled (RC) vehicle includes a receiver configured to receive a radio frequency (RF) signal from a remote control device. The RF signal indicates command data in accordance with a first coordinate system. The command data includes yaw-velocity command data. The RC vehicle includes motion sensors configured to generate motion data. The RC vehicle includes a processor coupled to the motion sensors and to the receiver. The processor is configured to transform the command data into control data based on the motion data and in accordance with a second coordinate system from a perspective of the RC vehicle. The control data includes yaw-velocity control data. The yaw-velocity control data is related to the yaw-velocity command data. The RC vehicle includes control devices coupled to the processor and configured to control motion of the RC vehicle based on the control data.
"RADIO CONTROLLED AIRCRAFT, REMOTE CONTROLLER AND METHODS FOR USE THEREWITH",https://lens.org/151-684-385-235-500,2019,A radio controlled (RC) vehicle includes a receiver configured to receive a radio frequency (RF) signal from a remote control device. The RF signal indicates command data in accordance with a first coordinate system. The command data includes yaw-velocity command data. The RC vehicle includes motion sensors configured to generate motion data. The RC vehicle includes a processor coupled to the motion sensors and to the receiver. The processor is configured to transform the command data into control data based on the motion data and in accordance with a second coordinate system from a perspective of the RC vehicle. The control data includes yaw-velocity control data. The yaw-velocity control data is related to the yaw-velocity command data. The RC vehicle includes control devices coupled to the processor and configured to control motion of the RC vehicle based on the control data.
"PIPE INSPECTION DEVICES AND SYSTEMS, AND METHODS OF USING SAME",https://lens.org/173-258-028-613-346,2022,An unmanned vehicle can comprise a vehicle body configured to be at least partially submerged within liquid inside a conduit. At least one propeller can be coupled to the vehicle body. An actuator can be configured to effect movement of the at least one propeller to control motion of the unmanned vehicle within the liquid inside the conduit. A testing probe can be coupled to the vehicle body. The testing probe can optionally be an ultrasonic or microwave testing probe. An acoustic emission probe can be coupled to the vehicle body. A camera can be coupled to the vehicle body.
"PIPE INSPECTION DEVICES AND SYSTEMS, AND METHODS OF USING SAME",https://lens.org/173-258-028-613-346,2022,An unmanned vehicle can comprise a vehicle body configured to be at least partially submerged within liquid inside a conduit. At least one propeller can be coupled to the vehicle body. An actuator can be configured to effect movement of the at least one propeller to control motion of the unmanned vehicle within the liquid inside the conduit. A testing probe can be coupled to the vehicle body. The testing probe can optionally be an ultrasonic or microwave testing probe. An acoustic emission probe can be coupled to the vehicle body. A camera can be coupled to the vehicle body.
SYSTEMS AND METHODS FOR CONTROLLING AN AUTONOMOUS VEHICLE,https://lens.org/138-758-133-042-073,2022,"Systems and methods for controlling an autonomous vehicle are disclosed herein. One embodiment determines a reference path for the autonomous vehicle along a roadway segment and steers the autonomous vehicle along a path that includes controlled back and forth lateral deviations from the reference path along the roadway segment to provide feedback to an occupant of the autonomous vehicle, the feedback indicating to the occupant that the autonomous vehicle is in an autonomous driving mode and that the autonomous driving mode is operating correctly."
SYSTEMS AND METHODS FOR CONTROLLING AN AUTONOMOUS VEHICLE,https://lens.org/138-758-133-042-073,2022,"Systems and methods for controlling an autonomous vehicle are disclosed herein. One embodiment determines a reference path for the autonomous vehicle along a roadway segment and steers the autonomous vehicle along a path that includes controlled back and forth lateral deviations from the reference path along the roadway segment to provide feedback to an occupant of the autonomous vehicle, the feedback indicating to the occupant that the autonomous vehicle is in an autonomous driving mode and that the autonomous driving mode is operating correctly."
KEYWORD DETECTION USING MOTION SENSING,https://lens.org/067-666-594-555-435,2023,"Systems and processes for operating an intelligent automated assistant are provided. In one embodiment, data is received from a motion sensor, for instance, recording the motion of a user as the user utters a spoken input. A determination is made whether a portion of the motion data matches reference data for a set of one or more words (e.g., a word or phrase). If so, a task associated with the one or more words is initiated in response."
KEYWORD DETECTION USING MOTION SENSING,https://lens.org/047-939-935-921-372,2023,"Systems and processes for operating an intelligent automated assistant are provided. In one embodiment, data is received from a motion sensor, for instance, recording the motion of a user as the user utters a spoken input. A determination is made whether a portion of the motion data matches reference data for a set of one or more words (e.g., a word or phrase). If so, a task associated with the one or more words is initiated in response."
AUTONOMOUS VEHICLE AND AUTHENTICATION AGENCY METHOD THEREOF,https://lens.org/064-378-058-116-118,2022,"Disclosed are an autonomous vehicle and an authentication agency method thereof. The autonomous vehicle includes: a controller that outputs a location and a route of the vehicle when an event requiring authentication of a passenger occurs; and an authentication system that sets a preliminary zone on the basis of the location and the route of the vehicle input from the controller, attempts direct authentication of the passenger in the preliminary zone, and performs authentication on the basis of data stored in advance or data received through a network after arriving at an authentication zone outside the vehicle when direct authentication of the passenger is failed, One or more of an autonomous vehicle, an AI device, and an external device may be associated with an artificial intelligence module, a drone ((Unmanned Aerial Vehicle, UAV), a robot, an AR (Augmented Reality) device, a VR (Virtual Reality) device, a device associated with 5G services, etc."
AUTONOMOUS VEHICLE AND AUTHENTICATION AGENCY METHOD THEREOF,https://lens.org/064-378-058-116-118,2022,"Disclosed are an autonomous vehicle and an authentication agency method thereof. The autonomous vehicle includes: a controller that outputs a location and a route of the vehicle when an event requiring authentication of a passenger occurs; and an authentication system that sets a preliminary zone on the basis of the location and the route of the vehicle input from the controller, attempts direct authentication of the passenger in the preliminary zone, and performs authentication on the basis of data stored in advance or data received through a network after arriving at an authentication zone outside the vehicle when direct authentication of the passenger is failed, One or more of an autonomous vehicle, an AI device, and an external device may be associated with an artificial intelligence module, a drone ((Unmanned Aerial Vehicle, UAV), a robot, an AR (Augmented Reality) device, a VR (Virtual Reality) device, a device associated with 5G services, etc."
CRANE,https://lens.org/066-373-233-369-930,2018,"A crane including a crane arm with a crane tip and an implement arrangeable on the crane tip. The at least one part of the implement is movable in relation to the crane tip. A crane controller controls the crane arm and the at least one part of the implement. The crane controller can issue control commands by a user for movement of the crane arm and for movement of the at least one part of the implement. With an implement on the crane tip, when predetermined control commands are issued by a user for movement of the at least one part of the implement arranged on the crane tip, additional control commands for movement of the at least one crane arm can be given off by the crane controller to at least partially compensate for the movement of the at least one part of the implement."
UNIVERSAL VIRTUAL REMOTE CONTROL FOR SMART DEVICES,https://lens.org/158-625-950-548-740,2022,"A universal virtual device remote control is implemented on a computerized device such as a smart phone. The remote control operates by receiving one or more pictures of a target device, and identifying the target device by comparing the one or more pictures to pictures in a data set. The remote control also receives functional data associated with the identified device from the data set, and presents controls for the physical device to a user based on the received functional data. An input is received from the user in association with one or more of the controls, and a command associated with the input is sent to the identified device based on the functional data associated with the identified device."
UNIVERSAL VIRTUAL REMOTE CONTROL FOR SMART DEVICES,https://lens.org/158-625-950-548-740,2022,"A universal virtual device remote control is implemented on a computerized device such as a smart phone. The remote control operates by receiving one or more pictures of a target device, and identifying the target device by comparing the one or more pictures to pictures in a data set. The remote control also receives functional data associated with the identified device from the data set, and presents controls for the physical device to a user based on the received functional data. An input is received from the user in association with one or more of the controls, and a command associated with the input is sent to the identified device based on the functional data associated with the identified device."
Method of landing of a surveillance unmanned aerial vehicle and and a surveillance unmanned aerial vehicle,https://lens.org/127-307-851-534-337,2014,"The mode of landing of an unmanned aerial vehicle driven by an electric engine, containing main power supply batteries, control systems of the surveillance head, transmitting and receiving systems, a flight control system, and a container (4) equipped with a surveillance head (1) with a looking down lens (9), placed in a recess (2) situated in the lower part of the fuselage (3) by which the vehicle is lightened at the last stage of flight shortly before landing, which means the container (4) placed in the recess (2) is detached, then moved outside the vehicle's body (3) and descended by means of a parachute (5) into a desired location, and the lightened vehicle lands in some other place. The recess (2) in the fuselage (3) contains an electrically controlled lock (8) which fixes detachably the container (4) equipped with at least one parachute (5) placed at the bottom section of the container (4), on the side of the surveillance head (1)."
DYNAMIC OPERATION OF A VOICE CONTROLLED DEVICE,https://lens.org/130-445-230-848-37X,2023,"A voice-controlled device is operated in a location. When a mobile device enters the location, audio outputted by the mobile device is stored. If a voice command is received at the voice-controlled device, the stored audio outputted by the mobile device is accessed. If it is determined that the voice command originated from the mobile device, then the received voice command is ignored."
DYNAMIC OPERATION OF A VOICE CONTROLLED DEVICE,https://lens.org/127-627-755-287-076,2023,"A voice-controlled device is operated in a location. When a mobile device enters the location, audio outputted by the mobile device is stored. If a voice command is received at the voice-controlled device, the stored audio outputted by the mobile device is accessed. If it is determined that the voice command originated from the mobile device, then the received voice command is ignored."
DYNAMIC OPERATION OF A VOICE CONTROLLED DEVICE,https://lens.org/127-627-755-287-076,2023,"A voice-controlled device is operated in a location. When a mobile device enters the location, audio outputted by the mobile device is stored. If a voice command is received at the voice-controlled device, the stored audio outputted by the mobile device is accessed. If it is determined that the voice command originated from the mobile device, then the received voice command is ignored."
DYNAMIC OPERATION OF A VOICE CONTROLLED DEVICE,https://lens.org/130-445-230-848-37X,2023,"A voice-controlled device is operated in a location. When a mobile device enters the location, audio outputted by the mobile device is stored. If a voice command is received at the voice-controlled device, the stored audio outputted by the mobile device is accessed. If it is determined that the voice command originated from the mobile device, then the received voice command is ignored."
MULTIROTOR GAME SYSTEM,https://lens.org/136-086-668-862-893,2018,A system enabling remote-controlled piloting of multirotors with first-person-video to play games. Each multirotor has a transmission system and a detection system. The transmission system acts as a gun that transmits an electromagnetic radiation signal and the detection system acts as a shot detector by detecting the electromagnetic radiation signal. Game information can be processed and overlaid on the first person video provided to the player piloting the multirotor. Each multirotor may include a lighting system and a LASER to provide visual cues to other players and observers. Some embodiments utilize flag devices in a capture-the-flag game mode.
"Information processing device, information processing device control method, and program",https://lens.org/124-679-555-315-867,2022,"Provided is technology for making it possible to remotely control a laser device using a general-purpose mobile terminal such as a smartphone. This information processing device (2) comprises a control unit (27), a display unit (22), an operation unit (23), and a short-range wireless communication unit (26) capable of communicating with a laser device that detects a horizontal direction and emits laser light at a set inclination. The control unit (27) comprises a control function unit (272) for achieving a remote control function for remotely controlling the laser device via the short-range wireless communication unit (26). The control function unit (272) acquires, via the short-range wireless communication unit (26), status information indicating the operation state of the laser device. The control function unit (272) displays, on an initial control screen for remote control, a pictogram that corresponds to the status information and indicates the state of the laser device, and an icon for invoking the remote control function."
"Information processing device, information processing device control method, and program",https://lens.org/124-679-555-315-867,2022,"Provided is technology for making it possible to remotely control a laser device using a general-purpose mobile terminal such as a smartphone. This information processing device (2) comprises a control unit (27), a display unit (22), an operation unit (23), and a short-range wireless communication unit (26) capable of communicating with a laser device that detects a horizontal direction and emits laser light at a set inclination. The control unit (27) comprises a control function unit (272) for achieving a remote control function for remotely controlling the laser device via the short-range wireless communication unit (26). The control function unit (272) acquires, via the short-range wireless communication unit (26), status information indicating the operation state of the laser device. The control function unit (272) displays, on an initial control screen for remote control, a pictogram that corresponds to the status information and indicates the state of the laser device, and an icon for invoking the remote control function."
Sonotube Deployable Multicopter,https://lens.org/102-276-641-762-028,2017,"An unmanned aerial system (UAS) including a sonotube deployable multicopter (SDM) having a plurality of rotors for propulsion, a plurality of extension arms, and a central pivot device. Each extension arm supports at least one of the plurality of rotors. The central pivot device supports the plurality of extension arms radially extending from the central pivot device. Pivotal movement of a first arm-support structure of the central pivot device relative to a second arm-support structure of the central pivot device rotates a first pair of the plurality of extension arms in unison relative to a second pair of the plurality of extension arms. The pivotal movement is biased to rotate the plurality of extension arms from a compact configuration to an expanded configuration while the UAS is airborne. The SDM configured to be held inside a sonoshell in the compact configuration."
Sonotube Deployable Multicopter,https://lens.org/102-276-641-762-028,2017,"An unmanned aerial system (UAS) including a sonotube deployable multicopter (SDM) having a plurality of rotors for propulsion, a plurality of extension arms, and a central pivot device. Each extension arm supports at least one of the plurality of rotors. The central pivot device supports the plurality of extension arms radially extending from the central pivot device. Pivotal movement of a first arm-support structure of the central pivot device relative to a second arm-support structure of the central pivot device rotates a first pair of the plurality of extension arms in unison relative to a second pair of the plurality of extension arms. The pivotal movement is biased to rotate the plurality of extension arms from a compact configuration to an expanded configuration while the UAS is airborne. The SDM configured to be held inside a sonoshell in the compact configuration."
Sonotube deployable multicopter,https://lens.org/060-746-892-961-63X,2018,"An unmanned aerial system (UAS) including a sonotube deployable multicopter (SDM) having a plurality of rotors for propulsion, a plurality of extension arms, and a central pivot device. Each extension arm supports at least one of the plurality of rotors. The central pivot device supports the plurality of extension arms radially extending from the central pivot device. Pivotal movement of a first arm-support structure of the central pivot device relative to a second arm-support structure of the central pivot device rotates a first pair of the plurality of extension arms in unison relative to a second pair of the plurality of extension arms. The pivotal movement is biased to rotate the plurality of extension arms from a compact configuration to an expanded configuration while the UAS is airborne. The SDM configured to be held inside a sonoshell in the compact configuration."
Voice Control System for Recreational Vehicles,https://lens.org/082-363-378-464-120,2023,"A voice control system for recreational vehicles controls safe operation of deployable components of the RV, such as an antenna, awning or room extension. A voice recognition system is employed to interpret voice commands and control operation of the deployable components in response. A control system monitors the status of the RV and its components to detect unsafe conditions relating to operation of the deployable components. For example, this can be done via a wired or wireless network of sensors detecting the state of the RV and its deployable components. The control system can also monitor the status of the RV via the data bus built into the RV. If an unsafe condition is detected, the safety manager of the control system triggers a warning or activates a predetermined interlock to prevent unsafe operation of the RV and its deployable components."
END-TO-END UNMANNED CONTROL SYSTEM OF AIRCRAFT NAVIGATION AND SURVEILLANCE SYSTEMS,https://lens.org/108-839-707-518-314,2022,A control system in communication with one of an aircraft navigational aid system and an aircraft surveillance system is described. The control system obtains measurement data associated with radio frequency (RF) signals transmitted by the one of the aircraft navigational aid system and the aircraft surveillance system from an unmanned aerial vehicle (UAV) reporting the measurement data. The control system also determines whether the measurement data indicates the RF signals are within a range of values based on a location of the UAV in an airspace proximate to the one of the aircraft navigational aid system and the aircraft surveillance system. The control system further controls the RF signals transmitted by the one of the aircraft navigational aid system and the aircraft surveillance system based on the measurement data and the location of the UAV. Methods performed by the control system are also described.
END-TO-END UNMANNED CONTROL SYSTEM OF AIRCRAFT NAVIGATION AND SURVEILLANCE SYSTEMS,https://lens.org/108-839-707-518-314,2022,A control system in communication with one of an aircraft navigational aid system and an aircraft surveillance system is described. The control system obtains measurement data associated with radio frequency (RF) signals transmitted by the one of the aircraft navigational aid system and the aircraft surveillance system from an unmanned aerial vehicle (UAV) reporting the measurement data. The control system also determines whether the measurement data indicates the RF signals are within a range of values based on a location of the UAV in an airspace proximate to the one of the aircraft navigational aid system and the aircraft surveillance system. The control system further controls the RF signals transmitted by the one of the aircraft navigational aid system and the aircraft surveillance system based on the measurement data and the location of the UAV. Methods performed by the control system are also described.
END-TO-END UNMANNED CONTROL SYSTEM OF AIRCRAFT NAVIGATION AND SURVEILLANCE SYSTEMS,https://lens.org/108-839-707-518-314,2022,A control system in communication with one of an aircraft navigational aid system and an aircraft surveillance system is described. The control system obtains measurement data associated with radio frequency (RF) signals transmitted by the one of the aircraft navigational aid system and the aircraft surveillance system from an unmanned aerial vehicle (UAV) reporting the measurement data. The control system also determines whether the measurement data indicates the RF signals are within a range of values based on a location of the UAV in an airspace proximate to the one of the aircraft navigational aid system and the aircraft surveillance system. The control system further controls the RF signals transmitted by the one of the aircraft navigational aid system and the aircraft surveillance system based on the measurement data and the location of the UAV. Methods performed by the control system are also described.
AUTONOMOUS DRIVING DEVICE,https://lens.org/148-111-462-554-737,2020,"An autonomous driving device includes a navigation device configured to search a plurality of routes, from a diverging point to a target position, for one or more extra routes other than a recommended route before a vehicle passes the diverging point wherein the diverging point is a point where the vehicle is expected to pass; and an electronic control unit configured to control autonomous driving of the vehicle based on information on a particular extra route when the vehicle departs from the recommended route at the diverging point and travels on the particular extra route wherein the particular extra route is one of the one or more extra routes."
Autonomous driving device,https://lens.org/102-968-579-111-87X,2022,"An autonomous driving device includes a navigation device configured to search a plurality of routes, from a diverging point to a target position, for one or more extra routes other than a recommended route before a vehicle passes the diverging point wherein the diverging point is a point where the vehicle is expected to pass; and an electronic control unit configured to control autonomous driving of the vehicle based on information on a particular extra route when the vehicle departs from the recommended route at the diverging point and travels on the particular extra route wherein the particular extra route is one of the one or more extra routes."
AUTONOMOUS DRIVING DEVICE,https://lens.org/148-111-462-554-737,2020,"An autonomous driving device includes a navigation device configured to search a plurality of routes, from a diverging point to a target position, for one or more extra routes other than a recommended route before a vehicle passes the diverging point wherein the diverging point is a point where the vehicle is expected to pass; and an electronic control unit configured to control autonomous driving of the vehicle based on information on a particular extra route when the vehicle departs from the recommended route at the diverging point and travels on the particular extra route wherein the particular extra route is one of the one or more extra routes."
WATERPROOF REMOTE CONTROL,https://lens.org/168-584-947-384-241,2008,"A waterproof remote controller. The waterproof remote controller includes a battery, a battery cover, a housing a translucent window, and a battery compartment, a circuit board, and a waterproof mask. An o-ring in a channel of the housing is compressed by the battery compartment cover to form a water-tight seal. A mask is adhered to the circuit board and to a ledge of the housing forming a water tight-seal. A light emitting diode transmits an infra-red signal to a remote device indicating a location on the mask that is pressed."
FIRST RESPONSE LOCATOR SYSTEM,https://lens.org/008-000-148-827-065,2018,"A first response locator system includes at least one emergency locator unit having a main body and a lighting unit for generating light in a plurality of different colors. Indicia is disposed along the main body, and a speaker for generating an audible sound is positioned along the main body. An internal controller controls the operation of the speaker and the lighting unit. A remote operation device communicates with the internal controller and includes a plurality of buttons for selectively activating one or both of the lighting unit and the speaker"
First response locator system,https://lens.org/066-642-454-455-472,2019,"A first response locator system includes at least one emergency locator unit having a main body and a lighting unit for generating light in a plurality of different colors. Indicia is disposed along the main body, and a speaker for generating an audible sound is positioned along the main body. An internal controller controls the operation of the speaker and the lighting unit. A remote operation device communicates with the internal controller and includes a plurality of buttons for selectively activating one or both of the lighting unit and the speaker"
Self leveling integrated lifting device,https://lens.org/026-781-225-250-376,2004,"This self-leveling device is employed in the field of lifting of aircraft, helicopters, civil and military flying vehicles, watercraft, camping vehicles, trains, bridges, radar, etc., and for all those activities that require self-leveling and centring during lifting and lowering operations with fast results, without damages to the structure and in perfect safety (eg.: for helicopter lifting, for internal load balance, for safery during take-off and landing). The device is composed of a number of electromechanical lifting groups (Fig.01) that operate synchronistically and autonomously from one another, linked with an electronic central general control (Fig.12) for operation and a leveling cell (Fig.05). The whole system provides perfect self-leveling in case of unstable ground, for weighing and leveling purposes, targeting, weight balance, maintenance, etc."
Instructing unmanned aerial vehicles to land,https://lens.org/183-938-807-166-356,2018,"In some examples, a system for instructing an unmanned aerial vehicle is provided. The system may include a delivery management service for processing orders for items available in connection with an electronic marketplace. The delivery management service may also determine a landing location for delivery of an item to a customer of the electronic marketplace. The landing location may correspond the customer's address. Determination of the landing location may be based on a first digital elevation dataset, a second digital elevation dataset, and parcel data corresponding to a region in which the customer's address is located. The unmanned aerial vehicle may access the landing location as part of delivering the item to the customer."
USING DRONE DATA TO GENERATE HIGH-DEFINITION MAP FOR AUTONOMOUS VEHICLE NAVIGATION,https://lens.org/014-648-016-652-16X,2021,"An autonomous vehicle navigates using a digital map stored in memory. In one approach, the vehicle plans a navigation route that includes a geographic location (e.g., a location on a road to be traveled by the vehicle). An unmanned aerial vehicle (UAV) collects sensor data at the geographic location (e.g., in advance of travel on the road). The collected sensor data is processed to generate map data for objects or other features at the geographic location. The digital map is updated using the generated map data."
EXTENDED REALITY DEVICE AND CONTROLLING METHOD THEREOF,https://lens.org/150-658-734-318-705,2019,"The present invention relates to a method of controlling an XR device, including generating location information of the XR device by a location sensor, generating direction information of the XR device by a direction sensor, and disposing an Augmented Reality (AR) object by a controller based on the location information and the direction information."
EXTENDED REALITY DEVICE AND CONTROLLING METHOD THEREOF,https://lens.org/037-298-394-739-534,2021,"The present invention relates to a method of controlling an XR device, including generating location information of the XR device by a location sensor, generating direction information of the XR device by a direction sensor, and disposing an Augmented Reality (AR) object by a controller based on the location information and the direction information."
Unmanned plane control handle,https://lens.org/172-348-363-015-418,2016,"The invention provides an unmanned plane control handle used for performing flight control on an unmanned plane, comprising a control panel and an intelligent device detachably adhered to the control panel. A supporting seat is detachably adhered on the control panel, and is provided with a silicone pad. The intelligent device is detachably clamped to the supporting seat, and is adhered on the silicone pad. The control panel is provided with control structural components used for flight control. The edge positions on two sides of the supporting seat are correspondingly provided with a pair of bumping posts, and two ends of the intelligent device are respectively clamped between the pair of bumping posts. The unmanned plane control handle is a portable miniaturization structure; the intelligent device is convenient to assemble and disassemble through the silicone pad, and can be carried independently after being dissembled; a holder is adhered through the silicon panel; modularization design facilitates decomposition and carrying."
Unmanned aerial vehicle management system,https://lens.org/095-858-269-257-380,2019,"An Unmanned Aerial System configured to receive a request from a user and fulfill that request using an Unmanned Aerial Vehicle. The Unmanned Aerial System selects a distribution center that is within range of the user, and deploys a suitable Unmanned Aerial Vehicle to fulfill the request from that distribution center. The Unmanned Aerial System is configured to provide real-time information about the flight route to the Unmanned Aerial Vehicle during its flight, and the Unmanned Aerial Vehicle is configured to dynamically update its mission based on information received from the Unmanned Aerial System."
Unmanned aerial vehicle management system,https://lens.org/026-620-169-965-432,2017,"An Unmanned Aerial System configured to receive a request from a user and fulfill that request using an Unmanned Aerial Vehicle. The Unmanned Aerial System selects a distribution center that is within range of the user, and deploys a suitable Unmanned Aerial Vehicle to fulfill the request from that distribution center. The Unmanned Aerial System is configured to provide real-time information about the flight route to the Unmanned Aerial Vehicle during its flight, and the Unmanned Aerial Vehicle is configured to dynamically update its mission based on information received from the Unmanned Aerial System."
Unmanned aerial vehicle management system,https://lens.org/153-203-027-305-866,2016,"An Unmanned Aerial System configured to receive a request from a user and fulfill that request using an Unmanned Aerial Vehicle. The Unmanned Aerial System selects a distribution center that is within range of the user, and deploys a suitable Unmanned Aerial Vehicle to fulfill the request from that distribution center. The Unmanned Aerial System is configured to provide real-time information about the flight route to the Unmanned Aerial Vehicle during its flight, and the Unmanned Aerial Vehicle is configured to dynamically update its mission based on information received from the Unmanned Aerial System."
UNMANNED AERIAL VEHICLE MANAGEMENT SYSTEM,https://lens.org/083-726-217-874-811,2016,"An Unmanned Aerial System configured to receive a request from a user and fulfill that request using an Unmanned Aerial Vehicle. The Unmanned Aerial System selects a distribution center that is within range of the user, and deploys a suitable Unmanned Aerial Vehicle to fulfill the request from that distribution center. The Unmanned Aerial System is configured to provide real-time information about the flight route to the Unmanned Aerial Vehicle during its flight, and the Unmanned Aerial Vehicle is configured to dynamically update its mission based on information received from the Unmanned Aerial System."
UNMANNED AERIAL VEHICLE MANAGEMENT SYSTEM,https://lens.org/175-235-512-411-907,2017,"An Unmanned Aerial System configured to receive a request from a user and fulfill that request using an Unmanned Aerial Vehicle. The Unmanned Aerial System selects a distribution center that is within range of the user, and deploys a suitable Unmanned Aerial Vehicle to fulfill the request from that distribution center. The Unmanned Aerial System is configured to provide real-time information about the flight route to the Unmanned Aerial Vehicle during its flight, and the Unmanned Aerial Vehicle is configured to dynamically update its mission based on information received from the Unmanned Aerial System."
UNMANNED AERIAL VEHICLE MANAGEMENT SYSTEM,https://lens.org/112-821-952-215-527,2021,"An Unmanned Aerial System configured to receive a request from a user and fulfill that request using an Unmanned Aerial Vehicle. The Unmanned Aerial System selects a distribution center that is within range of the user, and deploys a suitable Unmanned Aerial Vehicle to fulfill the request from that distribution center. The Unmanned Aerial System is configured to provide real-time information about the flight route to the Unmanned Aerial Vehicle during its flight, and the Unmanned Aerial Vehicle is configured to dynamically update its mission based on information received from the Unmanned Aerial System."
Unmanned aerial vehicle management system,https://lens.org/158-643-032-281-898,2021,"An Unmanned Aerial System configured to receive a request from a user and fulfill that request using an Unmanned Aerial Vehicle. The Unmanned Aerial System selects a distribution center that is within range of the user, and deploys a suitable Unmanned Aerial Vehicle to fulfill the request from that distribution center. The Unmanned Aerial System is configured to provide real-time information about the flight route to the Unmanned Aerial Vehicle during its flight, and the Unmanned Aerial Vehicle is configured to dynamically update its mission based on information received from the Unmanned Aerial System."
A robot and method for operating a robot,https://lens.org/037-882-359-200-237,2000,"A utility robot 20 is capable of operating in at least one autonomous mode and at least one manual mode. The utility robot 20 comprises a main body 27 configured for receiving a signal from a control device 30,30',130',141, a recognition system 42 for recognizing the signal and a controller 43 in communication with the recognition system 42, for changing an operative mode 44,45,46 of said utility robot 20, in accordance with the recognized signal. The combination of an autonomous mode and a manual mode being available in a robot can allow for operating in areas that are not accessible to a robot that operates only in an autonomous mode. <IMAGE>"
AUTOMATED ACCESS DEVICE INTERACTION PROCESSING,https://lens.org/118-002-219-170-943,2020,"A method is disclosed. The method includes forming a local data connection between a mobile communication device comprising a voice assistant module, and an access device in an interaction. The method also includes receiving, by the mobile communication device, a voice command with a request for the access device to automatically provide a resource to a user of the mobile communication device."
AUTOMATED ACCESS DEVICE INTERACTION PROCESSING,https://lens.org/027-576-470-488-170,2022,"A method is disclosed. The method includes forming a local data connection between a mobile communication device comprising a voice assistant module, and an access device in an interaction. The method also includes receiving, by the mobile communication device, a voice command with a request for the access device to automatically provide a resource to a user of the mobile communication device."
"Method for capturing a video, related computer program and electronic system for capturing a video",https://lens.org/171-198-710-078-521,2018,"The invention relates to a method for capturing a video using a camera on board a fixed-wing drone, the camera comprising an image sensor, the drone having, during flight, a drift angle between the longitudinal axis of the drone and a flight direction of the drone. This method comprises: determining the drift angle of the drone; and obtaining video by image acquisition corresponding to a zone with reduced dimensions relative to those of the image sensor, the position of the zone being determined as a function of the drift angle of the drone."
INDOOR DRONE NAVIGATION SUPPORT SYSTEM BASED ON MACHINE LEARNING,https://lens.org/001-547-296-846-49X,2020,The invention relates to systems for providing the positioning of an unmanned aerial vehicle in a setting that is closed to GPS access. The invention is a system and method for positioning unmanned aerial vehicles (100) (drone) in a setting (400). The subject setting (400) may be an indoor storage space with reference to Figure 1.
METHODS AND SYSTEM FOR TRANSPORTATION USING UNMANNED AERIAL VEHICLES,https://lens.org/055-708-906-964-447,2022,"An unmanned aerial vehicle (UAV) station, comprising: a landing platform; a payload receiving structure configured to receive payloads from and attach payloads to a UAV positioned on the landing platform; a plurality of optical sensors configured to monitor and scan airspace proximate the landing platform for obstacles; and a communication interface configured to issue instructions authorizing takeoff and landing operations of the UAV based on sensor readings generated by the plurality of optical sensors."
METHODS AND SYSTEM FOR TRANSPORTATION USING UNMANNED AERIAL VEHICLES,https://lens.org/055-708-906-964-447,2022,"An unmanned aerial vehicle (UAV) station, comprising: a landing platform; a payload receiving structure configured to receive payloads from and attach payloads to a UAV positioned on the landing platform; a plurality of optical sensors configured to monitor and scan airspace proximate the landing platform for obstacles; and a communication interface configured to issue instructions authorizing takeoff and landing operations of the UAV based on sensor readings generated by the plurality of optical sensors."
METHODS AND SYSTEM FOR TRANSPORTATION USING UNMANNED AERIAL VEHICLES,https://lens.org/157-372-854-999-817,2022,"An unmanned aerial vehicle (UAV) station, comprising: a landing platform; a payload receiving structure configured to receive payloads from and attach payloads to a UAV positioned on the landing platform; a plurality of optical sensors configured to monitor and scan airspace proximate the landing platform for obstacles; and a communication interface configured to issue instructions authorizing takeoff and landing operations of the UAV based on sensor readings generated by the plurality of optical sensors."
Drone-based event reconstruction,https://lens.org/006-640-655-165-556,2020,"A method is disclosed for providing drone oversight at a location having high potential for a collision event. The method may include recruiting one or more drones to provide oversight at a location having high potential for a collision event, and dispatching the drones to the location. One or more servers may request from the drones buffers of sensory data corresponding to the location. In response, the servers may receive from the drones the buffers of sensory data. A corresponding system and computer program product are also disclosed and claimed herein."
Drone-based event reconstruction,https://lens.org/117-703-267-074-468,2020,"A method is disclosed for providing drone oversight at a location having high potential for a collision event. The method may include recruiting one or more drones to provide oversight at a location having high potential for a collision event, and dispatching the drones to the location. One or more servers may request from the drones buffers of sensory data corresponding to the location. In response, the servers may receive from the drones the buffers of sensory data. A corresponding system and computer program product are also disclosed and claimed herein."
TARGET TRACKING METHOD AND APPARATUS AND UNMANNED AERIAL VEHICLE,https://lens.org/044-026-205-646-254,2022,"The embodiment is a target tracking method. The method is applicable to a UAV including a visible light camera and an infrared camera, and includes: controlling the visible light camera to perform visual tracking on a target object, and recording first tracking information of the target object in real time; controlling the infrared camera to perform infrared tracking on the target object, and recording second tracking information of the target object in real time; controlling, in a case of determining that the target object is lost in the visible light camera, the visible light camera to re-lock the target object according to the second tracking information and continue to perform visual tracking; or controlling, in a case of determining that the target object is lost in the infrared camera, the infrared camera to re-lock the target object according to the first tracking information and continue to perform infrared tracking."
TARGET TRACKING METHOD AND APPARATUS AND UNMANNED AERIAL VEHICLE,https://lens.org/044-026-205-646-254,2022,"The embodiment is a target tracking method. The method is applicable to a UAV including a visible light camera and an infrared camera, and includes: controlling the visible light camera to perform visual tracking on a target object, and recording first tracking information of the target object in real time; controlling the infrared camera to perform infrared tracking on the target object, and recording second tracking information of the target object in real time; controlling, in a case of determining that the target object is lost in the visible light camera, the visible light camera to re-lock the target object according to the second tracking information and continue to perform visual tracking; or controlling, in a case of determining that the target object is lost in the infrared camera, the infrared camera to re-lock the target object according to the first tracking information and continue to perform infrared tracking."
A SYSTEM AND METHOD FOR MANAGING AND ANALYZING MULTIMEDIA INFORMATION,https://lens.org/127-154-517-651-832,2023,"A UAV data processing and management system is provided including an encoder broadcaster and data manager which provides end users with a single interface for searching and sharing any video or imagery source, from any device with no client software required. Data inputs to the resource can include UAV video, photos, traffic cameras, fixed surveillance systems, iOS and Android device pictures, and other data (e.g., texts, emails) and inputs from all forms of social media, such as Twitter, Instagram, Facebook, etc. The cloud based manager is built with collaboration and sharing in mind while at the same time maintaining data privacy, security protection, chain-of-custody control and audit trail maintenance. Analytic tools are integrated accordingly as ""plug-ins"" or as a store of available app resources which are easily removed, added and customized based on user needs and system requirements and cost constraints."
A SYSTEM AND METHOD FOR MANAGING AND ANALYZING MULTIMEDIA INFORMATION,https://lens.org/127-154-517-651-832,2023,"A UAV data processing and management system is provided including an encoder broadcaster and data manager which provides end users with a single interface for searching and sharing any video or imagery source, from any device with no client software required. Data inputs to the resource can include UAV video, photos, traffic cameras, fixed surveillance systems, iOS and Android device pictures, and other data (e.g., texts, emails) and inputs from all forms of social media, such as Twitter, Instagram, Facebook, etc. The cloud based manager is built with collaboration and sharing in mind while at the same time maintaining data privacy, security protection, chain-of-custody control and audit trail maintenance. Analytic tools are integrated accordingly as ""plug-ins"" or as a store of available app resources which are easily removed, added and customized based on user needs and system requirements and cost constraints."
Automated drone package receiver module,https://lens.org/076-700-483-685-993,2016,"A structure preferably over 3m high that can securely receive packages delivered by an Unmanned Aerial Vehicle. The structure will detect the drone when it is hovering above the module by way of audio detection means or by way of a signal sent by the UAV. Upon detecting the UAV, doors in the top of the structure will open, allowing the UAV to deposit the package within the structure. The doors will then close and the package will be lowered internally by way of a lift to the base of the structure where it can be kept securely until retrieved. The structure may have solar panels. The package receiving area may be surrounded by netting to minimise the risk an imprecise delivery."
Control devices for controlling the position of a marine seismic streamer,https://lens.org/181-908-126-508-103,2003,"A control device or ""bird"" for controlling the position of a marine seismic streamer is provided with an elongate, partly flexible body which is designed to be electrically and mechanically connected in series with a streamer. In its preferred form, the bird has two opposed wings which are independently controllable in order to control the streamer's lateral position as well as its depth."
Control devices for controlling the position of a marine seismic streamer,https://lens.org/032-781-201-331-785,2005,"A control device or ""bird"" for controlling the position of a marine seismic streamer is provided with an elongate, partly flexible body which is designed to be electrically and mechanically connected in series with a streamer. In its preferred form, the bird has two opposed wings which are independently controllable in order to control the streamer's lateral position as well as its depth."
Control devices for controlling the position of a marine seismic streamer,https://lens.org/167-491-854-905-678,2005,"A control device or ""bird"" for controlling the position of a marine seismic streamer is provided with an elongate, partly flexible body which is designed to be electrically and mechanically connected in series with a streamer. In its preferred form, the bird has two opposed wings which are independently controllable in order to control the streamer's lateral position as well as its depth."
Control Devices for Controlling the Position of a Marine Seismic Streamer,https://lens.org/048-765-080-743-636,2009,"A control device or ""bird"" for controlling the position of a marine seismic streamer is provided with an elongate, partly flexible body which is designed to be electrically and mechanically connected in series with a streamer. In its preferred form, the bird has two opposed wings which are independently controllable in order to control the streamer's lateral position as well as its depth."
Control devices for controlling the position of a marine seismic streamer,https://lens.org/003-806-430-730-380,2002,"A control device or ""bird"" for controlling the position of a marine seismic streamer is provided with an elongate, partly flexible body which is designed to be electrically and mechanically connected in series with a streamer. In its preferred form, the bird has two opposed wings which are independently controllable in order to control the streamer's lateral position as well as its depth."
SYSTEMS AND METHODS FOR AUTONOMOUS VEHICLES,https://lens.org/105-336-241-475-442,2019,"An autonomous vehicle configured to facilitate its use and/or enhance what it and/or occupants can do with it, such as, for example, by: autonomously acting based on events within the autonomous vehicle, including by autonomously rerouting itself, altering a cabin of the autonomous vehicle, notifying a third party external to the autonomous vehicle, stopping (e.g., parking) the autonomous vehicle, altering how the autonomous vehicle drives itself, and/or performing other actions based on what and/or how an occupant is doing, an emergency, or another event occurring in the cabin of the autonomous vehicle; autonomously acting based on interactions with (e.g., gestures of) humans (e.g., police officers, school-crossing guards, traffic guards at roadwork or other temporary traffic control sites, drivers of other vehicles, etc.) external to the autonomous vehicle; autonomously acting based on indicators placed at particular locations (e.g., drive-through establishments, potholes, parking spots, etc.); facilitating acts of occupants in the cabin of the autonomous vehicle, such as acts unrelated to and normally not done while driving, including, for example, sleeping, exercising, working, eating, cooking, and/or any other suitable act; and/or automatically personalizing the autonomous vehicle for an occupant (e.g., a configuration of the cabin, a self-driving mode, a destination and/or a route, etc.)."
SYSTEMS AND METHODS FOR AUTONOMOUS VEHICLES,https://lens.org/081-127-586-914-797,2023,"An autonomous vehicle configured to facilitate its use and/or enhance what it and/or occupants can do with it, such as, for example, by: autonomously acting based on events within the autonomous vehicle, including by autonomously rerouting itself, altering a cabin of the autonomous vehicle, notifying a third party external to the autonomous vehicle, stopping (e.g., parking) the autonomous vehicle, altering how the autonomous vehicle drives itself, and/or performing other actions based on what and/or how an occupant is doing, an emergency, or another event occurring in the cabin of the autonomous vehicle; autonomously acting based on interactions with (e.g., gestures of) humans (e.g., police officers, school-crossing guards, traffic guards at roadwork or other temporary traffic control sites, drivers of other vehicles, etc.) external to the autonomous vehicle; autonomously acting based on indicators placed at particular locations (e.g., drive-through establishments, potholes, parking spots, etc.); facilitating acts of occupants in the cabin of the autonomous vehicle, such as acts unrelated to and normally not done while driving, including, for example, sleeping, exercising, working, eating, cooking, and/or any other suitable act; and/or automatically personalizing the autonomous vehicle for an occupant (e.g., a configuration of the cabin, a self-driving mode, a destination and/or a route, etc.)."
Foldable remote controller,https://lens.org/114-501-075-423-702,2008,"A foldable remote controller is provided to remotely control a multimedia network device, transmit signals to the multimedia network device, and transmit or receive audio signals between the foldable remote controller and the multimedia network device, so as to communicate on the internet."
Foldable remote controller,https://lens.org/144-130-327-687-412,2009,"A foldable remote controller is provided to remotely control a multimedia network device, transmit signals to the multimedia network device, and transmit or receive audio signals between the foldable remote controller and the multimedia network device, so as to communicate on the internet."
Maintaining network connectivity of aerial devices during unmanned flight,https://lens.org/079-390-694-638-124,2021,"Example methods, apparatus, systems, and articles of manufacture (e.g., physical storage media) to facilitate maintaining network connectivity of aerial devices during unmanned flight are disclosed. An example method may include providing, to an access point of a radio access network (RAN) during flight of the unmanned aerial vehicle (UAV) on a flight route, channel allocation instructions for connecting the UAV to the radio access network via communication channels. The method may further include detecting an interference event associated with a portion of the flight route of the UAV during the flight. The method may further include adjusting, during the flight, the channel allocation instructions in response to detecting the interference event. The method may further include providing the adjusted channel allocation instructions to an access point of the radio access network during the flight."
METHODS AND SYSTEMS FOR INTEGRATING AUTONOMOUS DEVICES WITH AN ACCESS CONTROL SYSTEM,https://lens.org/058-037-338-285-378,2023,"Apparatus and methods for integrating autonomous devices with an Access Control System (ACS) includes assigning, by the ACS, one or more security credentials to an autonomous device. The ACS receives an access request from an autonomous device. The access request includes one or more security credentials identifying the autonomous device to the system. The ACS performs validation of the received access request by comparing the received one or more security credentials with the one or more security credentials assigned to the autonomous device. The ACS grants access to one or more resources in a building to the autonomous device, in response to successful validation of the received access request."
METHOD AND APPARATUS FOR ADJUSTING DETECTION THRESHOLD FOR ACTIVATING VOICE ASSISTANT FUNCTION,https://lens.org/127-126-500-197-786,2015,"A method for activating a voice assistant function in a mobile device is disclosed. The method includes receiving an input sound stream by a sound sensor and determining a context of the mobile device. The method may determine the context based on the input sound stream. For determining the context, the method may also obtain data indicative of the context of the mobile device from at least one of an acceleration sensor, a location sensor, an illumination sensor, a proximity sensor, a clock unit, and a calendar unit in the mobile device. In this method, a threshold for activating the voice assistant function is adjusted based on the context. The method detects a target keyword from the input sound stream based on the adjusted threshold. If the target keyword is detected, the method activates the voice assistant function."
METHOD AND APPARATUS FOR ADJUSTING DETECTION THRESHOLD FOR ACTIVATING VOICE ASSISTANT FUNCTION,https://lens.org/184-766-697-672-036,2015,"A method for activating a voice assistant function in a mobile device is disclosed. The method includes receiving an input sound stream by a sound sensor and determining a context of the mobile device. The method may determine the context based on the input sound stream. For determining the context, the method may also obtain data indicative of the context of the mobile device from at least one of an acceleration sensor, a location sensor, an illumination sensor, a proximity sensor, a clock unit, and a calendar unit in the mobile device. In this method, a threshold for activating the voice assistant function is adjusted based on the context. The method detects a target keyword from the input sound stream based on the adjusted threshold. If the target keyword is detected, the method activates the voice assistant function."
Method and apparatus for adjusting detection threshold for activating voice assistant function,https://lens.org/096-396-606-490-240,2016,"A method for activating a voice assistant function in a mobile device is disclosed. The method includes receiving an input sound stream by a sound sensor and determining a context of the mobile device. The method may determine the context based on the input sound stream. For determining the context, the method may also obtain data indicative of the context of the mobile device from at least one of an acceleration sensor, a location sensor, an illumination sensor, a proximity sensor, a clock unit, and a calendar unit in the mobile device. In this method, a threshold for activating the voice assistant function is adjusted based on the context. The method detects a target keyword from the input sound stream based on the adjusted threshold. If the target keyword is detected, the method activates the voice assistant function."
METHOD AND APPARATUS FOR ADJUSTING DETECTION THRESHOLD FOR ACTIVATING VOICE ASSISTANT FUNCTION,https://lens.org/029-655-579-738-776,2020,"A method for activating a voice assistant function in a mobile device is disclosed. The method includes receiving an input sound stream by a sound sensor and determining a context of the mobile device. The method may determine the context based on the input sound stream. For determining the context, the method may also obtain data indicative of the context of the mobile device from at least one of an acceleration sensor, a location sensor, an illumination sensor, a proximity sensor, a clock unit, and a calendar unit in the mobile device. In this method, a threshold for activating the voice assistant function is adjusted based on the context. The method detects a target keyword from the input sound stream based on the adjusted threshold. If the target keyword is detected, the method activates the voice assistant function."
Airborne manipulator unmanned aerial vehicle (UAV),https://lens.org/015-263-144-917-563,2008,"A manipulator arm system (1) on a ducted air-fan UAV is disclosed herein. The target site may be accurately located by the UAV, and the manipulator system may accurately locate the payload at the target site. The manipulator arm may select tools from a toolbox located on-board the UAV to assist in payload placement or the execution of remote operations. The system may handle the delivery of mission payloads, environmental sampling, and sensor placement and repair."
Airborne manipulator unmanned aerial vehicle (UAV),https://lens.org/122-768-497-407-043,2011,"A manipulator arm system (1) on a ducted air-fan UAV is disclosed herein. The target site may be accurately located by the UAV, and the manipulator system may accurately locate the payload at the target site. The manipulator arm may select tools from a toolbox located on-board the UAV to assist in payload placement or the execution of remote operations. The system may handle the delivery of mission payloads, environmental sampling, and sensor placement and repair.
"
Remote assistance visual controller,https://lens.org/180-910-480-789-127,2016,"The invention discloses a remote assistance visual controller. The controller comprises a camera, a WIFI module, a battery module, an onboard microphone and loudspeaker, an operation keyboard, a bluetooth module, a display screen, an infrared emitter, an ARM processor and a mobile communication module. The controller is in interaction with a server and/or a mobile phone of a user through the WIFI module or the mobile communication module, and is capable of remotely monitoring and controlling various kinds of equipment in home."
Remote Control Device with Environment Mapping,https://lens.org/095-752-063-419-414,2022,A remote control device for controlling devices in an environment can utilize an environment map and location information to accurately determine an intended device to provide control for multiple devices in an environment. The environment mapping can be performed using the remote control device including a plurality of sensors. A spatial map can be generated for an environment along with location information for controllable devices within the environment. The spatial map and location information can be stored on the remote control device. The mapping can allow the remote control device to quickly group devices or drag and drop content from one type of device to another type of device. The remote control device can perform search queries based on combinations of image and audio data in some examples.
Remote Control Device with Environment Mapping,https://lens.org/095-752-063-419-414,2022,A remote control device for controlling devices in an environment can utilize an environment map and location information to accurately determine an intended device to provide control for multiple devices in an environment. The environment mapping can be performed using the remote control device including a plurality of sensors. A spatial map can be generated for an environment along with location information for controllable devices within the environment. The spatial map and location information can be stored on the remote control device. The mapping can allow the remote control device to quickly group devices or drag and drop content from one type of device to another type of device. The remote control device can perform search queries based on combinations of image and audio data in some examples.
Remote Control Device with Environment Mapping,https://lens.org/095-752-063-419-414,2022,A remote control device for controlling devices in an environment can utilize an environment map and location information to accurately determine an intended device to provide control for multiple devices in an environment. The environment mapping can be performed using the remote control device including a plurality of sensors. A spatial map can be generated for an environment along with location information for controllable devices within the environment. The spatial map and location information can be stored on the remote control device. The mapping can allow the remote control device to quickly group devices or drag and drop content from one type of device to another type of device. The remote control device can perform search queries based on combinations of image and audio data in some examples.
AUTONOMOUS GOLF COMPETITION SYSTEMS AND METHODS,https://lens.org/045-014-576-955-273,2021,A system for monitoring and recording and processing an activity includes one or more cameras for automatically recording video of the activity. A remote media system is located at the location of the activity. A network media processor and services is communicatively coupled with the remote media system. The remote media system includes one or more AI enabled cameras. The AI enabled camera is configured to record the activity. The network media processor is configured to receive an activation request of the AI enabled camera and the validate the record request. The system may automatically administer a skill-based competition.
Autonomous golf competition systems and methods,https://lens.org/097-411-525-543-67X,2023,A system for monitoring and recording and processing an activity includes one or more cameras for automatically recording video of the activity. A remote media system is located at the location of the activity. A network media processor and services is communicatively coupled with the remote media system. The remote media system includes one or more AI enabled cameras. The AI enabled camera is configured to record the activity. The network media processor is configured to receive an activation request of the AI enabled camera and the validate the record request. The system may automatically administer a skill-based competition.
Autonomous golf competition systems and methods,https://lens.org/162-112-803-502-006,2023,A system for monitoring and recording and processing an activity includes one or more cameras for automatically recording video of the activity. A remote media system is located at the location of the activity. A network media processor and services is communicatively coupled with the remote media system. The remote media system includes one or more AI enabled cameras. The AI enabled camera is configured to record the activity. The network media processor is configured to receive an activation request of the AI enabled camera and the validate the record request. The system may automatically administer a skill-based competition.
Autonomous golf competition systems and methods,https://lens.org/097-411-525-543-67X,2023,A system for monitoring and recording and processing an activity includes one or more cameras for automatically recording video of the activity. A remote media system is located at the location of the activity. A network media processor and services is communicatively coupled with the remote media system. The remote media system includes one or more AI enabled cameras. The AI enabled camera is configured to record the activity. The network media processor is configured to receive an activation request of the AI enabled camera and the validate the record request. The system may automatically administer a skill-based competition.
AUTONOMOUS GOLF COMPETITION SYSTEMS AND METHODS,https://lens.org/143-808-322-075-820,2022,A system for monitoring and recording and processing an activity includes one or more cameras for automatically recording video of the activity. A remote media system is located at the location of the activity. A network media processor and services is communicatively coupled with the remote media system. The remote media system includes one or more AI enabled cameras. The AI enabled camera is configured to record the activity. The network media processor is configured to receive an activation request of the AI enabled camera and the validate the record request. The system may automatically administer a skill-based competition.
Autonomous golf competition systems and methods,https://lens.org/162-112-803-502-006,2023,A system for monitoring and recording and processing an activity includes one or more cameras for automatically recording video of the activity. A remote media system is located at the location of the activity. A network media processor and services is communicatively coupled with the remote media system. The remote media system includes one or more AI enabled cameras. The AI enabled camera is configured to record the activity. The network media processor is configured to receive an activation request of the AI enabled camera and the validate the record request. The system may automatically administer a skill-based competition.
Method and apparatus for controlling the functions of an image capturing apparatus,https://lens.org/070-449-686-221-974,2007,"A control apparatus for remotely controlling one of adjusting functions of an image capturing apparatus, including contrast, gamma, sharpness, and aperture. The control apparatus transmits to the image capture apparatus a first command requesting a current value of the adjusting function of the image capture apparatus and a second command requesting a remotely controllable range of the adjusting function. The control apparatus detects the current value of the adjusting function from a response to the first command and a remotely controllable range of the adjusting function from a response to the second command. The control apparatus then displays the current value and the remotely controllable range of the adjusting function on a display unit of the control apparatus."
Voice Control Device and Voice Control Method and Display Device,https://lens.org/161-579-159-791-224,2011,"A voice control device for a display device includes a voice receiver for receiving a voice signal, a voice recognition unit coupled to the voice receiver for recognizing the voice signal to generate a recognition result, a function decision unit coupled to the voice recognition unit for selecting an operating function from a plurality of operating functions according to the recognition result, and an execution unit coupled to the function decision unit for controlling the display device to perform the operating function."
APPARATUS FOR CONSTRUCTING DEVICE INFORMATION FOR CONTROL OF SMART APPLIANCES AND METHOD THEREOF,https://lens.org/087-098-631-777-41X,2014,"An apparatus for constructing device information for control of smart appliances includes a camera member, which generates multi-view images for 3D reconstruction through multi-angle photographing in an indoor space using a depth camera, and generates 3D data using the generated multi-view images, and a home device controller, which constructs a 3D space using the generated 3D data, and constructs a device profile for controlling an operation of a device to be controlled, which is designated by a user, through combination of spatial data of the device to be controlled and the constructed 3D space."
An uninhabited airborne vehicle in-flight refueling system,https://lens.org/029-485-913-893-730,2004,"A method and system is provided for performing automated air refueling of uninhabited airborne vehicles (UAVs). The method and system includes any combination of a positioning system component (42a), an air collision avoidance system (ACAS) component (94), a voice processing component (80), an image processing component (88), a flight controller (64), a wireless data link connecting the UAV with the tanker (30), and refueling components (36). The ACAS component (94) receives position information of other aircraft, such as UAVs and tankers, over the wireless data link, and generates navigation instructions based on the received position information, and sends the generated navigation instructions to the flight controller (64). The refueling components (36) include sensors that determine the status of the refueling components. Refueling of the UAV is based on the determined status. <IMAGE>"
Micro self-aware autonomous aerial vehicle for home safety and security,https://lens.org/126-442-434-162-945,2020,"A system for use in monitoring a building. The system comprises a heavier-than-air programmable aircraft (aircraft) of dimensions suitable for use in the building and adapted to move within the building in the air, a position determining system adapted to determine a relative position of the aircraft within any room of the building and acquire additional spatial information of any room within the building so that the aircraft can travel within the building, and wherein the position determining system is further adapted to facilitate generation of a three-dimensional image representing an interior space of the building, one or more communications systems adapted to be carried by the aircraft, and a processor system adapted to receive data and commands through use of the one or more communications systems, and facilitate generation of the three dimensional image of the interior space of the building through use of the position determining system."
Connected accessory for a voice-controlled device,https://lens.org/073-667-784-846-550,2022,"Coordinated operation of a voice-controlled device and an accessory device in an environment is described. A remote system processes audio data it receives from the voice-controlled device in the environment to identify a first intent associated with a first domain, a second intent associated with a second domain, and a named entity associated with the audio data. The remote system sends, to the voice-controlled device, first information for accessing main content associated with the named entity, and a first instruction corresponding to the first intent. The remote system also sends, to the accessory device, second information for accessing control information or supplemental content associated with the main content, and a second instruction corresponding to the second intent. The first and second instructions, when processed by the devices in the environment, cause coordinated operation of the voice-controlled device and the accessory device."
Connected accessory for a voice-controlled device,https://lens.org/055-528-595-754-064,2019,"Coordinated operation of a voice-controlled device and an accessory device in an environment is described. A remote system processes audio data it receives from the voice-controlled device in the environment to identify a first intent associated with a first domain, a second intent associated with a second domain, and a named entity associated with the audio data. The remote system sends, to the voice-controlled device, first information for accessing main content associated with the named entity, and a first instruction corresponding to the first intent. The remote system also sends, to the accessory device, second information for accessing control information or supplemental content associated with the main content, and a second instruction corresponding to the second intent. The first and second instructions, when processed by the devices in the environment, cause coordinated operation of the voice-controlled device and the accessory device."
Connected accessory for a voice-controlled device,https://lens.org/073-667-784-846-550,2022,"Coordinated operation of a voice-controlled device and an accessory device in an environment is described. A remote system processes audio data it receives from the voice-controlled device in the environment to identify a first intent associated with a first domain, a second intent associated with a second domain, and a named entity associated with the audio data. The remote system sends, to the voice-controlled device, first information for accessing main content associated with the named entity, and a first instruction corresponding to the first intent. The remote system also sends, to the accessory device, second information for accessing control information or supplemental content associated with the main content, and a second instruction corresponding to the second intent. The first and second instructions, when processed by the devices in the environment, cause coordinated operation of the voice-controlled device and the accessory device."
Connected accessory for a voice-controlled device,https://lens.org/138-991-364-532-740,2018,"Coordinated operation of a voice-controlled device and an accessory device in an environment is described. A remote system processes audio data it receives from the voice-controlled device in the environment to identify a first intent associated with a first domain, a second intent associated with a second domain, and a named entity associated with the audio data. The remote system sends, to the voice-controlled device, first information for accessing main content associated with the named entity, and a first instruction corresponding to the first intent. The remote system also sends, to the accessory device, second information for accessing control information or supplemental content associated with the main content, and a second instruction corresponding to the second intent. The first and second instructions, when processed by the devices in the environment, cause coordinated operation of the voice-controlled device and the accessory device."
Smart device active monitoring,https://lens.org/153-253-378-791-531,2022,"A wake-up command is received from a user. A smart device for receiving is awakened for processing a user prompt in response to receiving the wake-up command. A user-defined event is received within the user prompt. During the user-defined event, the smart device is to remain awake and monitor a predetermined set of user activities without additional wake-up commands. The predetermined set of user activities is monitored during the user-defined event using the smart device."
SMART DEVICE ACTIVE MONITORING,https://lens.org/038-602-410-684-570,2021,"A wake-up command is received from a user. A smart device for receiving is awakened for processing a user prompt in response to receiving the wake-up command. A user-defined event is received within the user prompt. During the user-defined event, the smart device is to remain awake and monitor a predetermined set of user activities without additional wake-up commands. The predetermined set of user activities is monitored during the user-defined event using the smart device."
Smart device active monitoring,https://lens.org/153-253-378-791-531,2022,"A wake-up command is received from a user. A smart device for receiving is awakened for processing a user prompt in response to receiving the wake-up command. A user-defined event is received within the user prompt. During the user-defined event, the smart device is to remain awake and monitor a predetermined set of user activities without additional wake-up commands. The predetermined set of user activities is monitored during the user-defined event using the smart device."
AN AERIAL VEHICLE ALSO CAPABLE OF MOVING ON INCLINED SURFACES,https://lens.org/131-474-599-194-264,2022,"A flying driving vehicle, comprising a body; a driving interface coupled to the body, configured to enable the body to drive on a surface and one or more driving actuators configured to provide power to the driving interface; a set of propellers coupled to the body; wherein the propellers' movement keep the vehicle in place when the surface is in slope; a controller for controlling the speed of the driving interface, a rotation speed of the set of propellers and a magnitude and direction of thrust applied by the set of propellers"
AN AERIAL VEHICLE ALSO CAPABLE OF MOVING ON INCLINED SURFACES,https://lens.org/131-474-599-194-264,2022,"A flying driving vehicle, comprising a body; a driving interface coupled to the body, configured to enable the body to drive on a surface and one or more driving actuators configured to provide power to the driving interface; a set of propellers coupled to the body; wherein the propellers' movement keep the vehicle in place when the surface is in slope; a controller for controlling the speed of the driving interface, a rotation speed of the set of propellers and a magnitude and direction of thrust applied by the set of propellers"
DRONE FOR PAINTING OUTER WALL OF MULTI-STORY BUILDING,https://lens.org/094-940-097-551-415,2022,"The present invention relates to a drone for painting an outer wall of a multi-story building and, more specifically, to a painting drone which can float and move in the air and comprises a drone body and a floating and moving part for floating and moving the drone body in the air. A camera unit for obtaining an image of the outer surface of a building is provided on the drone body. Driving wheels for guidance to the outer surface of the building are provided on one surface of the drone body. Absorption angle members are further formed on the drone body in order to absorb the impact from the building. Paint nozzle parts for painting by spraying paint on the outer surface of the building are further formed on the drone body. By using a drone which can float and move in the air to paint an outer wall of a skyscraper, cost or painting the sky scraper can be reduced, the painting work can be simplified, fatal accidents due to falls can be prevented, and painting time can be shortened."
DRONE FOR PAINTING OUTER WALL OF MULTI-STORY BUILDING,https://lens.org/094-940-097-551-415,2022,"The present invention relates to a drone for painting an outer wall of a multi-story building and, more specifically, to a painting drone which can float and move in the air and comprises a drone body and a floating and moving part for floating and moving the drone body in the air. A camera unit for obtaining an image of the outer surface of a building is provided on the drone body. Driving wheels for guidance to the outer surface of the building are provided on one surface of the drone body. Absorption angle members are further formed on the drone body in order to absorb the impact from the building. Paint nozzle parts for painting by spraying paint on the outer surface of the building are further formed on the drone body. By using a drone which can float and move in the air to paint an outer wall of a skyscraper, cost or painting the sky scraper can be reduced, the painting work can be simplified, fatal accidents due to falls can be prevented, and painting time can be shortened."
MOBILE INDUSTRIAL ROBOT WITH SECURITY SYSTEM FOR PALLET DOCKETING,https://lens.org/012-366-442-461-341,2020,There is provided a mobile industrial robot with a security system based on 3D camera technology mounted on the robot for detecting obstacles located in a pallet storage rack area in order to prevent the robot from colliding with obstacles on the pallet storage rack.
MOBILE INDUSTRIAL ROBOT WITH SECURITY SYSTEM FOR PALLET DOCKETING,https://lens.org/012-366-442-461-341,2020,There is provided a mobile industrial robot with a security system based on 3D camera technology mounted on the robot for detecting obstacles located in a pallet storage rack area in order to prevent the robot from colliding with obstacles on the pallet storage rack.
First response locator system,https://lens.org/081-559-374-227-193,2018,"A first response locator system includes at least one emergency locator unit having a main body and a lighting unit for generating light in a plurality of different colors. Indicia is disposed along the main body, and a speaker for generating an audible sound is positioned along the main body. An internal controller controls the operation of the speaker and the lighting unit. A remote operation device communicates with the internal controller and includes a plurality of buttons for selectively activating one or both of the lighting unit and the speaker."
FIRST RESPONSE LOCATOR SYSTEM,https://lens.org/077-920-075-664-684,2017,"A first response locator system includes at least one emergency locator unit having a main body and a lighting unit for generating light in a plurality of different colors. Indicia is disposed along the main body, and a speaker for generating an audible sound is positioned along the main body. An internal controller controls the operation of the speaker and the lighting unit. A remote operation device communicates with the internal controller and includes a plurality of buttons for selectively activating one or both of the lighting unit and the speaker."
First response locator system,https://lens.org/144-709-100-407-191,2019,"A first response locator system includes at least one emergency locator unit having a main body and a lighting unit for generating light in a plurality of different colors. Indicia is disposed along the main body, and a speaker for generating an audible sound is positioned along the main body. An internal controller controls the operation of the speaker and the lighting unit. A remote operation device communicates with the internal controller and includes a plurality of buttons for selectively activating one or both of the lighting unit and the speaker."
